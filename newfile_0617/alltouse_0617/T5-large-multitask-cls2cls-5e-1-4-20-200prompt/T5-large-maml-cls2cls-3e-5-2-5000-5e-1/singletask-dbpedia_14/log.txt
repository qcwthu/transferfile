03/14/2022 15:18:23 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-cls2cls', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
03/14/2022 15:18:23 - INFO - __main__ - models/T5-large-cls2cls/singletask-dbpedia_14
03/14/2022 15:18:23 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-cls2cls', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
03/14/2022 15:18:23 - INFO - __main__ - models/T5-large-cls2cls/singletask-dbpedia_14
03/14/2022 15:30:29 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-cls2cls', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
03/14/2022 15:30:29 - INFO - __main__ - models/T5-large-cls2cls/singletask-dbpedia_14
03/14/2022 15:30:29 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-cls2cls', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
03/14/2022 15:30:29 - INFO - __main__ - models/T5-large-cls2cls/singletask-dbpedia_14
03/14/2022 15:31:21 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-cls2cls', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
03/14/2022 15:31:21 - INFO - __main__ - models/T5-large-cls2cls/singletask-dbpedia_14
03/14/2022 15:31:21 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-cls2cls', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
03/14/2022 15:31:21 - INFO - __main__ - models/T5-large-cls2cls/singletask-dbpedia_14
03/15/2022 20:42:12 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
03/15/2022 20:42:12 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14
03/15/2022 20:42:12 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
03/15/2022 20:42:12 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14
03/15/2022 20:42:14 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
03/15/2022 20:42:14 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
03/15/2022 20:42:14 - INFO - __main__ - args.device: cuda:0
03/15/2022 20:42:14 - INFO - __main__ - Using 2 gpus
03/15/2022 20:42:14 - INFO - __main__ - args.device: cuda:1
03/15/2022 20:42:14 - INFO - __main__ - Using 2 gpus
03/15/2022 20:42:14 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
03/15/2022 20:42:14 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
03/15/2022 20:42:22 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
03/15/2022 20:42:23 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 20:42:23 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 20:42:23 - INFO - __main__ - Printing 3 examples
03/15/2022 20:42:23 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
03/15/2022 20:42:23 - INFO - __main__ - ['Animal']
03/15/2022 20:42:23 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
03/15/2022 20:42:23 - INFO - __main__ - Printing 3 examples
03/15/2022 20:42:23 - INFO - __main__ - ['Animal']
03/15/2022 20:42:23 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
03/15/2022 20:42:23 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
03/15/2022 20:42:23 - INFO - __main__ - ['Animal']
03/15/2022 20:42:23 - INFO - __main__ - ['Animal']
03/15/2022 20:42:23 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
03/15/2022 20:42:23 - INFO - __main__ - ['Animal']
03/15/2022 20:42:23 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
03/15/2022 20:42:23 - INFO - __main__ - Tokenizing Input ...
03/15/2022 20:42:23 - INFO - __main__ - ['Animal']
03/15/2022 20:42:23 - INFO - __main__ - Tokenizing Input ...
03/15/2022 20:42:23 - INFO - __main__ - Tokenizing Output ...
03/15/2022 20:42:23 - INFO - __main__ - Tokenizing Output ...
03/15/2022 20:42:23 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 20:42:23 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 20:42:23 - INFO - __main__ - Printing 3 examples
03/15/2022 20:42:23 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
03/15/2022 20:42:23 - INFO - __main__ - ['Animal']
03/15/2022 20:42:23 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
03/15/2022 20:42:23 - INFO - __main__ - ['Animal']
03/15/2022 20:42:23 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
03/15/2022 20:42:23 - INFO - __main__ - ['Animal']
03/15/2022 20:42:23 - INFO - __main__ - Tokenizing Input ...
03/15/2022 20:42:23 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 20:42:23 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 20:42:23 - INFO - __main__ - Printing 3 examples
03/15/2022 20:42:23 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
03/15/2022 20:42:23 - INFO - __main__ - ['Animal']
03/15/2022 20:42:23 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
03/15/2022 20:42:23 - INFO - __main__ - ['Animal']
03/15/2022 20:42:23 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
03/15/2022 20:42:23 - INFO - __main__ - ['Animal']
03/15/2022 20:42:23 - INFO - __main__ - Tokenizing Input ...
03/15/2022 20:42:23 - INFO - __main__ - Tokenizing Output ...
03/15/2022 20:42:23 - INFO - __main__ - Tokenizing Output ...
03/15/2022 20:42:23 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 20:42:23 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 20:42:41 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 20:42:41 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 20:42:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 20:42:42 - INFO - __main__ - Starting training!
03/15/2022 20:42:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 20:42:48 - INFO - __main__ - Starting training!
03/15/2022 20:42:55 - INFO - __main__ - Step 10 Global step 10 Train loss 4.33 on epoch=0
03/15/2022 20:42:57 - INFO - __main__ - Step 20 Global step 20 Train loss 2.67 on epoch=1
03/15/2022 20:43:00 - INFO - __main__ - Step 30 Global step 30 Train loss 1.92 on epoch=2
03/15/2022 20:43:02 - INFO - __main__ - Step 40 Global step 40 Train loss 1.46 on epoch=2
03/15/2022 20:43:05 - INFO - __main__ - Step 50 Global step 50 Train loss 1.29 on epoch=3
03/15/2022 20:43:11 - INFO - __main__ - Global step 50 Train loss 2.33 Classification-F1 0.297168806186709 on epoch=3
03/15/2022 20:43:11 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.297168806186709 on epoch=3, global_step=50
03/15/2022 20:43:14 - INFO - __main__ - Step 60 Global step 60 Train loss 1.14 on epoch=4
03/15/2022 20:43:16 - INFO - __main__ - Step 70 Global step 70 Train loss 0.93 on epoch=4
03/15/2022 20:43:19 - INFO - __main__ - Step 80 Global step 80 Train loss 0.85 on epoch=5
03/15/2022 20:43:21 - INFO - __main__ - Step 90 Global step 90 Train loss 0.84 on epoch=6
03/15/2022 20:43:24 - INFO - __main__ - Step 100 Global step 100 Train loss 0.83 on epoch=7
03/15/2022 20:43:30 - INFO - __main__ - Global step 100 Train loss 0.92 Classification-F1 0.4907601108701937 on epoch=7
03/15/2022 20:43:30 - INFO - __main__ - Saving model with best Classification-F1: 0.297168806186709 -> 0.4907601108701937 on epoch=7, global_step=100
03/15/2022 20:43:32 - INFO - __main__ - Step 110 Global step 110 Train loss 0.68 on epoch=7
03/15/2022 20:43:35 - INFO - __main__ - Step 120 Global step 120 Train loss 0.63 on epoch=8
03/15/2022 20:43:37 - INFO - __main__ - Step 130 Global step 130 Train loss 0.63 on epoch=9
03/15/2022 20:43:40 - INFO - __main__ - Step 140 Global step 140 Train loss 0.56 on epoch=9
03/15/2022 20:43:43 - INFO - __main__ - Step 150 Global step 150 Train loss 0.61 on epoch=10
03/15/2022 20:43:50 - INFO - __main__ - Global step 150 Train loss 0.62 Classification-F1 0.6854439484464141 on epoch=10
03/15/2022 20:43:50 - INFO - __main__ - Saving model with best Classification-F1: 0.4907601108701937 -> 0.6854439484464141 on epoch=10, global_step=150
03/15/2022 20:43:53 - INFO - __main__ - Step 160 Global step 160 Train loss 0.42 on epoch=11
03/15/2022 20:43:56 - INFO - __main__ - Step 170 Global step 170 Train loss 0.61 on epoch=12
03/15/2022 20:43:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.47 on epoch=12
03/15/2022 20:44:01 - INFO - __main__ - Step 190 Global step 190 Train loss 0.48 on epoch=13
03/15/2022 20:44:03 - INFO - __main__ - Step 200 Global step 200 Train loss 0.40 on epoch=14
03/15/2022 20:44:10 - INFO - __main__ - Global step 200 Train loss 0.48 Classification-F1 0.6512576686924968 on epoch=14
03/15/2022 20:44:13 - INFO - __main__ - Step 210 Global step 210 Train loss 0.31 on epoch=14
03/15/2022 20:44:15 - INFO - __main__ - Step 220 Global step 220 Train loss 0.32 on epoch=15
03/15/2022 20:44:18 - INFO - __main__ - Step 230 Global step 230 Train loss 0.28 on epoch=16
03/15/2022 20:44:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.31 on epoch=17
03/15/2022 20:44:23 - INFO - __main__ - Step 250 Global step 250 Train loss 0.23 on epoch=17
03/15/2022 20:44:30 - INFO - __main__ - Global step 250 Train loss 0.29 Classification-F1 0.5372918667394413 on epoch=17
03/15/2022 20:44:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.22 on epoch=18
03/15/2022 20:44:35 - INFO - __main__ - Step 270 Global step 270 Train loss 0.22 on epoch=19
03/15/2022 20:44:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=19
03/15/2022 20:44:40 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=20
03/15/2022 20:44:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.28 on epoch=21
03/15/2022 20:44:49 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.8180931088678361 on epoch=21
03/15/2022 20:44:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6854439484464141 -> 0.8180931088678361 on epoch=21, global_step=300
03/15/2022 20:44:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.20 on epoch=22
03/15/2022 20:44:55 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=22
03/15/2022 20:44:57 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=23
03/15/2022 20:45:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.13 on epoch=24
03/15/2022 20:45:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.14 on epoch=24
03/15/2022 20:45:08 - INFO - __main__ - Global step 350 Train loss 0.19 Classification-F1 0.8151270964764205 on epoch=24
03/15/2022 20:45:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.17 on epoch=25
03/15/2022 20:45:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.21 on epoch=26
03/15/2022 20:45:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.16 on epoch=27
03/15/2022 20:45:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.14 on epoch=27
03/15/2022 20:45:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.13 on epoch=28
03/15/2022 20:45:28 - INFO - __main__ - Global step 400 Train loss 0.16 Classification-F1 0.7802076304518465 on epoch=28
03/15/2022 20:45:30 - INFO - __main__ - Step 410 Global step 410 Train loss 0.14 on epoch=29
03/15/2022 20:45:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.12 on epoch=29
03/15/2022 20:45:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.13 on epoch=30
03/15/2022 20:45:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.08 on epoch=31
03/15/2022 20:45:40 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=32
03/15/2022 20:45:47 - INFO - __main__ - Global step 450 Train loss 0.13 Classification-F1 0.7784965387753567 on epoch=32
03/15/2022 20:45:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.07 on epoch=32
03/15/2022 20:45:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.07 on epoch=33
03/15/2022 20:45:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.16 on epoch=34
03/15/2022 20:45:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.12 on epoch=34
03/15/2022 20:45:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.12 on epoch=35
03/15/2022 20:46:06 - INFO - __main__ - Global step 500 Train loss 0.11 Classification-F1 0.8975326780862344 on epoch=35
03/15/2022 20:46:06 - INFO - __main__ - Saving model with best Classification-F1: 0.8180931088678361 -> 0.8975326780862344 on epoch=35, global_step=500
03/15/2022 20:46:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=36
03/15/2022 20:46:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=37
03/15/2022 20:46:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.09 on epoch=37
03/15/2022 20:46:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=38
03/15/2022 20:46:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=39
03/15/2022 20:46:25 - INFO - __main__ - Global step 550 Train loss 0.10 Classification-F1 0.8183683651752237 on epoch=39
03/15/2022 20:46:28 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=39
03/15/2022 20:46:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=40
03/15/2022 20:46:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.10 on epoch=41
03/15/2022 20:46:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.11 on epoch=42
03/15/2022 20:46:38 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=42
03/15/2022 20:46:44 - INFO - __main__ - Global step 600 Train loss 0.10 Classification-F1 0.9016239473845965 on epoch=42
03/15/2022 20:46:44 - INFO - __main__ - Saving model with best Classification-F1: 0.8975326780862344 -> 0.9016239473845965 on epoch=42, global_step=600
03/15/2022 20:46:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=43
03/15/2022 20:46:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=44
03/15/2022 20:46:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=44
03/15/2022 20:46:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=45
03/15/2022 20:46:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.07 on epoch=46
03/15/2022 20:47:03 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.905819220801881 on epoch=46
03/15/2022 20:47:03 - INFO - __main__ - Saving model with best Classification-F1: 0.9016239473845965 -> 0.905819220801881 on epoch=46, global_step=650
03/15/2022 20:47:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=47
03/15/2022 20:47:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=47
03/15/2022 20:47:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=48
03/15/2022 20:47:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=49
03/15/2022 20:47:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=49
03/15/2022 20:47:22 - INFO - __main__ - Global step 700 Train loss 0.07 Classification-F1 0.8434582722385142 on epoch=49
03/15/2022 20:47:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=50
03/15/2022 20:47:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=51
03/15/2022 20:47:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=52
03/15/2022 20:47:32 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=52
03/15/2022 20:47:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=53
03/15/2022 20:47:40 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.8893358591287662 on epoch=53
03/15/2022 20:47:42 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=54
03/15/2022 20:47:45 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=54
03/15/2022 20:47:47 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=55
03/15/2022 20:47:50 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=56
03/15/2022 20:47:52 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=57
03/15/2022 20:47:58 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.8932198835647112 on epoch=57
03/15/2022 20:48:01 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=57
03/15/2022 20:48:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=58
03/15/2022 20:48:06 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=59
03/15/2022 20:48:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=59
03/15/2022 20:48:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=60
03/15/2022 20:48:17 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.9776348295916607 on epoch=60
03/15/2022 20:48:17 - INFO - __main__ - Saving model with best Classification-F1: 0.905819220801881 -> 0.9776348295916607 on epoch=60, global_step=850
03/15/2022 20:48:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=61
03/15/2022 20:48:22 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=62
03/15/2022 20:48:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=62
03/15/2022 20:48:27 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=63
03/15/2022 20:48:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=64
03/15/2022 20:48:36 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.905819220801881 on epoch=64
03/15/2022 20:48:38 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=64
03/15/2022 20:48:41 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=65
03/15/2022 20:48:43 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=66
03/15/2022 20:48:46 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=67
03/15/2022 20:48:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=67
03/15/2022 20:48:55 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.9776348295916607 on epoch=67
03/15/2022 20:48:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=68
03/15/2022 20:49:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=69
03/15/2022 20:49:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=69
03/15/2022 20:49:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
03/15/2022 20:49:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=71
03/15/2022 20:49:14 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.8973514788663974 on epoch=71
03/15/2022 20:49:16 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=72
03/15/2022 20:49:19 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=72
03/15/2022 20:49:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=73
03/15/2022 20:49:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
03/15/2022 20:49:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=74
03/15/2022 20:49:32 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.9101652674755142 on epoch=74
03/15/2022 20:49:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=75
03/15/2022 20:49:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=76
03/15/2022 20:49:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=77
03/15/2022 20:49:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
03/15/2022 20:49:45 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=78
03/15/2022 20:49:51 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.826333825828311 on epoch=78
03/15/2022 20:49:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=79
03/15/2022 20:49:56 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
03/15/2022 20:49:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
03/15/2022 20:50:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
03/15/2022 20:50:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=82
03/15/2022 20:50:09 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.8974777414926599 on epoch=82
03/15/2022 20:50:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=82
03/15/2022 20:50:14 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=83
03/15/2022 20:50:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=84
03/15/2022 20:50:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
03/15/2022 20:50:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=85
03/15/2022 20:50:28 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.8973663101604277 on epoch=85
03/15/2022 20:50:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
03/15/2022 20:50:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=87
03/15/2022 20:50:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
03/15/2022 20:50:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=88
03/15/2022 20:50:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=89
03/15/2022 20:50:47 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.8933951905837333 on epoch=89
03/15/2022 20:50:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
03/15/2022 20:50:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
03/15/2022 20:50:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
03/15/2022 20:50:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
03/15/2022 20:51:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
03/15/2022 20:51:06 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.8352471285434995 on epoch=92
03/15/2022 20:51:09 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
03/15/2022 20:51:11 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=94
03/15/2022 20:51:14 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
03/15/2022 20:51:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
03/15/2022 20:51:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
03/15/2022 20:51:25 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.9038595633756923 on epoch=96
03/15/2022 20:51:28 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
03/15/2022 20:51:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=97
03/15/2022 20:51:33 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=98
03/15/2022 20:51:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
03/15/2022 20:51:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
03/15/2022 20:51:44 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.901526291508952 on epoch=99
03/15/2022 20:51:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
03/15/2022 20:51:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
03/15/2022 20:51:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
03/15/2022 20:51:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
03/15/2022 20:51:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
03/15/2022 20:52:03 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.9731478515159729 on epoch=103
03/15/2022 20:52:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=104
03/15/2022 20:52:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
03/15/2022 20:52:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
03/15/2022 20:52:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
03/15/2022 20:52:15 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
03/15/2022 20:52:21 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.968679201886033 on epoch=107
03/15/2022 20:52:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=107
03/15/2022 20:52:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
03/15/2022 20:52:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
03/15/2022 20:52:31 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
03/15/2022 20:52:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
03/15/2022 20:52:40 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9403024534327056 on epoch=110
03/15/2022 20:52:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
03/15/2022 20:52:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
03/15/2022 20:52:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
03/15/2022 20:52:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
03/15/2022 20:52:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=114
03/15/2022 20:52:58 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.9776427873202066 on epoch=114
03/15/2022 20:52:58 - INFO - __main__ - Saving model with best Classification-F1: 0.9776348295916607 -> 0.9776427873202066 on epoch=114, global_step=1600
03/15/2022 20:53:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
03/15/2022 20:53:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
03/15/2022 20:53:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
03/15/2022 20:53:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
03/15/2022 20:53:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
03/15/2022 20:53:17 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.968679201886033 on epoch=117
03/15/2022 20:53:19 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
03/15/2022 20:53:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
03/15/2022 20:53:24 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
03/15/2022 20:53:27 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
03/15/2022 20:53:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
03/15/2022 20:53:35 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9731478515159729 on epoch=121
03/15/2022 20:53:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
03/15/2022 20:53:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
03/15/2022 20:53:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
03/15/2022 20:53:46 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
03/15/2022 20:53:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
03/15/2022 20:53:54 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.9731478515159729 on epoch=124
03/15/2022 20:53:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
03/15/2022 20:53:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
03/15/2022 20:54:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
03/15/2022 20:54:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
03/15/2022 20:54:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
03/15/2022 20:54:13 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.9685255920550039 on epoch=128
03/15/2022 20:54:15 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
03/15/2022 20:54:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
03/15/2022 20:54:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=130
03/15/2022 20:54:23 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
03/15/2022 20:54:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
03/15/2022 20:54:32 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9101652674755142 on epoch=132
03/15/2022 20:54:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
03/15/2022 20:54:37 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
03/15/2022 20:54:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
03/15/2022 20:54:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.12 on epoch=134
03/15/2022 20:54:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
03/15/2022 20:54:50 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.9821297653958945 on epoch=135
03/15/2022 20:54:50 - INFO - __main__ - Saving model with best Classification-F1: 0.9776427873202066 -> 0.9821297653958945 on epoch=135, global_step=1900
03/15/2022 20:54:53 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
03/15/2022 20:54:55 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=137
03/15/2022 20:54:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
03/15/2022 20:55:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
03/15/2022 20:55:03 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
03/15/2022 20:55:09 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9686107388652702 on epoch=139
03/15/2022 20:55:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
03/15/2022 20:55:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
03/15/2022 20:55:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
03/15/2022 20:55:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
03/15/2022 20:55:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
03/15/2022 20:55:27 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9685255920550039 on epoch=142
03/15/2022 20:55:30 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=143
03/15/2022 20:55:32 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
03/15/2022 20:55:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
03/15/2022 20:55:37 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=145
03/15/2022 20:55:40 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=146
03/15/2022 20:55:46 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9731661799617208 on epoch=146
03/15/2022 20:55:48 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
03/15/2022 20:55:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=147
03/15/2022 20:55:53 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
03/15/2022 20:55:56 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
03/15/2022 20:55:58 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
03/15/2022 20:56:04 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9731741376902666 on epoch=149
03/15/2022 20:56:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
03/15/2022 20:56:09 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.11 on epoch=151
03/15/2022 20:56:12 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
03/15/2022 20:56:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
03/15/2022 20:56:17 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
03/15/2022 20:56:23 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.968679201886033 on epoch=153
03/15/2022 20:56:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=154
03/15/2022 20:56:28 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
03/15/2022 20:56:31 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
03/15/2022 20:56:33 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
03/15/2022 20:56:36 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
03/15/2022 20:56:42 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9776427873202066 on epoch=157
03/15/2022 20:56:44 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
03/15/2022 20:56:47 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
03/15/2022 20:56:49 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
03/15/2022 20:56:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
03/15/2022 20:56:55 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
03/15/2022 20:57:01 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9731478515159729 on epoch=160
03/15/2022 20:57:03 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
03/15/2022 20:57:06 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
03/15/2022 20:57:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
03/15/2022 20:57:11 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
03/15/2022 20:57:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
03/15/2022 20:57:19 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9776427873202066 on epoch=164
03/15/2022 20:57:22 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
03/15/2022 20:57:24 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=165
03/15/2022 20:57:27 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=166
03/15/2022 20:57:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
03/15/2022 20:57:32 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
03/15/2022 20:57:37 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9776427873202066 on epoch=167
03/15/2022 20:57:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
03/15/2022 20:57:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
03/15/2022 20:57:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
03/15/2022 20:57:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
03/15/2022 20:57:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
03/15/2022 20:57:56 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9821297653958945 on epoch=171
03/15/2022 20:57:59 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
03/15/2022 20:58:01 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
03/15/2022 20:58:04 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
03/15/2022 20:58:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
03/15/2022 20:58:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
03/15/2022 20:58:15 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9821297653958945 on epoch=174
03/15/2022 20:58:18 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
03/15/2022 20:58:20 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
03/15/2022 20:58:23 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
03/15/2022 20:58:25 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
03/15/2022 20:58:28 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
03/15/2022 20:58:34 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9776427873202066 on epoch=178
03/15/2022 20:58:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
03/15/2022 20:58:39 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
03/15/2022 20:58:41 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
03/15/2022 20:58:44 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
03/15/2022 20:58:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
03/15/2022 20:58:52 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9731478515159729 on epoch=182
03/15/2022 20:58:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
03/15/2022 20:58:57 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
03/15/2022 20:59:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
03/15/2022 20:59:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
03/15/2022 20:59:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
03/15/2022 20:59:10 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9731478515159729 on epoch=185
03/15/2022 20:59:13 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
03/15/2022 20:59:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
03/15/2022 20:59:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
03/15/2022 20:59:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
03/15/2022 20:59:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
03/15/2022 20:59:28 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9731661799617208 on epoch=189
03/15/2022 20:59:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
03/15/2022 20:59:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
03/15/2022 20:59:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
03/15/2022 20:59:38 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
03/15/2022 20:59:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
03/15/2022 20:59:46 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9731741376902666 on epoch=192
03/15/2022 20:59:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
03/15/2022 20:59:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
03/15/2022 20:59:54 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
03/15/2022 20:59:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
03/15/2022 20:59:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
03/15/2022 21:00:05 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9776611157659545 on epoch=196
03/15/2022 21:00:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
03/15/2022 21:00:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
03/15/2022 21:00:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
03/15/2022 21:00:15 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
03/15/2022 21:00:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
03/15/2022 21:00:23 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9777884394226898 on epoch=199
03/15/2022 21:00:26 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
03/15/2022 21:00:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
03/15/2022 21:00:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
03/15/2022 21:00:33 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
03/15/2022 21:00:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
03/15/2022 21:00:42 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9731741376902666 on epoch=203
03/15/2022 21:00:44 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
03/15/2022 21:00:47 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
03/15/2022 21:00:49 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
03/15/2022 21:00:52 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
03/15/2022 21:00:54 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
03/15/2022 21:01:00 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9644542861132723 on epoch=207
03/15/2022 21:01:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
03/15/2022 21:01:05 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
03/15/2022 21:01:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
03/15/2022 21:01:10 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
03/15/2022 21:01:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
03/15/2022 21:01:18 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9101726946888236 on epoch=210
03/15/2022 21:01:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
03/15/2022 21:01:23 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
03/15/2022 21:01:26 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
03/15/2022 21:01:28 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
03/15/2022 21:01:31 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
03/15/2022 21:01:32 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 21:01:32 - INFO - __main__ - Printing 3 examples
03/15/2022 21:01:32 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
03/15/2022 21:01:32 - INFO - __main__ - ['Animal']
03/15/2022 21:01:32 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
03/15/2022 21:01:32 - INFO - __main__ - ['Animal']
03/15/2022 21:01:32 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
03/15/2022 21:01:32 - INFO - __main__ - ['Animal']
03/15/2022 21:01:32 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:01:32 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:01:33 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 21:01:33 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 21:01:33 - INFO - __main__ - Printing 3 examples
03/15/2022 21:01:33 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
03/15/2022 21:01:33 - INFO - __main__ - ['Animal']
03/15/2022 21:01:33 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
03/15/2022 21:01:33 - INFO - __main__ - ['Animal']
03/15/2022 21:01:33 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
03/15/2022 21:01:33 - INFO - __main__ - ['Animal']
03/15/2022 21:01:33 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:01:33 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:01:33 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 21:01:37 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9821297653958945 on epoch=214
03/15/2022 21:01:37 - INFO - __main__ - save last model!
03/15/2022 21:01:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/15/2022 21:01:37 - INFO - __main__ - Start tokenizing ... 3500 instances
03/15/2022 21:01:37 - INFO - __main__ - Printing 3 examples
03/15/2022 21:01:37 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/15/2022 21:01:37 - INFO - __main__ - ['Animal']
03/15/2022 21:01:37 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/15/2022 21:01:37 - INFO - __main__ - ['Animal']
03/15/2022 21:01:37 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/15/2022 21:01:37 - INFO - __main__ - ['Village']
03/15/2022 21:01:37 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:01:39 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:01:42 - INFO - __main__ - Loaded 3500 examples from test data
03/15/2022 21:01:52 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 21:01:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 21:01:53 - INFO - __main__ - Starting training!
03/15/2022 21:03:46 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
03/15/2022 21:03:46 - INFO - __main__ - Classification-F1 on test data: 0.8499
03/15/2022 21:03:48 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.9821297653958945, test_performance=0.8499176290839263
03/15/2022 21:03:48 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
03/15/2022 21:03:49 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 21:03:49 - INFO - __main__ - Printing 3 examples
03/15/2022 21:03:49 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
03/15/2022 21:03:49 - INFO - __main__ - ['Animal']
03/15/2022 21:03:49 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
03/15/2022 21:03:49 - INFO - __main__ - ['Animal']
03/15/2022 21:03:49 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
03/15/2022 21:03:49 - INFO - __main__ - ['Animal']
03/15/2022 21:03:49 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:03:49 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:03:49 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 21:03:49 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 21:03:49 - INFO - __main__ - Printing 3 examples
03/15/2022 21:03:49 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
03/15/2022 21:03:49 - INFO - __main__ - ['Animal']
03/15/2022 21:03:49 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
03/15/2022 21:03:49 - INFO - __main__ - ['Animal']
03/15/2022 21:03:49 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
03/15/2022 21:03:49 - INFO - __main__ - ['Animal']
03/15/2022 21:03:49 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:03:50 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:03:50 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 21:04:08 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 21:04:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 21:04:09 - INFO - __main__ - Starting training!
03/15/2022 21:04:13 - INFO - __main__ - Step 10 Global step 10 Train loss 4.67 on epoch=0
03/15/2022 21:04:16 - INFO - __main__ - Step 20 Global step 20 Train loss 3.03 on epoch=1
03/15/2022 21:04:18 - INFO - __main__ - Step 30 Global step 30 Train loss 2.16 on epoch=2
03/15/2022 21:04:21 - INFO - __main__ - Step 40 Global step 40 Train loss 1.60 on epoch=2
03/15/2022 21:04:24 - INFO - __main__ - Step 50 Global step 50 Train loss 1.43 on epoch=3
03/15/2022 21:04:29 - INFO - __main__ - Global step 50 Train loss 2.58 Classification-F1 0.33303340145808086 on epoch=3
03/15/2022 21:04:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.33303340145808086 on epoch=3, global_step=50
03/15/2022 21:04:32 - INFO - __main__ - Step 60 Global step 60 Train loss 1.19 on epoch=4
03/15/2022 21:04:34 - INFO - __main__ - Step 70 Global step 70 Train loss 1.09 on epoch=4
03/15/2022 21:04:37 - INFO - __main__ - Step 80 Global step 80 Train loss 0.89 on epoch=5
03/15/2022 21:04:39 - INFO - __main__ - Step 90 Global step 90 Train loss 0.78 on epoch=6
03/15/2022 21:04:42 - INFO - __main__ - Step 100 Global step 100 Train loss 0.85 on epoch=7
03/15/2022 21:04:49 - INFO - __main__ - Global step 100 Train loss 0.96 Classification-F1 0.7136484418900612 on epoch=7
03/15/2022 21:04:49 - INFO - __main__ - Saving model with best Classification-F1: 0.33303340145808086 -> 0.7136484418900612 on epoch=7, global_step=100
03/15/2022 21:04:51 - INFO - __main__ - Step 110 Global step 110 Train loss 0.84 on epoch=7
03/15/2022 21:04:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.79 on epoch=8
03/15/2022 21:04:56 - INFO - __main__ - Step 130 Global step 130 Train loss 0.74 on epoch=9
03/15/2022 21:04:59 - INFO - __main__ - Step 140 Global step 140 Train loss 0.62 on epoch=9
03/15/2022 21:05:02 - INFO - __main__ - Step 150 Global step 150 Train loss 0.56 on epoch=10
03/15/2022 21:05:09 - INFO - __main__ - Global step 150 Train loss 0.71 Classification-F1 0.6027550886578442 on epoch=10
03/15/2022 21:05:11 - INFO - __main__ - Step 160 Global step 160 Train loss 0.56 on epoch=11
03/15/2022 21:05:14 - INFO - __main__ - Step 170 Global step 170 Train loss 0.68 on epoch=12
03/15/2022 21:05:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.52 on epoch=12
03/15/2022 21:05:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.54 on epoch=13
03/15/2022 21:05:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.56 on epoch=14
03/15/2022 21:05:29 - INFO - __main__ - Global step 200 Train loss 0.57 Classification-F1 0.7595696760746707 on epoch=14
03/15/2022 21:05:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7136484418900612 -> 0.7595696760746707 on epoch=14, global_step=200
03/15/2022 21:05:31 - INFO - __main__ - Step 210 Global step 210 Train loss 0.50 on epoch=14
03/15/2022 21:05:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.49 on epoch=15
03/15/2022 21:05:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.46 on epoch=16
03/15/2022 21:05:39 - INFO - __main__ - Step 240 Global step 240 Train loss 0.42 on epoch=17
03/15/2022 21:05:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=17
03/15/2022 21:05:49 - INFO - __main__ - Global step 250 Train loss 0.45 Classification-F1 0.7239963926076314 on epoch=17
03/15/2022 21:05:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.30 on epoch=18
03/15/2022 21:05:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=19
03/15/2022 21:05:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.40 on epoch=19
03/15/2022 21:05:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.40 on epoch=20
03/15/2022 21:06:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=21
03/15/2022 21:06:08 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.8330761469069715 on epoch=21
03/15/2022 21:06:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7595696760746707 -> 0.8330761469069715 on epoch=21, global_step=300
03/15/2022 21:06:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.33 on epoch=22
03/15/2022 21:06:14 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=22
03/15/2022 21:06:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=23
03/15/2022 21:06:19 - INFO - __main__ - Step 340 Global step 340 Train loss 0.32 on epoch=24
03/15/2022 21:06:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=24
03/15/2022 21:06:28 - INFO - __main__ - Global step 350 Train loss 0.28 Classification-F1 0.6724738622362444 on epoch=24
03/15/2022 21:06:31 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=25
03/15/2022 21:06:33 - INFO - __main__ - Step 370 Global step 370 Train loss 0.21 on epoch=26
03/15/2022 21:06:36 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=27
03/15/2022 21:06:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=27
03/15/2022 21:06:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=28
03/15/2022 21:06:48 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.6810807012512611 on epoch=28
03/15/2022 21:06:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.15 on epoch=29
03/15/2022 21:06:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.15 on epoch=29
03/15/2022 21:06:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=30
03/15/2022 21:06:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=31
03/15/2022 21:07:01 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=32
03/15/2022 21:07:07 - INFO - __main__ - Global step 450 Train loss 0.17 Classification-F1 0.6953048208431545 on epoch=32
03/15/2022 21:07:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=32
03/15/2022 21:07:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=33
03/15/2022 21:07:14 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=34
03/15/2022 21:07:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.11 on epoch=34
03/15/2022 21:07:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.17 on epoch=35
03/15/2022 21:07:28 - INFO - __main__ - Global step 500 Train loss 0.16 Classification-F1 0.9595264498761382 on epoch=35
03/15/2022 21:07:28 - INFO - __main__ - Saving model with best Classification-F1: 0.8330761469069715 -> 0.9595264498761382 on epoch=35, global_step=500
03/15/2022 21:07:30 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=36
03/15/2022 21:07:33 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=37
03/15/2022 21:07:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.11 on epoch=37
03/15/2022 21:07:38 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=38
03/15/2022 21:07:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=39
03/15/2022 21:07:47 - INFO - __main__ - Global step 550 Train loss 0.17 Classification-F1 0.7822633397200522 on epoch=39
03/15/2022 21:07:50 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=39
03/15/2022 21:07:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=40
03/15/2022 21:07:55 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=41
03/15/2022 21:07:58 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=42
03/15/2022 21:08:00 - INFO - __main__ - Step 600 Global step 600 Train loss 0.10 on epoch=42
03/15/2022 21:08:07 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.832586637711511 on epoch=42
03/15/2022 21:08:10 - INFO - __main__ - Step 610 Global step 610 Train loss 0.13 on epoch=43
03/15/2022 21:08:13 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=44
03/15/2022 21:08:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=44
03/15/2022 21:08:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=45
03/15/2022 21:08:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=46
03/15/2022 21:08:27 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.8701915230738759 on epoch=46
03/15/2022 21:08:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=47
03/15/2022 21:08:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=47
03/15/2022 21:08:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=48
03/15/2022 21:08:37 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=49
03/15/2022 21:08:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=49
03/15/2022 21:08:46 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.888854941998522 on epoch=49
03/15/2022 21:08:49 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=50
03/15/2022 21:08:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=51
03/15/2022 21:08:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
03/15/2022 21:08:57 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=52
03/15/2022 21:08:59 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=53
03/15/2022 21:09:05 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.9016239473845964 on epoch=53
03/15/2022 21:09:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=54
03/15/2022 21:09:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=54
03/15/2022 21:09:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=55
03/15/2022 21:09:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=56
03/15/2022 21:09:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=57
03/15/2022 21:09:25 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.9776427873202066 on epoch=57
03/15/2022 21:09:25 - INFO - __main__ - Saving model with best Classification-F1: 0.9595264498761382 -> 0.9776427873202066 on epoch=57, global_step=800
03/15/2022 21:09:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.09 on epoch=57
03/15/2022 21:09:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=58
03/15/2022 21:09:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=59
03/15/2022 21:09:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=59
03/15/2022 21:09:38 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=60
03/15/2022 21:09:44 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.8872727914774632 on epoch=60
03/15/2022 21:09:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=61
03/15/2022 21:09:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=62
03/15/2022 21:09:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=62
03/15/2022 21:09:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=63
03/15/2022 21:09:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=64
03/15/2022 21:10:03 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.9731478515159729 on epoch=64
03/15/2022 21:10:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=64
03/15/2022 21:10:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=65
03/15/2022 21:10:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=66
03/15/2022 21:10:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=67
03/15/2022 21:10:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=67
03/15/2022 21:10:23 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.8192028840389765 on epoch=67
03/15/2022 21:10:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=68
03/15/2022 21:10:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=69
03/15/2022 21:10:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
03/15/2022 21:10:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
03/15/2022 21:10:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
03/15/2022 21:10:43 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.9733014613470022 on epoch=71
03/15/2022 21:10:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=72
03/15/2022 21:10:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
03/15/2022 21:10:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
03/15/2022 21:10:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
03/15/2022 21:10:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=74
03/15/2022 21:11:03 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.908022157054415 on epoch=74
03/15/2022 21:11:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
03/15/2022 21:11:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=76
03/15/2022 21:11:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=77
03/15/2022 21:11:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
03/15/2022 21:11:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
03/15/2022 21:11:23 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.9403489930494872 on epoch=78
03/15/2022 21:11:25 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=79
03/15/2022 21:11:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
03/15/2022 21:11:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=80
03/15/2022 21:11:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=81
03/15/2022 21:11:36 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=82
03/15/2022 21:11:42 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.908022157054415 on epoch=82
03/15/2022 21:11:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
03/15/2022 21:11:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=83
03/15/2022 21:11:50 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
03/15/2022 21:11:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=84
03/15/2022 21:11:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
03/15/2022 21:12:02 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.9686529157117392 on epoch=85
03/15/2022 21:12:04 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
03/15/2022 21:12:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
03/15/2022 21:12:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=87
03/15/2022 21:12:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
03/15/2022 21:12:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
03/15/2022 21:12:21 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.973170543877375 on epoch=89
03/15/2022 21:12:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
03/15/2022 21:12:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
03/15/2022 21:12:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
03/15/2022 21:12:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
03/15/2022 21:12:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
03/15/2022 21:12:41 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.9060272075594656 on epoch=92
03/15/2022 21:12:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
03/15/2022 21:12:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
03/15/2022 21:12:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
03/15/2022 21:12:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
03/15/2022 21:12:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
03/15/2022 21:13:01 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.9597295809819528 on epoch=96
03/15/2022 21:13:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
03/15/2022 21:13:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
03/15/2022 21:13:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
03/15/2022 21:13:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
03/15/2022 21:13:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
03/15/2022 21:13:21 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.9731785016059209 on epoch=99
03/15/2022 21:13:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
03/15/2022 21:13:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
03/15/2022 21:13:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
03/15/2022 21:13:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
03/15/2022 21:13:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=103
03/15/2022 21:13:41 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.9059945278209035 on epoch=103
03/15/2022 21:13:43 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
03/15/2022 21:13:46 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
03/15/2022 21:13:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
03/15/2022 21:13:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
03/15/2022 21:13:54 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
03/15/2022 21:14:00 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.9687098519759809 on epoch=107
03/15/2022 21:14:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=107
03/15/2022 21:14:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
03/15/2022 21:14:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
03/15/2022 21:14:10 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
03/15/2022 21:14:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
03/15/2022 21:14:20 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.9686529157117392 on epoch=110
03/15/2022 21:14:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
03/15/2022 21:14:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
03/15/2022 21:14:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
03/15/2022 21:14:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
03/15/2022 21:14:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
03/15/2022 21:14:39 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.855196878054741 on epoch=114
03/15/2022 21:14:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
03/15/2022 21:14:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=115
03/15/2022 21:14:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
03/15/2022 21:14:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
03/15/2022 21:14:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
03/15/2022 21:14:59 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8951723344813707 on epoch=117
03/15/2022 21:15:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
03/15/2022 21:15:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
03/15/2022 21:15:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=119
03/15/2022 21:15:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
03/15/2022 21:15:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
03/15/2022 21:15:18 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9081409924673682 on epoch=121
03/15/2022 21:15:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
03/15/2022 21:15:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
03/15/2022 21:15:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
03/15/2022 21:15:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
03/15/2022 21:15:31 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
03/15/2022 21:15:38 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.968679201886033 on epoch=124
03/15/2022 21:15:41 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
03/15/2022 21:15:43 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
03/15/2022 21:15:46 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
03/15/2022 21:15:48 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
03/15/2022 21:15:51 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
03/15/2022 21:15:58 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.9731478515159729 on epoch=128
03/15/2022 21:16:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
03/15/2022 21:16:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
03/15/2022 21:16:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
03/15/2022 21:16:08 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
03/15/2022 21:16:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
03/15/2022 21:16:18 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9733014613470022 on epoch=132
03/15/2022 21:16:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
03/15/2022 21:16:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
03/15/2022 21:16:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
03/15/2022 21:16:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
03/15/2022 21:16:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
03/15/2022 21:16:38 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9733014613470022 on epoch=135
03/15/2022 21:16:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
03/15/2022 21:16:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
03/15/2022 21:16:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
03/15/2022 21:16:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
03/15/2022 21:16:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
03/15/2022 21:16:57 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9731478515159729 on epoch=139
03/15/2022 21:17:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
03/15/2022 21:17:02 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
03/15/2022 21:17:05 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
03/15/2022 21:17:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
03/15/2022 21:17:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
03/15/2022 21:17:17 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9731618160460664 on epoch=142
03/15/2022 21:17:19 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
03/15/2022 21:17:22 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=144
03/15/2022 21:17:24 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
03/15/2022 21:17:27 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
03/15/2022 21:17:29 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=146
03/15/2022 21:17:36 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.9593925061176255 on epoch=146
03/15/2022 21:17:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
03/15/2022 21:17:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
03/15/2022 21:17:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
03/15/2022 21:17:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
03/15/2022 21:17:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
03/15/2022 21:17:55 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9061207904471662 on epoch=149
03/15/2022 21:17:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
03/15/2022 21:18:00 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
03/15/2022 21:18:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
03/15/2022 21:18:06 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
03/15/2022 21:18:08 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
03/15/2022 21:18:14 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9776427873202066 on epoch=153
03/15/2022 21:18:17 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
03/15/2022 21:18:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
03/15/2022 21:18:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
03/15/2022 21:18:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
03/15/2022 21:18:27 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
03/15/2022 21:18:34 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9731478515159729 on epoch=157
03/15/2022 21:18:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
03/15/2022 21:18:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
03/15/2022 21:18:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
03/15/2022 21:18:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
03/15/2022 21:18:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
03/15/2022 21:18:54 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9731478515159729 on epoch=160
03/15/2022 21:18:57 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
03/15/2022 21:18:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
03/15/2022 21:19:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
03/15/2022 21:19:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
03/15/2022 21:19:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
03/15/2022 21:19:13 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9733014613470022 on epoch=164
03/15/2022 21:19:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
03/15/2022 21:19:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
03/15/2022 21:19:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
03/15/2022 21:19:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
03/15/2022 21:19:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
03/15/2022 21:19:33 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9731478515159729 on epoch=167
03/15/2022 21:19:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
03/15/2022 21:19:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
03/15/2022 21:19:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
03/15/2022 21:19:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
03/15/2022 21:19:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
03/15/2022 21:19:52 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9731478515159729 on epoch=171
03/15/2022 21:19:55 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
03/15/2022 21:19:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
03/15/2022 21:20:00 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
03/15/2022 21:20:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
03/15/2022 21:20:05 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
03/15/2022 21:20:13 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9686529157117392 on epoch=174
03/15/2022 21:20:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
03/15/2022 21:20:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
03/15/2022 21:20:21 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
03/15/2022 21:20:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
03/15/2022 21:20:26 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
03/15/2022 21:20:32 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9103086366511413 on epoch=178
03/15/2022 21:20:34 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
03/15/2022 21:20:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
03/15/2022 21:20:39 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
03/15/2022 21:20:42 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
03/15/2022 21:20:44 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
03/15/2022 21:20:51 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9061207904471662 on epoch=182
03/15/2022 21:20:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
03/15/2022 21:20:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
03/15/2022 21:20:58 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
03/15/2022 21:21:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
03/15/2022 21:21:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
03/15/2022 21:21:10 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9731478515159729 on epoch=185
03/15/2022 21:21:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
03/15/2022 21:21:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
03/15/2022 21:21:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
03/15/2022 21:21:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
03/15/2022 21:21:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
03/15/2022 21:21:29 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9686835658016871 on epoch=189
03/15/2022 21:21:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
03/15/2022 21:21:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
03/15/2022 21:21:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
03/15/2022 21:21:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/15/2022 21:21:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
03/15/2022 21:21:48 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9731478515159729 on epoch=192
03/15/2022 21:21:50 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
03/15/2022 21:21:53 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
03/15/2022 21:21:56 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
03/15/2022 21:21:58 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
03/15/2022 21:22:01 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
03/15/2022 21:22:07 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9688328117170623 on epoch=196
03/15/2022 21:22:10 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
03/15/2022 21:22:12 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
03/15/2022 21:22:15 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
03/15/2022 21:22:17 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
03/15/2022 21:22:20 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
03/15/2022 21:22:26 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9104348992774038 on epoch=199
03/15/2022 21:22:29 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
03/15/2022 21:22:31 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
03/15/2022 21:22:34 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
03/15/2022 21:22:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
03/15/2022 21:22:39 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
03/15/2022 21:22:46 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9104348992774038 on epoch=203
03/15/2022 21:22:48 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
03/15/2022 21:22:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
03/15/2022 21:22:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
03/15/2022 21:22:56 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
03/15/2022 21:22:58 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
03/15/2022 21:23:04 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8439747730307503 on epoch=207
03/15/2022 21:23:07 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
03/15/2022 21:23:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
03/15/2022 21:23:12 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
03/15/2022 21:23:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
03/15/2022 21:23:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
03/15/2022 21:23:23 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9776348295916607 on epoch=210
03/15/2022 21:23:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
03/15/2022 21:23:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
03/15/2022 21:23:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
03/15/2022 21:23:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
03/15/2022 21:23:36 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
03/15/2022 21:23:38 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 21:23:38 - INFO - __main__ - Printing 3 examples
03/15/2022 21:23:38 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
03/15/2022 21:23:38 - INFO - __main__ - ['Animal']
03/15/2022 21:23:38 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
03/15/2022 21:23:38 - INFO - __main__ - ['Animal']
03/15/2022 21:23:38 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
03/15/2022 21:23:38 - INFO - __main__ - ['Animal']
03/15/2022 21:23:38 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:23:38 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:23:38 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 21:23:38 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 21:23:38 - INFO - __main__ - Printing 3 examples
03/15/2022 21:23:38 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
03/15/2022 21:23:38 - INFO - __main__ - ['Animal']
03/15/2022 21:23:38 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
03/15/2022 21:23:38 - INFO - __main__ - ['Animal']
03/15/2022 21:23:38 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
03/15/2022 21:23:38 - INFO - __main__ - ['Animal']
03/15/2022 21:23:38 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:23:38 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:23:38 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 21:23:43 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9146227454813792 on epoch=214
03/15/2022 21:23:43 - INFO - __main__ - save last model!
03/15/2022 21:23:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/15/2022 21:23:43 - INFO - __main__ - Start tokenizing ... 3500 instances
03/15/2022 21:23:43 - INFO - __main__ - Printing 3 examples
03/15/2022 21:23:43 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/15/2022 21:23:43 - INFO - __main__ - ['Animal']
03/15/2022 21:23:43 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/15/2022 21:23:43 - INFO - __main__ - ['Animal']
03/15/2022 21:23:43 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/15/2022 21:23:43 - INFO - __main__ - ['Village']
03/15/2022 21:23:43 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:23:45 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:23:48 - INFO - __main__ - Loaded 3500 examples from test data
03/15/2022 21:23:54 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 21:23:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 21:23:54 - INFO - __main__ - Starting training!
03/15/2022 21:26:11 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
03/15/2022 21:26:11 - INFO - __main__ - Classification-F1 on test data: 0.6826
03/15/2022 21:26:11 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.9776427873202066, test_performance=0.6825524641634951
03/15/2022 21:26:11 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
03/15/2022 21:26:12 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 21:26:12 - INFO - __main__ - Printing 3 examples
03/15/2022 21:26:12 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
03/15/2022 21:26:12 - INFO - __main__ - ['Animal']
03/15/2022 21:26:12 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
03/15/2022 21:26:12 - INFO - __main__ - ['Animal']
03/15/2022 21:26:12 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
03/15/2022 21:26:12 - INFO - __main__ - ['Animal']
03/15/2022 21:26:12 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:26:12 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:26:13 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 21:26:13 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 21:26:13 - INFO - __main__ - Printing 3 examples
03/15/2022 21:26:13 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
03/15/2022 21:26:13 - INFO - __main__ - ['Animal']
03/15/2022 21:26:13 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
03/15/2022 21:26:13 - INFO - __main__ - ['Animal']
03/15/2022 21:26:13 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
03/15/2022 21:26:13 - INFO - __main__ - ['Animal']
03/15/2022 21:26:13 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:26:13 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:26:13 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 21:26:31 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 21:26:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 21:26:32 - INFO - __main__ - Starting training!
03/15/2022 21:26:36 - INFO - __main__ - Step 10 Global step 10 Train loss 4.88 on epoch=0
03/15/2022 21:26:38 - INFO - __main__ - Step 20 Global step 20 Train loss 3.45 on epoch=1
03/15/2022 21:26:41 - INFO - __main__ - Step 30 Global step 30 Train loss 2.49 on epoch=2
03/15/2022 21:26:43 - INFO - __main__ - Step 40 Global step 40 Train loss 2.07 on epoch=2
03/15/2022 21:26:46 - INFO - __main__ - Step 50 Global step 50 Train loss 1.78 on epoch=3
03/15/2022 21:26:52 - INFO - __main__ - Global step 50 Train loss 2.93 Classification-F1 0.19533662143534766 on epoch=3
03/15/2022 21:26:52 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.19533662143534766 on epoch=3, global_step=50
03/15/2022 21:26:55 - INFO - __main__ - Step 60 Global step 60 Train loss 1.46 on epoch=4
03/15/2022 21:26:57 - INFO - __main__ - Step 70 Global step 70 Train loss 1.26 on epoch=4
03/15/2022 21:27:00 - INFO - __main__ - Step 80 Global step 80 Train loss 1.28 on epoch=5
03/15/2022 21:27:02 - INFO - __main__ - Step 90 Global step 90 Train loss 0.90 on epoch=6
03/15/2022 21:27:05 - INFO - __main__ - Step 100 Global step 100 Train loss 0.99 on epoch=7
03/15/2022 21:27:11 - INFO - __main__ - Global step 100 Train loss 1.18 Classification-F1 0.513206025207769 on epoch=7
03/15/2022 21:27:11 - INFO - __main__ - Saving model with best Classification-F1: 0.19533662143534766 -> 0.513206025207769 on epoch=7, global_step=100
03/15/2022 21:27:13 - INFO - __main__ - Step 110 Global step 110 Train loss 0.90 on epoch=7
03/15/2022 21:27:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.88 on epoch=8
03/15/2022 21:27:18 - INFO - __main__ - Step 130 Global step 130 Train loss 0.79 on epoch=9
03/15/2022 21:27:21 - INFO - __main__ - Step 140 Global step 140 Train loss 0.65 on epoch=9
03/15/2022 21:27:23 - INFO - __main__ - Step 150 Global step 150 Train loss 0.72 on epoch=10
03/15/2022 21:27:30 - INFO - __main__ - Global step 150 Train loss 0.79 Classification-F1 0.6745883825152539 on epoch=10
03/15/2022 21:27:30 - INFO - __main__ - Saving model with best Classification-F1: 0.513206025207769 -> 0.6745883825152539 on epoch=10, global_step=150
03/15/2022 21:27:32 - INFO - __main__ - Step 160 Global step 160 Train loss 0.71 on epoch=11
03/15/2022 21:27:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.63 on epoch=12
03/15/2022 21:27:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.56 on epoch=12
03/15/2022 21:27:40 - INFO - __main__ - Step 190 Global step 190 Train loss 0.66 on epoch=13
03/15/2022 21:27:43 - INFO - __main__ - Step 200 Global step 200 Train loss 0.61 on epoch=14
03/15/2022 21:27:49 - INFO - __main__ - Global step 200 Train loss 0.63 Classification-F1 0.6145850576278429 on epoch=14
03/15/2022 21:27:52 - INFO - __main__ - Step 210 Global step 210 Train loss 0.49 on epoch=14
03/15/2022 21:27:54 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=15
03/15/2022 21:27:57 - INFO - __main__ - Step 230 Global step 230 Train loss 0.52 on epoch=16
03/15/2022 21:28:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.50 on epoch=17
03/15/2022 21:28:02 - INFO - __main__ - Step 250 Global step 250 Train loss 0.46 on epoch=17
03/15/2022 21:28:08 - INFO - __main__ - Global step 250 Train loss 0.49 Classification-F1 0.6571853000313683 on epoch=17
03/15/2022 21:28:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.40 on epoch=18
03/15/2022 21:28:14 - INFO - __main__ - Step 270 Global step 270 Train loss 0.43 on epoch=19
03/15/2022 21:28:16 - INFO - __main__ - Step 280 Global step 280 Train loss 0.35 on epoch=19
03/15/2022 21:28:19 - INFO - __main__ - Step 290 Global step 290 Train loss 0.41 on epoch=20
03/15/2022 21:28:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.33 on epoch=21
03/15/2022 21:28:28 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.6577770501903611 on epoch=21
03/15/2022 21:28:30 - INFO - __main__ - Step 310 Global step 310 Train loss 0.34 on epoch=22
03/15/2022 21:28:33 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=22
03/15/2022 21:28:35 - INFO - __main__ - Step 330 Global step 330 Train loss 0.37 on epoch=23
03/15/2022 21:28:38 - INFO - __main__ - Step 340 Global step 340 Train loss 0.37 on epoch=24
03/15/2022 21:28:40 - INFO - __main__ - Step 350 Global step 350 Train loss 0.27 on epoch=24
03/15/2022 21:28:46 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.6695016250116679 on epoch=24
03/15/2022 21:28:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=25
03/15/2022 21:28:51 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=26
03/15/2022 21:28:54 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=27
03/15/2022 21:28:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=27
03/15/2022 21:28:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=28
03/15/2022 21:29:06 - INFO - __main__ - Global step 400 Train loss 0.27 Classification-F1 0.8117454563531694 on epoch=28
03/15/2022 21:29:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6745883825152539 -> 0.8117454563531694 on epoch=28, global_step=400
03/15/2022 21:29:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.27 on epoch=29
03/15/2022 21:29:11 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=29
03/15/2022 21:29:14 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=30
03/15/2022 21:29:16 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=31
03/15/2022 21:29:19 - INFO - __main__ - Step 450 Global step 450 Train loss 0.39 on epoch=32
03/15/2022 21:29:26 - INFO - __main__ - Global step 450 Train loss 0.28 Classification-F1 0.6550733623042315 on epoch=32
03/15/2022 21:29:28 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=32
03/15/2022 21:29:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=33
03/15/2022 21:29:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=34
03/15/2022 21:29:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=34
03/15/2022 21:29:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=35
03/15/2022 21:29:46 - INFO - __main__ - Global step 500 Train loss 0.25 Classification-F1 0.7838080813273838 on epoch=35
03/15/2022 21:29:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=36
03/15/2022 21:29:51 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=37
03/15/2022 21:29:53 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=37
03/15/2022 21:29:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=38
03/15/2022 21:29:58 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=39
03/15/2022 21:30:06 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.729306447235546 on epoch=39
03/15/2022 21:30:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=39
03/15/2022 21:30:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=40
03/15/2022 21:30:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=41
03/15/2022 21:30:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=42
03/15/2022 21:30:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=42
03/15/2022 21:30:26 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.7829758387959289 on epoch=42
03/15/2022 21:30:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=43
03/15/2022 21:30:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=44
03/15/2022 21:30:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=44
03/15/2022 21:30:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=45
03/15/2022 21:30:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=46
03/15/2022 21:30:46 - INFO - __main__ - Global step 650 Train loss 0.16 Classification-F1 0.640824643618029 on epoch=46
03/15/2022 21:30:49 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=47
03/15/2022 21:30:52 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=47
03/15/2022 21:30:54 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=48
03/15/2022 21:30:57 - INFO - __main__ - Step 690 Global step 690 Train loss 0.11 on epoch=49
03/15/2022 21:30:59 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=49
03/15/2022 21:31:07 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.7989324888616585 on epoch=49
03/15/2022 21:31:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=50
03/15/2022 21:31:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=51
03/15/2022 21:31:14 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=52
03/15/2022 21:31:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=52
03/15/2022 21:31:19 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=53
03/15/2022 21:31:27 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.7309284379362244 on epoch=53
03/15/2022 21:31:30 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=54
03/15/2022 21:31:32 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=54
03/15/2022 21:31:35 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
03/15/2022 21:31:37 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=56
03/15/2022 21:31:40 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=57
03/15/2022 21:31:47 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.7083546759003148 on epoch=57
03/15/2022 21:31:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=57
03/15/2022 21:31:52 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=58
03/15/2022 21:31:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=59
03/15/2022 21:31:57 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=59
03/15/2022 21:32:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=60
03/15/2022 21:32:07 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.6727866081426992 on epoch=60
03/15/2022 21:32:10 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=61
03/15/2022 21:32:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=62
03/15/2022 21:32:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=62
03/15/2022 21:32:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=63
03/15/2022 21:32:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=64
03/15/2022 21:32:27 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.6939432010475085 on epoch=64
03/15/2022 21:32:30 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=64
03/15/2022 21:32:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=65
03/15/2022 21:32:35 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
03/15/2022 21:32:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
03/15/2022 21:32:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=67
03/15/2022 21:32:46 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.9018066816169283 on epoch=67
03/15/2022 21:32:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8117454563531694 -> 0.9018066816169283 on epoch=67, global_step=950
03/15/2022 21:32:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=68
03/15/2022 21:32:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
03/15/2022 21:32:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=69
03/15/2022 21:32:56 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=70
03/15/2022 21:32:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
03/15/2022 21:33:05 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.8355380437137945 on epoch=71
03/15/2022 21:33:08 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
03/15/2022 21:33:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
03/15/2022 21:33:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=73
03/15/2022 21:33:15 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
03/15/2022 21:33:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
03/15/2022 21:33:24 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.847353740799839 on epoch=74
03/15/2022 21:33:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
03/15/2022 21:33:29 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=76
03/15/2022 21:33:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
03/15/2022 21:33:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=77
03/15/2022 21:33:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=78
03/15/2022 21:33:43 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.9637477278301351 on epoch=78
03/15/2022 21:33:43 - INFO - __main__ - Saving model with best Classification-F1: 0.9018066816169283 -> 0.9637477278301351 on epoch=78, global_step=1100
03/15/2022 21:33:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
03/15/2022 21:33:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
03/15/2022 21:33:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
03/15/2022 21:33:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=81
03/15/2022 21:33:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
03/15/2022 21:34:02 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.9731661799617208 on epoch=82
03/15/2022 21:34:02 - INFO - __main__ - Saving model with best Classification-F1: 0.9637477278301351 -> 0.9731661799617208 on epoch=82, global_step=1150
03/15/2022 21:34:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=82
03/15/2022 21:34:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
03/15/2022 21:34:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=84
03/15/2022 21:34:12 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=84
03/15/2022 21:34:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
03/15/2022 21:34:21 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.8973555518543413 on epoch=85
03/15/2022 21:34:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
03/15/2022 21:34:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
03/15/2022 21:34:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
03/15/2022 21:34:31 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=88
03/15/2022 21:34:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
03/15/2022 21:34:39 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.9103331704138155 on epoch=89
03/15/2022 21:34:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
03/15/2022 21:34:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
03/15/2022 21:34:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
03/15/2022 21:34:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
03/15/2022 21:34:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
03/15/2022 21:34:58 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.9061378969965309 on epoch=92
03/15/2022 21:35:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
03/15/2022 21:35:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
03/15/2022 21:35:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
03/15/2022 21:35:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
03/15/2022 21:35:10 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
03/15/2022 21:35:16 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.8066737105399345 on epoch=96
03/15/2022 21:35:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
03/15/2022 21:35:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
03/15/2022 21:35:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
03/15/2022 21:35:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
03/15/2022 21:35:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
03/15/2022 21:35:34 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.9104348992774042 on epoch=99
03/15/2022 21:35:37 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
03/15/2022 21:35:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
03/15/2022 21:35:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
03/15/2022 21:35:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
03/15/2022 21:35:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
03/15/2022 21:35:54 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.9144868035190615 on epoch=103
03/15/2022 21:35:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
03/15/2022 21:35:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
03/15/2022 21:36:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
03/15/2022 21:36:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
03/15/2022 21:36:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
03/15/2022 21:36:13 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.9821297653958945 on epoch=107
03/15/2022 21:36:13 - INFO - __main__ - Saving model with best Classification-F1: 0.9731661799617208 -> 0.9821297653958945 on epoch=107, global_step=1500
03/15/2022 21:36:15 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
03/15/2022 21:36:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
03/15/2022 21:36:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=109
03/15/2022 21:36:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=109
03/15/2022 21:36:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
03/15/2022 21:36:32 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.839448112139992 on epoch=110
03/15/2022 21:36:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
03/15/2022 21:36:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=112
03/15/2022 21:36:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
03/15/2022 21:36:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
03/15/2022 21:36:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
03/15/2022 21:36:50 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.9080392636037797 on epoch=114
03/15/2022 21:36:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
03/15/2022 21:36:55 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
03/15/2022 21:36:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
03/15/2022 21:37:00 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
03/15/2022 21:37:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
03/15/2022 21:37:09 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.9864404412791509 on epoch=117
03/15/2022 21:37:09 - INFO - __main__ - Saving model with best Classification-F1: 0.9821297653958945 -> 0.9864404412791509 on epoch=117, global_step=1650
03/15/2022 21:37:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
03/15/2022 21:37:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
03/15/2022 21:37:17 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
03/15/2022 21:37:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
03/15/2022 21:37:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
03/15/2022 21:37:28 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.9731968300516688 on epoch=121
03/15/2022 21:37:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
03/15/2022 21:37:33 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
03/15/2022 21:37:36 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
03/15/2022 21:37:38 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
03/15/2022 21:37:41 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
03/15/2022 21:37:47 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.9776654796816088 on epoch=124
03/15/2022 21:37:50 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
03/15/2022 21:37:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
03/15/2022 21:37:55 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
03/15/2022 21:37:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
03/15/2022 21:38:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
03/15/2022 21:38:06 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.9776427873202066 on epoch=128
03/15/2022 21:38:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
03/15/2022 21:38:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
03/15/2022 21:38:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
03/15/2022 21:38:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
03/15/2022 21:38:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
03/15/2022 21:38:25 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9821297653958945 on epoch=132
03/15/2022 21:38:27 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
03/15/2022 21:38:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
03/15/2022 21:38:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
03/15/2022 21:38:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
03/15/2022 21:38:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
03/15/2022 21:38:43 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9732563039878708 on epoch=135
03/15/2022 21:38:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
03/15/2022 21:38:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
03/15/2022 21:38:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
03/15/2022 21:38:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
03/15/2022 21:38:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
03/15/2022 21:39:02 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.964300676282243 on epoch=139
03/15/2022 21:39:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
03/15/2022 21:39:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
03/15/2022 21:39:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=141
03/15/2022 21:39:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
03/15/2022 21:39:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
03/15/2022 21:39:21 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9732519400722166 on epoch=142
03/15/2022 21:39:23 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
03/15/2022 21:39:26 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
03/15/2022 21:39:28 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
03/15/2022 21:39:31 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=145
03/15/2022 21:39:33 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
03/15/2022 21:39:39 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9731828655215751 on epoch=146
03/15/2022 21:39:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
03/15/2022 21:39:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
03/15/2022 21:39:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
03/15/2022 21:39:49 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
03/15/2022 21:39:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
03/15/2022 21:39:58 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9687098519759809 on epoch=149
03/15/2022 21:40:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
03/15/2022 21:40:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
03/15/2022 21:40:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
03/15/2022 21:40:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
03/15/2022 21:40:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
03/15/2022 21:40:16 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9595570999660862 on epoch=153
03/15/2022 21:40:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
03/15/2022 21:40:21 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
03/15/2022 21:40:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
03/15/2022 21:40:26 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=156
03/15/2022 21:40:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
03/15/2022 21:40:35 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9731741376902666 on epoch=157
03/15/2022 21:40:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
03/15/2022 21:40:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
03/15/2022 21:40:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
03/15/2022 21:40:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=159
03/15/2022 21:40:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
03/15/2022 21:40:54 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9687098519759809 on epoch=160
03/15/2022 21:40:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
03/15/2022 21:40:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
03/15/2022 21:41:01 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
03/15/2022 21:41:04 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
03/15/2022 21:41:06 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=164
03/15/2022 21:41:12 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9731968300516688 on epoch=164
03/15/2022 21:41:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
03/15/2022 21:41:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
03/15/2022 21:41:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
03/15/2022 21:41:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
03/15/2022 21:41:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
03/15/2022 21:41:31 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9731478515159729 on epoch=167
03/15/2022 21:41:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
03/15/2022 21:41:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
03/15/2022 21:41:39 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
03/15/2022 21:41:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
03/15/2022 21:41:44 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
03/15/2022 21:41:50 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9821297653958945 on epoch=171
03/15/2022 21:41:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=172
03/15/2022 21:41:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
03/15/2022 21:41:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
03/15/2022 21:42:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
03/15/2022 21:42:03 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
03/15/2022 21:42:09 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9821297653958945 on epoch=174
03/15/2022 21:42:11 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
03/15/2022 21:42:14 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
03/15/2022 21:42:16 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
03/15/2022 21:42:19 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
03/15/2022 21:42:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
03/15/2022 21:42:28 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9821297653958945 on epoch=178
03/15/2022 21:42:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
03/15/2022 21:42:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
03/15/2022 21:42:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=180
03/15/2022 21:42:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
03/15/2022 21:42:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
03/15/2022 21:42:46 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9776611157659545 on epoch=182
03/15/2022 21:42:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=182
03/15/2022 21:42:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
03/15/2022 21:42:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
03/15/2022 21:42:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
03/15/2022 21:42:59 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
03/15/2022 21:43:05 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9821297653958945 on epoch=185
03/15/2022 21:43:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
03/15/2022 21:43:10 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
03/15/2022 21:43:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
03/15/2022 21:43:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
03/15/2022 21:43:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
03/15/2022 21:43:24 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9776698435972629 on epoch=189
03/15/2022 21:43:26 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
03/15/2022 21:43:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
03/15/2022 21:43:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
03/15/2022 21:43:34 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
03/15/2022 21:43:36 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
03/15/2022 21:43:43 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9865984150258343 on epoch=192
03/15/2022 21:43:43 - INFO - __main__ - Saving model with best Classification-F1: 0.9864404412791509 -> 0.9865984150258343 on epoch=192, global_step=2700
03/15/2022 21:43:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
03/15/2022 21:43:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=194
03/15/2022 21:43:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
03/15/2022 21:43:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
03/15/2022 21:43:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
03/15/2022 21:44:01 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9820991153059465 on epoch=196
03/15/2022 21:44:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
03/15/2022 21:44:06 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
03/15/2022 21:44:09 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
03/15/2022 21:44:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
03/15/2022 21:44:14 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
03/15/2022 21:44:20 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9819717916492109 on epoch=199
03/15/2022 21:44:23 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
03/15/2022 21:44:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
03/15/2022 21:44:28 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
03/15/2022 21:44:30 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
03/15/2022 21:44:33 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
03/15/2022 21:44:39 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9776427873202066 on epoch=203
03/15/2022 21:44:41 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
03/15/2022 21:44:44 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
03/15/2022 21:44:46 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
03/15/2022 21:44:49 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
03/15/2022 21:44:51 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
03/15/2022 21:44:58 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9731661799617208 on epoch=207
03/15/2022 21:45:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
03/15/2022 21:45:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
03/15/2022 21:45:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
03/15/2022 21:45:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
03/15/2022 21:45:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
03/15/2022 21:45:16 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9687062581630893 on epoch=210
03/15/2022 21:45:19 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
03/15/2022 21:45:21 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
03/15/2022 21:45:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
03/15/2022 21:45:26 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
03/15/2022 21:45:29 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
03/15/2022 21:45:30 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 21:45:30 - INFO - __main__ - Printing 3 examples
03/15/2022 21:45:30 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
03/15/2022 21:45:30 - INFO - __main__ - ['Animal']
03/15/2022 21:45:30 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
03/15/2022 21:45:30 - INFO - __main__ - ['Animal']
03/15/2022 21:45:30 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
03/15/2022 21:45:30 - INFO - __main__ - ['Animal']
03/15/2022 21:45:30 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:45:30 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:45:31 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 21:45:31 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 21:45:31 - INFO - __main__ - Printing 3 examples
03/15/2022 21:45:31 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
03/15/2022 21:45:31 - INFO - __main__ - ['Animal']
03/15/2022 21:45:31 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
03/15/2022 21:45:31 - INFO - __main__ - ['Animal']
03/15/2022 21:45:31 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
03/15/2022 21:45:31 - INFO - __main__ - ['Animal']
03/15/2022 21:45:31 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:45:31 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:45:31 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 21:45:35 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9821297653958945 on epoch=214
03/15/2022 21:45:35 - INFO - __main__ - save last model!
03/15/2022 21:45:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/15/2022 21:45:35 - INFO - __main__ - Start tokenizing ... 3500 instances
03/15/2022 21:45:35 - INFO - __main__ - Printing 3 examples
03/15/2022 21:45:35 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/15/2022 21:45:35 - INFO - __main__ - ['Animal']
03/15/2022 21:45:35 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/15/2022 21:45:35 - INFO - __main__ - ['Animal']
03/15/2022 21:45:35 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/15/2022 21:45:35 - INFO - __main__ - ['Village']
03/15/2022 21:45:35 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:45:37 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:45:40 - INFO - __main__ - Loaded 3500 examples from test data
03/15/2022 21:45:47 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 21:45:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 21:45:47 - INFO - __main__ - Starting training!
03/15/2022 21:47:51 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
03/15/2022 21:47:51 - INFO - __main__ - Classification-F1 on test data: 0.7184
03/15/2022 21:47:52 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.9865984150258343, test_performance=0.7183681615610947
03/15/2022 21:47:52 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
03/15/2022 21:47:53 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 21:47:53 - INFO - __main__ - Printing 3 examples
03/15/2022 21:47:53 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
03/15/2022 21:47:53 - INFO - __main__ - ['Animal']
03/15/2022 21:47:53 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
03/15/2022 21:47:53 - INFO - __main__ - ['Animal']
03/15/2022 21:47:53 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
03/15/2022 21:47:53 - INFO - __main__ - ['Animal']
03/15/2022 21:47:53 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:47:53 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:47:53 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 21:47:53 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 21:47:53 - INFO - __main__ - Printing 3 examples
03/15/2022 21:47:53 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
03/15/2022 21:47:53 - INFO - __main__ - ['Animal']
03/15/2022 21:47:53 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
03/15/2022 21:47:53 - INFO - __main__ - ['Animal']
03/15/2022 21:47:53 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
03/15/2022 21:47:53 - INFO - __main__ - ['Animal']
03/15/2022 21:47:53 - INFO - __main__ - Tokenizing Input ...
03/15/2022 21:47:53 - INFO - __main__ - Tokenizing Output ...
03/15/2022 21:47:53 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 21:48:12 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 21:48:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 21:48:13 - INFO - __main__ - Starting training!
03/15/2022 21:48:16 - INFO - __main__ - Step 10 Global step 10 Train loss 5.22 on epoch=0
03/15/2022 21:48:20 - INFO - __main__ - Step 20 Global step 20 Train loss 3.69 on epoch=1
03/15/2022 21:48:22 - INFO - __main__ - Step 30 Global step 30 Train loss 3.01 on epoch=2
03/15/2022 21:48:25 - INFO - __main__ - Step 40 Global step 40 Train loss 2.54 on epoch=2
03/15/2022 21:48:27 - INFO - __main__ - Step 50 Global step 50 Train loss 2.26 on epoch=3
03/15/2022 21:48:33 - INFO - __main__ - Global step 50 Train loss 3.34 Classification-F1 0.11479734946089151 on epoch=3
03/15/2022 21:48:33 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11479734946089151 on epoch=3, global_step=50
03/15/2022 21:48:35 - INFO - __main__ - Step 60 Global step 60 Train loss 1.96 on epoch=4
03/15/2022 21:48:38 - INFO - __main__ - Step 70 Global step 70 Train loss 1.61 on epoch=4
03/15/2022 21:48:40 - INFO - __main__ - Step 80 Global step 80 Train loss 1.54 on epoch=5
03/15/2022 21:48:43 - INFO - __main__ - Step 90 Global step 90 Train loss 1.19 on epoch=6
03/15/2022 21:48:45 - INFO - __main__ - Step 100 Global step 100 Train loss 1.15 on epoch=7
03/15/2022 21:48:51 - INFO - __main__ - Global step 100 Train loss 1.49 Classification-F1 0.3282834277063473 on epoch=7
03/15/2022 21:48:51 - INFO - __main__ - Saving model with best Classification-F1: 0.11479734946089151 -> 0.3282834277063473 on epoch=7, global_step=100
03/15/2022 21:48:54 - INFO - __main__ - Step 110 Global step 110 Train loss 1.10 on epoch=7
03/15/2022 21:48:56 - INFO - __main__ - Step 120 Global step 120 Train loss 0.97 on epoch=8
03/15/2022 21:48:59 - INFO - __main__ - Step 130 Global step 130 Train loss 0.89 on epoch=9
03/15/2022 21:49:01 - INFO - __main__ - Step 140 Global step 140 Train loss 0.82 on epoch=9
03/15/2022 21:49:04 - INFO - __main__ - Step 150 Global step 150 Train loss 0.81 on epoch=10
03/15/2022 21:49:11 - INFO - __main__ - Global step 150 Train loss 0.92 Classification-F1 0.4398856401800849 on epoch=10
03/15/2022 21:49:11 - INFO - __main__ - Saving model with best Classification-F1: 0.3282834277063473 -> 0.4398856401800849 on epoch=10, global_step=150
03/15/2022 21:49:13 - INFO - __main__ - Step 160 Global step 160 Train loss 0.77 on epoch=11
03/15/2022 21:49:16 - INFO - __main__ - Step 170 Global step 170 Train loss 0.79 on epoch=12
03/15/2022 21:49:18 - INFO - __main__ - Step 180 Global step 180 Train loss 0.66 on epoch=12
03/15/2022 21:49:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.59 on epoch=13
03/15/2022 21:49:23 - INFO - __main__ - Step 200 Global step 200 Train loss 0.59 on epoch=14
03/15/2022 21:49:30 - INFO - __main__ - Global step 200 Train loss 0.68 Classification-F1 0.6201760454488614 on epoch=14
03/15/2022 21:49:30 - INFO - __main__ - Saving model with best Classification-F1: 0.4398856401800849 -> 0.6201760454488614 on epoch=14, global_step=200
03/15/2022 21:49:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.56 on epoch=14
03/15/2022 21:49:35 - INFO - __main__ - Step 220 Global step 220 Train loss 0.64 on epoch=15
03/15/2022 21:49:38 - INFO - __main__ - Step 230 Global step 230 Train loss 0.83 on epoch=16
03/15/2022 21:49:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.72 on epoch=17
03/15/2022 21:49:43 - INFO - __main__ - Step 250 Global step 250 Train loss 0.66 on epoch=17
03/15/2022 21:49:50 - INFO - __main__ - Global step 250 Train loss 0.68 Classification-F1 0.5796064089167537 on epoch=17
03/15/2022 21:49:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.67 on epoch=18
03/15/2022 21:49:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.64 on epoch=19
03/15/2022 21:49:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.47 on epoch=19
03/15/2022 21:50:00 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=20
03/15/2022 21:50:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.51 on epoch=21
03/15/2022 21:50:10 - INFO - __main__ - Global step 300 Train loss 0.56 Classification-F1 0.6061640525938388 on epoch=21
03/15/2022 21:50:12 - INFO - __main__ - Step 310 Global step 310 Train loss 0.57 on epoch=22
03/15/2022 21:50:15 - INFO - __main__ - Step 320 Global step 320 Train loss 0.50 on epoch=22
03/15/2022 21:50:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.49 on epoch=23
03/15/2022 21:50:20 - INFO - __main__ - Step 340 Global step 340 Train loss 0.44 on epoch=24
03/15/2022 21:50:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.46 on epoch=24
03/15/2022 21:50:28 - INFO - __main__ - Global step 350 Train loss 0.49 Classification-F1 0.6431489032176373 on epoch=24
03/15/2022 21:50:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6201760454488614 -> 0.6431489032176373 on epoch=24, global_step=350
03/15/2022 21:50:31 - INFO - __main__ - Step 360 Global step 360 Train loss 0.43 on epoch=25
03/15/2022 21:50:33 - INFO - __main__ - Step 370 Global step 370 Train loss 0.48 on epoch=26
03/15/2022 21:50:36 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=27
03/15/2022 21:50:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.45 on epoch=27
03/15/2022 21:50:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=28
03/15/2022 21:50:48 - INFO - __main__ - Global step 400 Train loss 0.43 Classification-F1 0.6867618363194116 on epoch=28
03/15/2022 21:50:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6431489032176373 -> 0.6867618363194116 on epoch=28, global_step=400
03/15/2022 21:50:51 - INFO - __main__ - Step 410 Global step 410 Train loss 0.42 on epoch=29
03/15/2022 21:50:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.40 on epoch=29
03/15/2022 21:50:56 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=30
03/15/2022 21:50:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=31
03/15/2022 21:51:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=32
03/15/2022 21:51:08 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.6787896129452107 on epoch=32
03/15/2022 21:51:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.38 on epoch=32
03/15/2022 21:51:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=33
03/15/2022 21:51:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=34
03/15/2022 21:51:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.35 on epoch=34
03/15/2022 21:51:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.34 on epoch=35
03/15/2022 21:51:28 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.8099822966209944 on epoch=35
03/15/2022 21:51:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6867618363194116 -> 0.8099822966209944 on epoch=35, global_step=500
03/15/2022 21:51:30 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=36
03/15/2022 21:51:33 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=37
03/15/2022 21:51:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.31 on epoch=37
03/15/2022 21:51:38 - INFO - __main__ - Step 540 Global step 540 Train loss 0.31 on epoch=38
03/15/2022 21:51:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=39
03/15/2022 21:51:48 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.8045021481854892 on epoch=39
03/15/2022 21:51:51 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=39
03/15/2022 21:51:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.27 on epoch=40
03/15/2022 21:51:56 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=41
03/15/2022 21:51:58 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=42
03/15/2022 21:52:00 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=42
03/15/2022 21:52:07 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.7405826761677948 on epoch=42
03/15/2022 21:52:10 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=43
03/15/2022 21:52:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.26 on epoch=44
03/15/2022 21:52:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=44
03/15/2022 21:52:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=45
03/15/2022 21:52:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=46
03/15/2022 21:52:27 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.7857050165720698 on epoch=46
03/15/2022 21:52:29 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=47
03/15/2022 21:52:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=47
03/15/2022 21:52:34 - INFO - __main__ - Step 680 Global step 680 Train loss 0.23 on epoch=48
03/15/2022 21:52:37 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=49
03/15/2022 21:52:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=49
03/15/2022 21:52:47 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.8392386634411577 on epoch=49
03/15/2022 21:52:47 - INFO - __main__ - Saving model with best Classification-F1: 0.8099822966209944 -> 0.8392386634411577 on epoch=49, global_step=700
03/15/2022 21:52:49 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=50
03/15/2022 21:52:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=51
03/15/2022 21:52:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=52
03/15/2022 21:52:57 - INFO - __main__ - Step 740 Global step 740 Train loss 0.24 on epoch=52
03/15/2022 21:52:59 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=53
03/15/2022 21:53:07 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.9506726545406312 on epoch=53
03/15/2022 21:53:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8392386634411577 -> 0.9506726545406312 on epoch=53, global_step=750
03/15/2022 21:53:10 - INFO - __main__ - Step 760 Global step 760 Train loss 0.27 on epoch=54
03/15/2022 21:53:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=54
03/15/2022 21:53:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=55
03/15/2022 21:53:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=56
03/15/2022 21:53:20 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=57
03/15/2022 21:53:27 - INFO - __main__ - Global step 800 Train loss 0.22 Classification-F1 0.8892162818206462 on epoch=57
03/15/2022 21:53:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=57
03/15/2022 21:53:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=58
03/15/2022 21:53:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=59
03/15/2022 21:53:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=59
03/15/2022 21:53:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=60
03/15/2022 21:53:47 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.7311574694046686 on epoch=60
03/15/2022 21:53:50 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=61
03/15/2022 21:53:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=62
03/15/2022 21:53:55 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=62
03/15/2022 21:53:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=63
03/15/2022 21:54:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=64
03/15/2022 21:54:08 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.8888395569910978 on epoch=64
03/15/2022 21:54:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=64
03/15/2022 21:54:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=65
03/15/2022 21:54:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
03/15/2022 21:54:18 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=67
03/15/2022 21:54:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=67
03/15/2022 21:54:28 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.9637215104466297 on epoch=67
03/15/2022 21:54:28 - INFO - __main__ - Saving model with best Classification-F1: 0.9506726545406312 -> 0.9637215104466297 on epoch=67, global_step=950
03/15/2022 21:54:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=68
03/15/2022 21:54:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=69
03/15/2022 21:54:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=69
03/15/2022 21:54:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=70
03/15/2022 21:54:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=71
03/15/2022 21:54:48 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.968679201886033 on epoch=71
03/15/2022 21:54:48 - INFO - __main__ - Saving model with best Classification-F1: 0.9637215104466297 -> 0.968679201886033 on epoch=71, global_step=1000
03/15/2022 21:54:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=72
03/15/2022 21:54:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=72
03/15/2022 21:54:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=73
03/15/2022 21:54:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=74
03/15/2022 21:55:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=74
03/15/2022 21:55:08 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.9059945278209035 on epoch=74
03/15/2022 21:55:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=75
03/15/2022 21:55:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=76
03/15/2022 21:55:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
03/15/2022 21:55:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=77
03/15/2022 21:55:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=78
03/15/2022 21:55:29 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.84313795042868 on epoch=78
03/15/2022 21:55:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
03/15/2022 21:55:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
03/15/2022 21:55:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=80
03/15/2022 21:55:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=81
03/15/2022 21:55:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=82
03/15/2022 21:55:49 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.851152401026393 on epoch=82
03/15/2022 21:55:51 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=82
03/15/2022 21:55:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=83
03/15/2022 21:55:56 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
03/15/2022 21:55:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
03/15/2022 21:56:01 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=85
03/15/2022 21:56:09 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.95956200662083 on epoch=85
03/15/2022 21:56:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
03/15/2022 21:56:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=87
03/15/2022 21:56:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
03/15/2022 21:56:19 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=88
03/15/2022 21:56:21 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
03/15/2022 21:56:29 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.8451802027629234 on epoch=89
03/15/2022 21:56:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
03/15/2022 21:56:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=90
03/15/2022 21:56:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
03/15/2022 21:56:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=92
03/15/2022 21:56:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=92
03/15/2022 21:56:49 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.9058511586452762 on epoch=92
03/15/2022 21:56:52 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
03/15/2022 21:56:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
03/15/2022 21:56:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=94
03/15/2022 21:56:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=95
03/15/2022 21:57:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=96
03/15/2022 21:57:10 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.8472231506238859 on epoch=96
03/15/2022 21:57:12 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=97
03/15/2022 21:57:15 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
03/15/2022 21:57:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=98
03/15/2022 21:57:20 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
03/15/2022 21:57:22 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
03/15/2022 21:57:30 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.9018107546048721 on epoch=99
03/15/2022 21:57:32 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
03/15/2022 21:57:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
03/15/2022 21:57:37 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=102
03/15/2022 21:57:40 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
03/15/2022 21:57:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=103
03/15/2022 21:57:49 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.8259717429662283 on epoch=103
03/15/2022 21:57:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
03/15/2022 21:57:54 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=104
03/15/2022 21:57:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=105
03/15/2022 21:57:59 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
03/15/2022 21:58:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=107
03/15/2022 21:58:09 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.7913881235695458 on epoch=107
03/15/2022 21:58:11 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=107
03/15/2022 21:58:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=108
03/15/2022 21:58:17 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
03/15/2022 21:58:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
03/15/2022 21:58:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
03/15/2022 21:58:28 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.7796035637354424 on epoch=110
03/15/2022 21:58:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
03/15/2022 21:58:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
03/15/2022 21:58:36 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
03/15/2022 21:58:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
03/15/2022 21:58:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
03/15/2022 21:58:48 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8348324595804435 on epoch=114
03/15/2022 21:58:51 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=114
03/15/2022 21:58:53 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=115
03/15/2022 21:58:56 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=116
03/15/2022 21:58:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=117
03/15/2022 21:59:01 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
03/15/2022 21:59:08 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.9059986008088475 on epoch=117
03/15/2022 21:59:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
03/15/2022 21:59:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
03/15/2022 21:59:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
03/15/2022 21:59:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
03/15/2022 21:59:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
03/15/2022 21:59:27 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.8472231506238859 on epoch=121
03/15/2022 21:59:30 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=122
03/15/2022 21:59:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
03/15/2022 21:59:35 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
03/15/2022 21:59:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
03/15/2022 21:59:40 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
03/15/2022 21:59:46 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.8472231506238859 on epoch=124
03/15/2022 21:59:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
03/15/2022 21:59:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
03/15/2022 21:59:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
03/15/2022 21:59:56 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
03/15/2022 21:59:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
03/15/2022 22:00:05 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.9731478515159729 on epoch=128
03/15/2022 22:00:05 - INFO - __main__ - Saving model with best Classification-F1: 0.968679201886033 -> 0.9731478515159729 on epoch=128, global_step=1800
03/15/2022 22:00:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
03/15/2022 22:00:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
03/15/2022 22:00:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
03/15/2022 22:00:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=131
03/15/2022 22:00:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
03/15/2022 22:00:25 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.9101652674755142 on epoch=132
03/15/2022 22:00:27 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
03/15/2022 22:00:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
03/15/2022 22:00:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
03/15/2022 22:00:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
03/15/2022 22:00:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
03/15/2022 22:00:44 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9144753033178081 on epoch=135
03/15/2022 22:00:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
03/15/2022 22:00:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
03/15/2022 22:00:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
03/15/2022 22:00:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
03/15/2022 22:00:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.09 on epoch=139
03/15/2022 22:01:03 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.799165432086238 on epoch=139
03/15/2022 22:01:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.10 on epoch=139
03/15/2022 22:01:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
03/15/2022 22:01:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
03/15/2022 22:01:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
03/15/2022 22:01:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
03/15/2022 22:01:23 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8473767412023461 on epoch=142
03/15/2022 22:01:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
03/15/2022 22:01:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
03/15/2022 22:01:30 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
03/15/2022 22:01:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
03/15/2022 22:01:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
03/15/2022 22:01:42 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8512638092260365 on epoch=146
03/15/2022 22:01:45 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
03/15/2022 22:01:47 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
03/15/2022 22:01:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
03/15/2022 22:01:52 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
03/15/2022 22:01:54 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
03/15/2022 22:02:01 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9104560788147128 on epoch=149
03/15/2022 22:02:04 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
03/15/2022 22:02:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
03/15/2022 22:02:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
03/15/2022 22:02:11 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
03/15/2022 22:02:14 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=153
03/15/2022 22:02:20 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8433130821976885 on epoch=153
03/15/2022 22:02:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
03/15/2022 22:02:25 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
03/15/2022 22:02:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
03/15/2022 22:02:30 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
03/15/2022 22:02:33 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=157
03/15/2022 22:02:39 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.8472423326001955 on epoch=157
03/15/2022 22:02:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
03/15/2022 22:02:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
03/15/2022 22:02:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
03/15/2022 22:02:49 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
03/15/2022 22:02:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
03/15/2022 22:02:58 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8451802027629234 on epoch=160
03/15/2022 22:03:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
03/15/2022 22:03:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
03/15/2022 22:03:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
03/15/2022 22:03:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
03/15/2022 22:03:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
03/15/2022 22:03:18 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8472423326001955 on epoch=164
03/15/2022 22:03:20 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
03/15/2022 22:03:23 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
03/15/2022 22:03:25 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
03/15/2022 22:03:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
03/15/2022 22:03:30 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
03/15/2022 22:03:37 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8511294006238859 on epoch=167
03/15/2022 22:03:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
03/15/2022 22:03:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
03/15/2022 22:03:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
03/15/2022 22:03:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
03/15/2022 22:03:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
03/15/2022 22:03:56 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8472423326001955 on epoch=171
03/15/2022 22:03:59 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
03/15/2022 22:04:01 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
03/15/2022 22:04:04 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
03/15/2022 22:04:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
03/15/2022 22:04:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
03/15/2022 22:04:15 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9059699940582294 on epoch=174
03/15/2022 22:04:18 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
03/15/2022 22:04:20 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
03/15/2022 22:04:23 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
03/15/2022 22:04:25 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
03/15/2022 22:04:28 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=178
03/15/2022 22:04:34 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.795240924259278 on epoch=178
03/15/2022 22:04:37 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
03/15/2022 22:04:40 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
03/15/2022 22:04:42 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
03/15/2022 22:04:44 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
03/15/2022 22:04:47 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
03/15/2022 22:04:54 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9060190615835776 on epoch=182
03/15/2022 22:04:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
03/15/2022 22:04:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
03/15/2022 22:05:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
03/15/2022 22:05:04 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
03/15/2022 22:05:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
03/15/2022 22:05:13 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9059699940582294 on epoch=185
03/15/2022 22:05:16 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
03/15/2022 22:05:18 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
03/15/2022 22:05:21 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
03/15/2022 22:05:23 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
03/15/2022 22:05:26 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
03/15/2022 22:05:32 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7953241315977594 on epoch=189
03/15/2022 22:05:35 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
03/15/2022 22:05:37 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
03/15/2022 22:05:40 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
03/15/2022 22:05:42 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/15/2022 22:05:45 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
03/15/2022 22:05:51 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7954637202474573 on epoch=192
03/15/2022 22:05:54 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
03/15/2022 22:05:56 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=194
03/15/2022 22:05:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
03/15/2022 22:06:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
03/15/2022 22:06:04 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
03/15/2022 22:06:10 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8553044678281869 on epoch=196
03/15/2022 22:06:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
03/15/2022 22:06:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
03/15/2022 22:06:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=198
03/15/2022 22:06:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
03/15/2022 22:06:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
03/15/2022 22:06:29 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8009443694676422 on epoch=199
03/15/2022 22:06:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
03/15/2022 22:06:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
03/15/2022 22:06:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.09 on epoch=202
03/15/2022 22:06:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
03/15/2022 22:06:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
03/15/2022 22:06:48 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7599435212338439 on epoch=203
03/15/2022 22:06:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
03/15/2022 22:06:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
03/15/2022 22:06:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
03/15/2022 22:06:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
03/15/2022 22:07:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=207
03/15/2022 22:07:07 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.6773833088954058 on epoch=207
03/15/2022 22:07:09 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
03/15/2022 22:07:12 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
03/15/2022 22:07:14 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
03/15/2022 22:07:17 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
03/15/2022 22:07:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
03/15/2022 22:07:25 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7507003336159914 on epoch=210
03/15/2022 22:07:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
03/15/2022 22:07:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
03/15/2022 22:07:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
03/15/2022 22:07:35 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
03/15/2022 22:07:38 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=214
03/15/2022 22:07:39 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 22:07:39 - INFO - __main__ - Printing 3 examples
03/15/2022 22:07:39 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
03/15/2022 22:07:39 - INFO - __main__ - ['Animal']
03/15/2022 22:07:39 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
03/15/2022 22:07:39 - INFO - __main__ - ['Animal']
03/15/2022 22:07:39 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
03/15/2022 22:07:39 - INFO - __main__ - ['Animal']
03/15/2022 22:07:39 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:07:39 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:07:40 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 22:07:40 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 22:07:40 - INFO - __main__ - Printing 3 examples
03/15/2022 22:07:40 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
03/15/2022 22:07:40 - INFO - __main__ - ['Animal']
03/15/2022 22:07:40 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
03/15/2022 22:07:40 - INFO - __main__ - ['Animal']
03/15/2022 22:07:40 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
03/15/2022 22:07:40 - INFO - __main__ - ['Animal']
03/15/2022 22:07:40 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:07:40 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:07:40 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 22:07:44 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8512638092260365 on epoch=214
03/15/2022 22:07:44 - INFO - __main__ - save last model!
03/15/2022 22:07:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/15/2022 22:07:44 - INFO - __main__ - Start tokenizing ... 3500 instances
03/15/2022 22:07:44 - INFO - __main__ - Printing 3 examples
03/15/2022 22:07:44 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/15/2022 22:07:44 - INFO - __main__ - ['Animal']
03/15/2022 22:07:44 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/15/2022 22:07:44 - INFO - __main__ - ['Animal']
03/15/2022 22:07:44 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/15/2022 22:07:44 - INFO - __main__ - ['Village']
03/15/2022 22:07:44 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:07:46 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:07:50 - INFO - __main__ - Loaded 3500 examples from test data
03/15/2022 22:07:58 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 22:07:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 22:07:59 - INFO - __main__ - Starting training!
03/15/2022 22:10:01 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
03/15/2022 22:10:01 - INFO - __main__ - Classification-F1 on test data: 0.6463
03/15/2022 22:10:01 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.9731478515159729, test_performance=0.6463089890529291
03/15/2022 22:10:01 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
03/15/2022 22:10:02 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 22:10:02 - INFO - __main__ - Printing 3 examples
03/15/2022 22:10:02 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
03/15/2022 22:10:02 - INFO - __main__ - ['Animal']
03/15/2022 22:10:02 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
03/15/2022 22:10:02 - INFO - __main__ - ['Animal']
03/15/2022 22:10:02 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
03/15/2022 22:10:02 - INFO - __main__ - ['Animal']
03/15/2022 22:10:02 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:10:02 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:10:02 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 22:10:02 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 22:10:02 - INFO - __main__ - Printing 3 examples
03/15/2022 22:10:02 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
03/15/2022 22:10:02 - INFO - __main__ - ['Animal']
03/15/2022 22:10:02 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
03/15/2022 22:10:02 - INFO - __main__ - ['Animal']
03/15/2022 22:10:02 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
03/15/2022 22:10:02 - INFO - __main__ - ['Animal']
03/15/2022 22:10:02 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:10:03 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:10:03 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 22:10:18 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 22:10:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 22:10:19 - INFO - __main__ - Starting training!
03/15/2022 22:10:24 - INFO - __main__ - Step 10 Global step 10 Train loss 4.46 on epoch=0
03/15/2022 22:10:27 - INFO - __main__ - Step 20 Global step 20 Train loss 2.45 on epoch=1
03/15/2022 22:10:29 - INFO - __main__ - Step 30 Global step 30 Train loss 1.72 on epoch=2
03/15/2022 22:10:32 - INFO - __main__ - Step 40 Global step 40 Train loss 1.26 on epoch=2
03/15/2022 22:10:34 - INFO - __main__ - Step 50 Global step 50 Train loss 1.14 on epoch=3
03/15/2022 22:10:41 - INFO - __main__ - Global step 50 Train loss 2.21 Classification-F1 0.3093810561671093 on epoch=3
03/15/2022 22:10:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3093810561671093 on epoch=3, global_step=50
03/15/2022 22:10:44 - INFO - __main__ - Step 60 Global step 60 Train loss 0.99 on epoch=4
03/15/2022 22:10:46 - INFO - __main__ - Step 70 Global step 70 Train loss 0.98 on epoch=4
03/15/2022 22:10:49 - INFO - __main__ - Step 80 Global step 80 Train loss 0.74 on epoch=5
03/15/2022 22:10:51 - INFO - __main__ - Step 90 Global step 90 Train loss 0.75 on epoch=6
03/15/2022 22:10:54 - INFO - __main__ - Step 100 Global step 100 Train loss 0.67 on epoch=7
03/15/2022 22:11:01 - INFO - __main__ - Global step 100 Train loss 0.83 Classification-F1 0.5754754056673287 on epoch=7
03/15/2022 22:11:01 - INFO - __main__ - Saving model with best Classification-F1: 0.3093810561671093 -> 0.5754754056673287 on epoch=7, global_step=100
03/15/2022 22:11:04 - INFO - __main__ - Step 110 Global step 110 Train loss 0.45 on epoch=7
03/15/2022 22:11:06 - INFO - __main__ - Step 120 Global step 120 Train loss 0.59 on epoch=8
03/15/2022 22:11:09 - INFO - __main__ - Step 130 Global step 130 Train loss 0.59 on epoch=9
03/15/2022 22:11:11 - INFO - __main__ - Step 140 Global step 140 Train loss 0.50 on epoch=9
03/15/2022 22:11:14 - INFO - __main__ - Step 150 Global step 150 Train loss 0.58 on epoch=10
03/15/2022 22:11:21 - INFO - __main__ - Global step 150 Train loss 0.54 Classification-F1 0.7322159317886747 on epoch=10
03/15/2022 22:11:21 - INFO - __main__ - Saving model with best Classification-F1: 0.5754754056673287 -> 0.7322159317886747 on epoch=10, global_step=150
03/15/2022 22:11:23 - INFO - __main__ - Step 160 Global step 160 Train loss 0.50 on epoch=11
03/15/2022 22:11:26 - INFO - __main__ - Step 170 Global step 170 Train loss 0.43 on epoch=12
03/15/2022 22:11:28 - INFO - __main__ - Step 180 Global step 180 Train loss 0.37 on epoch=12
03/15/2022 22:11:31 - INFO - __main__ - Step 190 Global step 190 Train loss 0.44 on epoch=13
03/15/2022 22:11:33 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=14
03/15/2022 22:11:40 - INFO - __main__ - Global step 200 Train loss 0.44 Classification-F1 0.6132854543176594 on epoch=14
03/15/2022 22:11:42 - INFO - __main__ - Step 210 Global step 210 Train loss 0.43 on epoch=14
03/15/2022 22:11:45 - INFO - __main__ - Step 220 Global step 220 Train loss 0.33 on epoch=15
03/15/2022 22:11:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.36 on epoch=16
03/15/2022 22:11:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.50 on epoch=17
03/15/2022 22:11:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.30 on epoch=17
03/15/2022 22:11:59 - INFO - __main__ - Global step 250 Train loss 0.38 Classification-F1 0.7439405676925178 on epoch=17
03/15/2022 22:11:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7322159317886747 -> 0.7439405676925178 on epoch=17, global_step=250
03/15/2022 22:12:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.26 on epoch=18
03/15/2022 22:12:04 - INFO - __main__ - Step 270 Global step 270 Train loss 0.36 on epoch=19
03/15/2022 22:12:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.24 on epoch=19
03/15/2022 22:12:09 - INFO - __main__ - Step 290 Global step 290 Train loss 0.31 on epoch=20
03/15/2022 22:12:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.20 on epoch=21
03/15/2022 22:12:19 - INFO - __main__ - Global step 300 Train loss 0.27 Classification-F1 0.7084781340250702 on epoch=21
03/15/2022 22:12:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=22
03/15/2022 22:12:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=22
03/15/2022 22:12:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.20 on epoch=23
03/15/2022 22:12:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.29 on epoch=24
03/15/2022 22:12:31 - INFO - __main__ - Step 350 Global step 350 Train loss 0.16 on epoch=24
03/15/2022 22:12:38 - INFO - __main__ - Global step 350 Train loss 0.27 Classification-F1 0.6973387891596304 on epoch=24
03/15/2022 22:12:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.19 on epoch=25
03/15/2022 22:12:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.13 on epoch=26
03/15/2022 22:12:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=27
03/15/2022 22:12:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.16 on epoch=27
03/15/2022 22:12:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.16 on epoch=28
03/15/2022 22:12:58 - INFO - __main__ - Global step 400 Train loss 0.19 Classification-F1 0.5452145263330396 on epoch=28
03/15/2022 22:13:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.15 on epoch=29
03/15/2022 22:13:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.14 on epoch=29
03/15/2022 22:13:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=30
03/15/2022 22:13:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.12 on epoch=31
03/15/2022 22:13:10 - INFO - __main__ - Step 450 Global step 450 Train loss 0.18 on epoch=32
03/15/2022 22:13:17 - INFO - __main__ - Global step 450 Train loss 0.16 Classification-F1 0.6640575551529243 on epoch=32
03/15/2022 22:13:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=32
03/15/2022 22:13:22 - INFO - __main__ - Step 470 Global step 470 Train loss 0.12 on epoch=33
03/15/2022 22:13:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=34
03/15/2022 22:13:27 - INFO - __main__ - Step 490 Global step 490 Train loss 0.13 on epoch=34
03/15/2022 22:13:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.14 on epoch=35
03/15/2022 22:13:37 - INFO - __main__ - Global step 500 Train loss 0.16 Classification-F1 0.7989170172431528 on epoch=35
03/15/2022 22:13:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7439405676925178 -> 0.7989170172431528 on epoch=35, global_step=500
03/15/2022 22:13:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=36
03/15/2022 22:13:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.11 on epoch=37
03/15/2022 22:13:45 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=37
03/15/2022 22:13:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=38
03/15/2022 22:13:50 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=39
03/15/2022 22:13:57 - INFO - __main__ - Global step 550 Train loss 0.12 Classification-F1 0.5153561097851049 on epoch=39
03/15/2022 22:13:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.12 on epoch=39
03/15/2022 22:14:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=40
03/15/2022 22:14:05 - INFO - __main__ - Step 580 Global step 580 Train loss 0.09 on epoch=41
03/15/2022 22:14:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=42
03/15/2022 22:14:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=42
03/15/2022 22:14:17 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.7242509659901534 on epoch=42
03/15/2022 22:14:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=43
03/15/2022 22:14:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=44
03/15/2022 22:14:25 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=44
03/15/2022 22:14:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.09 on epoch=45
03/15/2022 22:14:30 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=46
03/15/2022 22:14:37 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.8937309733277475 on epoch=46
03/15/2022 22:14:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7989170172431528 -> 0.8937309733277475 on epoch=46, global_step=650
03/15/2022 22:14:40 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=47
03/15/2022 22:14:42 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=47
03/15/2022 22:14:45 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=48
03/15/2022 22:14:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=49
03/15/2022 22:14:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=49
03/15/2022 22:14:56 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.7515609371704284 on epoch=49
03/15/2022 22:14:59 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=50
03/15/2022 22:15:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=51
03/15/2022 22:15:04 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=52
03/15/2022 22:15:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=52
03/15/2022 22:15:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.04 on epoch=53
03/15/2022 22:15:16 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.8122993194976771 on epoch=53
03/15/2022 22:15:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=54
03/15/2022 22:15:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=54
03/15/2022 22:15:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=55
03/15/2022 22:15:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=56
03/15/2022 22:15:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=57
03/15/2022 22:15:35 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.835746166124538 on epoch=57
03/15/2022 22:15:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=57
03/15/2022 22:15:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=58
03/15/2022 22:15:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=59
03/15/2022 22:15:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=59
03/15/2022 22:15:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=60
03/15/2022 22:15:54 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.5170639917288297 on epoch=60
03/15/2022 22:15:56 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=61
03/15/2022 22:15:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=62
03/15/2022 22:16:01 - INFO - __main__ - Step 880 Global step 880 Train loss 0.56 on epoch=62
03/15/2022 22:16:04 - INFO - __main__ - Step 890 Global step 890 Train loss 0.52 on epoch=63
03/15/2022 22:16:06 - INFO - __main__ - Step 900 Global step 900 Train loss 0.74 on epoch=64
03/15/2022 22:16:12 - INFO - __main__ - Global step 900 Train loss 0.38 Classification-F1 0.8797891285141826 on epoch=64
03/15/2022 22:16:15 - INFO - __main__ - Step 910 Global step 910 Train loss 0.37 on epoch=64
03/15/2022 22:16:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.40 on epoch=65
03/15/2022 22:16:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=66
03/15/2022 22:16:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=67
03/15/2022 22:16:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=67
03/15/2022 22:16:31 - INFO - __main__ - Global step 950 Train loss 0.28 Classification-F1 0.6727922858975517 on epoch=67
03/15/2022 22:16:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=68
03/15/2022 22:16:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=69
03/15/2022 22:16:39 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=69
03/15/2022 22:16:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
03/15/2022 22:16:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
03/15/2022 22:16:50 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.6677287077304555 on epoch=71
03/15/2022 22:16:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
03/15/2022 22:16:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
03/15/2022 22:16:58 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=73
03/15/2022 22:17:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=74
03/15/2022 22:17:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
03/15/2022 22:17:09 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.720897742446604 on epoch=74
03/15/2022 22:17:12 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
03/15/2022 22:17:14 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=76
03/15/2022 22:17:17 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
03/15/2022 22:17:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=77
03/15/2022 22:17:22 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
03/15/2022 22:17:28 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7555291416654413 on epoch=78
03/15/2022 22:17:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=79
03/15/2022 22:17:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
03/15/2022 22:17:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
03/15/2022 22:17:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
03/15/2022 22:17:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=82
03/15/2022 22:17:47 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7743614042657512 on epoch=82
03/15/2022 22:17:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
03/15/2022 22:17:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=83
03/15/2022 22:17:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
03/15/2022 22:17:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
03/15/2022 22:18:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
03/15/2022 22:18:06 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.841185544965787 on epoch=85
03/15/2022 22:18:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
03/15/2022 22:18:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=87
03/15/2022 22:18:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
03/15/2022 22:18:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
03/15/2022 22:18:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=89
03/15/2022 22:18:24 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.8995429149176777 on epoch=89
03/15/2022 22:18:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8937309733277475 -> 0.8995429149176777 on epoch=89, global_step=1250
03/15/2022 22:18:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
03/15/2022 22:18:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
03/15/2022 22:18:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
03/15/2022 22:18:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=92
03/15/2022 22:18:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
03/15/2022 22:18:43 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.8913358442106071 on epoch=92
03/15/2022 22:18:45 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
03/15/2022 22:18:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
03/15/2022 22:18:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
03/15/2022 22:18:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
03/15/2022 22:18:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
03/15/2022 22:19:01 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.8405786831873006 on epoch=96
03/15/2022 22:19:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=97
03/15/2022 22:19:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
03/15/2022 22:19:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
03/15/2022 22:19:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
03/15/2022 22:19:14 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
03/15/2022 22:19:19 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7346452693991625 on epoch=99
03/15/2022 22:19:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
03/15/2022 22:19:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
03/15/2022 22:19:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
03/15/2022 22:19:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
03/15/2022 22:19:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
03/15/2022 22:19:38 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.8916416803497765 on epoch=103
03/15/2022 22:19:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
03/15/2022 22:19:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
03/15/2022 22:19:45 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
03/15/2022 22:19:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
03/15/2022 22:19:50 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
03/15/2022 22:19:57 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.8916457533377204 on epoch=107
03/15/2022 22:19:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
03/15/2022 22:20:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
03/15/2022 22:20:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
03/15/2022 22:20:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
03/15/2022 22:20:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
03/15/2022 22:20:15 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8995469879056216 on epoch=110
03/15/2022 22:20:15 - INFO - __main__ - Saving model with best Classification-F1: 0.8995429149176777 -> 0.8995469879056216 on epoch=110, global_step=1550
03/15/2022 22:20:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
03/15/2022 22:20:20 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
03/15/2022 22:20:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
03/15/2022 22:20:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
03/15/2022 22:20:28 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=114
03/15/2022 22:20:34 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9640892354009052 on epoch=114
03/15/2022 22:20:34 - INFO - __main__ - Saving model with best Classification-F1: 0.8995469879056216 -> 0.9640892354009052 on epoch=114, global_step=1600
03/15/2022 22:20:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
03/15/2022 22:20:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
03/15/2022 22:20:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
03/15/2022 22:20:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
03/15/2022 22:20:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
03/15/2022 22:20:52 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.835175293225036 on epoch=117
03/15/2022 22:20:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
03/15/2022 22:20:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
03/15/2022 22:21:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
03/15/2022 22:21:02 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
03/15/2022 22:21:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
03/15/2022 22:21:12 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8854193260882065 on epoch=121
03/15/2022 22:21:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
03/15/2022 22:21:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
03/15/2022 22:21:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
03/15/2022 22:21:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
03/15/2022 22:21:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
03/15/2022 22:21:31 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8896517107871228 on epoch=124
03/15/2022 22:21:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
03/15/2022 22:21:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
03/15/2022 22:21:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
03/15/2022 22:21:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
03/15/2022 22:21:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
03/15/2022 22:21:50 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.8216395967148438 on epoch=128
03/15/2022 22:21:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
03/15/2022 22:21:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
03/15/2022 22:21:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
03/15/2022 22:22:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
03/15/2022 22:22:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
03/15/2022 22:22:09 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9686668802418329 on epoch=132
03/15/2022 22:22:09 - INFO - __main__ - Saving model with best Classification-F1: 0.9640892354009052 -> 0.9686668802418329 on epoch=132, global_step=1850
03/15/2022 22:22:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
03/15/2022 22:22:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
03/15/2022 22:22:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
03/15/2022 22:22:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
03/15/2022 22:22:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
03/15/2022 22:22:28 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9100635386119258 on epoch=135
03/15/2022 22:22:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
03/15/2022 22:22:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
03/15/2022 22:22:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
03/15/2022 22:22:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
03/15/2022 22:22:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
03/15/2022 22:22:47 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.9593184561214516 on epoch=139
03/15/2022 22:22:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
03/15/2022 22:22:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
03/15/2022 22:22:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
03/15/2022 22:22:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
03/15/2022 22:22:59 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
03/15/2022 22:23:06 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.972872924829756 on epoch=142
03/15/2022 22:23:06 - INFO - __main__ - Saving model with best Classification-F1: 0.9686668802418329 -> 0.972872924829756 on epoch=142, global_step=2000
03/15/2022 22:23:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
03/15/2022 22:23:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
03/15/2022 22:23:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
03/15/2022 22:23:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
03/15/2022 22:23:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=146
03/15/2022 22:23:25 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.9683787839132013 on epoch=146
03/15/2022 22:23:27 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
03/15/2022 22:23:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
03/15/2022 22:23:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
03/15/2022 22:23:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
03/15/2022 22:23:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
03/15/2022 22:23:44 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9728167834531932 on epoch=149
03/15/2022 22:23:46 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
03/15/2022 22:23:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
03/15/2022 22:23:51 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
03/15/2022 22:23:54 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
03/15/2022 22:23:56 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
03/15/2022 22:24:02 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9683481338232534 on epoch=153
03/15/2022 22:24:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=154
03/15/2022 22:24:07 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
03/15/2022 22:24:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
03/15/2022 22:24:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=156
03/15/2022 22:24:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
03/15/2022 22:24:21 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9728387057118327 on epoch=157
03/15/2022 22:24:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
03/15/2022 22:24:26 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
03/15/2022 22:24:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
03/15/2022 22:24:31 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
03/15/2022 22:24:34 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
03/15/2022 22:24:40 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9644122678396874 on epoch=160
03/15/2022 22:24:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
03/15/2022 22:24:45 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
03/15/2022 22:24:47 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
03/15/2022 22:24:50 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
03/15/2022 22:24:52 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=164
03/15/2022 22:24:59 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9638794841933132 on epoch=164
03/15/2022 22:25:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
03/15/2022 22:25:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
03/15/2022 22:25:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
03/15/2022 22:25:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=167
03/15/2022 22:25:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
03/15/2022 22:25:17 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9773495321882419 on epoch=167
03/15/2022 22:25:17 - INFO - __main__ - Saving model with best Classification-F1: 0.972872924829756 -> 0.9773495321882419 on epoch=167, global_step=2350
03/15/2022 22:25:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
03/15/2022 22:25:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
03/15/2022 22:25:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
03/15/2022 22:25:28 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
03/15/2022 22:25:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
03/15/2022 22:25:37 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9728167834531932 on epoch=171
03/15/2022 22:25:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
03/15/2022 22:25:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
03/15/2022 22:25:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
03/15/2022 22:25:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
03/15/2022 22:25:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
03/15/2022 22:25:55 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.972843069627487 on epoch=174
03/15/2022 22:25:58 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
03/15/2022 22:26:00 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
03/15/2022 22:26:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
03/15/2022 22:26:05 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
03/15/2022 22:26:08 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
03/15/2022 22:26:14 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.972843069627487 on epoch=178
03/15/2022 22:26:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
03/15/2022 22:26:19 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
03/15/2022 22:26:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
03/15/2022 22:26:24 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
03/15/2022 22:26:27 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
03/15/2022 22:26:33 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9728167834531932 on epoch=182
03/15/2022 22:26:35 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
03/15/2022 22:26:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
03/15/2022 22:26:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
03/15/2022 22:26:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
03/15/2022 22:26:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
03/15/2022 22:26:51 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.977770110976942 on epoch=185
03/15/2022 22:26:51 - INFO - __main__ - Saving model with best Classification-F1: 0.9773495321882419 -> 0.977770110976942 on epoch=185, global_step=2600
03/15/2022 22:26:54 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
03/15/2022 22:26:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
03/15/2022 22:26:59 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
03/15/2022 22:27:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
03/15/2022 22:27:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
03/15/2022 22:27:10 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.973026534660785 on epoch=189
03/15/2022 22:27:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
03/15/2022 22:27:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
03/15/2022 22:27:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
03/15/2022 22:27:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
03/15/2022 22:27:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
03/15/2022 22:27:28 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.972812419537539 on epoch=192
03/15/2022 22:27:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
03/15/2022 22:27:33 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
03/15/2022 22:27:36 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
03/15/2022 22:27:38 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
03/15/2022 22:27:41 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
03/15/2022 22:27:47 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9728992110040497 on epoch=196
03/15/2022 22:27:50 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
03/15/2022 22:27:52 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
03/15/2022 22:27:55 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
03/15/2022 22:27:57 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
03/15/2022 22:28:00 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
03/15/2022 22:28:06 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9685622489464996 on epoch=199
03/15/2022 22:28:09 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
03/15/2022 22:28:11 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
03/15/2022 22:28:14 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
03/15/2022 22:28:16 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
03/15/2022 22:28:19 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
03/15/2022 22:28:24 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.973147851515973 on epoch=203
03/15/2022 22:28:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
03/15/2022 22:28:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
03/15/2022 22:28:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
03/15/2022 22:28:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
03/15/2022 22:28:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
03/15/2022 22:28:43 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9059774212715389 on epoch=207
03/15/2022 22:28:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
03/15/2022 22:28:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
03/15/2022 22:28:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
03/15/2022 22:28:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
03/15/2022 22:28:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
03/15/2022 22:29:02 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9819717916492111 on epoch=210
03/15/2022 22:29:02 - INFO - __main__ - Saving model with best Classification-F1: 0.977770110976942 -> 0.9819717916492111 on epoch=210, global_step=2950
03/15/2022 22:29:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
03/15/2022 22:29:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
03/15/2022 22:29:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
03/15/2022 22:29:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
03/15/2022 22:29:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
03/15/2022 22:29:16 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 22:29:16 - INFO - __main__ - Printing 3 examples
03/15/2022 22:29:16 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
03/15/2022 22:29:16 - INFO - __main__ - ['Animal']
03/15/2022 22:29:16 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
03/15/2022 22:29:16 - INFO - __main__ - ['Animal']
03/15/2022 22:29:16 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
03/15/2022 22:29:16 - INFO - __main__ - ['Animal']
03/15/2022 22:29:16 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:29:16 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:29:17 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 22:29:17 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 22:29:17 - INFO - __main__ - Printing 3 examples
03/15/2022 22:29:17 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
03/15/2022 22:29:17 - INFO - __main__ - ['Animal']
03/15/2022 22:29:17 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
03/15/2022 22:29:17 - INFO - __main__ - ['Animal']
03/15/2022 22:29:17 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
03/15/2022 22:29:17 - INFO - __main__ - ['Animal']
03/15/2022 22:29:17 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:29:17 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:29:17 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 22:29:21 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9774768558449772 on epoch=214
03/15/2022 22:29:21 - INFO - __main__ - save last model!
03/15/2022 22:29:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/15/2022 22:29:21 - INFO - __main__ - Start tokenizing ... 3500 instances
03/15/2022 22:29:21 - INFO - __main__ - Printing 3 examples
03/15/2022 22:29:21 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/15/2022 22:29:21 - INFO - __main__ - ['Animal']
03/15/2022 22:29:21 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/15/2022 22:29:21 - INFO - __main__ - ['Animal']
03/15/2022 22:29:21 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/15/2022 22:29:21 - INFO - __main__ - ['Village']
03/15/2022 22:29:21 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:29:23 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:29:26 - INFO - __main__ - Loaded 3500 examples from test data
03/15/2022 22:29:35 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 22:29:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 22:29:36 - INFO - __main__ - Starting training!
03/15/2022 22:31:34 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
03/15/2022 22:31:34 - INFO - __main__ - Classification-F1 on test data: 0.8056
03/15/2022 22:31:34 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.9819717916492111, test_performance=0.8056294247799579
03/15/2022 22:31:34 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
03/15/2022 22:31:35 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 22:31:35 - INFO - __main__ - Printing 3 examples
03/15/2022 22:31:35 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
03/15/2022 22:31:35 - INFO - __main__ - ['Animal']
03/15/2022 22:31:35 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
03/15/2022 22:31:35 - INFO - __main__ - ['Animal']
03/15/2022 22:31:35 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
03/15/2022 22:31:35 - INFO - __main__ - ['Animal']
03/15/2022 22:31:35 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:31:35 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:31:35 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 22:31:35 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 22:31:35 - INFO - __main__ - Printing 3 examples
03/15/2022 22:31:35 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
03/15/2022 22:31:35 - INFO - __main__ - ['Animal']
03/15/2022 22:31:35 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
03/15/2022 22:31:35 - INFO - __main__ - ['Animal']
03/15/2022 22:31:35 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
03/15/2022 22:31:35 - INFO - __main__ - ['Animal']
03/15/2022 22:31:35 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:31:35 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:31:36 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 22:31:51 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 22:31:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 22:31:51 - INFO - __main__ - Starting training!
03/15/2022 22:31:55 - INFO - __main__ - Step 10 Global step 10 Train loss 4.27 on epoch=0
03/15/2022 22:31:58 - INFO - __main__ - Step 20 Global step 20 Train loss 2.99 on epoch=1
03/15/2022 22:32:00 - INFO - __main__ - Step 30 Global step 30 Train loss 2.22 on epoch=2
03/15/2022 22:32:03 - INFO - __main__ - Step 40 Global step 40 Train loss 1.49 on epoch=2
03/15/2022 22:32:05 - INFO - __main__ - Step 50 Global step 50 Train loss 1.31 on epoch=3
03/15/2022 22:32:12 - INFO - __main__ - Global step 50 Train loss 2.46 Classification-F1 0.26562704747250887 on epoch=3
03/15/2022 22:32:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.26562704747250887 on epoch=3, global_step=50
03/15/2022 22:32:14 - INFO - __main__ - Step 60 Global step 60 Train loss 1.09 on epoch=4
03/15/2022 22:32:17 - INFO - __main__ - Step 70 Global step 70 Train loss 1.00 on epoch=4
03/15/2022 22:32:19 - INFO - __main__ - Step 80 Global step 80 Train loss 0.75 on epoch=5
03/15/2022 22:32:22 - INFO - __main__ - Step 90 Global step 90 Train loss 0.79 on epoch=6
03/15/2022 22:32:24 - INFO - __main__ - Step 100 Global step 100 Train loss 0.68 on epoch=7
03/15/2022 22:32:31 - INFO - __main__ - Global step 100 Train loss 0.86 Classification-F1 0.45663315499304763 on epoch=7
03/15/2022 22:32:31 - INFO - __main__ - Saving model with best Classification-F1: 0.26562704747250887 -> 0.45663315499304763 on epoch=7, global_step=100
03/15/2022 22:32:34 - INFO - __main__ - Step 110 Global step 110 Train loss 0.74 on epoch=7
03/15/2022 22:32:36 - INFO - __main__ - Step 120 Global step 120 Train loss 0.62 on epoch=8
03/15/2022 22:32:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.67 on epoch=9
03/15/2022 22:32:42 - INFO - __main__ - Step 140 Global step 140 Train loss 0.50 on epoch=9
03/15/2022 22:32:44 - INFO - __main__ - Step 150 Global step 150 Train loss 0.59 on epoch=10
03/15/2022 22:32:51 - INFO - __main__ - Global step 150 Train loss 0.62 Classification-F1 0.701658335469583 on epoch=10
03/15/2022 22:32:51 - INFO - __main__ - Saving model with best Classification-F1: 0.45663315499304763 -> 0.701658335469583 on epoch=10, global_step=150
03/15/2022 22:32:53 - INFO - __main__ - Step 160 Global step 160 Train loss 0.43 on epoch=11
03/15/2022 22:32:56 - INFO - __main__ - Step 170 Global step 170 Train loss 0.47 on epoch=12
03/15/2022 22:32:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.44 on epoch=12
03/15/2022 22:33:01 - INFO - __main__ - Step 190 Global step 190 Train loss 0.43 on epoch=13
03/15/2022 22:33:03 - INFO - __main__ - Step 200 Global step 200 Train loss 0.36 on epoch=14
03/15/2022 22:33:10 - INFO - __main__ - Global step 200 Train loss 0.43 Classification-F1 0.6534143489702828 on epoch=14
03/15/2022 22:33:12 - INFO - __main__ - Step 210 Global step 210 Train loss 0.43 on epoch=14
03/15/2022 22:33:15 - INFO - __main__ - Step 220 Global step 220 Train loss 0.35 on epoch=15
03/15/2022 22:33:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.33 on epoch=16
03/15/2022 22:33:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.48 on epoch=17
03/15/2022 22:33:22 - INFO - __main__ - Step 250 Global step 250 Train loss 0.40 on epoch=17
03/15/2022 22:33:29 - INFO - __main__ - Global step 250 Train loss 0.40 Classification-F1 0.5747328132639912 on epoch=17
03/15/2022 22:33:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.32 on epoch=18
03/15/2022 22:33:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.41 on epoch=19
03/15/2022 22:33:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.37 on epoch=19
03/15/2022 22:33:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.32 on epoch=20
03/15/2022 22:33:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.31 on epoch=21
03/15/2022 22:33:49 - INFO - __main__ - Global step 300 Train loss 0.34 Classification-F1 0.6435960215609476 on epoch=21
03/15/2022 22:33:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.31 on epoch=22
03/15/2022 22:33:54 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=22
03/15/2022 22:33:57 - INFO - __main__ - Step 330 Global step 330 Train loss 0.24 on epoch=23
03/15/2022 22:33:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=24
03/15/2022 22:34:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=24
03/15/2022 22:34:08 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.7678603496654941 on epoch=24
03/15/2022 22:34:08 - INFO - __main__ - Saving model with best Classification-F1: 0.701658335469583 -> 0.7678603496654941 on epoch=24, global_step=350
03/15/2022 22:34:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=25
03/15/2022 22:34:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.18 on epoch=26
03/15/2022 22:34:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=27
03/15/2022 22:34:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=27
03/15/2022 22:34:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=28
03/15/2022 22:34:28 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.8182795571641635 on epoch=28
03/15/2022 22:34:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7678603496654941 -> 0.8182795571641635 on epoch=28, global_step=400
03/15/2022 22:34:30 - INFO - __main__ - Step 410 Global step 410 Train loss 0.17 on epoch=29
03/15/2022 22:34:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=29
03/15/2022 22:34:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=30
03/15/2022 22:34:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.18 on epoch=31
03/15/2022 22:34:41 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=32
03/15/2022 22:34:47 - INFO - __main__ - Global step 450 Train loss 0.19 Classification-F1 0.7627648468967254 on epoch=32
03/15/2022 22:34:50 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=32
03/15/2022 22:34:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.16 on epoch=33
03/15/2022 22:34:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=34
03/15/2022 22:34:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=34
03/15/2022 22:35:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.16 on epoch=35
03/15/2022 22:35:07 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.6899739131417117 on epoch=35
03/15/2022 22:35:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=36
03/15/2022 22:35:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=37
03/15/2022 22:35:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.15 on epoch=37
03/15/2022 22:35:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.08 on epoch=38
03/15/2022 22:35:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.16 on epoch=39
03/15/2022 22:35:26 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.8846433596260203 on epoch=39
03/15/2022 22:35:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8182795571641635 -> 0.8846433596260203 on epoch=39, global_step=550
03/15/2022 22:35:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.16 on epoch=39
03/15/2022 22:35:31 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=40
03/15/2022 22:35:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=41
03/15/2022 22:35:36 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=42
03/15/2022 22:35:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=42
03/15/2022 22:35:46 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.8893309566250742 on epoch=42
03/15/2022 22:35:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8846433596260203 -> 0.8893309566250742 on epoch=42, global_step=600
03/15/2022 22:35:49 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=43
03/15/2022 22:35:51 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=44
03/15/2022 22:35:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=44
03/15/2022 22:35:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=45
03/15/2022 22:35:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=46
03/15/2022 22:36:06 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.726841669381992 on epoch=46
03/15/2022 22:36:08 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=47
03/15/2022 22:36:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=47
03/15/2022 22:36:13 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=48
03/15/2022 22:36:16 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=49
03/15/2022 22:36:18 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=49
03/15/2022 22:36:25 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.8326669337595489 on epoch=49
03/15/2022 22:36:28 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=50
03/15/2022 22:36:30 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=51
03/15/2022 22:36:33 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=52
03/15/2022 22:36:35 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
03/15/2022 22:36:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=53
03/15/2022 22:36:45 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.9686895726032348 on epoch=53
03/15/2022 22:36:45 - INFO - __main__ - Saving model with best Classification-F1: 0.8893309566250742 -> 0.9686895726032348 on epoch=53, global_step=750
03/15/2022 22:36:47 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=54
03/15/2022 22:36:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=54
03/15/2022 22:36:52 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
03/15/2022 22:36:55 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=56
03/15/2022 22:36:57 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=57
03/15/2022 22:37:04 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.9689193419303207 on epoch=57
03/15/2022 22:37:04 - INFO - __main__ - Saving model with best Classification-F1: 0.9686895726032348 -> 0.9689193419303207 on epoch=57, global_step=800
03/15/2022 22:37:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=57
03/15/2022 22:37:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=58
03/15/2022 22:37:12 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=59
03/15/2022 22:37:14 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=59
03/15/2022 22:37:17 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=60
03/15/2022 22:37:23 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.9817760049717127 on epoch=60
03/15/2022 22:37:23 - INFO - __main__ - Saving model with best Classification-F1: 0.9689193419303207 -> 0.9817760049717127 on epoch=60, global_step=850
03/15/2022 22:37:26 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=61
03/15/2022 22:37:28 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=62
03/15/2022 22:37:31 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=62
03/15/2022 22:37:33 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=63
03/15/2022 22:37:36 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=64
03/15/2022 22:37:42 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.9640969318761988 on epoch=64
03/15/2022 22:37:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=64
03/15/2022 22:37:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=65
03/15/2022 22:37:49 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=66
03/15/2022 22:37:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=67
03/15/2022 22:37:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=67
03/15/2022 22:38:01 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.973026534660785 on epoch=67
03/15/2022 22:38:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=68
03/15/2022 22:38:06 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=69
03/15/2022 22:38:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=69
03/15/2022 22:38:11 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=70
03/15/2022 22:38:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=71
03/15/2022 22:38:20 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.9771537455107434 on epoch=71
03/15/2022 22:38:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
03/15/2022 22:38:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=72
03/15/2022 22:38:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
03/15/2022 22:38:30 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
03/15/2022 22:38:33 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=74
03/15/2022 22:38:39 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.8398743166621487 on epoch=74
03/15/2022 22:38:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=75
03/15/2022 22:38:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=76
03/15/2022 22:38:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=77
03/15/2022 22:38:50 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=77
03/15/2022 22:38:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=78
03/15/2022 22:38:59 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.9059699940582294 on epoch=78
03/15/2022 22:39:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=79
03/15/2022 22:39:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=79
03/15/2022 22:39:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
03/15/2022 22:39:09 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
03/15/2022 22:39:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=82
03/15/2022 22:39:17 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.973139893787427 on epoch=82
03/15/2022 22:39:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=82
03/15/2022 22:39:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=83
03/15/2022 22:39:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=84
03/15/2022 22:39:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=84
03/15/2022 22:39:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=85
03/15/2022 22:39:37 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.9121813965077723 on epoch=85
03/15/2022 22:39:39 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
03/15/2022 22:39:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=87
03/15/2022 22:39:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
03/15/2022 22:39:47 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=88
03/15/2022 22:39:49 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
03/15/2022 22:39:55 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.8508428606552338 on epoch=89
03/15/2022 22:39:58 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
03/15/2022 22:40:00 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
03/15/2022 22:40:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=91
03/15/2022 22:40:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=92
03/15/2022 22:40:08 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=92
03/15/2022 22:40:14 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.9865984150258343 on epoch=92
03/15/2022 22:40:14 - INFO - __main__ - Saving model with best Classification-F1: 0.9817760049717127 -> 0.9865984150258343 on epoch=92, global_step=1300
03/15/2022 22:40:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
03/15/2022 22:40:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
03/15/2022 22:40:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
03/15/2022 22:40:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
03/15/2022 22:40:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
03/15/2022 22:40:32 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.9776348295916607 on epoch=96
03/15/2022 22:40:35 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
03/15/2022 22:40:37 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
03/15/2022 22:40:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=98
03/15/2022 22:40:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
03/15/2022 22:40:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=99
03/15/2022 22:40:51 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.9771537455107434 on epoch=99
03/15/2022 22:40:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
03/15/2022 22:40:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
03/15/2022 22:40:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
03/15/2022 22:41:02 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
03/15/2022 22:41:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
03/15/2022 22:41:10 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.9685875037647781 on epoch=103
03/15/2022 22:41:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
03/15/2022 22:41:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
03/15/2022 22:41:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
03/15/2022 22:41:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
03/15/2022 22:41:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
03/15/2022 22:41:29 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.9685875037647781 on epoch=107
03/15/2022 22:41:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
03/15/2022 22:41:34 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
03/15/2022 22:41:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=109
03/15/2022 22:41:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
03/15/2022 22:41:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
03/15/2022 22:41:48 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.9818181818181818 on epoch=110
03/15/2022 22:41:50 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
03/15/2022 22:41:53 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
03/15/2022 22:41:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
03/15/2022 22:41:58 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
03/15/2022 22:42:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=114
03/15/2022 22:42:06 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.8980164754073672 on epoch=114
03/15/2022 22:42:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
03/15/2022 22:42:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
03/15/2022 22:42:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
03/15/2022 22:42:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
03/15/2022 22:42:19 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
03/15/2022 22:42:25 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.9686895726032348 on epoch=117
03/15/2022 22:42:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
03/15/2022 22:42:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
03/15/2022 22:42:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
03/15/2022 22:42:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
03/15/2022 22:42:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
03/15/2022 22:42:43 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8849928951479694 on epoch=121
03/15/2022 22:42:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
03/15/2022 22:42:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
03/15/2022 22:42:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
03/15/2022 22:42:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
03/15/2022 22:42:56 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
03/15/2022 22:43:02 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.9645437671647349 on epoch=124
03/15/2022 22:43:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
03/15/2022 22:43:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
03/15/2022 22:43:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
03/15/2022 22:43:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
03/15/2022 22:43:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
03/15/2022 22:43:21 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.9640224323794305 on epoch=128
03/15/2022 22:43:23 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
03/15/2022 22:43:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
03/15/2022 22:43:28 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=130
03/15/2022 22:43:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
03/15/2022 22:43:33 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
03/15/2022 22:43:40 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9018644658793844 on epoch=132
03/15/2022 22:43:42 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
03/15/2022 22:43:45 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=133
03/15/2022 22:43:47 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
03/15/2022 22:43:50 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
03/15/2022 22:43:52 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
03/15/2022 22:43:59 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9641188541348382 on epoch=135
03/15/2022 22:44:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
03/15/2022 22:44:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
03/15/2022 22:44:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
03/15/2022 22:44:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
03/15/2022 22:44:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
03/15/2022 22:44:17 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.9685875037647781 on epoch=139
03/15/2022 22:44:20 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
03/15/2022 22:44:22 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
03/15/2022 22:44:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
03/15/2022 22:44:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=142
03/15/2022 22:44:30 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
03/15/2022 22:44:36 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.9685875037647781 on epoch=142
03/15/2022 22:44:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
03/15/2022 22:44:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
03/15/2022 22:44:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
03/15/2022 22:44:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
03/15/2022 22:44:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=146
03/15/2022 22:44:55 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.9685918676804324 on epoch=146
03/15/2022 22:44:57 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
03/15/2022 22:45:00 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
03/15/2022 22:45:02 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
03/15/2022 22:45:05 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
03/15/2022 22:45:07 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
03/15/2022 22:45:13 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9644646568304742 on epoch=149
03/15/2022 22:45:16 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
03/15/2022 22:45:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
03/15/2022 22:45:21 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
03/15/2022 22:45:24 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
03/15/2022 22:45:26 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
03/15/2022 22:45:32 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9685918676804324 on epoch=153
03/15/2022 22:45:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
03/15/2022 22:45:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
03/15/2022 22:45:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
03/15/2022 22:45:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
03/15/2022 22:45:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
03/15/2022 22:45:51 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9688059828036787 on epoch=157
03/15/2022 22:45:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
03/15/2022 22:45:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
03/15/2022 22:45:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
03/15/2022 22:46:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
03/15/2022 22:46:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
03/15/2022 22:46:09 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9732563039878708 on epoch=160
03/15/2022 22:46:12 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
03/15/2022 22:46:14 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
03/15/2022 22:46:17 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=162
03/15/2022 22:46:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
03/15/2022 22:46:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
03/15/2022 22:46:28 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9732519400722166 on epoch=164
03/15/2022 22:46:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
03/15/2022 22:46:33 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
03/15/2022 22:46:36 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=166
03/15/2022 22:46:38 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
03/15/2022 22:46:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
03/15/2022 22:46:47 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9688016188880244 on epoch=167
03/15/2022 22:46:49 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
03/15/2022 22:46:52 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
03/15/2022 22:46:54 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
03/15/2022 22:46:57 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
03/15/2022 22:46:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
03/15/2022 22:47:05 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9641232180504924 on epoch=171
03/15/2022 22:47:08 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
03/15/2022 22:47:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
03/15/2022 22:47:13 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
03/15/2022 22:47:15 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
03/15/2022 22:47:18 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
03/15/2022 22:47:24 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9596772607819547 on epoch=174
03/15/2022 22:47:26 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
03/15/2022 22:47:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
03/15/2022 22:47:32 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
03/15/2022 22:47:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
03/15/2022 22:47:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
03/15/2022 22:47:42 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9643416970893929 on epoch=178
03/15/2022 22:47:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
03/15/2022 22:47:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
03/15/2022 22:47:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
03/15/2022 22:47:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
03/15/2022 22:47:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
03/15/2022 22:48:01 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.9688059828036787 on epoch=182
03/15/2022 22:48:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
03/15/2022 22:48:06 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
03/15/2022 22:48:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
03/15/2022 22:48:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
03/15/2022 22:48:13 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
03/15/2022 22:48:19 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9688016188880244 on epoch=185
03/15/2022 22:48:22 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
03/15/2022 22:48:24 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
03/15/2022 22:48:27 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
03/15/2022 22:48:29 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
03/15/2022 22:48:32 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
03/15/2022 22:48:38 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.9688016188880244 on epoch=189
03/15/2022 22:48:40 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
03/15/2022 22:48:43 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
03/15/2022 22:48:45 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
03/15/2022 22:48:48 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
03/15/2022 22:48:51 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
03/15/2022 22:48:57 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.8980772781579234 on epoch=192
03/15/2022 22:48:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
03/15/2022 22:49:02 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
03/15/2022 22:49:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
03/15/2022 22:49:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
03/15/2022 22:49:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
03/15/2022 22:49:15 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.9691380975655169 on epoch=196
03/15/2022 22:49:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
03/15/2022 22:49:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
03/15/2022 22:49:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
03/15/2022 22:49:25 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
03/15/2022 22:49:28 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
03/15/2022 22:49:34 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9645298026346413 on epoch=199
03/15/2022 22:49:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
03/15/2022 22:49:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
03/15/2022 22:49:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
03/15/2022 22:49:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
03/15/2022 22:49:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
03/15/2022 22:49:52 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9648011355079669 on epoch=203
03/15/2022 22:49:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
03/15/2022 22:49:57 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
03/15/2022 22:50:00 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
03/15/2022 22:50:02 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
03/15/2022 22:50:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
03/15/2022 22:50:11 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8982247203214946 on epoch=207
03/15/2022 22:50:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
03/15/2022 22:50:16 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
03/15/2022 22:50:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=209
03/15/2022 22:50:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
03/15/2022 22:50:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
03/15/2022 22:50:29 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8354941499955058 on epoch=210
03/15/2022 22:50:32 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
03/15/2022 22:50:34 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
03/15/2022 22:50:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
03/15/2022 22:50:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
03/15/2022 22:50:42 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
03/15/2022 22:50:43 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 22:50:43 - INFO - __main__ - Printing 3 examples
03/15/2022 22:50:43 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
03/15/2022 22:50:43 - INFO - __main__ - ['Animal']
03/15/2022 22:50:43 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
03/15/2022 22:50:43 - INFO - __main__ - ['Animal']
03/15/2022 22:50:43 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
03/15/2022 22:50:43 - INFO - __main__ - ['Animal']
03/15/2022 22:50:43 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:50:43 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:50:44 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 22:50:44 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 22:50:44 - INFO - __main__ - Printing 3 examples
03/15/2022 22:50:44 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
03/15/2022 22:50:44 - INFO - __main__ - ['Animal']
03/15/2022 22:50:44 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
03/15/2022 22:50:44 - INFO - __main__ - ['Animal']
03/15/2022 22:50:44 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
03/15/2022 22:50:44 - INFO - __main__ - ['Animal']
03/15/2022 22:50:44 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:50:44 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:50:44 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 22:50:48 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.8940384074776866 on epoch=214
03/15/2022 22:50:48 - INFO - __main__ - save last model!
03/15/2022 22:50:48 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/15/2022 22:50:48 - INFO - __main__ - Start tokenizing ... 3500 instances
03/15/2022 22:50:48 - INFO - __main__ - Printing 3 examples
03/15/2022 22:50:48 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/15/2022 22:50:48 - INFO - __main__ - ['Animal']
03/15/2022 22:50:48 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/15/2022 22:50:48 - INFO - __main__ - ['Animal']
03/15/2022 22:50:48 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/15/2022 22:50:48 - INFO - __main__ - ['Village']
03/15/2022 22:50:48 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:50:50 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:50:53 - INFO - __main__ - Loaded 3500 examples from test data
03/15/2022 22:50:59 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 22:51:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 22:51:00 - INFO - __main__ - Starting training!
03/15/2022 22:52:55 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
03/15/2022 22:52:55 - INFO - __main__ - Classification-F1 on test data: 0.7174
03/15/2022 22:52:56 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.9865984150258343, test_performance=0.7173803597962846
03/15/2022 22:52:56 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
03/15/2022 22:52:56 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 22:52:56 - INFO - __main__ - Printing 3 examples
03/15/2022 22:52:56 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
03/15/2022 22:52:56 - INFO - __main__ - ['Animal']
03/15/2022 22:52:56 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
03/15/2022 22:52:56 - INFO - __main__ - ['Animal']
03/15/2022 22:52:56 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
03/15/2022 22:52:56 - INFO - __main__ - ['Animal']
03/15/2022 22:52:56 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:52:57 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:52:57 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 22:52:57 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 22:52:57 - INFO - __main__ - Printing 3 examples
03/15/2022 22:52:57 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
03/15/2022 22:52:57 - INFO - __main__ - ['Animal']
03/15/2022 22:52:57 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
03/15/2022 22:52:57 - INFO - __main__ - ['Animal']
03/15/2022 22:52:57 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
03/15/2022 22:52:57 - INFO - __main__ - ['Animal']
03/15/2022 22:52:57 - INFO - __main__ - Tokenizing Input ...
03/15/2022 22:52:57 - INFO - __main__ - Tokenizing Output ...
03/15/2022 22:52:57 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 22:53:16 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 22:53:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 22:53:16 - INFO - __main__ - Starting training!
03/15/2022 22:53:23 - INFO - __main__ - Step 10 Global step 10 Train loss 5.00 on epoch=0
03/15/2022 22:53:26 - INFO - __main__ - Step 20 Global step 20 Train loss 3.60 on epoch=1
03/15/2022 22:53:28 - INFO - __main__ - Step 30 Global step 30 Train loss 2.70 on epoch=2
03/15/2022 22:53:31 - INFO - __main__ - Step 40 Global step 40 Train loss 2.16 on epoch=2
03/15/2022 22:53:33 - INFO - __main__ - Step 50 Global step 50 Train loss 1.83 on epoch=3
03/15/2022 22:53:39 - INFO - __main__ - Global step 50 Train loss 3.06 Classification-F1 0.14061279584297487 on epoch=3
03/15/2022 22:53:39 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.14061279584297487 on epoch=3, global_step=50
03/15/2022 22:53:41 - INFO - __main__ - Step 60 Global step 60 Train loss 1.55 on epoch=4
03/15/2022 22:53:44 - INFO - __main__ - Step 70 Global step 70 Train loss 1.18 on epoch=4
03/15/2022 22:53:47 - INFO - __main__ - Step 80 Global step 80 Train loss 1.09 on epoch=5
03/15/2022 22:53:49 - INFO - __main__ - Step 90 Global step 90 Train loss 1.07 on epoch=6
03/15/2022 22:53:52 - INFO - __main__ - Step 100 Global step 100 Train loss 0.87 on epoch=7
03/15/2022 22:53:58 - INFO - __main__ - Global step 100 Train loss 1.15 Classification-F1 0.4086488384914716 on epoch=7
03/15/2022 22:53:58 - INFO - __main__ - Saving model with best Classification-F1: 0.14061279584297487 -> 0.4086488384914716 on epoch=7, global_step=100
03/15/2022 22:54:01 - INFO - __main__ - Step 110 Global step 110 Train loss 0.89 on epoch=7
03/15/2022 22:54:03 - INFO - __main__ - Step 120 Global step 120 Train loss 0.74 on epoch=8
03/15/2022 22:54:06 - INFO - __main__ - Step 130 Global step 130 Train loss 0.69 on epoch=9
03/15/2022 22:54:08 - INFO - __main__ - Step 140 Global step 140 Train loss 0.74 on epoch=9
03/15/2022 22:54:11 - INFO - __main__ - Step 150 Global step 150 Train loss 0.63 on epoch=10
03/15/2022 22:54:18 - INFO - __main__ - Global step 150 Train loss 0.74 Classification-F1 0.5620228753031972 on epoch=10
03/15/2022 22:54:18 - INFO - __main__ - Saving model with best Classification-F1: 0.4086488384914716 -> 0.5620228753031972 on epoch=10, global_step=150
03/15/2022 22:54:20 - INFO - __main__ - Step 160 Global step 160 Train loss 0.48 on epoch=11
03/15/2022 22:54:23 - INFO - __main__ - Step 170 Global step 170 Train loss 0.62 on epoch=12
03/15/2022 22:54:25 - INFO - __main__ - Step 180 Global step 180 Train loss 0.56 on epoch=12
03/15/2022 22:54:28 - INFO - __main__ - Step 190 Global step 190 Train loss 0.47 on epoch=13
03/15/2022 22:54:30 - INFO - __main__ - Step 200 Global step 200 Train loss 0.52 on epoch=14
03/15/2022 22:54:37 - INFO - __main__ - Global step 200 Train loss 0.53 Classification-F1 0.577998981609146 on epoch=14
03/15/2022 22:54:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5620228753031972 -> 0.577998981609146 on epoch=14, global_step=200
03/15/2022 22:54:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.44 on epoch=14
03/15/2022 22:54:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.41 on epoch=15
03/15/2022 22:54:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.40 on epoch=16
03/15/2022 22:54:47 - INFO - __main__ - Step 240 Global step 240 Train loss 0.41 on epoch=17
03/15/2022 22:54:49 - INFO - __main__ - Step 250 Global step 250 Train loss 0.40 on epoch=17
03/15/2022 22:54:56 - INFO - __main__ - Global step 250 Train loss 0.41 Classification-F1 0.6767666061783709 on epoch=17
03/15/2022 22:54:56 - INFO - __main__ - Saving model with best Classification-F1: 0.577998981609146 -> 0.6767666061783709 on epoch=17, global_step=250
03/15/2022 22:54:59 - INFO - __main__ - Step 260 Global step 260 Train loss 0.37 on epoch=18
03/15/2022 22:55:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.43 on epoch=19
03/15/2022 22:55:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.37 on epoch=19
03/15/2022 22:55:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.29 on epoch=20
03/15/2022 22:55:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.37 on epoch=21
03/15/2022 22:55:16 - INFO - __main__ - Global step 300 Train loss 0.37 Classification-F1 0.6273871713918562 on epoch=21
03/15/2022 22:55:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.36 on epoch=22
03/15/2022 22:55:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=22
03/15/2022 22:55:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.28 on epoch=23
03/15/2022 22:55:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=24
03/15/2022 22:55:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=24
03/15/2022 22:55:35 - INFO - __main__ - Global step 350 Train loss 0.28 Classification-F1 0.666741565069088 on epoch=24
03/15/2022 22:55:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=25
03/15/2022 22:55:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=26
03/15/2022 22:55:43 - INFO - __main__ - Step 380 Global step 380 Train loss 0.27 on epoch=27
03/15/2022 22:55:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.15 on epoch=27
03/15/2022 22:55:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.24 on epoch=28
03/15/2022 22:55:56 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.9466207237437059 on epoch=28
03/15/2022 22:55:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6767666061783709 -> 0.9466207237437059 on epoch=28, global_step=400
03/15/2022 22:55:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.17 on epoch=29
03/15/2022 22:56:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=29
03/15/2022 22:56:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=30
03/15/2022 22:56:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=31
03/15/2022 22:56:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.24 on epoch=32
03/15/2022 22:56:16 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.8485779658882128 on epoch=32
03/15/2022 22:56:19 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=32
03/15/2022 22:56:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=33
03/15/2022 22:56:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=34
03/15/2022 22:56:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=34
03/15/2022 22:56:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=35
03/15/2022 22:56:36 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.8942686673158439 on epoch=35
03/15/2022 22:56:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=36
03/15/2022 22:56:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=37
03/15/2022 22:56:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=37
03/15/2022 22:56:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=38
03/15/2022 22:56:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=39
03/15/2022 22:56:56 - INFO - __main__ - Global step 550 Train loss 0.17 Classification-F1 0.8892384614096647 on epoch=39
03/15/2022 22:56:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=39
03/15/2022 22:57:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=40
03/15/2022 22:57:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.09 on epoch=41
03/15/2022 22:57:06 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=42
03/15/2022 22:57:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=42
03/15/2022 22:57:15 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.964288354638043 on epoch=42
03/15/2022 22:57:15 - INFO - __main__ - Saving model with best Classification-F1: 0.9466207237437059 -> 0.964288354638043 on epoch=42, global_step=600
03/15/2022 22:57:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=43
03/15/2022 22:57:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=44
03/15/2022 22:57:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.14 on epoch=44
03/15/2022 22:57:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=45
03/15/2022 22:57:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=46
03/15/2022 22:57:34 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.9641727393252781 on epoch=46
03/15/2022 22:57:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=47
03/15/2022 22:57:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
03/15/2022 22:57:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=48
03/15/2022 22:57:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=49
03/15/2022 22:57:47 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=49
03/15/2022 22:57:53 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.959819705008103 on epoch=49
03/15/2022 22:57:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=50
03/15/2022 22:57:58 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=51
03/15/2022 22:58:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=52
03/15/2022 22:58:03 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
03/15/2022 22:58:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=53
03/15/2022 22:58:12 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.9638838481089677 on epoch=53
03/15/2022 22:58:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=54
03/15/2022 22:58:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=54
03/15/2022 22:58:20 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=55
03/15/2022 22:58:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=56
03/15/2022 22:58:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=57
03/15/2022 22:58:32 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.9595644443944025 on epoch=57
03/15/2022 22:58:34 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=57
03/15/2022 22:58:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=58
03/15/2022 22:58:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=59
03/15/2022 22:58:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=59
03/15/2022 22:58:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=60
03/15/2022 22:58:51 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.9688155834181179 on epoch=60
03/15/2022 22:58:51 - INFO - __main__ - Saving model with best Classification-F1: 0.964288354638043 -> 0.9688155834181179 on epoch=60, global_step=850
03/15/2022 22:58:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=61
03/15/2022 22:58:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=62
03/15/2022 22:58:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=62
03/15/2022 22:59:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=63
03/15/2022 22:59:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=64
03/15/2022 22:59:10 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.9550475863315293 on epoch=64
03/15/2022 22:59:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=64
03/15/2022 22:59:15 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=65
03/15/2022 22:59:18 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
03/15/2022 22:59:20 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
03/15/2022 22:59:23 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=67
03/15/2022 22:59:29 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.8954820501025436 on epoch=67
03/15/2022 22:59:32 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=68
03/15/2022 22:59:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
03/15/2022 22:59:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=69
03/15/2022 22:59:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
03/15/2022 22:59:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=71
03/15/2022 22:59:48 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.9595819779524712 on epoch=71
03/15/2022 22:59:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
03/15/2022 22:59:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=72
03/15/2022 22:59:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=73
03/15/2022 22:59:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
03/15/2022 23:00:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=74
03/15/2022 23:00:07 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.9035948191593351 on epoch=74
03/15/2022 23:00:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=75
03/15/2022 23:00:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=76
03/15/2022 23:00:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=77
03/15/2022 23:00:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=77
03/15/2022 23:00:19 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=78
03/15/2022 23:00:26 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.968348133823253 on epoch=78
03/15/2022 23:00:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
03/15/2022 23:00:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
03/15/2022 23:00:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=80
03/15/2022 23:00:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
03/15/2022 23:00:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=82
03/15/2022 23:00:44 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.9596378828606981 on epoch=82
03/15/2022 23:00:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=82
03/15/2022 23:00:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
03/15/2022 23:00:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=84
03/15/2022 23:00:54 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=84
03/15/2022 23:00:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=85
03/15/2022 23:01:03 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.895571053445816 on epoch=85
03/15/2022 23:01:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
03/15/2022 23:01:08 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
03/15/2022 23:01:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
03/15/2022 23:01:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
03/15/2022 23:01:16 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
03/15/2022 23:01:22 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.968434925289764 on epoch=89
03/15/2022 23:01:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
03/15/2022 23:01:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
03/15/2022 23:01:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
03/15/2022 23:01:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
03/15/2022 23:01:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
03/15/2022 23:01:41 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.9505189979217494 on epoch=92
03/15/2022 23:01:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=93
03/15/2022 23:01:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
03/15/2022 23:01:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
03/15/2022 23:01:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
03/15/2022 23:01:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
03/15/2022 23:02:00 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.9688059828036787 on epoch=96
03/15/2022 23:02:02 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
03/15/2022 23:02:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
03/15/2022 23:02:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
03/15/2022 23:02:10 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
03/15/2022 23:02:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=99
03/15/2022 23:02:19 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.9018408947156575 on epoch=99
03/15/2022 23:02:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
03/15/2022 23:02:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
03/15/2022 23:02:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
03/15/2022 23:02:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=102
03/15/2022 23:02:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
03/15/2022 23:02:38 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.9508043124385629 on epoch=103
03/15/2022 23:02:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.16 on epoch=104
03/15/2022 23:02:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
03/15/2022 23:02:45 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
03/15/2022 23:02:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
03/15/2022 23:02:50 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
03/15/2022 23:02:57 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.9555010713963006 on epoch=107
03/15/2022 23:02:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=107
03/15/2022 23:03:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
03/15/2022 23:03:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
03/15/2022 23:03:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
03/15/2022 23:03:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
03/15/2022 23:03:15 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9640979632322136 on epoch=110
03/15/2022 23:03:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
03/15/2022 23:03:20 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
03/15/2022 23:03:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
03/15/2022 23:03:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
03/15/2022 23:03:28 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
03/15/2022 23:03:34 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.9683481338232534 on epoch=114
03/15/2022 23:03:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
03/15/2022 23:03:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
03/15/2022 23:03:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
03/15/2022 23:03:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
03/15/2022 23:03:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
03/15/2022 23:03:53 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.9592405391724897 on epoch=117
03/15/2022 23:03:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
03/15/2022 23:03:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=119
03/15/2022 23:04:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
03/15/2022 23:04:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
03/15/2022 23:04:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
03/15/2022 23:04:12 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9505901973153169 on epoch=121
03/15/2022 23:04:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
03/15/2022 23:04:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
03/15/2022 23:04:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
03/15/2022 23:04:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
03/15/2022 23:04:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
03/15/2022 23:04:30 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.9418467585908533 on epoch=124
03/15/2022 23:04:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
03/15/2022 23:04:35 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
03/15/2022 23:04:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
03/15/2022 23:04:40 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
03/15/2022 23:04:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
03/15/2022 23:04:49 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.9465635059936268 on epoch=128
03/15/2022 23:04:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
03/15/2022 23:04:54 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
03/15/2022 23:04:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
03/15/2022 23:04:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
03/15/2022 23:05:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
03/15/2022 23:05:08 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9688059828036787 on epoch=132
03/15/2022 23:05:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
03/15/2022 23:05:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=133
03/15/2022 23:05:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
03/15/2022 23:05:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
03/15/2022 23:05:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
03/15/2022 23:05:30 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9466023799549147 on epoch=135
03/15/2022 23:05:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
03/15/2022 23:05:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
03/15/2022 23:05:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
03/15/2022 23:05:40 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
03/15/2022 23:05:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
03/15/2022 23:05:48 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.9417114084147834 on epoch=139
03/15/2022 23:05:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
03/15/2022 23:05:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
03/15/2022 23:05:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
03/15/2022 23:05:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
03/15/2022 23:06:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
03/15/2022 23:06:08 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9508555768348396 on epoch=142
03/15/2022 23:06:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
03/15/2022 23:06:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
03/15/2022 23:06:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=144
03/15/2022 23:06:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=145
03/15/2022 23:06:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=146
03/15/2022 23:06:29 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.9461336462653287 on epoch=146
03/15/2022 23:06:31 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
03/15/2022 23:06:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
03/15/2022 23:06:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
03/15/2022 23:06:39 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
03/15/2022 23:06:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=149
03/15/2022 23:06:49 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9641059209607595 on epoch=149
03/15/2022 23:06:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
03/15/2022 23:06:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
03/15/2022 23:06:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
03/15/2022 23:06:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
03/15/2022 23:07:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
03/15/2022 23:07:08 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.959514923119617 on epoch=153
03/15/2022 23:07:10 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
03/15/2022 23:07:13 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=154
03/15/2022 23:07:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
03/15/2022 23:07:18 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
03/15/2022 23:07:20 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
03/15/2022 23:07:27 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9596205857709652 on epoch=157
03/15/2022 23:07:29 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
03/15/2022 23:07:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
03/15/2022 23:07:34 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
03/15/2022 23:07:37 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
03/15/2022 23:07:39 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
03/15/2022 23:07:46 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.959764594987555 on epoch=160
03/15/2022 23:07:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
03/15/2022 23:07:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
03/15/2022 23:07:53 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=162
03/15/2022 23:07:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
03/15/2022 23:07:58 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
03/15/2022 23:08:04 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.959873047459453 on epoch=164
03/15/2022 23:08:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
03/15/2022 23:08:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
03/15/2022 23:08:12 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
03/15/2022 23:08:14 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
03/15/2022 23:08:17 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
03/15/2022 23:08:23 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9411504879027152 on epoch=167
03/15/2022 23:08:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
03/15/2022 23:08:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
03/15/2022 23:08:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
03/15/2022 23:08:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
03/15/2022 23:08:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
03/15/2022 23:08:43 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9596422467763522 on epoch=171
03/15/2022 23:08:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.08 on epoch=172
03/15/2022 23:08:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
03/15/2022 23:08:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
03/15/2022 23:08:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
03/15/2022 23:08:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
03/15/2022 23:09:02 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9683604554674535 on epoch=174
03/15/2022 23:09:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
03/15/2022 23:09:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
03/15/2022 23:09:09 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
03/15/2022 23:09:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
03/15/2022 23:09:14 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
03/15/2022 23:09:20 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.9683524977389075 on epoch=178
03/15/2022 23:09:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
03/15/2022 23:09:25 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
03/15/2022 23:09:28 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
03/15/2022 23:09:30 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
03/15/2022 23:09:33 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
03/15/2022 23:09:40 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9552551519141382 on epoch=182
03/15/2022 23:09:43 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
03/15/2022 23:09:45 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
03/15/2022 23:09:48 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
03/15/2022 23:09:50 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
03/15/2022 23:09:53 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
03/15/2022 23:10:00 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9596422467763522 on epoch=185
03/15/2022 23:10:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
03/15/2022 23:10:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
03/15/2022 23:10:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
03/15/2022 23:10:10 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
03/15/2022 23:10:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
03/15/2022 23:10:19 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.959873047459453 on epoch=189
03/15/2022 23:10:21 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
03/15/2022 23:10:24 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
03/15/2022 23:10:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
03/15/2022 23:10:29 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/15/2022 23:10:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
03/15/2022 23:10:37 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9605140173688559 on epoch=192
03/15/2022 23:10:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
03/15/2022 23:10:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
03/15/2022 23:10:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
03/15/2022 23:10:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
03/15/2022 23:10:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
03/15/2022 23:10:56 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.950397727854414 on epoch=196
03/15/2022 23:10:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
03/15/2022 23:11:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
03/15/2022 23:11:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
03/15/2022 23:11:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
03/15/2022 23:11:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
03/15/2022 23:11:15 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9552792597977608 on epoch=199
03/15/2022 23:11:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
03/15/2022 23:11:20 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
03/15/2022 23:11:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
03/15/2022 23:11:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
03/15/2022 23:11:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
03/15/2022 23:11:33 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9643416970893929 on epoch=203
03/15/2022 23:11:36 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
03/15/2022 23:11:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
03/15/2022 23:11:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
03/15/2022 23:11:43 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
03/15/2022 23:11:46 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
03/15/2022 23:11:52 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.959729038242863 on epoch=207
03/15/2022 23:11:54 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
03/15/2022 23:11:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
03/15/2022 23:11:59 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
03/15/2022 23:12:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
03/15/2022 23:12:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
03/15/2022 23:12:11 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9642332446174952 on epoch=210
03/15/2022 23:12:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
03/15/2022 23:12:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
03/15/2022 23:12:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
03/15/2022 23:12:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
03/15/2022 23:12:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
03/15/2022 23:12:25 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 23:12:25 - INFO - __main__ - Printing 3 examples
03/15/2022 23:12:25 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
03/15/2022 23:12:25 - INFO - __main__ - ['Animal']
03/15/2022 23:12:25 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
03/15/2022 23:12:25 - INFO - __main__ - ['Animal']
03/15/2022 23:12:25 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
03/15/2022 23:12:25 - INFO - __main__ - ['Animal']
03/15/2022 23:12:25 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:12:25 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:12:25 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 23:12:25 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 23:12:25 - INFO - __main__ - Printing 3 examples
03/15/2022 23:12:25 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
03/15/2022 23:12:25 - INFO - __main__ - ['Animal']
03/15/2022 23:12:25 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
03/15/2022 23:12:25 - INFO - __main__ - ['Animal']
03/15/2022 23:12:25 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
03/15/2022 23:12:25 - INFO - __main__ - ['Animal']
03/15/2022 23:12:25 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:12:25 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:12:25 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 23:12:29 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.89766119448757 on epoch=214
03/15/2022 23:12:29 - INFO - __main__ - save last model!
03/15/2022 23:12:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/15/2022 23:12:29 - INFO - __main__ - Start tokenizing ... 3500 instances
03/15/2022 23:12:29 - INFO - __main__ - Printing 3 examples
03/15/2022 23:12:29 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/15/2022 23:12:29 - INFO - __main__ - ['Animal']
03/15/2022 23:12:29 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/15/2022 23:12:29 - INFO - __main__ - ['Animal']
03/15/2022 23:12:29 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/15/2022 23:12:29 - INFO - __main__ - ['Village']
03/15/2022 23:12:29 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:12:31 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:12:35 - INFO - __main__ - Loaded 3500 examples from test data
03/15/2022 23:12:41 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 23:12:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 23:12:41 - INFO - __main__ - Starting training!
03/15/2022 23:14:39 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
03/15/2022 23:14:39 - INFO - __main__ - Classification-F1 on test data: 0.7174
03/15/2022 23:14:40 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.9688155834181179, test_performance=0.7173974988163012
03/15/2022 23:14:40 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
03/15/2022 23:14:41 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 23:14:41 - INFO - __main__ - Printing 3 examples
03/15/2022 23:14:41 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
03/15/2022 23:14:41 - INFO - __main__ - ['Animal']
03/15/2022 23:14:41 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
03/15/2022 23:14:41 - INFO - __main__ - ['Animal']
03/15/2022 23:14:41 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
03/15/2022 23:14:41 - INFO - __main__ - ['Animal']
03/15/2022 23:14:41 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:14:41 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:14:41 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 23:14:41 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 23:14:41 - INFO - __main__ - Printing 3 examples
03/15/2022 23:14:41 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
03/15/2022 23:14:41 - INFO - __main__ - ['Animal']
03/15/2022 23:14:41 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
03/15/2022 23:14:41 - INFO - __main__ - ['Animal']
03/15/2022 23:14:41 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
03/15/2022 23:14:41 - INFO - __main__ - ['Animal']
03/15/2022 23:14:41 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:14:41 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:14:41 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 23:14:56 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 23:14:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 23:14:57 - INFO - __main__ - Starting training!
03/15/2022 23:15:01 - INFO - __main__ - Step 10 Global step 10 Train loss 4.94 on epoch=0
03/15/2022 23:15:03 - INFO - __main__ - Step 20 Global step 20 Train loss 3.71 on epoch=1
03/15/2022 23:15:06 - INFO - __main__ - Step 30 Global step 30 Train loss 2.86 on epoch=2
03/15/2022 23:15:08 - INFO - __main__ - Step 40 Global step 40 Train loss 2.35 on epoch=2
03/15/2022 23:15:11 - INFO - __main__ - Step 50 Global step 50 Train loss 2.04 on epoch=3
03/15/2022 23:15:16 - INFO - __main__ - Global step 50 Train loss 3.18 Classification-F1 0.08215726788611659 on epoch=3
03/15/2022 23:15:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08215726788611659 on epoch=3, global_step=50
03/15/2022 23:15:19 - INFO - __main__ - Step 60 Global step 60 Train loss 1.72 on epoch=4
03/15/2022 23:15:21 - INFO - __main__ - Step 70 Global step 70 Train loss 1.65 on epoch=4
03/15/2022 23:15:24 - INFO - __main__ - Step 80 Global step 80 Train loss 1.44 on epoch=5
03/15/2022 23:15:27 - INFO - __main__ - Step 90 Global step 90 Train loss 1.25 on epoch=6
03/15/2022 23:15:29 - INFO - __main__ - Step 100 Global step 100 Train loss 1.22 on epoch=7
03/15/2022 23:15:35 - INFO - __main__ - Global step 100 Train loss 1.46 Classification-F1 0.2812132221513979 on epoch=7
03/15/2022 23:15:35 - INFO - __main__ - Saving model with best Classification-F1: 0.08215726788611659 -> 0.2812132221513979 on epoch=7, global_step=100
03/15/2022 23:15:38 - INFO - __main__ - Step 110 Global step 110 Train loss 0.97 on epoch=7
03/15/2022 23:15:40 - INFO - __main__ - Step 120 Global step 120 Train loss 0.97 on epoch=8
03/15/2022 23:15:43 - INFO - __main__ - Step 130 Global step 130 Train loss 0.90 on epoch=9
03/15/2022 23:15:45 - INFO - __main__ - Step 140 Global step 140 Train loss 0.86 on epoch=9
03/15/2022 23:15:48 - INFO - __main__ - Step 150 Global step 150 Train loss 0.75 on epoch=10
03/15/2022 23:15:54 - INFO - __main__ - Global step 150 Train loss 0.89 Classification-F1 0.45582081992469353 on epoch=10
03/15/2022 23:15:54 - INFO - __main__ - Saving model with best Classification-F1: 0.2812132221513979 -> 0.45582081992469353 on epoch=10, global_step=150
03/15/2022 23:15:57 - INFO - __main__ - Step 160 Global step 160 Train loss 0.82 on epoch=11
03/15/2022 23:15:59 - INFO - __main__ - Step 170 Global step 170 Train loss 0.79 on epoch=12
03/15/2022 23:16:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.70 on epoch=12
03/15/2022 23:16:04 - INFO - __main__ - Step 190 Global step 190 Train loss 0.63 on epoch=13
03/15/2022 23:16:07 - INFO - __main__ - Step 200 Global step 200 Train loss 0.61 on epoch=14
03/15/2022 23:16:13 - INFO - __main__ - Global step 200 Train loss 0.71 Classification-F1 0.4545887775238216 on epoch=14
03/15/2022 23:16:15 - INFO - __main__ - Step 210 Global step 210 Train loss 0.64 on epoch=14
03/15/2022 23:16:18 - INFO - __main__ - Step 220 Global step 220 Train loss 0.60 on epoch=15
03/15/2022 23:16:20 - INFO - __main__ - Step 230 Global step 230 Train loss 0.65 on epoch=16
03/15/2022 23:16:23 - INFO - __main__ - Step 240 Global step 240 Train loss 0.59 on epoch=17
03/15/2022 23:16:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.67 on epoch=17
03/15/2022 23:16:32 - INFO - __main__ - Global step 250 Train loss 0.63 Classification-F1 0.5548506832865738 on epoch=17
03/15/2022 23:16:32 - INFO - __main__ - Saving model with best Classification-F1: 0.45582081992469353 -> 0.5548506832865738 on epoch=17, global_step=250
03/15/2022 23:16:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.51 on epoch=18
03/15/2022 23:16:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=19
03/15/2022 23:16:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.53 on epoch=19
03/15/2022 23:16:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.46 on epoch=20
03/15/2022 23:16:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=21
03/15/2022 23:16:52 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.5720994640371196 on epoch=21
03/15/2022 23:16:52 - INFO - __main__ - Saving model with best Classification-F1: 0.5548506832865738 -> 0.5720994640371196 on epoch=21, global_step=300
03/15/2022 23:16:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.50 on epoch=22
03/15/2022 23:16:57 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=22
03/15/2022 23:16:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.42 on epoch=23
03/15/2022 23:17:02 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=24
03/15/2022 23:17:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=24
03/15/2022 23:17:12 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.6730263752441172 on epoch=24
03/15/2022 23:17:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5720994640371196 -> 0.6730263752441172 on epoch=24, global_step=350
03/15/2022 23:17:14 - INFO - __main__ - Step 360 Global step 360 Train loss 0.41 on epoch=25
03/15/2022 23:17:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=26
03/15/2022 23:17:19 - INFO - __main__ - Step 380 Global step 380 Train loss 0.39 on epoch=27
03/15/2022 23:17:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.36 on epoch=27
03/15/2022 23:17:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=28
03/15/2022 23:17:32 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.6235062043235245 on epoch=28
03/15/2022 23:17:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.38 on epoch=29
03/15/2022 23:17:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=29
03/15/2022 23:17:40 - INFO - __main__ - Step 430 Global step 430 Train loss 0.31 on epoch=30
03/15/2022 23:17:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=31
03/15/2022 23:17:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.38 on epoch=32
03/15/2022 23:17:52 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.6356399525817215 on epoch=32
03/15/2022 23:17:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=32
03/15/2022 23:17:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=33
03/15/2022 23:18:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.35 on epoch=34
03/15/2022 23:18:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.33 on epoch=34
03/15/2022 23:18:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=35
03/15/2022 23:18:13 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.646836867369291 on epoch=35
03/15/2022 23:18:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=36
03/15/2022 23:18:18 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=37
03/15/2022 23:18:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=37
03/15/2022 23:18:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=38
03/15/2022 23:18:25 - INFO - __main__ - Step 550 Global step 550 Train loss 0.33 on epoch=39
03/15/2022 23:18:32 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.716275801035588 on epoch=39
03/15/2022 23:18:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6730263752441172 -> 0.716275801035588 on epoch=39, global_step=550
03/15/2022 23:18:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.32 on epoch=39
03/15/2022 23:18:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=40
03/15/2022 23:18:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=41
03/15/2022 23:18:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=42
03/15/2022 23:18:45 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=42
03/15/2022 23:18:52 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.8276989146913246 on epoch=42
03/15/2022 23:18:52 - INFO - __main__ - Saving model with best Classification-F1: 0.716275801035588 -> 0.8276989146913246 on epoch=42, global_step=600
03/15/2022 23:18:55 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=43
03/15/2022 23:18:58 - INFO - __main__ - Step 620 Global step 620 Train loss 0.26 on epoch=44
03/15/2022 23:19:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=44
03/15/2022 23:19:03 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=45
03/15/2022 23:19:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=46
03/15/2022 23:19:12 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.7520376816369949 on epoch=46
03/15/2022 23:19:15 - INFO - __main__ - Step 660 Global step 660 Train loss 0.26 on epoch=47
03/15/2022 23:19:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=47
03/15/2022 23:19:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=48
03/15/2022 23:19:22 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=49
03/15/2022 23:19:25 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=49
03/15/2022 23:19:32 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.7560526931969057 on epoch=49
03/15/2022 23:19:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=50
03/15/2022 23:19:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=51
03/15/2022 23:19:39 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=52
03/15/2022 23:19:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=52
03/15/2022 23:19:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=53
03/15/2022 23:19:52 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.8829500716328674 on epoch=53
03/15/2022 23:19:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8276989146913246 -> 0.8829500716328674 on epoch=53, global_step=750
03/15/2022 23:19:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=54
03/15/2022 23:19:57 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=54
03/15/2022 23:19:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=55
03/15/2022 23:20:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=56
03/15/2022 23:20:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=57
03/15/2022 23:20:12 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.9558312526156698 on epoch=57
03/15/2022 23:20:12 - INFO - __main__ - Saving model with best Classification-F1: 0.8829500716328674 -> 0.9558312526156698 on epoch=57, global_step=800
03/15/2022 23:20:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=57
03/15/2022 23:20:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=58
03/15/2022 23:20:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=59
03/15/2022 23:20:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=59
03/15/2022 23:20:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=60
03/15/2022 23:20:32 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.9553833483540044 on epoch=60
03/15/2022 23:20:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=61
03/15/2022 23:20:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=62
03/15/2022 23:20:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=62
03/15/2022 23:20:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=63
03/15/2022 23:20:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=64
03/15/2022 23:20:52 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.8976415483104287 on epoch=64
03/15/2022 23:20:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=64
03/15/2022 23:20:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.21 on epoch=65
03/15/2022 23:21:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=66
03/15/2022 23:21:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=67
03/15/2022 23:21:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=67
03/15/2022 23:21:12 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.8934245887993517 on epoch=67
03/15/2022 23:21:15 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=68
03/15/2022 23:21:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=69
03/15/2022 23:21:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
03/15/2022 23:21:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
03/15/2022 23:21:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
03/15/2022 23:21:32 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.9595942995966714 on epoch=71
03/15/2022 23:21:32 - INFO - __main__ - Saving model with best Classification-F1: 0.9558312526156698 -> 0.9595942995966714 on epoch=71, global_step=1000
03/15/2022 23:21:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=72
03/15/2022 23:21:37 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=72
03/15/2022 23:21:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=73
03/15/2022 23:21:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
03/15/2022 23:21:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
03/15/2022 23:21:52 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.8400763895687994 on epoch=74
03/15/2022 23:21:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=75
03/15/2022 23:21:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=76
03/15/2022 23:21:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=77
03/15/2022 23:22:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=77
03/15/2022 23:22:04 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
03/15/2022 23:22:12 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.9605140173688559 on epoch=78
03/15/2022 23:22:13 - INFO - __main__ - Saving model with best Classification-F1: 0.9595942995966714 -> 0.9605140173688559 on epoch=78, global_step=1100
03/15/2022 23:22:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=79
03/15/2022 23:22:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=79
03/15/2022 23:22:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=80
03/15/2022 23:22:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
03/15/2022 23:22:25 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=82
03/15/2022 23:22:32 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.96446029291482 on epoch=82
03/15/2022 23:22:32 - INFO - __main__ - Saving model with best Classification-F1: 0.9605140173688559 -> 0.96446029291482 on epoch=82, global_step=1150
03/15/2022 23:22:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=82
03/15/2022 23:22:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
03/15/2022 23:22:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=84
03/15/2022 23:22:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
03/15/2022 23:22:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=85
03/15/2022 23:22:52 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.968385946754068 on epoch=85
03/15/2022 23:22:52 - INFO - __main__ - Saving model with best Classification-F1: 0.96446029291482 -> 0.968385946754068 on epoch=85, global_step=1200
03/15/2022 23:22:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
03/15/2022 23:22:58 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=87
03/15/2022 23:23:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=87
03/15/2022 23:23:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=88
03/15/2022 23:23:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.22 on epoch=89
03/15/2022 23:23:12 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.8193627939270187 on epoch=89
03/15/2022 23:23:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=89
03/15/2022 23:23:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=90
03/15/2022 23:23:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=91
03/15/2022 23:23:22 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=92
03/15/2022 23:23:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=92
03/15/2022 23:23:32 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.8976742280489909 on epoch=92
03/15/2022 23:23:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
03/15/2022 23:23:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=94
03/15/2022 23:23:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=94
03/15/2022 23:23:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
03/15/2022 23:23:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
03/15/2022 23:23:52 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.9594809404700297 on epoch=96
03/15/2022 23:23:55 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=97
03/15/2022 23:23:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
03/15/2022 23:24:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
03/15/2022 23:24:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
03/15/2022 23:24:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
03/15/2022 23:24:12 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.9598380334538508 on epoch=99
03/15/2022 23:24:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
03/15/2022 23:24:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=101
03/15/2022 23:24:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
03/15/2022 23:24:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=102
03/15/2022 23:24:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
03/15/2022 23:24:32 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.9595986635123259 on epoch=103
03/15/2022 23:24:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=104
03/15/2022 23:24:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=104
03/15/2022 23:24:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
03/15/2022 23:24:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=106
03/15/2022 23:24:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
03/15/2022 23:24:51 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.9597150737127697 on epoch=107
03/15/2022 23:24:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
03/15/2022 23:24:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
03/15/2022 23:24:59 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=109
03/15/2022 23:25:01 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=109
03/15/2022 23:25:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
03/15/2022 23:25:11 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.9640979632322136 on epoch=110
03/15/2022 23:25:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=111
03/15/2022 23:25:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
03/15/2022 23:25:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
03/15/2022 23:25:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
03/15/2022 23:25:23 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=114
03/15/2022 23:25:30 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.9643066830837907 on epoch=114
03/15/2022 23:25:32 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
03/15/2022 23:25:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=115
03/15/2022 23:25:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
03/15/2022 23:25:40 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
03/15/2022 23:25:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
03/15/2022 23:25:50 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.9685578850308451 on epoch=117
03/15/2022 23:25:50 - INFO - __main__ - Saving model with best Classification-F1: 0.968385946754068 -> 0.9685578850308451 on epoch=117, global_step=1650
03/15/2022 23:25:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
03/15/2022 23:25:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
03/15/2022 23:25:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=119
03/15/2022 23:26:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
03/15/2022 23:26:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
03/15/2022 23:26:09 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.9685578850308451 on epoch=121
03/15/2022 23:26:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
03/15/2022 23:26:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
03/15/2022 23:26:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
03/15/2022 23:26:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
03/15/2022 23:26:21 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
03/15/2022 23:26:28 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.8935109156076898 on epoch=124
03/15/2022 23:26:31 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
03/15/2022 23:26:33 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=126
03/15/2022 23:26:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=127
03/15/2022 23:26:38 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=127
03/15/2022 23:26:41 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
03/15/2022 23:26:47 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.9643329692580844 on epoch=128
03/15/2022 23:26:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
03/15/2022 23:26:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
03/15/2022 23:26:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
03/15/2022 23:26:57 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
03/15/2022 23:27:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
03/15/2022 23:27:06 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.959996007200534 on epoch=132
03/15/2022 23:27:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
03/15/2022 23:27:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
03/15/2022 23:27:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
03/15/2022 23:27:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
03/15/2022 23:27:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
03/15/2022 23:27:26 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9466941929986186 on epoch=135
03/15/2022 23:27:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
03/15/2022 23:27:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
03/15/2022 23:27:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=137
03/15/2022 23:27:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
03/15/2022 23:27:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
03/15/2022 23:27:45 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.9598919186442905 on epoch=139
03/15/2022 23:27:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=139
03/15/2022 23:27:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
03/15/2022 23:27:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
03/15/2022 23:27:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
03/15/2022 23:27:57 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
03/15/2022 23:28:04 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.9060075613823242 on epoch=142
03/15/2022 23:28:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
03/15/2022 23:28:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=144
03/15/2022 23:28:11 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
03/15/2022 23:28:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
03/15/2022 23:28:16 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
03/15/2022 23:28:23 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8995429149176777 on epoch=146
03/15/2022 23:28:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
03/15/2022 23:28:28 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
03/15/2022 23:28:31 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=148
03/15/2022 23:28:33 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
03/15/2022 23:28:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
03/15/2022 23:28:43 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.8937113271506062 on epoch=149
03/15/2022 23:28:45 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
03/15/2022 23:28:48 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
03/15/2022 23:28:50 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
03/15/2022 23:28:53 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
03/15/2022 23:28:56 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
03/15/2022 23:29:02 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9643329692580844 on epoch=153
03/15/2022 23:29:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
03/15/2022 23:29:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
03/15/2022 23:29:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
03/15/2022 23:29:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
03/15/2022 23:29:16 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=157
03/15/2022 23:29:22 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.9598380334538508 on epoch=157
03/15/2022 23:29:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
03/15/2022 23:29:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
03/15/2022 23:29:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
03/15/2022 23:29:32 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
03/15/2022 23:29:35 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
03/15/2022 23:29:42 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9643329692580844 on epoch=160
03/15/2022 23:29:44 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
03/15/2022 23:29:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
03/15/2022 23:29:49 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
03/15/2022 23:29:52 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
03/15/2022 23:29:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
03/15/2022 23:30:01 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9597942137214882 on epoch=164
03/15/2022 23:30:04 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
03/15/2022 23:30:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
03/15/2022 23:30:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=166
03/15/2022 23:30:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=167
03/15/2022 23:30:14 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
03/15/2022 23:30:20 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.9600083288447342 on epoch=167
03/15/2022 23:30:23 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
03/15/2022 23:30:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
03/15/2022 23:30:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
03/15/2022 23:30:31 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
03/15/2022 23:30:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
03/15/2022 23:30:40 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.9510679785110526 on epoch=171
03/15/2022 23:30:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
03/15/2022 23:30:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
03/15/2022 23:30:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
03/15/2022 23:30:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
03/15/2022 23:30:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
03/15/2022 23:30:59 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9600083288447342 on epoch=174
03/15/2022 23:31:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
03/15/2022 23:31:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
03/15/2022 23:31:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
03/15/2022 23:31:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
03/15/2022 23:31:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=178
03/15/2022 23:31:19 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9558175616287572 on epoch=178
03/15/2022 23:31:22 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
03/15/2022 23:31:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
03/15/2022 23:31:27 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
03/15/2022 23:31:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
03/15/2022 23:31:32 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
03/15/2022 23:31:39 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9643329692580844 on epoch=182
03/15/2022 23:31:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.08 on epoch=182
03/15/2022 23:31:44 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
03/15/2022 23:31:47 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
03/15/2022 23:31:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
03/15/2022 23:31:52 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
03/15/2022 23:31:59 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9555549565867404 on epoch=185
03/15/2022 23:32:01 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
03/15/2022 23:32:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
03/15/2022 23:32:06 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
03/15/2022 23:32:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
03/15/2022 23:32:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
03/15/2022 23:32:18 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9556174815967441 on epoch=189
03/15/2022 23:32:21 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
03/15/2022 23:32:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
03/15/2022 23:32:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
03/15/2022 23:32:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/15/2022 23:32:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
03/15/2022 23:32:38 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9600611530047013 on epoch=192
03/15/2022 23:32:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=193
03/15/2022 23:32:43 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
03/15/2022 23:32:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
03/15/2022 23:32:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
03/15/2022 23:32:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
03/15/2022 23:32:57 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9643329692580844 on epoch=196
03/15/2022 23:32:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
03/15/2022 23:33:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
03/15/2022 23:33:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
03/15/2022 23:33:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
03/15/2022 23:33:10 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
03/15/2022 23:33:16 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9643373331737387 on epoch=199
03/15/2022 23:33:19 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
03/15/2022 23:33:22 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
03/15/2022 23:33:24 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
03/15/2022 23:33:27 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
03/15/2022 23:33:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
03/15/2022 23:33:36 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9553737477395651 on epoch=203
03/15/2022 23:33:39 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
03/15/2022 23:33:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
03/15/2022 23:33:44 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
03/15/2022 23:33:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
03/15/2022 23:33:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
03/15/2022 23:33:55 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9600611530047013 on epoch=207
03/15/2022 23:33:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
03/15/2022 23:34:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
03/15/2022 23:34:03 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
03/15/2022 23:34:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
03/15/2022 23:34:08 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
03/15/2022 23:34:15 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9600751175347949 on epoch=210
03/15/2022 23:34:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
03/15/2022 23:34:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
03/15/2022 23:34:23 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
03/15/2022 23:34:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
03/15/2022 23:34:28 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
03/15/2022 23:34:29 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 23:34:29 - INFO - __main__ - Printing 3 examples
03/15/2022 23:34:29 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
03/15/2022 23:34:29 - INFO - __main__ - ['Plant']
03/15/2022 23:34:29 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
03/15/2022 23:34:29 - INFO - __main__ - ['Plant']
03/15/2022 23:34:29 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
03/15/2022 23:34:29 - INFO - __main__ - ['Plant']
03/15/2022 23:34:29 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:34:29 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:34:30 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 23:34:30 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 23:34:30 - INFO - __main__ - Printing 3 examples
03/15/2022 23:34:30 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
03/15/2022 23:34:30 - INFO - __main__ - ['Plant']
03/15/2022 23:34:30 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
03/15/2022 23:34:30 - INFO - __main__ - ['Plant']
03/15/2022 23:34:30 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
03/15/2022 23:34:30 - INFO - __main__ - ['Plant']
03/15/2022 23:34:30 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:34:30 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:34:30 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 23:34:34 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9644813423903285 on epoch=214
03/15/2022 23:34:34 - INFO - __main__ - save last model!
03/15/2022 23:34:34 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/15/2022 23:34:34 - INFO - __main__ - Start tokenizing ... 3500 instances
03/15/2022 23:34:34 - INFO - __main__ - Printing 3 examples
03/15/2022 23:34:34 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/15/2022 23:34:34 - INFO - __main__ - ['Animal']
03/15/2022 23:34:34 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/15/2022 23:34:34 - INFO - __main__ - ['Animal']
03/15/2022 23:34:34 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/15/2022 23:34:34 - INFO - __main__ - ['Village']
03/15/2022 23:34:34 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:34:36 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:34:39 - INFO - __main__ - Loaded 3500 examples from test data
03/15/2022 23:34:45 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 23:34:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 23:34:46 - INFO - __main__ - Starting training!
03/15/2022 23:36:48 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
03/15/2022 23:36:48 - INFO - __main__ - Classification-F1 on test data: 0.8035
03/15/2022 23:36:49 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.9685578850308451, test_performance=0.803522146789686
03/15/2022 23:36:49 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
03/15/2022 23:36:50 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 23:36:50 - INFO - __main__ - Printing 3 examples
03/15/2022 23:36:50 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
03/15/2022 23:36:50 - INFO - __main__ - ['Plant']
03/15/2022 23:36:50 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
03/15/2022 23:36:50 - INFO - __main__ - ['Plant']
03/15/2022 23:36:50 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
03/15/2022 23:36:50 - INFO - __main__ - ['Plant']
03/15/2022 23:36:50 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:36:50 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:36:51 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 23:36:51 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 23:36:51 - INFO - __main__ - Printing 3 examples
03/15/2022 23:36:51 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
03/15/2022 23:36:51 - INFO - __main__ - ['Plant']
03/15/2022 23:36:51 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
03/15/2022 23:36:51 - INFO - __main__ - ['Plant']
03/15/2022 23:36:51 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
03/15/2022 23:36:51 - INFO - __main__ - ['Plant']
03/15/2022 23:36:51 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:36:51 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:36:51 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 23:37:09 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 23:37:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 23:37:10 - INFO - __main__ - Starting training!
03/15/2022 23:37:13 - INFO - __main__ - Step 10 Global step 10 Train loss 4.36 on epoch=0
03/15/2022 23:37:16 - INFO - __main__ - Step 20 Global step 20 Train loss 2.54 on epoch=1
03/15/2022 23:37:18 - INFO - __main__ - Step 30 Global step 30 Train loss 1.72 on epoch=2
03/15/2022 23:37:21 - INFO - __main__ - Step 40 Global step 40 Train loss 1.36 on epoch=2
03/15/2022 23:37:24 - INFO - __main__ - Step 50 Global step 50 Train loss 1.00 on epoch=3
03/15/2022 23:37:30 - INFO - __main__ - Global step 50 Train loss 2.20 Classification-F1 0.4632426532520552 on epoch=3
03/15/2022 23:37:30 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.4632426532520552 on epoch=3, global_step=50
03/15/2022 23:37:32 - INFO - __main__ - Step 60 Global step 60 Train loss 0.94 on epoch=4
03/15/2022 23:37:35 - INFO - __main__ - Step 70 Global step 70 Train loss 0.86 on epoch=4
03/15/2022 23:37:37 - INFO - __main__ - Step 80 Global step 80 Train loss 0.73 on epoch=5
03/15/2022 23:37:40 - INFO - __main__ - Step 90 Global step 90 Train loss 0.68 on epoch=6
03/15/2022 23:37:42 - INFO - __main__ - Step 100 Global step 100 Train loss 0.62 on epoch=7
03/15/2022 23:37:49 - INFO - __main__ - Global step 100 Train loss 0.76 Classification-F1 0.6063696633854856 on epoch=7
03/15/2022 23:37:49 - INFO - __main__ - Saving model with best Classification-F1: 0.4632426532520552 -> 0.6063696633854856 on epoch=7, global_step=100
03/15/2022 23:37:52 - INFO - __main__ - Step 110 Global step 110 Train loss 0.61 on epoch=7
03/15/2022 23:37:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.57 on epoch=8
03/15/2022 23:37:57 - INFO - __main__ - Step 130 Global step 130 Train loss 0.42 on epoch=9
03/15/2022 23:38:00 - INFO - __main__ - Step 140 Global step 140 Train loss 0.47 on epoch=9
03/15/2022 23:38:02 - INFO - __main__ - Step 150 Global step 150 Train loss 0.46 on epoch=10
03/15/2022 23:38:09 - INFO - __main__ - Global step 150 Train loss 0.51 Classification-F1 0.6696544067642725 on epoch=10
03/15/2022 23:38:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6063696633854856 -> 0.6696544067642725 on epoch=10, global_step=150
03/15/2022 23:38:12 - INFO - __main__ - Step 160 Global step 160 Train loss 0.46 on epoch=11
03/15/2022 23:38:14 - INFO - __main__ - Step 170 Global step 170 Train loss 0.47 on epoch=12
03/15/2022 23:38:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.44 on epoch=12
03/15/2022 23:38:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.42 on epoch=13
03/15/2022 23:38:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.48 on epoch=14
03/15/2022 23:38:29 - INFO - __main__ - Global step 200 Train loss 0.46 Classification-F1 0.653705725236353 on epoch=14
03/15/2022 23:38:32 - INFO - __main__ - Step 210 Global step 210 Train loss 0.46 on epoch=14
03/15/2022 23:38:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.38 on epoch=15
03/15/2022 23:38:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.41 on epoch=16
03/15/2022 23:38:39 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=17
03/15/2022 23:38:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.34 on epoch=17
03/15/2022 23:38:50 - INFO - __main__ - Global step 250 Train loss 0.40 Classification-F1 0.7390574739469705 on epoch=17
03/15/2022 23:38:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6696544067642725 -> 0.7390574739469705 on epoch=17, global_step=250
03/15/2022 23:38:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=18
03/15/2022 23:38:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.46 on epoch=19
03/15/2022 23:38:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.36 on epoch=19
03/15/2022 23:39:00 - INFO - __main__ - Step 290 Global step 290 Train loss 0.33 on epoch=20
03/15/2022 23:39:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=21
03/15/2022 23:39:10 - INFO - __main__ - Global step 300 Train loss 0.36 Classification-F1 0.5853588533097047 on epoch=21
03/15/2022 23:39:12 - INFO - __main__ - Step 310 Global step 310 Train loss 0.36 on epoch=22
03/15/2022 23:39:15 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=22
03/15/2022 23:39:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=23
03/15/2022 23:39:20 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=24
03/15/2022 23:39:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=24
03/15/2022 23:39:30 - INFO - __main__ - Global step 350 Train loss 0.28 Classification-F1 0.8167706246543844 on epoch=24
03/15/2022 23:39:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7390574739469705 -> 0.8167706246543844 on epoch=24, global_step=350
03/15/2022 23:39:33 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=25
03/15/2022 23:39:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=26
03/15/2022 23:39:38 - INFO - __main__ - Step 380 Global step 380 Train loss 0.18 on epoch=27
03/15/2022 23:39:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=27
03/15/2022 23:39:43 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=28
03/15/2022 23:39:50 - INFO - __main__ - Global step 400 Train loss 0.22 Classification-F1 0.8313032782761198 on epoch=28
03/15/2022 23:39:50 - INFO - __main__ - Saving model with best Classification-F1: 0.8167706246543844 -> 0.8313032782761198 on epoch=28, global_step=400
03/15/2022 23:39:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.17 on epoch=29
03/15/2022 23:39:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.18 on epoch=29
03/15/2022 23:39:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=30
03/15/2022 23:40:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=31
03/15/2022 23:40:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.18 on epoch=32
03/15/2022 23:40:10 - INFO - __main__ - Global step 450 Train loss 0.19 Classification-F1 0.787158212032204 on epoch=32
03/15/2022 23:40:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=32
03/15/2022 23:40:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.11 on epoch=33
03/15/2022 23:40:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.12 on epoch=34
03/15/2022 23:40:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.14 on epoch=34
03/15/2022 23:40:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.17 on epoch=35
03/15/2022 23:40:30 - INFO - __main__ - Global step 500 Train loss 0.14 Classification-F1 0.9686225177703803 on epoch=35
03/15/2022 23:40:30 - INFO - __main__ - Saving model with best Classification-F1: 0.8313032782761198 -> 0.9686225177703803 on epoch=35, global_step=500
03/15/2022 23:40:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=36
03/15/2022 23:40:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.13 on epoch=37
03/15/2022 23:40:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=37
03/15/2022 23:40:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=38
03/15/2022 23:40:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=39
03/15/2022 23:40:50 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.8774069147171614 on epoch=39
03/15/2022 23:40:53 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=39
03/15/2022 23:40:55 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=40
03/15/2022 23:40:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=41
03/15/2022 23:41:01 - INFO - __main__ - Step 590 Global step 590 Train loss 0.08 on epoch=42
03/15/2022 23:41:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.10 on epoch=42
03/15/2022 23:41:11 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.8431449134411576 on epoch=42
03/15/2022 23:41:14 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=43
03/15/2022 23:41:16 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=44
03/15/2022 23:41:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=44
03/15/2022 23:41:21 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=45
03/15/2022 23:41:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=46
03/15/2022 23:41:31 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.7446439114002645 on epoch=46
03/15/2022 23:41:34 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=47
03/15/2022 23:41:36 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
03/15/2022 23:41:39 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=48
03/15/2022 23:41:42 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=49
03/15/2022 23:41:44 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=49
03/15/2022 23:41:52 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.785515921405472 on epoch=49
03/15/2022 23:41:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=50
03/15/2022 23:41:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=51
03/15/2022 23:42:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=52
03/15/2022 23:42:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=52
03/15/2022 23:42:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=53
03/15/2022 23:42:12 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.8308859881962348 on epoch=53
03/15/2022 23:42:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=54
03/15/2022 23:42:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=54
03/15/2022 23:42:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=55
03/15/2022 23:42:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=56
03/15/2022 23:42:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=57
03/15/2022 23:42:32 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.8314900406590449 on epoch=57
03/15/2022 23:42:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=57
03/15/2022 23:42:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=58
03/15/2022 23:42:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=59
03/15/2022 23:42:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=59
03/15/2022 23:42:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=60
03/15/2022 23:42:53 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.7668327876011664 on epoch=60
03/15/2022 23:42:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=61
03/15/2022 23:42:58 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=62
03/15/2022 23:43:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=62
03/15/2022 23:43:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=63
03/15/2022 23:43:05 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=64
03/15/2022 23:43:12 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.8429885915860671 on epoch=64
03/15/2022 23:43:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=64
03/15/2022 23:43:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=65
03/15/2022 23:43:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=66
03/15/2022 23:43:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=67
03/15/2022 23:43:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
03/15/2022 23:43:32 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.9057860345068356 on epoch=67
03/15/2022 23:43:35 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=68
03/15/2022 23:43:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=69
03/15/2022 23:43:40 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=69
03/15/2022 23:43:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=70
03/15/2022 23:43:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
03/15/2022 23:43:52 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.9017713895481675 on epoch=71
03/15/2022 23:43:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
03/15/2022 23:43:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
03/15/2022 23:44:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=73
03/15/2022 23:44:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=74
03/15/2022 23:44:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=74
03/15/2022 23:44:13 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.8843709498928262 on epoch=74
03/15/2022 23:44:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
03/15/2022 23:44:18 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
03/15/2022 23:44:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
03/15/2022 23:44:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=77
03/15/2022 23:44:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
03/15/2022 23:44:32 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.941808869468863 on epoch=78
03/15/2022 23:44:35 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
03/15/2022 23:44:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
03/15/2022 23:44:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=80
03/15/2022 23:44:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
03/15/2022 23:44:45 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=82
03/15/2022 23:44:52 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.9146227454813792 on epoch=82
03/15/2022 23:44:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
03/15/2022 23:44:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=83
03/15/2022 23:45:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
03/15/2022 23:45:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
03/15/2022 23:45:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
03/15/2022 23:45:12 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.9687238165060746 on epoch=85
03/15/2022 23:45:12 - INFO - __main__ - Saving model with best Classification-F1: 0.9686225177703803 -> 0.9687238165060746 on epoch=85, global_step=1200
03/15/2022 23:45:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
03/15/2022 23:45:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
03/15/2022 23:45:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
03/15/2022 23:45:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
03/15/2022 23:45:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=89
03/15/2022 23:45:32 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.9779017985493318 on epoch=89
03/15/2022 23:45:32 - INFO - __main__ - Saving model with best Classification-F1: 0.9687238165060746 -> 0.9779017985493318 on epoch=89, global_step=1250
03/15/2022 23:45:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
03/15/2022 23:45:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=90
03/15/2022 23:45:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
03/15/2022 23:45:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
03/15/2022 23:45:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
03/15/2022 23:45:52 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.9822527251369758 on epoch=92
03/15/2022 23:45:52 - INFO - __main__ - Saving model with best Classification-F1: 0.9779017985493318 -> 0.9822527251369758 on epoch=92, global_step=1300
03/15/2022 23:45:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=93
03/15/2022 23:45:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
03/15/2022 23:46:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
03/15/2022 23:46:02 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
03/15/2022 23:46:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
03/15/2022 23:46:12 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.9822570890526298 on epoch=96
03/15/2022 23:46:12 - INFO - __main__ - Saving model with best Classification-F1: 0.9822527251369758 -> 0.9822570890526298 on epoch=96, global_step=1350
03/15/2022 23:46:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=97
03/15/2022 23:46:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
03/15/2022 23:46:20 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
03/15/2022 23:46:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
03/15/2022 23:46:25 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
03/15/2022 23:46:32 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.9731845084074686 on epoch=99
03/15/2022 23:46:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
03/15/2022 23:46:37 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=101
03/15/2022 23:46:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
03/15/2022 23:46:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
03/15/2022 23:46:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
03/15/2022 23:46:52 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.9866027789414886 on epoch=103
03/15/2022 23:46:52 - INFO - __main__ - Saving model with best Classification-F1: 0.9822570890526298 -> 0.9866027789414886 on epoch=103, global_step=1450
03/15/2022 23:46:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
03/15/2022 23:46:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
03/15/2022 23:46:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
03/15/2022 23:47:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
03/15/2022 23:47:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
03/15/2022 23:47:11 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.9821297653958945 on epoch=107
03/15/2022 23:47:13 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
03/15/2022 23:47:16 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
03/15/2022 23:47:18 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
03/15/2022 23:47:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
03/15/2022 23:47:23 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
03/15/2022 23:47:30 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9058641922066968 on epoch=110
03/15/2022 23:47:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
03/15/2022 23:47:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
03/15/2022 23:47:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
03/15/2022 23:47:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
03/15/2022 23:47:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
03/15/2022 23:47:48 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9018352883675465 on epoch=114
03/15/2022 23:47:51 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
03/15/2022 23:47:54 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
03/15/2022 23:47:56 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
03/15/2022 23:47:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
03/15/2022 23:48:01 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
03/15/2022 23:48:07 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.8996944300691929 on epoch=117
03/15/2022 23:48:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
03/15/2022 23:48:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=119
03/15/2022 23:48:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
03/15/2022 23:48:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
03/15/2022 23:48:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
03/15/2022 23:48:27 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.8989406464038407 on epoch=121
03/15/2022 23:48:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
03/15/2022 23:48:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
03/15/2022 23:48:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
03/15/2022 23:48:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
03/15/2022 23:48:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
03/15/2022 23:48:46 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.977525834380673 on epoch=124
03/15/2022 23:48:48 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
03/15/2022 23:48:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
03/15/2022 23:48:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
03/15/2022 23:48:56 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
03/15/2022 23:48:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=128
03/15/2022 23:49:05 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.9726850958808034 on epoch=128
03/15/2022 23:49:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=129
03/15/2022 23:49:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
03/15/2022 23:49:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
03/15/2022 23:49:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
03/15/2022 23:49:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
03/15/2022 23:49:25 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.8418489448565349 on epoch=132
03/15/2022 23:49:27 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
03/15/2022 23:49:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
03/15/2022 23:49:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
03/15/2022 23:49:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
03/15/2022 23:49:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
03/15/2022 23:49:43 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.8568119143324233 on epoch=135
03/15/2022 23:49:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
03/15/2022 23:49:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
03/15/2022 23:49:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
03/15/2022 23:49:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
03/15/2022 23:49:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
03/15/2022 23:50:03 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9731801444918143 on epoch=139
03/15/2022 23:50:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
03/15/2022 23:50:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
03/15/2022 23:50:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
03/15/2022 23:50:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
03/15/2022 23:50:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
03/15/2022 23:50:23 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.8304304758927031 on epoch=142
03/15/2022 23:50:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
03/15/2022 23:50:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
03/15/2022 23:50:31 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
03/15/2022 23:50:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
03/15/2022 23:50:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
03/15/2022 23:50:42 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9777928033383441 on epoch=146
03/15/2022 23:50:45 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
03/15/2022 23:50:47 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
03/15/2022 23:50:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
03/15/2022 23:50:52 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=149
03/15/2022 23:50:55 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=149
03/15/2022 23:51:01 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.8511193147119298 on epoch=149
03/15/2022 23:51:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=150
03/15/2022 23:51:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
03/15/2022 23:51:08 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
03/15/2022 23:51:11 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
03/15/2022 23:51:13 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
03/15/2022 23:51:19 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9146227454813792 on epoch=153
03/15/2022 23:51:22 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
03/15/2022 23:51:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
03/15/2022 23:51:27 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
03/15/2022 23:51:30 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
03/15/2022 23:51:32 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
03/15/2022 23:51:38 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8969728300373461 on epoch=157
03/15/2022 23:51:41 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
03/15/2022 23:51:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
03/15/2022 23:51:46 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
03/15/2022 23:51:49 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
03/15/2022 23:51:51 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
03/15/2022 23:51:57 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8469857343597263 on epoch=160
03/15/2022 23:52:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
03/15/2022 23:52:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
03/15/2022 23:52:05 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
03/15/2022 23:52:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
03/15/2022 23:52:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
03/15/2022 23:52:16 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9056888851876747 on epoch=164
03/15/2022 23:52:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
03/15/2022 23:52:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
03/15/2022 23:52:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
03/15/2022 23:52:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=167
03/15/2022 23:52:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
03/15/2022 23:52:35 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9776444302061 on epoch=167
03/15/2022 23:52:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
03/15/2022 23:52:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
03/15/2022 23:52:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
03/15/2022 23:52:45 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
03/15/2022 23:52:47 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
03/15/2022 23:52:53 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9865984150258343 on epoch=171
03/15/2022 23:52:56 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
03/15/2022 23:52:58 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
03/15/2022 23:53:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
03/15/2022 23:53:03 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
03/15/2022 23:53:06 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
03/15/2022 23:53:12 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8610008858748779 on epoch=174
03/15/2022 23:53:14 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
03/15/2022 23:53:17 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
03/15/2022 23:53:20 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
03/15/2022 23:53:22 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
03/15/2022 23:53:25 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
03/15/2022 23:53:30 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.855196878054741 on epoch=178
03/15/2022 23:53:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
03/15/2022 23:53:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
03/15/2022 23:53:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
03/15/2022 23:53:41 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
03/15/2022 23:53:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
03/15/2022 23:53:49 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8591153470185728 on epoch=182
03/15/2022 23:53:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
03/15/2022 23:53:54 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
03/15/2022 23:53:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
03/15/2022 23:54:00 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
03/15/2022 23:54:02 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
03/15/2022 23:54:08 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7826912500380521 on epoch=185
03/15/2022 23:54:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
03/15/2022 23:54:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
03/15/2022 23:54:16 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
03/15/2022 23:54:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
03/15/2022 23:54:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
03/15/2022 23:54:27 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8508672985828977 on epoch=189
03/15/2022 23:54:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
03/15/2022 23:54:32 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
03/15/2022 23:54:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
03/15/2022 23:54:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/15/2022 23:54:40 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
03/15/2022 23:54:46 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8553082862543845 on epoch=192
03/15/2022 23:54:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
03/15/2022 23:54:51 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
03/15/2022 23:54:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
03/15/2022 23:54:56 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
03/15/2022 23:54:58 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
03/15/2022 23:55:04 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8028671439250187 on epoch=196
03/15/2022 23:55:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
03/15/2022 23:55:09 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
03/15/2022 23:55:12 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
03/15/2022 23:55:14 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
03/15/2022 23:55:17 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
03/15/2022 23:55:23 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8009696107181876 on epoch=199
03/15/2022 23:55:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
03/15/2022 23:55:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
03/15/2022 23:55:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
03/15/2022 23:55:33 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
03/15/2022 23:55:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
03/15/2022 23:55:41 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9034406916776215 on epoch=203
03/15/2022 23:55:44 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.09 on epoch=204
03/15/2022 23:55:46 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
03/15/2022 23:55:49 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
03/15/2022 23:55:52 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
03/15/2022 23:55:54 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
03/15/2022 23:56:00 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8346093615232018 on epoch=207
03/15/2022 23:56:03 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
03/15/2022 23:56:05 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
03/15/2022 23:56:08 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
03/15/2022 23:56:10 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
03/15/2022 23:56:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
03/15/2022 23:56:19 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8398328158242769 on epoch=210
03/15/2022 23:56:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
03/15/2022 23:56:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
03/15/2022 23:56:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
03/15/2022 23:56:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
03/15/2022 23:56:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
03/15/2022 23:56:33 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 23:56:33 - INFO - __main__ - Printing 3 examples
03/15/2022 23:56:33 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
03/15/2022 23:56:33 - INFO - __main__ - ['Plant']
03/15/2022 23:56:33 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
03/15/2022 23:56:33 - INFO - __main__ - ['Plant']
03/15/2022 23:56:33 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
03/15/2022 23:56:33 - INFO - __main__ - ['Plant']
03/15/2022 23:56:33 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:56:33 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:56:34 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 23:56:34 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 23:56:34 - INFO - __main__ - Printing 3 examples
03/15/2022 23:56:34 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
03/15/2022 23:56:34 - INFO - __main__ - ['Plant']
03/15/2022 23:56:34 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
03/15/2022 23:56:34 - INFO - __main__ - ['Plant']
03/15/2022 23:56:34 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
03/15/2022 23:56:34 - INFO - __main__ - ['Plant']
03/15/2022 23:56:34 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:56:34 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:56:34 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 23:56:38 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9072494735919783 on epoch=214
03/15/2022 23:56:38 - INFO - __main__ - save last model!
03/15/2022 23:56:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/15/2022 23:56:38 - INFO - __main__ - Start tokenizing ... 3500 instances
03/15/2022 23:56:38 - INFO - __main__ - Printing 3 examples
03/15/2022 23:56:38 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/15/2022 23:56:38 - INFO - __main__ - ['Animal']
03/15/2022 23:56:38 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/15/2022 23:56:38 - INFO - __main__ - ['Animal']
03/15/2022 23:56:38 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/15/2022 23:56:38 - INFO - __main__ - ['Village']
03/15/2022 23:56:38 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:56:40 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:56:43 - INFO - __main__ - Loaded 3500 examples from test data
03/15/2022 23:56:49 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 23:56:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 23:56:50 - INFO - __main__ - Starting training!
03/15/2022 23:58:45 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
03/15/2022 23:58:45 - INFO - __main__ - Classification-F1 on test data: 0.6747
03/15/2022 23:58:45 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.9866027789414886, test_performance=0.67473399847233
03/15/2022 23:58:45 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
03/15/2022 23:58:46 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 23:58:46 - INFO - __main__ - Printing 3 examples
03/15/2022 23:58:46 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
03/15/2022 23:58:46 - INFO - __main__ - ['Plant']
03/15/2022 23:58:46 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
03/15/2022 23:58:46 - INFO - __main__ - ['Plant']
03/15/2022 23:58:46 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
03/15/2022 23:58:46 - INFO - __main__ - ['Plant']
03/15/2022 23:58:46 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:58:46 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:58:47 - INFO - __main__ - Loaded 224 examples from train data
03/15/2022 23:58:47 - INFO - __main__ - Start tokenizing ... 224 instances
03/15/2022 23:58:47 - INFO - __main__ - Printing 3 examples
03/15/2022 23:58:47 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
03/15/2022 23:58:47 - INFO - __main__ - ['Plant']
03/15/2022 23:58:47 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
03/15/2022 23:58:47 - INFO - __main__ - ['Plant']
03/15/2022 23:58:47 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
03/15/2022 23:58:47 - INFO - __main__ - ['Plant']
03/15/2022 23:58:47 - INFO - __main__ - Tokenizing Input ...
03/15/2022 23:58:47 - INFO - __main__ - Tokenizing Output ...
03/15/2022 23:58:47 - INFO - __main__ - Loaded 224 examples from dev data
03/15/2022 23:59:05 - INFO - __main__ - load prompt embedding from ckpt
03/15/2022 23:59:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/15/2022 23:59:06 - INFO - __main__ - Starting training!
03/15/2022 23:59:09 - INFO - __main__ - Step 10 Global step 10 Train loss 4.28 on epoch=0
03/15/2022 23:59:12 - INFO - __main__ - Step 20 Global step 20 Train loss 2.70 on epoch=1
03/15/2022 23:59:14 - INFO - __main__ - Step 30 Global step 30 Train loss 1.98 on epoch=2
03/15/2022 23:59:17 - INFO - __main__ - Step 40 Global step 40 Train loss 1.57 on epoch=2
03/15/2022 23:59:19 - INFO - __main__ - Step 50 Global step 50 Train loss 1.35 on epoch=3
03/15/2022 23:59:27 - INFO - __main__ - Global step 50 Train loss 2.38 Classification-F1 0.2131144383066359 on epoch=3
03/15/2022 23:59:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2131144383066359 on epoch=3, global_step=50
03/15/2022 23:59:29 - INFO - __main__ - Step 60 Global step 60 Train loss 1.04 on epoch=4
03/15/2022 23:59:32 - INFO - __main__ - Step 70 Global step 70 Train loss 0.92 on epoch=4
03/15/2022 23:59:34 - INFO - __main__ - Step 80 Global step 80 Train loss 0.75 on epoch=5
03/15/2022 23:59:37 - INFO - __main__ - Step 90 Global step 90 Train loss 0.82 on epoch=6
03/15/2022 23:59:39 - INFO - __main__ - Step 100 Global step 100 Train loss 0.61 on epoch=7
03/15/2022 23:59:46 - INFO - __main__ - Global step 100 Train loss 0.83 Classification-F1 0.5495725255368196 on epoch=7
03/15/2022 23:59:46 - INFO - __main__ - Saving model with best Classification-F1: 0.2131144383066359 -> 0.5495725255368196 on epoch=7, global_step=100
03/15/2022 23:59:49 - INFO - __main__ - Step 110 Global step 110 Train loss 0.69 on epoch=7
03/15/2022 23:59:51 - INFO - __main__ - Step 120 Global step 120 Train loss 0.55 on epoch=8
03/15/2022 23:59:54 - INFO - __main__ - Step 130 Global step 130 Train loss 0.65 on epoch=9
03/15/2022 23:59:56 - INFO - __main__ - Step 140 Global step 140 Train loss 0.53 on epoch=9
03/15/2022 23:59:59 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=10
03/16/2022 00:00:05 - INFO - __main__ - Global step 150 Train loss 0.59 Classification-F1 0.6587824625459033 on epoch=10
03/16/2022 00:00:05 - INFO - __main__ - Saving model with best Classification-F1: 0.5495725255368196 -> 0.6587824625459033 on epoch=10, global_step=150
03/16/2022 00:00:08 - INFO - __main__ - Step 160 Global step 160 Train loss 0.49 on epoch=11
03/16/2022 00:00:10 - INFO - __main__ - Step 170 Global step 170 Train loss 0.47 on epoch=12
03/16/2022 00:00:13 - INFO - __main__ - Step 180 Global step 180 Train loss 0.51 on epoch=12
03/16/2022 00:00:15 - INFO - __main__ - Step 190 Global step 190 Train loss 0.50 on epoch=13
03/16/2022 00:00:18 - INFO - __main__ - Step 200 Global step 200 Train loss 0.49 on epoch=14
03/16/2022 00:00:24 - INFO - __main__ - Global step 200 Train loss 0.49 Classification-F1 0.747593991052 on epoch=14
03/16/2022 00:00:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6587824625459033 -> 0.747593991052 on epoch=14, global_step=200
03/16/2022 00:00:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.39 on epoch=14
03/16/2022 00:00:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.41 on epoch=15
03/16/2022 00:00:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.34 on epoch=16
03/16/2022 00:00:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.37 on epoch=17
03/16/2022 00:00:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.31 on epoch=17
03/16/2022 00:00:44 - INFO - __main__ - Global step 250 Train loss 0.36 Classification-F1 0.6986658221952339 on epoch=17
03/16/2022 00:00:47 - INFO - __main__ - Step 260 Global step 260 Train loss 0.34 on epoch=18
03/16/2022 00:00:49 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=19
03/16/2022 00:00:52 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=19
03/16/2022 00:00:54 - INFO - __main__ - Step 290 Global step 290 Train loss 0.41 on epoch=20
03/16/2022 00:00:57 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=21
03/16/2022 00:01:05 - INFO - __main__ - Global step 300 Train loss 0.34 Classification-F1 0.7491066836836454 on epoch=21
03/16/2022 00:01:05 - INFO - __main__ - Saving model with best Classification-F1: 0.747593991052 -> 0.7491066836836454 on epoch=21, global_step=300
03/16/2022 00:01:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.21 on epoch=22
03/16/2022 00:01:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=22
03/16/2022 00:01:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=23
03/16/2022 00:01:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=24
03/16/2022 00:01:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=24
03/16/2022 00:01:26 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.7303664644773503 on epoch=24
03/16/2022 00:01:28 - INFO - __main__ - Step 360 Global step 360 Train loss 0.15 on epoch=25
03/16/2022 00:01:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.16 on epoch=26
03/16/2022 00:01:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.18 on epoch=27
03/16/2022 00:01:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=27
03/16/2022 00:01:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=28
03/16/2022 00:01:45 - INFO - __main__ - Global step 400 Train loss 0.18 Classification-F1 0.8166802892846535 on epoch=28
03/16/2022 00:01:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7491066836836454 -> 0.8166802892846535 on epoch=28, global_step=400
03/16/2022 00:01:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=29
03/16/2022 00:01:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=29
03/16/2022 00:01:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=30
03/16/2022 00:01:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.11 on epoch=31
03/16/2022 00:01:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=32
03/16/2022 00:02:05 - INFO - __main__ - Global step 450 Train loss 0.17 Classification-F1 0.8475993247266885 on epoch=32
03/16/2022 00:02:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8166802892846535 -> 0.8475993247266885 on epoch=32, global_step=450
03/16/2022 00:02:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=32
03/16/2022 00:02:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.16 on epoch=33
03/16/2022 00:02:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.15 on epoch=34
03/16/2022 00:02:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.14 on epoch=34
03/16/2022 00:02:18 - INFO - __main__ - Step 500 Global step 500 Train loss 0.12 on epoch=35
03/16/2022 00:02:25 - INFO - __main__ - Global step 500 Train loss 0.16 Classification-F1 0.7418440805959254 on epoch=35
03/16/2022 00:02:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=36
03/16/2022 00:02:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=37
03/16/2022 00:02:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=37
03/16/2022 00:02:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.12 on epoch=38
03/16/2022 00:02:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=39
03/16/2022 00:02:46 - INFO - __main__ - Global step 550 Train loss 0.17 Classification-F1 0.8028671439250187 on epoch=39
03/16/2022 00:02:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.12 on epoch=39
03/16/2022 00:02:51 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=40
03/16/2022 00:02:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.09 on epoch=41
03/16/2022 00:02:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.11 on epoch=42
03/16/2022 00:02:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=42
03/16/2022 00:03:06 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.964346337601343 on epoch=42
03/16/2022 00:03:06 - INFO - __main__ - Saving model with best Classification-F1: 0.8475993247266885 -> 0.964346337601343 on epoch=42, global_step=600
03/16/2022 00:03:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=43
03/16/2022 00:03:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.10 on epoch=44
03/16/2022 00:03:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=44
03/16/2022 00:03:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=45
03/16/2022 00:03:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=46
03/16/2022 00:03:26 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.9146301726946888 on epoch=46
03/16/2022 00:03:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=47
03/16/2022 00:03:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=47
03/16/2022 00:03:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=48
03/16/2022 00:03:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=49
03/16/2022 00:03:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=49
03/16/2022 00:03:45 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.7270074012009496 on epoch=49
03/16/2022 00:03:48 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=50
03/16/2022 00:03:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=51
03/16/2022 00:03:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=52
03/16/2022 00:03:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=52
03/16/2022 00:03:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=53
03/16/2022 00:04:04 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.8474100840624359 on epoch=53
03/16/2022 00:04:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=54
03/16/2022 00:04:09 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=54
03/16/2022 00:04:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=55
03/16/2022 00:04:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=56
03/16/2022 00:04:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=57
03/16/2022 00:04:24 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.9097292892280786 on epoch=57
03/16/2022 00:04:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=57
03/16/2022 00:04:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=58
03/16/2022 00:04:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=59
03/16/2022 00:04:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=59
03/16/2022 00:04:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=60
03/16/2022 00:04:44 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.8337871959952049 on epoch=60
03/16/2022 00:04:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=61
03/16/2022 00:04:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=62
03/16/2022 00:04:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=62
03/16/2022 00:04:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=63
03/16/2022 00:04:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=64
03/16/2022 00:05:03 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.9822650467811757 on epoch=64
03/16/2022 00:05:03 - INFO - __main__ - Saving model with best Classification-F1: 0.964346337601343 -> 0.9822650467811757 on epoch=64, global_step=900
03/16/2022 00:05:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
03/16/2022 00:05:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=65
03/16/2022 00:05:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=66
03/16/2022 00:05:13 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=67
03/16/2022 00:05:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=67
03/16/2022 00:05:23 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.9910627007401202 on epoch=67
03/16/2022 00:05:23 - INFO - __main__ - Saving model with best Classification-F1: 0.9822650467811757 -> 0.9910627007401202 on epoch=67, global_step=950
03/16/2022 00:05:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
03/16/2022 00:05:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=69
03/16/2022 00:05:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=69
03/16/2022 00:05:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=70
03/16/2022 00:05:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
03/16/2022 00:05:42 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.9683560915517992 on epoch=71
03/16/2022 00:05:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=72
03/16/2022 00:05:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=72
03/16/2022 00:05:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=73
03/16/2022 00:05:52 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=74
03/16/2022 00:05:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
03/16/2022 00:06:02 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.9819717916492109 on epoch=74
03/16/2022 00:06:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
03/16/2022 00:06:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=76
03/16/2022 00:06:10 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=77
03/16/2022 00:06:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
03/16/2022 00:06:15 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
03/16/2022 00:06:21 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.9865984150258343 on epoch=78
03/16/2022 00:06:24 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=79
03/16/2022 00:06:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=79
03/16/2022 00:06:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=80
03/16/2022 00:06:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=81
03/16/2022 00:06:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=82
03/16/2022 00:06:41 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.9101742280489908 on epoch=82
03/16/2022 00:06:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=82
03/16/2022 00:06:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
03/16/2022 00:06:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=84
03/16/2022 00:06:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
03/16/2022 00:06:54 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=85
03/16/2022 00:07:00 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.9820991153059465 on epoch=85
03/16/2022 00:07:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
03/16/2022 00:07:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
03/16/2022 00:07:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
03/16/2022 00:07:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=88
03/16/2022 00:07:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
03/16/2022 00:07:19 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.6288788907972557 on epoch=89
03/16/2022 00:07:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
03/16/2022 00:07:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
03/16/2022 00:07:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
03/16/2022 00:07:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
03/16/2022 00:07:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
03/16/2022 00:07:38 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.9775743242994436 on epoch=92
03/16/2022 00:07:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=93
03/16/2022 00:07:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=94
03/16/2022 00:07:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
03/16/2022 00:07:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
03/16/2022 00:07:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
03/16/2022 00:07:57 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.9187894121480459 on epoch=96
03/16/2022 00:07:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
03/16/2022 00:08:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
03/16/2022 00:08:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
03/16/2022 00:08:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
03/16/2022 00:08:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
03/16/2022 00:08:15 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7415336157271641 on epoch=99
03/16/2022 00:08:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
03/16/2022 00:08:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
03/16/2022 00:08:23 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
03/16/2022 00:08:26 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
03/16/2022 00:08:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
03/16/2022 00:08:34 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.9073913094074385 on epoch=103
03/16/2022 00:08:37 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
03/16/2022 00:08:39 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
03/16/2022 00:08:42 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
03/16/2022 00:08:44 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
03/16/2022 00:08:47 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
03/16/2022 00:08:53 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.9865677649358864 on epoch=107
03/16/2022 00:08:55 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=107
03/16/2022 00:08:58 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
03/16/2022 00:09:00 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
03/16/2022 00:09:03 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
03/16/2022 00:09:05 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
03/16/2022 00:09:11 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9100185672071099 on epoch=110
03/16/2022 00:09:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
03/16/2022 00:09:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
03/16/2022 00:09:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
03/16/2022 00:09:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
03/16/2022 00:09:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
03/16/2022 00:09:30 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.8402175314977735 on epoch=114
03/16/2022 00:09:32 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
03/16/2022 00:09:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
03/16/2022 00:09:37 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
03/16/2022 00:09:40 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
03/16/2022 00:09:42 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
03/16/2022 00:09:48 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.9141893068617207 on epoch=117
03/16/2022 00:09:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
03/16/2022 00:09:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
03/16/2022 00:09:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
03/16/2022 00:09:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
03/16/2022 00:10:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
03/16/2022 00:10:07 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.9821158008658009 on epoch=121
03/16/2022 00:10:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
03/16/2022 00:10:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
03/16/2022 00:10:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
03/16/2022 00:10:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
03/16/2022 00:10:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
03/16/2022 00:10:26 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.9115620490620491 on epoch=124
03/16/2022 00:10:28 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
03/16/2022 00:10:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
03/16/2022 00:10:33 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
03/16/2022 00:10:36 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
03/16/2022 00:10:38 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
03/16/2022 00:10:45 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.9141893068617207 on epoch=128
03/16/2022 00:10:47 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
03/16/2022 00:10:50 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
03/16/2022 00:10:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
03/16/2022 00:10:55 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
03/16/2022 00:10:57 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
03/16/2022 00:11:03 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.977770110976942 on epoch=132
03/16/2022 00:11:06 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
03/16/2022 00:11:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
03/16/2022 00:11:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
03/16/2022 00:11:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
03/16/2022 00:11:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
03/16/2022 00:11:22 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9103160638644509 on epoch=135
03/16/2022 00:11:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
03/16/2022 00:11:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
03/16/2022 00:11:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
03/16/2022 00:11:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
03/16/2022 00:11:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
03/16/2022 00:11:41 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9097407894293321 on epoch=139
03/16/2022 00:11:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
03/16/2022 00:11:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.13 on epoch=140
03/16/2022 00:11:48 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
03/16/2022 00:11:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
03/16/2022 00:11:53 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
03/16/2022 00:11:59 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8388170914084747 on epoch=142
03/16/2022 00:12:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
03/16/2022 00:12:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
03/16/2022 00:12:07 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
03/16/2022 00:12:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
03/16/2022 00:12:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
03/16/2022 00:12:18 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.8537156681057891 on epoch=146
03/16/2022 00:12:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
03/16/2022 00:12:23 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
03/16/2022 00:12:26 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
03/16/2022 00:12:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
03/16/2022 00:12:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
03/16/2022 00:12:37 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8294163018946582 on epoch=149
03/16/2022 00:12:40 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
03/16/2022 00:12:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
03/16/2022 00:12:45 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
03/16/2022 00:12:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
03/16/2022 00:12:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
03/16/2022 00:12:56 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8390468708202394 on epoch=153
03/16/2022 00:12:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
03/16/2022 00:13:01 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=154
03/16/2022 00:13:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
03/16/2022 00:13:06 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
03/16/2022 00:13:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
03/16/2022 00:13:14 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.8646244143324232 on epoch=157
03/16/2022 00:13:17 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
03/16/2022 00:13:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=158
03/16/2022 00:13:22 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
03/16/2022 00:13:24 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
03/16/2022 00:13:27 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
03/16/2022 00:13:33 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9821158008658009 on epoch=160
03/16/2022 00:13:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
03/16/2022 00:13:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
03/16/2022 00:13:41 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
03/16/2022 00:13:43 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=163
03/16/2022 00:13:46 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
03/16/2022 00:13:52 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9866027789414886 on epoch=164
03/16/2022 00:13:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
03/16/2022 00:13:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
03/16/2022 00:14:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
03/16/2022 00:14:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
03/16/2022 00:14:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
03/16/2022 00:14:10 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9777824326211422 on epoch=167
03/16/2022 00:14:13 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
03/16/2022 00:14:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
03/16/2022 00:14:18 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
03/16/2022 00:14:21 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
03/16/2022 00:14:23 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
03/16/2022 00:14:29 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9733058252626563 on epoch=171
03/16/2022 00:14:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
03/16/2022 00:14:34 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
03/16/2022 00:14:37 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
03/16/2022 00:14:39 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=174
03/16/2022 00:14:42 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
03/16/2022 00:14:48 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9865984150258343 on epoch=174
03/16/2022 00:14:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
03/16/2022 00:14:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
03/16/2022 00:14:56 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
03/16/2022 00:14:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
03/16/2022 00:15:01 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
03/16/2022 00:15:07 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.977770110976942 on epoch=178
03/16/2022 00:15:09 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
03/16/2022 00:15:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
03/16/2022 00:15:14 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
03/16/2022 00:15:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
03/16/2022 00:15:19 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
03/16/2022 00:15:26 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.977770110976942 on epoch=182
03/16/2022 00:15:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
03/16/2022 00:15:31 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
03/16/2022 00:15:33 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
03/16/2022 00:15:36 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
03/16/2022 00:15:38 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
03/16/2022 00:15:44 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9821297653958945 on epoch=185
03/16/2022 00:15:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
03/16/2022 00:15:49 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
03/16/2022 00:15:52 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
03/16/2022 00:15:54 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
03/16/2022 00:15:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
03/16/2022 00:16:03 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9822527251369755 on epoch=189
03/16/2022 00:16:05 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
03/16/2022 00:16:08 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
03/16/2022 00:16:10 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
03/16/2022 00:16:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
03/16/2022 00:16:16 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
03/16/2022 00:16:22 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.9821158008658009 on epoch=192
03/16/2022 00:16:24 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
03/16/2022 00:16:27 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
03/16/2022 00:16:29 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
03/16/2022 00:16:32 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
03/16/2022 00:16:34 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
03/16/2022 00:16:40 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9865984150258343 on epoch=196
03/16/2022 00:16:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
03/16/2022 00:16:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
03/16/2022 00:16:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
03/16/2022 00:16:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
03/16/2022 00:16:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
03/16/2022 00:16:59 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9822570890526298 on epoch=199
03/16/2022 00:17:02 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
03/16/2022 00:17:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
03/16/2022 00:17:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
03/16/2022 00:17:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
03/16/2022 00:17:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
03/16/2022 00:17:18 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.9775301982963273 on epoch=203
03/16/2022 00:17:21 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
03/16/2022 00:17:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
03/16/2022 00:17:26 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
03/16/2022 00:17:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
03/16/2022 00:17:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
03/16/2022 00:17:37 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=207
03/16/2022 00:17:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
03/16/2022 00:17:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
03/16/2022 00:17:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
03/16/2022 00:17:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
03/16/2022 00:17:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
03/16/2022 00:17:56 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=210
03/16/2022 00:17:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=211
03/16/2022 00:18:01 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
03/16/2022 00:18:04 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
03/16/2022 00:18:06 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
03/16/2022 00:18:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
03/16/2022 00:18:10 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 00:18:10 - INFO - __main__ - Printing 3 examples
03/16/2022 00:18:10 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
03/16/2022 00:18:10 - INFO - __main__ - ['Plant']
03/16/2022 00:18:10 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
03/16/2022 00:18:10 - INFO - __main__ - ['Plant']
03/16/2022 00:18:10 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
03/16/2022 00:18:10 - INFO - __main__ - ['Plant']
03/16/2022 00:18:10 - INFO - __main__ - Tokenizing Input ...
03/16/2022 00:18:10 - INFO - __main__ - Tokenizing Output ...
03/16/2022 00:18:11 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 00:18:11 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 00:18:11 - INFO - __main__ - Printing 3 examples
03/16/2022 00:18:11 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
03/16/2022 00:18:11 - INFO - __main__ - ['Plant']
03/16/2022 00:18:11 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
03/16/2022 00:18:11 - INFO - __main__ - ['Plant']
03/16/2022 00:18:11 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
03/16/2022 00:18:11 - INFO - __main__ - ['Plant']
03/16/2022 00:18:11 - INFO - __main__ - Tokenizing Input ...
03/16/2022 00:18:11 - INFO - __main__ - Tokenizing Output ...
03/16/2022 00:18:11 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 00:18:15 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=214
03/16/2022 00:18:15 - INFO - __main__ - save last model!
03/16/2022 00:18:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/16/2022 00:18:15 - INFO - __main__ - Start tokenizing ... 3500 instances
03/16/2022 00:18:15 - INFO - __main__ - Printing 3 examples
03/16/2022 00:18:15 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/16/2022 00:18:15 - INFO - __main__ - ['Animal']
03/16/2022 00:18:15 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/16/2022 00:18:15 - INFO - __main__ - ['Animal']
03/16/2022 00:18:15 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/16/2022 00:18:15 - INFO - __main__ - ['Village']
03/16/2022 00:18:15 - INFO - __main__ - Tokenizing Input ...
03/16/2022 00:18:17 - INFO - __main__ - Tokenizing Output ...
03/16/2022 00:18:21 - INFO - __main__ - Loaded 3500 examples from test data
03/16/2022 00:18:30 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 00:18:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 00:18:31 - INFO - __main__ - Starting training!
03/16/2022 00:20:35 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
03/16/2022 00:20:35 - INFO - __main__ - Classification-F1 on test data: 0.8565
03/16/2022 00:20:35 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.9910627007401202, test_performance=0.8564524606998681
03/16/2022 00:20:35 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
03/16/2022 00:20:36 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 00:20:36 - INFO - __main__ - Printing 3 examples
03/16/2022 00:20:36 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
03/16/2022 00:20:36 - INFO - __main__ - ['Plant']
03/16/2022 00:20:36 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
03/16/2022 00:20:36 - INFO - __main__ - ['Plant']
03/16/2022 00:20:36 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
03/16/2022 00:20:36 - INFO - __main__ - ['Plant']
03/16/2022 00:20:36 - INFO - __main__ - Tokenizing Input ...
03/16/2022 00:20:36 - INFO - __main__ - Tokenizing Output ...
03/16/2022 00:20:37 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 00:20:37 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 00:20:37 - INFO - __main__ - Printing 3 examples
03/16/2022 00:20:37 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
03/16/2022 00:20:37 - INFO - __main__ - ['Plant']
03/16/2022 00:20:37 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
03/16/2022 00:20:37 - INFO - __main__ - ['Plant']
03/16/2022 00:20:37 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
03/16/2022 00:20:37 - INFO - __main__ - ['Plant']
03/16/2022 00:20:37 - INFO - __main__ - Tokenizing Input ...
03/16/2022 00:20:37 - INFO - __main__ - Tokenizing Output ...
03/16/2022 00:20:37 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 00:20:52 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 00:20:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 00:20:53 - INFO - __main__ - Starting training!
03/16/2022 00:20:57 - INFO - __main__ - Step 10 Global step 10 Train loss 4.66 on epoch=0
03/16/2022 00:20:59 - INFO - __main__ - Step 20 Global step 20 Train loss 3.06 on epoch=1
03/16/2022 00:21:02 - INFO - __main__ - Step 30 Global step 30 Train loss 2.38 on epoch=2
03/16/2022 00:21:04 - INFO - __main__ - Step 40 Global step 40 Train loss 1.89 on epoch=2
03/16/2022 00:21:07 - INFO - __main__ - Step 50 Global step 50 Train loss 1.72 on epoch=3
03/16/2022 00:21:12 - INFO - __main__ - Global step 50 Train loss 2.74 Classification-F1 0.15382168762558662 on epoch=3
03/16/2022 00:21:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.15382168762558662 on epoch=3, global_step=50
03/16/2022 00:21:15 - INFO - __main__ - Step 60 Global step 60 Train loss 1.22 on epoch=4
03/16/2022 00:21:17 - INFO - __main__ - Step 70 Global step 70 Train loss 1.21 on epoch=4
03/16/2022 00:21:20 - INFO - __main__ - Step 80 Global step 80 Train loss 0.99 on epoch=5
03/16/2022 00:21:22 - INFO - __main__ - Step 90 Global step 90 Train loss 0.94 on epoch=6
03/16/2022 00:21:25 - INFO - __main__ - Step 100 Global step 100 Train loss 0.87 on epoch=7
03/16/2022 00:21:31 - INFO - __main__ - Global step 100 Train loss 1.05 Classification-F1 0.5883530422658897 on epoch=7
03/16/2022 00:21:31 - INFO - __main__ - Saving model with best Classification-F1: 0.15382168762558662 -> 0.5883530422658897 on epoch=7, global_step=100
03/16/2022 00:21:34 - INFO - __main__ - Step 110 Global step 110 Train loss 3.05 on epoch=7
03/16/2022 00:21:37 - INFO - __main__ - Step 120 Global step 120 Train loss 1.51 on epoch=8
03/16/2022 00:21:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.84 on epoch=9
03/16/2022 00:21:42 - INFO - __main__ - Step 140 Global step 140 Train loss 0.80 on epoch=9
03/16/2022 00:21:44 - INFO - __main__ - Step 150 Global step 150 Train loss 0.74 on epoch=10
03/16/2022 00:21:50 - INFO - __main__ - Global step 150 Train loss 1.39 Classification-F1 0.5510824282452051 on epoch=10
03/16/2022 00:21:53 - INFO - __main__ - Step 160 Global step 160 Train loss 0.80 on epoch=11
03/16/2022 00:21:55 - INFO - __main__ - Step 170 Global step 170 Train loss 0.77 on epoch=12
03/16/2022 00:21:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=12
03/16/2022 00:22:00 - INFO - __main__ - Step 190 Global step 190 Train loss 0.81 on epoch=13
03/16/2022 00:22:03 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=14
03/16/2022 00:22:09 - INFO - __main__ - Global step 200 Train loss 0.75 Classification-F1 0.5678795944507847 on epoch=14
03/16/2022 00:22:12 - INFO - __main__ - Step 210 Global step 210 Train loss 0.71 on epoch=14
03/16/2022 00:22:14 - INFO - __main__ - Step 220 Global step 220 Train loss 0.82 on epoch=15
03/16/2022 00:22:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.62 on epoch=16
03/16/2022 00:22:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.54 on epoch=17
03/16/2022 00:22:22 - INFO - __main__ - Step 250 Global step 250 Train loss 0.69 on epoch=17
03/16/2022 00:22:29 - INFO - __main__ - Global step 250 Train loss 0.67 Classification-F1 0.6819757617083164 on epoch=17
03/16/2022 00:22:29 - INFO - __main__ - Saving model with best Classification-F1: 0.5883530422658897 -> 0.6819757617083164 on epoch=17, global_step=250
03/16/2022 00:22:31 - INFO - __main__ - Step 260 Global step 260 Train loss 0.59 on epoch=18
03/16/2022 00:22:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.61 on epoch=19
03/16/2022 00:22:36 - INFO - __main__ - Step 280 Global step 280 Train loss 0.62 on epoch=19
03/16/2022 00:22:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.58 on epoch=20
03/16/2022 00:22:41 - INFO - __main__ - Step 300 Global step 300 Train loss 0.63 on epoch=21
03/16/2022 00:22:48 - INFO - __main__ - Global step 300 Train loss 0.61 Classification-F1 0.7430077406376934 on epoch=21
03/16/2022 00:22:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6819757617083164 -> 0.7430077406376934 on epoch=21, global_step=300
03/16/2022 00:22:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.53 on epoch=22
03/16/2022 00:22:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.53 on epoch=22
03/16/2022 00:22:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.53 on epoch=23
03/16/2022 00:22:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.53 on epoch=24
03/16/2022 00:23:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.55 on epoch=24
03/16/2022 00:23:08 - INFO - __main__ - Global step 350 Train loss 0.53 Classification-F1 0.6931860076702436 on epoch=24
03/16/2022 00:23:10 - INFO - __main__ - Step 360 Global step 360 Train loss 0.46 on epoch=25
03/16/2022 00:23:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.46 on epoch=26
03/16/2022 00:23:15 - INFO - __main__ - Step 380 Global step 380 Train loss 0.50 on epoch=27
03/16/2022 00:23:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.49 on epoch=27
03/16/2022 00:23:20 - INFO - __main__ - Step 400 Global step 400 Train loss 0.45 on epoch=28
03/16/2022 00:23:27 - INFO - __main__ - Global step 400 Train loss 0.47 Classification-F1 0.6991070393389771 on epoch=28
03/16/2022 00:23:30 - INFO - __main__ - Step 410 Global step 410 Train loss 0.47 on epoch=29
03/16/2022 00:23:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.43 on epoch=29
03/16/2022 00:23:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.43 on epoch=30
03/16/2022 00:23:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.34 on epoch=31
03/16/2022 00:23:40 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=32
03/16/2022 00:23:46 - INFO - __main__ - Global step 450 Train loss 0.41 Classification-F1 0.7572626255827157 on epoch=32
03/16/2022 00:23:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7430077406376934 -> 0.7572626255827157 on epoch=32, global_step=450
03/16/2022 00:23:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.39 on epoch=32
03/16/2022 00:23:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.36 on epoch=33
03/16/2022 00:23:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=34
03/16/2022 00:23:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.34 on epoch=34
03/16/2022 00:23:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.38 on epoch=35
03/16/2022 00:24:06 - INFO - __main__ - Global step 500 Train loss 0.35 Classification-F1 0.8315706080411963 on epoch=35
03/16/2022 00:24:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7572626255827157 -> 0.8315706080411963 on epoch=35, global_step=500
03/16/2022 00:24:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=36
03/16/2022 00:24:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.33 on epoch=37
03/16/2022 00:24:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=37
03/16/2022 00:24:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.34 on epoch=38
03/16/2022 00:24:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=39
03/16/2022 00:24:26 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.8781082596208647 on epoch=39
03/16/2022 00:24:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8315706080411963 -> 0.8781082596208647 on epoch=39, global_step=550
03/16/2022 00:24:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.31 on epoch=39
03/16/2022 00:24:31 - INFO - __main__ - Step 570 Global step 570 Train loss 0.29 on epoch=40
03/16/2022 00:24:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.29 on epoch=41
03/16/2022 00:24:36 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=42
03/16/2022 00:24:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.32 on epoch=42
03/16/2022 00:24:47 - INFO - __main__ - Global step 600 Train loss 0.29 Classification-F1 0.925104587323478 on epoch=42
03/16/2022 00:24:47 - INFO - __main__ - Saving model with best Classification-F1: 0.8781082596208647 -> 0.925104587323478 on epoch=42, global_step=600
03/16/2022 00:24:49 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=43
03/16/2022 00:24:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=44
03/16/2022 00:24:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=44
03/16/2022 00:24:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=45
03/16/2022 00:24:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=46
03/16/2022 00:25:07 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.8311568189340367 on epoch=46
03/16/2022 00:25:10 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=47
03/16/2022 00:25:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.25 on epoch=47
03/16/2022 00:25:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=48
03/16/2022 00:25:17 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=49
03/16/2022 00:25:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=49
03/16/2022 00:25:28 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.9141737336725233 on epoch=49
03/16/2022 00:25:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=50
03/16/2022 00:25:33 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=51
03/16/2022 00:25:35 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=52
03/16/2022 00:25:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=52
03/16/2022 00:25:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=53
03/16/2022 00:25:47 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.9594327568220127 on epoch=53
03/16/2022 00:25:47 - INFO - __main__ - Saving model with best Classification-F1: 0.925104587323478 -> 0.9594327568220127 on epoch=53, global_step=750
03/16/2022 00:25:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=54
03/16/2022 00:25:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=54
03/16/2022 00:25:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=55
03/16/2022 00:25:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.23 on epoch=56
03/16/2022 00:26:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=57
03/16/2022 00:26:08 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.9101652674755142 on epoch=57
03/16/2022 00:26:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=57
03/16/2022 00:26:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=58
03/16/2022 00:26:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=59
03/16/2022 00:26:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=59
03/16/2022 00:26:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=60
03/16/2022 00:26:28 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.914360540892799 on epoch=60
03/16/2022 00:26:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=61
03/16/2022 00:26:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=62
03/16/2022 00:26:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=62
03/16/2022 00:26:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
03/16/2022 00:26:41 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=64
03/16/2022 00:26:48 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.9105578076783012 on epoch=64
03/16/2022 00:26:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=64
03/16/2022 00:26:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=65
03/16/2022 00:26:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=66
03/16/2022 00:26:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=67
03/16/2022 00:27:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=67
03/16/2022 00:27:09 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.9103201368523948 on epoch=67
03/16/2022 00:27:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=68
03/16/2022 00:27:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=69
03/16/2022 00:27:16 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
03/16/2022 00:27:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=70
03/16/2022 00:27:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=71
03/16/2022 00:27:29 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.855335105083089 on epoch=71
03/16/2022 00:27:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
03/16/2022 00:27:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
03/16/2022 00:27:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.25 on epoch=73
03/16/2022 00:27:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=74
03/16/2022 00:27:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=74
03/16/2022 00:27:49 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.9865984150258343 on epoch=74
03/16/2022 00:27:49 - INFO - __main__ - Saving model with best Classification-F1: 0.9594327568220127 -> 0.9865984150258343 on epoch=74, global_step=1050
03/16/2022 00:27:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
03/16/2022 00:27:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=76
03/16/2022 00:27:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=77
03/16/2022 00:28:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=77
03/16/2022 00:28:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=78
03/16/2022 00:28:09 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.9146301726946888 on epoch=78
03/16/2022 00:28:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=79
03/16/2022 00:28:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=79
03/16/2022 00:28:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
03/16/2022 00:28:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=81
03/16/2022 00:28:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=82
03/16/2022 00:28:30 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.916380742913001 on epoch=82
03/16/2022 00:28:32 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
03/16/2022 00:28:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.21 on epoch=83
03/16/2022 00:28:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=84
03/16/2022 00:28:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=84
03/16/2022 00:28:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=85
03/16/2022 00:28:50 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.9731785016059208 on epoch=85
03/16/2022 00:28:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=86
03/16/2022 00:28:55 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=87
03/16/2022 00:28:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
03/16/2022 00:29:00 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
03/16/2022 00:29:03 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
03/16/2022 00:29:10 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.9865984150258343 on epoch=89
03/16/2022 00:29:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
03/16/2022 00:29:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=90
03/16/2022 00:29:18 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=91
03/16/2022 00:29:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
03/16/2022 00:29:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=92
03/16/2022 00:29:31 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.8513713989994824 on epoch=92
03/16/2022 00:29:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
03/16/2022 00:29:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=94
03/16/2022 00:29:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=94
03/16/2022 00:29:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=95
03/16/2022 00:29:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=96
03/16/2022 00:29:51 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.914360540892799 on epoch=96
03/16/2022 00:29:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
03/16/2022 00:29:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.13 on epoch=97
03/16/2022 00:29:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
03/16/2022 00:30:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=99
03/16/2022 00:30:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
03/16/2022 00:30:11 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.9185312805474095 on epoch=99
03/16/2022 00:30:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
03/16/2022 00:30:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=101
03/16/2022 00:30:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=102
03/16/2022 00:30:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=102
03/16/2022 00:30:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
03/16/2022 00:30:30 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.9643829113706358 on epoch=103
03/16/2022 00:30:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.14 on epoch=104
03/16/2022 00:30:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
03/16/2022 00:30:38 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
03/16/2022 00:30:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=106
03/16/2022 00:30:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
03/16/2022 00:30:50 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.9780510444647066 on epoch=107
03/16/2022 00:30:53 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
03/16/2022 00:30:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=108
03/16/2022 00:30:58 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
03/16/2022 00:31:00 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
03/16/2022 00:31:03 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=110
03/16/2022 00:31:10 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.9726850958808034 on epoch=110
03/16/2022 00:31:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=111
03/16/2022 00:31:15 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=112
03/16/2022 00:31:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=112
03/16/2022 00:31:20 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
03/16/2022 00:31:23 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.14 on epoch=114
03/16/2022 00:31:30 - INFO - __main__ - Global step 1600 Train loss 0.11 Classification-F1 0.9775118698505795 on epoch=114
03/16/2022 00:31:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=114
03/16/2022 00:31:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=115
03/16/2022 00:31:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
03/16/2022 00:31:40 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
03/16/2022 00:31:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.14 on epoch=117
03/16/2022 00:31:50 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.9016737336725232 on epoch=117
03/16/2022 00:31:53 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
03/16/2022 00:31:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
03/16/2022 00:31:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
03/16/2022 00:32:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
03/16/2022 00:32:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
03/16/2022 00:32:10 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.9821297653958945 on epoch=121
03/16/2022 00:32:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
03/16/2022 00:32:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
03/16/2022 00:32:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
03/16/2022 00:32:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=124
03/16/2022 00:32:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
03/16/2022 00:32:30 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.9773538961038959 on epoch=124
03/16/2022 00:32:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
03/16/2022 00:32:35 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
03/16/2022 00:32:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=127
03/16/2022 00:32:40 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
03/16/2022 00:32:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=128
03/16/2022 00:32:50 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.9820991153059465 on epoch=128
03/16/2022 00:32:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=129
03/16/2022 00:32:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
03/16/2022 00:32:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
03/16/2022 00:33:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
03/16/2022 00:33:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
03/16/2022 00:33:10 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.9185272075594656 on epoch=132
03/16/2022 00:33:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
03/16/2022 00:33:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
03/16/2022 00:33:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
03/16/2022 00:33:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
03/16/2022 00:33:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
03/16/2022 00:33:30 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.9865940511101802 on epoch=135
03/16/2022 00:33:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=136
03/16/2022 00:33:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
03/16/2022 00:33:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
03/16/2022 00:33:40 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
03/16/2022 00:33:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
03/16/2022 00:33:49 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.9731355298717729 on epoch=139
03/16/2022 00:33:52 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
03/16/2022 00:33:55 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
03/16/2022 00:33:57 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
03/16/2022 00:34:00 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
03/16/2022 00:34:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
03/16/2022 00:34:09 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9820991153059465 on epoch=142
03/16/2022 00:34:12 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
03/16/2022 00:34:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
03/16/2022 00:34:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
03/16/2022 00:34:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
03/16/2022 00:34:22 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
03/16/2022 00:34:29 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9776567518503002 on epoch=146
03/16/2022 00:34:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
03/16/2022 00:34:35 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
03/16/2022 00:34:37 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
03/16/2022 00:34:40 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
03/16/2022 00:34:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
03/16/2022 00:34:49 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9776567518503002 on epoch=149
03/16/2022 00:34:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
03/16/2022 00:34:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=151
03/16/2022 00:34:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
03/16/2022 00:35:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
03/16/2022 00:35:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
03/16/2022 00:35:08 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9143735744542195 on epoch=153
03/16/2022 00:35:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
03/16/2022 00:35:13 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
03/16/2022 00:35:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=155
03/16/2022 00:35:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
03/16/2022 00:35:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
03/16/2022 00:35:28 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.9730388563049852 on epoch=157
03/16/2022 00:35:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
03/16/2022 00:35:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
03/16/2022 00:35:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=159
03/16/2022 00:35:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
03/16/2022 00:35:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
03/16/2022 00:35:48 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.910202834799609 on epoch=160
03/16/2022 00:35:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
03/16/2022 00:35:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
03/16/2022 00:35:56 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=162
03/16/2022 00:35:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
03/16/2022 00:36:01 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=164
03/16/2022 00:36:07 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9865940511101802 on epoch=164
03/16/2022 00:36:10 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
03/16/2022 00:36:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
03/16/2022 00:36:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
03/16/2022 00:36:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
03/16/2022 00:36:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
03/16/2022 00:36:27 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9776304656760065 on epoch=167
03/16/2022 00:36:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
03/16/2022 00:36:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
03/16/2022 00:36:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
03/16/2022 00:36:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
03/16/2022 00:36:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
03/16/2022 00:36:46 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9820991153059465 on epoch=171
03/16/2022 00:36:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
03/16/2022 00:36:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=172
03/16/2022 00:36:54 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
03/16/2022 00:36:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
03/16/2022 00:36:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
03/16/2022 00:37:06 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9101857282502444 on epoch=174
03/16/2022 00:37:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
03/16/2022 00:37:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
03/16/2022 00:37:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
03/16/2022 00:37:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
03/16/2022 00:37:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
03/16/2022 00:37:25 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9821254014802402 on epoch=178
03/16/2022 00:37:28 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
03/16/2022 00:37:31 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
03/16/2022 00:37:33 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
03/16/2022 00:37:36 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
03/16/2022 00:37:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
03/16/2022 00:37:45 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9687018942474351 on epoch=182
03/16/2022 00:37:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
03/16/2022 00:37:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
03/16/2022 00:37:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
03/16/2022 00:37:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
03/16/2022 00:37:58 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
03/16/2022 00:38:04 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9776567518503002 on epoch=185
03/16/2022 00:38:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
03/16/2022 00:38:10 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
03/16/2022 00:38:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
03/16/2022 00:38:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
03/16/2022 00:38:17 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
03/16/2022 00:38:24 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9776304656760065 on epoch=189
03/16/2022 00:38:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
03/16/2022 00:38:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
03/16/2022 00:38:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
03/16/2022 00:38:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/16/2022 00:38:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
03/16/2022 00:38:44 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9776304656760065 on epoch=192
03/16/2022 00:38:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
03/16/2022 00:38:49 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
03/16/2022 00:38:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
03/16/2022 00:38:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.07 on epoch=195
03/16/2022 00:38:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
03/16/2022 00:39:03 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9776304656760065 on epoch=196
03/16/2022 00:39:06 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
03/16/2022 00:39:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
03/16/2022 00:39:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=198
03/16/2022 00:39:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
03/16/2022 00:39:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
03/16/2022 00:39:23 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=199
03/16/2022 00:39:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=200
03/16/2022 00:39:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
03/16/2022 00:39:30 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
03/16/2022 00:39:33 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
03/16/2022 00:39:35 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
03/16/2022 00:39:42 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9821254014802402 on epoch=203
03/16/2022 00:39:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
03/16/2022 00:39:47 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
03/16/2022 00:39:50 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
03/16/2022 00:39:53 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
03/16/2022 00:39:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
03/16/2022 00:40:02 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9776304656760065 on epoch=207
03/16/2022 00:40:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
03/16/2022 00:40:07 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
03/16/2022 00:40:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
03/16/2022 00:40:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
03/16/2022 00:40:15 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
03/16/2022 00:40:21 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=210
03/16/2022 00:40:23 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
03/16/2022 00:40:26 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
03/16/2022 00:40:28 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
03/16/2022 00:40:31 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
03/16/2022 00:40:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
03/16/2022 00:40:35 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 00:40:35 - INFO - __main__ - Printing 3 examples
03/16/2022 00:40:35 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
03/16/2022 00:40:35 - INFO - __main__ - ['Plant']
03/16/2022 00:40:35 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
03/16/2022 00:40:35 - INFO - __main__ - ['Plant']
03/16/2022 00:40:35 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
03/16/2022 00:40:35 - INFO - __main__ - ['Plant']
03/16/2022 00:40:35 - INFO - __main__ - Tokenizing Input ...
03/16/2022 00:40:35 - INFO - __main__ - Tokenizing Output ...
03/16/2022 00:40:35 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 00:40:35 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 00:40:35 - INFO - __main__ - Printing 3 examples
03/16/2022 00:40:35 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
03/16/2022 00:40:35 - INFO - __main__ - ['Plant']
03/16/2022 00:40:35 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
03/16/2022 00:40:35 - INFO - __main__ - ['Plant']
03/16/2022 00:40:35 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
03/16/2022 00:40:35 - INFO - __main__ - ['Plant']
03/16/2022 00:40:35 - INFO - __main__ - Tokenizing Input ...
03/16/2022 00:40:35 - INFO - __main__ - Tokenizing Output ...
03/16/2022 00:40:35 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 00:40:40 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9820991153059465 on epoch=214
03/16/2022 00:40:40 - INFO - __main__ - save last model!
03/16/2022 00:40:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/16/2022 00:40:40 - INFO - __main__ - Start tokenizing ... 3500 instances
03/16/2022 00:40:40 - INFO - __main__ - Printing 3 examples
03/16/2022 00:40:40 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/16/2022 00:40:40 - INFO - __main__ - ['Animal']
03/16/2022 00:40:40 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/16/2022 00:40:40 - INFO - __main__ - ['Animal']
03/16/2022 00:40:40 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/16/2022 00:40:40 - INFO - __main__ - ['Village']
03/16/2022 00:40:40 - INFO - __main__ - Tokenizing Input ...
03/16/2022 00:40:42 - INFO - __main__ - Tokenizing Output ...
03/16/2022 00:40:45 - INFO - __main__ - Loaded 3500 examples from test data
03/16/2022 00:40:51 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 00:40:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 00:40:52 - INFO - __main__ - Starting training!
03/16/2022 00:42:52 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
03/16/2022 00:42:52 - INFO - __main__ - Classification-F1 on test data: 0.8564
03/16/2022 00:42:52 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.9865984150258343, test_performance=0.8564078560566614
03/16/2022 00:42:52 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
03/16/2022 00:42:53 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 00:42:53 - INFO - __main__ - Printing 3 examples
03/16/2022 00:42:53 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
03/16/2022 00:42:53 - INFO - __main__ - ['Plant']
03/16/2022 00:42:53 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
03/16/2022 00:42:53 - INFO - __main__ - ['Plant']
03/16/2022 00:42:53 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
03/16/2022 00:42:53 - INFO - __main__ - ['Plant']
03/16/2022 00:42:53 - INFO - __main__ - Tokenizing Input ...
03/16/2022 00:42:53 - INFO - __main__ - Tokenizing Output ...
03/16/2022 00:42:53 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 00:42:53 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 00:42:53 - INFO - __main__ - Printing 3 examples
03/16/2022 00:42:53 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
03/16/2022 00:42:53 - INFO - __main__ - ['Plant']
03/16/2022 00:42:53 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
03/16/2022 00:42:53 - INFO - __main__ - ['Plant']
03/16/2022 00:42:53 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
03/16/2022 00:42:53 - INFO - __main__ - ['Plant']
03/16/2022 00:42:53 - INFO - __main__ - Tokenizing Input ...
03/16/2022 00:42:54 - INFO - __main__ - Tokenizing Output ...
03/16/2022 00:42:54 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 00:43:09 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 00:43:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 00:43:10 - INFO - __main__ - Starting training!
03/16/2022 00:43:13 - INFO - __main__ - Step 10 Global step 10 Train loss 5.09 on epoch=0
03/16/2022 00:43:16 - INFO - __main__ - Step 20 Global step 20 Train loss 3.81 on epoch=1
03/16/2022 00:43:18 - INFO - __main__ - Step 30 Global step 30 Train loss 3.02 on epoch=2
03/16/2022 00:43:21 - INFO - __main__ - Step 40 Global step 40 Train loss 2.36 on epoch=2
03/16/2022 00:43:23 - INFO - __main__ - Step 50 Global step 50 Train loss 2.16 on epoch=3
03/16/2022 00:43:29 - INFO - __main__ - Global step 50 Train loss 3.29 Classification-F1 0.10722128342742378 on epoch=3
03/16/2022 00:43:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10722128342742378 on epoch=3, global_step=50
03/16/2022 00:43:32 - INFO - __main__ - Step 60 Global step 60 Train loss 1.81 on epoch=4
03/16/2022 00:43:34 - INFO - __main__ - Step 70 Global step 70 Train loss 1.63 on epoch=4
03/16/2022 00:43:37 - INFO - __main__ - Step 80 Global step 80 Train loss 1.28 on epoch=5
03/16/2022 00:43:39 - INFO - __main__ - Step 90 Global step 90 Train loss 1.19 on epoch=6
03/16/2022 00:43:42 - INFO - __main__ - Step 100 Global step 100 Train loss 1.14 on epoch=7
03/16/2022 00:43:48 - INFO - __main__ - Global step 100 Train loss 1.41 Classification-F1 0.4611896216302898 on epoch=7
03/16/2022 00:43:48 - INFO - __main__ - Saving model with best Classification-F1: 0.10722128342742378 -> 0.4611896216302898 on epoch=7, global_step=100
03/16/2022 00:43:50 - INFO - __main__ - Step 110 Global step 110 Train loss 0.97 on epoch=7
03/16/2022 00:43:53 - INFO - __main__ - Step 120 Global step 120 Train loss 0.96 on epoch=8
03/16/2022 00:43:55 - INFO - __main__ - Step 130 Global step 130 Train loss 0.82 on epoch=9
03/16/2022 00:43:58 - INFO - __main__ - Step 140 Global step 140 Train loss 0.75 on epoch=9
03/16/2022 00:44:01 - INFO - __main__ - Step 150 Global step 150 Train loss 0.79 on epoch=10
03/16/2022 00:44:07 - INFO - __main__ - Global step 150 Train loss 0.86 Classification-F1 0.6067249252163309 on epoch=10
03/16/2022 00:44:07 - INFO - __main__ - Saving model with best Classification-F1: 0.4611896216302898 -> 0.6067249252163309 on epoch=10, global_step=150
03/16/2022 00:44:10 - INFO - __main__ - Step 160 Global step 160 Train loss 0.69 on epoch=11
03/16/2022 00:44:12 - INFO - __main__ - Step 170 Global step 170 Train loss 0.65 on epoch=12
03/16/2022 00:44:15 - INFO - __main__ - Step 180 Global step 180 Train loss 0.63 on epoch=12
03/16/2022 00:44:17 - INFO - __main__ - Step 190 Global step 190 Train loss 0.52 on epoch=13
03/16/2022 00:44:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=14
03/16/2022 00:44:27 - INFO - __main__ - Global step 200 Train loss 0.62 Classification-F1 0.6245188714325389 on epoch=14
03/16/2022 00:44:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6067249252163309 -> 0.6245188714325389 on epoch=14, global_step=200
03/16/2022 00:44:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.56 on epoch=14
03/16/2022 00:44:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.49 on epoch=15
03/16/2022 00:44:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.55 on epoch=16
03/16/2022 00:44:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.46 on epoch=17
03/16/2022 00:44:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.53 on epoch=17
03/16/2022 00:44:46 - INFO - __main__ - Global step 250 Train loss 0.52 Classification-F1 0.70938744020566 on epoch=17
03/16/2022 00:44:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6245188714325389 -> 0.70938744020566 on epoch=17, global_step=250
03/16/2022 00:44:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=18
03/16/2022 00:44:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.41 on epoch=19
03/16/2022 00:44:53 - INFO - __main__ - Step 280 Global step 280 Train loss 0.43 on epoch=19
03/16/2022 00:44:56 - INFO - __main__ - Step 290 Global step 290 Train loss 0.38 on epoch=20
03/16/2022 00:44:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.39 on epoch=21
03/16/2022 00:45:05 - INFO - __main__ - Global step 300 Train loss 0.43 Classification-F1 0.6674575195324369 on epoch=21
03/16/2022 00:45:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.39 on epoch=22
03/16/2022 00:45:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=22
03/16/2022 00:45:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.36 on epoch=23
03/16/2022 00:45:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=24
03/16/2022 00:45:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=24
03/16/2022 00:45:24 - INFO - __main__ - Global step 350 Train loss 0.37 Classification-F1 0.8041366041366041 on epoch=24
03/16/2022 00:45:24 - INFO - __main__ - Saving model with best Classification-F1: 0.70938744020566 -> 0.8041366041366041 on epoch=24, global_step=350
03/16/2022 00:45:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=25
03/16/2022 00:45:29 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=26
03/16/2022 00:45:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=27
03/16/2022 00:45:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.34 on epoch=27
03/16/2022 00:45:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=28
03/16/2022 00:45:44 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.7152199002768262 on epoch=28
03/16/2022 00:45:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.36 on epoch=29
03/16/2022 00:45:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=29
03/16/2022 00:45:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=30
03/16/2022 00:45:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.25 on epoch=31
03/16/2022 00:45:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=32
03/16/2022 00:46:03 - INFO - __main__ - Global step 450 Train loss 0.27 Classification-F1 0.730908448280692 on epoch=32
03/16/2022 00:46:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=32
03/16/2022 00:46:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=33
03/16/2022 00:46:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=34
03/16/2022 00:46:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=34
03/16/2022 00:46:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=35
03/16/2022 00:46:23 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.7072457934395521 on epoch=35
03/16/2022 00:46:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.15 on epoch=36
03/16/2022 00:46:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=37
03/16/2022 00:46:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=37
03/16/2022 00:46:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=38
03/16/2022 00:46:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=39
03/16/2022 00:46:42 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.691863718120558 on epoch=39
03/16/2022 00:46:45 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=39
03/16/2022 00:46:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=40
03/16/2022 00:46:50 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=41
03/16/2022 00:46:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=42
03/16/2022 00:46:55 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=42
03/16/2022 00:47:02 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.6418477367723581 on epoch=42
03/16/2022 00:47:04 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=43
03/16/2022 00:47:07 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=44
03/16/2022 00:47:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=44
03/16/2022 00:47:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=45
03/16/2022 00:47:14 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
03/16/2022 00:47:22 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.8094030864290125 on epoch=46
03/16/2022 00:47:22 - INFO - __main__ - Saving model with best Classification-F1: 0.8041366041366041 -> 0.8094030864290125 on epoch=46, global_step=650
03/16/2022 00:47:25 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=47
03/16/2022 00:47:27 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=47
03/16/2022 00:47:30 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=48
03/16/2022 00:47:32 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=49
03/16/2022 00:47:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=49
03/16/2022 00:47:42 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.6481272335474373 on epoch=49
03/16/2022 00:47:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=50
03/16/2022 00:47:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=51
03/16/2022 00:47:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=52
03/16/2022 00:47:52 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=52
03/16/2022 00:47:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=53
03/16/2022 00:48:02 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.6974277466839918 on epoch=53
03/16/2022 00:48:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.26 on epoch=54
03/16/2022 00:48:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=54
03/16/2022 00:48:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=55
03/16/2022 00:48:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=56
03/16/2022 00:48:14 - INFO - __main__ - Step 800 Global step 800 Train loss 0.17 on epoch=57
03/16/2022 00:48:22 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.7030035444862838 on epoch=57
03/16/2022 00:48:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=57
03/16/2022 00:48:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=58
03/16/2022 00:48:29 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=59
03/16/2022 00:48:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=59
03/16/2022 00:48:35 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=60
03/16/2022 00:48:42 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.6702639296187684 on epoch=60
03/16/2022 00:48:44 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=61
03/16/2022 00:48:47 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=62
03/16/2022 00:48:49 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=62
03/16/2022 00:48:52 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=63
03/16/2022 00:48:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=64
03/16/2022 00:49:01 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.6713087866725638 on epoch=64
03/16/2022 00:49:04 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=64
03/16/2022 00:49:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=65
03/16/2022 00:49:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=66
03/16/2022 00:49:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=67
03/16/2022 00:49:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=67
03/16/2022 00:49:21 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.9103886794209376 on epoch=67
03/16/2022 00:49:21 - INFO - __main__ - Saving model with best Classification-F1: 0.8094030864290125 -> 0.9103886794209376 on epoch=67, global_step=950
03/16/2022 00:49:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=68
03/16/2022 00:49:26 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
03/16/2022 00:49:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
03/16/2022 00:49:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=70
03/16/2022 00:49:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=71
03/16/2022 00:49:40 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.6956853478148209 on epoch=71
03/16/2022 00:49:43 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=72
03/16/2022 00:49:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
03/16/2022 00:49:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=73
03/16/2022 00:49:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=74
03/16/2022 00:49:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
03/16/2022 00:50:00 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.8269266114632494 on epoch=74
03/16/2022 00:50:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
03/16/2022 00:50:05 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=76
03/16/2022 00:50:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
03/16/2022 00:50:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.24 on epoch=77
03/16/2022 00:50:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
03/16/2022 00:50:19 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.9057730009454147 on epoch=78
03/16/2022 00:50:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=79
03/16/2022 00:50:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=79
03/16/2022 00:50:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=80
03/16/2022 00:50:29 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
03/16/2022 00:50:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=82
03/16/2022 00:50:39 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.7969953772833559 on epoch=82
03/16/2022 00:50:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
03/16/2022 00:50:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
03/16/2022 00:50:46 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=84
03/16/2022 00:50:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=84
03/16/2022 00:50:52 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=85
03/16/2022 00:50:58 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.9014976847583339 on epoch=85
03/16/2022 00:51:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=86
03/16/2022 00:51:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=87
03/16/2022 00:51:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
03/16/2022 00:51:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
03/16/2022 00:51:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
03/16/2022 00:51:18 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.8470748376835819 on epoch=89
03/16/2022 00:51:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
03/16/2022 00:51:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=90
03/16/2022 00:51:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
03/16/2022 00:51:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=92
03/16/2022 00:51:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
03/16/2022 00:51:38 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.8511193147119298 on epoch=92
03/16/2022 00:51:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=93
03/16/2022 00:51:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=94
03/16/2022 00:51:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
03/16/2022 00:51:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
03/16/2022 00:51:51 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=96
03/16/2022 00:51:58 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.914360540892799 on epoch=96
03/16/2022 00:51:58 - INFO - __main__ - Saving model with best Classification-F1: 0.9103886794209376 -> 0.914360540892799 on epoch=96, global_step=1350
03/16/2022 00:52:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
03/16/2022 00:52:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=97
03/16/2022 00:52:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=98
03/16/2022 00:52:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
03/16/2022 00:52:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
03/16/2022 00:52:17 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.8974818144806039 on epoch=99
03/16/2022 00:52:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=100
03/16/2022 00:52:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=101
03/16/2022 00:52:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=102
03/16/2022 00:52:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=102
03/16/2022 00:52:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=103
03/16/2022 00:52:36 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.9005206183700807 on epoch=103
03/16/2022 00:52:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
03/16/2022 00:52:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
03/16/2022 00:52:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
03/16/2022 00:52:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
03/16/2022 00:52:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=107
03/16/2022 00:52:55 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.8935087481111817 on epoch=107
03/16/2022 00:52:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=107
03/16/2022 00:53:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=108
03/16/2022 00:53:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
03/16/2022 00:53:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.13 on epoch=109
03/16/2022 00:53:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
03/16/2022 00:53:14 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.7923339977894057 on epoch=110
03/16/2022 00:53:17 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
03/16/2022 00:53:19 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.12 on epoch=112
03/16/2022 00:53:22 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
03/16/2022 00:53:24 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
03/16/2022 00:53:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
03/16/2022 00:53:33 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.9729906726569685 on epoch=114
03/16/2022 00:53:33 - INFO - __main__ - Saving model with best Classification-F1: 0.914360540892799 -> 0.9729906726569685 on epoch=114, global_step=1600
03/16/2022 00:53:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=114
03/16/2022 00:53:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
03/16/2022 00:53:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=116
03/16/2022 00:53:43 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=117
03/16/2022 00:53:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
03/16/2022 00:53:52 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.9775118698505795 on epoch=117
03/16/2022 00:53:52 - INFO - __main__ - Saving model with best Classification-F1: 0.9729906726569685 -> 0.9775118698505795 on epoch=117, global_step=1650
03/16/2022 00:53:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=118
03/16/2022 00:53:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
03/16/2022 00:54:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
03/16/2022 00:54:02 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=120
03/16/2022 00:54:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
03/16/2022 00:54:11 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.9865984150258343 on epoch=121
03/16/2022 00:54:11 - INFO - __main__ - Saving model with best Classification-F1: 0.9775118698505795 -> 0.9865984150258343 on epoch=121, global_step=1700
03/16/2022 00:54:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=122
03/16/2022 00:54:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
03/16/2022 00:54:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
03/16/2022 00:54:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
03/16/2022 00:54:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
03/16/2022 00:54:31 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.9684785085537906 on epoch=124
03/16/2022 00:54:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
03/16/2022 00:54:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
03/16/2022 00:54:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
03/16/2022 00:54:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
03/16/2022 00:54:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=128
03/16/2022 00:54:51 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.9822570890526298 on epoch=128
03/16/2022 00:54:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
03/16/2022 00:54:56 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=129
03/16/2022 00:54:59 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
03/16/2022 00:55:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=131
03/16/2022 00:55:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
03/16/2022 00:55:10 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.9186787227109808 on epoch=132
03/16/2022 00:55:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.12 on epoch=132
03/16/2022 00:55:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
03/16/2022 00:55:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
03/16/2022 00:55:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
03/16/2022 00:55:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
03/16/2022 00:55:29 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.9821158008658009 on epoch=135
03/16/2022 00:55:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
03/16/2022 00:55:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
03/16/2022 00:55:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=137
03/16/2022 00:55:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=138
03/16/2022 00:55:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
03/16/2022 00:55:48 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.9819901200949587 on epoch=139
03/16/2022 00:55:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
03/16/2022 00:55:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
03/16/2022 00:55:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
03/16/2022 00:55:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
03/16/2022 00:56:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=142
03/16/2022 00:56:07 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.9080277634025262 on epoch=142
03/16/2022 00:56:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=143
03/16/2022 00:56:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
03/16/2022 00:56:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
03/16/2022 00:56:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=145
03/16/2022 00:56:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
03/16/2022 00:56:27 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.9228413163897033 on epoch=146
03/16/2022 00:56:29 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
03/16/2022 00:56:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=147
03/16/2022 00:56:34 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
03/16/2022 00:56:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=149
03/16/2022 00:56:39 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
03/16/2022 00:56:46 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9147027882511752 on epoch=149
03/16/2022 00:56:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
03/16/2022 00:56:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
03/16/2022 00:56:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
03/16/2022 00:56:56 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
03/16/2022 00:56:59 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
03/16/2022 00:57:05 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.977495184290725 on epoch=153
03/16/2022 00:57:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=154
03/16/2022 00:57:10 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
03/16/2022 00:57:13 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
03/16/2022 00:57:15 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
03/16/2022 00:57:18 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=157
03/16/2022 00:57:24 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.9097407894293321 on epoch=157
03/16/2022 00:57:27 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
03/16/2022 00:57:30 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=158
03/16/2022 00:57:32 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
03/16/2022 00:57:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
03/16/2022 00:57:37 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
03/16/2022 00:57:44 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.9867213747669155 on epoch=160
03/16/2022 00:57:44 - INFO - __main__ - Saving model with best Classification-F1: 0.9865984150258343 -> 0.9867213747669155 on epoch=160, global_step=2250
03/16/2022 00:57:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
03/16/2022 00:57:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
03/16/2022 00:57:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
03/16/2022 00:57:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
03/16/2022 00:57:56 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=164
03/16/2022 00:58:03 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.97787856344884 on epoch=164
03/16/2022 00:58:05 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
03/16/2022 00:58:08 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
03/16/2022 00:58:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=166
03/16/2022 00:58:13 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
03/16/2022 00:58:15 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
03/16/2022 00:58:22 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.9867213747669155 on epoch=167
03/16/2022 00:58:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
03/16/2022 00:58:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
03/16/2022 00:58:29 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
03/16/2022 00:58:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
03/16/2022 00:58:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
03/16/2022 00:58:41 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9777205897021565 on epoch=171
03/16/2022 00:58:43 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
03/16/2022 00:58:46 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
03/16/2022 00:58:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=173
03/16/2022 00:58:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
03/16/2022 00:58:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
03/16/2022 00:59:00 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8591191654447703 on epoch=174
03/16/2022 00:59:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
03/16/2022 00:59:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
03/16/2022 00:59:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=177
03/16/2022 00:59:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
03/16/2022 00:59:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
03/16/2022 00:59:19 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9731881022203603 on epoch=178
03/16/2022 00:59:22 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
03/16/2022 00:59:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
03/16/2022 00:59:27 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
03/16/2022 00:59:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
03/16/2022 00:59:32 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
03/16/2022 00:59:38 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.97780076106689 on epoch=182
03/16/2022 00:59:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=182
03/16/2022 00:59:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
03/16/2022 00:59:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
03/16/2022 00:59:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
03/16/2022 00:59:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
03/16/2022 00:59:58 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9144883368792288 on epoch=185
03/16/2022 01:00:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
03/16/2022 01:00:03 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
03/16/2022 01:00:05 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
03/16/2022 01:00:08 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=188
03/16/2022 01:00:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
03/16/2022 01:00:17 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9723279341061938 on epoch=189
03/16/2022 01:00:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
03/16/2022 01:00:22 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
03/16/2022 01:00:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.11 on epoch=191
03/16/2022 01:00:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/16/2022 01:00:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
03/16/2022 01:00:36 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.9732792729455687 on epoch=192
03/16/2022 01:00:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
03/16/2022 01:00:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
03/16/2022 01:00:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
03/16/2022 01:00:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
03/16/2022 01:00:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=196
03/16/2022 01:00:55 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9144753033178079 on epoch=196
03/16/2022 01:00:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
03/16/2022 01:01:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.15 on epoch=197
03/16/2022 01:01:03 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
03/16/2022 01:01:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
03/16/2022 01:01:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
03/16/2022 01:01:15 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.9822570890526298 on epoch=199
03/16/2022 01:01:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
03/16/2022 01:01:20 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
03/16/2022 01:01:23 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
03/16/2022 01:01:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
03/16/2022 01:01:28 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
03/16/2022 01:01:34 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9679169612531027 on epoch=203
03/16/2022 01:01:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
03/16/2022 01:01:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
03/16/2022 01:01:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
03/16/2022 01:01:44 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
03/16/2022 01:01:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.08 on epoch=207
03/16/2022 01:01:54 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9054093658564313 on epoch=207
03/16/2022 01:01:56 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
03/16/2022 01:01:59 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
03/16/2022 01:02:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
03/16/2022 01:02:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
03/16/2022 01:02:06 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
03/16/2022 01:02:13 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9821034792216007 on epoch=210
03/16/2022 01:02:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
03/16/2022 01:02:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
03/16/2022 01:02:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
03/16/2022 01:02:23 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
03/16/2022 01:02:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
03/16/2022 01:02:27 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 01:02:27 - INFO - __main__ - Printing 3 examples
03/16/2022 01:02:27 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
03/16/2022 01:02:27 - INFO - __main__ - ['Company']
03/16/2022 01:02:27 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
03/16/2022 01:02:27 - INFO - __main__ - ['Company']
03/16/2022 01:02:27 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
03/16/2022 01:02:27 - INFO - __main__ - ['Company']
03/16/2022 01:02:27 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:02:27 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:02:27 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 01:02:27 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 01:02:27 - INFO - __main__ - Printing 3 examples
03/16/2022 01:02:27 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
03/16/2022 01:02:27 - INFO - __main__ - ['Company']
03/16/2022 01:02:27 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
03/16/2022 01:02:27 - INFO - __main__ - ['Company']
03/16/2022 01:02:27 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
03/16/2022 01:02:27 - INFO - __main__ - ['Company']
03/16/2022 01:02:27 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:02:27 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:02:28 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 01:02:32 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.910434899277404 on epoch=214
03/16/2022 01:02:32 - INFO - __main__ - save last model!
03/16/2022 01:02:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/16/2022 01:02:32 - INFO - __main__ - Start tokenizing ... 3500 instances
03/16/2022 01:02:32 - INFO - __main__ - Printing 3 examples
03/16/2022 01:02:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/16/2022 01:02:32 - INFO - __main__ - ['Animal']
03/16/2022 01:02:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/16/2022 01:02:32 - INFO - __main__ - ['Animal']
03/16/2022 01:02:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/16/2022 01:02:32 - INFO - __main__ - ['Village']
03/16/2022 01:02:32 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:02:34 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:02:37 - INFO - __main__ - Loaded 3500 examples from test data
03/16/2022 01:02:43 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 01:02:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 01:02:43 - INFO - __main__ - Starting training!
03/16/2022 01:04:53 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
03/16/2022 01:04:53 - INFO - __main__ - Classification-F1 on test data: 0.6759
03/16/2022 01:04:54 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.9867213747669155, test_performance=0.6758804685267276
03/16/2022 01:04:54 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
03/16/2022 01:04:54 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 01:04:54 - INFO - __main__ - Printing 3 examples
03/16/2022 01:04:54 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
03/16/2022 01:04:54 - INFO - __main__ - ['Company']
03/16/2022 01:04:54 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
03/16/2022 01:04:54 - INFO - __main__ - ['Company']
03/16/2022 01:04:54 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
03/16/2022 01:04:54 - INFO - __main__ - ['Company']
03/16/2022 01:04:54 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:04:55 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:04:55 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 01:04:55 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 01:04:55 - INFO - __main__ - Printing 3 examples
03/16/2022 01:04:55 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
03/16/2022 01:04:55 - INFO - __main__ - ['Company']
03/16/2022 01:04:55 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
03/16/2022 01:04:55 - INFO - __main__ - ['Company']
03/16/2022 01:04:55 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
03/16/2022 01:04:55 - INFO - __main__ - ['Company']
03/16/2022 01:04:55 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:04:55 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:04:55 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 01:05:13 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 01:05:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 01:05:14 - INFO - __main__ - Starting training!
03/16/2022 01:05:18 - INFO - __main__ - Step 10 Global step 10 Train loss 4.39 on epoch=0
03/16/2022 01:05:21 - INFO - __main__ - Step 20 Global step 20 Train loss 2.87 on epoch=1
03/16/2022 01:05:23 - INFO - __main__ - Step 30 Global step 30 Train loss 2.17 on epoch=2
03/16/2022 01:05:26 - INFO - __main__ - Step 40 Global step 40 Train loss 1.45 on epoch=2
03/16/2022 01:05:29 - INFO - __main__ - Step 50 Global step 50 Train loss 1.10 on epoch=3
03/16/2022 01:05:35 - INFO - __main__ - Global step 50 Train loss 2.40 Classification-F1 0.3781315927214134 on epoch=3
03/16/2022 01:05:35 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3781315927214134 on epoch=3, global_step=50
03/16/2022 01:05:38 - INFO - __main__ - Step 60 Global step 60 Train loss 0.95 on epoch=4
03/16/2022 01:05:40 - INFO - __main__ - Step 70 Global step 70 Train loss 0.93 on epoch=4
03/16/2022 01:05:43 - INFO - __main__ - Step 80 Global step 80 Train loss 0.75 on epoch=5
03/16/2022 01:05:46 - INFO - __main__ - Step 90 Global step 90 Train loss 0.63 on epoch=6
03/16/2022 01:05:48 - INFO - __main__ - Step 100 Global step 100 Train loss 0.70 on epoch=7
03/16/2022 01:05:55 - INFO - __main__ - Global step 100 Train loss 0.79 Classification-F1 0.4667450390800013 on epoch=7
03/16/2022 01:05:55 - INFO - __main__ - Saving model with best Classification-F1: 0.3781315927214134 -> 0.4667450390800013 on epoch=7, global_step=100
03/16/2022 01:05:58 - INFO - __main__ - Step 110 Global step 110 Train loss 0.63 on epoch=7
03/16/2022 01:06:00 - INFO - __main__ - Step 120 Global step 120 Train loss 0.50 on epoch=8
03/16/2022 01:06:03 - INFO - __main__ - Step 130 Global step 130 Train loss 0.55 on epoch=9
03/16/2022 01:06:06 - INFO - __main__ - Step 140 Global step 140 Train loss 0.54 on epoch=9
03/16/2022 01:06:08 - INFO - __main__ - Step 150 Global step 150 Train loss 0.47 on epoch=10
03/16/2022 01:06:15 - INFO - __main__ - Global step 150 Train loss 0.54 Classification-F1 0.6148183259014178 on epoch=10
03/16/2022 01:06:15 - INFO - __main__ - Saving model with best Classification-F1: 0.4667450390800013 -> 0.6148183259014178 on epoch=10, global_step=150
03/16/2022 01:06:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.52 on epoch=11
03/16/2022 01:06:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.48 on epoch=12
03/16/2022 01:06:22 - INFO - __main__ - Step 180 Global step 180 Train loss 0.35 on epoch=12
03/16/2022 01:06:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.41 on epoch=13
03/16/2022 01:06:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.50 on epoch=14
03/16/2022 01:06:35 - INFO - __main__ - Global step 200 Train loss 0.45 Classification-F1 0.6309483655568848 on epoch=14
03/16/2022 01:06:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6148183259014178 -> 0.6309483655568848 on epoch=14, global_step=200
03/16/2022 01:06:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.43 on epoch=14
03/16/2022 01:06:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.32 on epoch=15
03/16/2022 01:06:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.33 on epoch=16
03/16/2022 01:06:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.37 on epoch=17
03/16/2022 01:06:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.33 on epoch=17
03/16/2022 01:06:56 - INFO - __main__ - Global step 250 Train loss 0.36 Classification-F1 0.7619192039230548 on epoch=17
03/16/2022 01:06:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6309483655568848 -> 0.7619192039230548 on epoch=17, global_step=250
03/16/2022 01:06:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.36 on epoch=18
03/16/2022 01:07:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.27 on epoch=19
03/16/2022 01:07:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.31 on epoch=19
03/16/2022 01:07:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.23 on epoch=20
03/16/2022 01:07:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=21
03/16/2022 01:07:16 - INFO - __main__ - Global step 300 Train loss 0.29 Classification-F1 0.6356452037787509 on epoch=21
03/16/2022 01:07:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=22
03/16/2022 01:07:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=22
03/16/2022 01:07:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=23
03/16/2022 01:07:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=24
03/16/2022 01:07:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=24
03/16/2022 01:07:37 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.8847546022245579 on epoch=24
03/16/2022 01:07:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7619192039230548 -> 0.8847546022245579 on epoch=24, global_step=350
03/16/2022 01:07:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.17 on epoch=25
03/16/2022 01:07:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.15 on epoch=26
03/16/2022 01:07:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=27
03/16/2022 01:07:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.18 on epoch=27
03/16/2022 01:07:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.19 on epoch=28
03/16/2022 01:07:56 - INFO - __main__ - Global step 400 Train loss 0.18 Classification-F1 0.6547607160399582 on epoch=28
03/16/2022 01:07:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=29
03/16/2022 01:08:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=29
03/16/2022 01:08:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=30
03/16/2022 01:08:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=31
03/16/2022 01:08:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=32
03/16/2022 01:08:17 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.7651708938320648 on epoch=32
03/16/2022 01:08:19 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=32
03/16/2022 01:08:22 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=33
03/16/2022 01:08:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.16 on epoch=34
03/16/2022 01:08:27 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=34
03/16/2022 01:08:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=35
03/16/2022 01:08:37 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.7915751045202839 on epoch=35
03/16/2022 01:08:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.17 on epoch=36
03/16/2022 01:08:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=37
03/16/2022 01:08:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.15 on epoch=37
03/16/2022 01:08:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=38
03/16/2022 01:08:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.11 on epoch=39
03/16/2022 01:08:56 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.6312122442447756 on epoch=39
03/16/2022 01:08:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=39
03/16/2022 01:09:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=40
03/16/2022 01:09:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=41
03/16/2022 01:09:06 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=42
03/16/2022 01:09:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.10 on epoch=42
03/16/2022 01:09:15 - INFO - __main__ - Global step 600 Train loss 0.12 Classification-F1 0.6801598938695713 on epoch=42
03/16/2022 01:09:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=43
03/16/2022 01:09:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=44
03/16/2022 01:09:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=44
03/16/2022 01:09:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=45
03/16/2022 01:09:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=46
03/16/2022 01:09:36 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.7910640537049735 on epoch=46
03/16/2022 01:09:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=47
03/16/2022 01:09:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=47
03/16/2022 01:09:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=48
03/16/2022 01:09:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=49
03/16/2022 01:09:48 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=49
03/16/2022 01:09:55 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.7094797546286042 on epoch=49
03/16/2022 01:09:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=50
03/16/2022 01:10:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=51
03/16/2022 01:10:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=52
03/16/2022 01:10:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=52
03/16/2022 01:10:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=53
03/16/2022 01:10:15 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.7112324843086992 on epoch=53
03/16/2022 01:10:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=54
03/16/2022 01:10:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=54
03/16/2022 01:10:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=55
03/16/2022 01:10:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=56
03/16/2022 01:10:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=57
03/16/2022 01:10:34 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.8287442649293981 on epoch=57
03/16/2022 01:10:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=57
03/16/2022 01:10:39 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=58
03/16/2022 01:10:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=59
03/16/2022 01:10:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=59
03/16/2022 01:10:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=60
03/16/2022 01:10:53 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.7990121023872482 on epoch=60
03/16/2022 01:10:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=61
03/16/2022 01:10:58 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=62
03/16/2022 01:11:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=62
03/16/2022 01:11:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=63
03/16/2022 01:11:05 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=64
03/16/2022 01:11:12 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.8364766418134539 on epoch=64
03/16/2022 01:11:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=64
03/16/2022 01:11:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=65
03/16/2022 01:11:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=66
03/16/2022 01:11:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=67
03/16/2022 01:11:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=67
03/16/2022 01:11:31 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.7160811764977212 on epoch=67
03/16/2022 01:11:33 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=68
03/16/2022 01:11:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=69
03/16/2022 01:11:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=69
03/16/2022 01:11:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
03/16/2022 01:11:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=71
03/16/2022 01:11:50 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.7981192603444452 on epoch=71
03/16/2022 01:11:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=72
03/16/2022 01:11:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=72
03/16/2022 01:11:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=73
03/16/2022 01:12:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
03/16/2022 01:12:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=74
03/16/2022 01:12:08 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.9060895713663494 on epoch=74
03/16/2022 01:12:08 - INFO - __main__ - Saving model with best Classification-F1: 0.8847546022245579 -> 0.9060895713663494 on epoch=74, global_step=1050
03/16/2022 01:12:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
03/16/2022 01:12:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=76
03/16/2022 01:12:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=77
03/16/2022 01:12:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=77
03/16/2022 01:12:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=78
03/16/2022 01:12:28 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.8386578167027645 on epoch=78
03/16/2022 01:12:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=79
03/16/2022 01:12:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
03/16/2022 01:12:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
03/16/2022 01:12:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=81
03/16/2022 01:12:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
03/16/2022 01:12:47 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.7529520171176751 on epoch=82
03/16/2022 01:12:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
03/16/2022 01:12:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
03/16/2022 01:12:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=84
03/16/2022 01:12:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=84
03/16/2022 01:13:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=85
03/16/2022 01:13:06 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.8513452756974971 on epoch=85
03/16/2022 01:13:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
03/16/2022 01:13:12 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
03/16/2022 01:13:14 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
03/16/2022 01:13:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=88
03/16/2022 01:13:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
03/16/2022 01:13:25 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7721662271946902 on epoch=89
03/16/2022 01:13:28 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
03/16/2022 01:13:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
03/16/2022 01:13:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
03/16/2022 01:13:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
03/16/2022 01:13:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
03/16/2022 01:13:44 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.8313954190970321 on epoch=92
03/16/2022 01:13:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
03/16/2022 01:13:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
03/16/2022 01:13:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
03/16/2022 01:13:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
03/16/2022 01:13:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
03/16/2022 01:14:04 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.8908120057946664 on epoch=96
03/16/2022 01:14:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
03/16/2022 01:14:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=97
03/16/2022 01:14:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
03/16/2022 01:14:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=99
03/16/2022 01:14:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
03/16/2022 01:14:23 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.9738813832250985 on epoch=99
03/16/2022 01:14:23 - INFO - __main__ - Saving model with best Classification-F1: 0.9060895713663494 -> 0.9738813832250985 on epoch=99, global_step=1400
03/16/2022 01:14:25 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
03/16/2022 01:14:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
03/16/2022 01:14:30 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=102
03/16/2022 01:14:33 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
03/16/2022 01:14:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
03/16/2022 01:14:42 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7891436455938632 on epoch=103
03/16/2022 01:14:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
03/16/2022 01:14:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
03/16/2022 01:14:49 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
03/16/2022 01:14:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
03/16/2022 01:14:54 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
03/16/2022 01:15:01 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8904820501025433 on epoch=107
03/16/2022 01:15:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
03/16/2022 01:15:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
03/16/2022 01:15:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=109
03/16/2022 01:15:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
03/16/2022 01:15:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
03/16/2022 01:15:20 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7573689042826224 on epoch=110
03/16/2022 01:15:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
03/16/2022 01:15:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
03/16/2022 01:15:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
03/16/2022 01:15:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
03/16/2022 01:15:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
03/16/2022 01:15:39 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7632906980445912 on epoch=114
03/16/2022 01:15:41 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
03/16/2022 01:15:44 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
03/16/2022 01:15:46 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=116
03/16/2022 01:15:49 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
03/16/2022 01:15:51 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
03/16/2022 01:15:58 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8548995566474138 on epoch=117
03/16/2022 01:16:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
03/16/2022 01:16:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
03/16/2022 01:16:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
03/16/2022 01:16:08 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
03/16/2022 01:16:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
03/16/2022 01:16:17 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8548995566474138 on epoch=121
03/16/2022 01:16:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
03/16/2022 01:16:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
03/16/2022 01:16:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
03/16/2022 01:16:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
03/16/2022 01:16:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
03/16/2022 01:16:36 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7990409374506854 on epoch=124
03/16/2022 01:16:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
03/16/2022 01:16:41 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
03/16/2022 01:16:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
03/16/2022 01:16:46 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
03/16/2022 01:16:49 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
03/16/2022 01:16:55 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7991588990738372 on epoch=128
03/16/2022 01:16:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
03/16/2022 01:17:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
03/16/2022 01:17:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
03/16/2022 01:17:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
03/16/2022 01:17:08 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
03/16/2022 01:17:14 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.8023141074611663 on epoch=132
03/16/2022 01:17:17 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
03/16/2022 01:17:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
03/16/2022 01:17:22 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
03/16/2022 01:17:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
03/16/2022 01:17:27 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
03/16/2022 01:17:33 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9146301726946888 on epoch=135
03/16/2022 01:17:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
03/16/2022 01:17:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
03/16/2022 01:17:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
03/16/2022 01:17:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
03/16/2022 01:17:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
03/16/2022 01:17:52 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8024183280350262 on epoch=139
03/16/2022 01:17:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
03/16/2022 01:17:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
03/16/2022 01:18:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
03/16/2022 01:18:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
03/16/2022 01:18:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
03/16/2022 01:18:11 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8505425630662823 on epoch=142
03/16/2022 01:18:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
03/16/2022 01:18:16 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
03/16/2022 01:18:19 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
03/16/2022 01:18:21 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
03/16/2022 01:18:24 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
03/16/2022 01:18:30 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9640054262174077 on epoch=146
03/16/2022 01:18:33 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
03/16/2022 01:18:36 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
03/16/2022 01:18:38 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
03/16/2022 01:18:41 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
03/16/2022 01:18:43 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
03/16/2022 01:18:50 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8869064245661334 on epoch=149
03/16/2022 01:18:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
03/16/2022 01:18:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
03/16/2022 01:18:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
03/16/2022 01:19:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
03/16/2022 01:19:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
03/16/2022 01:19:09 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8362478129081544 on epoch=153
03/16/2022 01:19:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
03/16/2022 01:19:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
03/16/2022 01:19:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
03/16/2022 01:19:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
03/16/2022 01:19:22 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
03/16/2022 01:19:28 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7489178024216956 on epoch=157
03/16/2022 01:19:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
03/16/2022 01:19:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
03/16/2022 01:19:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
03/16/2022 01:19:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
03/16/2022 01:19:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
03/16/2022 01:19:47 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8436230755131965 on epoch=160
03/16/2022 01:19:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
03/16/2022 01:19:52 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
03/16/2022 01:19:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
03/16/2022 01:19:57 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
03/16/2022 01:20:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
03/16/2022 01:20:07 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9682304107809571 on epoch=164
03/16/2022 01:20:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
03/16/2022 01:20:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
03/16/2022 01:20:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
03/16/2022 01:20:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
03/16/2022 01:20:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
03/16/2022 01:20:26 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9683577344376927 on epoch=167
03/16/2022 01:20:29 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
03/16/2022 01:20:31 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
03/16/2022 01:20:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
03/16/2022 01:20:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
03/16/2022 01:20:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
03/16/2022 01:20:46 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.977311719257427 on epoch=171
03/16/2022 01:20:46 - INFO - __main__ - Saving model with best Classification-F1: 0.9738813832250985 -> 0.977311719257427 on epoch=171, global_step=2400
03/16/2022 01:20:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
03/16/2022 01:20:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
03/16/2022 01:20:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
03/16/2022 01:20:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
03/16/2022 01:20:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
03/16/2022 01:21:06 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8461145292264838 on epoch=174
03/16/2022 01:21:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
03/16/2022 01:21:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
03/16/2022 01:21:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
03/16/2022 01:21:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
03/16/2022 01:21:18 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
03/16/2022 01:21:25 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8432807595684649 on epoch=178
03/16/2022 01:21:28 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
03/16/2022 01:21:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
03/16/2022 01:21:33 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
03/16/2022 01:21:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
03/16/2022 01:21:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
03/16/2022 01:21:44 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8462475003034775 on epoch=182
03/16/2022 01:21:46 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
03/16/2022 01:21:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
03/16/2022 01:21:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
03/16/2022 01:21:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
03/16/2022 01:21:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
03/16/2022 01:22:03 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9013151301576348 on epoch=185
03/16/2022 01:22:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
03/16/2022 01:22:08 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
03/16/2022 01:22:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
03/16/2022 01:22:13 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
03/16/2022 01:22:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
03/16/2022 01:22:22 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8954276842701889 on epoch=189
03/16/2022 01:22:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
03/16/2022 01:22:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
03/16/2022 01:22:29 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
03/16/2022 01:22:32 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/16/2022 01:22:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
03/16/2022 01:22:40 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9020727107935116 on epoch=192
03/16/2022 01:22:43 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=193
03/16/2022 01:22:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
03/16/2022 01:22:48 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
03/16/2022 01:22:51 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
03/16/2022 01:22:53 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
03/16/2022 01:22:59 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9102304789512797 on epoch=196
03/16/2022 01:23:02 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
03/16/2022 01:23:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
03/16/2022 01:23:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
03/16/2022 01:23:09 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
03/16/2022 01:23:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
03/16/2022 01:23:19 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9100185672071099 on epoch=199
03/16/2022 01:23:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
03/16/2022 01:23:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
03/16/2022 01:23:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
03/16/2022 01:23:29 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
03/16/2022 01:23:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
03/16/2022 01:23:40 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9100185672071099 on epoch=203
03/16/2022 01:23:42 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
03/16/2022 01:23:45 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
03/16/2022 01:23:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
03/16/2022 01:23:50 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
03/16/2022 01:23:52 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
03/16/2022 01:23:59 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9100144942191659 on epoch=207
03/16/2022 01:24:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
03/16/2022 01:24:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
03/16/2022 01:24:06 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
03/16/2022 01:24:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
03/16/2022 01:24:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
03/16/2022 01:24:18 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7981495058107961 on epoch=210
03/16/2022 01:24:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
03/16/2022 01:24:23 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
03/16/2022 01:24:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
03/16/2022 01:24:28 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
03/16/2022 01:24:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
03/16/2022 01:24:32 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 01:24:32 - INFO - __main__ - Printing 3 examples
03/16/2022 01:24:32 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
03/16/2022 01:24:32 - INFO - __main__ - ['Company']
03/16/2022 01:24:32 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
03/16/2022 01:24:32 - INFO - __main__ - ['Company']
03/16/2022 01:24:32 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
03/16/2022 01:24:32 - INFO - __main__ - ['Company']
03/16/2022 01:24:32 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:24:32 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:24:32 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 01:24:32 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 01:24:32 - INFO - __main__ - Printing 3 examples
03/16/2022 01:24:32 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
03/16/2022 01:24:32 - INFO - __main__ - ['Company']
03/16/2022 01:24:32 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
03/16/2022 01:24:32 - INFO - __main__ - ['Company']
03/16/2022 01:24:32 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
03/16/2022 01:24:32 - INFO - __main__ - ['Company']
03/16/2022 01:24:32 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:24:32 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:24:32 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 01:24:37 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9143449677036014 on epoch=214
03/16/2022 01:24:37 - INFO - __main__ - save last model!
03/16/2022 01:24:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/16/2022 01:24:37 - INFO - __main__ - Start tokenizing ... 3500 instances
03/16/2022 01:24:37 - INFO - __main__ - Printing 3 examples
03/16/2022 01:24:37 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/16/2022 01:24:37 - INFO - __main__ - ['Animal']
03/16/2022 01:24:37 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/16/2022 01:24:37 - INFO - __main__ - ['Animal']
03/16/2022 01:24:37 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/16/2022 01:24:37 - INFO - __main__ - ['Village']
03/16/2022 01:24:37 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:24:39 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:24:42 - INFO - __main__ - Loaded 3500 examples from test data
03/16/2022 01:24:48 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 01:24:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 01:24:49 - INFO - __main__ - Starting training!
03/16/2022 01:26:45 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
03/16/2022 01:26:45 - INFO - __main__ - Classification-F1 on test data: 0.6208
03/16/2022 01:26:45 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.977311719257427, test_performance=0.6207855682485387
03/16/2022 01:26:45 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
03/16/2022 01:26:46 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 01:26:46 - INFO - __main__ - Printing 3 examples
03/16/2022 01:26:46 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
03/16/2022 01:26:46 - INFO - __main__ - ['Company']
03/16/2022 01:26:46 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
03/16/2022 01:26:46 - INFO - __main__ - ['Company']
03/16/2022 01:26:46 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
03/16/2022 01:26:46 - INFO - __main__ - ['Company']
03/16/2022 01:26:46 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:26:46 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:26:47 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 01:26:47 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 01:26:47 - INFO - __main__ - Printing 3 examples
03/16/2022 01:26:47 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
03/16/2022 01:26:47 - INFO - __main__ - ['Company']
03/16/2022 01:26:47 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
03/16/2022 01:26:47 - INFO - __main__ - ['Company']
03/16/2022 01:26:47 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
03/16/2022 01:26:47 - INFO - __main__ - ['Company']
03/16/2022 01:26:47 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:26:47 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:26:47 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 01:27:02 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 01:27:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 01:27:03 - INFO - __main__ - Starting training!
03/16/2022 01:27:06 - INFO - __main__ - Step 10 Global step 10 Train loss 4.45 on epoch=0
03/16/2022 01:27:09 - INFO - __main__ - Step 20 Global step 20 Train loss 2.90 on epoch=1
03/16/2022 01:27:11 - INFO - __main__ - Step 30 Global step 30 Train loss 2.10 on epoch=2
03/16/2022 01:27:14 - INFO - __main__ - Step 40 Global step 40 Train loss 1.65 on epoch=2
03/16/2022 01:27:17 - INFO - __main__ - Step 50 Global step 50 Train loss 1.28 on epoch=3
03/16/2022 01:27:25 - INFO - __main__ - Global step 50 Train loss 2.48 Classification-F1 0.2911927076098739 on epoch=3
03/16/2022 01:27:25 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2911927076098739 on epoch=3, global_step=50
03/16/2022 01:27:27 - INFO - __main__ - Step 60 Global step 60 Train loss 1.09 on epoch=4
03/16/2022 01:27:30 - INFO - __main__ - Step 70 Global step 70 Train loss 0.86 on epoch=4
03/16/2022 01:27:32 - INFO - __main__ - Step 80 Global step 80 Train loss 0.86 on epoch=5
03/16/2022 01:27:35 - INFO - __main__ - Step 90 Global step 90 Train loss 0.79 on epoch=6
03/16/2022 01:27:38 - INFO - __main__ - Step 100 Global step 100 Train loss 0.73 on epoch=7
03/16/2022 01:27:44 - INFO - __main__ - Global step 100 Train loss 0.87 Classification-F1 0.47214866453996895 on epoch=7
03/16/2022 01:27:44 - INFO - __main__ - Saving model with best Classification-F1: 0.2911927076098739 -> 0.47214866453996895 on epoch=7, global_step=100
03/16/2022 01:27:47 - INFO - __main__ - Step 110 Global step 110 Train loss 0.60 on epoch=7
03/16/2022 01:27:49 - INFO - __main__ - Step 120 Global step 120 Train loss 0.65 on epoch=8
03/16/2022 01:27:52 - INFO - __main__ - Step 130 Global step 130 Train loss 0.59 on epoch=9
03/16/2022 01:27:54 - INFO - __main__ - Step 140 Global step 140 Train loss 0.57 on epoch=9
03/16/2022 01:27:57 - INFO - __main__ - Step 150 Global step 150 Train loss 0.45 on epoch=10
03/16/2022 01:28:03 - INFO - __main__ - Global step 150 Train loss 0.57 Classification-F1 0.6528393983161228 on epoch=10
03/16/2022 01:28:04 - INFO - __main__ - Saving model with best Classification-F1: 0.47214866453996895 -> 0.6528393983161228 on epoch=10, global_step=150
03/16/2022 01:28:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.59 on epoch=11
03/16/2022 01:28:09 - INFO - __main__ - Step 170 Global step 170 Train loss 0.55 on epoch=12
03/16/2022 01:28:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.56 on epoch=12
03/16/2022 01:28:14 - INFO - __main__ - Step 190 Global step 190 Train loss 0.50 on epoch=13
03/16/2022 01:28:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.39 on epoch=14
03/16/2022 01:28:24 - INFO - __main__ - Global step 200 Train loss 0.52 Classification-F1 0.6188306314080307 on epoch=14
03/16/2022 01:28:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.39 on epoch=14
03/16/2022 01:28:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.31 on epoch=15
03/16/2022 01:28:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.39 on epoch=16
03/16/2022 01:28:34 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=17
03/16/2022 01:28:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.33 on epoch=17
03/16/2022 01:28:44 - INFO - __main__ - Global step 250 Train loss 0.37 Classification-F1 0.753141810195645 on epoch=17
03/16/2022 01:28:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6528393983161228 -> 0.753141810195645 on epoch=17, global_step=250
03/16/2022 01:28:47 - INFO - __main__ - Step 260 Global step 260 Train loss 0.35 on epoch=18
03/16/2022 01:28:49 - INFO - __main__ - Step 270 Global step 270 Train loss 0.29 on epoch=19
03/16/2022 01:28:52 - INFO - __main__ - Step 280 Global step 280 Train loss 0.35 on epoch=19
03/16/2022 01:28:54 - INFO - __main__ - Step 290 Global step 290 Train loss 0.26 on epoch=20
03/16/2022 01:28:57 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=21
03/16/2022 01:29:04 - INFO - __main__ - Global step 300 Train loss 0.30 Classification-F1 0.7224006725981142 on epoch=21
03/16/2022 01:29:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.36 on epoch=22
03/16/2022 01:29:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=22
03/16/2022 01:29:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=23
03/16/2022 01:29:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=24
03/16/2022 01:29:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=24
03/16/2022 01:29:24 - INFO - __main__ - Global step 350 Train loss 0.30 Classification-F1 0.7240408514822898 on epoch=24
03/16/2022 01:29:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=25
03/16/2022 01:29:29 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=26
03/16/2022 01:29:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=27
03/16/2022 01:29:34 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=27
03/16/2022 01:29:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=28
03/16/2022 01:29:44 - INFO - __main__ - Global step 400 Train loss 0.25 Classification-F1 0.7732266550075458 on epoch=28
03/16/2022 01:29:44 - INFO - __main__ - Saving model with best Classification-F1: 0.753141810195645 -> 0.7732266550075458 on epoch=28, global_step=400
03/16/2022 01:29:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.17 on epoch=29
03/16/2022 01:29:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=29
03/16/2022 01:29:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=30
03/16/2022 01:29:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=31
03/16/2022 01:29:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=32
03/16/2022 01:30:04 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.8397819830620983 on epoch=32
03/16/2022 01:30:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7732266550075458 -> 0.8397819830620983 on epoch=32, global_step=450
03/16/2022 01:30:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=32
03/16/2022 01:30:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=33
03/16/2022 01:30:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=34
03/16/2022 01:30:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=34
03/16/2022 01:30:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=35
03/16/2022 01:30:25 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.8880362919578606 on epoch=35
03/16/2022 01:30:25 - INFO - __main__ - Saving model with best Classification-F1: 0.8397819830620983 -> 0.8880362919578606 on epoch=35, global_step=500
03/16/2022 01:30:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=36
03/16/2022 01:30:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=37
03/16/2022 01:30:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=37
03/16/2022 01:30:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.12 on epoch=38
03/16/2022 01:30:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=39
03/16/2022 01:30:45 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.8350406777130915 on epoch=39
03/16/2022 01:30:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=39
03/16/2022 01:30:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=40
03/16/2022 01:30:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=41
03/16/2022 01:30:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=42
03/16/2022 01:30:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=42
03/16/2022 01:31:05 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.9020602336731367 on epoch=42
03/16/2022 01:31:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8880362919578606 -> 0.9020602336731367 on epoch=42, global_step=600
03/16/2022 01:31:07 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=43
03/16/2022 01:31:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=44
03/16/2022 01:31:12 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=44
03/16/2022 01:31:15 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=45
03/16/2022 01:31:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
03/16/2022 01:31:24 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.9910364145658264 on epoch=46
03/16/2022 01:31:24 - INFO - __main__ - Saving model with best Classification-F1: 0.9020602336731367 -> 0.9910364145658264 on epoch=46, global_step=650
03/16/2022 01:31:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.10 on epoch=47
03/16/2022 01:31:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=47
03/16/2022 01:31:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=48
03/16/2022 01:31:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=49
03/16/2022 01:31:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=49
03/16/2022 01:31:44 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.9775075059349252 on epoch=49
03/16/2022 01:31:47 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=50
03/16/2022 01:31:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=51
03/16/2022 01:31:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=52
03/16/2022 01:31:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=52
03/16/2022 01:31:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=53
03/16/2022 01:32:04 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.9777928033383442 on epoch=53
03/16/2022 01:32:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=54
03/16/2022 01:32:09 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=54
03/16/2022 01:32:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=55
03/16/2022 01:32:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=56
03/16/2022 01:32:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
03/16/2022 01:32:24 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.9635266863343579 on epoch=57
03/16/2022 01:32:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=57
03/16/2022 01:32:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=58
03/16/2022 01:32:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=59
03/16/2022 01:32:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=59
03/16/2022 01:32:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=60
03/16/2022 01:32:44 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.9821341293115486 on epoch=60
03/16/2022 01:32:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=61
03/16/2022 01:32:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=62
03/16/2022 01:32:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=62
03/16/2022 01:32:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=63
03/16/2022 01:32:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=64
03/16/2022 01:33:03 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.9185272075594656 on epoch=64
03/16/2022 01:33:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=64
03/16/2022 01:33:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=65
03/16/2022 01:33:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=66
03/16/2022 01:33:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=67
03/16/2022 01:33:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=67
03/16/2022 01:33:23 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.8514020362543845 on epoch=67
03/16/2022 01:33:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=68
03/16/2022 01:33:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=69
03/16/2022 01:33:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=69
03/16/2022 01:33:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=70
03/16/2022 01:33:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
03/16/2022 01:33:42 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.9228413163897036 on epoch=71
03/16/2022 01:33:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=72
03/16/2022 01:33:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
03/16/2022 01:33:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
03/16/2022 01:33:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=74
03/16/2022 01:33:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=74
03/16/2022 01:34:01 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.8555177349532188 on epoch=74
03/16/2022 01:34:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=75
03/16/2022 01:34:06 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=76
03/16/2022 01:34:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
03/16/2022 01:34:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=77
03/16/2022 01:34:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=78
03/16/2022 01:34:21 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.9143646138807429 on epoch=78
03/16/2022 01:34:24 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
03/16/2022 01:34:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
03/16/2022 01:34:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=80
03/16/2022 01:34:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
03/16/2022 01:34:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=82
03/16/2022 01:34:41 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.9185272075594656 on epoch=82
03/16/2022 01:34:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=82
03/16/2022 01:34:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
03/16/2022 01:34:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=84
03/16/2022 01:34:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=84
03/16/2022 01:34:54 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=85
03/16/2022 01:35:01 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.9186705767350927 on epoch=85
03/16/2022 01:35:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
03/16/2022 01:35:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
03/16/2022 01:35:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=87
03/16/2022 01:35:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
03/16/2022 01:35:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
03/16/2022 01:35:20 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.9186705767350927 on epoch=89
03/16/2022 01:35:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
03/16/2022 01:35:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
03/16/2022 01:35:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
03/16/2022 01:35:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
03/16/2022 01:35:33 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
03/16/2022 01:35:39 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.9910714285714286 on epoch=92
03/16/2022 01:35:39 - INFO - __main__ - Saving model with best Classification-F1: 0.9910364145658264 -> 0.9910714285714286 on epoch=92, global_step=1300
03/16/2022 01:35:42 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=93
03/16/2022 01:35:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
03/16/2022 01:35:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
03/16/2022 01:35:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
03/16/2022 01:35:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
03/16/2022 01:35:58 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.958914601194013 on epoch=96
03/16/2022 01:36:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
03/16/2022 01:36:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
03/16/2022 01:36:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
03/16/2022 01:36:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
03/16/2022 01:36:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
03/16/2022 01:36:17 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.9731661799617208 on epoch=99
03/16/2022 01:36:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
03/16/2022 01:36:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
03/16/2022 01:36:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
03/16/2022 01:36:28 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
03/16/2022 01:36:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
03/16/2022 01:36:37 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.9015337187222615 on epoch=103
03/16/2022 01:36:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=104
03/16/2022 01:36:42 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=104
03/16/2022 01:36:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
03/16/2022 01:36:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
03/16/2022 01:36:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
03/16/2022 01:36:56 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.9821341293115486 on epoch=107
03/16/2022 01:36:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
03/16/2022 01:37:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
03/16/2022 01:37:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=109
03/16/2022 01:37:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
03/16/2022 01:37:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
03/16/2022 01:37:15 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.9910627007401202 on epoch=110
03/16/2022 01:37:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
03/16/2022 01:37:20 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
03/16/2022 01:37:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
03/16/2022 01:37:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
03/16/2022 01:37:28 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=114
03/16/2022 01:37:34 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.98212540148024 on epoch=114
03/16/2022 01:37:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
03/16/2022 01:37:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
03/16/2022 01:37:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=116
03/16/2022 01:37:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
03/16/2022 01:37:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
03/16/2022 01:37:53 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.9865940511101802 on epoch=117
03/16/2022 01:37:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
03/16/2022 01:37:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
03/16/2022 01:38:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
03/16/2022 01:38:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=120
03/16/2022 01:38:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
03/16/2022 01:38:13 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9729819200407436 on epoch=121
03/16/2022 01:38:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
03/16/2022 01:38:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
03/16/2022 01:38:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
03/16/2022 01:38:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
03/16/2022 01:38:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
03/16/2022 01:38:32 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.98659405111018 on epoch=124
03/16/2022 01:38:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
03/16/2022 01:38:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
03/16/2022 01:38:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
03/16/2022 01:38:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
03/16/2022 01:38:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=128
03/16/2022 01:38:51 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.9059986008088475 on epoch=128
03/16/2022 01:38:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
03/16/2022 01:38:56 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=129
03/16/2022 01:38:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
03/16/2022 01:39:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
03/16/2022 01:39:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
03/16/2022 01:39:10 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9866027789414886 on epoch=132
03/16/2022 01:39:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
03/16/2022 01:39:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
03/16/2022 01:39:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=134
03/16/2022 01:39:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
03/16/2022 01:39:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
03/16/2022 01:39:29 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9226979472140762 on epoch=135
03/16/2022 01:39:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
03/16/2022 01:39:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
03/16/2022 01:39:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
03/16/2022 01:39:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
03/16/2022 01:39:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
03/16/2022 01:39:48 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9270120560443141 on epoch=139
03/16/2022 01:39:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
03/16/2022 01:39:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
03/16/2022 01:39:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
03/16/2022 01:39:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
03/16/2022 01:40:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
03/16/2022 01:40:07 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9143646138807429 on epoch=142
03/16/2022 01:40:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.13 on epoch=143
03/16/2022 01:40:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
03/16/2022 01:40:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
03/16/2022 01:40:17 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
03/16/2022 01:40:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=146
03/16/2022 01:40:26 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.9228413163897033 on epoch=146
03/16/2022 01:40:29 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
03/16/2022 01:40:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
03/16/2022 01:40:34 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
03/16/2022 01:40:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
03/16/2022 01:40:39 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
03/16/2022 01:40:45 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9866027789414886 on epoch=149
03/16/2022 01:40:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
03/16/2022 01:40:50 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
03/16/2022 01:40:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
03/16/2022 01:40:56 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
03/16/2022 01:40:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
03/16/2022 01:41:04 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9186787227109808 on epoch=153
03/16/2022 01:41:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
03/16/2022 01:41:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
03/16/2022 01:41:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
03/16/2022 01:41:15 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
03/16/2022 01:41:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
03/16/2022 01:41:23 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9228494623655915 on epoch=157
03/16/2022 01:41:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
03/16/2022 01:41:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
03/16/2022 01:41:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
03/16/2022 01:41:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
03/16/2022 01:41:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
03/16/2022 01:41:42 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=160
03/16/2022 01:41:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
03/16/2022 01:41:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
03/16/2022 01:41:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
03/16/2022 01:41:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=163
03/16/2022 01:41:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
03/16/2022 01:42:01 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9185272075594656 on epoch=164
03/16/2022 01:42:04 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
03/16/2022 01:42:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
03/16/2022 01:42:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
03/16/2022 01:42:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
03/16/2022 01:42:14 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
03/16/2022 01:42:20 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9101938742261323 on epoch=167
03/16/2022 01:42:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
03/16/2022 01:42:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
03/16/2022 01:42:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
03/16/2022 01:42:30 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
03/16/2022 01:42:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
03/16/2022 01:42:39 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9228494623655915 on epoch=171
03/16/2022 01:42:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
03/16/2022 01:42:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
03/16/2022 01:42:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
03/16/2022 01:42:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
03/16/2022 01:42:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
03/16/2022 01:42:57 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9821384932272029 on epoch=174
03/16/2022 01:43:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
03/16/2022 01:43:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=176
03/16/2022 01:43:05 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
03/16/2022 01:43:07 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
03/16/2022 01:43:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
03/16/2022 01:43:16 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9228494623655915 on epoch=178
03/16/2022 01:43:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
03/16/2022 01:43:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
03/16/2022 01:43:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
03/16/2022 01:43:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
03/16/2022 01:43:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
03/16/2022 01:43:35 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9143564679048547 on epoch=182
03/16/2022 01:43:38 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
03/16/2022 01:43:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
03/16/2022 01:43:43 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
03/16/2022 01:43:45 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
03/16/2022 01:43:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
03/16/2022 01:43:54 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9865677649358864 on epoch=185
03/16/2022 01:43:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
03/16/2022 01:43:59 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
03/16/2022 01:44:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
03/16/2022 01:44:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
03/16/2022 01:44:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
03/16/2022 01:44:13 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9819717916492109 on epoch=189
03/16/2022 01:44:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
03/16/2022 01:44:18 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
03/16/2022 01:44:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
03/16/2022 01:44:23 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/16/2022 01:44:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
03/16/2022 01:44:31 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9866027789414886 on epoch=192
03/16/2022 01:44:34 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
03/16/2022 01:44:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=194
03/16/2022 01:44:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
03/16/2022 01:44:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
03/16/2022 01:44:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
03/16/2022 01:44:50 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8553121046805819 on epoch=196
03/16/2022 01:44:52 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
03/16/2022 01:44:55 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
03/16/2022 01:44:57 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
03/16/2022 01:45:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
03/16/2022 01:45:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
03/16/2022 01:45:09 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.914360540892799 on epoch=199
03/16/2022 01:45:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
03/16/2022 01:45:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=201
03/16/2022 01:45:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
03/16/2022 01:45:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
03/16/2022 01:45:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
03/16/2022 01:45:27 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9776698435972629 on epoch=203
03/16/2022 01:45:30 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
03/16/2022 01:45:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
03/16/2022 01:45:35 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
03/16/2022 01:45:37 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
03/16/2022 01:45:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
03/16/2022 01:45:46 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9776304656760063 on epoch=207
03/16/2022 01:45:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
03/16/2022 01:45:51 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
03/16/2022 01:45:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
03/16/2022 01:45:56 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
03/16/2022 01:45:59 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
03/16/2022 01:46:05 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9101938742261323 on epoch=210
03/16/2022 01:46:07 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
03/16/2022 01:46:10 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
03/16/2022 01:46:12 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
03/16/2022 01:46:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
03/16/2022 01:46:17 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
03/16/2022 01:46:21 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 01:46:21 - INFO - __main__ - Printing 3 examples
03/16/2022 01:46:21 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
03/16/2022 01:46:21 - INFO - __main__ - ['Company']
03/16/2022 01:46:21 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
03/16/2022 01:46:21 - INFO - __main__ - ['Company']
03/16/2022 01:46:21 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
03/16/2022 01:46:21 - INFO - __main__ - ['Company']
03/16/2022 01:46:21 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:46:21 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:46:21 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 01:46:21 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 01:46:21 - INFO - __main__ - Printing 3 examples
03/16/2022 01:46:21 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
03/16/2022 01:46:21 - INFO - __main__ - ['Company']
03/16/2022 01:46:21 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
03/16/2022 01:46:21 - INFO - __main__ - ['Company']
03/16/2022 01:46:21 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
03/16/2022 01:46:21 - INFO - __main__ - ['Company']
03/16/2022 01:46:21 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:46:22 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:46:22 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 01:46:23 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=214
03/16/2022 01:46:23 - INFO - __main__ - save last model!
03/16/2022 01:46:23 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/16/2022 01:46:23 - INFO - __main__ - Start tokenizing ... 3500 instances
03/16/2022 01:46:23 - INFO - __main__ - Printing 3 examples
03/16/2022 01:46:23 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/16/2022 01:46:23 - INFO - __main__ - ['Animal']
03/16/2022 01:46:23 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/16/2022 01:46:23 - INFO - __main__ - ['Animal']
03/16/2022 01:46:23 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/16/2022 01:46:23 - INFO - __main__ - ['Village']
03/16/2022 01:46:23 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:46:25 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:46:29 - INFO - __main__ - Loaded 3500 examples from test data
03/16/2022 01:46:37 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 01:46:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 01:46:38 - INFO - __main__ - Starting training!
03/16/2022 01:48:36 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
03/16/2022 01:48:36 - INFO - __main__ - Classification-F1 on test data: 0.6520
03/16/2022 01:48:36 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.9910714285714286, test_performance=0.65197100897935
03/16/2022 01:48:36 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
03/16/2022 01:48:37 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 01:48:37 - INFO - __main__ - Printing 3 examples
03/16/2022 01:48:37 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
03/16/2022 01:48:37 - INFO - __main__ - ['Company']
03/16/2022 01:48:37 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
03/16/2022 01:48:37 - INFO - __main__ - ['Company']
03/16/2022 01:48:37 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
03/16/2022 01:48:37 - INFO - __main__ - ['Company']
03/16/2022 01:48:37 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:48:37 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:48:37 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 01:48:37 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 01:48:37 - INFO - __main__ - Printing 3 examples
03/16/2022 01:48:37 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
03/16/2022 01:48:37 - INFO - __main__ - ['Company']
03/16/2022 01:48:37 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
03/16/2022 01:48:37 - INFO - __main__ - ['Company']
03/16/2022 01:48:37 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
03/16/2022 01:48:37 - INFO - __main__ - ['Company']
03/16/2022 01:48:37 - INFO - __main__ - Tokenizing Input ...
03/16/2022 01:48:37 - INFO - __main__ - Tokenizing Output ...
03/16/2022 01:48:38 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 01:48:56 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 01:48:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 01:48:57 - INFO - __main__ - Starting training!
03/16/2022 01:49:00 - INFO - __main__ - Step 10 Global step 10 Train loss 4.75 on epoch=0
03/16/2022 01:49:03 - INFO - __main__ - Step 20 Global step 20 Train loss 3.23 on epoch=1
03/16/2022 01:49:05 - INFO - __main__ - Step 30 Global step 30 Train loss 2.50 on epoch=2
03/16/2022 01:49:08 - INFO - __main__ - Step 40 Global step 40 Train loss 1.83 on epoch=2
03/16/2022 01:49:10 - INFO - __main__ - Step 50 Global step 50 Train loss 1.59 on epoch=3
03/16/2022 01:49:16 - INFO - __main__ - Global step 50 Train loss 2.78 Classification-F1 0.22087555365110137 on epoch=3
03/16/2022 01:49:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.22087555365110137 on epoch=3, global_step=50
03/16/2022 01:49:18 - INFO - __main__ - Step 60 Global step 60 Train loss 1.37 on epoch=4
03/16/2022 01:49:21 - INFO - __main__ - Step 70 Global step 70 Train loss 1.18 on epoch=4
03/16/2022 01:49:23 - INFO - __main__ - Step 80 Global step 80 Train loss 0.96 on epoch=5
03/16/2022 01:49:26 - INFO - __main__ - Step 90 Global step 90 Train loss 0.94 on epoch=6
03/16/2022 01:49:28 - INFO - __main__ - Step 100 Global step 100 Train loss 0.79 on epoch=7
03/16/2022 01:49:35 - INFO - __main__ - Global step 100 Train loss 1.05 Classification-F1 0.4480035271473675 on epoch=7
03/16/2022 01:49:35 - INFO - __main__ - Saving model with best Classification-F1: 0.22087555365110137 -> 0.4480035271473675 on epoch=7, global_step=100
03/16/2022 01:49:37 - INFO - __main__ - Step 110 Global step 110 Train loss 0.77 on epoch=7
03/16/2022 01:49:40 - INFO - __main__ - Step 120 Global step 120 Train loss 0.69 on epoch=8
03/16/2022 01:49:42 - INFO - __main__ - Step 130 Global step 130 Train loss 0.77 on epoch=9
03/16/2022 01:49:45 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=9
03/16/2022 01:49:47 - INFO - __main__ - Step 150 Global step 150 Train loss 0.64 on epoch=10
03/16/2022 01:49:54 - INFO - __main__ - Global step 150 Train loss 0.72 Classification-F1 0.590924708179511 on epoch=10
03/16/2022 01:49:54 - INFO - __main__ - Saving model with best Classification-F1: 0.4480035271473675 -> 0.590924708179511 on epoch=10, global_step=150
03/16/2022 01:49:57 - INFO - __main__ - Step 160 Global step 160 Train loss 0.65 on epoch=11
03/16/2022 01:49:59 - INFO - __main__ - Step 170 Global step 170 Train loss 0.64 on epoch=12
03/16/2022 01:50:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.57 on epoch=12
03/16/2022 01:50:04 - INFO - __main__ - Step 190 Global step 190 Train loss 0.61 on epoch=13
03/16/2022 01:50:07 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=14
03/16/2022 01:50:14 - INFO - __main__ - Global step 200 Train loss 0.61 Classification-F1 0.6317463281831824 on epoch=14
03/16/2022 01:50:14 - INFO - __main__ - Saving model with best Classification-F1: 0.590924708179511 -> 0.6317463281831824 on epoch=14, global_step=200
03/16/2022 01:50:16 - INFO - __main__ - Step 210 Global step 210 Train loss 0.48 on epoch=14
03/16/2022 01:50:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.44 on epoch=15
03/16/2022 01:50:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.50 on epoch=16
03/16/2022 01:50:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.53 on epoch=17
03/16/2022 01:50:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=17
03/16/2022 01:50:33 - INFO - __main__ - Global step 250 Train loss 0.48 Classification-F1 0.6006481441550227 on epoch=17
03/16/2022 01:50:36 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=18
03/16/2022 01:50:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.33 on epoch=19
03/16/2022 01:50:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.41 on epoch=19
03/16/2022 01:50:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.33 on epoch=20
03/16/2022 01:50:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.36 on epoch=21
03/16/2022 01:50:53 - INFO - __main__ - Global step 300 Train loss 0.39 Classification-F1 0.682178914527185 on epoch=21
03/16/2022 01:50:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6317463281831824 -> 0.682178914527185 on epoch=21, global_step=300
03/16/2022 01:50:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.38 on epoch=22
03/16/2022 01:50:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.31 on epoch=22
03/16/2022 01:51:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=23
03/16/2022 01:51:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.35 on epoch=24
03/16/2022 01:51:06 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=24
03/16/2022 01:51:13 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.7195534042437879 on epoch=24
03/16/2022 01:51:13 - INFO - __main__ - Saving model with best Classification-F1: 0.682178914527185 -> 0.7195534042437879 on epoch=24, global_step=350
03/16/2022 01:51:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=25
03/16/2022 01:51:18 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=26
03/16/2022 01:51:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.35 on epoch=27
03/16/2022 01:51:23 - INFO - __main__ - Step 390 Global step 390 Train loss 0.26 on epoch=27
03/16/2022 01:51:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.24 on epoch=28
03/16/2022 01:51:33 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.7609087770474167 on epoch=28
03/16/2022 01:51:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7195534042437879 -> 0.7609087770474167 on epoch=28, global_step=400
03/16/2022 01:51:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.32 on epoch=29
03/16/2022 01:51:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.31 on epoch=29
03/16/2022 01:51:40 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=30
03/16/2022 01:51:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=31
03/16/2022 01:51:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=32
03/16/2022 01:51:53 - INFO - __main__ - Global step 450 Train loss 0.28 Classification-F1 0.668342752114682 on epoch=32
03/16/2022 01:51:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=32
03/16/2022 01:51:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=33
03/16/2022 01:52:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=34
03/16/2022 01:52:03 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=34
03/16/2022 01:52:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=35
03/16/2022 01:52:13 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.6603611300979721 on epoch=35
03/16/2022 01:52:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=36
03/16/2022 01:52:18 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=37
03/16/2022 01:52:21 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=37
03/16/2022 01:52:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=38
03/16/2022 01:52:26 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=39
03/16/2022 01:52:34 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.7265012745510321 on epoch=39
03/16/2022 01:52:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=39
03/16/2022 01:52:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=40
03/16/2022 01:52:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=41
03/16/2022 01:52:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=42
03/16/2022 01:52:47 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=42
03/16/2022 01:52:55 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.7399820354991132 on epoch=42
03/16/2022 01:52:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=43
03/16/2022 01:53:00 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=44
03/16/2022 01:53:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=44
03/16/2022 01:53:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=45
03/16/2022 01:53:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=46
03/16/2022 01:53:15 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.7867716653295401 on epoch=46
03/16/2022 01:53:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7609087770474167 -> 0.7867716653295401 on epoch=46, global_step=650
03/16/2022 01:53:18 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=47
03/16/2022 01:53:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
03/16/2022 01:53:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=48
03/16/2022 01:53:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=49
03/16/2022 01:53:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=49
03/16/2022 01:53:36 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.7950264045587184 on epoch=49
03/16/2022 01:53:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7867716653295401 -> 0.7950264045587184 on epoch=49, global_step=700
03/16/2022 01:53:39 - INFO - __main__ - Step 710 Global step 710 Train loss 0.13 on epoch=50
03/16/2022 01:53:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=51
03/16/2022 01:53:44 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=52
03/16/2022 01:53:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=52
03/16/2022 01:53:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=53
03/16/2022 01:53:57 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.9140548982595699 on epoch=53
03/16/2022 01:53:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7950264045587184 -> 0.9140548982595699 on epoch=53, global_step=750
03/16/2022 01:53:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=54
03/16/2022 01:54:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=54
03/16/2022 01:54:05 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=55
03/16/2022 01:54:07 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
03/16/2022 01:54:10 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
03/16/2022 01:54:18 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.7987281163974993 on epoch=57
03/16/2022 01:54:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=57
03/16/2022 01:54:23 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=58
03/16/2022 01:54:26 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=59
03/16/2022 01:54:28 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=59
03/16/2022 01:54:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=60
03/16/2022 01:54:39 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.7268747229531543 on epoch=60
03/16/2022 01:54:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=61
03/16/2022 01:54:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=62
03/16/2022 01:54:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=62
03/16/2022 01:54:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=63
03/16/2022 01:54:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=64
03/16/2022 01:54:59 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.8064040258635562 on epoch=64
03/16/2022 01:55:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=64
03/16/2022 01:55:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
03/16/2022 01:55:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=66
03/16/2022 01:55:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=67
03/16/2022 01:55:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=67
03/16/2022 01:55:19 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.8627304749384839 on epoch=67
03/16/2022 01:55:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=68
03/16/2022 01:55:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
03/16/2022 01:55:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=69
03/16/2022 01:55:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=70
03/16/2022 01:55:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
03/16/2022 01:55:39 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.8043583430052825 on epoch=71
03/16/2022 01:55:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=72
03/16/2022 01:55:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
03/16/2022 01:55:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=73
03/16/2022 01:55:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=74
03/16/2022 01:55:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
03/16/2022 01:56:00 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.8100840902646831 on epoch=74
03/16/2022 01:56:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=75
03/16/2022 01:56:05 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=76
03/16/2022 01:56:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
03/16/2022 01:56:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=77
03/16/2022 01:56:13 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=78
03/16/2022 01:56:19 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.8591153470185728 on epoch=78
03/16/2022 01:56:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
03/16/2022 01:56:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
03/16/2022 01:56:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=80
03/16/2022 01:56:29 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
03/16/2022 01:56:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=82
03/16/2022 01:56:38 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.8062890238510209 on epoch=82
03/16/2022 01:56:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
03/16/2022 01:56:43 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
03/16/2022 01:56:46 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
03/16/2022 01:56:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=84
03/16/2022 01:56:51 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
03/16/2022 01:56:58 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.802482457236105 on epoch=85
03/16/2022 01:57:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
03/16/2022 01:57:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=87
03/16/2022 01:57:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
03/16/2022 01:57:08 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
03/16/2022 01:57:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
03/16/2022 01:57:18 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.7788511298947732 on epoch=89
03/16/2022 01:57:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=89
03/16/2022 01:57:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
03/16/2022 01:57:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
03/16/2022 01:57:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
03/16/2022 01:57:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=92
03/16/2022 01:57:38 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.7985363019714915 on epoch=92
03/16/2022 01:57:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
03/16/2022 01:57:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=94
03/16/2022 01:57:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=94
03/16/2022 01:57:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=95
03/16/2022 01:57:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=96
03/16/2022 01:57:57 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.8473683406647117 on epoch=96
03/16/2022 01:58:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
03/16/2022 01:58:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
03/16/2022 01:58:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
03/16/2022 01:58:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
03/16/2022 01:58:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
03/16/2022 01:58:17 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7991870795238917 on epoch=99
03/16/2022 01:58:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
03/16/2022 01:58:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
03/16/2022 01:58:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
03/16/2022 01:58:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
03/16/2022 01:58:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
03/16/2022 01:58:36 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.8551930596285435 on epoch=103
03/16/2022 01:58:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=104
03/16/2022 01:58:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
03/16/2022 01:58:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
03/16/2022 01:58:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
03/16/2022 01:58:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
03/16/2022 01:58:56 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.9185272075594656 on epoch=107
03/16/2022 01:58:56 - INFO - __main__ - Saving model with best Classification-F1: 0.9140548982595699 -> 0.9185272075594656 on epoch=107, global_step=1500
03/16/2022 01:58:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
03/16/2022 01:59:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
03/16/2022 01:59:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=109
03/16/2022 01:59:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=109
03/16/2022 01:59:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
03/16/2022 01:59:15 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7148634048464269 on epoch=110
03/16/2022 01:59:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
03/16/2022 01:59:20 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
03/16/2022 01:59:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
03/16/2022 01:59:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
03/16/2022 01:59:28 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
03/16/2022 01:59:35 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.8467023172905526 on epoch=114
03/16/2022 01:59:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=114
03/16/2022 01:59:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=115
03/16/2022 01:59:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
03/16/2022 01:59:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
03/16/2022 01:59:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
03/16/2022 01:59:54 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.9097292892280786 on epoch=117
03/16/2022 01:59:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
03/16/2022 01:59:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
03/16/2022 02:00:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
03/16/2022 02:00:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
03/16/2022 02:00:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
03/16/2022 02:00:13 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.8429969948871159 on epoch=121
03/16/2022 02:00:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
03/16/2022 02:00:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
03/16/2022 02:00:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
03/16/2022 02:00:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
03/16/2022 02:00:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
03/16/2022 02:00:31 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7516552126081959 on epoch=124
03/16/2022 02:00:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
03/16/2022 02:00:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
03/16/2022 02:00:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
03/16/2022 02:00:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
03/16/2022 02:00:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=128
03/16/2022 02:00:50 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8507467943189007 on epoch=128
03/16/2022 02:00:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
03/16/2022 02:00:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
03/16/2022 02:00:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
03/16/2022 02:01:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
03/16/2022 02:01:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
03/16/2022 02:01:10 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.9226979472140762 on epoch=132
03/16/2022 02:01:10 - INFO - __main__ - Saving model with best Classification-F1: 0.9185272075594656 -> 0.9226979472140762 on epoch=132, global_step=1850
03/16/2022 02:01:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
03/16/2022 02:01:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
03/16/2022 02:01:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
03/16/2022 02:01:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
03/16/2022 02:01:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
03/16/2022 02:01:28 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.8103501811281698 on epoch=135
03/16/2022 02:01:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.11 on epoch=136
03/16/2022 02:01:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
03/16/2022 02:01:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
03/16/2022 02:01:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
03/16/2022 02:01:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
03/16/2022 02:01:48 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.9101742280489908 on epoch=139
03/16/2022 02:01:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
03/16/2022 02:01:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
03/16/2022 02:01:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=141
03/16/2022 02:01:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
03/16/2022 02:02:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
03/16/2022 02:02:07 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9185272075594656 on epoch=142
03/16/2022 02:02:09 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
03/16/2022 02:02:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=144
03/16/2022 02:02:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
03/16/2022 02:02:17 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
03/16/2022 02:02:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
03/16/2022 02:02:26 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8103501811281698 on epoch=146
03/16/2022 02:02:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
03/16/2022 02:02:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
03/16/2022 02:02:34 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
03/16/2022 02:02:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
03/16/2022 02:02:39 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
03/16/2022 02:02:45 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9185272075594656 on epoch=149
03/16/2022 02:02:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
03/16/2022 02:02:50 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
03/16/2022 02:02:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
03/16/2022 02:02:55 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
03/16/2022 02:02:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
03/16/2022 02:03:04 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9185272075594656 on epoch=153
03/16/2022 02:03:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
03/16/2022 02:03:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
03/16/2022 02:03:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
03/16/2022 02:03:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
03/16/2022 02:03:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
03/16/2022 02:03:24 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8591069464809384 on epoch=157
03/16/2022 02:03:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=157
03/16/2022 02:03:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
03/16/2022 02:03:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
03/16/2022 02:03:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
03/16/2022 02:03:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.10 on epoch=160
03/16/2022 02:03:43 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.9185272075594656 on epoch=160
03/16/2022 02:03:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
03/16/2022 02:03:48 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
03/16/2022 02:03:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
03/16/2022 02:03:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
03/16/2022 02:03:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
03/16/2022 02:04:02 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.859103128054741 on epoch=164
03/16/2022 02:04:05 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
03/16/2022 02:04:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=165
03/16/2022 02:04:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
03/16/2022 02:04:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=167
03/16/2022 02:04:15 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=167
03/16/2022 02:04:21 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.859103128054741 on epoch=167
03/16/2022 02:04:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
03/16/2022 02:04:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
03/16/2022 02:04:29 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
03/16/2022 02:04:31 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
03/16/2022 02:04:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
03/16/2022 02:04:41 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9185272075594656 on epoch=171
03/16/2022 02:04:43 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
03/16/2022 02:04:46 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
03/16/2022 02:04:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
03/16/2022 02:04:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
03/16/2022 02:04:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
03/16/2022 02:05:00 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9139245626453634 on epoch=174
03/16/2022 02:05:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
03/16/2022 02:05:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
03/16/2022 02:05:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
03/16/2022 02:05:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
03/16/2022 02:05:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
03/16/2022 02:05:19 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.98659405111018 on epoch=178
03/16/2022 02:05:19 - INFO - __main__ - Saving model with best Classification-F1: 0.9226979472140762 -> 0.98659405111018 on epoch=178, global_step=2500
03/16/2022 02:05:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
03/16/2022 02:05:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
03/16/2022 02:05:27 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
03/16/2022 02:05:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
03/16/2022 02:05:32 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
03/16/2022 02:05:38 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8521906856584276 on epoch=182
03/16/2022 02:05:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
03/16/2022 02:05:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
03/16/2022 02:05:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
03/16/2022 02:05:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
03/16/2022 02:05:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
03/16/2022 02:05:58 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9096072386394968 on epoch=185
03/16/2022 02:06:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
03/16/2022 02:06:03 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
03/16/2022 02:06:05 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
03/16/2022 02:06:08 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
03/16/2022 02:06:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
03/16/2022 02:06:17 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9143564679048549 on epoch=189
03/16/2022 02:06:20 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
03/16/2022 02:06:22 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
03/16/2022 02:06:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
03/16/2022 02:06:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/16/2022 02:06:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
03/16/2022 02:06:36 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9185272075594656 on epoch=192
03/16/2022 02:06:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
03/16/2022 02:06:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
03/16/2022 02:06:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
03/16/2022 02:06:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
03/16/2022 02:06:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
03/16/2022 02:06:55 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.98659405111018 on epoch=196
03/16/2022 02:06:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
03/16/2022 02:07:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
03/16/2022 02:07:03 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
03/16/2022 02:07:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
03/16/2022 02:07:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
03/16/2022 02:07:15 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9143564679048547 on epoch=199
03/16/2022 02:07:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
03/16/2022 02:07:20 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
03/16/2022 02:07:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
03/16/2022 02:07:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
03/16/2022 02:07:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
03/16/2022 02:07:33 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9819717916492109 on epoch=203
03/16/2022 02:07:36 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=204
03/16/2022 02:07:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
03/16/2022 02:07:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
03/16/2022 02:07:43 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
03/16/2022 02:07:46 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
03/16/2022 02:07:52 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.859103128054741 on epoch=207
03/16/2022 02:07:55 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
03/16/2022 02:07:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
03/16/2022 02:08:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
03/16/2022 02:08:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
03/16/2022 02:08:05 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
03/16/2022 02:08:12 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.859103128054741 on epoch=210
03/16/2022 02:08:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
03/16/2022 02:08:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
03/16/2022 02:08:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=212
03/16/2022 02:08:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
03/16/2022 02:08:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
03/16/2022 02:08:26 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 02:08:26 - INFO - __main__ - Printing 3 examples
03/16/2022 02:08:26 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
03/16/2022 02:08:26 - INFO - __main__ - ['Company']
03/16/2022 02:08:26 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
03/16/2022 02:08:26 - INFO - __main__ - ['Company']
03/16/2022 02:08:26 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
03/16/2022 02:08:26 - INFO - __main__ - ['Company']
03/16/2022 02:08:26 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:08:26 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:08:26 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 02:08:26 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 02:08:26 - INFO - __main__ - Printing 3 examples
03/16/2022 02:08:26 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
03/16/2022 02:08:26 - INFO - __main__ - ['Company']
03/16/2022 02:08:26 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
03/16/2022 02:08:26 - INFO - __main__ - ['Company']
03/16/2022 02:08:26 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
03/16/2022 02:08:26 - INFO - __main__ - ['Company']
03/16/2022 02:08:26 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:08:26 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:08:26 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 02:08:31 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.859103128054741 on epoch=214
03/16/2022 02:08:31 - INFO - __main__ - save last model!
03/16/2022 02:08:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/16/2022 02:08:31 - INFO - __main__ - Start tokenizing ... 3500 instances
03/16/2022 02:08:31 - INFO - __main__ - Printing 3 examples
03/16/2022 02:08:31 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/16/2022 02:08:31 - INFO - __main__ - ['Animal']
03/16/2022 02:08:31 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/16/2022 02:08:31 - INFO - __main__ - ['Animal']
03/16/2022 02:08:31 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/16/2022 02:08:31 - INFO - __main__ - ['Village']
03/16/2022 02:08:31 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:08:33 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:08:36 - INFO - __main__ - Loaded 3500 examples from test data
03/16/2022 02:08:41 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 02:08:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 02:08:42 - INFO - __main__ - Starting training!
03/16/2022 02:10:43 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
03/16/2022 02:10:43 - INFO - __main__ - Classification-F1 on test data: 0.5945
03/16/2022 02:10:43 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.98659405111018, test_performance=0.5945339623696411
03/16/2022 02:10:43 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
03/16/2022 02:10:44 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 02:10:44 - INFO - __main__ - Printing 3 examples
03/16/2022 02:10:44 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
03/16/2022 02:10:44 - INFO - __main__ - ['Company']
03/16/2022 02:10:44 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
03/16/2022 02:10:44 - INFO - __main__ - ['Company']
03/16/2022 02:10:44 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
03/16/2022 02:10:44 - INFO - __main__ - ['Company']
03/16/2022 02:10:44 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:10:44 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:10:44 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 02:10:44 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 02:10:44 - INFO - __main__ - Printing 3 examples
03/16/2022 02:10:44 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
03/16/2022 02:10:44 - INFO - __main__ - ['Company']
03/16/2022 02:10:44 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
03/16/2022 02:10:44 - INFO - __main__ - ['Company']
03/16/2022 02:10:44 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
03/16/2022 02:10:44 - INFO - __main__ - ['Company']
03/16/2022 02:10:44 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:10:45 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:10:45 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 02:11:00 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 02:11:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 02:11:01 - INFO - __main__ - Starting training!
03/16/2022 02:11:04 - INFO - __main__ - Step 10 Global step 10 Train loss 5.20 on epoch=0
03/16/2022 02:11:07 - INFO - __main__ - Step 20 Global step 20 Train loss 3.85 on epoch=1
03/16/2022 02:11:09 - INFO - __main__ - Step 30 Global step 30 Train loss 3.12 on epoch=2
03/16/2022 02:11:12 - INFO - __main__ - Step 40 Global step 40 Train loss 2.58 on epoch=2
03/16/2022 02:11:15 - INFO - __main__ - Step 50 Global step 50 Train loss 2.09 on epoch=3
03/16/2022 02:11:20 - INFO - __main__ - Global step 50 Train loss 3.37 Classification-F1 0.11897299048131094 on epoch=3
03/16/2022 02:11:20 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11897299048131094 on epoch=3, global_step=50
03/16/2022 02:11:22 - INFO - __main__ - Step 60 Global step 60 Train loss 1.87 on epoch=4
03/16/2022 02:11:25 - INFO - __main__ - Step 70 Global step 70 Train loss 1.65 on epoch=4
03/16/2022 02:11:27 - INFO - __main__ - Step 80 Global step 80 Train loss 1.26 on epoch=5
03/16/2022 02:11:30 - INFO - __main__ - Step 90 Global step 90 Train loss 1.34 on epoch=6
03/16/2022 02:11:33 - INFO - __main__ - Step 100 Global step 100 Train loss 1.14 on epoch=7
03/16/2022 02:11:39 - INFO - __main__ - Global step 100 Train loss 1.45 Classification-F1 0.33074144251013593 on epoch=7
03/16/2022 02:11:39 - INFO - __main__ - Saving model with best Classification-F1: 0.11897299048131094 -> 0.33074144251013593 on epoch=7, global_step=100
03/16/2022 02:11:41 - INFO - __main__ - Step 110 Global step 110 Train loss 0.98 on epoch=7
03/16/2022 02:11:44 - INFO - __main__ - Step 120 Global step 120 Train loss 0.88 on epoch=8
03/16/2022 02:11:47 - INFO - __main__ - Step 130 Global step 130 Train loss 0.83 on epoch=9
03/16/2022 02:11:49 - INFO - __main__ - Step 140 Global step 140 Train loss 0.99 on epoch=9
03/16/2022 02:11:52 - INFO - __main__ - Step 150 Global step 150 Train loss 0.75 on epoch=10
03/16/2022 02:11:58 - INFO - __main__ - Global step 150 Train loss 0.89 Classification-F1 0.5120971254684927 on epoch=10
03/16/2022 02:11:58 - INFO - __main__ - Saving model with best Classification-F1: 0.33074144251013593 -> 0.5120971254684927 on epoch=10, global_step=150
03/16/2022 02:12:01 - INFO - __main__ - Step 160 Global step 160 Train loss 0.69 on epoch=11
03/16/2022 02:12:03 - INFO - __main__ - Step 170 Global step 170 Train loss 0.77 on epoch=12
03/16/2022 02:12:06 - INFO - __main__ - Step 180 Global step 180 Train loss 0.71 on epoch=12
03/16/2022 02:12:08 - INFO - __main__ - Step 190 Global step 190 Train loss 0.61 on epoch=13
03/16/2022 02:12:11 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=14
03/16/2022 02:12:17 - INFO - __main__ - Global step 200 Train loss 0.67 Classification-F1 0.5373739560604708 on epoch=14
03/16/2022 02:12:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5120971254684927 -> 0.5373739560604708 on epoch=14, global_step=200
03/16/2022 02:12:20 - INFO - __main__ - Step 210 Global step 210 Train loss 0.70 on epoch=14
03/16/2022 02:12:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.57 on epoch=15
03/16/2022 02:12:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.60 on epoch=16
03/16/2022 02:12:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.56 on epoch=17
03/16/2022 02:12:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.54 on epoch=17
03/16/2022 02:12:37 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.5531413311921168 on epoch=17
03/16/2022 02:12:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5373739560604708 -> 0.5531413311921168 on epoch=17, global_step=250
03/16/2022 02:12:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.47 on epoch=18
03/16/2022 02:12:42 - INFO - __main__ - Step 270 Global step 270 Train loss 0.63 on epoch=19
03/16/2022 02:12:44 - INFO - __main__ - Step 280 Global step 280 Train loss 0.56 on epoch=19
03/16/2022 02:12:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.40 on epoch=20
03/16/2022 02:12:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.50 on epoch=21
03/16/2022 02:12:57 - INFO - __main__ - Global step 300 Train loss 0.51 Classification-F1 0.5754128453889393 on epoch=21
03/16/2022 02:12:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5531413311921168 -> 0.5754128453889393 on epoch=21, global_step=300
03/16/2022 02:12:59 - INFO - __main__ - Step 310 Global step 310 Train loss 0.51 on epoch=22
03/16/2022 02:13:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=22
03/16/2022 02:13:04 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=23
03/16/2022 02:13:07 - INFO - __main__ - Step 340 Global step 340 Train loss 0.53 on epoch=24
03/16/2022 02:13:09 - INFO - __main__ - Step 350 Global step 350 Train loss 0.47 on epoch=24
03/16/2022 02:13:16 - INFO - __main__ - Global step 350 Train loss 0.47 Classification-F1 0.6080419396902255 on epoch=24
03/16/2022 02:13:16 - INFO - __main__ - Saving model with best Classification-F1: 0.5754128453889393 -> 0.6080419396902255 on epoch=24, global_step=350
03/16/2022 02:13:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.39 on epoch=25
03/16/2022 02:13:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.39 on epoch=26
03/16/2022 02:13:24 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=27
03/16/2022 02:13:26 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=27
03/16/2022 02:13:29 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=28
03/16/2022 02:13:36 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.5686294459036765 on epoch=28
03/16/2022 02:13:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=29
03/16/2022 02:13:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.39 on epoch=29
03/16/2022 02:13:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=30
03/16/2022 02:13:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=31
03/16/2022 02:13:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.39 on epoch=32
03/16/2022 02:13:56 - INFO - __main__ - Global step 450 Train loss 0.36 Classification-F1 0.5980417794210898 on epoch=32
03/16/2022 02:13:58 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=32
03/16/2022 02:14:01 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=33
03/16/2022 02:14:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.32 on epoch=34
03/16/2022 02:14:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=34
03/16/2022 02:14:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=35
03/16/2022 02:14:15 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.600761735689433 on epoch=35
03/16/2022 02:14:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.34 on epoch=36
03/16/2022 02:14:20 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=37
03/16/2022 02:14:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=37
03/16/2022 02:14:26 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=38
03/16/2022 02:14:28 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=39
03/16/2022 02:14:35 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.5823839347648871 on epoch=39
03/16/2022 02:14:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.28 on epoch=39
03/16/2022 02:14:40 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=40
03/16/2022 02:14:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=41
03/16/2022 02:14:45 - INFO - __main__ - Step 590 Global step 590 Train loss 0.27 on epoch=42
03/16/2022 02:14:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=42
03/16/2022 02:14:55 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.5680865193384592 on epoch=42
03/16/2022 02:14:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.32 on epoch=43
03/16/2022 02:15:00 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=44
03/16/2022 02:15:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=44
03/16/2022 02:15:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.26 on epoch=45
03/16/2022 02:15:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=46
03/16/2022 02:15:14 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.7750433829346577 on epoch=46
03/16/2022 02:15:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6080419396902255 -> 0.7750433829346577 on epoch=46, global_step=650
03/16/2022 02:15:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.30 on epoch=47
03/16/2022 02:15:19 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=47
03/16/2022 02:15:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=48
03/16/2022 02:15:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=49
03/16/2022 02:15:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=49
03/16/2022 02:15:34 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.7405085197658207 on epoch=49
03/16/2022 02:15:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=50
03/16/2022 02:15:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=51
03/16/2022 02:15:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=52
03/16/2022 02:15:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.25 on epoch=52
03/16/2022 02:15:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.27 on epoch=53
03/16/2022 02:15:54 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.6893662447655188 on epoch=53
03/16/2022 02:15:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=54
03/16/2022 02:15:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=54
03/16/2022 02:16:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=55
03/16/2022 02:16:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=56
03/16/2022 02:16:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=57
03/16/2022 02:16:14 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.7720260208830844 on epoch=57
03/16/2022 02:16:17 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=57
03/16/2022 02:16:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=58
03/16/2022 02:16:22 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=59
03/16/2022 02:16:24 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=59
03/16/2022 02:16:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=60
03/16/2022 02:16:35 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.7262476213941532 on epoch=60
03/16/2022 02:16:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=61
03/16/2022 02:16:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.24 on epoch=62
03/16/2022 02:16:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=62
03/16/2022 02:16:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=63
03/16/2022 02:16:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=64
03/16/2022 02:16:55 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.7473910673020795 on epoch=64
03/16/2022 02:16:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=64
03/16/2022 02:17:00 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=65
03/16/2022 02:17:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=66
03/16/2022 02:17:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=67
03/16/2022 02:17:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=67
03/16/2022 02:17:15 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.8401670436552946 on epoch=67
03/16/2022 02:17:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7750433829346577 -> 0.8401670436552946 on epoch=67, global_step=950
03/16/2022 02:17:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=68
03/16/2022 02:17:21 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=69
03/16/2022 02:17:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=69
03/16/2022 02:17:26 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=70
03/16/2022 02:17:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=71
03/16/2022 02:17:36 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.7025137583286989 on epoch=71
03/16/2022 02:17:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
03/16/2022 02:17:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=72
03/16/2022 02:17:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=73
03/16/2022 02:17:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=74
03/16/2022 02:17:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=74
03/16/2022 02:17:56 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.720401262211607 on epoch=74
03/16/2022 02:17:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
03/16/2022 02:18:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=76
03/16/2022 02:18:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=77
03/16/2022 02:18:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=77
03/16/2022 02:18:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
03/16/2022 02:18:17 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.8466279125286478 on epoch=78
03/16/2022 02:18:17 - INFO - __main__ - Saving model with best Classification-F1: 0.8401670436552946 -> 0.8466279125286478 on epoch=78, global_step=1100
03/16/2022 02:18:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
03/16/2022 02:18:22 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=79
03/16/2022 02:18:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
03/16/2022 02:18:27 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=81
03/16/2022 02:18:29 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=82
03/16/2022 02:18:37 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.8552006964809384 on epoch=82
03/16/2022 02:18:37 - INFO - __main__ - Saving model with best Classification-F1: 0.8466279125286478 -> 0.8552006964809384 on epoch=82, global_step=1150
03/16/2022 02:18:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=82
03/16/2022 02:18:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=83
03/16/2022 02:18:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=84
03/16/2022 02:18:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=84
03/16/2022 02:18:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=85
03/16/2022 02:18:57 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.799425624139599 on epoch=85
03/16/2022 02:19:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=86
03/16/2022 02:19:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=87
03/16/2022 02:19:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
03/16/2022 02:19:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=88
03/16/2022 02:19:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=89
03/16/2022 02:19:18 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.7528501924190761 on epoch=89
03/16/2022 02:19:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=89
03/16/2022 02:19:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=90
03/16/2022 02:19:25 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=91
03/16/2022 02:19:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=92
03/16/2022 02:19:30 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=92
03/16/2022 02:19:38 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.9821341293115486 on epoch=92
03/16/2022 02:19:38 - INFO - __main__ - Saving model with best Classification-F1: 0.8552006964809384 -> 0.9821341293115486 on epoch=92, global_step=1300
03/16/2022 02:19:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
03/16/2022 02:19:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
03/16/2022 02:19:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
03/16/2022 02:19:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=95
03/16/2022 02:19:51 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
03/16/2022 02:19:59 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.9186705767350929 on epoch=96
03/16/2022 02:20:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=97
03/16/2022 02:20:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.11 on epoch=97
03/16/2022 02:20:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
03/16/2022 02:20:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=99
03/16/2022 02:20:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
03/16/2022 02:20:19 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.8027311490882125 on epoch=99
03/16/2022 02:20:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
03/16/2022 02:20:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=101
03/16/2022 02:20:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
03/16/2022 02:20:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=102
03/16/2022 02:20:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
03/16/2022 02:20:40 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.9776654796816088 on epoch=103
03/16/2022 02:20:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
03/16/2022 02:20:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=104
03/16/2022 02:20:47 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
03/16/2022 02:20:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=106
03/16/2022 02:20:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=107
03/16/2022 02:21:00 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.9018942979490647 on epoch=107
03/16/2022 02:21:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
03/16/2022 02:21:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
03/16/2022 02:21:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
03/16/2022 02:21:10 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
03/16/2022 02:21:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=110
03/16/2022 02:21:21 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.9821341293115486 on epoch=110
03/16/2022 02:21:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=111
03/16/2022 02:21:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=112
03/16/2022 02:21:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
03/16/2022 02:21:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
03/16/2022 02:21:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
03/16/2022 02:21:41 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.9730432202206395 on epoch=114
03/16/2022 02:21:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=114
03/16/2022 02:21:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
03/16/2022 02:21:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
03/16/2022 02:21:51 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
03/16/2022 02:21:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
03/16/2022 02:22:01 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.8393373777802657 on epoch=117
03/16/2022 02:22:04 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
03/16/2022 02:22:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=119
03/16/2022 02:22:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=119
03/16/2022 02:22:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=120
03/16/2022 02:22:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
03/16/2022 02:22:22 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.973201193967323 on epoch=121
03/16/2022 02:22:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
03/16/2022 02:22:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
03/16/2022 02:22:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=123
03/16/2022 02:22:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
03/16/2022 02:22:34 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
03/16/2022 02:22:42 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.9145079830563703 on epoch=124
03/16/2022 02:22:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
03/16/2022 02:22:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
03/16/2022 02:22:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
03/16/2022 02:22:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
03/16/2022 02:22:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
03/16/2022 02:23:03 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.9865940511101802 on epoch=128
03/16/2022 02:23:03 - INFO - __main__ - Saving model with best Classification-F1: 0.9821341293115486 -> 0.9865940511101802 on epoch=128, global_step=1800
03/16/2022 02:23:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
03/16/2022 02:23:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
03/16/2022 02:23:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
03/16/2022 02:23:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
03/16/2022 02:23:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
03/16/2022 02:23:23 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.8505609813573523 on epoch=132
03/16/2022 02:23:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
03/16/2022 02:23:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
03/16/2022 02:23:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
03/16/2022 02:23:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=134
03/16/2022 02:23:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
03/16/2022 02:23:44 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.9730475841362937 on epoch=135
03/16/2022 02:23:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
03/16/2022 02:23:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
03/16/2022 02:23:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
03/16/2022 02:23:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
03/16/2022 02:23:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
03/16/2022 02:24:04 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.9821341293115486 on epoch=139
03/16/2022 02:24:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
03/16/2022 02:24:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
03/16/2022 02:24:12 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
03/16/2022 02:24:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
03/16/2022 02:24:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
03/16/2022 02:24:24 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.8510117249384839 on epoch=142
03/16/2022 02:24:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
03/16/2022 02:24:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=144
03/16/2022 02:24:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
03/16/2022 02:24:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
03/16/2022 02:24:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=146
03/16/2022 02:24:45 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.9100070670058564 on epoch=146
03/16/2022 02:24:48 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
03/16/2022 02:24:50 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
03/16/2022 02:24:53 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
03/16/2022 02:24:55 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
03/16/2022 02:24:58 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
03/16/2022 02:25:05 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9098963775687914 on epoch=149
03/16/2022 02:25:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
03/16/2022 02:25:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
03/16/2022 02:25:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=152
03/16/2022 02:25:15 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
03/16/2022 02:25:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=153
03/16/2022 02:25:25 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.9098963775687914 on epoch=153
03/16/2022 02:25:28 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
03/16/2022 02:25:30 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
03/16/2022 02:25:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
03/16/2022 02:25:35 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=156
03/16/2022 02:25:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=157
03/16/2022 02:25:46 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.914058971247514 on epoch=157
03/16/2022 02:25:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
03/16/2022 02:25:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
03/16/2022 02:25:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=159
03/16/2022 02:25:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
03/16/2022 02:25:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
03/16/2022 02:26:06 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9775162337662338 on epoch=160
03/16/2022 02:26:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
03/16/2022 02:26:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
03/16/2022 02:26:13 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
03/16/2022 02:26:16 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
03/16/2022 02:26:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
03/16/2022 02:26:26 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.914058971247514 on epoch=164
03/16/2022 02:26:28 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
03/16/2022 02:26:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
03/16/2022 02:26:33 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
03/16/2022 02:26:36 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
03/16/2022 02:26:38 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
03/16/2022 02:26:46 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9819761555648652 on epoch=167
03/16/2022 02:26:48 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
03/16/2022 02:26:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
03/16/2022 02:26:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
03/16/2022 02:26:56 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
03/16/2022 02:26:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
03/16/2022 02:27:05 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9143646138807429 on epoch=171
03/16/2022 02:27:08 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
03/16/2022 02:27:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
03/16/2022 02:27:13 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
03/16/2022 02:27:16 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
03/16/2022 02:27:18 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
03/16/2022 02:27:26 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9057256379141807 on epoch=174
03/16/2022 02:27:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
03/16/2022 02:27:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=176
03/16/2022 02:27:34 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
03/16/2022 02:27:36 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
03/16/2022 02:27:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
03/16/2022 02:27:46 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9098963775687914 on epoch=178
03/16/2022 02:27:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
03/16/2022 02:27:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
03/16/2022 02:27:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
03/16/2022 02:27:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
03/16/2022 02:27:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
03/16/2022 02:28:06 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9057256379141807 on epoch=182
03/16/2022 02:28:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
03/16/2022 02:28:11 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
03/16/2022 02:28:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=184
03/16/2022 02:28:16 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
03/16/2022 02:28:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
03/16/2022 02:28:26 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9775162337662338 on epoch=185
03/16/2022 02:28:28 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
03/16/2022 02:28:31 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
03/16/2022 02:28:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
03/16/2022 02:28:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
03/16/2022 02:28:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
03/16/2022 02:28:45 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9821341293115486 on epoch=189
03/16/2022 02:28:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
03/16/2022 02:28:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
03/16/2022 02:28:53 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
03/16/2022 02:28:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/16/2022 02:28:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
03/16/2022 02:29:05 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9775075059349252 on epoch=192
03/16/2022 02:29:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
03/16/2022 02:29:10 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
03/16/2022 02:29:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
03/16/2022 02:29:15 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
03/16/2022 02:29:18 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
03/16/2022 02:29:25 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9775075059349252 on epoch=196
03/16/2022 02:29:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
03/16/2022 02:29:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
03/16/2022 02:29:32 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
03/16/2022 02:29:35 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
03/16/2022 02:29:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
03/16/2022 02:29:45 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9730475841362939 on epoch=199
03/16/2022 02:29:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
03/16/2022 02:29:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
03/16/2022 02:29:52 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
03/16/2022 02:29:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
03/16/2022 02:29:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
03/16/2022 02:30:05 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9098963775687914 on epoch=203
03/16/2022 02:30:07 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
03/16/2022 02:30:10 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
03/16/2022 02:30:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
03/16/2022 02:30:15 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
03/16/2022 02:30:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
03/16/2022 02:30:25 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9775118698505795 on epoch=207
03/16/2022 02:30:27 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
03/16/2022 02:30:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
03/16/2022 02:30:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
03/16/2022 02:30:35 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
03/16/2022 02:30:37 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
03/16/2022 02:30:44 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.912066634082763 on epoch=210
03/16/2022 02:30:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
03/16/2022 02:30:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
03/16/2022 02:30:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=212
03/16/2022 02:30:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
03/16/2022 02:30:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
03/16/2022 02:30:58 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 02:30:58 - INFO - __main__ - Printing 3 examples
03/16/2022 02:30:58 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
03/16/2022 02:30:58 - INFO - __main__ - ['Film']
03/16/2022 02:30:58 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
03/16/2022 02:30:58 - INFO - __main__ - ['Film']
03/16/2022 02:30:58 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
03/16/2022 02:30:58 - INFO - __main__ - ['Film']
03/16/2022 02:30:58 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:30:58 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:30:59 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 02:30:59 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 02:30:59 - INFO - __main__ - Printing 3 examples
03/16/2022 02:30:59 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
03/16/2022 02:30:59 - INFO - __main__ - ['Film']
03/16/2022 02:30:59 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
03/16/2022 02:30:59 - INFO - __main__ - ['Film']
03/16/2022 02:30:59 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
03/16/2022 02:30:59 - INFO - __main__ - ['Film']
03/16/2022 02:30:59 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:30:59 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:30:59 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 02:31:04 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9775162337662338 on epoch=214
03/16/2022 02:31:04 - INFO - __main__ - save last model!
03/16/2022 02:31:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/16/2022 02:31:04 - INFO - __main__ - Start tokenizing ... 3500 instances
03/16/2022 02:31:04 - INFO - __main__ - Printing 3 examples
03/16/2022 02:31:04 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/16/2022 02:31:04 - INFO - __main__ - ['Animal']
03/16/2022 02:31:04 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/16/2022 02:31:04 - INFO - __main__ - ['Animal']
03/16/2022 02:31:04 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/16/2022 02:31:04 - INFO - __main__ - ['Village']
03/16/2022 02:31:04 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:31:06 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:31:10 - INFO - __main__ - Loaded 3500 examples from test data
03/16/2022 02:31:14 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 02:31:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 02:31:15 - INFO - __main__ - Starting training!
03/16/2022 02:33:21 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
03/16/2022 02:33:21 - INFO - __main__ - Classification-F1 on test data: 0.7210
03/16/2022 02:33:22 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.9865940511101802, test_performance=0.7210320141901686
03/16/2022 02:33:22 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
03/16/2022 02:33:23 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 02:33:23 - INFO - __main__ - Printing 3 examples
03/16/2022 02:33:23 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
03/16/2022 02:33:23 - INFO - __main__ - ['Film']
03/16/2022 02:33:23 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
03/16/2022 02:33:23 - INFO - __main__ - ['Film']
03/16/2022 02:33:23 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
03/16/2022 02:33:23 - INFO - __main__ - ['Film']
03/16/2022 02:33:23 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:33:23 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:33:23 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 02:33:23 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 02:33:23 - INFO - __main__ - Printing 3 examples
03/16/2022 02:33:23 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
03/16/2022 02:33:23 - INFO - __main__ - ['Film']
03/16/2022 02:33:23 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
03/16/2022 02:33:23 - INFO - __main__ - ['Film']
03/16/2022 02:33:23 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
03/16/2022 02:33:23 - INFO - __main__ - ['Film']
03/16/2022 02:33:23 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:33:23 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:33:23 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 02:33:42 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 02:33:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 02:33:43 - INFO - __main__ - Starting training!
03/16/2022 02:33:46 - INFO - __main__ - Step 10 Global step 10 Train loss 4.54 on epoch=0
03/16/2022 02:33:50 - INFO - __main__ - Step 20 Global step 20 Train loss 2.76 on epoch=1
03/16/2022 02:33:53 - INFO - __main__ - Step 30 Global step 30 Train loss 2.00 on epoch=2
03/16/2022 02:33:55 - INFO - __main__ - Step 40 Global step 40 Train loss 1.45 on epoch=2
03/16/2022 02:33:58 - INFO - __main__ - Step 50 Global step 50 Train loss 1.14 on epoch=3
03/16/2022 02:34:05 - INFO - __main__ - Global step 50 Train loss 2.38 Classification-F1 0.3487845655911342 on epoch=3
03/16/2022 02:34:05 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3487845655911342 on epoch=3, global_step=50
03/16/2022 02:34:07 - INFO - __main__ - Step 60 Global step 60 Train loss 1.00 on epoch=4
03/16/2022 02:34:10 - INFO - __main__ - Step 70 Global step 70 Train loss 0.81 on epoch=4
03/16/2022 02:34:12 - INFO - __main__ - Step 80 Global step 80 Train loss 0.70 on epoch=5
03/16/2022 02:34:15 - INFO - __main__ - Step 90 Global step 90 Train loss 0.68 on epoch=6
03/16/2022 02:34:17 - INFO - __main__ - Step 100 Global step 100 Train loss 0.65 on epoch=7
03/16/2022 02:34:25 - INFO - __main__ - Global step 100 Train loss 0.77 Classification-F1 0.6170689940002334 on epoch=7
03/16/2022 02:34:25 - INFO - __main__ - Saving model with best Classification-F1: 0.3487845655911342 -> 0.6170689940002334 on epoch=7, global_step=100
03/16/2022 02:34:27 - INFO - __main__ - Step 110 Global step 110 Train loss 0.59 on epoch=7
03/16/2022 02:34:30 - INFO - __main__ - Step 120 Global step 120 Train loss 0.55 on epoch=8
03/16/2022 02:34:32 - INFO - __main__ - Step 130 Global step 130 Train loss 0.48 on epoch=9
03/16/2022 02:34:35 - INFO - __main__ - Step 140 Global step 140 Train loss 0.48 on epoch=9
03/16/2022 02:34:37 - INFO - __main__ - Step 150 Global step 150 Train loss 0.44 on epoch=10
03/16/2022 02:34:44 - INFO - __main__ - Global step 150 Train loss 0.51 Classification-F1 0.6934459654134293 on epoch=10
03/16/2022 02:34:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6170689940002334 -> 0.6934459654134293 on epoch=10, global_step=150
03/16/2022 02:34:46 - INFO - __main__ - Step 160 Global step 160 Train loss 0.46 on epoch=11
03/16/2022 02:34:49 - INFO - __main__ - Step 170 Global step 170 Train loss 0.50 on epoch=12
03/16/2022 02:34:51 - INFO - __main__ - Step 180 Global step 180 Train loss 0.36 on epoch=12
03/16/2022 02:34:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.39 on epoch=13
03/16/2022 02:34:56 - INFO - __main__ - Step 200 Global step 200 Train loss 0.35 on epoch=14
03/16/2022 02:35:03 - INFO - __main__ - Global step 200 Train loss 0.41 Classification-F1 0.8118728363889655 on epoch=14
03/16/2022 02:35:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6934459654134293 -> 0.8118728363889655 on epoch=14, global_step=200
03/16/2022 02:35:06 - INFO - __main__ - Step 210 Global step 210 Train loss 0.34 on epoch=14
03/16/2022 02:35:08 - INFO - __main__ - Step 220 Global step 220 Train loss 0.30 on epoch=15
03/16/2022 02:35:11 - INFO - __main__ - Step 230 Global step 230 Train loss 0.31 on epoch=16
03/16/2022 02:35:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.29 on epoch=17
03/16/2022 02:35:16 - INFO - __main__ - Step 250 Global step 250 Train loss 0.31 on epoch=17
03/16/2022 02:35:23 - INFO - __main__ - Global step 250 Train loss 0.31 Classification-F1 0.8215581798355412 on epoch=17
03/16/2022 02:35:23 - INFO - __main__ - Saving model with best Classification-F1: 0.8118728363889655 -> 0.8215581798355412 on epoch=17, global_step=250
03/16/2022 02:35:25 - INFO - __main__ - Step 260 Global step 260 Train loss 0.30 on epoch=18
03/16/2022 02:35:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.31 on epoch=19
03/16/2022 02:35:31 - INFO - __main__ - Step 280 Global step 280 Train loss 0.24 on epoch=19
03/16/2022 02:35:33 - INFO - __main__ - Step 290 Global step 290 Train loss 0.26 on epoch=20
03/16/2022 02:35:36 - INFO - __main__ - Step 300 Global step 300 Train loss 0.19 on epoch=21
03/16/2022 02:35:43 - INFO - __main__ - Global step 300 Train loss 0.26 Classification-F1 0.7345047794288782 on epoch=21
03/16/2022 02:35:45 - INFO - __main__ - Step 310 Global step 310 Train loss 0.20 on epoch=22
03/16/2022 02:35:48 - INFO - __main__ - Step 320 Global step 320 Train loss 0.18 on epoch=22
03/16/2022 02:35:50 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=23
03/16/2022 02:35:53 - INFO - __main__ - Step 340 Global step 340 Train loss 0.18 on epoch=24
03/16/2022 02:35:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.22 on epoch=24
03/16/2022 02:36:02 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.7797267148099944 on epoch=24
03/16/2022 02:36:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=25
03/16/2022 02:36:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.18 on epoch=26
03/16/2022 02:36:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.14 on epoch=27
03/16/2022 02:36:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.11 on epoch=27
03/16/2022 02:36:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=28
03/16/2022 02:36:21 - INFO - __main__ - Global step 400 Train loss 0.17 Classification-F1 0.8188496191328822 on epoch=28
03/16/2022 02:36:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.13 on epoch=29
03/16/2022 02:36:26 - INFO - __main__ - Step 420 Global step 420 Train loss 0.18 on epoch=29
03/16/2022 02:36:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.10 on epoch=30
03/16/2022 02:36:31 - INFO - __main__ - Step 440 Global step 440 Train loss 0.18 on epoch=31
03/16/2022 02:36:34 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=32
03/16/2022 02:36:41 - INFO - __main__ - Global step 450 Train loss 0.15 Classification-F1 0.9731494944018664 on epoch=32
03/16/2022 02:36:41 - INFO - __main__ - Saving model with best Classification-F1: 0.8215581798355412 -> 0.9731494944018664 on epoch=32, global_step=450
03/16/2022 02:36:44 - INFO - __main__ - Step 460 Global step 460 Train loss 0.08 on epoch=32
03/16/2022 02:36:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.07 on epoch=33
03/16/2022 02:36:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.08 on epoch=34
03/16/2022 02:36:51 - INFO - __main__ - Step 490 Global step 490 Train loss 0.12 on epoch=34
03/16/2022 02:36:54 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=35
03/16/2022 02:37:00 - INFO - __main__ - Global step 500 Train loss 0.08 Classification-F1 0.9538064086451185 on epoch=35
03/16/2022 02:37:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=36
03/16/2022 02:37:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=37
03/16/2022 02:37:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=37
03/16/2022 02:37:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.04 on epoch=38
03/16/2022 02:37:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.08 on epoch=39
03/16/2022 02:37:20 - INFO - __main__ - Global step 550 Train loss 0.08 Classification-F1 0.9822527251369758 on epoch=39
03/16/2022 02:37:20 - INFO - __main__ - Saving model with best Classification-F1: 0.9731494944018664 -> 0.9822527251369758 on epoch=39, global_step=550
03/16/2022 02:37:22 - INFO - __main__ - Step 560 Global step 560 Train loss 0.11 on epoch=39
03/16/2022 02:37:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=40
03/16/2022 02:37:27 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=41
03/16/2022 02:37:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.07 on epoch=42
03/16/2022 02:37:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=42
03/16/2022 02:37:39 - INFO - __main__ - Global step 600 Train loss 0.08 Classification-F1 0.9687098519759809 on epoch=42
03/16/2022 02:37:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=43
03/16/2022 02:37:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=44
03/16/2022 02:37:47 - INFO - __main__ - Step 630 Global step 630 Train loss 0.07 on epoch=44
03/16/2022 02:37:49 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=45
03/16/2022 02:37:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=46
03/16/2022 02:37:59 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.9058077206006279 on epoch=46
03/16/2022 02:38:01 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=47
03/16/2022 02:38:04 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=47
03/16/2022 02:38:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=48
03/16/2022 02:38:09 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=49
03/16/2022 02:38:11 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=49
03/16/2022 02:38:18 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.9821254014802404 on epoch=49
03/16/2022 02:38:20 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=50
03/16/2022 02:38:23 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=51
03/16/2022 02:38:25 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=52
03/16/2022 02:38:28 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
03/16/2022 02:38:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=53
03/16/2022 02:38:37 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.9821254014802404 on epoch=53
03/16/2022 02:38:39 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=54
03/16/2022 02:38:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=54
03/16/2022 02:38:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=55
03/16/2022 02:38:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=56
03/16/2022 02:38:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=57
03/16/2022 02:38:56 - INFO - __main__ - Global step 800 Train loss 0.04 Classification-F1 0.986440441279151 on epoch=57
03/16/2022 02:38:56 - INFO - __main__ - Saving model with best Classification-F1: 0.9822527251369758 -> 0.986440441279151 on epoch=57, global_step=800
03/16/2022 02:38:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=57
03/16/2022 02:39:01 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=58
03/16/2022 02:39:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=59
03/16/2022 02:39:06 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=59
03/16/2022 02:39:09 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=60
03/16/2022 02:39:15 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.9771800316850372 on epoch=60
03/16/2022 02:39:18 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=61
03/16/2022 02:39:20 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=62
03/16/2022 02:39:23 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=62
03/16/2022 02:39:25 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=63
03/16/2022 02:39:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=64
03/16/2022 02:39:34 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.9776611157659545 on epoch=64
03/16/2022 02:39:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=64
03/16/2022 02:39:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=65
03/16/2022 02:39:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=66
03/16/2022 02:39:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=67
03/16/2022 02:39:47 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=67
03/16/2022 02:39:53 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.9822527251369758 on epoch=67
03/16/2022 02:39:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=68
03/16/2022 02:39:58 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=69
03/16/2022 02:40:01 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=69
03/16/2022 02:40:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=70
03/16/2022 02:40:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
03/16/2022 02:40:12 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.9688204900728622 on epoch=71
03/16/2022 02:40:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=72
03/16/2022 02:40:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=72
03/16/2022 02:40:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=73
03/16/2022 02:40:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
03/16/2022 02:40:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
03/16/2022 02:40:31 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.9642089781609885 on epoch=74
03/16/2022 02:40:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=75
03/16/2022 02:40:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=76
03/16/2022 02:40:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=77
03/16/2022 02:40:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=77
03/16/2022 02:40:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=78
03/16/2022 02:40:50 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.9776567518503005 on epoch=78
03/16/2022 02:40:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=79
03/16/2022 02:40:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=79
03/16/2022 02:40:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=80
03/16/2022 02:41:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=81
03/16/2022 02:41:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=82
03/16/2022 02:41:09 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.9821254014802404 on epoch=82
03/16/2022 02:41:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=82
03/16/2022 02:41:14 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=83
03/16/2022 02:41:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=84
03/16/2022 02:41:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=84
03/16/2022 02:41:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=85
03/16/2022 02:41:28 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.9821254014802404 on epoch=85
03/16/2022 02:41:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
03/16/2022 02:41:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=87
03/16/2022 02:41:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
03/16/2022 02:41:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=88
03/16/2022 02:41:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=89
03/16/2022 02:41:47 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.8472092462857324 on epoch=89
03/16/2022 02:41:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
03/16/2022 02:41:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
03/16/2022 02:41:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=91
03/16/2022 02:41:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=92
03/16/2022 02:42:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=92
03/16/2022 02:42:06 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.9644419644690723 on epoch=92
03/16/2022 02:42:09 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=93
03/16/2022 02:42:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
03/16/2022 02:42:14 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=94
03/16/2022 02:42:17 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=95
03/16/2022 02:42:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
03/16/2022 02:42:26 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.9776567518503005 on epoch=96
03/16/2022 02:42:28 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=97
03/16/2022 02:42:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=97
03/16/2022 02:42:33 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=98
03/16/2022 02:42:36 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=99
03/16/2022 02:42:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=99
03/16/2022 02:42:45 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.9733154258770959 on epoch=99
03/16/2022 02:42:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
03/16/2022 02:42:50 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
03/16/2022 02:42:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=102
03/16/2022 02:42:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=102
03/16/2022 02:42:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
03/16/2022 02:43:04 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.9776611157659545 on epoch=103
03/16/2022 02:43:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
03/16/2022 02:43:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
03/16/2022 02:43:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
03/16/2022 02:43:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
03/16/2022 02:43:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=107
03/16/2022 02:43:23 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.9821254014802402 on epoch=107
03/16/2022 02:43:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=107
03/16/2022 02:43:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=108
03/16/2022 02:43:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
03/16/2022 02:43:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
03/16/2022 02:43:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
03/16/2022 02:43:42 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.9777840755070358 on epoch=110
03/16/2022 02:43:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=111
03/16/2022 02:43:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=112
03/16/2022 02:43:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
03/16/2022 02:43:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=113
03/16/2022 02:43:54 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
03/16/2022 02:44:01 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.9821254014802402 on epoch=114
03/16/2022 02:44:03 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
03/16/2022 02:44:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
03/16/2022 02:44:08 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
03/16/2022 02:44:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
03/16/2022 02:44:13 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
03/16/2022 02:44:20 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.9777840755070356 on epoch=117
03/16/2022 02:44:23 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=118
03/16/2022 02:44:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
03/16/2022 02:44:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
03/16/2022 02:44:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=120
03/16/2022 02:44:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=121
03/16/2022 02:44:40 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.968613789939072 on epoch=121
03/16/2022 02:44:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=122
03/16/2022 02:44:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
03/16/2022 02:44:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=123
03/16/2022 02:44:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=124
03/16/2022 02:44:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=124
03/16/2022 02:44:59 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.9730082062150374 on epoch=124
03/16/2022 02:45:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
03/16/2022 02:45:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
03/16/2022 02:45:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=127
03/16/2022 02:45:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
03/16/2022 02:45:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
03/16/2022 02:45:18 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.9103045636631976 on epoch=128
03/16/2022 02:45:20 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
03/16/2022 02:45:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
03/16/2022 02:45:25 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=130
03/16/2022 02:45:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
03/16/2022 02:45:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
03/16/2022 02:45:37 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9776567518503005 on epoch=132
03/16/2022 02:45:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
03/16/2022 02:45:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
03/16/2022 02:45:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
03/16/2022 02:45:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
03/16/2022 02:45:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=135
03/16/2022 02:45:56 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9776567518503005 on epoch=135
03/16/2022 02:45:58 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
03/16/2022 02:46:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
03/16/2022 02:46:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
03/16/2022 02:46:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=138
03/16/2022 02:46:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
03/16/2022 02:46:15 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.906166503747149 on epoch=139
03/16/2022 02:46:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=139
03/16/2022 02:46:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
03/16/2022 02:46:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
03/16/2022 02:46:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
03/16/2022 02:46:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=142
03/16/2022 02:46:34 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.9776567518503002 on epoch=142
03/16/2022 02:46:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=143
03/16/2022 02:46:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
03/16/2022 02:46:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
03/16/2022 02:46:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
03/16/2022 02:46:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
03/16/2022 02:46:54 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.9733197897927501 on epoch=146
03/16/2022 02:46:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
03/16/2022 02:46:59 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
03/16/2022 02:47:01 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=148
03/16/2022 02:47:04 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
03/16/2022 02:47:06 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=149
03/16/2022 02:47:13 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9641232180504927 on epoch=149
03/16/2022 02:47:15 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
03/16/2022 02:47:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
03/16/2022 02:47:20 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
03/16/2022 02:47:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
03/16/2022 02:47:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
03/16/2022 02:47:32 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9775075059349254 on epoch=153
03/16/2022 02:47:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=154
03/16/2022 02:47:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=154
03/16/2022 02:47:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
03/16/2022 02:47:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=156
03/16/2022 02:47:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
03/16/2022 02:47:51 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9775075059349254 on epoch=157
03/16/2022 02:47:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
03/16/2022 02:47:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
03/16/2022 02:47:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
03/16/2022 02:48:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
03/16/2022 02:48:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
03/16/2022 02:48:09 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9686137899390721 on epoch=160
03/16/2022 02:48:12 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
03/16/2022 02:48:15 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
03/16/2022 02:48:17 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=162
03/16/2022 02:48:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
03/16/2022 02:48:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
03/16/2022 02:48:28 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9639891758267335 on epoch=164
03/16/2022 02:48:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
03/16/2022 02:48:33 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
03/16/2022 02:48:36 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=166
03/16/2022 02:48:38 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
03/16/2022 02:48:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
03/16/2022 02:48:47 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9103290974258716 on epoch=167
03/16/2022 02:48:50 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
03/16/2022 02:48:52 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
03/16/2022 02:48:55 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
03/16/2022 02:48:57 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
03/16/2022 02:49:00 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
03/16/2022 02:49:06 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9776304656760065 on epoch=171
03/16/2022 02:49:09 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
03/16/2022 02:49:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
03/16/2022 02:49:14 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
03/16/2022 02:49:16 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
03/16/2022 02:49:19 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
03/16/2022 02:49:26 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.9821254014802402 on epoch=174
03/16/2022 02:49:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
03/16/2022 02:49:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
03/16/2022 02:49:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
03/16/2022 02:49:36 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
03/16/2022 02:49:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
03/16/2022 02:49:45 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9821254014802402 on epoch=178
03/16/2022 02:49:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
03/16/2022 02:49:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
03/16/2022 02:49:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
03/16/2022 02:49:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
03/16/2022 02:49:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
03/16/2022 02:50:04 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.9734055499032459 on epoch=182
03/16/2022 02:50:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
03/16/2022 02:50:09 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
03/16/2022 02:50:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=184
03/16/2022 02:50:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
03/16/2022 02:50:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
03/16/2022 02:50:23 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9777840755070358 on epoch=185
03/16/2022 02:50:26 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
03/16/2022 02:50:28 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
03/16/2022 02:50:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
03/16/2022 02:50:33 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
03/16/2022 02:50:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
03/16/2022 02:50:42 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9733154258770959 on epoch=189
03/16/2022 02:50:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
03/16/2022 02:50:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
03/16/2022 02:50:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=191
03/16/2022 02:50:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/16/2022 02:50:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
03/16/2022 02:51:01 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9187894121480461 on epoch=192
03/16/2022 02:51:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
03/16/2022 02:51:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
03/16/2022 02:51:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
03/16/2022 02:51:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
03/16/2022 02:51:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
03/16/2022 02:51:20 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.8408843449403222 on epoch=196
03/16/2022 02:51:22 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
03/16/2022 02:51:25 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
03/16/2022 02:51:27 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
03/16/2022 02:51:30 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
03/16/2022 02:51:32 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
03/16/2022 02:51:39 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.972843069627487 on epoch=199
03/16/2022 02:51:41 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
03/16/2022 02:51:44 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
03/16/2022 02:51:46 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
03/16/2022 02:51:49 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
03/16/2022 02:51:51 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
03/16/2022 02:51:57 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9147027882511752 on epoch=203
03/16/2022 02:52:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
03/16/2022 02:52:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
03/16/2022 02:52:05 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
03/16/2022 02:52:08 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
03/16/2022 02:52:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
03/16/2022 02:52:16 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.9775075059349254 on epoch=207
03/16/2022 02:52:19 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
03/16/2022 02:52:22 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
03/16/2022 02:52:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
03/16/2022 02:52:27 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
03/16/2022 02:52:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
03/16/2022 02:52:36 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.9730868034846664 on epoch=210
03/16/2022 02:52:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
03/16/2022 02:52:41 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
03/16/2022 02:52:43 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
03/16/2022 02:52:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
03/16/2022 02:52:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
03/16/2022 02:52:51 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 02:52:51 - INFO - __main__ - Printing 3 examples
03/16/2022 02:52:51 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
03/16/2022 02:52:51 - INFO - __main__ - ['Film']
03/16/2022 02:52:51 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
03/16/2022 02:52:51 - INFO - __main__ - ['Film']
03/16/2022 02:52:51 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
03/16/2022 02:52:51 - INFO - __main__ - ['Film']
03/16/2022 02:52:51 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:52:51 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:52:51 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 02:52:51 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 02:52:51 - INFO - __main__ - Printing 3 examples
03/16/2022 02:52:51 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
03/16/2022 02:52:51 - INFO - __main__ - ['Film']
03/16/2022 02:52:51 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
03/16/2022 02:52:51 - INFO - __main__ - ['Film']
03/16/2022 02:52:51 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
03/16/2022 02:52:51 - INFO - __main__ - ['Film']
03/16/2022 02:52:51 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:52:51 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:52:51 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 02:52:55 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.9143564679048549 on epoch=214
03/16/2022 02:52:55 - INFO - __main__ - save last model!
03/16/2022 02:52:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/16/2022 02:52:55 - INFO - __main__ - Start tokenizing ... 3500 instances
03/16/2022 02:52:55 - INFO - __main__ - Printing 3 examples
03/16/2022 02:52:55 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/16/2022 02:52:55 - INFO - __main__ - ['Animal']
03/16/2022 02:52:55 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/16/2022 02:52:55 - INFO - __main__ - ['Animal']
03/16/2022 02:52:55 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/16/2022 02:52:55 - INFO - __main__ - ['Village']
03/16/2022 02:52:55 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:52:57 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:53:00 - INFO - __main__ - Loaded 3500 examples from test data
03/16/2022 02:53:07 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 02:53:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 02:53:07 - INFO - __main__ - Starting training!
03/16/2022 02:55:06 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
03/16/2022 02:55:06 - INFO - __main__ - Classification-F1 on test data: 0.6492
03/16/2022 02:55:07 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.986440441279151, test_performance=0.6491763668891986
03/16/2022 02:55:07 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
03/16/2022 02:55:08 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 02:55:08 - INFO - __main__ - Printing 3 examples
03/16/2022 02:55:08 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
03/16/2022 02:55:08 - INFO - __main__ - ['Film']
03/16/2022 02:55:08 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
03/16/2022 02:55:08 - INFO - __main__ - ['Film']
03/16/2022 02:55:08 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
03/16/2022 02:55:08 - INFO - __main__ - ['Film']
03/16/2022 02:55:08 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:55:08 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:55:08 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 02:55:08 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 02:55:08 - INFO - __main__ - Printing 3 examples
03/16/2022 02:55:08 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
03/16/2022 02:55:08 - INFO - __main__ - ['Film']
03/16/2022 02:55:08 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
03/16/2022 02:55:08 - INFO - __main__ - ['Film']
03/16/2022 02:55:08 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
03/16/2022 02:55:08 - INFO - __main__ - ['Film']
03/16/2022 02:55:08 - INFO - __main__ - Tokenizing Input ...
03/16/2022 02:55:08 - INFO - __main__ - Tokenizing Output ...
03/16/2022 02:55:08 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 02:55:27 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 02:55:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 02:55:28 - INFO - __main__ - Starting training!
03/16/2022 02:55:31 - INFO - __main__ - Step 10 Global step 10 Train loss 4.58 on epoch=0
03/16/2022 02:55:34 - INFO - __main__ - Step 20 Global step 20 Train loss 2.88 on epoch=1
03/16/2022 02:55:37 - INFO - __main__ - Step 30 Global step 30 Train loss 2.05 on epoch=2
03/16/2022 02:55:39 - INFO - __main__ - Step 40 Global step 40 Train loss 1.51 on epoch=2
03/16/2022 02:55:42 - INFO - __main__ - Step 50 Global step 50 Train loss 1.29 on epoch=3
03/16/2022 02:55:49 - INFO - __main__ - Global step 50 Train loss 2.46 Classification-F1 0.34747273824418373 on epoch=3
03/16/2022 02:55:49 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.34747273824418373 on epoch=3, global_step=50
03/16/2022 02:55:51 - INFO - __main__ - Step 60 Global step 60 Train loss 1.06 on epoch=4
03/16/2022 02:55:54 - INFO - __main__ - Step 70 Global step 70 Train loss 0.85 on epoch=4
03/16/2022 02:55:57 - INFO - __main__ - Step 80 Global step 80 Train loss 0.95 on epoch=5
03/16/2022 02:55:59 - INFO - __main__ - Step 90 Global step 90 Train loss 0.75 on epoch=6
03/16/2022 02:56:02 - INFO - __main__ - Step 100 Global step 100 Train loss 0.66 on epoch=7
03/16/2022 02:56:08 - INFO - __main__ - Global step 100 Train loss 0.85 Classification-F1 0.5542110566739571 on epoch=7
03/16/2022 02:56:08 - INFO - __main__ - Saving model with best Classification-F1: 0.34747273824418373 -> 0.5542110566739571 on epoch=7, global_step=100
03/16/2022 02:56:11 - INFO - __main__ - Step 110 Global step 110 Train loss 0.65 on epoch=7
03/16/2022 02:56:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.65 on epoch=8
03/16/2022 02:56:16 - INFO - __main__ - Step 130 Global step 130 Train loss 0.67 on epoch=9
03/16/2022 02:56:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.50 on epoch=9
03/16/2022 02:56:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.43 on epoch=10
03/16/2022 02:56:28 - INFO - __main__ - Global step 150 Train loss 0.58 Classification-F1 0.6702974621408833 on epoch=10
03/16/2022 02:56:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5542110566739571 -> 0.6702974621408833 on epoch=10, global_step=150
03/16/2022 02:56:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.51 on epoch=11
03/16/2022 02:56:33 - INFO - __main__ - Step 170 Global step 170 Train loss 0.51 on epoch=12
03/16/2022 02:56:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.31 on epoch=12
03/16/2022 02:56:39 - INFO - __main__ - Step 190 Global step 190 Train loss 0.34 on epoch=13
03/16/2022 02:56:41 - INFO - __main__ - Step 200 Global step 200 Train loss 0.41 on epoch=14
03/16/2022 02:56:48 - INFO - __main__ - Global step 200 Train loss 0.42 Classification-F1 0.820438550248797 on epoch=14
03/16/2022 02:56:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6702974621408833 -> 0.820438550248797 on epoch=14, global_step=200
03/16/2022 02:56:51 - INFO - __main__ - Step 210 Global step 210 Train loss 0.40 on epoch=14
03/16/2022 02:56:53 - INFO - __main__ - Step 220 Global step 220 Train loss 0.29 on epoch=15
03/16/2022 02:56:56 - INFO - __main__ - Step 230 Global step 230 Train loss 0.27 on epoch=16
03/16/2022 02:56:58 - INFO - __main__ - Step 240 Global step 240 Train loss 0.35 on epoch=17
03/16/2022 02:57:01 - INFO - __main__ - Step 250 Global step 250 Train loss 0.26 on epoch=17
03/16/2022 02:57:08 - INFO - __main__ - Global step 250 Train loss 0.31 Classification-F1 0.7871129563685584 on epoch=17
03/16/2022 02:57:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.29 on epoch=18
03/16/2022 02:57:13 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=19
03/16/2022 02:57:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.30 on epoch=19
03/16/2022 02:57:18 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=20
03/16/2022 02:57:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.19 on epoch=21
03/16/2022 02:57:27 - INFO - __main__ - Global step 300 Train loss 0.27 Classification-F1 0.711119526413117 on epoch=21
03/16/2022 02:57:30 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=22
03/16/2022 02:57:32 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=22
03/16/2022 02:57:35 - INFO - __main__ - Step 330 Global step 330 Train loss 0.18 on epoch=23
03/16/2022 02:57:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=24
03/16/2022 02:57:40 - INFO - __main__ - Step 350 Global step 350 Train loss 0.17 on epoch=24
03/16/2022 02:57:47 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.8647346905056422 on epoch=24
03/16/2022 02:57:47 - INFO - __main__ - Saving model with best Classification-F1: 0.820438550248797 -> 0.8647346905056422 on epoch=24, global_step=350
03/16/2022 02:57:50 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=25
03/16/2022 02:57:52 - INFO - __main__ - Step 370 Global step 370 Train loss 0.16 on epoch=26
03/16/2022 02:57:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.15 on epoch=27
03/16/2022 02:57:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.16 on epoch=27
03/16/2022 02:58:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.18 on epoch=28
03/16/2022 02:58:08 - INFO - __main__ - Global step 400 Train loss 0.18 Classification-F1 0.9641451403091319 on epoch=28
03/16/2022 02:58:08 - INFO - __main__ - Saving model with best Classification-F1: 0.8647346905056422 -> 0.9641451403091319 on epoch=28, global_step=400
03/16/2022 02:58:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=29
03/16/2022 02:58:13 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=29
03/16/2022 02:58:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=30
03/16/2022 02:58:18 - INFO - __main__ - Step 440 Global step 440 Train loss 0.15 on epoch=31
03/16/2022 02:58:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.18 on epoch=32
03/16/2022 02:58:28 - INFO - __main__ - Global step 450 Train loss 0.20 Classification-F1 0.8344448903664003 on epoch=32
03/16/2022 02:58:31 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=32
03/16/2022 02:58:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=33
03/16/2022 02:58:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.09 on epoch=34
03/16/2022 02:58:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.12 on epoch=34
03/16/2022 02:58:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=35
03/16/2022 02:58:48 - INFO - __main__ - Global step 500 Train loss 0.13 Classification-F1 0.9143564679048549 on epoch=35
03/16/2022 02:58:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=36
03/16/2022 02:58:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=37
03/16/2022 02:58:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=37
03/16/2022 02:58:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=38
03/16/2022 02:59:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.11 on epoch=39
03/16/2022 02:59:08 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.8928549858088125 on epoch=39
03/16/2022 02:59:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=39
03/16/2022 02:59:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=40
03/16/2022 02:59:16 - INFO - __main__ - Step 580 Global step 580 Train loss 0.10 on epoch=41
03/16/2022 02:59:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.08 on epoch=42
03/16/2022 02:59:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=42
03/16/2022 02:59:29 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.9103045636631976 on epoch=42
03/16/2022 02:59:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=43
03/16/2022 02:59:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=44
03/16/2022 02:59:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.14 on epoch=44
03/16/2022 02:59:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=45
03/16/2022 02:59:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=46
03/16/2022 02:59:49 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.8711198001520584 on epoch=46
03/16/2022 02:59:51 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=47
03/16/2022 02:59:54 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=47
03/16/2022 02:59:56 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=48
03/16/2022 02:59:59 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=49
03/16/2022 03:00:01 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=49
03/16/2022 03:00:08 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.9730388563049855 on epoch=49
03/16/2022 03:00:08 - INFO - __main__ - Saving model with best Classification-F1: 0.9641451403091319 -> 0.9730388563049855 on epoch=49, global_step=700
03/16/2022 03:00:11 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=50
03/16/2022 03:00:13 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=51
03/16/2022 03:00:16 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=52
03/16/2022 03:00:19 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=52
03/16/2022 03:00:21 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=53
03/16/2022 03:00:30 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.9643000629820134 on epoch=53
03/16/2022 03:00:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=54
03/16/2022 03:00:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.09 on epoch=54
03/16/2022 03:00:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=55
03/16/2022 03:00:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=56
03/16/2022 03:00:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=57
03/16/2022 03:00:51 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.9824964589941548 on epoch=57
03/16/2022 03:00:51 - INFO - __main__ - Saving model with best Classification-F1: 0.9730388563049855 -> 0.9824964589941548 on epoch=57, global_step=800
03/16/2022 03:00:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=57
03/16/2022 03:00:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=58
03/16/2022 03:00:58 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=59
03/16/2022 03:01:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=59
03/16/2022 03:01:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=60
03/16/2022 03:01:11 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.8473918761558623 on epoch=60
03/16/2022 03:01:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=61
03/16/2022 03:01:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=62
03/16/2022 03:01:19 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=62
03/16/2022 03:01:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=63
03/16/2022 03:01:24 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=64
03/16/2022 03:01:31 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.9690685878456955 on epoch=64
03/16/2022 03:01:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=64
03/16/2022 03:01:36 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=65
03/16/2022 03:01:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=66
03/16/2022 03:01:41 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=67
03/16/2022 03:01:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=67
03/16/2022 03:01:51 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.9694146671376274 on epoch=67
03/16/2022 03:01:54 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=68
03/16/2022 03:01:56 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=69
03/16/2022 03:01:59 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=69
03/16/2022 03:02:01 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
03/16/2022 03:02:04 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=71
03/16/2022 03:02:11 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.8942835055169023 on epoch=71
03/16/2022 03:02:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=72
03/16/2022 03:02:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=72
03/16/2022 03:02:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
03/16/2022 03:02:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
03/16/2022 03:02:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
03/16/2022 03:02:31 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.9601006384958678 on epoch=74
03/16/2022 03:02:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=75
03/16/2022 03:02:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=76
03/16/2022 03:02:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
03/16/2022 03:02:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=77
03/16/2022 03:02:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=78
03/16/2022 03:02:51 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.9688344546029557 on epoch=78
03/16/2022 03:02:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=79
03/16/2022 03:02:56 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
03/16/2022 03:02:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
03/16/2022 03:03:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
03/16/2022 03:03:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=82
03/16/2022 03:03:10 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.8547881484477703 on epoch=82
03/16/2022 03:03:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=82
03/16/2022 03:03:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=83
03/16/2022 03:03:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=84
03/16/2022 03:03:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=84
03/16/2022 03:03:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
03/16/2022 03:03:30 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.9104479328388246 on epoch=85
03/16/2022 03:03:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=86
03/16/2022 03:03:35 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=87
03/16/2022 03:03:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
03/16/2022 03:03:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=88
03/16/2022 03:03:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
03/16/2022 03:03:50 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7815618916188176 on epoch=89
03/16/2022 03:03:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
03/16/2022 03:03:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
03/16/2022 03:03:58 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
03/16/2022 03:04:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
03/16/2022 03:04:03 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
03/16/2022 03:04:11 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7988023928349781 on epoch=92
03/16/2022 03:04:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
03/16/2022 03:04:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=94
03/16/2022 03:04:18 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
03/16/2022 03:04:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=95
03/16/2022 03:04:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
03/16/2022 03:04:31 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.8271519751595653 on epoch=96
03/16/2022 03:04:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=97
03/16/2022 03:04:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=97
03/16/2022 03:04:38 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
03/16/2022 03:04:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
03/16/2022 03:04:43 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
03/16/2022 03:04:52 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.8547881484477702 on epoch=99
03/16/2022 03:04:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
03/16/2022 03:04:57 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=101
03/16/2022 03:05:00 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=102
03/16/2022 03:05:02 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=102
03/16/2022 03:05:05 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
03/16/2022 03:05:13 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.8547881484477702 on epoch=103
03/16/2022 03:05:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=104
03/16/2022 03:05:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
03/16/2022 03:05:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
03/16/2022 03:05:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
03/16/2022 03:05:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
03/16/2022 03:05:34 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.9144753033178081 on epoch=107
03/16/2022 03:05:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
03/16/2022 03:05:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
03/16/2022 03:05:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=109
03/16/2022 03:05:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
03/16/2022 03:05:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
03/16/2022 03:05:53 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.8757764689453492 on epoch=110
03/16/2022 03:05:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
03/16/2022 03:05:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
03/16/2022 03:06:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
03/16/2022 03:06:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
03/16/2022 03:06:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
03/16/2022 03:06:13 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.9104233990761504 on epoch=114
03/16/2022 03:06:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
03/16/2022 03:06:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=115
03/16/2022 03:06:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
03/16/2022 03:06:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
03/16/2022 03:06:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
03/16/2022 03:06:35 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.8033185452540291 on epoch=117
03/16/2022 03:06:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
03/16/2022 03:06:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
03/16/2022 03:06:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
03/16/2022 03:06:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
03/16/2022 03:06:47 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
03/16/2022 03:06:59 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.8004140072451268 on epoch=121
03/16/2022 03:07:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
03/16/2022 03:07:04 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
03/16/2022 03:07:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
03/16/2022 03:07:09 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=124
03/16/2022 03:07:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
03/16/2022 03:07:23 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.8417723165040445 on epoch=124
03/16/2022 03:07:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
03/16/2022 03:07:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
03/16/2022 03:07:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
03/16/2022 03:07:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=127
03/16/2022 03:07:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
03/16/2022 03:07:43 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.8970704859129908 on epoch=128
03/16/2022 03:07:45 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
03/16/2022 03:07:48 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=129
03/16/2022 03:07:50 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
03/16/2022 03:07:53 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
03/16/2022 03:07:55 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
03/16/2022 03:08:02 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9686668802418329 on epoch=132
03/16/2022 03:08:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
03/16/2022 03:08:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
03/16/2022 03:08:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=134
03/16/2022 03:08:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=134
03/16/2022 03:08:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
03/16/2022 03:08:22 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9069831960154543 on epoch=135
03/16/2022 03:08:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
03/16/2022 03:08:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
03/16/2022 03:08:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
03/16/2022 03:08:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
03/16/2022 03:08:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
03/16/2022 03:08:41 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.8205648434227064 on epoch=139
03/16/2022 03:08:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
03/16/2022 03:08:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=140
03/16/2022 03:08:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=141
03/16/2022 03:08:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
03/16/2022 03:08:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=142
03/16/2022 03:09:01 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.8697516253161415 on epoch=142
03/16/2022 03:09:04 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
03/16/2022 03:09:07 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
03/16/2022 03:09:09 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=144
03/16/2022 03:09:12 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
03/16/2022 03:09:15 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
03/16/2022 03:09:21 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.8160449370363981 on epoch=146
03/16/2022 03:09:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
03/16/2022 03:09:26 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
03/16/2022 03:09:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=148
03/16/2022 03:09:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
03/16/2022 03:09:34 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
03/16/2022 03:09:41 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8068487103129568 on epoch=149
03/16/2022 03:09:43 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
03/16/2022 03:09:46 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
03/16/2022 03:09:48 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
03/16/2022 03:09:51 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
03/16/2022 03:09:54 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=153
03/16/2022 03:10:01 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9144998370804823 on epoch=153
03/16/2022 03:10:04 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
03/16/2022 03:10:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=154
03/16/2022 03:10:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
03/16/2022 03:10:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
03/16/2022 03:10:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
03/16/2022 03:10:23 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9022007551798824 on epoch=157
03/16/2022 03:10:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
03/16/2022 03:10:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
03/16/2022 03:10:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
03/16/2022 03:10:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
03/16/2022 03:10:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
03/16/2022 03:10:43 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8508818984477702 on epoch=160
03/16/2022 03:10:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
03/16/2022 03:10:48 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
03/16/2022 03:10:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
03/16/2022 03:10:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
03/16/2022 03:10:56 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
03/16/2022 03:11:02 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8739048933356334 on epoch=164
03/16/2022 03:11:05 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
03/16/2022 03:11:08 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=165
03/16/2022 03:11:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
03/16/2022 03:11:13 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
03/16/2022 03:11:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
03/16/2022 03:11:22 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.8734866351232575 on epoch=167
03/16/2022 03:11:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
03/16/2022 03:11:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
03/16/2022 03:11:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
03/16/2022 03:11:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
03/16/2022 03:11:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
03/16/2022 03:11:42 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8735952846436718 on epoch=171
03/16/2022 03:11:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
03/16/2022 03:11:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
03/16/2022 03:11:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
03/16/2022 03:11:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
03/16/2022 03:11:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
03/16/2022 03:12:02 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8988834605200832 on epoch=174
03/16/2022 03:12:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
03/16/2022 03:12:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
03/16/2022 03:12:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
03/16/2022 03:12:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
03/16/2022 03:12:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
03/16/2022 03:12:21 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.8125559097983228 on epoch=178
03/16/2022 03:12:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
03/16/2022 03:12:27 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
03/16/2022 03:12:29 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
03/16/2022 03:12:32 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
03/16/2022 03:12:34 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
03/16/2022 03:12:40 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8437411751927881 on epoch=182
03/16/2022 03:12:43 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
03/16/2022 03:12:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
03/16/2022 03:12:48 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
03/16/2022 03:12:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
03/16/2022 03:12:53 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
03/16/2022 03:12:59 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.828793134739233 on epoch=185
03/16/2022 03:13:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
03/16/2022 03:13:05 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
03/16/2022 03:13:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
03/16/2022 03:13:10 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
03/16/2022 03:13:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
03/16/2022 03:13:19 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8089992479473654 on epoch=189
03/16/2022 03:13:21 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
03/16/2022 03:13:24 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
03/16/2022 03:13:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
03/16/2022 03:13:29 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/16/2022 03:13:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
03/16/2022 03:13:38 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7439745088701445 on epoch=192
03/16/2022 03:13:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
03/16/2022 03:13:43 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
03/16/2022 03:13:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
03/16/2022 03:13:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
03/16/2022 03:13:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
03/16/2022 03:13:57 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.89876462510713 on epoch=196
03/16/2022 03:14:00 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
03/16/2022 03:14:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
03/16/2022 03:14:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
03/16/2022 03:14:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
03/16/2022 03:14:10 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
03/16/2022 03:14:17 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8862936973420846 on epoch=199
03/16/2022 03:14:20 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
03/16/2022 03:14:22 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
03/16/2022 03:14:25 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
03/16/2022 03:14:27 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
03/16/2022 03:14:30 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
03/16/2022 03:14:36 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8895400310549495 on epoch=203
03/16/2022 03:14:39 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
03/16/2022 03:14:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
03/16/2022 03:14:44 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
03/16/2022 03:14:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
03/16/2022 03:14:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
03/16/2022 03:14:55 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.9104479328388249 on epoch=207
03/16/2022 03:14:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
03/16/2022 03:15:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
03/16/2022 03:15:03 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
03/16/2022 03:15:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
03/16/2022 03:15:08 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
03/16/2022 03:15:14 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9646650840199228 on epoch=210
03/16/2022 03:15:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
03/16/2022 03:15:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
03/16/2022 03:15:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
03/16/2022 03:15:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
03/16/2022 03:15:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
03/16/2022 03:15:29 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 03:15:29 - INFO - __main__ - Printing 3 examples
03/16/2022 03:15:29 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
03/16/2022 03:15:29 - INFO - __main__ - ['Film']
03/16/2022 03:15:29 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
03/16/2022 03:15:29 - INFO - __main__ - ['Film']
03/16/2022 03:15:29 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
03/16/2022 03:15:29 - INFO - __main__ - ['Film']
03/16/2022 03:15:29 - INFO - __main__ - Tokenizing Input ...
03/16/2022 03:15:29 - INFO - __main__ - Tokenizing Output ...
03/16/2022 03:15:29 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 03:15:29 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 03:15:29 - INFO - __main__ - Printing 3 examples
03/16/2022 03:15:29 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
03/16/2022 03:15:29 - INFO - __main__ - ['Film']
03/16/2022 03:15:29 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
03/16/2022 03:15:29 - INFO - __main__ - ['Film']
03/16/2022 03:15:29 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
03/16/2022 03:15:29 - INFO - __main__ - ['Film']
03/16/2022 03:15:29 - INFO - __main__ - Tokenizing Input ...
03/16/2022 03:15:29 - INFO - __main__ - Tokenizing Output ...
03/16/2022 03:15:30 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 03:15:33 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.9688248539885164 on epoch=214
03/16/2022 03:15:33 - INFO - __main__ - save last model!
03/16/2022 03:15:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/16/2022 03:15:33 - INFO - __main__ - Start tokenizing ... 3500 instances
03/16/2022 03:15:33 - INFO - __main__ - Printing 3 examples
03/16/2022 03:15:33 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/16/2022 03:15:33 - INFO - __main__ - ['Animal']
03/16/2022 03:15:33 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/16/2022 03:15:33 - INFO - __main__ - ['Animal']
03/16/2022 03:15:33 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/16/2022 03:15:33 - INFO - __main__ - ['Village']
03/16/2022 03:15:33 - INFO - __main__ - Tokenizing Input ...
03/16/2022 03:15:35 - INFO - __main__ - Tokenizing Output ...
03/16/2022 03:15:39 - INFO - __main__ - Loaded 3500 examples from test data
03/16/2022 03:15:48 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 03:15:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 03:15:49 - INFO - __main__ - Starting training!
03/16/2022 03:17:41 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
03/16/2022 03:17:41 - INFO - __main__ - Classification-F1 on test data: 0.6791
03/16/2022 03:17:42 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.9824964589941548, test_performance=0.6790758533088554
03/16/2022 03:17:42 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
03/16/2022 03:17:42 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 03:17:42 - INFO - __main__ - Printing 3 examples
03/16/2022 03:17:42 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
03/16/2022 03:17:42 - INFO - __main__ - ['Film']
03/16/2022 03:17:42 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
03/16/2022 03:17:42 - INFO - __main__ - ['Film']
03/16/2022 03:17:42 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
03/16/2022 03:17:42 - INFO - __main__ - ['Film']
03/16/2022 03:17:42 - INFO - __main__ - Tokenizing Input ...
03/16/2022 03:17:43 - INFO - __main__ - Tokenizing Output ...
03/16/2022 03:17:43 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 03:17:43 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 03:17:43 - INFO - __main__ - Printing 3 examples
03/16/2022 03:17:43 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
03/16/2022 03:17:43 - INFO - __main__ - ['Film']
03/16/2022 03:17:43 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
03/16/2022 03:17:43 - INFO - __main__ - ['Film']
03/16/2022 03:17:43 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
03/16/2022 03:17:43 - INFO - __main__ - ['Film']
03/16/2022 03:17:43 - INFO - __main__ - Tokenizing Input ...
03/16/2022 03:17:43 - INFO - __main__ - Tokenizing Output ...
03/16/2022 03:17:43 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 03:18:02 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 03:18:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 03:18:03 - INFO - __main__ - Starting training!
03/16/2022 03:18:06 - INFO - __main__ - Step 10 Global step 10 Train loss 4.81 on epoch=0
03/16/2022 03:18:09 - INFO - __main__ - Step 20 Global step 20 Train loss 3.40 on epoch=1
03/16/2022 03:18:11 - INFO - __main__ - Step 30 Global step 30 Train loss 2.40 on epoch=2
03/16/2022 03:18:14 - INFO - __main__ - Step 40 Global step 40 Train loss 2.01 on epoch=2
03/16/2022 03:18:17 - INFO - __main__ - Step 50 Global step 50 Train loss 1.77 on epoch=3
03/16/2022 03:18:23 - INFO - __main__ - Global step 50 Train loss 2.88 Classification-F1 0.20313315955266834 on epoch=3
03/16/2022 03:18:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.20313315955266834 on epoch=3, global_step=50
03/16/2022 03:18:26 - INFO - __main__ - Step 60 Global step 60 Train loss 1.30 on epoch=4
03/16/2022 03:18:28 - INFO - __main__ - Step 70 Global step 70 Train loss 1.18 on epoch=4
03/16/2022 03:18:31 - INFO - __main__ - Step 80 Global step 80 Train loss 1.08 on epoch=5
03/16/2022 03:18:33 - INFO - __main__ - Step 90 Global step 90 Train loss 0.92 on epoch=6
03/16/2022 03:18:36 - INFO - __main__ - Step 100 Global step 100 Train loss 0.82 on epoch=7
03/16/2022 03:18:43 - INFO - __main__ - Global step 100 Train loss 1.06 Classification-F1 0.6751296686485442 on epoch=7
03/16/2022 03:18:43 - INFO - __main__ - Saving model with best Classification-F1: 0.20313315955266834 -> 0.6751296686485442 on epoch=7, global_step=100
03/16/2022 03:18:45 - INFO - __main__ - Step 110 Global step 110 Train loss 0.70 on epoch=7
03/16/2022 03:18:48 - INFO - __main__ - Step 120 Global step 120 Train loss 0.78 on epoch=8
03/16/2022 03:18:50 - INFO - __main__ - Step 130 Global step 130 Train loss 0.55 on epoch=9
03/16/2022 03:18:53 - INFO - __main__ - Step 140 Global step 140 Train loss 0.55 on epoch=9
03/16/2022 03:18:56 - INFO - __main__ - Step 150 Global step 150 Train loss 0.58 on epoch=10
03/16/2022 03:19:02 - INFO - __main__ - Global step 150 Train loss 0.63 Classification-F1 0.5926603095032533 on epoch=10
03/16/2022 03:19:05 - INFO - __main__ - Step 160 Global step 160 Train loss 0.51 on epoch=11
03/16/2022 03:19:07 - INFO - __main__ - Step 170 Global step 170 Train loss 0.59 on epoch=12
03/16/2022 03:19:10 - INFO - __main__ - Step 180 Global step 180 Train loss 0.48 on epoch=12
03/16/2022 03:19:12 - INFO - __main__ - Step 190 Global step 190 Train loss 0.49 on epoch=13
03/16/2022 03:19:15 - INFO - __main__ - Step 200 Global step 200 Train loss 0.52 on epoch=14
03/16/2022 03:19:22 - INFO - __main__ - Global step 200 Train loss 0.52 Classification-F1 0.7225141639934282 on epoch=14
03/16/2022 03:19:22 - INFO - __main__ - Saving model with best Classification-F1: 0.6751296686485442 -> 0.7225141639934282 on epoch=14, global_step=200
03/16/2022 03:19:24 - INFO - __main__ - Step 210 Global step 210 Train loss 0.46 on epoch=14
03/16/2022 03:19:27 - INFO - __main__ - Step 220 Global step 220 Train loss 0.37 on epoch=15
03/16/2022 03:19:29 - INFO - __main__ - Step 230 Global step 230 Train loss 0.42 on epoch=16
03/16/2022 03:19:32 - INFO - __main__ - Step 240 Global step 240 Train loss 0.32 on epoch=17
03/16/2022 03:19:35 - INFO - __main__ - Step 250 Global step 250 Train loss 0.35 on epoch=17
03/16/2022 03:19:42 - INFO - __main__ - Global step 250 Train loss 0.38 Classification-F1 0.6614886117081296 on epoch=17
03/16/2022 03:19:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=18
03/16/2022 03:19:47 - INFO - __main__ - Step 270 Global step 270 Train loss 0.32 on epoch=19
03/16/2022 03:19:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.40 on epoch=19
03/16/2022 03:19:52 - INFO - __main__ - Step 290 Global step 290 Train loss 0.32 on epoch=20
03/16/2022 03:19:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.31 on epoch=21
03/16/2022 03:20:02 - INFO - __main__ - Global step 300 Train loss 0.33 Classification-F1 0.6844594511978206 on epoch=21
03/16/2022 03:20:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=22
03/16/2022 03:20:07 - INFO - __main__ - Step 320 Global step 320 Train loss 0.26 on epoch=22
03/16/2022 03:20:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.28 on epoch=23
03/16/2022 03:20:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=24
03/16/2022 03:20:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.27 on epoch=24
03/16/2022 03:20:22 - INFO - __main__ - Global step 350 Train loss 0.27 Classification-F1 0.8352159570893536 on epoch=24
03/16/2022 03:20:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7225141639934282 -> 0.8352159570893536 on epoch=24, global_step=350
03/16/2022 03:20:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=25
03/16/2022 03:20:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=26
03/16/2022 03:20:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=27
03/16/2022 03:20:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=27
03/16/2022 03:20:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=28
03/16/2022 03:20:44 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.8708891478879374 on epoch=28
03/16/2022 03:20:44 - INFO - __main__ - Saving model with best Classification-F1: 0.8352159570893536 -> 0.8708891478879374 on epoch=28, global_step=400
03/16/2022 03:20:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.29 on epoch=29
03/16/2022 03:20:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=29
03/16/2022 03:20:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.16 on epoch=30
03/16/2022 03:20:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=31
03/16/2022 03:20:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=32
03/16/2022 03:21:04 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.8337458875722632 on epoch=32
03/16/2022 03:21:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=32
03/16/2022 03:21:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.24 on epoch=33
03/16/2022 03:21:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=34
03/16/2022 03:21:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=34
03/16/2022 03:21:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=35
03/16/2022 03:21:25 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.9306989658033302 on epoch=35
03/16/2022 03:21:25 - INFO - __main__ - Saving model with best Classification-F1: 0.8708891478879374 -> 0.9306989658033302 on epoch=35, global_step=500
03/16/2022 03:21:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.15 on epoch=36
03/16/2022 03:21:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=37
03/16/2022 03:21:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=37
03/16/2022 03:21:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=38
03/16/2022 03:21:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=39
03/16/2022 03:21:46 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.9143564679048549 on epoch=39
03/16/2022 03:21:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=39
03/16/2022 03:21:51 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=40
03/16/2022 03:21:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.10 on epoch=41
03/16/2022 03:21:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=42
03/16/2022 03:21:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=42
03/16/2022 03:22:07 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.8847902456798393 on epoch=42
03/16/2022 03:22:10 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=43
03/16/2022 03:22:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=44
03/16/2022 03:22:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=44
03/16/2022 03:22:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=45
03/16/2022 03:22:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=46
03/16/2022 03:22:27 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.8928187814715329 on epoch=46
03/16/2022 03:22:29 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=47
03/16/2022 03:22:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=47
03/16/2022 03:22:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=48
03/16/2022 03:22:37 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=49
03/16/2022 03:22:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=49
03/16/2022 03:22:48 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.968374419997547 on epoch=49
03/16/2022 03:22:48 - INFO - __main__ - Saving model with best Classification-F1: 0.9306989658033302 -> 0.968374419997547 on epoch=49, global_step=700
03/16/2022 03:22:50 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=50
03/16/2022 03:22:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=51
03/16/2022 03:22:55 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=52
03/16/2022 03:22:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=52
03/16/2022 03:23:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=53
03/16/2022 03:23:09 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.9654872642091628 on epoch=53
03/16/2022 03:23:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=54
03/16/2022 03:23:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=54
03/16/2022 03:23:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=55
03/16/2022 03:23:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=56
03/16/2022 03:23:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=57
03/16/2022 03:23:30 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.9686668802418329 on epoch=57
03/16/2022 03:23:30 - INFO - __main__ - Saving model with best Classification-F1: 0.968374419997547 -> 0.9686668802418329 on epoch=57, global_step=800
03/16/2022 03:23:32 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=57
03/16/2022 03:23:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=58
03/16/2022 03:23:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=59
03/16/2022 03:23:40 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=59
03/16/2022 03:23:43 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=60
03/16/2022 03:23:51 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.9686668802418329 on epoch=60
03/16/2022 03:23:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=61
03/16/2022 03:23:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=62
03/16/2022 03:23:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=62
03/16/2022 03:24:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=63
03/16/2022 03:24:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
03/16/2022 03:24:12 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.9187894121480459 on epoch=64
03/16/2022 03:24:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=64
03/16/2022 03:24:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=65
03/16/2022 03:24:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
03/16/2022 03:24:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=67
03/16/2022 03:24:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=67
03/16/2022 03:24:32 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.9144753033178081 on epoch=67
03/16/2022 03:24:35 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=68
03/16/2022 03:24:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=69
03/16/2022 03:24:40 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=69
03/16/2022 03:24:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
03/16/2022 03:24:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
03/16/2022 03:24:53 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.9820991153059465 on epoch=71
03/16/2022 03:24:53 - INFO - __main__ - Saving model with best Classification-F1: 0.9686668802418329 -> 0.9820991153059465 on epoch=71, global_step=1000
03/16/2022 03:24:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=72
03/16/2022 03:24:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
03/16/2022 03:25:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
03/16/2022 03:25:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=74
03/16/2022 03:25:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
03/16/2022 03:25:13 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.9061378969965309 on epoch=74
03/16/2022 03:25:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
03/16/2022 03:25:18 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=76
03/16/2022 03:25:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=77
03/16/2022 03:25:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=77
03/16/2022 03:25:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
03/16/2022 03:25:33 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.9737766074171604 on epoch=78
03/16/2022 03:25:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=79
03/16/2022 03:25:38 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
03/16/2022 03:25:41 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=80
03/16/2022 03:25:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=81
03/16/2022 03:25:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
03/16/2022 03:25:53 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.9061468575700076 on epoch=82
03/16/2022 03:25:56 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
03/16/2022 03:25:58 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
03/16/2022 03:26:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=84
03/16/2022 03:26:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=84
03/16/2022 03:26:06 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
03/16/2022 03:26:13 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.9732891397028022 on epoch=85
03/16/2022 03:26:16 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
03/16/2022 03:26:18 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=87
03/16/2022 03:26:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
03/16/2022 03:26:23 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
03/16/2022 03:26:26 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
03/16/2022 03:26:34 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.9062526594215401 on epoch=89
03/16/2022 03:26:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
03/16/2022 03:26:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
03/16/2022 03:26:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
03/16/2022 03:26:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
03/16/2022 03:26:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=92
03/16/2022 03:26:53 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.9061092902459128 on epoch=92
03/16/2022 03:26:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=93
03/16/2022 03:26:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
03/16/2022 03:27:01 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
03/16/2022 03:27:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
03/16/2022 03:27:06 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
03/16/2022 03:27:13 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.9064801443549072 on epoch=96
03/16/2022 03:27:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=97
03/16/2022 03:27:18 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
03/16/2022 03:27:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
03/16/2022 03:27:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
03/16/2022 03:27:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
03/16/2022 03:27:33 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.9062567324094838 on epoch=99
03/16/2022 03:27:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
03/16/2022 03:27:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
03/16/2022 03:27:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=102
03/16/2022 03:27:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
03/16/2022 03:27:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
03/16/2022 03:27:53 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.8491362719941349 on epoch=103
03/16/2022 03:27:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
03/16/2022 03:27:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
03/16/2022 03:28:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
03/16/2022 03:28:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
03/16/2022 03:28:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
03/16/2022 03:28:13 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.9642121951419865 on epoch=107
03/16/2022 03:28:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
03/16/2022 03:28:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
03/16/2022 03:28:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
03/16/2022 03:28:24 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
03/16/2022 03:28:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
03/16/2022 03:28:33 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.954679511100628 on epoch=110
03/16/2022 03:28:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
03/16/2022 03:28:38 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=112
03/16/2022 03:28:41 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
03/16/2022 03:28:43 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
03/16/2022 03:28:46 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=114
03/16/2022 03:28:53 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.9144753033178081 on epoch=114
03/16/2022 03:28:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
03/16/2022 03:28:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
03/16/2022 03:29:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
03/16/2022 03:29:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
03/16/2022 03:29:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
03/16/2022 03:29:13 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.8931691748057974 on epoch=117
03/16/2022 03:29:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
03/16/2022 03:29:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
03/16/2022 03:29:21 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
03/16/2022 03:29:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
03/16/2022 03:29:26 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
03/16/2022 03:29:32 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8972210790474549 on epoch=121
03/16/2022 03:29:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=122
03/16/2022 03:29:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
03/16/2022 03:29:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
03/16/2022 03:29:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
03/16/2022 03:29:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
03/16/2022 03:29:52 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.8485034336315171 on epoch=124
03/16/2022 03:29:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
03/16/2022 03:29:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
03/16/2022 03:30:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
03/16/2022 03:30:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
03/16/2022 03:30:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
03/16/2022 03:30:12 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.9103290974258716 on epoch=128
03/16/2022 03:30:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
03/16/2022 03:30:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
03/16/2022 03:30:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
03/16/2022 03:30:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
03/16/2022 03:30:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
03/16/2022 03:30:32 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9122100032583904 on epoch=132
03/16/2022 03:30:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
03/16/2022 03:30:37 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
03/16/2022 03:30:40 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
03/16/2022 03:30:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
03/16/2022 03:30:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
03/16/2022 03:30:52 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8517420751291719 on epoch=135
03/16/2022 03:30:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
03/16/2022 03:30:57 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
03/16/2022 03:31:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
03/16/2022 03:31:02 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
03/16/2022 03:31:05 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
03/16/2022 03:31:12 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.8554388764303376 on epoch=139
03/16/2022 03:31:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
03/16/2022 03:31:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
03/16/2022 03:31:20 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
03/16/2022 03:31:22 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
03/16/2022 03:31:25 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
03/16/2022 03:31:32 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9016152948522247 on epoch=142
03/16/2022 03:31:35 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
03/16/2022 03:31:37 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
03/16/2022 03:31:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
03/16/2022 03:31:42 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
03/16/2022 03:31:45 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
03/16/2022 03:31:52 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7184949704873804 on epoch=146
03/16/2022 03:31:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
03/16/2022 03:31:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
03/16/2022 03:32:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
03/16/2022 03:32:02 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
03/16/2022 03:32:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
03/16/2022 03:32:12 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.8748921057507395 on epoch=149
03/16/2022 03:32:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
03/16/2022 03:32:17 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
03/16/2022 03:32:20 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
03/16/2022 03:32:22 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
03/16/2022 03:32:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
03/16/2022 03:32:31 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.8934056845173773 on epoch=153
03/16/2022 03:32:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
03/16/2022 03:32:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
03/16/2022 03:32:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
03/16/2022 03:32:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
03/16/2022 03:32:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
03/16/2022 03:32:51 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8604080380930477 on epoch=157
03/16/2022 03:32:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
03/16/2022 03:32:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
03/16/2022 03:32:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
03/16/2022 03:33:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
03/16/2022 03:33:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
03/16/2022 03:33:10 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8865155869394383 on epoch=160
03/16/2022 03:33:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
03/16/2022 03:33:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
03/16/2022 03:33:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
03/16/2022 03:33:21 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
03/16/2022 03:33:24 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
03/16/2022 03:33:31 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8735111688859319 on epoch=164
03/16/2022 03:33:33 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
03/16/2022 03:33:36 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=165
03/16/2022 03:33:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
03/16/2022 03:33:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
03/16/2022 03:33:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
03/16/2022 03:33:50 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9029598985244147 on epoch=167
03/16/2022 03:33:52 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
03/16/2022 03:33:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
03/16/2022 03:33:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
03/16/2022 03:34:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
03/16/2022 03:34:03 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
03/16/2022 03:34:10 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8941847581869721 on epoch=171
03/16/2022 03:34:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
03/16/2022 03:34:15 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
03/16/2022 03:34:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
03/16/2022 03:34:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
03/16/2022 03:34:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
03/16/2022 03:34:31 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.793109736563247 on epoch=174
03/16/2022 03:34:33 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
03/16/2022 03:34:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
03/16/2022 03:34:39 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
03/16/2022 03:34:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
03/16/2022 03:34:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
03/16/2022 03:34:50 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9097578959786969 on epoch=178
03/16/2022 03:34:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
03/16/2022 03:34:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
03/16/2022 03:34:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
03/16/2022 03:35:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
03/16/2022 03:35:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
03/16/2022 03:35:09 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9030787339373679 on epoch=182
03/16/2022 03:35:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
03/16/2022 03:35:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
03/16/2022 03:35:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
03/16/2022 03:35:19 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
03/16/2022 03:35:22 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
03/16/2022 03:35:28 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8513943994019896 on epoch=185
03/16/2022 03:35:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
03/16/2022 03:35:33 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
03/16/2022 03:35:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
03/16/2022 03:35:38 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
03/16/2022 03:35:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
03/16/2022 03:35:47 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9039587526115043 on epoch=189
03/16/2022 03:35:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
03/16/2022 03:35:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
03/16/2022 03:35:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
03/16/2022 03:35:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/16/2022 03:36:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
03/16/2022 03:36:06 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.845445201541027 on epoch=192
03/16/2022 03:36:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
03/16/2022 03:36:11 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
03/16/2022 03:36:14 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
03/16/2022 03:36:16 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
03/16/2022 03:36:19 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
03/16/2022 03:36:25 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.8960575180436029 on epoch=196
03/16/2022 03:36:28 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
03/16/2022 03:36:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
03/16/2022 03:36:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
03/16/2022 03:36:35 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
03/16/2022 03:36:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
03/16/2022 03:36:44 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8973113719145258 on epoch=199
03/16/2022 03:36:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
03/16/2022 03:36:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
03/16/2022 03:36:52 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
03/16/2022 03:36:54 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
03/16/2022 03:36:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
03/16/2022 03:37:03 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9040775880244571 on epoch=203
03/16/2022 03:37:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
03/16/2022 03:37:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
03/16/2022 03:37:11 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
03/16/2022 03:37:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
03/16/2022 03:37:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
03/16/2022 03:37:23 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9734427495338315 on epoch=207
03/16/2022 03:37:26 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
03/16/2022 03:37:28 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
03/16/2022 03:37:31 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
03/16/2022 03:37:33 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
03/16/2022 03:37:36 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
03/16/2022 03:37:43 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9000154978902607 on epoch=210
03/16/2022 03:37:45 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
03/16/2022 03:37:48 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
03/16/2022 03:37:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
03/16/2022 03:37:53 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
03/16/2022 03:37:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
03/16/2022 03:37:57 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 03:37:57 - INFO - __main__ - Printing 3 examples
03/16/2022 03:37:57 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
03/16/2022 03:37:57 - INFO - __main__ - ['Film']
03/16/2022 03:37:57 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
03/16/2022 03:37:57 - INFO - __main__ - ['Film']
03/16/2022 03:37:57 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
03/16/2022 03:37:57 - INFO - __main__ - ['Film']
03/16/2022 03:37:57 - INFO - __main__ - Tokenizing Input ...
03/16/2022 03:37:57 - INFO - __main__ - Tokenizing Output ...
03/16/2022 03:37:58 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 03:37:58 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 03:37:58 - INFO - __main__ - Printing 3 examples
03/16/2022 03:37:58 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
03/16/2022 03:37:58 - INFO - __main__ - ['Film']
03/16/2022 03:37:58 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
03/16/2022 03:37:58 - INFO - __main__ - ['Film']
03/16/2022 03:37:58 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
03/16/2022 03:37:58 - INFO - __main__ - ['Film']
03/16/2022 03:37:58 - INFO - __main__ - Tokenizing Input ...
03/16/2022 03:37:58 - INFO - __main__ - Tokenizing Output ...
03/16/2022 03:37:58 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 03:38:02 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9645692881258078 on epoch=214
03/16/2022 03:38:02 - INFO - __main__ - save last model!
03/16/2022 03:38:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/16/2022 03:38:02 - INFO - __main__ - Start tokenizing ... 3500 instances
03/16/2022 03:38:02 - INFO - __main__ - Printing 3 examples
03/16/2022 03:38:02 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/16/2022 03:38:02 - INFO - __main__ - ['Animal']
03/16/2022 03:38:02 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/16/2022 03:38:02 - INFO - __main__ - ['Animal']
03/16/2022 03:38:02 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/16/2022 03:38:02 - INFO - __main__ - ['Village']
03/16/2022 03:38:02 - INFO - __main__ - Tokenizing Input ...
03/16/2022 03:38:04 - INFO - __main__ - Tokenizing Output ...
03/16/2022 03:38:08 - INFO - __main__ - Loaded 3500 examples from test data
03/16/2022 03:38:14 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 03:38:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 03:38:14 - INFO - __main__ - Starting training!
03/16/2022 03:40:14 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
03/16/2022 03:40:14 - INFO - __main__ - Classification-F1 on test data: 0.7521
03/16/2022 03:40:15 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.9820991153059465, test_performance=0.7520773294043069
03/16/2022 03:40:15 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
03/16/2022 03:40:16 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 03:40:16 - INFO - __main__ - Printing 3 examples
03/16/2022 03:40:16 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
03/16/2022 03:40:16 - INFO - __main__ - ['Film']
03/16/2022 03:40:16 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
03/16/2022 03:40:16 - INFO - __main__ - ['Film']
03/16/2022 03:40:16 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
03/16/2022 03:40:16 - INFO - __main__ - ['Film']
03/16/2022 03:40:16 - INFO - __main__ - Tokenizing Input ...
03/16/2022 03:40:16 - INFO - __main__ - Tokenizing Output ...
03/16/2022 03:40:16 - INFO - __main__ - Loaded 224 examples from train data
03/16/2022 03:40:16 - INFO - __main__ - Start tokenizing ... 224 instances
03/16/2022 03:40:16 - INFO - __main__ - Printing 3 examples
03/16/2022 03:40:16 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
03/16/2022 03:40:16 - INFO - __main__ - ['Film']
03/16/2022 03:40:16 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
03/16/2022 03:40:16 - INFO - __main__ - ['Film']
03/16/2022 03:40:16 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
03/16/2022 03:40:16 - INFO - __main__ - ['Film']
03/16/2022 03:40:16 - INFO - __main__ - Tokenizing Input ...
03/16/2022 03:40:16 - INFO - __main__ - Tokenizing Output ...
03/16/2022 03:40:16 - INFO - __main__ - Loaded 224 examples from dev data
03/16/2022 03:40:35 - INFO - __main__ - load prompt embedding from ckpt
03/16/2022 03:40:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
03/16/2022 03:40:36 - INFO - __main__ - Starting training!
03/16/2022 03:40:39 - INFO - __main__ - Step 10 Global step 10 Train loss 5.11 on epoch=0
03/16/2022 03:40:42 - INFO - __main__ - Step 20 Global step 20 Train loss 3.87 on epoch=1
03/16/2022 03:40:45 - INFO - __main__ - Step 30 Global step 30 Train loss 3.04 on epoch=2
03/16/2022 03:40:47 - INFO - __main__ - Step 40 Global step 40 Train loss 2.52 on epoch=2
03/16/2022 03:40:50 - INFO - __main__ - Step 50 Global step 50 Train loss 2.24 on epoch=3
03/16/2022 03:40:56 - INFO - __main__ - Global step 50 Train loss 3.36 Classification-F1 0.09508455496894712 on epoch=3
03/16/2022 03:40:56 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09508455496894712 on epoch=3, global_step=50
03/16/2022 03:40:59 - INFO - __main__ - Step 60 Global step 60 Train loss 1.75 on epoch=4
03/16/2022 03:41:01 - INFO - __main__ - Step 70 Global step 70 Train loss 1.50 on epoch=4
03/16/2022 03:41:04 - INFO - __main__ - Step 80 Global step 80 Train loss 1.48 on epoch=5
03/16/2022 03:41:06 - INFO - __main__ - Step 90 Global step 90 Train loss 1.14 on epoch=6
03/16/2022 03:41:09 - INFO - __main__ - Step 100 Global step 100 Train loss 1.06 on epoch=7
03/16/2022 03:41:15 - INFO - __main__ - Global step 100 Train loss 1.38 Classification-F1 0.39707513097579805 on epoch=7
03/16/2022 03:41:15 - INFO - __main__ - Saving model with best Classification-F1: 0.09508455496894712 -> 0.39707513097579805 on epoch=7, global_step=100
03/16/2022 03:41:17 - INFO - __main__ - Step 110 Global step 110 Train loss 0.97 on epoch=7
03/16/2022 03:41:20 - INFO - __main__ - Step 120 Global step 120 Train loss 1.00 on epoch=8
03/16/2022 03:41:22 - INFO - __main__ - Step 130 Global step 130 Train loss 0.91 on epoch=9
03/16/2022 03:41:25 - INFO - __main__ - Step 140 Global step 140 Train loss 0.78 on epoch=9
03/16/2022 03:41:27 - INFO - __main__ - Step 150 Global step 150 Train loss 0.71 on epoch=10
03/16/2022 03:41:33 - INFO - __main__ - Global step 150 Train loss 0.88 Classification-F1 0.548431978050145 on epoch=10
03/16/2022 03:41:34 - INFO - __main__ - Saving model with best Classification-F1: 0.39707513097579805 -> 0.548431978050145 on epoch=10, global_step=150
03/16/2022 03:41:36 - INFO - __main__ - Step 160 Global step 160 Train loss 0.71 on epoch=11
03/16/2022 03:41:39 - INFO - __main__ - Step 170 Global step 170 Train loss 0.72 on epoch=12
03/16/2022 03:41:41 - INFO - __main__ - Step 180 Global step 180 Train loss 0.61 on epoch=12
03/16/2022 03:41:43 - INFO - __main__ - Step 190 Global step 190 Train loss 0.66 on epoch=13
03/16/2022 03:41:46 - INFO - __main__ - Step 200 Global step 200 Train loss 0.57 on epoch=14
03/16/2022 03:41:52 - INFO - __main__ - Global step 200 Train loss 0.65 Classification-F1 0.7951472518851889 on epoch=14
03/16/2022 03:41:52 - INFO - __main__ - Saving model with best Classification-F1: 0.548431978050145 -> 0.7951472518851889 on epoch=14, global_step=200
03/16/2022 03:41:55 - INFO - __main__ - Step 210 Global step 210 Train loss 0.61 on epoch=14
03/16/2022 03:41:57 - INFO - __main__ - Step 220 Global step 220 Train loss 0.63 on epoch=15
03/16/2022 03:42:00 - INFO - __main__ - Step 230 Global step 230 Train loss 0.51 on epoch=16
03/16/2022 03:42:02 - INFO - __main__ - Step 240 Global step 240 Train loss 0.50 on epoch=17
03/16/2022 03:42:05 - INFO - __main__ - Step 250 Global step 250 Train loss 0.57 on epoch=17
03/16/2022 03:42:11 - INFO - __main__ - Global step 250 Train loss 0.56 Classification-F1 0.7788383005274343 on epoch=17
03/16/2022 03:42:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.46 on epoch=18
03/16/2022 03:42:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=19
03/16/2022 03:42:18 - INFO - __main__ - Step 280 Global step 280 Train loss 0.45 on epoch=19
03/16/2022 03:42:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.42 on epoch=20
03/16/2022 03:42:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=21
03/16/2022 03:42:30 - INFO - __main__ - Global step 300 Train loss 0.46 Classification-F1 0.7838280698875645 on epoch=21
03/16/2022 03:42:33 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=22
03/16/2022 03:42:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=22
03/16/2022 03:42:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.31 on epoch=23
03/16/2022 03:42:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.38 on epoch=24
03/16/2022 03:42:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.43 on epoch=24
03/16/2022 03:42:49 - INFO - __main__ - Global step 350 Train loss 0.40 Classification-F1 0.7114437093515074 on epoch=24
03/16/2022 03:42:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=25
03/16/2022 03:42:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=26
03/16/2022 03:42:57 - INFO - __main__ - Step 380 Global step 380 Train loss 0.41 on epoch=27
03/16/2022 03:42:59 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=27
03/16/2022 03:43:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.40 on epoch=28
03/16/2022 03:43:09 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.8495743045695607 on epoch=28
03/16/2022 03:43:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7951472518851889 -> 0.8495743045695607 on epoch=28, global_step=400
03/16/2022 03:43:12 - INFO - __main__ - Step 410 Global step 410 Train loss 0.41 on epoch=29
03/16/2022 03:43:14 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=29
03/16/2022 03:43:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=30
03/16/2022 03:43:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.25 on epoch=31
03/16/2022 03:43:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=32
03/16/2022 03:43:29 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.7642513525031096 on epoch=32
03/16/2022 03:43:31 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=32
03/16/2022 03:43:34 - INFO - __main__ - Step 470 Global step 470 Train loss 0.28 on epoch=33
03/16/2022 03:43:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=34
03/16/2022 03:43:39 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
03/16/2022 03:43:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=35
03/16/2022 03:43:48 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.8766707370580956 on epoch=35
03/16/2022 03:43:48 - INFO - __main__ - Saving model with best Classification-F1: 0.8495743045695607 -> 0.8766707370580956 on epoch=35, global_step=500
03/16/2022 03:43:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=36
03/16/2022 03:43:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=37
03/16/2022 03:43:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.25 on epoch=37
03/16/2022 03:43:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=38
03/16/2022 03:44:00 - INFO - __main__ - Step 550 Global step 550 Train loss 0.16 on epoch=39
03/16/2022 03:44:08 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.8807153670447854 on epoch=39
03/16/2022 03:44:08 - INFO - __main__ - Saving model with best Classification-F1: 0.8766707370580956 -> 0.8807153670447854 on epoch=39, global_step=550
03/16/2022 03:44:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=39
03/16/2022 03:44:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=40
03/16/2022 03:44:16 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=41
03/16/2022 03:44:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=42
03/16/2022 03:44:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=42
03/16/2022 03:44:28 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.7185571274568079 on epoch=42
03/16/2022 03:44:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=43
03/16/2022 03:44:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=44
03/16/2022 03:44:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=44
03/16/2022 03:44:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=45
03/16/2022 03:44:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=46
03/16/2022 03:44:48 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.7027751787055425 on epoch=46
03/16/2022 03:44:50 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=47
03/16/2022 03:44:53 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=47
03/16/2022 03:44:55 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=48
03/16/2022 03:44:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=49
03/16/2022 03:45:00 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=49
03/16/2022 03:45:08 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.7587440405013589 on epoch=49
03/16/2022 03:45:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=50
03/16/2022 03:45:13 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=51
03/16/2022 03:45:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=52
03/16/2022 03:45:18 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=52
03/16/2022 03:45:20 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=53
03/16/2022 03:45:28 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.7458639320830972 on epoch=53
03/16/2022 03:45:30 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=54
03/16/2022 03:45:32 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=54
03/16/2022 03:45:35 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=55
03/16/2022 03:45:37 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=56
03/16/2022 03:45:40 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=57
03/16/2022 03:45:47 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.8205841063156105 on epoch=57
03/16/2022 03:45:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=57
03/16/2022 03:45:52 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=58
03/16/2022 03:45:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=59
03/16/2022 03:45:57 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=59
03/16/2022 03:46:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=60
03/16/2022 03:46:08 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.8256584275939114 on epoch=60
03/16/2022 03:46:10 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=61
03/16/2022 03:46:13 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=62
03/16/2022 03:46:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=62
03/16/2022 03:46:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=63
03/16/2022 03:46:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=64
03/16/2022 03:46:28 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.8022322287191751 on epoch=64
03/16/2022 03:46:30 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=64
03/16/2022 03:46:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=65
03/16/2022 03:46:35 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=66
03/16/2022 03:46:38 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=67
03/16/2022 03:46:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=67
03/16/2022 03:46:48 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.9865984150258343 on epoch=67
03/16/2022 03:46:48 - INFO - __main__ - Saving model with best Classification-F1: 0.8807153670447854 -> 0.9865984150258343 on epoch=67, global_step=950
03/16/2022 03:46:50 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
03/16/2022 03:46:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=69
03/16/2022 03:46:55 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=69
03/16/2022 03:46:58 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=70
03/16/2022 03:47:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
03/16/2022 03:47:07 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.8450656716638016 on epoch=71
03/16/2022 03:47:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=72
03/16/2022 03:47:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=72
03/16/2022 03:47:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=73
03/16/2022 03:47:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
03/16/2022 03:47:19 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=74
03/16/2022 03:47:27 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.9121854694957162 on epoch=74
03/16/2022 03:47:29 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=75
03/16/2022 03:47:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=76
03/16/2022 03:47:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
03/16/2022 03:47:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
03/16/2022 03:47:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=78
03/16/2022 03:47:47 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.9780278093642151 on epoch=78
03/16/2022 03:47:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=79
03/16/2022 03:47:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=79
03/16/2022 03:47:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
03/16/2022 03:47:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=81
03/16/2022 03:47:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.21 on epoch=82
03/16/2022 03:48:06 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.8514089992668622 on epoch=82
03/16/2022 03:48:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
03/16/2022 03:48:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
03/16/2022 03:48:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=84
03/16/2022 03:48:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=84
03/16/2022 03:48:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
03/16/2022 03:48:26 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.7908023816380276 on epoch=85
03/16/2022 03:48:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
03/16/2022 03:48:31 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=87
03/16/2022 03:48:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
03/16/2022 03:48:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
03/16/2022 03:48:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
03/16/2022 03:48:45 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.8568042774800284 on epoch=89
03/16/2022 03:48:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
03/16/2022 03:48:50 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=90
03/16/2022 03:48:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=91
03/16/2022 03:48:55 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
03/16/2022 03:48:57 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
03/16/2022 03:49:04 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.8670576735092864 on epoch=92
03/16/2022 03:49:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
03/16/2022 03:49:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
03/16/2022 03:49:12 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
03/16/2022 03:49:14 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=95
03/16/2022 03:49:17 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=96
03/16/2022 03:49:23 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.9144868035190616 on epoch=96
03/16/2022 03:49:26 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
03/16/2022 03:49:28 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
03/16/2022 03:49:31 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
03/16/2022 03:49:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=99
03/16/2022 03:49:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=99
03/16/2022 03:49:44 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.9148461574268026 on epoch=99
03/16/2022 03:49:46 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
03/16/2022 03:49:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
03/16/2022 03:49:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
03/16/2022 03:49:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=102
03/16/2022 03:49:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
03/16/2022 03:50:03 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.8631514235092864 on epoch=103
03/16/2022 03:50:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.14 on epoch=104
03/16/2022 03:50:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
03/16/2022 03:50:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
03/16/2022 03:50:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
03/16/2022 03:50:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
03/16/2022 03:50:23 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.9186705767350929 on epoch=107
03/16/2022 03:50:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=107
03/16/2022 03:50:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
03/16/2022 03:50:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=109
03/16/2022 03:50:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
03/16/2022 03:50:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
03/16/2022 03:50:43 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.9186746497230369 on epoch=110
03/16/2022 03:50:45 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=111
03/16/2022 03:50:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
03/16/2022 03:50:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
03/16/2022 03:50:53 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
03/16/2022 03:50:55 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
03/16/2022 03:51:03 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.9066275865184785 on epoch=114
03/16/2022 03:51:05 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
03/16/2022 03:51:08 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
03/16/2022 03:51:10 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
03/16/2022 03:51:13 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
03/16/2022 03:51:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
03/16/2022 03:51:22 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.9065128240934693 on epoch=117
03/16/2022 03:51:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
03/16/2022 03:51:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
03/16/2022 03:51:30 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
03/16/2022 03:51:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
03/16/2022 03:51:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
03/16/2022 03:51:42 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9777840755070358 on epoch=121
03/16/2022 03:51:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
03/16/2022 03:51:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=122
03/16/2022 03:51:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
03/16/2022 03:51:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
03/16/2022 03:51:56 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
03/16/2022 03:52:04 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.910675417772192 on epoch=124
03/16/2022 03:52:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
03/16/2022 03:52:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
03/16/2022 03:52:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
03/16/2022 03:52:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
03/16/2022 03:52:17 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
03/16/2022 03:52:24 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.9780278093642151 on epoch=128
03/16/2022 03:52:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
03/16/2022 03:52:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
03/16/2022 03:52:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
03/16/2022 03:52:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
03/16/2022 03:52:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
03/16/2022 03:52:45 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.98225708905263 on epoch=132
03/16/2022 03:52:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
03/16/2022 03:52:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
03/16/2022 03:52:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
03/16/2022 03:52:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
03/16/2022 03:52:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
03/16/2022 03:53:05 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9144998370804823 on epoch=135
03/16/2022 03:53:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
03/16/2022 03:53:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
03/16/2022 03:53:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
03/16/2022 03:53:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
03/16/2022 03:53:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
03/16/2022 03:53:25 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9865984150258343 on epoch=139
03/16/2022 03:53:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
03/16/2022 03:53:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
03/16/2022 03:53:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
03/16/2022 03:53:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
03/16/2022 03:53:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
03/16/2022 03:53:45 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9777840755070356 on epoch=142
03/16/2022 03:53:48 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
03/16/2022 03:53:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=144
03/16/2022 03:53:53 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
03/16/2022 03:53:56 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
03/16/2022 03:53:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
03/16/2022 03:54:06 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9144998370804823 on epoch=146
03/16/2022 03:54:08 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
03/16/2022 03:54:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
03/16/2022 03:54:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=148
03/16/2022 03:54:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=149
03/16/2022 03:54:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
03/16/2022 03:54:26 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9822527251369758 on epoch=149
03/16/2022 03:54:28 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
03/16/2022 03:54:31 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
03/16/2022 03:54:33 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
03/16/2022 03:54:36 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
03/16/2022 03:54:39 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
03/16/2022 03:54:46 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8514173998044966 on epoch=153
03/16/2022 03:54:48 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
03/16/2022 03:54:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
03/16/2022 03:54:53 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
03/16/2022 03:54:56 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
03/16/2022 03:54:59 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
03/16/2022 03:55:06 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9731661799617208 on epoch=157
03/16/2022 03:55:08 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
03/16/2022 03:55:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
03/16/2022 03:55:14 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
03/16/2022 03:55:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
03/16/2022 03:55:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
03/16/2022 03:55:26 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9144998370804823 on epoch=160
03/16/2022 03:55:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
03/16/2022 03:55:32 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
03/16/2022 03:55:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
03/16/2022 03:55:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
03/16/2022 03:55:40 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
03/16/2022 03:55:47 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9187894121480459 on epoch=164
03/16/2022 03:55:50 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
03/16/2022 03:55:52 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
03/16/2022 03:55:55 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
03/16/2022 03:55:58 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
03/16/2022 03:56:00 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
03/16/2022 03:56:07 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9739096029418614 on epoch=167
03/16/2022 03:56:10 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
03/16/2022 03:56:12 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
03/16/2022 03:56:15 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
03/16/2022 03:56:17 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=170
03/16/2022 03:56:20 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=171
03/16/2022 03:56:27 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.9776567518503005 on epoch=171
03/16/2022 03:56:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
03/16/2022 03:56:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
03/16/2022 03:56:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
03/16/2022 03:56:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
03/16/2022 03:56:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
03/16/2022 03:56:47 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9103290974258716 on epoch=174
03/16/2022 03:56:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
03/16/2022 03:56:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
03/16/2022 03:56:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
03/16/2022 03:56:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
03/16/2022 03:57:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
03/16/2022 03:57:08 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9146186724934355 on epoch=178
03/16/2022 03:57:11 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
03/16/2022 03:57:13 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
03/16/2022 03:57:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
03/16/2022 03:57:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
03/16/2022 03:57:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
03/16/2022 03:57:29 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9776567518503002 on epoch=182
03/16/2022 03:57:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
03/16/2022 03:57:34 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
03/16/2022 03:57:36 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
03/16/2022 03:57:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
03/16/2022 03:57:42 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
03/16/2022 03:57:49 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8592375366568915 on epoch=185
03/16/2022 03:57:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
03/16/2022 03:57:54 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
03/16/2022 03:57:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
03/16/2022 03:57:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
03/16/2022 03:58:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
03/16/2022 03:58:09 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9061378969965309 on epoch=189
03/16/2022 03:58:11 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
03/16/2022 03:58:14 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
03/16/2022 03:58:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
03/16/2022 03:58:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
03/16/2022 03:58:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
03/16/2022 03:58:29 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7992919343000269 on epoch=192
03/16/2022 03:58:32 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
03/16/2022 03:58:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
03/16/2022 03:58:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
03/16/2022 03:58:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
03/16/2022 03:58:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
03/16/2022 03:58:49 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9776567518503005 on epoch=196
03/16/2022 03:58:52 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
03/16/2022 03:58:54 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
03/16/2022 03:58:57 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
03/16/2022 03:58:59 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
03/16/2022 03:59:02 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
03/16/2022 03:59:09 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9821297653958947 on epoch=199
03/16/2022 03:59:12 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
03/16/2022 03:59:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
03/16/2022 03:59:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
03/16/2022 03:59:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
03/16/2022 03:59:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
03/16/2022 03:59:29 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=203
03/16/2022 03:59:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
03/16/2022 03:59:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
03/16/2022 03:59:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
03/16/2022 03:59:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
03/16/2022 03:59:42 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
03/16/2022 03:59:50 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9144998370804823 on epoch=207
03/16/2022 03:59:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
03/16/2022 03:59:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
03/16/2022 03:59:57 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
03/16/2022 04:00:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
03/16/2022 04:00:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
03/16/2022 04:00:09 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9144998370804823 on epoch=210
03/16/2022 04:00:12 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
03/16/2022 04:00:15 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
03/16/2022 04:00:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
03/16/2022 04:00:20 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=213
03/16/2022 04:00:22 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
03/16/2022 04:00:30 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.855196878054741 on epoch=214
03/16/2022 04:00:30 - INFO - __main__ - save last model!
03/16/2022 04:00:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
03/16/2022 04:00:30 - INFO - __main__ - Start tokenizing ... 3500 instances
03/16/2022 04:00:30 - INFO - __main__ - Printing 3 examples
03/16/2022 04:00:30 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
03/16/2022 04:00:30 - INFO - __main__ - ['Animal']
03/16/2022 04:00:30 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
03/16/2022 04:00:30 - INFO - __main__ - ['Animal']
03/16/2022 04:00:30 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
03/16/2022 04:00:30 - INFO - __main__ - ['Village']
03/16/2022 04:00:30 - INFO - __main__ - Tokenizing Input ...
03/16/2022 04:00:31 - INFO - __main__ - Tokenizing Output ...
03/16/2022 04:00:35 - INFO - __main__ - Loaded 3500 examples from test data
03/16/2022 04:02:44 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
03/16/2022 04:02:44 - INFO - __main__ - Classification-F1 on test data: 0.5912
03/16/2022 04:02:44 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.9865984150258343, test_performance=0.59117593987898
