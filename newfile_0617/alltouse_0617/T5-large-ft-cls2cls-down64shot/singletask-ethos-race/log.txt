05/21/2022 21:29:04 - INFO - __main__ - Namespace(task_dir='data_64/ethos-race/', task_name='ethos-race', identifier='T5-large-ft-cls2cls-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/21/2022 21:29:04 - INFO - __main__ - models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race
05/21/2022 21:29:04 - INFO - __main__ - Namespace(task_dir='data_64/ethos-race/', task_name='ethos-race', identifier='T5-large-ft-cls2cls-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/21/2022 21:29:04 - INFO - __main__ - models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race
05/21/2022 21:29:06 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:29:06 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:29:06 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:29:06 - INFO - __main__ - Using 2 gpus
05/21/2022 21:29:06 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:29:06 - INFO - __main__ - Using 2 gpus
05/21/2022 21:29:06 - INFO - __main__ - Fine-tuning the following samples: ['ethos-race_64_100', 'ethos-race_64_13', 'ethos-race_64_21', 'ethos-race_64_42', 'ethos-race_64_87']
05/21/2022 21:29:06 - INFO - __main__ - Fine-tuning the following samples: ['ethos-race_64_100', 'ethos-race_64_13', 'ethos-race_64_21', 'ethos-race_64_42', 'ethos-race_64_87']
05/21/2022 21:29:11 - INFO - __main__ - Running ... prefix=ethos-race_64_100, lr=0.0005, bsz=8 ...
06/03/2022 03:42:11 - INFO - __main__ - Namespace(task_dir='data_64/ethos-race/', task_name='ethos-race', identifier='T5-large-ft-cls2cls-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
06/03/2022 03:42:11 - INFO - __main__ - models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race
06/03/2022 03:42:11 - INFO - __main__ - Namespace(task_dir='data_64/ethos-race/', task_name='ethos-race', identifier='T5-large-ft-cls2cls-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
06/03/2022 03:42:11 - INFO - __main__ - models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race
06/03/2022 03:42:13 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/03/2022 03:42:13 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/03/2022 03:42:13 - INFO - __main__ - args.device: cuda:0
06/03/2022 03:42:13 - INFO - __main__ - args.device: cuda:1
06/03/2022 03:42:13 - INFO - __main__ - Using 2 gpus
06/03/2022 03:42:13 - INFO - __main__ - Using 2 gpus
06/03/2022 03:42:13 - INFO - __main__ - Fine-tuning the following samples: ['ethos-race_64_100', 'ethos-race_64_13', 'ethos-race_64_21', 'ethos-race_64_42', 'ethos-race_64_87']
06/03/2022 03:42:13 - INFO - __main__ - Fine-tuning the following samples: ['ethos-race_64_100', 'ethos-race_64_13', 'ethos-race_64_21', 'ethos-race_64_42', 'ethos-race_64_87']
06/03/2022 03:42:17 - INFO - __main__ - Running ... prefix=ethos-race_64_100, lr=0.0005, bsz=8 ...
06/03/2022 03:42:18 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 03:42:18 - INFO - __main__ - Printing 3 examples
06/03/2022 03:42:18 - INFO - __main__ -  [ethos-race] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
06/03/2022 03:42:18 - INFO - __main__ - ['false']
06/03/2022 03:42:18 - INFO - __main__ -  [ethos-race] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
06/03/2022 03:42:18 - INFO - __main__ - ['false']
06/03/2022 03:42:18 - INFO - __main__ -  [ethos-race] an Asian Moe Howard piece of shit
06/03/2022 03:42:18 - INFO - __main__ - ['false']
06/03/2022 03:42:18 - INFO - __main__ - Tokenizing Input ...
06/03/2022 03:42:18 - INFO - __main__ - Tokenizing Output ...
06/03/2022 03:42:18 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 03:42:18 - INFO - __main__ - Printing 3 examples
06/03/2022 03:42:18 - INFO - __main__ -  [ethos-race] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
06/03/2022 03:42:18 - INFO - __main__ - ['false']
06/03/2022 03:42:18 - INFO - __main__ -  [ethos-race] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
06/03/2022 03:42:18 - INFO - __main__ - ['false']
06/03/2022 03:42:18 - INFO - __main__ -  [ethos-race] an Asian Moe Howard piece of shit
06/03/2022 03:42:18 - INFO - __main__ - ['false']
06/03/2022 03:42:18 - INFO - __main__ - Tokenizing Input ...
06/03/2022 03:42:18 - INFO - __main__ - Tokenizing Output ...
06/03/2022 03:42:18 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 03:42:18 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 03:42:18 - INFO - __main__ - Printing 3 examples
06/03/2022 03:42:18 - INFO - __main__ -  [ethos-race] Humans with third leg I hope to distinct soon, with much love
06/03/2022 03:42:18 - INFO - __main__ - ['false']
06/03/2022 03:42:18 - INFO - __main__ -  [ethos-race] Time to nuke China or Unleash a plague.
06/03/2022 03:42:18 - INFO - __main__ - ['false']
06/03/2022 03:42:18 - INFO - __main__ -  [ethos-race] You should be so meaner to dyslexic people.
06/03/2022 03:42:18 - INFO - __main__ - ['false']
06/03/2022 03:42:18 - INFO - __main__ - Tokenizing Input ...
06/03/2022 03:42:18 - INFO - __main__ - Tokenizing Output ...
06/03/2022 03:42:18 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 03:42:18 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 03:42:18 - INFO - __main__ - Printing 3 examples
06/03/2022 03:42:18 - INFO - __main__ -  [ethos-race] Humans with third leg I hope to distinct soon, with much love
06/03/2022 03:42:18 - INFO - __main__ - ['false']
06/03/2022 03:42:18 - INFO - __main__ -  [ethos-race] Time to nuke China or Unleash a plague.
06/03/2022 03:42:18 - INFO - __main__ - ['false']
06/03/2022 03:42:18 - INFO - __main__ -  [ethos-race] You should be so meaner to dyslexic people.
06/03/2022 03:42:18 - INFO - __main__ - ['false']
06/03/2022 03:42:18 - INFO - __main__ - Tokenizing Input ...
06/03/2022 03:42:18 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 03:42:19 - INFO - __main__ - Tokenizing Output ...
06/03/2022 03:42:19 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 03:42:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 03:42:32 - INFO - __main__ - Starting training!
06/03/2022 03:42:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 03:42:32 - INFO - __main__ - Starting training!
06/03/2022 03:42:37 - INFO - __main__ - Step 10 Global step 10 Train loss 23.543854 on epoch=1
06/03/2022 03:42:42 - INFO - __main__ - Step 20 Global step 20 Train loss 19.004707 on epoch=2
06/03/2022 03:42:47 - INFO - __main__ - Step 30 Global step 30 Train loss 16.279520 on epoch=3
06/03/2022 03:42:52 - INFO - __main__ - Step 40 Global step 40 Train loss 13.297793 on epoch=4
06/03/2022 03:42:57 - INFO - __main__ - Step 50 Global step 50 Train loss 10.685351 on epoch=6
06/03/2022 03:43:07 - INFO - __main__ - Global step 50 Train loss 16.562246 Classification-F1 0.0 on epoch=6
06/03/2022 03:43:12 - INFO - __main__ - Step 60 Global step 60 Train loss 5.950047 on epoch=7
06/03/2022 03:43:17 - INFO - __main__ - Step 70 Global step 70 Train loss 3.641698 on epoch=8
06/03/2022 03:43:22 - INFO - __main__ - Step 80 Global step 80 Train loss 2.951114 on epoch=9
06/03/2022 03:43:28 - INFO - __main__ - Step 90 Global step 90 Train loss 2.363757 on epoch=11
06/03/2022 03:43:33 - INFO - __main__ - Step 100 Global step 100 Train loss 0.743500 on epoch=12
06/03/2022 03:43:33 - INFO - __main__ - Global step 100 Train loss 3.130023 Classification-F1 1.0 on epoch=12
06/03/2022 03:43:40 - INFO - __main__ - Step 110 Global step 110 Train loss 0.529727 on epoch=13
06/03/2022 03:43:45 - INFO - __main__ - Step 120 Global step 120 Train loss 0.543290 on epoch=14
06/03/2022 03:43:50 - INFO - __main__ - Step 130 Global step 130 Train loss 0.369880 on epoch=16
06/03/2022 03:43:55 - INFO - __main__ - Step 140 Global step 140 Train loss 0.419256 on epoch=17
06/03/2022 03:44:00 - INFO - __main__ - Step 150 Global step 150 Train loss 0.438302 on epoch=18
06/03/2022 03:44:01 - INFO - __main__ - Global step 150 Train loss 0.460091 Classification-F1 0.4576271186440678 on epoch=18
06/03/2022 03:44:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.378520 on epoch=19
06/03/2022 03:44:11 - INFO - __main__ - Step 170 Global step 170 Train loss 0.392465 on epoch=21
06/03/2022 03:44:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.341053 on epoch=22
06/03/2022 03:44:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.321870 on epoch=23
06/03/2022 03:44:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.374981 on epoch=24
06/03/2022 03:44:27 - INFO - __main__ - Global step 200 Train loss 0.361778 Classification-F1 0.49606299212598426 on epoch=24
06/03/2022 03:44:32 - INFO - __main__ - Step 210 Global step 210 Train loss 0.229238 on epoch=26
06/03/2022 03:44:37 - INFO - __main__ - Step 220 Global step 220 Train loss 0.292336 on epoch=27
06/03/2022 03:44:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.220636 on epoch=28
06/03/2022 03:44:47 - INFO - __main__ - Step 240 Global step 240 Train loss 0.193790 on epoch=29
06/03/2022 03:44:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.142417 on epoch=31
06/03/2022 03:44:53 - INFO - __main__ - Global step 250 Train loss 0.215683 Classification-F1 0.4838709677419355 on epoch=31
06/03/2022 03:44:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.202961 on epoch=32
06/03/2022 03:45:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.166614 on epoch=33
06/03/2022 03:45:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.100414 on epoch=34
06/03/2022 03:45:13 - INFO - __main__ - Step 290 Global step 290 Train loss 0.057776 on epoch=36
06/03/2022 03:45:18 - INFO - __main__ - Step 300 Global step 300 Train loss 0.125704 on epoch=37
06/03/2022 03:45:19 - INFO - __main__ - Global step 300 Train loss 0.130694 Classification-F1 0.41284403669724773 on epoch=37
06/03/2022 03:45:24 - INFO - __main__ - Step 310 Global step 310 Train loss 0.086348 on epoch=38
06/03/2022 03:45:29 - INFO - __main__ - Step 320 Global step 320 Train loss 0.087400 on epoch=39
06/03/2022 03:45:34 - INFO - __main__ - Step 330 Global step 330 Train loss 0.079709 on epoch=41
06/03/2022 03:45:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.180381 on epoch=42
06/03/2022 03:45:45 - INFO - __main__ - Step 350 Global step 350 Train loss 0.050367 on epoch=43
06/03/2022 03:45:45 - INFO - __main__ - Global step 350 Train loss 0.096841 Classification-F1 0.4666666666666667 on epoch=43
06/03/2022 03:45:50 - INFO - __main__ - Step 360 Global step 360 Train loss 0.049236 on epoch=44
06/03/2022 03:45:55 - INFO - __main__ - Step 370 Global step 370 Train loss 0.028262 on epoch=46
06/03/2022 03:46:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.038677 on epoch=47
06/03/2022 03:46:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.093031 on epoch=48
06/03/2022 03:46:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.071450 on epoch=49
06/03/2022 03:46:11 - INFO - __main__ - Global step 400 Train loss 0.056131 Classification-F1 0.488 on epoch=49
06/03/2022 03:46:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.071341 on epoch=51
06/03/2022 03:46:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.061688 on epoch=52
06/03/2022 03:46:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.048426 on epoch=53
06/03/2022 03:46:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.021674 on epoch=54
06/03/2022 03:46:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.031981 on epoch=56
06/03/2022 03:46:37 - INFO - __main__ - Global step 450 Train loss 0.047022 Classification-F1 0.4796747967479675 on epoch=56
06/03/2022 03:46:42 - INFO - __main__ - Step 460 Global step 460 Train loss 0.019037 on epoch=57
06/03/2022 03:46:48 - INFO - __main__ - Step 470 Global step 470 Train loss 0.033199 on epoch=58
06/03/2022 03:46:53 - INFO - __main__ - Step 480 Global step 480 Train loss 0.010904 on epoch=59
06/03/2022 03:46:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.009138 on epoch=61
06/03/2022 03:47:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.003489 on epoch=62
06/03/2022 03:47:04 - INFO - __main__ - Global step 500 Train loss 0.015153 Classification-F1 0.488 on epoch=62
06/03/2022 03:47:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.007658 on epoch=63
06/03/2022 03:47:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.005958 on epoch=64
06/03/2022 03:47:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.002395 on epoch=66
06/03/2022 03:47:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.030718 on epoch=67
06/03/2022 03:47:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.031992 on epoch=68
06/03/2022 03:47:29 - INFO - __main__ - Global step 550 Train loss 0.015745 Classification-F1 0.4482758620689655 on epoch=68
06/03/2022 03:47:34 - INFO - __main__ - Step 560 Global step 560 Train loss 0.013901 on epoch=69
06/03/2022 03:47:40 - INFO - __main__ - Step 570 Global step 570 Train loss 0.003754 on epoch=71
06/03/2022 03:47:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.003470 on epoch=72
06/03/2022 03:47:50 - INFO - __main__ - Step 590 Global step 590 Train loss 0.001206 on epoch=73
06/03/2022 03:47:55 - INFO - __main__ - Step 600 Global step 600 Train loss 0.012347 on epoch=74
06/03/2022 03:47:55 - INFO - __main__ - Global step 600 Train loss 0.006936 Classification-F1 0.4796747967479675 on epoch=74
06/03/2022 03:48:00 - INFO - __main__ - Step 610 Global step 610 Train loss 0.008329 on epoch=76
06/03/2022 03:48:05 - INFO - __main__ - Step 620 Global step 620 Train loss 0.002878 on epoch=77
06/03/2022 03:48:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.001827 on epoch=78
06/03/2022 03:48:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.087860 on epoch=79
06/03/2022 03:48:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.059245 on epoch=81
06/03/2022 03:48:21 - INFO - __main__ - Global step 650 Train loss 0.032028 Classification-F1 0.47540983606557374 on epoch=81
06/03/2022 03:48:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.016436 on epoch=82
06/03/2022 03:48:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.003602 on epoch=83
06/03/2022 03:48:37 - INFO - __main__ - Step 680 Global step 680 Train loss 0.030119 on epoch=84
06/03/2022 03:48:42 - INFO - __main__ - Step 690 Global step 690 Train loss 0.035972 on epoch=86
06/03/2022 03:48:47 - INFO - __main__ - Step 700 Global step 700 Train loss 0.007537 on epoch=87
06/03/2022 03:48:47 - INFO - __main__ - Global step 700 Train loss 0.018733 Classification-F1 0.488 on epoch=87
06/03/2022 03:48:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.002138 on epoch=88
06/03/2022 03:48:58 - INFO - __main__ - Step 720 Global step 720 Train loss 0.042247 on epoch=89
06/03/2022 03:49:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.002850 on epoch=91
06/03/2022 03:49:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.001522 on epoch=92
06/03/2022 03:49:13 - INFO - __main__ - Step 750 Global step 750 Train loss 0.058024 on epoch=93
06/03/2022 03:49:14 - INFO - __main__ - Global step 750 Train loss 0.021356 Classification-F1 0.4838709677419355 on epoch=93
06/03/2022 03:49:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.001047 on epoch=94
06/03/2022 03:49:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000867 on epoch=96
06/03/2022 03:49:29 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000314 on epoch=97
06/03/2022 03:49:34 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000605 on epoch=98
06/03/2022 03:49:39 - INFO - __main__ - Step 800 Global step 800 Train loss 0.007339 on epoch=99
06/03/2022 03:49:40 - INFO - __main__ - Global step 800 Train loss 0.002034 Classification-F1 0.4838709677419355 on epoch=99
06/03/2022 03:49:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000392 on epoch=101
06/03/2022 03:49:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000788 on epoch=102
06/03/2022 03:49:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000432 on epoch=103
06/03/2022 03:50:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000366 on epoch=104
06/03/2022 03:50:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000224 on epoch=106
06/03/2022 03:50:06 - INFO - __main__ - Global step 850 Train loss 0.000440 Classification-F1 0.4838709677419355 on epoch=106
06/03/2022 03:50:11 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000133 on epoch=107
06/03/2022 03:50:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000153 on epoch=108
06/03/2022 03:50:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000182 on epoch=109
06/03/2022 03:50:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.047485 on epoch=111
06/03/2022 03:50:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.002836 on epoch=112
06/03/2022 03:50:32 - INFO - __main__ - Global step 900 Train loss 0.010158 Classification-F1 0.49206349206349204 on epoch=112
06/03/2022 03:50:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000319 on epoch=113
06/03/2022 03:50:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000094 on epoch=114
06/03/2022 03:50:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000410 on epoch=116
06/03/2022 03:50:53 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000082 on epoch=117
06/03/2022 03:50:58 - INFO - __main__ - Step 950 Global step 950 Train loss 0.003096 on epoch=118
06/03/2022 03:50:58 - INFO - __main__ - Global step 950 Train loss 0.000800 Classification-F1 0.47540983606557374 on epoch=118
06/03/2022 03:51:03 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000263 on epoch=119
06/03/2022 03:51:08 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000349 on epoch=121
06/03/2022 03:51:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.003409 on epoch=122
06/03/2022 03:51:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000626 on epoch=123
06/03/2022 03:51:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000105 on epoch=124
06/03/2022 03:51:24 - INFO - __main__ - Global step 1000 Train loss 0.000950 Classification-F1 0.4796747967479675 on epoch=124
06/03/2022 03:51:24 - INFO - __main__ - save last model!
06/03/2022 03:51:25 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 03:51:25 - INFO - __main__ - Printing 3 examples
06/03/2022 03:51:25 - INFO - __main__ -  [ethos-race] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
06/03/2022 03:51:25 - INFO - __main__ - ['false']
06/03/2022 03:51:25 - INFO - __main__ -  [ethos-race] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
06/03/2022 03:51:25 - INFO - __main__ - ['false']
06/03/2022 03:51:25 - INFO - __main__ -  [ethos-race] an Asian Moe Howard piece of shit
06/03/2022 03:51:25 - INFO - __main__ - ['false']
06/03/2022 03:51:25 - INFO - __main__ - Tokenizing Input ...
06/03/2022 03:51:25 - INFO - __main__ - Tokenizing Output ...
06/03/2022 03:51:25 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 03:51:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 03:51:25 - INFO - __main__ - Printing 3 examples
06/03/2022 03:51:25 - INFO - __main__ -  [ethos-race] Humans with third leg I hope to distinct soon, with much love
06/03/2022 03:51:25 - INFO - __main__ - ['false']
06/03/2022 03:51:25 - INFO - __main__ -  [ethos-race] Time to nuke China or Unleash a plague.
06/03/2022 03:51:25 - INFO - __main__ - ['false']
06/03/2022 03:51:25 - INFO - __main__ -  [ethos-race] You should be so meaner to dyslexic people.
06/03/2022 03:51:25 - INFO - __main__ - ['false']
06/03/2022 03:51:25 - INFO - __main__ - Tokenizing Input ...
06/03/2022 03:51:25 - INFO - __main__ - Tokenizing Output ...
06/03/2022 03:51:25 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 03:51:31 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 03:51:32 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 03:51:32 - INFO - __main__ - Printing 3 examples
06/03/2022 03:51:32 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 03:51:32 - INFO - __main__ - ['true']
06/03/2022 03:51:32 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 03:51:32 - INFO - __main__ - ['false']
06/03/2022 03:51:32 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 03:51:32 - INFO - __main__ - ['false']
06/03/2022 03:51:32 - INFO - __main__ - Tokenizing Input ...
06/03/2022 03:51:32 - INFO - __main__ - Tokenizing Output ...
06/03/2022 03:51:32 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 03:51:33 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_100_0.0005_8_predictions.txt
06/03/2022 03:51:33 - INFO - __main__ - Classification-F1 on test data: 0.4494
06/03/2022 03:51:34 - INFO - __main__ - prefix=ethos-race_64_100, lr=0.0005, bsz=8, dev_performance=1.0, test_performance=0.44936708860759494
06/03/2022 03:51:34 - INFO - __main__ - Running ... prefix=ethos-race_64_100, lr=0.0003, bsz=8 ...
06/03/2022 03:51:35 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 03:51:35 - INFO - __main__ - Printing 3 examples
06/03/2022 03:51:35 - INFO - __main__ -  [ethos-race] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
06/03/2022 03:51:35 - INFO - __main__ - ['false']
06/03/2022 03:51:35 - INFO - __main__ -  [ethos-race] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
06/03/2022 03:51:35 - INFO - __main__ - ['false']
06/03/2022 03:51:35 - INFO - __main__ -  [ethos-race] an Asian Moe Howard piece of shit
06/03/2022 03:51:35 - INFO - __main__ - ['false']
06/03/2022 03:51:35 - INFO - __main__ - Tokenizing Input ...
06/03/2022 03:51:35 - INFO - __main__ - Tokenizing Output ...
06/03/2022 03:51:35 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 03:51:35 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 03:51:35 - INFO - __main__ - Printing 3 examples
06/03/2022 03:51:35 - INFO - __main__ -  [ethos-race] Humans with third leg I hope to distinct soon, with much love
06/03/2022 03:51:35 - INFO - __main__ - ['false']
06/03/2022 03:51:35 - INFO - __main__ -  [ethos-race] Time to nuke China or Unleash a plague.
06/03/2022 03:51:35 - INFO - __main__ - ['false']
06/03/2022 03:51:35 - INFO - __main__ -  [ethos-race] You should be so meaner to dyslexic people.
06/03/2022 03:51:35 - INFO - __main__ - ['false']
06/03/2022 03:51:35 - INFO - __main__ - Tokenizing Input ...
06/03/2022 03:51:35 - INFO - __main__ - Tokenizing Output ...
06/03/2022 03:51:35 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 03:51:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 03:51:38 - INFO - __main__ - Starting training!
06/03/2022 03:51:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 03:51:46 - INFO - __main__ - Starting training!
06/03/2022 03:51:50 - INFO - __main__ - Step 10 Global step 10 Train loss 24.168278 on epoch=1
06/03/2022 03:51:55 - INFO - __main__ - Step 20 Global step 20 Train loss 18.657833 on epoch=2
06/03/2022 03:52:00 - INFO - __main__ - Step 30 Global step 30 Train loss 16.892061 on epoch=3
06/03/2022 03:52:05 - INFO - __main__ - Step 40 Global step 40 Train loss 16.596161 on epoch=4
06/03/2022 03:52:10 - INFO - __main__ - Step 50 Global step 50 Train loss 15.274381 on epoch=6
06/03/2022 03:52:13 - INFO - __main__ - Global step 50 Train loss 18.317743 Classification-F1 0.0 on epoch=6
06/03/2022 03:52:19 - INFO - __main__ - Step 60 Global step 60 Train loss 14.192423 on epoch=7
06/03/2022 03:52:24 - INFO - __main__ - Step 70 Global step 70 Train loss 13.221258 on epoch=8
06/03/2022 03:52:29 - INFO - __main__ - Step 80 Global step 80 Train loss 12.243764 on epoch=9
06/03/2022 03:52:34 - INFO - __main__ - Step 90 Global step 90 Train loss 8.168242 on epoch=11
06/03/2022 03:52:39 - INFO - __main__ - Step 100 Global step 100 Train loss 3.914080 on epoch=12
06/03/2022 03:52:39 - INFO - __main__ - Global step 100 Train loss 10.347953 Classification-F1 0.020202020202020204 on epoch=12
06/03/2022 03:52:46 - INFO - __main__ - Step 110 Global step 110 Train loss 1.658651 on epoch=13
06/03/2022 03:52:51 - INFO - __main__ - Step 120 Global step 120 Train loss 0.658390 on epoch=14
06/03/2022 03:52:56 - INFO - __main__ - Step 130 Global step 130 Train loss 0.533012 on epoch=16
06/03/2022 03:53:02 - INFO - __main__ - Step 140 Global step 140 Train loss 0.448714 on epoch=17
06/03/2022 03:53:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.497181 on epoch=18
06/03/2022 03:53:08 - INFO - __main__ - Global step 150 Train loss 0.759190 Classification-F1 0.058823529411764705 on epoch=18
06/03/2022 03:53:14 - INFO - __main__ - Step 160 Global step 160 Train loss 0.473427 on epoch=19
06/03/2022 03:53:19 - INFO - __main__ - Step 170 Global step 170 Train loss 0.382661 on epoch=21
06/03/2022 03:53:24 - INFO - __main__ - Step 180 Global step 180 Train loss 0.363118 on epoch=22
06/03/2022 03:53:29 - INFO - __main__ - Step 190 Global step 190 Train loss 0.301118 on epoch=23
06/03/2022 03:53:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.447101 on epoch=24
06/03/2022 03:53:35 - INFO - __main__ - Global step 200 Train loss 0.393485 Classification-F1 0.49206349206349204 on epoch=24
06/03/2022 03:53:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.345820 on epoch=26
06/03/2022 03:53:46 - INFO - __main__ - Step 220 Global step 220 Train loss 0.256345 on epoch=27
06/03/2022 03:53:51 - INFO - __main__ - Step 230 Global step 230 Train loss 0.248116 on epoch=28
06/03/2022 03:53:57 - INFO - __main__ - Step 240 Global step 240 Train loss 0.173837 on epoch=29
06/03/2022 03:54:02 - INFO - __main__ - Step 250 Global step 250 Train loss 0.142133 on epoch=31
06/03/2022 03:54:03 - INFO - __main__ - Global step 250 Train loss 0.233250 Classification-F1 0.488 on epoch=31
06/03/2022 03:54:08 - INFO - __main__ - Step 260 Global step 260 Train loss 0.203519 on epoch=32
06/03/2022 03:54:13 - INFO - __main__ - Step 270 Global step 270 Train loss 0.143343 on epoch=33
06/03/2022 03:54:18 - INFO - __main__ - Step 280 Global step 280 Train loss 0.108825 on epoch=34
06/03/2022 03:54:23 - INFO - __main__ - Step 290 Global step 290 Train loss 0.123431 on epoch=36
06/03/2022 03:54:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.137369 on epoch=37
06/03/2022 03:54:29 - INFO - __main__ - Global step 300 Train loss 0.143297 Classification-F1 0.47107438016528924 on epoch=37
06/03/2022 03:54:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.088166 on epoch=38
06/03/2022 03:54:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.070790 on epoch=39
06/03/2022 03:54:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.052479 on epoch=41
06/03/2022 03:54:50 - INFO - __main__ - Step 340 Global step 340 Train loss 0.071746 on epoch=42
06/03/2022 03:54:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.081646 on epoch=43
06/03/2022 03:54:56 - INFO - __main__ - Global step 350 Train loss 0.072965 Classification-F1 0.4796747967479675 on epoch=43
06/03/2022 03:55:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.047948 on epoch=44
06/03/2022 03:55:06 - INFO - __main__ - Step 370 Global step 370 Train loss 0.034633 on epoch=46
06/03/2022 03:55:11 - INFO - __main__ - Step 380 Global step 380 Train loss 0.036621 on epoch=47
06/03/2022 03:55:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.041712 on epoch=48
06/03/2022 03:55:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.039934 on epoch=49
06/03/2022 03:55:22 - INFO - __main__ - Global step 400 Train loss 0.040170 Classification-F1 0.4796747967479675 on epoch=49
06/03/2022 03:55:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.014932 on epoch=51
06/03/2022 03:55:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.041820 on epoch=52
06/03/2022 03:55:37 - INFO - __main__ - Step 430 Global step 430 Train loss 0.050787 on epoch=53
06/03/2022 03:55:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.009312 on epoch=54
06/03/2022 03:55:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.015207 on epoch=56
06/03/2022 03:55:48 - INFO - __main__ - Global step 450 Train loss 0.026411 Classification-F1 0.4666666666666667 on epoch=56
06/03/2022 03:55:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.011245 on epoch=57
06/03/2022 03:55:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.012509 on epoch=58
06/03/2022 03:56:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.004577 on epoch=59
06/03/2022 03:56:09 - INFO - __main__ - Step 490 Global step 490 Train loss 0.002517 on epoch=61
06/03/2022 03:56:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.001062 on epoch=62
06/03/2022 03:56:15 - INFO - __main__ - Global step 500 Train loss 0.006382 Classification-F1 0.46218487394957986 on epoch=62
06/03/2022 03:56:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.001872 on epoch=63
06/03/2022 03:56:25 - INFO - __main__ - Step 520 Global step 520 Train loss 0.008301 on epoch=64
06/03/2022 03:56:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.007770 on epoch=66
06/03/2022 03:56:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.015752 on epoch=67
06/03/2022 03:56:41 - INFO - __main__ - Step 550 Global step 550 Train loss 0.020173 on epoch=68
06/03/2022 03:56:41 - INFO - __main__ - Global step 550 Train loss 0.010774 Classification-F1 0.4666666666666667 on epoch=68
06/03/2022 03:56:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.004563 on epoch=69
06/03/2022 03:56:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.005187 on epoch=71
06/03/2022 03:56:57 - INFO - __main__ - Step 580 Global step 580 Train loss 0.000714 on epoch=72
06/03/2022 03:57:02 - INFO - __main__ - Step 590 Global step 590 Train loss 0.005656 on epoch=73
06/03/2022 03:57:07 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000258 on epoch=74
06/03/2022 03:57:08 - INFO - __main__ - Global step 600 Train loss 0.003276 Classification-F1 0.36 on epoch=74
06/03/2022 03:57:13 - INFO - __main__ - Step 610 Global step 610 Train loss 0.007090 on epoch=76
06/03/2022 03:57:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.000303 on epoch=77
06/03/2022 03:57:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.000294 on epoch=78
06/03/2022 03:57:28 - INFO - __main__ - Step 640 Global step 640 Train loss 0.000601 on epoch=79
06/03/2022 03:57:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000082 on epoch=81
06/03/2022 03:57:34 - INFO - __main__ - Global step 650 Train loss 0.001674 Classification-F1 0.4838709677419355 on epoch=81
06/03/2022 03:57:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000162 on epoch=82
06/03/2022 03:57:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.002227 on epoch=83
06/03/2022 03:57:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.002785 on epoch=84
06/03/2022 03:57:55 - INFO - __main__ - Step 690 Global step 690 Train loss 0.018191 on epoch=86
06/03/2022 03:58:00 - INFO - __main__ - Step 700 Global step 700 Train loss 0.005033 on epoch=87
06/03/2022 03:58:01 - INFO - __main__ - Global step 700 Train loss 0.005680 Classification-F1 0.4666666666666667 on epoch=87
06/03/2022 03:58:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000050 on epoch=88
06/03/2022 03:58:11 - INFO - __main__ - Step 720 Global step 720 Train loss 0.001758 on epoch=89
06/03/2022 03:58:16 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000742 on epoch=91
06/03/2022 03:58:21 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000107 on epoch=92
06/03/2022 03:58:27 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000677 on epoch=93
06/03/2022 03:58:27 - INFO - __main__ - Global step 750 Train loss 0.000667 Classification-F1 0.4796747967479675 on epoch=93
06/03/2022 03:58:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.002952 on epoch=94
06/03/2022 03:58:38 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000045 on epoch=96
06/03/2022 03:58:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000185 on epoch=97
06/03/2022 03:58:48 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000081 on epoch=98
06/03/2022 03:58:53 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000021 on epoch=99
06/03/2022 03:58:54 - INFO - __main__ - Global step 800 Train loss 0.000657 Classification-F1 0.46218487394957986 on epoch=99
06/03/2022 03:58:59 - INFO - __main__ - Step 810 Global step 810 Train loss 0.006386 on epoch=101
06/03/2022 03:59:04 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000404 on epoch=102
06/03/2022 03:59:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000283 on epoch=103
06/03/2022 03:59:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000560 on epoch=104
06/03/2022 03:59:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000161 on epoch=106
06/03/2022 03:59:20 - INFO - __main__ - Global step 850 Train loss 0.001559 Classification-F1 0.4666666666666667 on epoch=106
06/03/2022 03:59:26 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000082 on epoch=107
06/03/2022 03:59:31 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000087 on epoch=108
06/03/2022 03:59:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000057 on epoch=109
06/03/2022 03:59:41 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000042 on epoch=111
06/03/2022 03:59:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000156 on epoch=112
06/03/2022 03:59:47 - INFO - __main__ - Global step 900 Train loss 0.000085 Classification-F1 0.452991452991453 on epoch=112
06/03/2022 03:59:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000534 on epoch=113
06/03/2022 03:59:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000152 on epoch=114
06/03/2022 04:00:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000118 on epoch=116
06/03/2022 04:00:08 - INFO - __main__ - Step 940 Global step 940 Train loss 0.001456 on epoch=117
06/03/2022 04:00:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000220 on epoch=118
06/03/2022 04:00:14 - INFO - __main__ - Global step 950 Train loss 0.000496 Classification-F1 0.4838709677419355 on epoch=118
06/03/2022 04:00:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.001369 on epoch=119
06/03/2022 04:00:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000210 on epoch=121
06/03/2022 04:00:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000059 on epoch=122
06/03/2022 04:00:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000312 on epoch=123
06/03/2022 04:00:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000220 on epoch=124
06/03/2022 04:00:40 - INFO - __main__ - Global step 1000 Train loss 0.000434 Classification-F1 0.4576271186440678 on epoch=124
06/03/2022 04:00:40 - INFO - __main__ - save last model!
06/03/2022 04:00:41 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 04:00:41 - INFO - __main__ - Printing 3 examples
06/03/2022 04:00:41 - INFO - __main__ -  [ethos-race] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
06/03/2022 04:00:41 - INFO - __main__ - ['false']
06/03/2022 04:00:41 - INFO - __main__ -  [ethos-race] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
06/03/2022 04:00:41 - INFO - __main__ - ['false']
06/03/2022 04:00:41 - INFO - __main__ -  [ethos-race] an Asian Moe Howard piece of shit
06/03/2022 04:00:41 - INFO - __main__ - ['false']
06/03/2022 04:00:41 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:00:41 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:00:41 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 04:00:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 04:00:41 - INFO - __main__ - Printing 3 examples
06/03/2022 04:00:41 - INFO - __main__ -  [ethos-race] Humans with third leg I hope to distinct soon, with much love
06/03/2022 04:00:41 - INFO - __main__ - ['false']
06/03/2022 04:00:41 - INFO - __main__ -  [ethos-race] Time to nuke China or Unleash a plague.
06/03/2022 04:00:41 - INFO - __main__ - ['false']
06/03/2022 04:00:41 - INFO - __main__ -  [ethos-race] You should be so meaner to dyslexic people.
06/03/2022 04:00:41 - INFO - __main__ - ['false']
06/03/2022 04:00:41 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:00:41 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:00:41 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 04:00:47 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 04:00:48 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 04:00:48 - INFO - __main__ - Printing 3 examples
06/03/2022 04:00:48 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 04:00:48 - INFO - __main__ - ['true']
06/03/2022 04:00:48 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 04:00:48 - INFO - __main__ - ['false']
06/03/2022 04:00:48 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 04:00:48 - INFO - __main__ - ['false']
06/03/2022 04:00:48 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:00:48 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:00:48 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 04:00:50 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_100_0.0003_8_predictions.txt
06/03/2022 04:00:50 - INFO - __main__ - Classification-F1 on test data: 0.6497
06/03/2022 04:00:50 - INFO - __main__ - prefix=ethos-race_64_100, lr=0.0003, bsz=8, dev_performance=0.49206349206349204, test_performance=0.6496644295302013
06/03/2022 04:00:50 - INFO - __main__ - Running ... prefix=ethos-race_64_100, lr=0.0002, bsz=8 ...
06/03/2022 04:00:51 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 04:00:51 - INFO - __main__ - Printing 3 examples
06/03/2022 04:00:51 - INFO - __main__ -  [ethos-race] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
06/03/2022 04:00:51 - INFO - __main__ - ['false']
06/03/2022 04:00:51 - INFO - __main__ -  [ethos-race] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
06/03/2022 04:00:51 - INFO - __main__ - ['false']
06/03/2022 04:00:51 - INFO - __main__ -  [ethos-race] an Asian Moe Howard piece of shit
06/03/2022 04:00:51 - INFO - __main__ - ['false']
06/03/2022 04:00:51 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:00:51 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:00:51 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 04:00:51 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 04:00:51 - INFO - __main__ - Printing 3 examples
06/03/2022 04:00:51 - INFO - __main__ -  [ethos-race] Humans with third leg I hope to distinct soon, with much love
06/03/2022 04:00:51 - INFO - __main__ - ['false']
06/03/2022 04:00:51 - INFO - __main__ -  [ethos-race] Time to nuke China or Unleash a plague.
06/03/2022 04:00:51 - INFO - __main__ - ['false']
06/03/2022 04:00:51 - INFO - __main__ -  [ethos-race] You should be so meaner to dyslexic people.
06/03/2022 04:00:51 - INFO - __main__ - ['false']
06/03/2022 04:00:51 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:00:51 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:00:51 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 04:00:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 04:00:54 - INFO - __main__ - Starting training!
06/03/2022 04:01:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 04:01:04 - INFO - __main__ - Starting training!
06/03/2022 04:01:08 - INFO - __main__ - Step 10 Global step 10 Train loss 23.518723 on epoch=1
06/03/2022 04:01:13 - INFO - __main__ - Step 20 Global step 20 Train loss 19.394402 on epoch=2
06/03/2022 04:01:19 - INFO - __main__ - Step 30 Global step 30 Train loss 18.359379 on epoch=3
06/03/2022 04:01:24 - INFO - __main__ - Step 40 Global step 40 Train loss 17.709305 on epoch=4
06/03/2022 04:01:29 - INFO - __main__ - Step 50 Global step 50 Train loss 15.289639 on epoch=6
06/03/2022 04:01:30 - INFO - __main__ - Global step 50 Train loss 18.854290 Classification-F1 0.0 on epoch=6
06/03/2022 04:01:35 - INFO - __main__ - Step 60 Global step 60 Train loss 15.857671 on epoch=7
06/03/2022 04:01:41 - INFO - __main__ - Step 70 Global step 70 Train loss 14.309973 on epoch=8
06/03/2022 04:01:46 - INFO - __main__ - Step 80 Global step 80 Train loss 13.993200 on epoch=9
06/03/2022 04:01:51 - INFO - __main__ - Step 90 Global step 90 Train loss 13.905035 on epoch=11
06/03/2022 04:01:56 - INFO - __main__ - Step 100 Global step 100 Train loss 12.181787 on epoch=12
06/03/2022 04:01:57 - INFO - __main__ - Global step 100 Train loss 14.049534 Classification-F1 0.0 on epoch=12
06/03/2022 04:02:02 - INFO - __main__ - Step 110 Global step 110 Train loss 11.853201 on epoch=13
06/03/2022 04:02:07 - INFO - __main__ - Step 120 Global step 120 Train loss 10.127687 on epoch=14
06/03/2022 04:02:12 - INFO - __main__ - Step 130 Global step 130 Train loss 7.679302 on epoch=16
06/03/2022 04:02:17 - INFO - __main__ - Step 140 Global step 140 Train loss 5.224799 on epoch=17
06/03/2022 04:02:22 - INFO - __main__ - Step 150 Global step 150 Train loss 3.238614 on epoch=18
06/03/2022 04:02:23 - INFO - __main__ - Global step 150 Train loss 7.624721 Classification-F1 0.49606299212598426 on epoch=18
06/03/2022 04:02:29 - INFO - __main__ - Step 160 Global step 160 Train loss 3.713484 on epoch=19
06/03/2022 04:02:34 - INFO - __main__ - Step 170 Global step 170 Train loss 2.396733 on epoch=21
06/03/2022 04:02:40 - INFO - __main__ - Step 180 Global step 180 Train loss 2.984161 on epoch=22
06/03/2022 04:02:45 - INFO - __main__ - Step 190 Global step 190 Train loss 2.504936 on epoch=23
06/03/2022 04:02:50 - INFO - __main__ - Step 200 Global step 200 Train loss 1.024859 on epoch=24
06/03/2022 04:02:51 - INFO - __main__ - Global step 200 Train loss 2.524835 Classification-F1 0.15789473684210525 on epoch=24
06/03/2022 04:02:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.666274 on epoch=26
06/03/2022 04:03:01 - INFO - __main__ - Step 220 Global step 220 Train loss 1.566986 on epoch=27
06/03/2022 04:03:06 - INFO - __main__ - Step 230 Global step 230 Train loss 1.528356 on epoch=28
06/03/2022 04:03:11 - INFO - __main__ - Step 240 Global step 240 Train loss 3.438080 on epoch=29
06/03/2022 04:03:16 - INFO - __main__ - Step 250 Global step 250 Train loss 2.132281 on epoch=31
06/03/2022 04:03:17 - INFO - __main__ - Global step 250 Train loss 1.866395 Classification-F1 1.0 on epoch=31
06/03/2022 04:03:22 - INFO - __main__ - Step 260 Global step 260 Train loss 2.378651 on epoch=32
06/03/2022 04:03:28 - INFO - __main__ - Step 270 Global step 270 Train loss 2.478053 on epoch=33
06/03/2022 04:03:33 - INFO - __main__ - Step 280 Global step 280 Train loss 1.858822 on epoch=34
06/03/2022 04:03:38 - INFO - __main__ - Step 290 Global step 290 Train loss 1.074070 on epoch=36
06/03/2022 04:03:43 - INFO - __main__ - Step 300 Global step 300 Train loss 0.450353 on epoch=37
06/03/2022 04:03:43 - INFO - __main__ - Global step 300 Train loss 1.647990 Classification-F1 0.49206349206349204 on epoch=37
06/03/2022 04:03:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.555826 on epoch=38
06/03/2022 04:03:54 - INFO - __main__ - Step 320 Global step 320 Train loss 0.450306 on epoch=39
06/03/2022 04:03:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.359899 on epoch=41
06/03/2022 04:04:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.417659 on epoch=42
06/03/2022 04:04:09 - INFO - __main__ - Step 350 Global step 350 Train loss 0.460170 on epoch=43
06/03/2022 04:04:10 - INFO - __main__ - Global step 350 Train loss 0.448772 Classification-F1 0.36633663366336633 on epoch=43
06/03/2022 04:04:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.408152 on epoch=44
06/03/2022 04:04:20 - INFO - __main__ - Step 370 Global step 370 Train loss 0.405030 on epoch=46
06/03/2022 04:04:25 - INFO - __main__ - Step 380 Global step 380 Train loss 0.349796 on epoch=47
06/03/2022 04:04:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.393858 on epoch=48
06/03/2022 04:04:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.358487 on epoch=49
06/03/2022 04:04:36 - INFO - __main__ - Global step 400 Train loss 0.383064 Classification-F1 1.0 on epoch=49
06/03/2022 04:04:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.363847 on epoch=51
06/03/2022 04:04:46 - INFO - __main__ - Step 420 Global step 420 Train loss 0.441767 on epoch=52
06/03/2022 04:04:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.442164 on epoch=53
06/03/2022 04:04:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.383896 on epoch=54
06/03/2022 04:05:02 - INFO - __main__ - Step 450 Global step 450 Train loss 0.415970 on epoch=56
06/03/2022 04:05:03 - INFO - __main__ - Global step 450 Train loss 0.409529 Classification-F1 0.2727272727272727 on epoch=56
06/03/2022 04:05:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.376162 on epoch=57
06/03/2022 04:05:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.382598 on epoch=58
06/03/2022 04:05:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.353881 on epoch=59
06/03/2022 04:05:24 - INFO - __main__ - Step 490 Global step 490 Train loss 0.346099 on epoch=61
06/03/2022 04:05:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.417508 on epoch=62
06/03/2022 04:05:29 - INFO - __main__ - Global step 500 Train loss 0.375250 Classification-F1 0.4482758620689655 on epoch=62
06/03/2022 04:05:35 - INFO - __main__ - Step 510 Global step 510 Train loss 0.396778 on epoch=63
06/03/2022 04:05:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.675903 on epoch=64
06/03/2022 04:05:45 - INFO - __main__ - Step 530 Global step 530 Train loss 0.501209 on epoch=66
06/03/2022 04:05:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.351016 on epoch=67
06/03/2022 04:05:55 - INFO - __main__ - Step 550 Global step 550 Train loss 0.603672 on epoch=68
06/03/2022 04:05:55 - INFO - __main__ - Global step 550 Train loss 0.505715 Classification-F1 0.36 on epoch=68
06/03/2022 04:06:00 - INFO - __main__ - Step 560 Global step 560 Train loss 0.570267 on epoch=69
06/03/2022 04:06:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.504813 on epoch=71
06/03/2022 04:06:11 - INFO - __main__ - Step 580 Global step 580 Train loss 0.382245 on epoch=72
06/03/2022 04:06:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.373825 on epoch=73
06/03/2022 04:06:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.339198 on epoch=74
06/03/2022 04:06:21 - INFO - __main__ - Global step 600 Train loss 0.434070 Classification-F1 1.0 on epoch=74
06/03/2022 04:06:26 - INFO - __main__ - Step 610 Global step 610 Train loss 0.354420 on epoch=76
06/03/2022 04:06:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.355415 on epoch=77
06/03/2022 04:06:37 - INFO - __main__ - Step 630 Global step 630 Train loss 0.426693 on epoch=78
06/03/2022 04:06:42 - INFO - __main__ - Step 640 Global step 640 Train loss 0.336650 on epoch=79
06/03/2022 04:06:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.369679 on epoch=81
06/03/2022 04:06:47 - INFO - __main__ - Global step 650 Train loss 0.368571 Classification-F1 1.0 on epoch=81
06/03/2022 04:06:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.340361 on epoch=82
06/03/2022 04:06:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.361491 on epoch=83
06/03/2022 04:07:03 - INFO - __main__ - Step 680 Global step 680 Train loss 0.377682 on epoch=84
06/03/2022 04:07:08 - INFO - __main__ - Step 690 Global step 690 Train loss 0.358989 on epoch=86
06/03/2022 04:07:13 - INFO - __main__ - Step 700 Global step 700 Train loss 0.386154 on epoch=87
06/03/2022 04:07:13 - INFO - __main__ - Global step 700 Train loss 0.364935 Classification-F1 1.0 on epoch=87
06/03/2022 04:07:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.369703 on epoch=88
06/03/2022 04:07:24 - INFO - __main__ - Step 720 Global step 720 Train loss 0.401972 on epoch=89
06/03/2022 04:07:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.358819 on epoch=91
06/03/2022 04:07:34 - INFO - __main__ - Step 740 Global step 740 Train loss 0.367885 on epoch=92
06/03/2022 04:07:39 - INFO - __main__ - Step 750 Global step 750 Train loss 0.382823 on epoch=93
06/03/2022 04:07:39 - INFO - __main__ - Global step 750 Train loss 0.376240 Classification-F1 0.41818181818181815 on epoch=93
06/03/2022 04:07:45 - INFO - __main__ - Step 760 Global step 760 Train loss 0.362417 on epoch=94
06/03/2022 04:07:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.363540 on epoch=96
06/03/2022 04:07:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.347320 on epoch=97
06/03/2022 04:08:00 - INFO - __main__ - Step 790 Global step 790 Train loss 0.374800 on epoch=98
06/03/2022 04:08:05 - INFO - __main__ - Step 800 Global step 800 Train loss 0.328724 on epoch=99
06/03/2022 04:08:05 - INFO - __main__ - Global step 800 Train loss 0.355360 Classification-F1 1.0 on epoch=99
06/03/2022 04:08:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.353603 on epoch=101
06/03/2022 04:08:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.356766 on epoch=102
06/03/2022 04:08:21 - INFO - __main__ - Step 830 Global step 830 Train loss 0.349088 on epoch=103
06/03/2022 04:08:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.350723 on epoch=104
06/03/2022 04:08:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.337193 on epoch=106
06/03/2022 04:08:31 - INFO - __main__ - Global step 850 Train loss 0.349475 Classification-F1 1.0 on epoch=106
06/03/2022 04:08:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.358776 on epoch=107
06/03/2022 04:08:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.358747 on epoch=108
06/03/2022 04:08:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.318139 on epoch=109
06/03/2022 04:08:52 - INFO - __main__ - Step 890 Global step 890 Train loss 0.374428 on epoch=111
06/03/2022 04:08:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.343645 on epoch=112
06/03/2022 04:08:57 - INFO - __main__ - Global step 900 Train loss 0.350747 Classification-F1 0.49606299212598426 on epoch=112
06/03/2022 04:09:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.358555 on epoch=113
06/03/2022 04:09:07 - INFO - __main__ - Step 920 Global step 920 Train loss 0.333310 on epoch=114
06/03/2022 04:09:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.334477 on epoch=116
06/03/2022 04:09:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.374758 on epoch=117
06/03/2022 04:09:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.356610 on epoch=118
06/03/2022 04:09:23 - INFO - __main__ - Global step 950 Train loss 0.351542 Classification-F1 0.28888888888888886 on epoch=118
06/03/2022 04:09:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.340183 on epoch=119
06/03/2022 04:09:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.300993 on epoch=121
06/03/2022 04:09:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.355061 on epoch=122
06/03/2022 04:09:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.324107 on epoch=123
06/03/2022 04:09:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.340543 on epoch=124
06/03/2022 04:09:49 - INFO - __main__ - Global step 1000 Train loss 0.332178 Classification-F1 0.49206349206349204 on epoch=124
06/03/2022 04:09:49 - INFO - __main__ - save last model!
06/03/2022 04:09:50 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 04:09:50 - INFO - __main__ - Printing 3 examples
06/03/2022 04:09:50 - INFO - __main__ -  [ethos-race] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
06/03/2022 04:09:50 - INFO - __main__ - ['false']
06/03/2022 04:09:50 - INFO - __main__ -  [ethos-race] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
06/03/2022 04:09:50 - INFO - __main__ - ['false']
06/03/2022 04:09:50 - INFO - __main__ -  [ethos-race] an Asian Moe Howard piece of shit
06/03/2022 04:09:50 - INFO - __main__ - ['false']
06/03/2022 04:09:50 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:09:50 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:09:50 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 04:09:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 04:09:50 - INFO - __main__ - Printing 3 examples
06/03/2022 04:09:50 - INFO - __main__ -  [ethos-race] Humans with third leg I hope to distinct soon, with much love
06/03/2022 04:09:50 - INFO - __main__ - ['false']
06/03/2022 04:09:50 - INFO - __main__ -  [ethos-race] Time to nuke China or Unleash a plague.
06/03/2022 04:09:50 - INFO - __main__ - ['false']
06/03/2022 04:09:50 - INFO - __main__ -  [ethos-race] You should be so meaner to dyslexic people.
06/03/2022 04:09:50 - INFO - __main__ - ['false']
06/03/2022 04:09:50 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:09:50 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:09:50 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 04:09:57 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 04:09:58 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 04:09:58 - INFO - __main__ - Printing 3 examples
06/03/2022 04:09:58 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 04:09:58 - INFO - __main__ - ['true']
06/03/2022 04:09:58 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 04:09:58 - INFO - __main__ - ['false']
06/03/2022 04:09:58 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 04:09:58 - INFO - __main__ - ['false']
06/03/2022 04:09:58 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:09:58 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:09:58 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 04:10:00 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_100_0.0002_8_predictions.txt
06/03/2022 04:10:00 - INFO - __main__ - Classification-F1 on test data: 0.4494
06/03/2022 04:10:00 - INFO - __main__ - prefix=ethos-race_64_100, lr=0.0002, bsz=8, dev_performance=1.0, test_performance=0.44936708860759494
06/03/2022 04:10:00 - INFO - __main__ - Running ... prefix=ethos-race_64_100, lr=0.0001, bsz=8 ...
06/03/2022 04:10:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 04:10:01 - INFO - __main__ - Starting training!
06/03/2022 04:10:01 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 04:10:01 - INFO - __main__ - Printing 3 examples
06/03/2022 04:10:01 - INFO - __main__ -  [ethos-race] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
06/03/2022 04:10:01 - INFO - __main__ - ['false']
06/03/2022 04:10:01 - INFO - __main__ -  [ethos-race] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
06/03/2022 04:10:01 - INFO - __main__ - ['false']
06/03/2022 04:10:01 - INFO - __main__ -  [ethos-race] an Asian Moe Howard piece of shit
06/03/2022 04:10:01 - INFO - __main__ - ['false']
06/03/2022 04:10:01 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:10:01 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:10:01 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 04:10:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 04:10:01 - INFO - __main__ - Printing 3 examples
06/03/2022 04:10:01 - INFO - __main__ -  [ethos-race] Humans with third leg I hope to distinct soon, with much love
06/03/2022 04:10:01 - INFO - __main__ - ['false']
06/03/2022 04:10:01 - INFO - __main__ -  [ethos-race] Time to nuke China or Unleash a plague.
06/03/2022 04:10:01 - INFO - __main__ - ['false']
06/03/2022 04:10:01 - INFO - __main__ -  [ethos-race] You should be so meaner to dyslexic people.
06/03/2022 04:10:01 - INFO - __main__ - ['false']
06/03/2022 04:10:01 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:10:01 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:10:01 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 04:10:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 04:10:14 - INFO - __main__ - Starting training!
06/03/2022 04:10:18 - INFO - __main__ - Step 10 Global step 10 Train loss 23.568485 on epoch=1
06/03/2022 04:10:23 - INFO - __main__ - Step 20 Global step 20 Train loss 22.050636 on epoch=2
06/03/2022 04:10:28 - INFO - __main__ - Step 30 Global step 30 Train loss 18.730305 on epoch=3
06/03/2022 04:10:33 - INFO - __main__ - Step 40 Global step 40 Train loss 17.853609 on epoch=4
06/03/2022 04:10:38 - INFO - __main__ - Step 50 Global step 50 Train loss 17.856541 on epoch=6
06/03/2022 04:10:57 - INFO - __main__ - Global step 50 Train loss 20.011915 Classification-F1 0.0 on epoch=6
06/03/2022 04:11:02 - INFO - __main__ - Step 60 Global step 60 Train loss 17.013189 on epoch=7
06/03/2022 04:11:07 - INFO - __main__ - Step 70 Global step 70 Train loss 16.789118 on epoch=8
06/03/2022 04:11:12 - INFO - __main__ - Step 80 Global step 80 Train loss 16.980169 on epoch=9
06/03/2022 04:11:18 - INFO - __main__ - Step 90 Global step 90 Train loss 15.329633 on epoch=11
06/03/2022 04:11:23 - INFO - __main__ - Step 100 Global step 100 Train loss 15.779813 on epoch=12
06/03/2022 04:11:41 - INFO - __main__ - Global step 100 Train loss 16.378386 Classification-F1 0.0 on epoch=12
06/03/2022 04:11:46 - INFO - __main__ - Step 110 Global step 110 Train loss 15.419167 on epoch=13
06/03/2022 04:11:51 - INFO - __main__ - Step 120 Global step 120 Train loss 14.955446 on epoch=14
06/03/2022 04:11:56 - INFO - __main__ - Step 130 Global step 130 Train loss 15.091318 on epoch=16
06/03/2022 04:12:01 - INFO - __main__ - Step 140 Global step 140 Train loss 14.120659 on epoch=17
06/03/2022 04:12:06 - INFO - __main__ - Step 150 Global step 150 Train loss 14.294271 on epoch=18
06/03/2022 04:12:24 - INFO - __main__ - Global step 150 Train loss 14.776172 Classification-F1 0.0 on epoch=18
06/03/2022 04:12:29 - INFO - __main__ - Step 160 Global step 160 Train loss 13.760485 on epoch=19
06/03/2022 04:12:34 - INFO - __main__ - Step 170 Global step 170 Train loss 13.967293 on epoch=21
06/03/2022 04:12:39 - INFO - __main__ - Step 180 Global step 180 Train loss 12.735059 on epoch=22
06/03/2022 04:12:45 - INFO - __main__ - Step 190 Global step 190 Train loss 12.712852 on epoch=23
06/03/2022 04:12:50 - INFO - __main__ - Step 200 Global step 200 Train loss 11.178741 on epoch=24
06/03/2022 04:13:08 - INFO - __main__ - Global step 200 Train loss 12.870888 Classification-F1 0.0 on epoch=24
06/03/2022 04:13:13 - INFO - __main__ - Step 210 Global step 210 Train loss 11.147451 on epoch=26
06/03/2022 04:13:18 - INFO - __main__ - Step 220 Global step 220 Train loss 10.362371 on epoch=27
06/03/2022 04:13:23 - INFO - __main__ - Step 230 Global step 230 Train loss 9.480021 on epoch=28
06/03/2022 04:13:28 - INFO - __main__ - Step 240 Global step 240 Train loss 9.015467 on epoch=29
06/03/2022 04:13:33 - INFO - __main__ - Step 250 Global step 250 Train loss 7.286607 on epoch=31
06/03/2022 04:13:49 - INFO - __main__ - Global step 250 Train loss 9.458384 Classification-F1 0.0 on epoch=31
06/03/2022 04:13:54 - INFO - __main__ - Step 260 Global step 260 Train loss 6.802653 on epoch=32
06/03/2022 04:13:59 - INFO - __main__ - Step 270 Global step 270 Train loss 5.201188 on epoch=33
06/03/2022 04:14:05 - INFO - __main__ - Step 280 Global step 280 Train loss 3.577553 on epoch=34
06/03/2022 04:14:10 - INFO - __main__ - Step 290 Global step 290 Train loss 2.983402 on epoch=36
06/03/2022 04:14:15 - INFO - __main__ - Step 300 Global step 300 Train loss 3.836859 on epoch=37
06/03/2022 04:14:15 - INFO - __main__ - Global step 300 Train loss 4.480331 Classification-F1 0.21428571428571427 on epoch=37
06/03/2022 04:14:21 - INFO - __main__ - Step 310 Global step 310 Train loss 2.692237 on epoch=38
06/03/2022 04:14:26 - INFO - __main__ - Step 320 Global step 320 Train loss 3.011389 on epoch=39
06/03/2022 04:14:31 - INFO - __main__ - Step 330 Global step 330 Train loss 1.807842 on epoch=41
06/03/2022 04:14:36 - INFO - __main__ - Step 340 Global step 340 Train loss 1.443424 on epoch=42
06/03/2022 04:14:41 - INFO - __main__ - Step 350 Global step 350 Train loss 1.311490 on epoch=43
06/03/2022 04:14:42 - INFO - __main__ - Global step 350 Train loss 2.053276 Classification-F1 0.488 on epoch=43
06/03/2022 04:14:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.940166 on epoch=44
06/03/2022 04:14:53 - INFO - __main__ - Step 370 Global step 370 Train loss 0.498802 on epoch=46
06/03/2022 04:14:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.554587 on epoch=47
06/03/2022 04:15:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.734494 on epoch=48
06/03/2022 04:15:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.540740 on epoch=49
06/03/2022 04:15:08 - INFO - __main__ - Global step 400 Train loss 0.653758 Classification-F1 0.4666666666666667 on epoch=49
06/03/2022 04:15:13 - INFO - __main__ - Step 410 Global step 410 Train loss 0.364527 on epoch=51
06/03/2022 04:15:19 - INFO - __main__ - Step 420 Global step 420 Train loss 0.516228 on epoch=52
06/03/2022 04:15:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.379461 on epoch=53
06/03/2022 04:15:29 - INFO - __main__ - Step 440 Global step 440 Train loss 0.415576 on epoch=54
06/03/2022 04:15:34 - INFO - __main__ - Step 450 Global step 450 Train loss 0.339417 on epoch=56
06/03/2022 04:15:34 - INFO - __main__ - Global step 450 Train loss 0.403042 Classification-F1 0.4796747967479675 on epoch=56
06/03/2022 04:15:40 - INFO - __main__ - Step 460 Global step 460 Train loss 0.370503 on epoch=57
06/03/2022 04:15:45 - INFO - __main__ - Step 470 Global step 470 Train loss 0.285441 on epoch=58
06/03/2022 04:15:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.305059 on epoch=59
06/03/2022 04:15:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.269659 on epoch=61
06/03/2022 04:16:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.252407 on epoch=62
06/03/2022 04:16:01 - INFO - __main__ - Global step 500 Train loss 0.296614 Classification-F1 0.4666666666666667 on epoch=62
06/03/2022 04:16:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.226995 on epoch=63
06/03/2022 04:16:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.246722 on epoch=64
06/03/2022 04:16:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.223757 on epoch=66
06/03/2022 04:16:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.271494 on epoch=67
06/03/2022 04:16:26 - INFO - __main__ - Step 550 Global step 550 Train loss 0.232843 on epoch=68
06/03/2022 04:16:27 - INFO - __main__ - Global step 550 Train loss 0.240362 Classification-F1 0.4336283185840708 on epoch=68
06/03/2022 04:16:32 - INFO - __main__ - Step 560 Global step 560 Train loss 0.196465 on epoch=69
06/03/2022 04:16:37 - INFO - __main__ - Step 570 Global step 570 Train loss 0.142382 on epoch=71
06/03/2022 04:16:42 - INFO - __main__ - Step 580 Global step 580 Train loss 0.219850 on epoch=72
06/03/2022 04:16:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.200008 on epoch=73
06/03/2022 04:16:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.166917 on epoch=74
06/03/2022 04:16:53 - INFO - __main__ - Global step 600 Train loss 0.185124 Classification-F1 0.4796747967479675 on epoch=74
06/03/2022 04:16:58 - INFO - __main__ - Step 610 Global step 610 Train loss 0.142290 on epoch=76
06/03/2022 04:17:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.160684 on epoch=77
06/03/2022 04:17:08 - INFO - __main__ - Step 630 Global step 630 Train loss 0.157348 on epoch=78
06/03/2022 04:17:13 - INFO - __main__ - Step 640 Global step 640 Train loss 0.127465 on epoch=79
06/03/2022 04:17:18 - INFO - __main__ - Step 650 Global step 650 Train loss 0.151291 on epoch=81
06/03/2022 04:17:19 - INFO - __main__ - Global step 650 Train loss 0.147815 Classification-F1 0.4838709677419355 on epoch=81
06/03/2022 04:17:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.131957 on epoch=82
06/03/2022 04:17:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.156702 on epoch=83
06/03/2022 04:17:34 - INFO - __main__ - Step 680 Global step 680 Train loss 0.157321 on epoch=84
06/03/2022 04:17:39 - INFO - __main__ - Step 690 Global step 690 Train loss 0.088027 on epoch=86
06/03/2022 04:17:44 - INFO - __main__ - Step 700 Global step 700 Train loss 0.077481 on epoch=87
06/03/2022 04:17:45 - INFO - __main__ - Global step 700 Train loss 0.122298 Classification-F1 0.47540983606557374 on epoch=87
06/03/2022 04:17:50 - INFO - __main__ - Step 710 Global step 710 Train loss 0.102427 on epoch=88
06/03/2022 04:17:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.062812 on epoch=89
06/03/2022 04:18:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.113981 on epoch=91
06/03/2022 04:18:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.112546 on epoch=92
06/03/2022 04:18:10 - INFO - __main__ - Step 750 Global step 750 Train loss 0.126270 on epoch=93
06/03/2022 04:18:11 - INFO - __main__ - Global step 750 Train loss 0.103607 Classification-F1 0.47107438016528924 on epoch=93
06/03/2022 04:18:16 - INFO - __main__ - Step 760 Global step 760 Train loss 0.112512 on epoch=94
06/03/2022 04:18:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.113312 on epoch=96
06/03/2022 04:18:26 - INFO - __main__ - Step 780 Global step 780 Train loss 0.070339 on epoch=97
06/03/2022 04:18:31 - INFO - __main__ - Step 790 Global step 790 Train loss 0.041719 on epoch=98
06/03/2022 04:18:36 - INFO - __main__ - Step 800 Global step 800 Train loss 0.066231 on epoch=99
06/03/2022 04:18:37 - INFO - __main__ - Global step 800 Train loss 0.080823 Classification-F1 0.43859649122807015 on epoch=99
06/03/2022 04:18:42 - INFO - __main__ - Step 810 Global step 810 Train loss 0.066704 on epoch=101
06/03/2022 04:18:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.049047 on epoch=102
06/03/2022 04:18:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.047187 on epoch=103
06/03/2022 04:18:57 - INFO - __main__ - Step 840 Global step 840 Train loss 0.084163 on epoch=104
06/03/2022 04:19:02 - INFO - __main__ - Step 850 Global step 850 Train loss 0.091933 on epoch=106
06/03/2022 04:19:03 - INFO - __main__ - Global step 850 Train loss 0.067807 Classification-F1 0.452991452991453 on epoch=106
06/03/2022 04:19:08 - INFO - __main__ - Step 860 Global step 860 Train loss 0.072339 on epoch=107
06/03/2022 04:19:13 - INFO - __main__ - Step 870 Global step 870 Train loss 0.054247 on epoch=108
06/03/2022 04:19:18 - INFO - __main__ - Step 880 Global step 880 Train loss 0.064688 on epoch=109
06/03/2022 04:19:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.072200 on epoch=111
06/03/2022 04:19:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.049250 on epoch=112
06/03/2022 04:19:29 - INFO - __main__ - Global step 900 Train loss 0.062545 Classification-F1 0.47107438016528924 on epoch=112
06/03/2022 04:19:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.048719 on epoch=113
06/03/2022 04:19:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.065180 on epoch=114
06/03/2022 04:19:44 - INFO - __main__ - Step 930 Global step 930 Train loss 0.024860 on epoch=116
06/03/2022 04:19:49 - INFO - __main__ - Step 940 Global step 940 Train loss 0.046229 on epoch=117
06/03/2022 04:19:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.046931 on epoch=118
06/03/2022 04:19:55 - INFO - __main__ - Global step 950 Train loss 0.046384 Classification-F1 0.452991452991453 on epoch=118
06/03/2022 04:20:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.043552 on epoch=119
06/03/2022 04:20:05 - INFO - __main__ - Step 970 Global step 970 Train loss 0.083745 on epoch=121
06/03/2022 04:20:10 - INFO - __main__ - Step 980 Global step 980 Train loss 0.066039 on epoch=122
06/03/2022 04:20:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.036671 on epoch=123
06/03/2022 04:20:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.031032 on epoch=124
06/03/2022 04:20:21 - INFO - __main__ - Global step 1000 Train loss 0.052208 Classification-F1 0.43859649122807015 on epoch=124
06/03/2022 04:20:21 - INFO - __main__ - save last model!
06/03/2022 04:20:21 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 04:20:21 - INFO - __main__ - Printing 3 examples
06/03/2022 04:20:21 - INFO - __main__ -  [ethos-race] Disability centres all around the world. That’s were our money goes. Let’s take em down
06/03/2022 04:20:21 - INFO - __main__ - ['false']
06/03/2022 04:20:21 - INFO - __main__ -  [ethos-race] FUCK GAYS disgusting
06/03/2022 04:20:21 - INFO - __main__ - ['false']
06/03/2022 04:20:21 - INFO - __main__ -  [ethos-race] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
06/03/2022 04:20:21 - INFO - __main__ - ['false']
06/03/2022 04:20:21 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:20:21 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:20:21 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 04:20:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 04:20:21 - INFO - __main__ - Printing 3 examples
06/03/2022 04:20:21 - INFO - __main__ -  [ethos-race] fucking slut deserved it
06/03/2022 04:20:21 - INFO - __main__ - ['false']
06/03/2022 04:20:21 - INFO - __main__ -  [ethos-race] Well done Slovakia and god bless. DO NOT build mosques, or allow or recognise Islam. They will get the point that EUROPE don't want Muslims here.
06/03/2022 04:20:21 - INFO - __main__ - ['false']
06/03/2022 04:20:21 - INFO - __main__ -  [ethos-race] Salute to Taliban Mujahideen. We Pakistanis are strongly supporting you. Go crush america and kill those bastards. Allah u Akbar. Victory will be yours Insha Allah.
06/03/2022 04:20:21 - INFO - __main__ - ['false']
06/03/2022 04:20:21 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:20:21 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:20:21 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 04:20:28 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 04:20:28 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 04:20:28 - INFO - __main__ - Printing 3 examples
06/03/2022 04:20:28 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 04:20:28 - INFO - __main__ - ['true']
06/03/2022 04:20:28 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 04:20:28 - INFO - __main__ - ['false']
06/03/2022 04:20:28 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 04:20:28 - INFO - __main__ - ['false']
06/03/2022 04:20:28 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:20:28 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:20:28 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 04:20:30 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_100_0.0001_8_predictions.txt
06/03/2022 04:20:30 - INFO - __main__ - Classification-F1 on test data: 0.2925
06/03/2022 04:20:30 - INFO - __main__ - prefix=ethos-race_64_100, lr=0.0001, bsz=8, dev_performance=0.488, test_performance=0.29247311827956995
06/03/2022 04:20:30 - INFO - __main__ - Running ... prefix=ethos-race_64_13, lr=0.0005, bsz=8 ...
06/03/2022 04:20:31 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 04:20:31 - INFO - __main__ - Printing 3 examples
06/03/2022 04:20:31 - INFO - __main__ -  [ethos-race] Disability centres all around the world. That’s were our money goes. Let’s take em down
06/03/2022 04:20:31 - INFO - __main__ - ['false']
06/03/2022 04:20:31 - INFO - __main__ -  [ethos-race] FUCK GAYS disgusting
06/03/2022 04:20:31 - INFO - __main__ - ['false']
06/03/2022 04:20:31 - INFO - __main__ -  [ethos-race] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
06/03/2022 04:20:31 - INFO - __main__ - ['false']
06/03/2022 04:20:31 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:20:31 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:20:31 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 04:20:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 04:20:31 - INFO - __main__ - Printing 3 examples
06/03/2022 04:20:31 - INFO - __main__ -  [ethos-race] fucking slut deserved it
06/03/2022 04:20:31 - INFO - __main__ - ['false']
06/03/2022 04:20:31 - INFO - __main__ -  [ethos-race] Well done Slovakia and god bless. DO NOT build mosques, or allow or recognise Islam. They will get the point that EUROPE don't want Muslims here.
06/03/2022 04:20:31 - INFO - __main__ - ['false']
06/03/2022 04:20:31 - INFO - __main__ -  [ethos-race] Salute to Taliban Mujahideen. We Pakistanis are strongly supporting you. Go crush america and kill those bastards. Allah u Akbar. Victory will be yours Insha Allah.
06/03/2022 04:20:31 - INFO - __main__ - ['false']
06/03/2022 04:20:31 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:20:31 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:20:31 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 04:20:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 04:20:32 - INFO - __main__ - Starting training!
06/03/2022 04:20:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 04:20:42 - INFO - __main__ - Starting training!
06/03/2022 04:20:47 - INFO - __main__ - Step 10 Global step 10 Train loss 24.306829 on epoch=1
06/03/2022 04:20:52 - INFO - __main__ - Step 20 Global step 20 Train loss 18.527832 on epoch=2
06/03/2022 04:20:57 - INFO - __main__ - Step 30 Global step 30 Train loss 16.697247 on epoch=3
06/03/2022 04:21:02 - INFO - __main__ - Step 40 Global step 40 Train loss 14.441032 on epoch=4
06/03/2022 04:21:07 - INFO - __main__ - Step 50 Global step 50 Train loss 12.019061 on epoch=6
06/03/2022 04:21:10 - INFO - __main__ - Global step 50 Train loss 17.198400 Classification-F1 0.004395604395604396 on epoch=6
06/03/2022 04:21:16 - INFO - __main__ - Step 60 Global step 60 Train loss 7.149327 on epoch=7
06/03/2022 04:21:21 - INFO - __main__ - Step 70 Global step 70 Train loss 4.068592 on epoch=8
06/03/2022 04:21:26 - INFO - __main__ - Step 80 Global step 80 Train loss 3.238531 on epoch=9
06/03/2022 04:21:31 - INFO - __main__ - Step 90 Global step 90 Train loss 2.144617 on epoch=11
06/03/2022 04:21:36 - INFO - __main__ - Step 100 Global step 100 Train loss 1.094211 on epoch=12
06/03/2022 04:21:37 - INFO - __main__ - Global step 100 Train loss 3.539056 Classification-F1 0.37254901960784315 on epoch=12
06/03/2022 04:21:43 - INFO - __main__ - Step 110 Global step 110 Train loss 0.846070 on epoch=13
06/03/2022 04:21:48 - INFO - __main__ - Step 120 Global step 120 Train loss 0.625291 on epoch=14
06/03/2022 04:21:53 - INFO - __main__ - Step 130 Global step 130 Train loss 0.565525 on epoch=16
06/03/2022 04:21:58 - INFO - __main__ - Step 140 Global step 140 Train loss 0.443556 on epoch=17
06/03/2022 04:22:04 - INFO - __main__ - Step 150 Global step 150 Train loss 0.578660 on epoch=18
06/03/2022 04:22:04 - INFO - __main__ - Global step 150 Train loss 0.611820 Classification-F1 1.0 on epoch=18
06/03/2022 04:22:10 - INFO - __main__ - Step 160 Global step 160 Train loss 0.398780 on epoch=19
06/03/2022 04:22:15 - INFO - __main__ - Step 170 Global step 170 Train loss 0.449205 on epoch=21
06/03/2022 04:22:21 - INFO - __main__ - Step 180 Global step 180 Train loss 0.297701 on epoch=22
06/03/2022 04:22:26 - INFO - __main__ - Step 190 Global step 190 Train loss 0.416336 on epoch=23
06/03/2022 04:22:31 - INFO - __main__ - Step 200 Global step 200 Train loss 0.295684 on epoch=24
06/03/2022 04:22:31 - INFO - __main__ - Global step 200 Train loss 0.371541 Classification-F1 1.0 on epoch=24
06/03/2022 04:22:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.353605 on epoch=26
06/03/2022 04:22:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.333903 on epoch=27
06/03/2022 04:22:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.311201 on epoch=28
06/03/2022 04:22:52 - INFO - __main__ - Step 240 Global step 240 Train loss 0.352586 on epoch=29
06/03/2022 04:22:57 - INFO - __main__ - Step 250 Global step 250 Train loss 0.362627 on epoch=31
06/03/2022 04:22:58 - INFO - __main__ - Global step 250 Train loss 0.342785 Classification-F1 0.49206349206349204 on epoch=31
06/03/2022 04:23:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.336554 on epoch=32
06/03/2022 04:23:08 - INFO - __main__ - Step 270 Global step 270 Train loss 0.415036 on epoch=33
06/03/2022 04:23:13 - INFO - __main__ - Step 280 Global step 280 Train loss 0.349620 on epoch=34
06/03/2022 04:23:18 - INFO - __main__ - Step 290 Global step 290 Train loss 0.241171 on epoch=36
06/03/2022 04:23:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.267272 on epoch=37
06/03/2022 04:23:24 - INFO - __main__ - Global step 300 Train loss 0.321931 Classification-F1 0.23809523809523808 on epoch=37
06/03/2022 04:23:30 - INFO - __main__ - Step 310 Global step 310 Train loss 0.244869 on epoch=38
06/03/2022 04:23:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.312115 on epoch=39
06/03/2022 04:23:40 - INFO - __main__ - Step 330 Global step 330 Train loss 0.245123 on epoch=41
06/03/2022 04:23:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.229785 on epoch=42
06/03/2022 04:23:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.208647 on epoch=43
06/03/2022 04:23:51 - INFO - __main__ - Global step 350 Train loss 0.248108 Classification-F1 0.49206349206349204 on epoch=43
06/03/2022 04:23:56 - INFO - __main__ - Step 360 Global step 360 Train loss 0.252967 on epoch=44
06/03/2022 04:24:01 - INFO - __main__ - Step 370 Global step 370 Train loss 0.136877 on epoch=46
06/03/2022 04:24:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.171714 on epoch=47
06/03/2022 04:24:11 - INFO - __main__ - Step 390 Global step 390 Train loss 0.161302 on epoch=48
06/03/2022 04:24:17 - INFO - __main__ - Step 400 Global step 400 Train loss 0.194416 on epoch=49
06/03/2022 04:24:17 - INFO - __main__ - Global step 400 Train loss 0.183455 Classification-F1 0.49606299212598426 on epoch=49
06/03/2022 04:24:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.157786 on epoch=51
06/03/2022 04:24:28 - INFO - __main__ - Step 420 Global step 420 Train loss 0.098545 on epoch=52
06/03/2022 04:24:33 - INFO - __main__ - Step 430 Global step 430 Train loss 0.109554 on epoch=53
06/03/2022 04:24:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.114382 on epoch=54
06/03/2022 04:24:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.122965 on epoch=56
06/03/2022 04:24:44 - INFO - __main__ - Global step 450 Train loss 0.120646 Classification-F1 0.47540983606557374 on epoch=56
06/03/2022 04:24:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.108428 on epoch=57
06/03/2022 04:24:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.089491 on epoch=58
06/03/2022 04:24:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.142869 on epoch=59
06/03/2022 04:25:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.135781 on epoch=61
06/03/2022 04:25:10 - INFO - __main__ - Step 500 Global step 500 Train loss 0.101069 on epoch=62
06/03/2022 04:25:10 - INFO - __main__ - Global step 500 Train loss 0.115528 Classification-F1 0.3333333333333333 on epoch=62
06/03/2022 04:25:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.094196 on epoch=63
06/03/2022 04:25:21 - INFO - __main__ - Step 520 Global step 520 Train loss 0.064509 on epoch=64
06/03/2022 04:25:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.070146 on epoch=66
06/03/2022 04:25:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.205026 on epoch=67
06/03/2022 04:25:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.068818 on epoch=68
06/03/2022 04:25:37 - INFO - __main__ - Global step 550 Train loss 0.100539 Classification-F1 0.41818181818181815 on epoch=68
06/03/2022 04:25:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.060105 on epoch=69
06/03/2022 04:25:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.038230 on epoch=71
06/03/2022 04:25:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.069185 on epoch=72
06/03/2022 04:25:58 - INFO - __main__ - Step 590 Global step 590 Train loss 0.061920 on epoch=73
06/03/2022 04:26:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.041949 on epoch=74
06/03/2022 04:26:03 - INFO - __main__ - Global step 600 Train loss 0.054278 Classification-F1 0.49606299212598426 on epoch=74
06/03/2022 04:26:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.068438 on epoch=76
06/03/2022 04:26:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.050041 on epoch=77
06/03/2022 04:26:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.094333 on epoch=78
06/03/2022 04:26:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.058298 on epoch=79
06/03/2022 04:26:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.044836 on epoch=81
06/03/2022 04:26:30 - INFO - __main__ - Global step 650 Train loss 0.063189 Classification-F1 0.49206349206349204 on epoch=81
06/03/2022 04:26:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.035632 on epoch=82
06/03/2022 04:26:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.061364 on epoch=83
06/03/2022 04:26:45 - INFO - __main__ - Step 680 Global step 680 Train loss 0.098568 on epoch=84
06/03/2022 04:26:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.034434 on epoch=86
06/03/2022 04:26:56 - INFO - __main__ - Step 700 Global step 700 Train loss 0.022584 on epoch=87
06/03/2022 04:26:56 - INFO - __main__ - Global step 700 Train loss 0.050516 Classification-F1 0.4434782608695652 on epoch=87
06/03/2022 04:27:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.065787 on epoch=88
06/03/2022 04:27:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.018294 on epoch=89
06/03/2022 04:27:12 - INFO - __main__ - Step 730 Global step 730 Train loss 0.070847 on epoch=91
06/03/2022 04:27:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.014453 on epoch=92
06/03/2022 04:27:22 - INFO - __main__ - Step 750 Global step 750 Train loss 0.039976 on epoch=93
06/03/2022 04:27:23 - INFO - __main__ - Global step 750 Train loss 0.041871 Classification-F1 0.4336283185840708 on epoch=93
06/03/2022 04:27:28 - INFO - __main__ - Step 760 Global step 760 Train loss 0.033397 on epoch=94
06/03/2022 04:27:33 - INFO - __main__ - Step 770 Global step 770 Train loss 0.011880 on epoch=96
06/03/2022 04:27:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.020319 on epoch=97
06/03/2022 04:27:43 - INFO - __main__ - Step 790 Global step 790 Train loss 0.084852 on epoch=98
06/03/2022 04:27:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.006957 on epoch=99
06/03/2022 04:27:49 - INFO - __main__ - Global step 800 Train loss 0.031481 Classification-F1 0.46218487394957986 on epoch=99
06/03/2022 04:27:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.006330 on epoch=101
06/03/2022 04:28:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.022817 on epoch=102
06/03/2022 04:28:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.007572 on epoch=103
06/03/2022 04:28:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.008834 on epoch=104
06/03/2022 04:28:15 - INFO - __main__ - Step 850 Global step 850 Train loss 0.031493 on epoch=106
06/03/2022 04:28:16 - INFO - __main__ - Global step 850 Train loss 0.015409 Classification-F1 0.4838709677419355 on epoch=106
06/03/2022 04:28:21 - INFO - __main__ - Step 860 Global step 860 Train loss 0.006557 on epoch=107
06/03/2022 04:28:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.010203 on epoch=108
06/03/2022 04:28:31 - INFO - __main__ - Step 880 Global step 880 Train loss 0.002969 on epoch=109
06/03/2022 04:28:36 - INFO - __main__ - Step 890 Global step 890 Train loss 0.011179 on epoch=111
06/03/2022 04:28:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.002862 on epoch=112
06/03/2022 04:28:42 - INFO - __main__ - Global step 900 Train loss 0.006754 Classification-F1 0.4796747967479675 on epoch=112
06/03/2022 04:28:47 - INFO - __main__ - Step 910 Global step 910 Train loss 0.033621 on epoch=113
06/03/2022 04:28:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.003579 on epoch=114
06/03/2022 04:28:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.014908 on epoch=116
06/03/2022 04:29:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.004431 on epoch=117
06/03/2022 04:29:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.001905 on epoch=118
06/03/2022 04:29:09 - INFO - __main__ - Global step 950 Train loss 0.011689 Classification-F1 0.47107438016528924 on epoch=118
06/03/2022 04:29:14 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000212 on epoch=119
06/03/2022 04:29:19 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000393 on epoch=121
06/03/2022 04:29:24 - INFO - __main__ - Step 980 Global step 980 Train loss 0.105567 on epoch=122
06/03/2022 04:29:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000547 on epoch=123
06/03/2022 04:29:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.013671 on epoch=124
06/03/2022 04:29:35 - INFO - __main__ - Global step 1000 Train loss 0.024078 Classification-F1 0.47107438016528924 on epoch=124
06/03/2022 04:29:35 - INFO - __main__ - save last model!
06/03/2022 04:29:36 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 04:29:36 - INFO - __main__ - Printing 3 examples
06/03/2022 04:29:36 - INFO - __main__ -  [ethos-race] Disability centres all around the world. That’s were our money goes. Let’s take em down
06/03/2022 04:29:36 - INFO - __main__ - ['false']
06/03/2022 04:29:36 - INFO - __main__ -  [ethos-race] FUCK GAYS disgusting
06/03/2022 04:29:36 - INFO - __main__ - ['false']
06/03/2022 04:29:36 - INFO - __main__ -  [ethos-race] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
06/03/2022 04:29:36 - INFO - __main__ - ['false']
06/03/2022 04:29:36 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:29:36 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:29:36 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 04:29:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 04:29:36 - INFO - __main__ - Printing 3 examples
06/03/2022 04:29:36 - INFO - __main__ -  [ethos-race] fucking slut deserved it
06/03/2022 04:29:36 - INFO - __main__ - ['false']
06/03/2022 04:29:36 - INFO - __main__ -  [ethos-race] Well done Slovakia and god bless. DO NOT build mosques, or allow or recognise Islam. They will get the point that EUROPE don't want Muslims here.
06/03/2022 04:29:36 - INFO - __main__ - ['false']
06/03/2022 04:29:36 - INFO - __main__ -  [ethos-race] Salute to Taliban Mujahideen. We Pakistanis are strongly supporting you. Go crush america and kill those bastards. Allah u Akbar. Victory will be yours Insha Allah.
06/03/2022 04:29:36 - INFO - __main__ - ['false']
06/03/2022 04:29:36 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:29:36 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:29:36 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 04:29:42 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 04:29:43 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 04:29:43 - INFO - __main__ - Printing 3 examples
06/03/2022 04:29:43 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 04:29:43 - INFO - __main__ - ['true']
06/03/2022 04:29:43 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 04:29:43 - INFO - __main__ - ['false']
06/03/2022 04:29:43 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 04:29:43 - INFO - __main__ - ['false']
06/03/2022 04:29:43 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:29:43 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:29:43 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 04:29:44 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_13_0.0005_8_predictions.txt
06/03/2022 04:29:44 - INFO - __main__ - Classification-F1 on test data: 0.4459
06/03/2022 04:29:45 - INFO - __main__ - prefix=ethos-race_64_13, lr=0.0005, bsz=8, dev_performance=1.0, test_performance=0.445859872611465
06/03/2022 04:29:45 - INFO - __main__ - Running ... prefix=ethos-race_64_13, lr=0.0003, bsz=8 ...
06/03/2022 04:29:46 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 04:29:46 - INFO - __main__ - Printing 3 examples
06/03/2022 04:29:46 - INFO - __main__ -  [ethos-race] Disability centres all around the world. That’s were our money goes. Let’s take em down
06/03/2022 04:29:46 - INFO - __main__ - ['false']
06/03/2022 04:29:46 - INFO - __main__ -  [ethos-race] FUCK GAYS disgusting
06/03/2022 04:29:46 - INFO - __main__ - ['false']
06/03/2022 04:29:46 - INFO - __main__ -  [ethos-race] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
06/03/2022 04:29:46 - INFO - __main__ - ['false']
06/03/2022 04:29:46 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:29:46 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:29:46 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 04:29:46 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 04:29:46 - INFO - __main__ - Printing 3 examples
06/03/2022 04:29:46 - INFO - __main__ -  [ethos-race] fucking slut deserved it
06/03/2022 04:29:46 - INFO - __main__ - ['false']
06/03/2022 04:29:46 - INFO - __main__ -  [ethos-race] Well done Slovakia and god bless. DO NOT build mosques, or allow or recognise Islam. They will get the point that EUROPE don't want Muslims here.
06/03/2022 04:29:46 - INFO - __main__ - ['false']
06/03/2022 04:29:46 - INFO - __main__ -  [ethos-race] Salute to Taliban Mujahideen. We Pakistanis are strongly supporting you. Go crush america and kill those bastards. Allah u Akbar. Victory will be yours Insha Allah.
06/03/2022 04:29:46 - INFO - __main__ - ['false']
06/03/2022 04:29:46 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:29:46 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:29:46 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 04:29:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 04:29:46 - INFO - __main__ - Starting training!
06/03/2022 04:29:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 04:29:57 - INFO - __main__ - Starting training!
06/03/2022 04:30:01 - INFO - __main__ - Step 10 Global step 10 Train loss 24.343143 on epoch=1
06/03/2022 04:30:07 - INFO - __main__ - Step 20 Global step 20 Train loss 18.108227 on epoch=2
06/03/2022 04:30:12 - INFO - __main__ - Step 30 Global step 30 Train loss 15.894353 on epoch=3
06/03/2022 04:30:17 - INFO - __main__ - Step 40 Global step 40 Train loss 15.363620 on epoch=4
06/03/2022 04:30:22 - INFO - __main__ - Step 50 Global step 50 Train loss 14.707762 on epoch=6
06/03/2022 04:30:39 - INFO - __main__ - Global step 50 Train loss 17.683422 Classification-F1 0.0 on epoch=6
06/03/2022 04:30:45 - INFO - __main__ - Step 60 Global step 60 Train loss 12.869291 on epoch=7
06/03/2022 04:30:50 - INFO - __main__ - Step 70 Global step 70 Train loss 11.412170 on epoch=8
06/03/2022 04:30:55 - INFO - __main__ - Step 80 Global step 80 Train loss 4.755152 on epoch=9
06/03/2022 04:31:01 - INFO - __main__ - Step 90 Global step 90 Train loss 0.731843 on epoch=11
06/03/2022 04:31:06 - INFO - __main__ - Step 100 Global step 100 Train loss 0.659917 on epoch=12
06/03/2022 04:31:06 - INFO - __main__ - Global step 100 Train loss 6.085674 Classification-F1 0.49206349206349204 on epoch=12
06/03/2022 04:31:13 - INFO - __main__ - Step 110 Global step 110 Train loss 0.467945 on epoch=13
06/03/2022 04:31:18 - INFO - __main__ - Step 120 Global step 120 Train loss 0.436764 on epoch=14
06/03/2022 04:31:23 - INFO - __main__ - Step 130 Global step 130 Train loss 0.450135 on epoch=16
06/03/2022 04:31:28 - INFO - __main__ - Step 140 Global step 140 Train loss 0.401691 on epoch=17
06/03/2022 04:31:33 - INFO - __main__ - Step 150 Global step 150 Train loss 1.578148 on epoch=18
06/03/2022 04:31:34 - INFO - __main__ - Global step 150 Train loss 0.666937 Classification-F1 0.42342342342342343 on epoch=18
06/03/2022 04:31:39 - INFO - __main__ - Step 160 Global step 160 Train loss 0.447819 on epoch=19
06/03/2022 04:31:44 - INFO - __main__ - Step 170 Global step 170 Train loss 0.274233 on epoch=21
06/03/2022 04:31:49 - INFO - __main__ - Step 180 Global step 180 Train loss 0.275290 on epoch=22
06/03/2022 04:31:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.181042 on epoch=23
06/03/2022 04:32:00 - INFO - __main__ - Step 200 Global step 200 Train loss 0.120410 on epoch=24
06/03/2022 04:32:00 - INFO - __main__ - Global step 200 Train loss 0.259759 Classification-F1 0.488 on epoch=24
06/03/2022 04:32:05 - INFO - __main__ - Step 210 Global step 210 Train loss 0.179781 on epoch=26
06/03/2022 04:32:11 - INFO - __main__ - Step 220 Global step 220 Train loss 0.164434 on epoch=27
06/03/2022 04:32:16 - INFO - __main__ - Step 230 Global step 230 Train loss 0.068066 on epoch=28
06/03/2022 04:32:21 - INFO - __main__ - Step 240 Global step 240 Train loss 0.119363 on epoch=29
06/03/2022 04:32:26 - INFO - __main__ - Step 250 Global step 250 Train loss 0.186484 on epoch=31
06/03/2022 04:32:27 - INFO - __main__ - Global step 250 Train loss 0.143626 Classification-F1 0.4434782608695652 on epoch=31
06/03/2022 04:32:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.043834 on epoch=32
06/03/2022 04:32:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.078451 on epoch=33
06/03/2022 04:32:42 - INFO - __main__ - Step 280 Global step 280 Train loss 0.037851 on epoch=34
06/03/2022 04:32:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.107340 on epoch=36
06/03/2022 04:32:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.064930 on epoch=37
06/03/2022 04:32:53 - INFO - __main__ - Global step 300 Train loss 0.066481 Classification-F1 0.4796747967479675 on epoch=37
06/03/2022 04:32:59 - INFO - __main__ - Step 310 Global step 310 Train loss 0.024555 on epoch=38
06/03/2022 04:33:04 - INFO - __main__ - Step 320 Global step 320 Train loss 0.098718 on epoch=39
06/03/2022 04:33:09 - INFO - __main__ - Step 330 Global step 330 Train loss 0.075600 on epoch=41
06/03/2022 04:33:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.032083 on epoch=42
06/03/2022 04:33:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.018730 on epoch=43
06/03/2022 04:33:20 - INFO - __main__ - Global step 350 Train loss 0.049937 Classification-F1 0.4482758620689655 on epoch=43
06/03/2022 04:33:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.018655 on epoch=44
06/03/2022 04:33:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.064097 on epoch=46
06/03/2022 04:33:36 - INFO - __main__ - Step 380 Global step 380 Train loss 0.021560 on epoch=47
06/03/2022 04:33:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.036942 on epoch=48
06/03/2022 04:33:46 - INFO - __main__ - Step 400 Global step 400 Train loss 0.006882 on epoch=49
06/03/2022 04:33:47 - INFO - __main__ - Global step 400 Train loss 0.029627 Classification-F1 0.42342342342342343 on epoch=49
06/03/2022 04:33:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.012172 on epoch=51
06/03/2022 04:33:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.010435 on epoch=52
06/03/2022 04:34:02 - INFO - __main__ - Step 430 Global step 430 Train loss 0.031082 on epoch=53
06/03/2022 04:34:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.039922 on epoch=54
06/03/2022 04:34:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.029857 on epoch=56
06/03/2022 04:34:13 - INFO - __main__ - Global step 450 Train loss 0.024694 Classification-F1 0.47540983606557374 on epoch=56
06/03/2022 04:34:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.096882 on epoch=57
06/03/2022 04:34:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.010364 on epoch=58
06/03/2022 04:34:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.017720 on epoch=59
06/03/2022 04:34:34 - INFO - __main__ - Step 490 Global step 490 Train loss 0.005124 on epoch=61
06/03/2022 04:34:39 - INFO - __main__ - Step 500 Global step 500 Train loss 0.008023 on epoch=62
06/03/2022 04:34:40 - INFO - __main__ - Global step 500 Train loss 0.027623 Classification-F1 0.4796747967479675 on epoch=62
06/03/2022 04:34:45 - INFO - __main__ - Step 510 Global step 510 Train loss 0.001857 on epoch=63
06/03/2022 04:34:50 - INFO - __main__ - Step 520 Global step 520 Train loss 0.000181 on epoch=64
06/03/2022 04:34:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.014116 on epoch=66
06/03/2022 04:35:00 - INFO - __main__ - Step 540 Global step 540 Train loss 0.007026 on epoch=67
06/03/2022 04:35:05 - INFO - __main__ - Step 550 Global step 550 Train loss 0.001706 on epoch=68
06/03/2022 04:35:06 - INFO - __main__ - Global step 550 Train loss 0.004977 Classification-F1 0.47540983606557374 on epoch=68
06/03/2022 04:35:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.016267 on epoch=69
06/03/2022 04:35:16 - INFO - __main__ - Step 570 Global step 570 Train loss 0.000560 on epoch=71
06/03/2022 04:35:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.000735 on epoch=72
06/03/2022 04:35:26 - INFO - __main__ - Step 590 Global step 590 Train loss 0.027304 on epoch=73
06/03/2022 04:35:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.001065 on epoch=74
06/03/2022 04:35:32 - INFO - __main__ - Global step 600 Train loss 0.009186 Classification-F1 0.47107438016528924 on epoch=74
06/03/2022 04:35:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.001606 on epoch=76
06/03/2022 04:35:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.000498 on epoch=77
06/03/2022 04:35:48 - INFO - __main__ - Step 630 Global step 630 Train loss 0.005260 on epoch=78
06/03/2022 04:35:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.041921 on epoch=79
06/03/2022 04:35:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000537 on epoch=81
06/03/2022 04:35:58 - INFO - __main__ - Global step 650 Train loss 0.009964 Classification-F1 0.47540983606557374 on epoch=81
06/03/2022 04:36:04 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000615 on epoch=82
06/03/2022 04:36:09 - INFO - __main__ - Step 670 Global step 670 Train loss 0.000360 on epoch=83
06/03/2022 04:36:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.013142 on epoch=84
06/03/2022 04:36:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000148 on epoch=86
06/03/2022 04:36:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.001695 on epoch=87
06/03/2022 04:36:25 - INFO - __main__ - Global step 700 Train loss 0.003192 Classification-F1 0.4796747967479675 on epoch=87
06/03/2022 04:36:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.002538 on epoch=88
06/03/2022 04:36:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000096 on epoch=89
06/03/2022 04:36:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000133 on epoch=91
06/03/2022 04:36:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.114421 on epoch=92
06/03/2022 04:36:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.007691 on epoch=93
06/03/2022 04:36:51 - INFO - __main__ - Global step 750 Train loss 0.024976 Classification-F1 0.47540983606557374 on epoch=93
06/03/2022 04:36:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.021085 on epoch=94
06/03/2022 04:37:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.066606 on epoch=96
06/03/2022 04:37:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.006055 on epoch=97
06/03/2022 04:37:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.003018 on epoch=98
06/03/2022 04:37:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000083 on epoch=99
06/03/2022 04:37:18 - INFO - __main__ - Global step 800 Train loss 0.019369 Classification-F1 0.4838709677419355 on epoch=99
06/03/2022 04:37:23 - INFO - __main__ - Step 810 Global step 810 Train loss 0.006084 on epoch=101
06/03/2022 04:37:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.001321 on epoch=102
06/03/2022 04:37:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.016229 on epoch=103
06/03/2022 04:37:39 - INFO - __main__ - Step 840 Global step 840 Train loss 0.011887 on epoch=104
06/03/2022 04:37:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.054382 on epoch=106
06/03/2022 04:37:44 - INFO - __main__ - Global step 850 Train loss 0.017981 Classification-F1 0.46218487394957986 on epoch=106
06/03/2022 04:37:50 - INFO - __main__ - Step 860 Global step 860 Train loss 0.019213 on epoch=107
06/03/2022 04:37:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.001924 on epoch=108
06/03/2022 04:38:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.018626 on epoch=109
06/03/2022 04:38:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.001844 on epoch=111
06/03/2022 04:38:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000998 on epoch=112
06/03/2022 04:38:11 - INFO - __main__ - Global step 900 Train loss 0.008521 Classification-F1 0.47107438016528924 on epoch=112
06/03/2022 04:38:16 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000432 on epoch=113
06/03/2022 04:38:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.003799 on epoch=114
06/03/2022 04:38:27 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000181 on epoch=116
06/03/2022 04:38:32 - INFO - __main__ - Step 940 Global step 940 Train loss 0.007311 on epoch=117
06/03/2022 04:38:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.001631 on epoch=118
06/03/2022 04:38:38 - INFO - __main__ - Global step 950 Train loss 0.002671 Classification-F1 0.46218487394957986 on epoch=118
06/03/2022 04:38:43 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000038 on epoch=119
06/03/2022 04:38:48 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000122 on epoch=121
06/03/2022 04:38:53 - INFO - __main__ - Step 980 Global step 980 Train loss 0.041656 on epoch=122
06/03/2022 04:38:58 - INFO - __main__ - Step 990 Global step 990 Train loss 0.019894 on epoch=123
06/03/2022 04:39:04 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.010430 on epoch=124
06/03/2022 04:39:04 - INFO - __main__ - Global step 1000 Train loss 0.014428 Classification-F1 0.4482758620689655 on epoch=124
06/03/2022 04:39:04 - INFO - __main__ - save last model!
06/03/2022 04:39:05 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 04:39:05 - INFO - __main__ - Printing 3 examples
06/03/2022 04:39:05 - INFO - __main__ -  [ethos-race] Disability centres all around the world. That’s were our money goes. Let’s take em down
06/03/2022 04:39:05 - INFO - __main__ - ['false']
06/03/2022 04:39:05 - INFO - __main__ -  [ethos-race] FUCK GAYS disgusting
06/03/2022 04:39:05 - INFO - __main__ - ['false']
06/03/2022 04:39:05 - INFO - __main__ -  [ethos-race] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
06/03/2022 04:39:05 - INFO - __main__ - ['false']
06/03/2022 04:39:05 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:39:05 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:39:05 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 04:39:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 04:39:05 - INFO - __main__ - Printing 3 examples
06/03/2022 04:39:05 - INFO - __main__ -  [ethos-race] fucking slut deserved it
06/03/2022 04:39:05 - INFO - __main__ - ['false']
06/03/2022 04:39:05 - INFO - __main__ -  [ethos-race] Well done Slovakia and god bless. DO NOT build mosques, or allow or recognise Islam. They will get the point that EUROPE don't want Muslims here.
06/03/2022 04:39:05 - INFO - __main__ - ['false']
06/03/2022 04:39:05 - INFO - __main__ -  [ethos-race] Salute to Taliban Mujahideen. We Pakistanis are strongly supporting you. Go crush america and kill those bastards. Allah u Akbar. Victory will be yours Insha Allah.
06/03/2022 04:39:05 - INFO - __main__ - ['false']
06/03/2022 04:39:05 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:39:05 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:39:05 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 04:39:11 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 04:39:12 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 04:39:12 - INFO - __main__ - Printing 3 examples
06/03/2022 04:39:12 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 04:39:12 - INFO - __main__ - ['true']
06/03/2022 04:39:12 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 04:39:12 - INFO - __main__ - ['false']
06/03/2022 04:39:12 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 04:39:12 - INFO - __main__ - ['false']
06/03/2022 04:39:12 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:39:12 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:39:12 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 04:39:14 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_13_0.0003_8_predictions.txt
06/03/2022 04:39:14 - INFO - __main__ - Classification-F1 on test data: 0.5043
06/03/2022 04:39:14 - INFO - __main__ - prefix=ethos-race_64_13, lr=0.0003, bsz=8, dev_performance=0.49206349206349204, test_performance=0.5042735042735043
06/03/2022 04:39:14 - INFO - __main__ - Running ... prefix=ethos-race_64_13, lr=0.0002, bsz=8 ...
06/03/2022 04:39:15 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 04:39:15 - INFO - __main__ - Printing 3 examples
06/03/2022 04:39:15 - INFO - __main__ -  [ethos-race] Disability centres all around the world. That’s were our money goes. Let’s take em down
06/03/2022 04:39:15 - INFO - __main__ - ['false']
06/03/2022 04:39:15 - INFO - __main__ -  [ethos-race] FUCK GAYS disgusting
06/03/2022 04:39:15 - INFO - __main__ - ['false']
06/03/2022 04:39:15 - INFO - __main__ -  [ethos-race] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
06/03/2022 04:39:15 - INFO - __main__ - ['false']
06/03/2022 04:39:15 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:39:15 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:39:15 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 04:39:15 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 04:39:15 - INFO - __main__ - Printing 3 examples
06/03/2022 04:39:15 - INFO - __main__ -  [ethos-race] fucking slut deserved it
06/03/2022 04:39:15 - INFO - __main__ - ['false']
06/03/2022 04:39:15 - INFO - __main__ -  [ethos-race] Well done Slovakia and god bless. DO NOT build mosques, or allow or recognise Islam. They will get the point that EUROPE don't want Muslims here.
06/03/2022 04:39:15 - INFO - __main__ - ['false']
06/03/2022 04:39:15 - INFO - __main__ -  [ethos-race] Salute to Taliban Mujahideen. We Pakistanis are strongly supporting you. Go crush america and kill those bastards. Allah u Akbar. Victory will be yours Insha Allah.
06/03/2022 04:39:15 - INFO - __main__ - ['false']
06/03/2022 04:39:15 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:39:15 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:39:15 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 04:39:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 04:39:18 - INFO - __main__ - Starting training!
06/03/2022 04:39:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 04:39:26 - INFO - __main__ - Starting training!
06/03/2022 04:39:30 - INFO - __main__ - Step 10 Global step 10 Train loss 24.474369 on epoch=1
06/03/2022 04:39:35 - INFO - __main__ - Step 20 Global step 20 Train loss 20.514307 on epoch=2
06/03/2022 04:39:41 - INFO - __main__ - Step 30 Global step 30 Train loss 18.521851 on epoch=3
06/03/2022 04:39:46 - INFO - __main__ - Step 40 Global step 40 Train loss 17.500311 on epoch=4
06/03/2022 04:39:52 - INFO - __main__ - Step 50 Global step 50 Train loss 16.210510 on epoch=6
06/03/2022 04:40:11 - INFO - __main__ - Global step 50 Train loss 19.444269 Classification-F1 0.0 on epoch=6
06/03/2022 04:40:17 - INFO - __main__ - Step 60 Global step 60 Train loss 15.737584 on epoch=7
06/03/2022 04:40:22 - INFO - __main__ - Step 70 Global step 70 Train loss 15.108351 on epoch=8
06/03/2022 04:40:27 - INFO - __main__ - Step 80 Global step 80 Train loss 14.578806 on epoch=9
06/03/2022 04:40:33 - INFO - __main__ - Step 90 Global step 90 Train loss 13.833226 on epoch=11
06/03/2022 04:40:38 - INFO - __main__ - Step 100 Global step 100 Train loss 12.762607 on epoch=12
06/03/2022 04:40:40 - INFO - __main__ - Global step 100 Train loss 14.404115 Classification-F1 0.0 on epoch=12
06/03/2022 04:40:45 - INFO - __main__ - Step 110 Global step 110 Train loss 11.476711 on epoch=13
06/03/2022 04:40:50 - INFO - __main__ - Step 120 Global step 120 Train loss 10.276369 on epoch=14
06/03/2022 04:40:55 - INFO - __main__ - Step 130 Global step 130 Train loss 6.933261 on epoch=16
06/03/2022 04:41:00 - INFO - __main__ - Step 140 Global step 140 Train loss 3.224431 on epoch=17
06/03/2022 04:41:05 - INFO - __main__ - Step 150 Global step 150 Train loss 0.682172 on epoch=18
06/03/2022 04:41:06 - INFO - __main__ - Global step 150 Train loss 6.518589 Classification-F1 0.49606299212598426 on epoch=18
06/03/2022 04:41:12 - INFO - __main__ - Step 160 Global step 160 Train loss 0.550864 on epoch=19
06/03/2022 04:41:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.485845 on epoch=21
06/03/2022 04:41:23 - INFO - __main__ - Step 180 Global step 180 Train loss 0.656628 on epoch=22
06/03/2022 04:41:28 - INFO - __main__ - Step 190 Global step 190 Train loss 0.473221 on epoch=23
06/03/2022 04:41:33 - INFO - __main__ - Step 200 Global step 200 Train loss 0.438869 on epoch=24
06/03/2022 04:41:34 - INFO - __main__ - Global step 200 Train loss 0.521085 Classification-F1 0.49206349206349204 on epoch=24
06/03/2022 04:41:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.410510 on epoch=26
06/03/2022 04:41:45 - INFO - __main__ - Step 220 Global step 220 Train loss 0.439289 on epoch=27
06/03/2022 04:41:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.408789 on epoch=28
06/03/2022 04:41:55 - INFO - __main__ - Step 240 Global step 240 Train loss 0.364753 on epoch=29
06/03/2022 04:42:00 - INFO - __main__ - Step 250 Global step 250 Train loss 0.441234 on epoch=31
06/03/2022 04:42:01 - INFO - __main__ - Global step 250 Train loss 0.412915 Classification-F1 0.0 on epoch=31
06/03/2022 04:42:06 - INFO - __main__ - Step 260 Global step 260 Train loss 0.395446 on epoch=32
06/03/2022 04:42:11 - INFO - __main__ - Step 270 Global step 270 Train loss 0.397438 on epoch=33
06/03/2022 04:42:17 - INFO - __main__ - Step 280 Global step 280 Train loss 0.433770 on epoch=34
06/03/2022 04:42:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.409666 on epoch=36
06/03/2022 04:42:27 - INFO - __main__ - Step 300 Global step 300 Train loss 0.400688 on epoch=37
06/03/2022 04:42:28 - INFO - __main__ - Global step 300 Train loss 0.407402 Classification-F1 1.0 on epoch=37
06/03/2022 04:42:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.404431 on epoch=38
06/03/2022 04:42:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.339898 on epoch=39
06/03/2022 04:42:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.355889 on epoch=41
06/03/2022 04:42:50 - INFO - __main__ - Step 340 Global step 340 Train loss 0.422848 on epoch=42
06/03/2022 04:42:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.401344 on epoch=43
06/03/2022 04:42:56 - INFO - __main__ - Global step 350 Train loss 0.384882 Classification-F1 0.49206349206349204 on epoch=43
06/03/2022 04:43:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.402166 on epoch=44
06/03/2022 04:43:06 - INFO - __main__ - Step 370 Global step 370 Train loss 0.392291 on epoch=46
06/03/2022 04:43:11 - INFO - __main__ - Step 380 Global step 380 Train loss 0.406319 on epoch=47
06/03/2022 04:43:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.383775 on epoch=48
06/03/2022 04:43:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.411862 on epoch=49
06/03/2022 04:43:22 - INFO - __main__ - Global step 400 Train loss 0.399282 Classification-F1 1.0 on epoch=49
06/03/2022 04:43:28 - INFO - __main__ - Step 410 Global step 410 Train loss 0.360689 on epoch=51
06/03/2022 04:43:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.390154 on epoch=52
06/03/2022 04:43:38 - INFO - __main__ - Step 430 Global step 430 Train loss 0.407087 on epoch=53
06/03/2022 04:43:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.411923 on epoch=54
06/03/2022 04:43:49 - INFO - __main__ - Step 450 Global step 450 Train loss 0.349386 on epoch=56
06/03/2022 04:43:49 - INFO - __main__ - Global step 450 Train loss 0.383848 Classification-F1 0.43859649122807015 on epoch=56
06/03/2022 04:43:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.418839 on epoch=57
06/03/2022 04:44:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.360028 on epoch=58
06/03/2022 04:44:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.342156 on epoch=59
06/03/2022 04:44:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.324814 on epoch=61
06/03/2022 04:44:15 - INFO - __main__ - Step 500 Global step 500 Train loss 0.342735 on epoch=62
06/03/2022 04:44:16 - INFO - __main__ - Global step 500 Train loss 0.357714 Classification-F1 0.49206349206349204 on epoch=62
06/03/2022 04:44:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.356858 on epoch=63
06/03/2022 04:44:27 - INFO - __main__ - Step 520 Global step 520 Train loss 0.314860 on epoch=64
06/03/2022 04:44:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.343189 on epoch=66
06/03/2022 04:44:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.338853 on epoch=67
06/03/2022 04:44:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.387221 on epoch=68
06/03/2022 04:44:43 - INFO - __main__ - Global step 550 Train loss 0.348196 Classification-F1 0.08571428571428572 on epoch=68
06/03/2022 04:44:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.343601 on epoch=69
06/03/2022 04:44:54 - INFO - __main__ - Step 570 Global step 570 Train loss 0.382060 on epoch=71
06/03/2022 04:44:59 - INFO - __main__ - Step 580 Global step 580 Train loss 0.355229 on epoch=72
06/03/2022 04:45:04 - INFO - __main__ - Step 590 Global step 590 Train loss 0.383752 on epoch=73
06/03/2022 04:45:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.369794 on epoch=74
06/03/2022 04:45:10 - INFO - __main__ - Global step 600 Train loss 0.366887 Classification-F1 0.452991452991453 on epoch=74
06/03/2022 04:45:15 - INFO - __main__ - Step 610 Global step 610 Train loss 0.345790 on epoch=76
06/03/2022 04:45:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.389724 on epoch=77
06/03/2022 04:45:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.343361 on epoch=78
06/03/2022 04:45:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.349682 on epoch=79
06/03/2022 04:45:36 - INFO - __main__ - Step 650 Global step 650 Train loss 0.364035 on epoch=81
06/03/2022 04:45:37 - INFO - __main__ - Global step 650 Train loss 0.358518 Classification-F1 0.488 on epoch=81
06/03/2022 04:45:42 - INFO - __main__ - Step 660 Global step 660 Train loss 0.303875 on epoch=82
06/03/2022 04:45:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.289647 on epoch=83
06/03/2022 04:45:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.339646 on epoch=84
06/03/2022 04:45:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.320814 on epoch=86
06/03/2022 04:46:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.309383 on epoch=87
06/03/2022 04:46:04 - INFO - __main__ - Global step 700 Train loss 0.312673 Classification-F1 0.49206349206349204 on epoch=87
06/03/2022 04:46:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.232074 on epoch=88
06/03/2022 04:46:14 - INFO - __main__ - Step 720 Global step 720 Train loss 0.215854 on epoch=89
06/03/2022 04:46:19 - INFO - __main__ - Step 730 Global step 730 Train loss 0.184874 on epoch=91
06/03/2022 04:46:24 - INFO - __main__ - Step 740 Global step 740 Train loss 0.287788 on epoch=92
06/03/2022 04:46:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.210768 on epoch=93
06/03/2022 04:46:30 - INFO - __main__ - Global step 750 Train loss 0.226272 Classification-F1 0.488 on epoch=93
06/03/2022 04:46:35 - INFO - __main__ - Step 760 Global step 760 Train loss 0.135682 on epoch=94
06/03/2022 04:46:40 - INFO - __main__ - Step 770 Global step 770 Train loss 0.206103 on epoch=96
06/03/2022 04:46:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.185746 on epoch=97
06/03/2022 04:46:50 - INFO - __main__ - Step 790 Global step 790 Train loss 0.229594 on epoch=98
06/03/2022 04:46:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.088638 on epoch=99
06/03/2022 04:46:56 - INFO - __main__ - Global step 800 Train loss 0.169153 Classification-F1 0.4838709677419355 on epoch=99
06/03/2022 04:47:01 - INFO - __main__ - Step 810 Global step 810 Train loss 0.138046 on epoch=101
06/03/2022 04:47:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.090391 on epoch=102
06/03/2022 04:47:11 - INFO - __main__ - Step 830 Global step 830 Train loss 0.135580 on epoch=103
06/03/2022 04:47:16 - INFO - __main__ - Step 840 Global step 840 Train loss 0.079384 on epoch=104
06/03/2022 04:47:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.102903 on epoch=106
06/03/2022 04:47:22 - INFO - __main__ - Global step 850 Train loss 0.109261 Classification-F1 0.488 on epoch=106
06/03/2022 04:47:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.061278 on epoch=107
06/03/2022 04:47:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.051451 on epoch=108
06/03/2022 04:47:38 - INFO - __main__ - Step 880 Global step 880 Train loss 0.051775 on epoch=109
06/03/2022 04:47:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.047965 on epoch=111
06/03/2022 04:47:48 - INFO - __main__ - Step 900 Global step 900 Train loss 0.035767 on epoch=112
06/03/2022 04:47:48 - INFO - __main__ - Global step 900 Train loss 0.049647 Classification-F1 0.46218487394957986 on epoch=112
06/03/2022 04:47:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.057805 on epoch=113
06/03/2022 04:47:59 - INFO - __main__ - Step 920 Global step 920 Train loss 0.040987 on epoch=114
06/03/2022 04:48:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.038709 on epoch=116
06/03/2022 04:48:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.051077 on epoch=117
06/03/2022 04:48:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.051875 on epoch=118
06/03/2022 04:48:14 - INFO - __main__ - Global step 950 Train loss 0.048091 Classification-F1 0.41284403669724773 on epoch=118
06/03/2022 04:48:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.036544 on epoch=119
06/03/2022 04:48:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.020305 on epoch=121
06/03/2022 04:48:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.016841 on epoch=122
06/03/2022 04:48:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.044692 on epoch=123
06/03/2022 04:48:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.017906 on epoch=124
06/03/2022 04:48:41 - INFO - __main__ - Global step 1000 Train loss 0.027257 Classification-F1 0.49606299212598426 on epoch=124
06/03/2022 04:48:41 - INFO - __main__ - save last model!
06/03/2022 04:48:41 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 04:48:41 - INFO - __main__ - Printing 3 examples
06/03/2022 04:48:41 - INFO - __main__ -  [ethos-race] Disability centres all around the world. That’s were our money goes. Let’s take em down
06/03/2022 04:48:41 - INFO - __main__ - ['false']
06/03/2022 04:48:41 - INFO - __main__ -  [ethos-race] FUCK GAYS disgusting
06/03/2022 04:48:41 - INFO - __main__ - ['false']
06/03/2022 04:48:41 - INFO - __main__ -  [ethos-race] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
06/03/2022 04:48:41 - INFO - __main__ - ['false']
06/03/2022 04:48:41 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:48:41 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:48:41 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 04:48:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 04:48:41 - INFO - __main__ - Printing 3 examples
06/03/2022 04:48:41 - INFO - __main__ -  [ethos-race] fucking slut deserved it
06/03/2022 04:48:41 - INFO - __main__ - ['false']
06/03/2022 04:48:41 - INFO - __main__ -  [ethos-race] Well done Slovakia and god bless. DO NOT build mosques, or allow or recognise Islam. They will get the point that EUROPE don't want Muslims here.
06/03/2022 04:48:41 - INFO - __main__ - ['false']
06/03/2022 04:48:41 - INFO - __main__ -  [ethos-race] Salute to Taliban Mujahideen. We Pakistanis are strongly supporting you. Go crush america and kill those bastards. Allah u Akbar. Victory will be yours Insha Allah.
06/03/2022 04:48:41 - INFO - __main__ - ['false']
06/03/2022 04:48:41 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:48:41 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:48:41 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 04:48:48 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 04:48:49 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 04:48:49 - INFO - __main__ - Printing 3 examples
06/03/2022 04:48:49 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 04:48:49 - INFO - __main__ - ['true']
06/03/2022 04:48:49 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 04:48:49 - INFO - __main__ - ['false']
06/03/2022 04:48:49 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 04:48:49 - INFO - __main__ - ['false']
06/03/2022 04:48:49 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:48:49 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:48:49 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 04:48:50 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_13_0.0002_8_predictions.txt
06/03/2022 04:48:50 - INFO - __main__ - Classification-F1 on test data: 0.4494
06/03/2022 04:48:51 - INFO - __main__ - prefix=ethos-race_64_13, lr=0.0002, bsz=8, dev_performance=1.0, test_performance=0.44936708860759494
06/03/2022 04:48:51 - INFO - __main__ - Running ... prefix=ethos-race_64_13, lr=0.0001, bsz=8 ...
06/03/2022 04:48:52 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 04:48:52 - INFO - __main__ - Printing 3 examples
06/03/2022 04:48:52 - INFO - __main__ -  [ethos-race] Disability centres all around the world. That’s were our money goes. Let’s take em down
06/03/2022 04:48:52 - INFO - __main__ - ['false']
06/03/2022 04:48:52 - INFO - __main__ -  [ethos-race] FUCK GAYS disgusting
06/03/2022 04:48:52 - INFO - __main__ - ['false']
06/03/2022 04:48:52 - INFO - __main__ -  [ethos-race] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
06/03/2022 04:48:52 - INFO - __main__ - ['false']
06/03/2022 04:48:52 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:48:52 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:48:52 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 04:48:52 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 04:48:52 - INFO - __main__ - Printing 3 examples
06/03/2022 04:48:52 - INFO - __main__ -  [ethos-race] fucking slut deserved it
06/03/2022 04:48:52 - INFO - __main__ - ['false']
06/03/2022 04:48:52 - INFO - __main__ -  [ethos-race] Well done Slovakia and god bless. DO NOT build mosques, or allow or recognise Islam. They will get the point that EUROPE don't want Muslims here.
06/03/2022 04:48:52 - INFO - __main__ - ['false']
06/03/2022 04:48:52 - INFO - __main__ -  [ethos-race] Salute to Taliban Mujahideen. We Pakistanis are strongly supporting you. Go crush america and kill those bastards. Allah u Akbar. Victory will be yours Insha Allah.
06/03/2022 04:48:52 - INFO - __main__ - ['false']
06/03/2022 04:48:52 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:48:52 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:48:52 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 04:48:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 04:48:52 - INFO - __main__ - Starting training!
06/03/2022 04:49:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 04:49:03 - INFO - __main__ - Starting training!
06/03/2022 04:49:07 - INFO - __main__ - Step 10 Global step 10 Train loss 23.413137 on epoch=1
06/03/2022 04:49:12 - INFO - __main__ - Step 20 Global step 20 Train loss 20.642075 on epoch=2
06/03/2022 04:49:17 - INFO - __main__ - Step 30 Global step 30 Train loss 18.958719 on epoch=3
06/03/2022 04:49:22 - INFO - __main__ - Step 40 Global step 40 Train loss 18.365458 on epoch=4
06/03/2022 04:49:27 - INFO - __main__ - Step 50 Global step 50 Train loss 16.553703 on epoch=6
06/03/2022 04:49:36 - INFO - __main__ - Global step 50 Train loss 19.586618 Classification-F1 0.0 on epoch=6
06/03/2022 04:49:41 - INFO - __main__ - Step 60 Global step 60 Train loss 17.476421 on epoch=7
06/03/2022 04:49:47 - INFO - __main__ - Step 70 Global step 70 Train loss 17.012445 on epoch=8
06/03/2022 04:49:52 - INFO - __main__ - Step 80 Global step 80 Train loss 16.038292 on epoch=9
06/03/2022 04:49:57 - INFO - __main__ - Step 90 Global step 90 Train loss 15.834036 on epoch=11
06/03/2022 04:50:02 - INFO - __main__ - Step 100 Global step 100 Train loss 14.961658 on epoch=12
06/03/2022 04:50:08 - INFO - __main__ - Global step 100 Train loss 16.264570 Classification-F1 0.0 on epoch=12
06/03/2022 04:50:13 - INFO - __main__ - Step 110 Global step 110 Train loss 16.082333 on epoch=13
06/03/2022 04:50:18 - INFO - __main__ - Step 120 Global step 120 Train loss 14.664281 on epoch=14
06/03/2022 04:50:23 - INFO - __main__ - Step 130 Global step 130 Train loss 14.787897 on epoch=16
06/03/2022 04:50:29 - INFO - __main__ - Step 140 Global step 140 Train loss 13.318300 on epoch=17
06/03/2022 04:50:34 - INFO - __main__ - Step 150 Global step 150 Train loss 13.733335 on epoch=18
06/03/2022 04:50:40 - INFO - __main__ - Global step 150 Train loss 14.517229 Classification-F1 0.0 on epoch=18
06/03/2022 04:50:45 - INFO - __main__ - Step 160 Global step 160 Train loss 12.668431 on epoch=19
06/03/2022 04:50:50 - INFO - __main__ - Step 170 Global step 170 Train loss 12.599205 on epoch=21
06/03/2022 04:50:56 - INFO - __main__ - Step 180 Global step 180 Train loss 12.152666 on epoch=22
06/03/2022 04:51:01 - INFO - __main__ - Step 190 Global step 190 Train loss 11.893868 on epoch=23
06/03/2022 04:51:06 - INFO - __main__ - Step 200 Global step 200 Train loss 11.544410 on epoch=24
06/03/2022 04:51:11 - INFO - __main__ - Global step 200 Train loss 12.171715 Classification-F1 0.0 on epoch=24
06/03/2022 04:51:16 - INFO - __main__ - Step 210 Global step 210 Train loss 9.863451 on epoch=26
06/03/2022 04:51:21 - INFO - __main__ - Step 220 Global step 220 Train loss 7.004233 on epoch=27
06/03/2022 04:51:26 - INFO - __main__ - Step 230 Global step 230 Train loss 4.676814 on epoch=28
06/03/2022 04:51:31 - INFO - __main__ - Step 240 Global step 240 Train loss 1.217906 on epoch=29
06/03/2022 04:51:36 - INFO - __main__ - Step 250 Global step 250 Train loss 0.999685 on epoch=31
06/03/2022 04:51:37 - INFO - __main__ - Global step 250 Train loss 4.752418 Classification-F1 0.49606299212598426 on epoch=31
06/03/2022 04:51:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.727452 on epoch=32
06/03/2022 04:51:48 - INFO - __main__ - Step 270 Global step 270 Train loss 0.849504 on epoch=33
06/03/2022 04:51:53 - INFO - __main__ - Step 280 Global step 280 Train loss 0.528252 on epoch=34
06/03/2022 04:51:58 - INFO - __main__ - Step 290 Global step 290 Train loss 0.390877 on epoch=36
06/03/2022 04:52:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.541257 on epoch=37
06/03/2022 04:52:04 - INFO - __main__ - Global step 300 Train loss 0.607468 Classification-F1 0.4796747967479675 on epoch=37
06/03/2022 04:52:09 - INFO - __main__ - Step 310 Global step 310 Train loss 0.384989 on epoch=38
06/03/2022 04:52:14 - INFO - __main__ - Step 320 Global step 320 Train loss 0.339091 on epoch=39
06/03/2022 04:52:19 - INFO - __main__ - Step 330 Global step 330 Train loss 0.383570 on epoch=41
06/03/2022 04:52:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.327311 on epoch=42
06/03/2022 04:52:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.371827 on epoch=43
06/03/2022 04:52:30 - INFO - __main__ - Global step 350 Train loss 0.361358 Classification-F1 0.28888888888888886 on epoch=43
06/03/2022 04:52:35 - INFO - __main__ - Step 360 Global step 360 Train loss 0.330304 on epoch=44
06/03/2022 04:52:40 - INFO - __main__ - Step 370 Global step 370 Train loss 0.247659 on epoch=46
06/03/2022 04:52:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.364667 on epoch=47
06/03/2022 04:52:51 - INFO - __main__ - Step 390 Global step 390 Train loss 0.202046 on epoch=48
06/03/2022 04:52:56 - INFO - __main__ - Step 400 Global step 400 Train loss 0.179497 on epoch=49
06/03/2022 04:52:56 - INFO - __main__ - Global step 400 Train loss 0.264834 Classification-F1 0.46218487394957986 on epoch=49
06/03/2022 04:53:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.220448 on epoch=51
06/03/2022 04:53:06 - INFO - __main__ - Step 420 Global step 420 Train loss 0.244811 on epoch=52
06/03/2022 04:53:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.211867 on epoch=53
06/03/2022 04:53:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.230454 on epoch=54
06/03/2022 04:53:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.203789 on epoch=56
06/03/2022 04:53:22 - INFO - __main__ - Global step 450 Train loss 0.222274 Classification-F1 0.4666666666666667 on epoch=56
06/03/2022 04:53:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.155067 on epoch=57
06/03/2022 04:53:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.178336 on epoch=58
06/03/2022 04:53:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.129767 on epoch=59
06/03/2022 04:53:43 - INFO - __main__ - Step 490 Global step 490 Train loss 0.207005 on epoch=61
06/03/2022 04:53:48 - INFO - __main__ - Step 500 Global step 500 Train loss 0.212460 on epoch=62
06/03/2022 04:53:49 - INFO - __main__ - Global step 500 Train loss 0.176527 Classification-F1 0.4482758620689655 on epoch=62
06/03/2022 04:53:54 - INFO - __main__ - Step 510 Global step 510 Train loss 0.171228 on epoch=63
06/03/2022 04:53:59 - INFO - __main__ - Step 520 Global step 520 Train loss 0.182163 on epoch=64
06/03/2022 04:54:04 - INFO - __main__ - Step 530 Global step 530 Train loss 0.119911 on epoch=66
06/03/2022 04:54:09 - INFO - __main__ - Step 540 Global step 540 Train loss 0.107561 on epoch=67
06/03/2022 04:54:14 - INFO - __main__ - Step 550 Global step 550 Train loss 0.154164 on epoch=68
06/03/2022 04:54:15 - INFO - __main__ - Global step 550 Train loss 0.147006 Classification-F1 0.4666666666666667 on epoch=68
06/03/2022 04:54:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.090824 on epoch=69
06/03/2022 04:54:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.124378 on epoch=71
06/03/2022 04:54:30 - INFO - __main__ - Step 580 Global step 580 Train loss 0.123625 on epoch=72
06/03/2022 04:54:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.074477 on epoch=73
06/03/2022 04:54:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.071023 on epoch=74
06/03/2022 04:54:41 - INFO - __main__ - Global step 600 Train loss 0.096865 Classification-F1 0.4576271186440678 on epoch=74
06/03/2022 04:54:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.125806 on epoch=76
06/03/2022 04:54:51 - INFO - __main__ - Step 620 Global step 620 Train loss 0.063194 on epoch=77
06/03/2022 04:54:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.101636 on epoch=78
06/03/2022 04:55:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.056179 on epoch=79
06/03/2022 04:55:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.104875 on epoch=81
06/03/2022 04:55:07 - INFO - __main__ - Global step 650 Train loss 0.090338 Classification-F1 0.4666666666666667 on epoch=81
06/03/2022 04:55:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.051918 on epoch=82
06/03/2022 04:55:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.115033 on epoch=83
06/03/2022 04:55:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.076027 on epoch=84
06/03/2022 04:55:28 - INFO - __main__ - Step 690 Global step 690 Train loss 0.048941 on epoch=86
06/03/2022 04:55:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.033122 on epoch=87
06/03/2022 04:55:34 - INFO - __main__ - Global step 700 Train loss 0.065008 Classification-F1 0.47107438016528924 on epoch=87
06/03/2022 04:55:39 - INFO - __main__ - Step 710 Global step 710 Train loss 0.060853 on epoch=88
06/03/2022 04:55:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.044669 on epoch=89
06/03/2022 04:55:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.071292 on epoch=91
06/03/2022 04:55:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.033558 on epoch=92
06/03/2022 04:55:59 - INFO - __main__ - Step 750 Global step 750 Train loss 0.082812 on epoch=93
06/03/2022 04:56:00 - INFO - __main__ - Global step 750 Train loss 0.058637 Classification-F1 0.42857142857142855 on epoch=93
06/03/2022 04:56:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.060612 on epoch=94
06/03/2022 04:56:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.101333 on epoch=96
06/03/2022 04:56:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.033278 on epoch=97
06/03/2022 04:56:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.037021 on epoch=98
06/03/2022 04:56:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.074317 on epoch=99
06/03/2022 04:56:26 - INFO - __main__ - Global step 800 Train loss 0.061312 Classification-F1 0.47540983606557374 on epoch=99
06/03/2022 04:56:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.037886 on epoch=101
06/03/2022 04:56:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.038599 on epoch=102
06/03/2022 04:56:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.014927 on epoch=103
06/03/2022 04:56:47 - INFO - __main__ - Step 840 Global step 840 Train loss 0.049238 on epoch=104
06/03/2022 04:56:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.033309 on epoch=106
06/03/2022 04:56:52 - INFO - __main__ - Global step 850 Train loss 0.034792 Classification-F1 0.4796747967479675 on epoch=106
06/03/2022 04:56:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.053979 on epoch=107
06/03/2022 04:57:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.035934 on epoch=108
06/03/2022 04:57:08 - INFO - __main__ - Step 880 Global step 880 Train loss 0.019740 on epoch=109
06/03/2022 04:57:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.025265 on epoch=111
06/03/2022 04:57:18 - INFO - __main__ - Step 900 Global step 900 Train loss 0.022113 on epoch=112
06/03/2022 04:57:19 - INFO - __main__ - Global step 900 Train loss 0.031406 Classification-F1 0.452991452991453 on epoch=112
06/03/2022 04:57:24 - INFO - __main__ - Step 910 Global step 910 Train loss 0.019591 on epoch=113
06/03/2022 04:57:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.035039 on epoch=114
06/03/2022 04:57:34 - INFO - __main__ - Step 930 Global step 930 Train loss 0.022380 on epoch=116
06/03/2022 04:57:39 - INFO - __main__ - Step 940 Global step 940 Train loss 0.030020 on epoch=117
06/03/2022 04:57:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.022341 on epoch=118
06/03/2022 04:57:45 - INFO - __main__ - Global step 950 Train loss 0.025874 Classification-F1 0.43859649122807015 on epoch=118
06/03/2022 04:57:51 - INFO - __main__ - Step 960 Global step 960 Train loss 0.020268 on epoch=119
06/03/2022 04:57:56 - INFO - __main__ - Step 970 Global step 970 Train loss 0.020818 on epoch=121
06/03/2022 04:58:01 - INFO - __main__ - Step 980 Global step 980 Train loss 0.015655 on epoch=122
06/03/2022 04:58:07 - INFO - __main__ - Step 990 Global step 990 Train loss 0.008931 on epoch=123
06/03/2022 04:58:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.032635 on epoch=124
06/03/2022 04:58:13 - INFO - __main__ - Global step 1000 Train loss 0.019661 Classification-F1 0.452991452991453 on epoch=124
06/03/2022 04:58:13 - INFO - __main__ - save last model!
06/03/2022 04:58:13 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 04:58:13 - INFO - __main__ - Printing 3 examples
06/03/2022 04:58:13 - INFO - __main__ -  [ethos-race] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
06/03/2022 04:58:13 - INFO - __main__ - ['false']
06/03/2022 04:58:13 - INFO - __main__ -  [ethos-race] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
06/03/2022 04:58:13 - INFO - __main__ - ['false']
06/03/2022 04:58:13 - INFO - __main__ -  [ethos-race] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
06/03/2022 04:58:13 - INFO - __main__ - ['false']
06/03/2022 04:58:13 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:58:13 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:58:13 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 04:58:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 04:58:13 - INFO - __main__ - Printing 3 examples
06/03/2022 04:58:13 - INFO - __main__ -  [ethos-race] WOW THIS GUY TALKS LIKE A RETARD HAHAHAHAHAH
06/03/2022 04:58:13 - INFO - __main__ - ['false']
06/03/2022 04:58:13 - INFO - __main__ -  [ethos-race] Hindus take my ass please
06/03/2022 04:58:13 - INFO - __main__ - ['false']
06/03/2022 04:58:13 - INFO - __main__ -  [ethos-race] Incest baby that got double-down syndrome
06/03/2022 04:58:13 - INFO - __main__ - ['false']
06/03/2022 04:58:13 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:58:13 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:58:13 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 04:58:20 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 04:58:20 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 04:58:20 - INFO - __main__ - Printing 3 examples
06/03/2022 04:58:20 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 04:58:20 - INFO - __main__ - ['true']
06/03/2022 04:58:20 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 04:58:20 - INFO - __main__ - ['false']
06/03/2022 04:58:20 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 04:58:20 - INFO - __main__ - ['false']
06/03/2022 04:58:20 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:58:20 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:58:21 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 04:58:22 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_13_0.0001_8_predictions.txt
06/03/2022 04:58:22 - INFO - __main__ - Classification-F1 on test data: 0.4387
06/03/2022 04:58:22 - INFO - __main__ - prefix=ethos-race_64_13, lr=0.0001, bsz=8, dev_performance=0.49606299212598426, test_performance=0.4387096774193549
06/03/2022 04:58:22 - INFO - __main__ - Running ... prefix=ethos-race_64_21, lr=0.0005, bsz=8 ...
06/03/2022 04:58:23 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 04:58:23 - INFO - __main__ - Printing 3 examples
06/03/2022 04:58:23 - INFO - __main__ -  [ethos-race] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
06/03/2022 04:58:23 - INFO - __main__ - ['false']
06/03/2022 04:58:23 - INFO - __main__ -  [ethos-race] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
06/03/2022 04:58:23 - INFO - __main__ - ['false']
06/03/2022 04:58:23 - INFO - __main__ -  [ethos-race] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
06/03/2022 04:58:23 - INFO - __main__ - ['false']
06/03/2022 04:58:23 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:58:23 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:58:23 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 04:58:23 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 04:58:23 - INFO - __main__ - Printing 3 examples
06/03/2022 04:58:23 - INFO - __main__ -  [ethos-race] WOW THIS GUY TALKS LIKE A RETARD HAHAHAHAHAH
06/03/2022 04:58:23 - INFO - __main__ - ['false']
06/03/2022 04:58:23 - INFO - __main__ -  [ethos-race] Hindus take my ass please
06/03/2022 04:58:23 - INFO - __main__ - ['false']
06/03/2022 04:58:23 - INFO - __main__ -  [ethos-race] Incest baby that got double-down syndrome
06/03/2022 04:58:23 - INFO - __main__ - ['false']
06/03/2022 04:58:23 - INFO - __main__ - Tokenizing Input ...
06/03/2022 04:58:23 - INFO - __main__ - Tokenizing Output ...
06/03/2022 04:58:24 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 04:58:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 04:58:26 - INFO - __main__ - Starting training!
06/03/2022 04:58:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 04:58:36 - INFO - __main__ - Starting training!
06/03/2022 04:58:41 - INFO - __main__ - Step 10 Global step 10 Train loss 24.535299 on epoch=1
06/03/2022 04:58:46 - INFO - __main__ - Step 20 Global step 20 Train loss 17.156464 on epoch=2
06/03/2022 04:58:51 - INFO - __main__ - Step 30 Global step 30 Train loss 16.304533 on epoch=3
06/03/2022 04:58:56 - INFO - __main__ - Step 40 Global step 40 Train loss 14.841362 on epoch=4
06/03/2022 04:59:01 - INFO - __main__ - Step 50 Global step 50 Train loss 13.194142 on epoch=6
06/03/2022 04:59:02 - INFO - __main__ - Global step 50 Train loss 17.206362 Classification-F1 0.0 on epoch=6
06/03/2022 04:59:08 - INFO - __main__ - Step 60 Global step 60 Train loss 10.152292 on epoch=7
06/03/2022 04:59:13 - INFO - __main__ - Step 70 Global step 70 Train loss 6.069180 on epoch=8
06/03/2022 04:59:18 - INFO - __main__ - Step 80 Global step 80 Train loss 2.460498 on epoch=9
06/03/2022 04:59:24 - INFO - __main__ - Step 90 Global step 90 Train loss 0.775797 on epoch=11
06/03/2022 04:59:29 - INFO - __main__ - Step 100 Global step 100 Train loss 0.596527 on epoch=12
06/03/2022 04:59:29 - INFO - __main__ - Global step 100 Train loss 4.010859 Classification-F1 1.0 on epoch=12
06/03/2022 04:59:35 - INFO - __main__ - Step 110 Global step 110 Train loss 0.478798 on epoch=13
06/03/2022 04:59:41 - INFO - __main__ - Step 120 Global step 120 Train loss 0.502293 on epoch=14
06/03/2022 04:59:46 - INFO - __main__ - Step 130 Global step 130 Train loss 0.467994 on epoch=16
06/03/2022 04:59:51 - INFO - __main__ - Step 140 Global step 140 Train loss 0.397577 on epoch=17
06/03/2022 04:59:57 - INFO - __main__ - Step 150 Global step 150 Train loss 0.511431 on epoch=18
06/03/2022 04:59:57 - INFO - __main__ - Global step 150 Train loss 0.471619 Classification-F1 0.46218487394957986 on epoch=18
06/03/2022 05:00:02 - INFO - __main__ - Step 160 Global step 160 Train loss 0.392544 on epoch=19
06/03/2022 05:00:08 - INFO - __main__ - Step 170 Global step 170 Train loss 0.411808 on epoch=21
06/03/2022 05:00:13 - INFO - __main__ - Step 180 Global step 180 Train loss 0.359229 on epoch=22
06/03/2022 05:00:18 - INFO - __main__ - Step 190 Global step 190 Train loss 0.391641 on epoch=23
06/03/2022 05:00:23 - INFO - __main__ - Step 200 Global step 200 Train loss 0.458612 on epoch=24
06/03/2022 05:00:24 - INFO - __main__ - Global step 200 Train loss 0.402767 Classification-F1 1.0 on epoch=24
06/03/2022 05:00:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.355146 on epoch=26
06/03/2022 05:00:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.395389 on epoch=27
06/03/2022 05:00:40 - INFO - __main__ - Step 230 Global step 230 Train loss 0.411161 on epoch=28
06/03/2022 05:00:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.343459 on epoch=29
06/03/2022 05:00:50 - INFO - __main__ - Step 250 Global step 250 Train loss 0.294404 on epoch=31
06/03/2022 05:00:51 - INFO - __main__ - Global step 250 Train loss 0.359912 Classification-F1 0.42342342342342343 on epoch=31
06/03/2022 05:00:56 - INFO - __main__ - Step 260 Global step 260 Train loss 0.310922 on epoch=32
06/03/2022 05:01:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.283698 on epoch=33
06/03/2022 05:01:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.259714 on epoch=34
06/03/2022 05:01:11 - INFO - __main__ - Step 290 Global step 290 Train loss 0.259633 on epoch=36
06/03/2022 05:01:17 - INFO - __main__ - Step 300 Global step 300 Train loss 0.337937 on epoch=37
06/03/2022 05:01:17 - INFO - __main__ - Global step 300 Train loss 0.290381 Classification-F1 0.49206349206349204 on epoch=37
06/03/2022 05:01:23 - INFO - __main__ - Step 310 Global step 310 Train loss 0.236440 on epoch=38
06/03/2022 05:01:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.226702 on epoch=39
06/03/2022 05:01:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.171511 on epoch=41
06/03/2022 05:01:38 - INFO - __main__ - Step 340 Global step 340 Train loss 0.289938 on epoch=42
06/03/2022 05:01:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.189682 on epoch=43
06/03/2022 05:01:44 - INFO - __main__ - Global step 350 Train loss 0.222855 Classification-F1 0.40186915887850466 on epoch=43
06/03/2022 05:01:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.135481 on epoch=44
06/03/2022 05:01:55 - INFO - __main__ - Step 370 Global step 370 Train loss 0.131270 on epoch=46
06/03/2022 05:02:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.085173 on epoch=47
06/03/2022 05:02:05 - INFO - __main__ - Step 390 Global step 390 Train loss 0.086753 on epoch=48
06/03/2022 05:02:10 - INFO - __main__ - Step 400 Global step 400 Train loss 0.116936 on epoch=49
06/03/2022 05:02:11 - INFO - __main__ - Global step 400 Train loss 0.111122 Classification-F1 0.4796747967479675 on epoch=49
06/03/2022 05:02:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.229492 on epoch=51
06/03/2022 05:02:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.143951 on epoch=52
06/03/2022 05:02:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.084734 on epoch=53
06/03/2022 05:02:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.119648 on epoch=54
06/03/2022 05:02:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.114985 on epoch=56
06/03/2022 05:02:38 - INFO - __main__ - Global step 450 Train loss 0.138562 Classification-F1 0.49206349206349204 on epoch=56
06/03/2022 05:02:43 - INFO - __main__ - Step 460 Global step 460 Train loss 0.144695 on epoch=57
06/03/2022 05:02:48 - INFO - __main__ - Step 470 Global step 470 Train loss 0.040286 on epoch=58
06/03/2022 05:02:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.058991 on epoch=59
06/03/2022 05:02:59 - INFO - __main__ - Step 490 Global step 490 Train loss 0.044832 on epoch=61
06/03/2022 05:03:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.146914 on epoch=62
06/03/2022 05:03:05 - INFO - __main__ - Global step 500 Train loss 0.087143 Classification-F1 0.4434782608695652 on epoch=62
06/03/2022 05:03:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.056844 on epoch=63
06/03/2022 05:03:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.055718 on epoch=64
06/03/2022 05:03:21 - INFO - __main__ - Step 530 Global step 530 Train loss 0.052048 on epoch=66
06/03/2022 05:03:26 - INFO - __main__ - Step 540 Global step 540 Train loss 0.023178 on epoch=67
06/03/2022 05:03:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.021902 on epoch=68
06/03/2022 05:03:32 - INFO - __main__ - Global step 550 Train loss 0.041938 Classification-F1 0.42857142857142855 on epoch=68
06/03/2022 05:03:37 - INFO - __main__ - Step 560 Global step 560 Train loss 0.020381 on epoch=69
06/03/2022 05:03:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.077178 on epoch=71
06/03/2022 05:03:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.032604 on epoch=72
06/03/2022 05:03:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.014881 on epoch=73
06/03/2022 05:03:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.022196 on epoch=74
06/03/2022 05:03:59 - INFO - __main__ - Global step 600 Train loss 0.033448 Classification-F1 0.29239766081871343 on epoch=74
06/03/2022 05:04:04 - INFO - __main__ - Step 610 Global step 610 Train loss 0.027488 on epoch=76
06/03/2022 05:04:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.004443 on epoch=77
06/03/2022 05:04:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.036425 on epoch=78
06/03/2022 05:04:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.057488 on epoch=79
06/03/2022 05:04:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.065187 on epoch=81
06/03/2022 05:04:26 - INFO - __main__ - Global step 650 Train loss 0.038206 Classification-F1 0.47540983606557374 on epoch=81
06/03/2022 05:04:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.003482 on epoch=82
06/03/2022 05:04:36 - INFO - __main__ - Step 670 Global step 670 Train loss 0.006475 on epoch=83
06/03/2022 05:04:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.009646 on epoch=84
06/03/2022 05:04:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.002998 on epoch=86
06/03/2022 05:04:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.002772 on epoch=87
06/03/2022 05:04:53 - INFO - __main__ - Global step 700 Train loss 0.005075 Classification-F1 0.4838709677419355 on epoch=87
06/03/2022 05:04:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.067752 on epoch=88
06/03/2022 05:05:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.007161 on epoch=89
06/03/2022 05:05:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.064144 on epoch=91
06/03/2022 05:05:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.007816 on epoch=92
06/03/2022 05:05:19 - INFO - __main__ - Step 750 Global step 750 Train loss 0.003664 on epoch=93
06/03/2022 05:05:20 - INFO - __main__ - Global step 750 Train loss 0.030107 Classification-F1 0.4838709677419355 on epoch=93
06/03/2022 05:05:25 - INFO - __main__ - Step 760 Global step 760 Train loss 0.011785 on epoch=94
06/03/2022 05:05:30 - INFO - __main__ - Step 770 Global step 770 Train loss 0.007094 on epoch=96
06/03/2022 05:05:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.003934 on epoch=97
06/03/2022 05:05:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.008144 on epoch=98
06/03/2022 05:05:46 - INFO - __main__ - Step 800 Global step 800 Train loss 0.004891 on epoch=99
06/03/2022 05:05:47 - INFO - __main__ - Global step 800 Train loss 0.007170 Classification-F1 0.4666666666666667 on epoch=99
06/03/2022 05:05:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.014572 on epoch=101
06/03/2022 05:05:57 - INFO - __main__ - Step 820 Global step 820 Train loss 0.002377 on epoch=102
06/03/2022 05:06:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.002602 on epoch=103
06/03/2022 05:06:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.009874 on epoch=104
06/03/2022 05:06:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.015260 on epoch=106
06/03/2022 05:06:14 - INFO - __main__ - Global step 850 Train loss 0.008937 Classification-F1 0.488 on epoch=106
06/03/2022 05:06:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.061546 on epoch=107
06/03/2022 05:06:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.021223 on epoch=108
06/03/2022 05:06:29 - INFO - __main__ - Step 880 Global step 880 Train loss 0.020463 on epoch=109
06/03/2022 05:06:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.004175 on epoch=111
06/03/2022 05:06:40 - INFO - __main__ - Step 900 Global step 900 Train loss 0.014084 on epoch=112
06/03/2022 05:06:40 - INFO - __main__ - Global step 900 Train loss 0.024298 Classification-F1 0.488 on epoch=112
06/03/2022 05:06:46 - INFO - __main__ - Step 910 Global step 910 Train loss 0.002666 on epoch=113
06/03/2022 05:06:51 - INFO - __main__ - Step 920 Global step 920 Train loss 0.051763 on epoch=114
06/03/2022 05:06:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.002534 on epoch=116
06/03/2022 05:07:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.036675 on epoch=117
06/03/2022 05:07:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.003030 on epoch=118
06/03/2022 05:07:07 - INFO - __main__ - Global step 950 Train loss 0.019333 Classification-F1 0.47107438016528924 on epoch=118
06/03/2022 05:07:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.009096 on epoch=119
06/03/2022 05:07:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.008014 on epoch=121
06/03/2022 05:07:22 - INFO - __main__ - Step 980 Global step 980 Train loss 0.012818 on epoch=122
06/03/2022 05:07:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.008798 on epoch=123
06/03/2022 05:07:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.001841 on epoch=124
06/03/2022 05:07:33 - INFO - __main__ - Global step 1000 Train loss 0.008114 Classification-F1 0.4576271186440678 on epoch=124
06/03/2022 05:07:33 - INFO - __main__ - save last model!
06/03/2022 05:07:34 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 05:07:34 - INFO - __main__ - Printing 3 examples
06/03/2022 05:07:34 - INFO - __main__ -  [ethos-race] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
06/03/2022 05:07:34 - INFO - __main__ - ['false']
06/03/2022 05:07:34 - INFO - __main__ -  [ethos-race] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
06/03/2022 05:07:34 - INFO - __main__ - ['false']
06/03/2022 05:07:34 - INFO - __main__ -  [ethos-race] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
06/03/2022 05:07:34 - INFO - __main__ - ['false']
06/03/2022 05:07:34 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:07:34 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:07:34 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 05:07:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 05:07:34 - INFO - __main__ - Printing 3 examples
06/03/2022 05:07:34 - INFO - __main__ -  [ethos-race] WOW THIS GUY TALKS LIKE A RETARD HAHAHAHAHAH
06/03/2022 05:07:34 - INFO - __main__ - ['false']
06/03/2022 05:07:34 - INFO - __main__ -  [ethos-race] Hindus take my ass please
06/03/2022 05:07:34 - INFO - __main__ - ['false']
06/03/2022 05:07:34 - INFO - __main__ -  [ethos-race] Incest baby that got double-down syndrome
06/03/2022 05:07:34 - INFO - __main__ - ['false']
06/03/2022 05:07:34 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:07:34 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:07:34 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 05:07:40 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 05:07:41 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 05:07:41 - INFO - __main__ - Printing 3 examples
06/03/2022 05:07:41 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 05:07:41 - INFO - __main__ - ['true']
06/03/2022 05:07:41 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 05:07:41 - INFO - __main__ - ['false']
06/03/2022 05:07:41 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 05:07:41 - INFO - __main__ - ['false']
06/03/2022 05:07:41 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:07:41 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:07:41 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 05:07:42 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_21_0.0005_8_predictions.txt
06/03/2022 05:07:42 - INFO - __main__ - Classification-F1 on test data: 0.4494
06/03/2022 05:07:43 - INFO - __main__ - prefix=ethos-race_64_21, lr=0.0005, bsz=8, dev_performance=1.0, test_performance=0.44936708860759494
06/03/2022 05:07:43 - INFO - __main__ - Running ... prefix=ethos-race_64_21, lr=0.0003, bsz=8 ...
06/03/2022 05:07:44 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 05:07:44 - INFO - __main__ - Printing 3 examples
06/03/2022 05:07:44 - INFO - __main__ -  [ethos-race] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
06/03/2022 05:07:44 - INFO - __main__ - ['false']
06/03/2022 05:07:44 - INFO - __main__ -  [ethos-race] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
06/03/2022 05:07:44 - INFO - __main__ - ['false']
06/03/2022 05:07:44 - INFO - __main__ -  [ethos-race] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
06/03/2022 05:07:44 - INFO - __main__ - ['false']
06/03/2022 05:07:44 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:07:44 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:07:44 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 05:07:44 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 05:07:44 - INFO - __main__ - Printing 3 examples
06/03/2022 05:07:44 - INFO - __main__ -  [ethos-race] WOW THIS GUY TALKS LIKE A RETARD HAHAHAHAHAH
06/03/2022 05:07:44 - INFO - __main__ - ['false']
06/03/2022 05:07:44 - INFO - __main__ -  [ethos-race] Hindus take my ass please
06/03/2022 05:07:44 - INFO - __main__ - ['false']
06/03/2022 05:07:44 - INFO - __main__ -  [ethos-race] Incest baby that got double-down syndrome
06/03/2022 05:07:44 - INFO - __main__ - ['false']
06/03/2022 05:07:44 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:07:44 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:07:44 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 05:07:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 05:07:45 - INFO - __main__ - Starting training!
06/03/2022 05:07:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 05:07:55 - INFO - __main__ - Starting training!
06/03/2022 05:07:59 - INFO - __main__ - Step 10 Global step 10 Train loss 24.711922 on epoch=1
06/03/2022 05:08:04 - INFO - __main__ - Step 20 Global step 20 Train loss 21.485542 on epoch=2
06/03/2022 05:08:09 - INFO - __main__ - Step 30 Global step 30 Train loss 17.194736 on epoch=3
06/03/2022 05:08:14 - INFO - __main__ - Step 40 Global step 40 Train loss 16.004139 on epoch=4
06/03/2022 05:08:19 - INFO - __main__ - Step 50 Global step 50 Train loss 14.908381 on epoch=6
06/03/2022 05:08:30 - INFO - __main__ - Global step 50 Train loss 18.860945 Classification-F1 0.0 on epoch=6
06/03/2022 05:08:36 - INFO - __main__ - Step 60 Global step 60 Train loss 14.220942 on epoch=7
06/03/2022 05:08:41 - INFO - __main__ - Step 70 Global step 70 Train loss 12.303656 on epoch=8
06/03/2022 05:08:46 - INFO - __main__ - Step 80 Global step 80 Train loss 10.476382 on epoch=9
06/03/2022 05:08:51 - INFO - __main__ - Step 90 Global step 90 Train loss 5.608006 on epoch=11
06/03/2022 05:08:56 - INFO - __main__ - Step 100 Global step 100 Train loss 1.929130 on epoch=12
06/03/2022 05:08:57 - INFO - __main__ - Global step 100 Train loss 8.907623 Classification-F1 0.328042328042328 on epoch=12
06/03/2022 05:09:03 - INFO - __main__ - Step 110 Global step 110 Train loss 2.156522 on epoch=13
06/03/2022 05:09:08 - INFO - __main__ - Step 120 Global step 120 Train loss 2.582803 on epoch=14
06/03/2022 05:09:13 - INFO - __main__ - Step 130 Global step 130 Train loss 0.867905 on epoch=16
06/03/2022 05:09:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.522667 on epoch=17
06/03/2022 05:09:23 - INFO - __main__ - Step 150 Global step 150 Train loss 0.466444 on epoch=18
06/03/2022 05:09:24 - INFO - __main__ - Global step 150 Train loss 1.319268 Classification-F1 0.2 on epoch=18
06/03/2022 05:09:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.427537 on epoch=19
06/03/2022 05:09:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.381001 on epoch=21
06/03/2022 05:09:40 - INFO - __main__ - Step 180 Global step 180 Train loss 0.398673 on epoch=22
06/03/2022 05:09:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.538764 on epoch=23
06/03/2022 05:09:50 - INFO - __main__ - Step 200 Global step 200 Train loss 0.415248 on epoch=24
06/03/2022 05:09:51 - INFO - __main__ - Global step 200 Train loss 0.432245 Classification-F1 0.49606299212598426 on epoch=24
06/03/2022 05:09:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.338092 on epoch=26
06/03/2022 05:10:02 - INFO - __main__ - Step 220 Global step 220 Train loss 0.316873 on epoch=27
06/03/2022 05:10:07 - INFO - __main__ - Step 230 Global step 230 Train loss 0.402270 on epoch=28
06/03/2022 05:10:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.390054 on epoch=29
06/03/2022 05:10:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.380817 on epoch=31
06/03/2022 05:10:18 - INFO - __main__ - Global step 250 Train loss 0.365621 Classification-F1 0.30434782608695654 on epoch=31
06/03/2022 05:10:23 - INFO - __main__ - Step 260 Global step 260 Train loss 0.362195 on epoch=32
06/03/2022 05:10:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.339736 on epoch=33
06/03/2022 05:10:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.306800 on epoch=34
06/03/2022 05:10:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.302349 on epoch=36
06/03/2022 05:10:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.338707 on epoch=37
06/03/2022 05:10:44 - INFO - __main__ - Global step 300 Train loss 0.329957 Classification-F1 1.0 on epoch=37
06/03/2022 05:10:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.344783 on epoch=38
06/03/2022 05:10:55 - INFO - __main__ - Step 320 Global step 320 Train loss 0.290720 on epoch=39
06/03/2022 05:11:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.289067 on epoch=41
06/03/2022 05:11:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.322986 on epoch=42
06/03/2022 05:11:11 - INFO - __main__ - Step 350 Global step 350 Train loss 0.298147 on epoch=43
06/03/2022 05:11:12 - INFO - __main__ - Global step 350 Train loss 0.309141 Classification-F1 0.08571428571428572 on epoch=43
06/03/2022 05:11:17 - INFO - __main__ - Step 360 Global step 360 Train loss 0.257144 on epoch=44
06/03/2022 05:11:22 - INFO - __main__ - Step 370 Global step 370 Train loss 0.227385 on epoch=46
06/03/2022 05:11:27 - INFO - __main__ - Step 380 Global step 380 Train loss 0.324368 on epoch=47
06/03/2022 05:11:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.296760 on epoch=48
06/03/2022 05:11:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.269771 on epoch=49
06/03/2022 05:11:38 - INFO - __main__ - Global step 400 Train loss 0.275086 Classification-F1 0.49206349206349204 on epoch=49
06/03/2022 05:11:43 - INFO - __main__ - Step 410 Global step 410 Train loss 0.260069 on epoch=51
06/03/2022 05:11:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.286598 on epoch=52
06/03/2022 05:11:53 - INFO - __main__ - Step 430 Global step 430 Train loss 0.278171 on epoch=53
06/03/2022 05:11:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.234463 on epoch=54
06/03/2022 05:12:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.176496 on epoch=56
06/03/2022 05:12:04 - INFO - __main__ - Global step 450 Train loss 0.247159 Classification-F1 0.49606299212598426 on epoch=56
06/03/2022 05:12:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.288591 on epoch=57
06/03/2022 05:12:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.236124 on epoch=58
06/03/2022 05:12:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.297287 on epoch=59
06/03/2022 05:12:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.205548 on epoch=61
06/03/2022 05:12:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.223982 on epoch=62
06/03/2022 05:12:31 - INFO - __main__ - Global step 500 Train loss 0.250306 Classification-F1 1.0 on epoch=62
06/03/2022 05:12:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.240428 on epoch=63
06/03/2022 05:12:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.168692 on epoch=64
06/03/2022 05:12:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.196898 on epoch=66
06/03/2022 05:12:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.204026 on epoch=67
06/03/2022 05:12:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.145637 on epoch=68
06/03/2022 05:12:57 - INFO - __main__ - Global step 550 Train loss 0.191136 Classification-F1 0.4434782608695652 on epoch=68
06/03/2022 05:13:02 - INFO - __main__ - Step 560 Global step 560 Train loss 0.157619 on epoch=69
06/03/2022 05:13:08 - INFO - __main__ - Step 570 Global step 570 Train loss 0.114228 on epoch=71
06/03/2022 05:13:13 - INFO - __main__ - Step 580 Global step 580 Train loss 0.184980 on epoch=72
06/03/2022 05:13:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.180022 on epoch=73
06/03/2022 05:13:23 - INFO - __main__ - Step 600 Global step 600 Train loss 0.181897 on epoch=74
06/03/2022 05:13:24 - INFO - __main__ - Global step 600 Train loss 0.163749 Classification-F1 0.4796747967479675 on epoch=74
06/03/2022 05:13:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.168375 on epoch=76
06/03/2022 05:13:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.141498 on epoch=77
06/03/2022 05:13:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.204478 on epoch=78
06/03/2022 05:13:44 - INFO - __main__ - Step 640 Global step 640 Train loss 0.153753 on epoch=79
06/03/2022 05:13:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.132734 on epoch=81
06/03/2022 05:13:50 - INFO - __main__ - Global step 650 Train loss 0.160168 Classification-F1 0.49206349206349204 on epoch=81
06/03/2022 05:13:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.145904 on epoch=82
06/03/2022 05:14:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.134814 on epoch=83
06/03/2022 05:14:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.107885 on epoch=84
06/03/2022 05:14:11 - INFO - __main__ - Step 690 Global step 690 Train loss 0.102408 on epoch=86
06/03/2022 05:14:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.101808 on epoch=87
06/03/2022 05:14:17 - INFO - __main__ - Global step 700 Train loss 0.118564 Classification-F1 0.4796747967479675 on epoch=87
06/03/2022 05:14:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.119046 on epoch=88
06/03/2022 05:14:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.098430 on epoch=89
06/03/2022 05:14:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.058328 on epoch=91
06/03/2022 05:14:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.099303 on epoch=92
06/03/2022 05:14:43 - INFO - __main__ - Step 750 Global step 750 Train loss 0.069205 on epoch=93
06/03/2022 05:14:43 - INFO - __main__ - Global step 750 Train loss 0.088862 Classification-F1 0.47107438016528924 on epoch=93
06/03/2022 05:14:48 - INFO - __main__ - Step 760 Global step 760 Train loss 0.064215 on epoch=94
06/03/2022 05:14:54 - INFO - __main__ - Step 770 Global step 770 Train loss 0.092794 on epoch=96
06/03/2022 05:14:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.075081 on epoch=97
06/03/2022 05:15:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.040310 on epoch=98
06/03/2022 05:15:09 - INFO - __main__ - Step 800 Global step 800 Train loss 0.060600 on epoch=99
06/03/2022 05:15:10 - INFO - __main__ - Global step 800 Train loss 0.066600 Classification-F1 0.47107438016528924 on epoch=99
06/03/2022 05:15:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.049779 on epoch=101
06/03/2022 05:15:20 - INFO - __main__ - Step 820 Global step 820 Train loss 0.062528 on epoch=102
06/03/2022 05:15:25 - INFO - __main__ - Step 830 Global step 830 Train loss 0.084409 on epoch=103
06/03/2022 05:15:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.033945 on epoch=104
06/03/2022 05:15:35 - INFO - __main__ - Step 850 Global step 850 Train loss 0.033111 on epoch=106
06/03/2022 05:15:36 - INFO - __main__ - Global step 850 Train loss 0.052754 Classification-F1 0.4796747967479675 on epoch=106
06/03/2022 05:15:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.020734 on epoch=107
06/03/2022 05:15:46 - INFO - __main__ - Step 870 Global step 870 Train loss 0.028531 on epoch=108
06/03/2022 05:15:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.022617 on epoch=109
06/03/2022 05:15:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.050080 on epoch=111
06/03/2022 05:16:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.023527 on epoch=112
06/03/2022 05:16:03 - INFO - __main__ - Global step 900 Train loss 0.029098 Classification-F1 0.47107438016528924 on epoch=112
06/03/2022 05:16:08 - INFO - __main__ - Step 910 Global step 910 Train loss 0.010006 on epoch=113
06/03/2022 05:16:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.017883 on epoch=114
06/03/2022 05:16:18 - INFO - __main__ - Step 930 Global step 930 Train loss 0.015810 on epoch=116
06/03/2022 05:16:24 - INFO - __main__ - Step 940 Global step 940 Train loss 0.123649 on epoch=117
06/03/2022 05:16:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.034344 on epoch=118
06/03/2022 05:16:30 - INFO - __main__ - Global step 950 Train loss 0.040338 Classification-F1 0.4796747967479675 on epoch=118
06/03/2022 05:16:35 - INFO - __main__ - Step 960 Global step 960 Train loss 0.041323 on epoch=119
06/03/2022 05:16:40 - INFO - __main__ - Step 970 Global step 970 Train loss 0.076602 on epoch=121
06/03/2022 05:16:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.016345 on epoch=122
06/03/2022 05:16:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.016081 on epoch=123
06/03/2022 05:16:56 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.033861 on epoch=124
06/03/2022 05:16:57 - INFO - __main__ - Global step 1000 Train loss 0.036842 Classification-F1 0.4074074074074074 on epoch=124
06/03/2022 05:16:57 - INFO - __main__ - save last model!
06/03/2022 05:16:57 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 05:16:57 - INFO - __main__ - Printing 3 examples
06/03/2022 05:16:57 - INFO - __main__ -  [ethos-race] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
06/03/2022 05:16:57 - INFO - __main__ - ['false']
06/03/2022 05:16:57 - INFO - __main__ -  [ethos-race] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
06/03/2022 05:16:57 - INFO - __main__ - ['false']
06/03/2022 05:16:57 - INFO - __main__ -  [ethos-race] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
06/03/2022 05:16:57 - INFO - __main__ - ['false']
06/03/2022 05:16:57 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:16:57 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:16:57 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 05:16:57 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 05:16:57 - INFO - __main__ - Printing 3 examples
06/03/2022 05:16:57 - INFO - __main__ -  [ethos-race] WOW THIS GUY TALKS LIKE A RETARD HAHAHAHAHAH
06/03/2022 05:16:57 - INFO - __main__ - ['false']
06/03/2022 05:16:57 - INFO - __main__ -  [ethos-race] Hindus take my ass please
06/03/2022 05:16:57 - INFO - __main__ - ['false']
06/03/2022 05:16:57 - INFO - __main__ -  [ethos-race] Incest baby that got double-down syndrome
06/03/2022 05:16:57 - INFO - __main__ - ['false']
06/03/2022 05:16:57 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:16:57 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:16:57 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 05:17:04 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 05:17:04 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 05:17:04 - INFO - __main__ - Printing 3 examples
06/03/2022 05:17:04 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 05:17:04 - INFO - __main__ - ['true']
06/03/2022 05:17:04 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 05:17:04 - INFO - __main__ - ['false']
06/03/2022 05:17:04 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 05:17:04 - INFO - __main__ - ['false']
06/03/2022 05:17:04 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:17:04 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:17:05 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 05:17:06 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_21_0.0003_8_predictions.txt
06/03/2022 05:17:06 - INFO - __main__ - Classification-F1 on test data: 0.5111
06/03/2022 05:17:06 - INFO - __main__ - prefix=ethos-race_64_21, lr=0.0003, bsz=8, dev_performance=1.0, test_performance=0.5110528287748219
06/03/2022 05:17:07 - INFO - __main__ - Running ... prefix=ethos-race_64_21, lr=0.0002, bsz=8 ...
06/03/2022 05:17:07 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 05:17:07 - INFO - __main__ - Printing 3 examples
06/03/2022 05:17:07 - INFO - __main__ -  [ethos-race] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
06/03/2022 05:17:07 - INFO - __main__ - ['false']
06/03/2022 05:17:07 - INFO - __main__ -  [ethos-race] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
06/03/2022 05:17:07 - INFO - __main__ - ['false']
06/03/2022 05:17:07 - INFO - __main__ -  [ethos-race] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
06/03/2022 05:17:07 - INFO - __main__ - ['false']
06/03/2022 05:17:07 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:17:07 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:17:08 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 05:17:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 05:17:08 - INFO - __main__ - Printing 3 examples
06/03/2022 05:17:08 - INFO - __main__ -  [ethos-race] WOW THIS GUY TALKS LIKE A RETARD HAHAHAHAHAH
06/03/2022 05:17:08 - INFO - __main__ - ['false']
06/03/2022 05:17:08 - INFO - __main__ -  [ethos-race] Hindus take my ass please
06/03/2022 05:17:08 - INFO - __main__ - ['false']
06/03/2022 05:17:08 - INFO - __main__ -  [ethos-race] Incest baby that got double-down syndrome
06/03/2022 05:17:08 - INFO - __main__ - ['false']
06/03/2022 05:17:08 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:17:08 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:17:08 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 05:17:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 05:17:08 - INFO - __main__ - Starting training!
06/03/2022 05:17:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 05:17:19 - INFO - __main__ - Starting training!
06/03/2022 05:17:23 - INFO - __main__ - Step 10 Global step 10 Train loss 24.388918 on epoch=1
06/03/2022 05:17:28 - INFO - __main__ - Step 20 Global step 20 Train loss 20.648975 on epoch=2
06/03/2022 05:17:33 - INFO - __main__ - Step 30 Global step 30 Train loss 18.120163 on epoch=3
06/03/2022 05:17:39 - INFO - __main__ - Step 40 Global step 40 Train loss 16.448696 on epoch=4
06/03/2022 05:17:44 - INFO - __main__ - Step 50 Global step 50 Train loss 16.330263 on epoch=6
06/03/2022 05:18:03 - INFO - __main__ - Global step 50 Train loss 19.187403 Classification-F1 0.0 on epoch=6
06/03/2022 05:18:09 - INFO - __main__ - Step 60 Global step 60 Train loss 15.090317 on epoch=7
06/03/2022 05:18:14 - INFO - __main__ - Step 70 Global step 70 Train loss 14.549914 on epoch=8
06/03/2022 05:18:19 - INFO - __main__ - Step 80 Global step 80 Train loss 13.881157 on epoch=9
06/03/2022 05:18:24 - INFO - __main__ - Step 90 Global step 90 Train loss 13.212305 on epoch=11
06/03/2022 05:18:30 - INFO - __main__ - Step 100 Global step 100 Train loss 12.559461 on epoch=12
06/03/2022 05:18:30 - INFO - __main__ - Global step 100 Train loss 13.858630 Classification-F1 0.0 on epoch=12
06/03/2022 05:18:36 - INFO - __main__ - Step 110 Global step 110 Train loss 11.020750 on epoch=13
06/03/2022 05:18:41 - INFO - __main__ - Step 120 Global step 120 Train loss 10.540718 on epoch=14
06/03/2022 05:18:46 - INFO - __main__ - Step 130 Global step 130 Train loss 6.794724 on epoch=16
06/03/2022 05:18:51 - INFO - __main__ - Step 140 Global step 140 Train loss 3.939536 on epoch=17
06/03/2022 05:18:56 - INFO - __main__ - Step 150 Global step 150 Train loss 2.434315 on epoch=18
06/03/2022 05:18:57 - INFO - __main__ - Global step 150 Train loss 6.946009 Classification-F1 0.49206349206349204 on epoch=18
06/03/2022 05:19:03 - INFO - __main__ - Step 160 Global step 160 Train loss 3.006923 on epoch=19
06/03/2022 05:19:08 - INFO - __main__ - Step 170 Global step 170 Train loss 2.414914 on epoch=21
06/03/2022 05:19:13 - INFO - __main__ - Step 180 Global step 180 Train loss 1.850782 on epoch=22
06/03/2022 05:19:18 - INFO - __main__ - Step 190 Global step 190 Train loss 2.000495 on epoch=23
06/03/2022 05:19:24 - INFO - __main__ - Step 200 Global step 200 Train loss 2.171795 on epoch=24
06/03/2022 05:19:24 - INFO - __main__ - Global step 200 Train loss 2.288982 Classification-F1 0.43859649122807015 on epoch=24
06/03/2022 05:19:29 - INFO - __main__ - Step 210 Global step 210 Train loss 2.457036 on epoch=26
06/03/2022 05:19:35 - INFO - __main__ - Step 220 Global step 220 Train loss 2.075259 on epoch=27
06/03/2022 05:19:40 - INFO - __main__ - Step 230 Global step 230 Train loss 1.613615 on epoch=28
06/03/2022 05:19:45 - INFO - __main__ - Step 240 Global step 240 Train loss 2.268382 on epoch=29
06/03/2022 05:19:50 - INFO - __main__ - Step 250 Global step 250 Train loss 2.116191 on epoch=31
06/03/2022 05:19:51 - INFO - __main__ - Global step 250 Train loss 2.106097 Classification-F1 0.4482758620689655 on epoch=31
06/03/2022 05:19:56 - INFO - __main__ - Step 260 Global step 260 Train loss 2.201235 on epoch=32
06/03/2022 05:20:01 - INFO - __main__ - Step 270 Global step 270 Train loss 1.247856 on epoch=33
06/03/2022 05:20:06 - INFO - __main__ - Step 280 Global step 280 Train loss 1.922349 on epoch=34
06/03/2022 05:20:12 - INFO - __main__ - Step 290 Global step 290 Train loss 1.414244 on epoch=36
06/03/2022 05:20:17 - INFO - __main__ - Step 300 Global step 300 Train loss 1.236759 on epoch=37
06/03/2022 05:20:17 - INFO - __main__ - Global step 300 Train loss 1.604488 Classification-F1 0.16883116883116883 on epoch=37
06/03/2022 05:20:23 - INFO - __main__ - Step 310 Global step 310 Train loss 1.137241 on epoch=38
06/03/2022 05:20:28 - INFO - __main__ - Step 320 Global step 320 Train loss 1.506406 on epoch=39
06/03/2022 05:20:33 - INFO - __main__ - Step 330 Global step 330 Train loss 1.151803 on epoch=41
06/03/2022 05:20:38 - INFO - __main__ - Step 340 Global step 340 Train loss 0.916095 on epoch=42
06/03/2022 05:20:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.685834 on epoch=43
06/03/2022 05:20:44 - INFO - __main__ - Global step 350 Train loss 1.079476 Classification-F1 0.3191489361702128 on epoch=43
06/03/2022 05:20:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.355506 on epoch=44
06/03/2022 05:20:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.320322 on epoch=46
06/03/2022 05:21:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.313209 on epoch=47
06/03/2022 05:21:05 - INFO - __main__ - Step 390 Global step 390 Train loss 0.283228 on epoch=48
06/03/2022 05:21:10 - INFO - __main__ - Step 400 Global step 400 Train loss 0.313537 on epoch=49
06/03/2022 05:21:11 - INFO - __main__ - Global step 400 Train loss 0.317161 Classification-F1 0.49206349206349204 on epoch=49
06/03/2022 05:21:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.227813 on epoch=51
06/03/2022 05:21:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.202241 on epoch=52
06/03/2022 05:21:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.197636 on epoch=53
06/03/2022 05:21:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.168519 on epoch=54
06/03/2022 05:21:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.267532 on epoch=56
06/03/2022 05:21:37 - INFO - __main__ - Global step 450 Train loss 0.212748 Classification-F1 0.4838709677419355 on epoch=56
06/03/2022 05:21:43 - INFO - __main__ - Step 460 Global step 460 Train loss 0.216084 on epoch=57
06/03/2022 05:21:48 - INFO - __main__ - Step 470 Global step 470 Train loss 0.152943 on epoch=58
06/03/2022 05:21:53 - INFO - __main__ - Step 480 Global step 480 Train loss 0.175177 on epoch=59
06/03/2022 05:21:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.150430 on epoch=61
06/03/2022 05:22:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.154403 on epoch=62
06/03/2022 05:22:04 - INFO - __main__ - Global step 500 Train loss 0.169807 Classification-F1 0.47540983606557374 on epoch=62
06/03/2022 05:22:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.228470 on epoch=63
06/03/2022 05:22:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.129768 on epoch=64
06/03/2022 05:22:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.144105 on epoch=66
06/03/2022 05:22:25 - INFO - __main__ - Step 540 Global step 540 Train loss 0.138206 on epoch=67
06/03/2022 05:22:30 - INFO - __main__ - Step 550 Global step 550 Train loss 0.105264 on epoch=68
06/03/2022 05:22:31 - INFO - __main__ - Global step 550 Train loss 0.149162 Classification-F1 0.4336283185840708 on epoch=68
06/03/2022 05:22:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.062286 on epoch=69
06/03/2022 05:22:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.107877 on epoch=71
06/03/2022 05:22:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.063692 on epoch=72
06/03/2022 05:22:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.043889 on epoch=73
06/03/2022 05:22:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.070905 on epoch=74
06/03/2022 05:22:57 - INFO - __main__ - Global step 600 Train loss 0.069730 Classification-F1 0.452991452991453 on epoch=74
06/03/2022 05:23:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.054821 on epoch=76
06/03/2022 05:23:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.060702 on epoch=77
06/03/2022 05:23:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.058763 on epoch=78
06/03/2022 05:23:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.094503 on epoch=79
06/03/2022 05:23:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.056062 on epoch=81
06/03/2022 05:23:24 - INFO - __main__ - Global step 650 Train loss 0.064970 Classification-F1 0.49206349206349204 on epoch=81
06/03/2022 05:23:29 - INFO - __main__ - Step 660 Global step 660 Train loss 0.065900 on epoch=82
06/03/2022 05:23:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.172581 on epoch=83
06/03/2022 05:23:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.126496 on epoch=84
06/03/2022 05:23:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.058721 on epoch=86
06/03/2022 05:23:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.060896 on epoch=87
06/03/2022 05:23:51 - INFO - __main__ - Global step 700 Train loss 0.096919 Classification-F1 0.47540983606557374 on epoch=87
06/03/2022 05:23:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.025583 on epoch=88
06/03/2022 05:24:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.106433 on epoch=89
06/03/2022 05:24:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.033114 on epoch=91
06/03/2022 05:24:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.028318 on epoch=92
06/03/2022 05:24:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.023901 on epoch=93
06/03/2022 05:24:18 - INFO - __main__ - Global step 750 Train loss 0.043470 Classification-F1 0.4482758620689655 on epoch=93
06/03/2022 05:24:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.010204 on epoch=94
06/03/2022 05:24:28 - INFO - __main__ - Step 770 Global step 770 Train loss 0.030425 on epoch=96
06/03/2022 05:24:33 - INFO - __main__ - Step 780 Global step 780 Train loss 0.083401 on epoch=97
06/03/2022 05:24:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.012267 on epoch=98
06/03/2022 05:24:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.014958 on epoch=99
06/03/2022 05:24:44 - INFO - __main__ - Global step 800 Train loss 0.030251 Classification-F1 0.4666666666666667 on epoch=99
06/03/2022 05:24:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.009037 on epoch=101
06/03/2022 05:24:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.018321 on epoch=102
06/03/2022 05:25:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.015145 on epoch=103
06/03/2022 05:25:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.017096 on epoch=104
06/03/2022 05:25:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.029920 on epoch=106
06/03/2022 05:25:11 - INFO - __main__ - Global step 850 Train loss 0.017904 Classification-F1 0.4838709677419355 on epoch=106
06/03/2022 05:25:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.021975 on epoch=107
06/03/2022 05:25:22 - INFO - __main__ - Step 870 Global step 870 Train loss 0.032888 on epoch=108
06/03/2022 05:25:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.004962 on epoch=109
06/03/2022 05:25:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.028897 on epoch=111
06/03/2022 05:25:37 - INFO - __main__ - Step 900 Global step 900 Train loss 0.022768 on epoch=112
06/03/2022 05:25:38 - INFO - __main__ - Global step 900 Train loss 0.022298 Classification-F1 0.4838709677419355 on epoch=112
06/03/2022 05:25:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.004191 on epoch=113
06/03/2022 05:25:49 - INFO - __main__ - Step 920 Global step 920 Train loss 0.013038 on epoch=114
06/03/2022 05:25:54 - INFO - __main__ - Step 930 Global step 930 Train loss 0.013199 on epoch=116
06/03/2022 05:25:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.014519 on epoch=117
06/03/2022 05:26:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.023644 on epoch=118
06/03/2022 05:26:05 - INFO - __main__ - Global step 950 Train loss 0.013718 Classification-F1 0.4796747967479675 on epoch=118
06/03/2022 05:26:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.001758 on epoch=119
06/03/2022 05:26:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.022125 on epoch=121
06/03/2022 05:26:21 - INFO - __main__ - Step 980 Global step 980 Train loss 0.018274 on epoch=122
06/03/2022 05:26:26 - INFO - __main__ - Step 990 Global step 990 Train loss 0.003335 on epoch=123
06/03/2022 05:26:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.021774 on epoch=124
06/03/2022 05:26:32 - INFO - __main__ - Global step 1000 Train loss 0.013453 Classification-F1 0.47540983606557374 on epoch=124
06/03/2022 05:26:32 - INFO - __main__ - save last model!
06/03/2022 05:26:32 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 05:26:32 - INFO - __main__ - Printing 3 examples
06/03/2022 05:26:32 - INFO - __main__ -  [ethos-race] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
06/03/2022 05:26:32 - INFO - __main__ - ['false']
06/03/2022 05:26:32 - INFO - __main__ -  [ethos-race] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
06/03/2022 05:26:32 - INFO - __main__ - ['false']
06/03/2022 05:26:32 - INFO - __main__ -  [ethos-race] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
06/03/2022 05:26:32 - INFO - __main__ - ['false']
06/03/2022 05:26:32 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:26:32 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:26:32 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 05:26:32 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 05:26:32 - INFO - __main__ - Printing 3 examples
06/03/2022 05:26:32 - INFO - __main__ -  [ethos-race] WOW THIS GUY TALKS LIKE A RETARD HAHAHAHAHAH
06/03/2022 05:26:32 - INFO - __main__ - ['false']
06/03/2022 05:26:32 - INFO - __main__ -  [ethos-race] Hindus take my ass please
06/03/2022 05:26:32 - INFO - __main__ - ['false']
06/03/2022 05:26:32 - INFO - __main__ -  [ethos-race] Incest baby that got double-down syndrome
06/03/2022 05:26:32 - INFO - __main__ - ['false']
06/03/2022 05:26:32 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:26:32 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:26:33 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 05:26:38 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 05:26:39 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 05:26:39 - INFO - __main__ - Printing 3 examples
06/03/2022 05:26:39 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 05:26:39 - INFO - __main__ - ['true']
06/03/2022 05:26:39 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 05:26:39 - INFO - __main__ - ['false']
06/03/2022 05:26:39 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 05:26:39 - INFO - __main__ - ['false']
06/03/2022 05:26:39 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:26:39 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:26:39 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 05:26:41 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_21_0.0002_8_predictions.txt
06/03/2022 05:26:41 - INFO - __main__ - Classification-F1 on test data: 0.5043
06/03/2022 05:26:41 - INFO - __main__ - prefix=ethos-race_64_21, lr=0.0002, bsz=8, dev_performance=0.49206349206349204, test_performance=0.5042735042735043
06/03/2022 05:26:41 - INFO - __main__ - Running ... prefix=ethos-race_64_21, lr=0.0001, bsz=8 ...
06/03/2022 05:26:42 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 05:26:42 - INFO - __main__ - Printing 3 examples
06/03/2022 05:26:42 - INFO - __main__ -  [ethos-race] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
06/03/2022 05:26:42 - INFO - __main__ - ['false']
06/03/2022 05:26:42 - INFO - __main__ -  [ethos-race] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
06/03/2022 05:26:42 - INFO - __main__ - ['false']
06/03/2022 05:26:42 - INFO - __main__ -  [ethos-race] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
06/03/2022 05:26:42 - INFO - __main__ - ['false']
06/03/2022 05:26:42 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:26:42 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:26:43 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 05:26:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 05:26:43 - INFO - __main__ - Printing 3 examples
06/03/2022 05:26:43 - INFO - __main__ -  [ethos-race] WOW THIS GUY TALKS LIKE A RETARD HAHAHAHAHAH
06/03/2022 05:26:43 - INFO - __main__ - ['false']
06/03/2022 05:26:43 - INFO - __main__ -  [ethos-race] Hindus take my ass please
06/03/2022 05:26:43 - INFO - __main__ - ['false']
06/03/2022 05:26:43 - INFO - __main__ -  [ethos-race] Incest baby that got double-down syndrome
06/03/2022 05:26:43 - INFO - __main__ - ['false']
06/03/2022 05:26:43 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:26:43 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:26:43 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 05:26:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 05:26:43 - INFO - __main__ - Starting training!
06/03/2022 05:26:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 05:26:53 - INFO - __main__ - Starting training!
06/03/2022 05:26:58 - INFO - __main__ - Step 10 Global step 10 Train loss 24.149574 on epoch=1
06/03/2022 05:27:03 - INFO - __main__ - Step 20 Global step 20 Train loss 22.125715 on epoch=2
06/03/2022 05:27:08 - INFO - __main__ - Step 30 Global step 30 Train loss 18.623911 on epoch=3
06/03/2022 05:27:13 - INFO - __main__ - Step 40 Global step 40 Train loss 17.985905 on epoch=4
06/03/2022 05:27:19 - INFO - __main__ - Step 50 Global step 50 Train loss 16.935793 on epoch=6
06/03/2022 05:27:39 - INFO - __main__ - Global step 50 Train loss 19.964182 Classification-F1 0.0 on epoch=6
06/03/2022 05:27:45 - INFO - __main__ - Step 60 Global step 60 Train loss 17.535841 on epoch=7
06/03/2022 05:27:50 - INFO - __main__ - Step 70 Global step 70 Train loss 16.872412 on epoch=8
06/03/2022 05:27:55 - INFO - __main__ - Step 80 Global step 80 Train loss 16.446466 on epoch=9
06/03/2022 05:28:00 - INFO - __main__ - Step 90 Global step 90 Train loss 15.983240 on epoch=11
06/03/2022 05:28:05 - INFO - __main__ - Step 100 Global step 100 Train loss 15.899508 on epoch=12
06/03/2022 05:28:25 - INFO - __main__ - Global step 100 Train loss 16.547493 Classification-F1 0.0 on epoch=12
06/03/2022 05:28:30 - INFO - __main__ - Step 110 Global step 110 Train loss 15.700348 on epoch=13
06/03/2022 05:28:35 - INFO - __main__ - Step 120 Global step 120 Train loss 14.622803 on epoch=14
06/03/2022 05:28:40 - INFO - __main__ - Step 130 Global step 130 Train loss 14.918048 on epoch=16
06/03/2022 05:28:45 - INFO - __main__ - Step 140 Global step 140 Train loss 14.925215 on epoch=17
06/03/2022 05:28:51 - INFO - __main__ - Step 150 Global step 150 Train loss 13.569738 on epoch=18
06/03/2022 05:29:10 - INFO - __main__ - Global step 150 Train loss 14.747231 Classification-F1 0.0 on epoch=18
06/03/2022 05:29:15 - INFO - __main__ - Step 160 Global step 160 Train loss 12.510935 on epoch=19
06/03/2022 05:29:20 - INFO - __main__ - Step 170 Global step 170 Train loss 12.699331 on epoch=21
06/03/2022 05:29:25 - INFO - __main__ - Step 180 Global step 180 Train loss 13.273043 on epoch=22
06/03/2022 05:29:30 - INFO - __main__ - Step 190 Global step 190 Train loss 11.255429 on epoch=23
06/03/2022 05:29:35 - INFO - __main__ - Step 200 Global step 200 Train loss 10.650883 on epoch=24
06/03/2022 05:29:53 - INFO - __main__ - Global step 200 Train loss 12.077924 Classification-F1 0.0013468013468013469 on epoch=24
06/03/2022 05:29:59 - INFO - __main__ - Step 210 Global step 210 Train loss 9.521338 on epoch=26
06/03/2022 05:30:04 - INFO - __main__ - Step 220 Global step 220 Train loss 6.733055 on epoch=27
06/03/2022 05:30:09 - INFO - __main__ - Step 230 Global step 230 Train loss 1.917702 on epoch=28
06/03/2022 05:30:14 - INFO - __main__ - Step 240 Global step 240 Train loss 0.711722 on epoch=29
06/03/2022 05:30:19 - INFO - __main__ - Step 250 Global step 250 Train loss 0.546070 on epoch=31
06/03/2022 05:30:20 - INFO - __main__ - Global step 250 Train loss 3.885978 Classification-F1 1.0 on epoch=31
06/03/2022 05:30:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.611120 on epoch=32
06/03/2022 05:30:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.473599 on epoch=33
06/03/2022 05:30:36 - INFO - __main__ - Step 280 Global step 280 Train loss 0.556275 on epoch=34
06/03/2022 05:30:41 - INFO - __main__ - Step 290 Global step 290 Train loss 0.511579 on epoch=36
06/03/2022 05:30:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.384278 on epoch=37
06/03/2022 05:30:47 - INFO - __main__ - Global step 300 Train loss 0.507370 Classification-F1 0.40186915887850466 on epoch=37
06/03/2022 05:30:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.325101 on epoch=38
06/03/2022 05:30:57 - INFO - __main__ - Step 320 Global step 320 Train loss 0.354475 on epoch=39
06/03/2022 05:31:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.326342 on epoch=41
06/03/2022 05:31:07 - INFO - __main__ - Step 340 Global step 340 Train loss 0.288186 on epoch=42
06/03/2022 05:31:12 - INFO - __main__ - Step 350 Global step 350 Train loss 0.279033 on epoch=43
06/03/2022 05:31:13 - INFO - __main__ - Global step 350 Train loss 0.314628 Classification-F1 0.38461538461538464 on epoch=43
06/03/2022 05:31:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.265657 on epoch=44
06/03/2022 05:31:23 - INFO - __main__ - Step 370 Global step 370 Train loss 0.175241 on epoch=46
06/03/2022 05:31:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.250003 on epoch=47
06/03/2022 05:31:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.255409 on epoch=48
06/03/2022 05:31:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.231429 on epoch=49
06/03/2022 05:31:39 - INFO - __main__ - Global step 400 Train loss 0.235548 Classification-F1 0.42857142857142855 on epoch=49
06/03/2022 05:31:44 - INFO - __main__ - Step 410 Global step 410 Train loss 0.238915 on epoch=51
06/03/2022 05:31:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.269913 on epoch=52
06/03/2022 05:31:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.114343 on epoch=53
06/03/2022 05:31:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.194192 on epoch=54
06/03/2022 05:32:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.137607 on epoch=56
06/03/2022 05:32:05 - INFO - __main__ - Global step 450 Train loss 0.190994 Classification-F1 0.4796747967479675 on epoch=56
06/03/2022 05:32:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.186835 on epoch=57
06/03/2022 05:32:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.158358 on epoch=58
06/03/2022 05:32:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.229620 on epoch=59
06/03/2022 05:32:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.127127 on epoch=61
06/03/2022 05:32:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.127645 on epoch=62
06/03/2022 05:32:31 - INFO - __main__ - Global step 500 Train loss 0.165917 Classification-F1 0.47107438016528924 on epoch=62
06/03/2022 05:32:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.140529 on epoch=63
06/03/2022 05:32:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.090010 on epoch=64
06/03/2022 05:32:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.113037 on epoch=66
06/03/2022 05:32:52 - INFO - __main__ - Step 540 Global step 540 Train loss 0.136563 on epoch=67
06/03/2022 05:32:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.123654 on epoch=68
06/03/2022 05:32:57 - INFO - __main__ - Global step 550 Train loss 0.120759 Classification-F1 0.36633663366336633 on epoch=68
06/03/2022 05:33:02 - INFO - __main__ - Step 560 Global step 560 Train loss 0.086762 on epoch=69
06/03/2022 05:33:07 - INFO - __main__ - Step 570 Global step 570 Train loss 0.127675 on epoch=71
06/03/2022 05:33:13 - INFO - __main__ - Step 580 Global step 580 Train loss 0.133100 on epoch=72
06/03/2022 05:33:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.112790 on epoch=73
06/03/2022 05:33:23 - INFO - __main__ - Step 600 Global step 600 Train loss 0.088492 on epoch=74
06/03/2022 05:33:23 - INFO - __main__ - Global step 600 Train loss 0.109764 Classification-F1 0.39622641509433965 on epoch=74
06/03/2022 05:33:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.057010 on epoch=76
06/03/2022 05:33:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.054693 on epoch=77
06/03/2022 05:33:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.097605 on epoch=78
06/03/2022 05:33:44 - INFO - __main__ - Step 640 Global step 640 Train loss 0.071431 on epoch=79
06/03/2022 05:33:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.051070 on epoch=81
06/03/2022 05:33:49 - INFO - __main__ - Global step 650 Train loss 0.066362 Classification-F1 0.47107438016528924 on epoch=81
06/03/2022 05:33:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.039424 on epoch=82
06/03/2022 05:33:59 - INFO - __main__ - Step 670 Global step 670 Train loss 0.034626 on epoch=83
06/03/2022 05:34:04 - INFO - __main__ - Step 680 Global step 680 Train loss 0.071826 on epoch=84
06/03/2022 05:34:10 - INFO - __main__ - Step 690 Global step 690 Train loss 0.024904 on epoch=86
06/03/2022 05:34:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.032382 on epoch=87
06/03/2022 05:34:15 - INFO - __main__ - Global step 700 Train loss 0.040633 Classification-F1 0.47107438016528924 on epoch=87
06/03/2022 05:34:20 - INFO - __main__ - Step 710 Global step 710 Train loss 0.056994 on epoch=88
06/03/2022 05:34:25 - INFO - __main__ - Step 720 Global step 720 Train loss 0.035492 on epoch=89
06/03/2022 05:34:31 - INFO - __main__ - Step 730 Global step 730 Train loss 0.039362 on epoch=91
06/03/2022 05:34:36 - INFO - __main__ - Step 740 Global step 740 Train loss 0.023571 on epoch=92
06/03/2022 05:34:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.048930 on epoch=93
06/03/2022 05:34:41 - INFO - __main__ - Global step 750 Train loss 0.040870 Classification-F1 0.4666666666666667 on epoch=93
06/03/2022 05:34:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.019198 on epoch=94
06/03/2022 05:34:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.053284 on epoch=96
06/03/2022 05:34:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.029253 on epoch=97
06/03/2022 05:35:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.011647 on epoch=98
06/03/2022 05:35:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.022254 on epoch=99
06/03/2022 05:35:08 - INFO - __main__ - Global step 800 Train loss 0.027127 Classification-F1 0.4074074074074074 on epoch=99
06/03/2022 05:35:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.024456 on epoch=101
06/03/2022 05:35:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.022596 on epoch=102
06/03/2022 05:35:23 - INFO - __main__ - Step 830 Global step 830 Train loss 0.020132 on epoch=103
06/03/2022 05:35:28 - INFO - __main__ - Step 840 Global step 840 Train loss 0.009282 on epoch=104
06/03/2022 05:35:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.010926 on epoch=106
06/03/2022 05:35:34 - INFO - __main__ - Global step 850 Train loss 0.017479 Classification-F1 0.47107438016528924 on epoch=106
06/03/2022 05:35:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.024873 on epoch=107
06/03/2022 05:35:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.015614 on epoch=108
06/03/2022 05:35:50 - INFO - __main__ - Step 880 Global step 880 Train loss 0.015855 on epoch=109
06/03/2022 05:35:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.037960 on epoch=111
06/03/2022 05:36:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.016309 on epoch=112
06/03/2022 05:36:01 - INFO - __main__ - Global step 900 Train loss 0.022122 Classification-F1 0.47540983606557374 on epoch=112
06/03/2022 05:36:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.004849 on epoch=113
06/03/2022 05:36:11 - INFO - __main__ - Step 920 Global step 920 Train loss 0.022175 on epoch=114
06/03/2022 05:36:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.023993 on epoch=116
06/03/2022 05:36:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.016330 on epoch=117
06/03/2022 05:36:27 - INFO - __main__ - Step 950 Global step 950 Train loss 0.006626 on epoch=118
06/03/2022 05:36:28 - INFO - __main__ - Global step 950 Train loss 0.014795 Classification-F1 0.42342342342342343 on epoch=118
06/03/2022 05:36:33 - INFO - __main__ - Step 960 Global step 960 Train loss 0.011662 on epoch=119
06/03/2022 05:36:38 - INFO - __main__ - Step 970 Global step 970 Train loss 0.013071 on epoch=121
06/03/2022 05:36:43 - INFO - __main__ - Step 980 Global step 980 Train loss 0.003247 on epoch=122
06/03/2022 05:36:49 - INFO - __main__ - Step 990 Global step 990 Train loss 0.009248 on epoch=123
06/03/2022 05:36:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.002102 on epoch=124
06/03/2022 05:36:54 - INFO - __main__ - Global step 1000 Train loss 0.007866 Classification-F1 0.4336283185840708 on epoch=124
06/03/2022 05:36:54 - INFO - __main__ - save last model!
06/03/2022 05:36:55 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 05:36:55 - INFO - __main__ - Printing 3 examples
06/03/2022 05:36:55 - INFO - __main__ -  [ethos-race] Women deserve to be abused, I guess.
06/03/2022 05:36:55 - INFO - __main__ - ['false']
06/03/2022 05:36:55 - INFO - __main__ -  [ethos-race] How can Europe allow millions of rapists animals to go there ?
06/03/2022 05:36:55 - INFO - __main__ - ['false']
06/03/2022 05:36:55 - INFO - __main__ -  [ethos-race] Most Americans are nazis or kkk members so they elected  Trump.
06/03/2022 05:36:55 - INFO - __main__ - ['false']
06/03/2022 05:36:55 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:36:55 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:36:55 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 05:36:55 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 05:36:55 - INFO - __main__ - Printing 3 examples
06/03/2022 05:36:55 - INFO - __main__ -  [ethos-race] Ugly long chin brainless problematic mother fucker he looks retarded
06/03/2022 05:36:55 - INFO - __main__ - ['false']
06/03/2022 05:36:55 - INFO - __main__ -  [ethos-race] You look like Russian and speak like Indian. Both are disgusting go kill yourself
06/03/2022 05:36:55 - INFO - __main__ - ['false']
06/03/2022 05:36:55 - INFO - __main__ -  [ethos-race] Why researchers invest their time on better wheelchairs? Those cunts did not deserve it!
06/03/2022 05:36:55 - INFO - __main__ - ['false']
06/03/2022 05:36:55 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:36:55 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:36:55 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 05:37:02 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 05:37:02 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 05:37:02 - INFO - __main__ - Printing 3 examples
06/03/2022 05:37:02 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 05:37:02 - INFO - __main__ - ['true']
06/03/2022 05:37:02 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 05:37:02 - INFO - __main__ - ['false']
06/03/2022 05:37:02 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 05:37:02 - INFO - __main__ - ['false']
06/03/2022 05:37:02 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:37:02 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:37:03 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 05:37:04 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_21_0.0001_8_predictions.txt
06/03/2022 05:37:04 - INFO - __main__ - Classification-F1 on test data: 0.4494
06/03/2022 05:37:04 - INFO - __main__ - prefix=ethos-race_64_21, lr=0.0001, bsz=8, dev_performance=1.0, test_performance=0.44936708860759494
06/03/2022 05:37:04 - INFO - __main__ - Running ... prefix=ethos-race_64_42, lr=0.0005, bsz=8 ...
06/03/2022 05:37:05 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 05:37:05 - INFO - __main__ - Printing 3 examples
06/03/2022 05:37:05 - INFO - __main__ -  [ethos-race] Women deserve to be abused, I guess.
06/03/2022 05:37:05 - INFO - __main__ - ['false']
06/03/2022 05:37:05 - INFO - __main__ -  [ethos-race] How can Europe allow millions of rapists animals to go there ?
06/03/2022 05:37:05 - INFO - __main__ - ['false']
06/03/2022 05:37:05 - INFO - __main__ -  [ethos-race] Most Americans are nazis or kkk members so they elected  Trump.
06/03/2022 05:37:05 - INFO - __main__ - ['false']
06/03/2022 05:37:05 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:37:05 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:37:06 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 05:37:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 05:37:06 - INFO - __main__ - Printing 3 examples
06/03/2022 05:37:06 - INFO - __main__ -  [ethos-race] Ugly long chin brainless problematic mother fucker he looks retarded
06/03/2022 05:37:06 - INFO - __main__ - ['false']
06/03/2022 05:37:06 - INFO - __main__ -  [ethos-race] You look like Russian and speak like Indian. Both are disgusting go kill yourself
06/03/2022 05:37:06 - INFO - __main__ - ['false']
06/03/2022 05:37:06 - INFO - __main__ -  [ethos-race] Why researchers invest their time on better wheelchairs? Those cunts did not deserve it!
06/03/2022 05:37:06 - INFO - __main__ - ['false']
06/03/2022 05:37:06 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:37:06 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:37:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 05:37:06 - INFO - __main__ - Starting training!
06/03/2022 05:37:06 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 05:37:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 05:37:17 - INFO - __main__ - Starting training!
06/03/2022 05:37:21 - INFO - __main__ - Step 10 Global step 10 Train loss 24.313375 on epoch=1
06/03/2022 05:37:26 - INFO - __main__ - Step 20 Global step 20 Train loss 18.347597 on epoch=2
06/03/2022 05:37:31 - INFO - __main__ - Step 30 Global step 30 Train loss 16.768679 on epoch=3
06/03/2022 05:37:37 - INFO - __main__ - Step 40 Global step 40 Train loss 14.539980 on epoch=4
06/03/2022 05:37:42 - INFO - __main__ - Step 50 Global step 50 Train loss 12.401377 on epoch=6
06/03/2022 05:37:43 - INFO - __main__ - Global step 50 Train loss 17.274200 Classification-F1 0.0 on epoch=6
06/03/2022 05:37:49 - INFO - __main__ - Step 60 Global step 60 Train loss 10.269243 on epoch=7
06/03/2022 05:37:54 - INFO - __main__ - Step 70 Global step 70 Train loss 3.812893 on epoch=8
06/03/2022 05:37:59 - INFO - __main__ - Step 80 Global step 80 Train loss 0.471001 on epoch=9
06/03/2022 05:38:04 - INFO - __main__ - Step 90 Global step 90 Train loss 0.473249 on epoch=11
06/03/2022 05:38:09 - INFO - __main__ - Step 100 Global step 100 Train loss 0.490819 on epoch=12
06/03/2022 05:38:10 - INFO - __main__ - Global step 100 Train loss 3.103441 Classification-F1 0.08571428571428572 on epoch=12
06/03/2022 05:38:16 - INFO - __main__ - Step 110 Global step 110 Train loss 0.414543 on epoch=13
06/03/2022 05:38:21 - INFO - __main__ - Step 120 Global step 120 Train loss 0.458128 on epoch=14
06/03/2022 05:38:26 - INFO - __main__ - Step 130 Global step 130 Train loss 0.408362 on epoch=16
06/03/2022 05:38:32 - INFO - __main__ - Step 140 Global step 140 Train loss 0.296186 on epoch=17
06/03/2022 05:38:37 - INFO - __main__ - Step 150 Global step 150 Train loss 0.419417 on epoch=18
06/03/2022 05:38:37 - INFO - __main__ - Global step 150 Train loss 0.399327 Classification-F1 0.488 on epoch=18
06/03/2022 05:38:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.327760 on epoch=19
06/03/2022 05:38:49 - INFO - __main__ - Step 170 Global step 170 Train loss 0.298874 on epoch=21
06/03/2022 05:38:54 - INFO - __main__ - Step 180 Global step 180 Train loss 0.300523 on epoch=22
06/03/2022 05:38:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.176271 on epoch=23
06/03/2022 05:39:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.213585 on epoch=24
06/03/2022 05:39:05 - INFO - __main__ - Global step 200 Train loss 0.263403 Classification-F1 0.49206349206349204 on epoch=24
06/03/2022 05:39:11 - INFO - __main__ - Step 210 Global step 210 Train loss 0.314316 on epoch=26
06/03/2022 05:39:16 - INFO - __main__ - Step 220 Global step 220 Train loss 0.138299 on epoch=27
06/03/2022 05:39:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.110789 on epoch=28
06/03/2022 05:39:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.180218 on epoch=29
06/03/2022 05:39:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.188425 on epoch=31
06/03/2022 05:39:33 - INFO - __main__ - Global step 250 Train loss 0.186409 Classification-F1 0.47107438016528924 on epoch=31
06/03/2022 05:39:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.142194 on epoch=32
06/03/2022 05:39:43 - INFO - __main__ - Step 270 Global step 270 Train loss 0.110165 on epoch=33
06/03/2022 05:39:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.257371 on epoch=34
06/03/2022 05:39:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.554822 on epoch=36
06/03/2022 05:39:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.180367 on epoch=37
06/03/2022 05:39:59 - INFO - __main__ - Global step 300 Train loss 0.248984 Classification-F1 0.4838709677419355 on epoch=37
06/03/2022 05:40:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.216449 on epoch=38
06/03/2022 05:40:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.290805 on epoch=39
06/03/2022 05:40:14 - INFO - __main__ - Step 330 Global step 330 Train loss 0.294769 on epoch=41
06/03/2022 05:40:19 - INFO - __main__ - Step 340 Global step 340 Train loss 0.209369 on epoch=42
06/03/2022 05:40:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.111008 on epoch=43
06/03/2022 05:40:25 - INFO - __main__ - Global step 350 Train loss 0.224480 Classification-F1 0.49206349206349204 on epoch=43
06/03/2022 05:40:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.155355 on epoch=44
06/03/2022 05:40:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.191011 on epoch=46
06/03/2022 05:40:41 - INFO - __main__ - Step 380 Global step 380 Train loss 0.192292 on epoch=47
06/03/2022 05:40:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.191538 on epoch=48
06/03/2022 05:40:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.144326 on epoch=49
06/03/2022 05:40:52 - INFO - __main__ - Global step 400 Train loss 0.174904 Classification-F1 0.4434782608695652 on epoch=49
06/03/2022 05:40:57 - INFO - __main__ - Step 410 Global step 410 Train loss 0.151443 on epoch=51
06/03/2022 05:41:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.165099 on epoch=52
06/03/2022 05:41:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.141257 on epoch=53
06/03/2022 05:41:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.127469 on epoch=54
06/03/2022 05:41:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.108033 on epoch=56
06/03/2022 05:41:18 - INFO - __main__ - Global step 450 Train loss 0.138660 Classification-F1 0.46218487394957986 on epoch=56
06/03/2022 05:41:24 - INFO - __main__ - Step 460 Global step 460 Train loss 0.106821 on epoch=57
06/03/2022 05:41:29 - INFO - __main__ - Step 470 Global step 470 Train loss 0.068615 on epoch=58
06/03/2022 05:41:34 - INFO - __main__ - Step 480 Global step 480 Train loss 0.072105 on epoch=59
06/03/2022 05:41:39 - INFO - __main__ - Step 490 Global step 490 Train loss 0.073665 on epoch=61
06/03/2022 05:41:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.073075 on epoch=62
06/03/2022 05:41:45 - INFO - __main__ - Global step 500 Train loss 0.078856 Classification-F1 0.488 on epoch=62
06/03/2022 05:41:50 - INFO - __main__ - Step 510 Global step 510 Train loss 0.062503 on epoch=63
06/03/2022 05:41:55 - INFO - __main__ - Step 520 Global step 520 Train loss 0.097450 on epoch=64
06/03/2022 05:42:00 - INFO - __main__ - Step 530 Global step 530 Train loss 0.064053 on epoch=66
06/03/2022 05:42:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.015929 on epoch=67
06/03/2022 05:42:11 - INFO - __main__ - Step 550 Global step 550 Train loss 0.024927 on epoch=68
06/03/2022 05:42:11 - INFO - __main__ - Global step 550 Train loss 0.052972 Classification-F1 0.47540983606557374 on epoch=68
06/03/2022 05:42:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.090315 on epoch=69
06/03/2022 05:42:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.032258 on epoch=71
06/03/2022 05:42:27 - INFO - __main__ - Step 580 Global step 580 Train loss 0.044010 on epoch=72
06/03/2022 05:42:32 - INFO - __main__ - Step 590 Global step 590 Train loss 0.035820 on epoch=73
06/03/2022 05:42:37 - INFO - __main__ - Step 600 Global step 600 Train loss 0.021346 on epoch=74
06/03/2022 05:42:38 - INFO - __main__ - Global step 600 Train loss 0.044750 Classification-F1 0.4796747967479675 on epoch=74
06/03/2022 05:42:43 - INFO - __main__ - Step 610 Global step 610 Train loss 0.126919 on epoch=76
06/03/2022 05:42:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.047456 on epoch=77
06/03/2022 05:42:53 - INFO - __main__ - Step 630 Global step 630 Train loss 0.054162 on epoch=78
06/03/2022 05:42:58 - INFO - __main__ - Step 640 Global step 640 Train loss 0.049969 on epoch=79
06/03/2022 05:43:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.060897 on epoch=81
06/03/2022 05:43:04 - INFO - __main__ - Global step 650 Train loss 0.067880 Classification-F1 0.4838709677419355 on epoch=81
06/03/2022 05:43:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.013935 on epoch=82
06/03/2022 05:43:15 - INFO - __main__ - Step 670 Global step 670 Train loss 0.008125 on epoch=83
06/03/2022 05:43:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.040851 on epoch=84
06/03/2022 05:43:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.039898 on epoch=86
06/03/2022 05:43:30 - INFO - __main__ - Step 700 Global step 700 Train loss 0.023943 on epoch=87
06/03/2022 05:43:31 - INFO - __main__ - Global step 700 Train loss 0.025350 Classification-F1 0.47540983606557374 on epoch=87
06/03/2022 05:43:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.009563 on epoch=88
06/03/2022 05:43:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.004986 on epoch=89
06/03/2022 05:43:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.009764 on epoch=91
06/03/2022 05:43:51 - INFO - __main__ - Step 740 Global step 740 Train loss 0.001403 on epoch=92
06/03/2022 05:43:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.007893 on epoch=93
06/03/2022 05:43:57 - INFO - __main__ - Global step 750 Train loss 0.006722 Classification-F1 0.47540983606557374 on epoch=93
06/03/2022 05:44:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.026661 on epoch=94
06/03/2022 05:44:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.012805 on epoch=96
06/03/2022 05:44:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.006142 on epoch=97
06/03/2022 05:44:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.008335 on epoch=98
06/03/2022 05:44:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.033516 on epoch=99
06/03/2022 05:44:24 - INFO - __main__ - Global step 800 Train loss 0.017492 Classification-F1 0.4666666666666667 on epoch=99
06/03/2022 05:44:29 - INFO - __main__ - Step 810 Global step 810 Train loss 0.008812 on epoch=101
06/03/2022 05:44:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.017347 on epoch=102
06/03/2022 05:44:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.006343 on epoch=103
06/03/2022 05:44:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.001787 on epoch=104
06/03/2022 05:44:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.010872 on epoch=106
06/03/2022 05:44:50 - INFO - __main__ - Global step 850 Train loss 0.009032 Classification-F1 0.47540983606557374 on epoch=106
06/03/2022 05:44:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.002952 on epoch=107
06/03/2022 05:45:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.001680 on epoch=108
06/03/2022 05:45:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000151 on epoch=109
06/03/2022 05:45:11 - INFO - __main__ - Step 890 Global step 890 Train loss 0.005729 on epoch=111
06/03/2022 05:45:16 - INFO - __main__ - Step 900 Global step 900 Train loss 0.005967 on epoch=112
06/03/2022 05:45:17 - INFO - __main__ - Global step 900 Train loss 0.003296 Classification-F1 0.47107438016528924 on epoch=112
06/03/2022 05:45:22 - INFO - __main__ - Step 910 Global step 910 Train loss 0.002068 on epoch=113
06/03/2022 05:45:27 - INFO - __main__ - Step 920 Global step 920 Train loss 0.007077 on epoch=114
06/03/2022 05:45:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.002476 on epoch=116
06/03/2022 05:45:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.002678 on epoch=117
06/03/2022 05:45:43 - INFO - __main__ - Step 950 Global step 950 Train loss 0.029330 on epoch=118
06/03/2022 05:45:43 - INFO - __main__ - Global step 950 Train loss 0.008726 Classification-F1 0.4838709677419355 on epoch=118
06/03/2022 05:45:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.001162 on epoch=119
06/03/2022 05:45:54 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000101 on epoch=121
06/03/2022 05:45:59 - INFO - __main__ - Step 980 Global step 980 Train loss 0.001144 on epoch=122
06/03/2022 05:46:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.041819 on epoch=123
06/03/2022 05:46:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.002253 on epoch=124
06/03/2022 05:46:10 - INFO - __main__ - Global step 1000 Train loss 0.009296 Classification-F1 0.47540983606557374 on epoch=124
06/03/2022 05:46:10 - INFO - __main__ - save last model!
06/03/2022 05:46:11 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 05:46:11 - INFO - __main__ - Printing 3 examples
06/03/2022 05:46:11 - INFO - __main__ -  [ethos-race] Women deserve to be abused, I guess.
06/03/2022 05:46:11 - INFO - __main__ - ['false']
06/03/2022 05:46:11 - INFO - __main__ -  [ethos-race] How can Europe allow millions of rapists animals to go there ?
06/03/2022 05:46:11 - INFO - __main__ - ['false']
06/03/2022 05:46:11 - INFO - __main__ -  [ethos-race] Most Americans are nazis or kkk members so they elected  Trump.
06/03/2022 05:46:11 - INFO - __main__ - ['false']
06/03/2022 05:46:11 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:46:11 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:46:11 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 05:46:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 05:46:11 - INFO - __main__ - Printing 3 examples
06/03/2022 05:46:11 - INFO - __main__ -  [ethos-race] Ugly long chin brainless problematic mother fucker he looks retarded
06/03/2022 05:46:11 - INFO - __main__ - ['false']
06/03/2022 05:46:11 - INFO - __main__ -  [ethos-race] You look like Russian and speak like Indian. Both are disgusting go kill yourself
06/03/2022 05:46:11 - INFO - __main__ - ['false']
06/03/2022 05:46:11 - INFO - __main__ -  [ethos-race] Why researchers invest their time on better wheelchairs? Those cunts did not deserve it!
06/03/2022 05:46:11 - INFO - __main__ - ['false']
06/03/2022 05:46:11 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:46:11 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:46:11 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 05:46:17 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 05:46:18 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 05:46:18 - INFO - __main__ - Printing 3 examples
06/03/2022 05:46:18 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 05:46:18 - INFO - __main__ - ['true']
06/03/2022 05:46:18 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 05:46:18 - INFO - __main__ - ['false']
06/03/2022 05:46:18 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 05:46:18 - INFO - __main__ - ['false']
06/03/2022 05:46:18 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:46:18 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:46:18 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 05:46:20 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_42_0.0005_8_predictions.txt
06/03/2022 05:46:20 - INFO - __main__ - Classification-F1 on test data: 0.7898
06/03/2022 05:46:20 - INFO - __main__ - prefix=ethos-race_64_42, lr=0.0005, bsz=8, dev_performance=0.49206349206349204, test_performance=0.7897986577181209
06/03/2022 05:46:20 - INFO - __main__ - Running ... prefix=ethos-race_64_42, lr=0.0003, bsz=8 ...
06/03/2022 05:46:21 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 05:46:21 - INFO - __main__ - Printing 3 examples
06/03/2022 05:46:21 - INFO - __main__ -  [ethos-race] Women deserve to be abused, I guess.
06/03/2022 05:46:21 - INFO - __main__ - ['false']
06/03/2022 05:46:21 - INFO - __main__ -  [ethos-race] How can Europe allow millions of rapists animals to go there ?
06/03/2022 05:46:21 - INFO - __main__ - ['false']
06/03/2022 05:46:21 - INFO - __main__ -  [ethos-race] Most Americans are nazis or kkk members so they elected  Trump.
06/03/2022 05:46:21 - INFO - __main__ - ['false']
06/03/2022 05:46:21 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:46:21 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:46:21 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 05:46:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 05:46:21 - INFO - __main__ - Printing 3 examples
06/03/2022 05:46:21 - INFO - __main__ -  [ethos-race] Ugly long chin brainless problematic mother fucker he looks retarded
06/03/2022 05:46:21 - INFO - __main__ - ['false']
06/03/2022 05:46:21 - INFO - __main__ -  [ethos-race] You look like Russian and speak like Indian. Both are disgusting go kill yourself
06/03/2022 05:46:21 - INFO - __main__ - ['false']
06/03/2022 05:46:21 - INFO - __main__ -  [ethos-race] Why researchers invest their time on better wheelchairs? Those cunts did not deserve it!
06/03/2022 05:46:21 - INFO - __main__ - ['false']
06/03/2022 05:46:21 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:46:21 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:46:21 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 05:46:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 05:46:24 - INFO - __main__ - Starting training!
06/03/2022 05:46:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 05:46:34 - INFO - __main__ - Starting training!
06/03/2022 05:46:38 - INFO - __main__ - Step 10 Global step 10 Train loss 23.582294 on epoch=1
06/03/2022 05:46:44 - INFO - __main__ - Step 20 Global step 20 Train loss 19.938503 on epoch=2
06/03/2022 05:46:49 - INFO - __main__ - Step 30 Global step 30 Train loss 17.529381 on epoch=3
06/03/2022 05:46:54 - INFO - __main__ - Step 40 Global step 40 Train loss 15.782747 on epoch=4
06/03/2022 05:46:59 - INFO - __main__ - Step 50 Global step 50 Train loss 14.947217 on epoch=6
06/03/2022 05:47:17 - INFO - __main__ - Global step 50 Train loss 18.356028 Classification-F1 0.0 on epoch=6
06/03/2022 05:47:22 - INFO - __main__ - Step 60 Global step 60 Train loss 13.884966 on epoch=7
06/03/2022 05:47:28 - INFO - __main__ - Step 70 Global step 70 Train loss 12.413841 on epoch=8
06/03/2022 05:47:33 - INFO - __main__ - Step 80 Global step 80 Train loss 9.406549 on epoch=9
06/03/2022 05:47:38 - INFO - __main__ - Step 90 Global step 90 Train loss 4.879547 on epoch=11
06/03/2022 05:47:43 - INFO - __main__ - Step 100 Global step 100 Train loss 1.673795 on epoch=12
06/03/2022 05:47:44 - INFO - __main__ - Global step 100 Train loss 8.451739 Classification-F1 1.0 on epoch=12
06/03/2022 05:47:50 - INFO - __main__ - Step 110 Global step 110 Train loss 0.505013 on epoch=13
06/03/2022 05:47:55 - INFO - __main__ - Step 120 Global step 120 Train loss 0.375138 on epoch=14
06/03/2022 05:48:00 - INFO - __main__ - Step 130 Global step 130 Train loss 0.331340 on epoch=16
06/03/2022 05:48:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.303334 on epoch=17
06/03/2022 05:48:11 - INFO - __main__ - Step 150 Global step 150 Train loss 0.312523 on epoch=18
06/03/2022 05:48:11 - INFO - __main__ - Global step 150 Train loss 0.365470 Classification-F1 0.49206349206349204 on epoch=18
06/03/2022 05:48:16 - INFO - __main__ - Step 160 Global step 160 Train loss 0.242898 on epoch=19
06/03/2022 05:48:22 - INFO - __main__ - Step 170 Global step 170 Train loss 0.245509 on epoch=21
06/03/2022 05:48:27 - INFO - __main__ - Step 180 Global step 180 Train loss 0.286288 on epoch=22
06/03/2022 05:48:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.128909 on epoch=23
06/03/2022 05:48:38 - INFO - __main__ - Step 200 Global step 200 Train loss 0.188705 on epoch=24
06/03/2022 05:48:38 - INFO - __main__ - Global step 200 Train loss 0.218462 Classification-F1 0.4336283185840708 on epoch=24
06/03/2022 05:48:43 - INFO - __main__ - Step 210 Global step 210 Train loss 0.145599 on epoch=26
06/03/2022 05:48:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.188095 on epoch=27
06/03/2022 05:48:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.123911 on epoch=28
06/03/2022 05:48:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.130345 on epoch=29
06/03/2022 05:49:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.106994 on epoch=31
06/03/2022 05:49:05 - INFO - __main__ - Global step 250 Train loss 0.138989 Classification-F1 0.42857142857142855 on epoch=31
06/03/2022 05:49:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.134179 on epoch=32
06/03/2022 05:49:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.080795 on epoch=33
06/03/2022 05:49:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.089729 on epoch=34
06/03/2022 05:49:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.040638 on epoch=36
06/03/2022 05:49:31 - INFO - __main__ - Step 300 Global step 300 Train loss 0.050337 on epoch=37
06/03/2022 05:49:31 - INFO - __main__ - Global step 300 Train loss 0.079136 Classification-F1 0.46218487394957986 on epoch=37
06/03/2022 05:49:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.166846 on epoch=38
06/03/2022 05:49:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.134491 on epoch=39
06/03/2022 05:49:47 - INFO - __main__ - Step 330 Global step 330 Train loss 0.246042 on epoch=41
06/03/2022 05:49:52 - INFO - __main__ - Step 340 Global step 340 Train loss 0.180427 on epoch=42
06/03/2022 05:49:57 - INFO - __main__ - Step 350 Global step 350 Train loss 0.230978 on epoch=43
06/03/2022 05:49:58 - INFO - __main__ - Global step 350 Train loss 0.191757 Classification-F1 0.4666666666666667 on epoch=43
06/03/2022 05:50:03 - INFO - __main__ - Step 360 Global step 360 Train loss 0.221090 on epoch=44
06/03/2022 05:50:08 - INFO - __main__ - Step 370 Global step 370 Train loss 0.160674 on epoch=46
06/03/2022 05:50:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.197529 on epoch=47
06/03/2022 05:50:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.080472 on epoch=48
06/03/2022 05:50:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.043418 on epoch=49
06/03/2022 05:50:24 - INFO - __main__ - Global step 400 Train loss 0.140636 Classification-F1 0.4666666666666667 on epoch=49
06/03/2022 05:50:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.050619 on epoch=51
06/03/2022 05:50:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.057446 on epoch=52
06/03/2022 05:50:40 - INFO - __main__ - Step 430 Global step 430 Train loss 0.034700 on epoch=53
06/03/2022 05:50:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.024094 on epoch=54
06/03/2022 05:50:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.028617 on epoch=56
06/03/2022 05:50:51 - INFO - __main__ - Global step 450 Train loss 0.039095 Classification-F1 0.4434782608695652 on epoch=56
06/03/2022 05:50:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.020796 on epoch=57
06/03/2022 05:51:01 - INFO - __main__ - Step 470 Global step 470 Train loss 0.050871 on epoch=58
06/03/2022 05:51:06 - INFO - __main__ - Step 480 Global step 480 Train loss 0.021209 on epoch=59
06/03/2022 05:51:11 - INFO - __main__ - Step 490 Global step 490 Train loss 0.024093 on epoch=61
06/03/2022 05:51:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.032571 on epoch=62
06/03/2022 05:51:17 - INFO - __main__ - Global step 500 Train loss 0.029908 Classification-F1 0.47107438016528924 on epoch=62
06/03/2022 05:51:22 - INFO - __main__ - Step 510 Global step 510 Train loss 0.015274 on epoch=63
06/03/2022 05:51:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.018157 on epoch=64
06/03/2022 05:51:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.008483 on epoch=66
06/03/2022 05:51:38 - INFO - __main__ - Step 540 Global step 540 Train loss 0.016538 on epoch=67
06/03/2022 05:51:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.006832 on epoch=68
06/03/2022 05:51:44 - INFO - __main__ - Global step 550 Train loss 0.013057 Classification-F1 0.4666666666666667 on epoch=68
06/03/2022 05:51:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.005690 on epoch=69
06/03/2022 05:51:54 - INFO - __main__ - Step 570 Global step 570 Train loss 0.017871 on epoch=71
06/03/2022 05:51:59 - INFO - __main__ - Step 580 Global step 580 Train loss 0.014406 on epoch=72
06/03/2022 05:52:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.016592 on epoch=73
06/03/2022 05:52:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.013372 on epoch=74
06/03/2022 05:52:11 - INFO - __main__ - Global step 600 Train loss 0.013586 Classification-F1 0.49606299212598426 on epoch=74
06/03/2022 05:52:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.611194 on epoch=76
06/03/2022 05:52:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.225201 on epoch=77
06/03/2022 05:52:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.064597 on epoch=78
06/03/2022 05:52:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.048309 on epoch=79
06/03/2022 05:52:37 - INFO - __main__ - Step 650 Global step 650 Train loss 0.016314 on epoch=81
06/03/2022 05:52:37 - INFO - __main__ - Global step 650 Train loss 0.193123 Classification-F1 0.46218487394957986 on epoch=81
06/03/2022 05:52:42 - INFO - __main__ - Step 660 Global step 660 Train loss 0.008273 on epoch=82
06/03/2022 05:52:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.007340 on epoch=83
06/03/2022 05:52:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.001231 on epoch=84
06/03/2022 05:52:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.002822 on epoch=86
06/03/2022 05:53:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.001251 on epoch=87
06/03/2022 05:53:04 - INFO - __main__ - Global step 700 Train loss 0.004183 Classification-F1 0.47107438016528924 on epoch=87
06/03/2022 05:53:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.006353 on epoch=88
06/03/2022 05:53:14 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000274 on epoch=89
06/03/2022 05:53:19 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000836 on epoch=91
06/03/2022 05:53:24 - INFO - __main__ - Step 740 Global step 740 Train loss 0.009487 on epoch=92
06/03/2022 05:53:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.004557 on epoch=93
06/03/2022 05:53:30 - INFO - __main__ - Global step 750 Train loss 0.004301 Classification-F1 0.46218487394957986 on epoch=93
06/03/2022 05:53:35 - INFO - __main__ - Step 760 Global step 760 Train loss 0.005773 on epoch=94
06/03/2022 05:53:40 - INFO - __main__ - Step 770 Global step 770 Train loss 0.004156 on epoch=96
06/03/2022 05:53:46 - INFO - __main__ - Step 780 Global step 780 Train loss 0.002213 on epoch=97
06/03/2022 05:53:51 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000670 on epoch=98
06/03/2022 05:53:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.002248 on epoch=99
06/03/2022 05:53:57 - INFO - __main__ - Global step 800 Train loss 0.003012 Classification-F1 0.3081232492997199 on epoch=99
06/03/2022 05:54:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000240 on epoch=101
06/03/2022 05:54:07 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000265 on epoch=102
06/03/2022 05:54:12 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000755 on epoch=103
06/03/2022 05:54:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000101 on epoch=104
06/03/2022 05:54:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000248 on epoch=106
06/03/2022 05:54:23 - INFO - __main__ - Global step 850 Train loss 0.000322 Classification-F1 0.3140495867768595 on epoch=106
06/03/2022 05:54:28 - INFO - __main__ - Step 860 Global step 860 Train loss 0.033757 on epoch=107
06/03/2022 05:54:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000315 on epoch=108
06/03/2022 05:54:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000142 on epoch=109
06/03/2022 05:54:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.002365 on epoch=111
06/03/2022 05:54:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000220 on epoch=112
06/03/2022 05:54:50 - INFO - __main__ - Global step 900 Train loss 0.007360 Classification-F1 0.3050847457627119 on epoch=112
06/03/2022 05:54:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.007404 on epoch=113
06/03/2022 05:55:00 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000580 on epoch=114
06/03/2022 05:55:05 - INFO - __main__ - Step 930 Global step 930 Train loss 0.001038 on epoch=116
06/03/2022 05:55:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000087 on epoch=117
06/03/2022 05:55:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000256 on epoch=118
06/03/2022 05:55:16 - INFO - __main__ - Global step 950 Train loss 0.001873 Classification-F1 0.46218487394957986 on epoch=118
06/03/2022 05:55:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000060 on epoch=119
06/03/2022 05:55:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000081 on epoch=121
06/03/2022 05:55:32 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000066 on epoch=122
06/03/2022 05:55:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000095 on epoch=123
06/03/2022 05:55:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000061 on epoch=124
06/03/2022 05:55:43 - INFO - __main__ - Global step 1000 Train loss 0.000073 Classification-F1 0.46218487394957986 on epoch=124
06/03/2022 05:55:43 - INFO - __main__ - save last model!
06/03/2022 05:55:43 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 05:55:43 - INFO - __main__ - Printing 3 examples
06/03/2022 05:55:43 - INFO - __main__ -  [ethos-race] Women deserve to be abused, I guess.
06/03/2022 05:55:43 - INFO - __main__ - ['false']
06/03/2022 05:55:43 - INFO - __main__ -  [ethos-race] How can Europe allow millions of rapists animals to go there ?
06/03/2022 05:55:43 - INFO - __main__ - ['false']
06/03/2022 05:55:43 - INFO - __main__ -  [ethos-race] Most Americans are nazis or kkk members so they elected  Trump.
06/03/2022 05:55:43 - INFO - __main__ - ['false']
06/03/2022 05:55:43 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:55:43 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:55:43 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 05:55:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 05:55:43 - INFO - __main__ - Printing 3 examples
06/03/2022 05:55:43 - INFO - __main__ -  [ethos-race] Ugly long chin brainless problematic mother fucker he looks retarded
06/03/2022 05:55:43 - INFO - __main__ - ['false']
06/03/2022 05:55:43 - INFO - __main__ -  [ethos-race] You look like Russian and speak like Indian. Both are disgusting go kill yourself
06/03/2022 05:55:43 - INFO - __main__ - ['false']
06/03/2022 05:55:43 - INFO - __main__ -  [ethos-race] Why researchers invest their time on better wheelchairs? Those cunts did not deserve it!
06/03/2022 05:55:43 - INFO - __main__ - ['false']
06/03/2022 05:55:43 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:55:43 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:55:44 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 05:55:50 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 05:55:50 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 05:55:50 - INFO - __main__ - Printing 3 examples
06/03/2022 05:55:50 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 05:55:50 - INFO - __main__ - ['true']
06/03/2022 05:55:50 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 05:55:50 - INFO - __main__ - ['false']
06/03/2022 05:55:50 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 05:55:50 - INFO - __main__ - ['false']
06/03/2022 05:55:50 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:55:50 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:55:50 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 05:55:52 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_42_0.0003_8_predictions.txt
06/03/2022 05:55:52 - INFO - __main__ - Classification-F1 on test data: 0.4494
06/03/2022 05:55:52 - INFO - __main__ - prefix=ethos-race_64_42, lr=0.0003, bsz=8, dev_performance=1.0, test_performance=0.44936708860759494
06/03/2022 05:55:52 - INFO - __main__ - Running ... prefix=ethos-race_64_42, lr=0.0002, bsz=8 ...
06/03/2022 05:55:53 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 05:55:53 - INFO - __main__ - Printing 3 examples
06/03/2022 05:55:53 - INFO - __main__ -  [ethos-race] Women deserve to be abused, I guess.
06/03/2022 05:55:53 - INFO - __main__ - ['false']
06/03/2022 05:55:53 - INFO - __main__ -  [ethos-race] How can Europe allow millions of rapists animals to go there ?
06/03/2022 05:55:53 - INFO - __main__ - ['false']
06/03/2022 05:55:53 - INFO - __main__ -  [ethos-race] Most Americans are nazis or kkk members so they elected  Trump.
06/03/2022 05:55:53 - INFO - __main__ - ['false']
06/03/2022 05:55:53 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:55:53 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:55:53 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 05:55:53 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 05:55:53 - INFO - __main__ - Printing 3 examples
06/03/2022 05:55:53 - INFO - __main__ -  [ethos-race] Ugly long chin brainless problematic mother fucker he looks retarded
06/03/2022 05:55:53 - INFO - __main__ - ['false']
06/03/2022 05:55:53 - INFO - __main__ -  [ethos-race] You look like Russian and speak like Indian. Both are disgusting go kill yourself
06/03/2022 05:55:53 - INFO - __main__ - ['false']
06/03/2022 05:55:53 - INFO - __main__ -  [ethos-race] Why researchers invest their time on better wheelchairs? Those cunts did not deserve it!
06/03/2022 05:55:53 - INFO - __main__ - ['false']
06/03/2022 05:55:53 - INFO - __main__ - Tokenizing Input ...
06/03/2022 05:55:53 - INFO - __main__ - Tokenizing Output ...
06/03/2022 05:55:53 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 05:55:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 05:55:56 - INFO - __main__ - Starting training!
06/03/2022 05:56:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 05:56:06 - INFO - __main__ - Starting training!
06/03/2022 05:56:11 - INFO - __main__ - Step 10 Global step 10 Train loss 24.041555 on epoch=1
06/03/2022 05:56:16 - INFO - __main__ - Step 20 Global step 20 Train loss 21.064945 on epoch=2
06/03/2022 05:56:21 - INFO - __main__ - Step 30 Global step 30 Train loss 17.457027 on epoch=3
06/03/2022 05:56:27 - INFO - __main__ - Step 40 Global step 40 Train loss 17.142275 on epoch=4
06/03/2022 05:56:32 - INFO - __main__ - Step 50 Global step 50 Train loss 16.092339 on epoch=6
06/03/2022 05:56:32 - INFO - __main__ - Global step 50 Train loss 19.159628 Classification-F1 0.0 on epoch=6
06/03/2022 05:56:38 - INFO - __main__ - Step 60 Global step 60 Train loss 15.307378 on epoch=7
06/03/2022 05:56:43 - INFO - __main__ - Step 70 Global step 70 Train loss 15.031540 on epoch=8
06/03/2022 05:56:48 - INFO - __main__ - Step 80 Global step 80 Train loss 13.548836 on epoch=9
06/03/2022 05:56:54 - INFO - __main__ - Step 90 Global step 90 Train loss 13.518143 on epoch=11
06/03/2022 05:56:59 - INFO - __main__ - Step 100 Global step 100 Train loss 12.674986 on epoch=12
06/03/2022 05:57:00 - INFO - __main__ - Global step 100 Train loss 14.016177 Classification-F1 0.0 on epoch=12
06/03/2022 05:57:05 - INFO - __main__ - Step 110 Global step 110 Train loss 11.581146 on epoch=13
06/03/2022 05:57:10 - INFO - __main__ - Step 120 Global step 120 Train loss 9.722191 on epoch=14
06/03/2022 05:57:15 - INFO - __main__ - Step 130 Global step 130 Train loss 5.458544 on epoch=16
06/03/2022 05:57:20 - INFO - __main__ - Step 140 Global step 140 Train loss 1.127542 on epoch=17
06/03/2022 05:57:25 - INFO - __main__ - Step 150 Global step 150 Train loss 0.476317 on epoch=18
06/03/2022 05:57:26 - INFO - __main__ - Global step 150 Train loss 5.673148 Classification-F1 0.3402061855670103 on epoch=18
06/03/2022 05:57:32 - INFO - __main__ - Step 160 Global step 160 Train loss 0.376443 on epoch=19
06/03/2022 05:57:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.392484 on epoch=21
06/03/2022 05:57:42 - INFO - __main__ - Step 180 Global step 180 Train loss 0.402825 on epoch=22
06/03/2022 05:57:48 - INFO - __main__ - Step 190 Global step 190 Train loss 0.352079 on epoch=23
06/03/2022 05:57:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.402435 on epoch=24
06/03/2022 05:57:53 - INFO - __main__ - Global step 200 Train loss 0.385253 Classification-F1 0.4666666666666667 on epoch=24
06/03/2022 05:57:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.347899 on epoch=26
06/03/2022 05:58:05 - INFO - __main__ - Step 220 Global step 220 Train loss 0.294289 on epoch=27
06/03/2022 05:58:10 - INFO - __main__ - Step 230 Global step 230 Train loss 0.260708 on epoch=28
06/03/2022 05:58:15 - INFO - __main__ - Step 240 Global step 240 Train loss 0.248608 on epoch=29
06/03/2022 05:58:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.227023 on epoch=31
06/03/2022 05:58:21 - INFO - __main__ - Global step 250 Train loss 0.275705 Classification-F1 0.3786407766990291 on epoch=31
06/03/2022 05:58:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.182745 on epoch=32
06/03/2022 05:58:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.192151 on epoch=33
06/03/2022 05:58:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.208593 on epoch=34
06/03/2022 05:58:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.126647 on epoch=36
06/03/2022 05:58:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.158810 on epoch=37
06/03/2022 05:58:48 - INFO - __main__ - Global step 300 Train loss 0.173789 Classification-F1 0.452991452991453 on epoch=37
06/03/2022 05:58:53 - INFO - __main__ - Step 310 Global step 310 Train loss 0.127917 on epoch=38
06/03/2022 05:58:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.146140 on epoch=39
06/03/2022 05:59:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.173415 on epoch=41
06/03/2022 05:59:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.136944 on epoch=42
06/03/2022 05:59:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.092780 on epoch=43
06/03/2022 05:59:14 - INFO - __main__ - Global step 350 Train loss 0.135439 Classification-F1 0.488 on epoch=43
06/03/2022 05:59:20 - INFO - __main__ - Step 360 Global step 360 Train loss 0.098879 on epoch=44
06/03/2022 05:59:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.091677 on epoch=46
06/03/2022 05:59:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.069400 on epoch=47
06/03/2022 05:59:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.053227 on epoch=48
06/03/2022 05:59:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.044741 on epoch=49
06/03/2022 05:59:41 - INFO - __main__ - Global step 400 Train loss 0.071585 Classification-F1 0.36 on epoch=49
06/03/2022 05:59:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.040830 on epoch=51
06/03/2022 05:59:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.048883 on epoch=52
06/03/2022 05:59:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.043886 on epoch=53
06/03/2022 06:00:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.036493 on epoch=54
06/03/2022 06:00:07 - INFO - __main__ - Step 450 Global step 450 Train loss 0.050497 on epoch=56
06/03/2022 06:00:08 - INFO - __main__ - Global step 450 Train loss 0.044118 Classification-F1 0.47107438016528924 on epoch=56
06/03/2022 06:00:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.063796 on epoch=57
06/03/2022 06:00:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.028726 on epoch=58
06/03/2022 06:00:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.023962 on epoch=59
06/03/2022 06:00:29 - INFO - __main__ - Step 490 Global step 490 Train loss 0.032983 on epoch=61
06/03/2022 06:00:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.026981 on epoch=62
06/03/2022 06:00:35 - INFO - __main__ - Global step 500 Train loss 0.035290 Classification-F1 0.4796747967479675 on epoch=62
06/03/2022 06:00:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.037413 on epoch=63
06/03/2022 06:00:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.033966 on epoch=64
06/03/2022 06:00:50 - INFO - __main__ - Step 530 Global step 530 Train loss 0.008667 on epoch=66
06/03/2022 06:00:55 - INFO - __main__ - Step 540 Global step 540 Train loss 0.013377 on epoch=67
06/03/2022 06:01:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.024375 on epoch=68
06/03/2022 06:01:01 - INFO - __main__ - Global step 550 Train loss 0.023560 Classification-F1 0.4838709677419355 on epoch=68
06/03/2022 06:01:06 - INFO - __main__ - Step 560 Global step 560 Train loss 0.027379 on epoch=69
06/03/2022 06:01:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.102986 on epoch=71
06/03/2022 06:01:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.289487 on epoch=72
06/03/2022 06:01:22 - INFO - __main__ - Step 590 Global step 590 Train loss 0.022249 on epoch=73
06/03/2022 06:01:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.024734 on epoch=74
06/03/2022 06:01:28 - INFO - __main__ - Global step 600 Train loss 0.093367 Classification-F1 0.3111111111111111 on epoch=74
06/03/2022 06:01:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.083667 on epoch=76
06/03/2022 06:01:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.005858 on epoch=77
06/03/2022 06:01:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.014149 on epoch=78
06/03/2022 06:01:49 - INFO - __main__ - Step 640 Global step 640 Train loss 0.008870 on epoch=79
06/03/2022 06:01:54 - INFO - __main__ - Step 650 Global step 650 Train loss 0.016351 on epoch=81
06/03/2022 06:01:55 - INFO - __main__ - Global step 650 Train loss 0.025779 Classification-F1 0.4838709677419355 on epoch=81
06/03/2022 06:02:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.011993 on epoch=82
06/03/2022 06:02:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.006026 on epoch=83
06/03/2022 06:02:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.009704 on epoch=84
06/03/2022 06:02:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.005608 on epoch=86
06/03/2022 06:02:21 - INFO - __main__ - Step 700 Global step 700 Train loss 0.003217 on epoch=87
06/03/2022 06:02:21 - INFO - __main__ - Global step 700 Train loss 0.007310 Classification-F1 0.4838709677419355 on epoch=87
06/03/2022 06:02:26 - INFO - __main__ - Step 710 Global step 710 Train loss 0.007054 on epoch=88
06/03/2022 06:02:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.001892 on epoch=89
06/03/2022 06:02:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.002749 on epoch=91
06/03/2022 06:02:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.013499 on epoch=92
06/03/2022 06:02:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.002840 on epoch=93
06/03/2022 06:02:48 - INFO - __main__ - Global step 750 Train loss 0.005607 Classification-F1 0.47540983606557374 on epoch=93
06/03/2022 06:02:53 - INFO - __main__ - Step 760 Global step 760 Train loss 0.013708 on epoch=94
06/03/2022 06:02:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.008859 on epoch=96
06/03/2022 06:03:03 - INFO - __main__ - Step 780 Global step 780 Train loss 0.062270 on epoch=97
06/03/2022 06:03:08 - INFO - __main__ - Step 790 Global step 790 Train loss 0.008223 on epoch=98
06/03/2022 06:03:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.010296 on epoch=99
06/03/2022 06:03:14 - INFO - __main__ - Global step 800 Train loss 0.020671 Classification-F1 0.488 on epoch=99
06/03/2022 06:03:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.011070 on epoch=101
06/03/2022 06:03:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.078039 on epoch=102
06/03/2022 06:03:30 - INFO - __main__ - Step 830 Global step 830 Train loss 0.202836 on epoch=103
06/03/2022 06:03:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.170461 on epoch=104
06/03/2022 06:03:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.161485 on epoch=106
06/03/2022 06:03:41 - INFO - __main__ - Global step 850 Train loss 0.124778 Classification-F1 0.39622641509433965 on epoch=106
06/03/2022 06:03:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.169882 on epoch=107
06/03/2022 06:03:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.071000 on epoch=108
06/03/2022 06:03:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.063170 on epoch=109
06/03/2022 06:04:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.105552 on epoch=111
06/03/2022 06:04:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.103228 on epoch=112
06/03/2022 06:04:07 - INFO - __main__ - Global step 900 Train loss 0.102566 Classification-F1 0.46218487394957986 on epoch=112
06/03/2022 06:04:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.056256 on epoch=113
06/03/2022 06:04:18 - INFO - __main__ - Step 920 Global step 920 Train loss 0.127871 on epoch=114
06/03/2022 06:04:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.119336 on epoch=116
06/03/2022 06:04:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.032327 on epoch=117
06/03/2022 06:04:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.094996 on epoch=118
06/03/2022 06:04:34 - INFO - __main__ - Global step 950 Train loss 0.086157 Classification-F1 0.4482758620689655 on epoch=118
06/03/2022 06:04:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.095856 on epoch=119
06/03/2022 06:04:45 - INFO - __main__ - Step 970 Global step 970 Train loss 0.041624 on epoch=121
06/03/2022 06:04:50 - INFO - __main__ - Step 980 Global step 980 Train loss 0.044566 on epoch=122
06/03/2022 06:04:55 - INFO - __main__ - Step 990 Global step 990 Train loss 0.082883 on epoch=123
06/03/2022 06:05:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.078490 on epoch=124
06/03/2022 06:05:01 - INFO - __main__ - Global step 1000 Train loss 0.068684 Classification-F1 0.488 on epoch=124
06/03/2022 06:05:01 - INFO - __main__ - save last model!
06/03/2022 06:05:01 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 06:05:01 - INFO - __main__ - Printing 3 examples
06/03/2022 06:05:01 - INFO - __main__ -  [ethos-race] Women deserve to be abused, I guess.
06/03/2022 06:05:01 - INFO - __main__ - ['false']
06/03/2022 06:05:01 - INFO - __main__ -  [ethos-race] How can Europe allow millions of rapists animals to go there ?
06/03/2022 06:05:01 - INFO - __main__ - ['false']
06/03/2022 06:05:01 - INFO - __main__ -  [ethos-race] Most Americans are nazis or kkk members so they elected  Trump.
06/03/2022 06:05:01 - INFO - __main__ - ['false']
06/03/2022 06:05:01 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:05:01 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:05:01 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 06:05:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 06:05:01 - INFO - __main__ - Printing 3 examples
06/03/2022 06:05:01 - INFO - __main__ -  [ethos-race] Ugly long chin brainless problematic mother fucker he looks retarded
06/03/2022 06:05:01 - INFO - __main__ - ['false']
06/03/2022 06:05:01 - INFO - __main__ -  [ethos-race] You look like Russian and speak like Indian. Both are disgusting go kill yourself
06/03/2022 06:05:01 - INFO - __main__ - ['false']
06/03/2022 06:05:01 - INFO - __main__ -  [ethos-race] Why researchers invest their time on better wheelchairs? Those cunts did not deserve it!
06/03/2022 06:05:01 - INFO - __main__ - ['false']
06/03/2022 06:05:01 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:05:02 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:05:02 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 06:05:08 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 06:05:08 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 06:05:08 - INFO - __main__ - Printing 3 examples
06/03/2022 06:05:08 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 06:05:08 - INFO - __main__ - ['true']
06/03/2022 06:05:08 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 06:05:08 - INFO - __main__ - ['false']
06/03/2022 06:05:08 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 06:05:08 - INFO - __main__ - ['false']
06/03/2022 06:05:08 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:05:08 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:05:09 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 06:05:10 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_42_0.0002_8_predictions.txt
06/03/2022 06:05:10 - INFO - __main__ - Classification-F1 on test data: 0.9065
06/03/2022 06:05:10 - INFO - __main__ - prefix=ethos-race_64_42, lr=0.0002, bsz=8, dev_performance=0.488, test_performance=0.9065119277885235
06/03/2022 06:05:10 - INFO - __main__ - Running ... prefix=ethos-race_64_42, lr=0.0001, bsz=8 ...
06/03/2022 06:05:11 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 06:05:11 - INFO - __main__ - Printing 3 examples
06/03/2022 06:05:11 - INFO - __main__ -  [ethos-race] Women deserve to be abused, I guess.
06/03/2022 06:05:11 - INFO - __main__ - ['false']
06/03/2022 06:05:11 - INFO - __main__ -  [ethos-race] How can Europe allow millions of rapists animals to go there ?
06/03/2022 06:05:11 - INFO - __main__ - ['false']
06/03/2022 06:05:11 - INFO - __main__ -  [ethos-race] Most Americans are nazis or kkk members so they elected  Trump.
06/03/2022 06:05:11 - INFO - __main__ - ['false']
06/03/2022 06:05:11 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:05:11 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:05:11 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 06:05:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 06:05:11 - INFO - __main__ - Printing 3 examples
06/03/2022 06:05:11 - INFO - __main__ -  [ethos-race] Ugly long chin brainless problematic mother fucker he looks retarded
06/03/2022 06:05:11 - INFO - __main__ - ['false']
06/03/2022 06:05:11 - INFO - __main__ -  [ethos-race] You look like Russian and speak like Indian. Both are disgusting go kill yourself
06/03/2022 06:05:11 - INFO - __main__ - ['false']
06/03/2022 06:05:11 - INFO - __main__ -  [ethos-race] Why researchers invest their time on better wheelchairs? Those cunts did not deserve it!
06/03/2022 06:05:11 - INFO - __main__ - ['false']
06/03/2022 06:05:11 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:05:11 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:05:12 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 06:05:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 06:05:14 - INFO - __main__ - Starting training!
06/03/2022 06:05:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 06:05:24 - INFO - __main__ - Starting training!
06/03/2022 06:05:29 - INFO - __main__ - Step 10 Global step 10 Train loss 24.021151 on epoch=1
06/03/2022 06:05:34 - INFO - __main__ - Step 20 Global step 20 Train loss 23.444906 on epoch=2
06/03/2022 06:05:39 - INFO - __main__ - Step 30 Global step 30 Train loss 19.480190 on epoch=3
06/03/2022 06:05:44 - INFO - __main__ - Step 40 Global step 40 Train loss 17.393126 on epoch=4
06/03/2022 06:05:50 - INFO - __main__ - Step 50 Global step 50 Train loss 17.720459 on epoch=6
06/03/2022 06:06:10 - INFO - __main__ - Global step 50 Train loss 20.411966 Classification-F1 0.0 on epoch=6
06/03/2022 06:06:16 - INFO - __main__ - Step 60 Global step 60 Train loss 16.914122 on epoch=7
06/03/2022 06:06:21 - INFO - __main__ - Step 70 Global step 70 Train loss 16.931635 on epoch=8
06/03/2022 06:06:27 - INFO - __main__ - Step 80 Global step 80 Train loss 17.763355 on epoch=9
06/03/2022 06:06:32 - INFO - __main__ - Step 90 Global step 90 Train loss 16.082211 on epoch=11
06/03/2022 06:06:37 - INFO - __main__ - Step 100 Global step 100 Train loss 15.507762 on epoch=12
06/03/2022 06:06:57 - INFO - __main__ - Global step 100 Train loss 16.639818 Classification-F1 0.0 on epoch=12
06/03/2022 06:07:02 - INFO - __main__ - Step 110 Global step 110 Train loss 15.785074 on epoch=13
06/03/2022 06:07:08 - INFO - __main__ - Step 120 Global step 120 Train loss 14.810379 on epoch=14
06/03/2022 06:07:13 - INFO - __main__ - Step 130 Global step 130 Train loss 15.434410 on epoch=16
06/03/2022 06:07:19 - INFO - __main__ - Step 140 Global step 140 Train loss 14.418300 on epoch=17
06/03/2022 06:07:24 - INFO - __main__ - Step 150 Global step 150 Train loss 13.629677 on epoch=18
06/03/2022 06:07:42 - INFO - __main__ - Global step 150 Train loss 14.815569 Classification-F1 0.0 on epoch=18
06/03/2022 06:07:47 - INFO - __main__ - Step 160 Global step 160 Train loss 13.563039 on epoch=19
06/03/2022 06:07:53 - INFO - __main__ - Step 170 Global step 170 Train loss 12.825925 on epoch=21
06/03/2022 06:07:58 - INFO - __main__ - Step 180 Global step 180 Train loss 12.479081 on epoch=22
06/03/2022 06:08:03 - INFO - __main__ - Step 190 Global step 190 Train loss 11.764996 on epoch=23
06/03/2022 06:08:08 - INFO - __main__ - Step 200 Global step 200 Train loss 11.541718 on epoch=24
06/03/2022 06:08:25 - INFO - __main__ - Global step 200 Train loss 12.434951 Classification-F1 0.0 on epoch=24
06/03/2022 06:08:31 - INFO - __main__ - Step 210 Global step 210 Train loss 10.817784 on epoch=26
06/03/2022 06:08:36 - INFO - __main__ - Step 220 Global step 220 Train loss 9.879938 on epoch=27
06/03/2022 06:08:41 - INFO - __main__ - Step 230 Global step 230 Train loss 8.468621 on epoch=28
06/03/2022 06:08:46 - INFO - __main__ - Step 240 Global step 240 Train loss 6.706149 on epoch=29
06/03/2022 06:08:51 - INFO - __main__ - Step 250 Global step 250 Train loss 3.078280 on epoch=31
06/03/2022 06:08:52 - INFO - __main__ - Global step 250 Train loss 7.790154 Classification-F1 0.49606299212598426 on epoch=31
06/03/2022 06:08:58 - INFO - __main__ - Step 260 Global step 260 Train loss 1.236981 on epoch=32
06/03/2022 06:09:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.794890 on epoch=33
06/03/2022 06:09:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.529397 on epoch=34
06/03/2022 06:09:14 - INFO - __main__ - Step 290 Global step 290 Train loss 0.507217 on epoch=36
06/03/2022 06:09:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.706209 on epoch=37
06/03/2022 06:09:19 - INFO - __main__ - Global step 300 Train loss 0.754939 Classification-F1 0.35353535353535354 on epoch=37
06/03/2022 06:09:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.402062 on epoch=38
06/03/2022 06:09:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.410357 on epoch=39
06/03/2022 06:09:35 - INFO - __main__ - Step 330 Global step 330 Train loss 0.370614 on epoch=41
06/03/2022 06:09:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.340628 on epoch=42
06/03/2022 06:09:45 - INFO - __main__ - Step 350 Global step 350 Train loss 0.365538 on epoch=43
06/03/2022 06:09:46 - INFO - __main__ - Global step 350 Train loss 0.377840 Classification-F1 0.39622641509433965 on epoch=43
06/03/2022 06:09:51 - INFO - __main__ - Step 360 Global step 360 Train loss 0.315397 on epoch=44
06/03/2022 06:09:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.285801 on epoch=46
06/03/2022 06:10:01 - INFO - __main__ - Step 380 Global step 380 Train loss 0.287797 on epoch=47
06/03/2022 06:10:07 - INFO - __main__ - Step 390 Global step 390 Train loss 0.310338 on epoch=48
06/03/2022 06:10:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.270663 on epoch=49
06/03/2022 06:10:12 - INFO - __main__ - Global step 400 Train loss 0.293999 Classification-F1 0.2289156626506024 on epoch=49
06/03/2022 06:10:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.343383 on epoch=51
06/03/2022 06:10:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.241739 on epoch=52
06/03/2022 06:10:28 - INFO - __main__ - Step 430 Global step 430 Train loss 0.211178 on epoch=53
06/03/2022 06:10:33 - INFO - __main__ - Step 440 Global step 440 Train loss 0.215827 on epoch=54
06/03/2022 06:10:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.227447 on epoch=56
06/03/2022 06:10:39 - INFO - __main__ - Global step 450 Train loss 0.247915 Classification-F1 0.43859649122807015 on epoch=56
06/03/2022 06:10:44 - INFO - __main__ - Step 460 Global step 460 Train loss 0.208443 on epoch=57
06/03/2022 06:10:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.177874 on epoch=58
06/03/2022 06:10:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.159985 on epoch=59
06/03/2022 06:11:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.168449 on epoch=61
06/03/2022 06:11:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.173444 on epoch=62
06/03/2022 06:11:06 - INFO - __main__ - Global step 500 Train loss 0.177639 Classification-F1 0.3786407766990291 on epoch=62
06/03/2022 06:11:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.121665 on epoch=63
06/03/2022 06:11:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.147071 on epoch=64
06/03/2022 06:11:21 - INFO - __main__ - Step 530 Global step 530 Train loss 0.109305 on epoch=66
06/03/2022 06:11:26 - INFO - __main__ - Step 540 Global step 540 Train loss 0.102145 on epoch=67
06/03/2022 06:11:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.145923 on epoch=68
06/03/2022 06:11:32 - INFO - __main__ - Global step 550 Train loss 0.125222 Classification-F1 0.47107438016528924 on epoch=68
06/03/2022 06:11:37 - INFO - __main__ - Step 560 Global step 560 Train loss 0.161201 on epoch=69
06/03/2022 06:11:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.097645 on epoch=71
06/03/2022 06:11:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.090973 on epoch=72
06/03/2022 06:11:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.070012 on epoch=73
06/03/2022 06:11:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.114272 on epoch=74
06/03/2022 06:11:58 - INFO - __main__ - Global step 600 Train loss 0.106821 Classification-F1 0.43859649122807015 on epoch=74
06/03/2022 06:12:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.112768 on epoch=76
06/03/2022 06:12:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.079199 on epoch=77
06/03/2022 06:12:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.035664 on epoch=78
06/03/2022 06:12:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.084378 on epoch=79
06/03/2022 06:12:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.115068 on epoch=81
06/03/2022 06:12:25 - INFO - __main__ - Global step 650 Train loss 0.085415 Classification-F1 0.47107438016528924 on epoch=81
06/03/2022 06:12:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.118794 on epoch=82
06/03/2022 06:12:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.029009 on epoch=83
06/03/2022 06:12:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.037411 on epoch=84
06/03/2022 06:12:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.061646 on epoch=86
06/03/2022 06:12:51 - INFO - __main__ - Step 700 Global step 700 Train loss 0.045002 on epoch=87
06/03/2022 06:12:51 - INFO - __main__ - Global step 700 Train loss 0.058372 Classification-F1 0.4576271186440678 on epoch=87
06/03/2022 06:12:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.047294 on epoch=88
06/03/2022 06:13:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.040382 on epoch=89
06/03/2022 06:13:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.033654 on epoch=91
06/03/2022 06:13:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.072595 on epoch=92
06/03/2022 06:13:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.044879 on epoch=93
06/03/2022 06:13:18 - INFO - __main__ - Global step 750 Train loss 0.047761 Classification-F1 0.4796747967479675 on epoch=93
06/03/2022 06:13:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.042469 on epoch=94
06/03/2022 06:13:28 - INFO - __main__ - Step 770 Global step 770 Train loss 0.069677 on epoch=96
06/03/2022 06:13:33 - INFO - __main__ - Step 780 Global step 780 Train loss 0.032145 on epoch=97
06/03/2022 06:13:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.032013 on epoch=98
06/03/2022 06:13:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.025109 on epoch=99
06/03/2022 06:13:44 - INFO - __main__ - Global step 800 Train loss 0.040283 Classification-F1 0.46218487394957986 on epoch=99
06/03/2022 06:13:49 - INFO - __main__ - Step 810 Global step 810 Train loss 0.047671 on epoch=101
06/03/2022 06:13:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.023366 on epoch=102
06/03/2022 06:14:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.054465 on epoch=103
06/03/2022 06:14:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.022253 on epoch=104
06/03/2022 06:14:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.051859 on epoch=106
06/03/2022 06:14:11 - INFO - __main__ - Global step 850 Train loss 0.039923 Classification-F1 0.39622641509433965 on epoch=106
06/03/2022 06:14:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.009422 on epoch=107
06/03/2022 06:14:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.214837 on epoch=108
06/03/2022 06:14:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.033626 on epoch=109
06/03/2022 06:14:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.021853 on epoch=111
06/03/2022 06:14:37 - INFO - __main__ - Step 900 Global step 900 Train loss 0.048666 on epoch=112
06/03/2022 06:14:37 - INFO - __main__ - Global step 900 Train loss 0.065681 Classification-F1 0.43859649122807015 on epoch=112
06/03/2022 06:14:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.051086 on epoch=113
06/03/2022 06:14:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.031288 on epoch=114
06/03/2022 06:14:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.027465 on epoch=116
06/03/2022 06:14:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.013515 on epoch=117
06/03/2022 06:15:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.041683 on epoch=118
06/03/2022 06:15:04 - INFO - __main__ - Global step 950 Train loss 0.033007 Classification-F1 0.4796747967479675 on epoch=118
06/03/2022 06:15:09 - INFO - __main__ - Step 960 Global step 960 Train loss 0.004413 on epoch=119
06/03/2022 06:15:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.004823 on epoch=121
06/03/2022 06:15:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.024803 on epoch=122
06/03/2022 06:15:25 - INFO - __main__ - Step 990 Global step 990 Train loss 0.008728 on epoch=123
06/03/2022 06:15:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.007201 on epoch=124
06/03/2022 06:15:30 - INFO - __main__ - Global step 1000 Train loss 0.009994 Classification-F1 0.452991452991453 on epoch=124
06/03/2022 06:15:30 - INFO - __main__ - save last model!
06/03/2022 06:15:31 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 06:15:31 - INFO - __main__ - Printing 3 examples
06/03/2022 06:15:31 - INFO - __main__ -  [ethos-race] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
06/03/2022 06:15:31 - INFO - __main__ - ['false']
06/03/2022 06:15:31 - INFO - __main__ -  [ethos-race] Honestly, go fuck yourself! bitch!
06/03/2022 06:15:31 - INFO - __main__ - ['false']
06/03/2022 06:15:31 - INFO - __main__ -  [ethos-race] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
06/03/2022 06:15:31 - INFO - __main__ - ['false']
06/03/2022 06:15:31 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:15:31 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:15:31 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 06:15:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 06:15:31 - INFO - __main__ - Printing 3 examples
06/03/2022 06:15:31 - INFO - __main__ -  [ethos-race] Lol, you're not white, you're a Jew. Jews are the worst nation and they must be annihilated, so like you
06/03/2022 06:15:31 - INFO - __main__ - ['false']
06/03/2022 06:15:31 - INFO - __main__ -  [ethos-race] Indian Ned Flanders. You look like you professionally harrass subpar women on Facebook
06/03/2022 06:15:31 - INFO - __main__ - ['false']
06/03/2022 06:15:31 - INFO - __main__ -  [ethos-race] Surprised that the burqa is banned in Belgium, but not in Poland where they are is much more looked-down upon. Kill them
06/03/2022 06:15:31 - INFO - __main__ - ['false']
06/03/2022 06:15:31 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:15:31 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:15:31 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 06:15:37 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 06:15:38 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 06:15:38 - INFO - __main__ - Printing 3 examples
06/03/2022 06:15:38 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 06:15:38 - INFO - __main__ - ['true']
06/03/2022 06:15:38 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 06:15:38 - INFO - __main__ - ['false']
06/03/2022 06:15:38 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 06:15:38 - INFO - __main__ - ['false']
06/03/2022 06:15:38 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:15:38 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:15:38 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 06:15:40 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_42_0.0001_8_predictions.txt
06/03/2022 06:15:40 - INFO - __main__ - Classification-F1 on test data: 0.4314
06/03/2022 06:15:40 - INFO - __main__ - prefix=ethos-race_64_42, lr=0.0001, bsz=8, dev_performance=0.49606299212598426, test_performance=0.43137254901960786
06/03/2022 06:15:40 - INFO - __main__ - Running ... prefix=ethos-race_64_87, lr=0.0005, bsz=8 ...
06/03/2022 06:15:41 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 06:15:41 - INFO - __main__ - Printing 3 examples
06/03/2022 06:15:41 - INFO - __main__ -  [ethos-race] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
06/03/2022 06:15:41 - INFO - __main__ - ['false']
06/03/2022 06:15:41 - INFO - __main__ -  [ethos-race] Honestly, go fuck yourself! bitch!
06/03/2022 06:15:41 - INFO - __main__ - ['false']
06/03/2022 06:15:41 - INFO - __main__ -  [ethos-race] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
06/03/2022 06:15:41 - INFO - __main__ - ['false']
06/03/2022 06:15:41 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:15:41 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:15:42 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 06:15:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 06:15:42 - INFO - __main__ - Printing 3 examples
06/03/2022 06:15:42 - INFO - __main__ -  [ethos-race] Lol, you're not white, you're a Jew. Jews are the worst nation and they must be annihilated, so like you
06/03/2022 06:15:42 - INFO - __main__ - ['false']
06/03/2022 06:15:42 - INFO - __main__ -  [ethos-race] Indian Ned Flanders. You look like you professionally harrass subpar women on Facebook
06/03/2022 06:15:42 - INFO - __main__ - ['false']
06/03/2022 06:15:42 - INFO - __main__ -  [ethos-race] Surprised that the burqa is banned in Belgium, but not in Poland where they are is much more looked-down upon. Kill them
06/03/2022 06:15:42 - INFO - __main__ - ['false']
06/03/2022 06:15:42 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:15:42 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:15:42 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 06:15:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 06:15:44 - INFO - __main__ - Starting training!
06/03/2022 06:15:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 06:15:52 - INFO - __main__ - Starting training!
06/03/2022 06:15:57 - INFO - __main__ - Step 10 Global step 10 Train loss 24.491650 on epoch=1
06/03/2022 06:16:02 - INFO - __main__ - Step 20 Global step 20 Train loss 18.796535 on epoch=2
06/03/2022 06:16:07 - INFO - __main__ - Step 30 Global step 30 Train loss 16.506557 on epoch=3
06/03/2022 06:16:12 - INFO - __main__ - Step 40 Global step 40 Train loss 15.189624 on epoch=4
06/03/2022 06:16:17 - INFO - __main__ - Step 50 Global step 50 Train loss 12.811600 on epoch=6
06/03/2022 06:16:33 - INFO - __main__ - Global step 50 Train loss 17.559195 Classification-F1 0.0 on epoch=6
06/03/2022 06:16:39 - INFO - __main__ - Step 60 Global step 60 Train loss 11.686690 on epoch=7
06/03/2022 06:16:44 - INFO - __main__ - Step 70 Global step 70 Train loss 5.401478 on epoch=8
06/03/2022 06:16:49 - INFO - __main__ - Step 80 Global step 80 Train loss 1.292365 on epoch=9
06/03/2022 06:16:54 - INFO - __main__ - Step 90 Global step 90 Train loss 0.761607 on epoch=11
06/03/2022 06:16:59 - INFO - __main__ - Step 100 Global step 100 Train loss 0.566700 on epoch=12
06/03/2022 06:17:00 - INFO - __main__ - Global step 100 Train loss 3.941768 Classification-F1 0.20987654320987653 on epoch=12
06/03/2022 06:17:06 - INFO - __main__ - Step 110 Global step 110 Train loss 0.359016 on epoch=13
06/03/2022 06:17:12 - INFO - __main__ - Step 120 Global step 120 Train loss 0.544153 on epoch=14
06/03/2022 06:17:17 - INFO - __main__ - Step 130 Global step 130 Train loss 0.375324 on epoch=16
06/03/2022 06:17:22 - INFO - __main__ - Step 140 Global step 140 Train loss 0.407130 on epoch=17
06/03/2022 06:17:27 - INFO - __main__ - Step 150 Global step 150 Train loss 0.342438 on epoch=18
06/03/2022 06:17:28 - INFO - __main__ - Global step 150 Train loss 0.405612 Classification-F1 0.2967032967032967 on epoch=18
06/03/2022 06:17:34 - INFO - __main__ - Step 160 Global step 160 Train loss 0.258712 on epoch=19
06/03/2022 06:17:39 - INFO - __main__ - Step 170 Global step 170 Train loss 0.265629 on epoch=21
06/03/2022 06:17:44 - INFO - __main__ - Step 180 Global step 180 Train loss 0.196912 on epoch=22
06/03/2022 06:17:49 - INFO - __main__ - Step 190 Global step 190 Train loss 0.126866 on epoch=23
06/03/2022 06:17:54 - INFO - __main__ - Step 200 Global step 200 Train loss 0.095911 on epoch=24
06/03/2022 06:17:55 - INFO - __main__ - Global step 200 Train loss 0.188806 Classification-F1 0.488 on epoch=24
06/03/2022 06:18:01 - INFO - __main__ - Step 210 Global step 210 Train loss 0.071718 on epoch=26
06/03/2022 06:18:06 - INFO - __main__ - Step 220 Global step 220 Train loss 0.097532 on epoch=27
06/03/2022 06:18:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.109837 on epoch=28
06/03/2022 06:18:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.195347 on epoch=29
06/03/2022 06:18:22 - INFO - __main__ - Step 250 Global step 250 Train loss 0.101081 on epoch=31
06/03/2022 06:18:23 - INFO - __main__ - Global step 250 Train loss 0.115103 Classification-F1 0.49206349206349204 on epoch=31
06/03/2022 06:18:29 - INFO - __main__ - Step 260 Global step 260 Train loss 0.206650 on epoch=32
06/03/2022 06:18:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.043158 on epoch=33
06/03/2022 06:18:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.059192 on epoch=34
06/03/2022 06:18:44 - INFO - __main__ - Step 290 Global step 290 Train loss 0.083384 on epoch=36
06/03/2022 06:18:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.062908 on epoch=37
06/03/2022 06:18:50 - INFO - __main__ - Global step 300 Train loss 0.091058 Classification-F1 0.42857142857142855 on epoch=37
06/03/2022 06:18:55 - INFO - __main__ - Step 310 Global step 310 Train loss 0.030080 on epoch=38
06/03/2022 06:19:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.130578 on epoch=39
06/03/2022 06:19:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.085767 on epoch=41
06/03/2022 06:19:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.083679 on epoch=42
06/03/2022 06:19:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.109745 on epoch=43
06/03/2022 06:19:16 - INFO - __main__ - Global step 350 Train loss 0.087970 Classification-F1 0.4838709677419355 on epoch=43
06/03/2022 06:19:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.048613 on epoch=44
06/03/2022 06:19:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.025407 on epoch=46
06/03/2022 06:19:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.031614 on epoch=47
06/03/2022 06:19:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.033608 on epoch=48
06/03/2022 06:19:42 - INFO - __main__ - Step 400 Global step 400 Train loss 0.016775 on epoch=49
06/03/2022 06:19:42 - INFO - __main__ - Global step 400 Train loss 0.031203 Classification-F1 0.4576271186440678 on epoch=49
06/03/2022 06:19:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.008814 on epoch=51
06/03/2022 06:19:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.045717 on epoch=52
06/03/2022 06:19:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.001734 on epoch=53
06/03/2022 06:20:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.014515 on epoch=54
06/03/2022 06:20:08 - INFO - __main__ - Step 450 Global step 450 Train loss 0.037008 on epoch=56
06/03/2022 06:20:09 - INFO - __main__ - Global step 450 Train loss 0.021558 Classification-F1 0.4666666666666667 on epoch=56
06/03/2022 06:20:14 - INFO - __main__ - Step 460 Global step 460 Train loss 0.004050 on epoch=57
06/03/2022 06:20:19 - INFO - __main__ - Step 470 Global step 470 Train loss 0.003033 on epoch=58
06/03/2022 06:20:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.008127 on epoch=59
06/03/2022 06:20:29 - INFO - __main__ - Step 490 Global step 490 Train loss 0.002252 on epoch=61
06/03/2022 06:20:35 - INFO - __main__ - Step 500 Global step 500 Train loss 0.009409 on epoch=62
06/03/2022 06:20:35 - INFO - __main__ - Global step 500 Train loss 0.005374 Classification-F1 0.4482758620689655 on epoch=62
06/03/2022 06:20:41 - INFO - __main__ - Step 510 Global step 510 Train loss 0.005561 on epoch=63
06/03/2022 06:20:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.005057 on epoch=64
06/03/2022 06:20:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.020942 on epoch=66
06/03/2022 06:20:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.005564 on epoch=67
06/03/2022 06:21:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.028603 on epoch=68
06/03/2022 06:21:02 - INFO - __main__ - Global step 550 Train loss 0.013146 Classification-F1 0.3904761904761905 on epoch=68
06/03/2022 06:21:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.008637 on epoch=69
06/03/2022 06:21:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.013979 on epoch=71
06/03/2022 06:21:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.002895 on epoch=72
06/03/2022 06:21:22 - INFO - __main__ - Step 590 Global step 590 Train loss 0.000522 on epoch=73
06/03/2022 06:21:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.007575 on epoch=74
06/03/2022 06:21:28 - INFO - __main__ - Global step 600 Train loss 0.006721 Classification-F1 0.4434782608695652 on epoch=74
06/03/2022 06:21:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.017448 on epoch=76
06/03/2022 06:21:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.001017 on epoch=77
06/03/2022 06:21:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.007118 on epoch=78
06/03/2022 06:21:49 - INFO - __main__ - Step 640 Global step 640 Train loss 0.001185 on epoch=79
06/03/2022 06:21:54 - INFO - __main__ - Step 650 Global step 650 Train loss 0.079083 on epoch=81
06/03/2022 06:21:54 - INFO - __main__ - Global step 650 Train loss 0.021170 Classification-F1 0.4838709677419355 on epoch=81
06/03/2022 06:22:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.033641 on epoch=82
06/03/2022 06:22:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.001587 on epoch=83
06/03/2022 06:22:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000783 on epoch=84
06/03/2022 06:22:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.024182 on epoch=86
06/03/2022 06:22:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.005354 on epoch=87
06/03/2022 06:22:21 - INFO - __main__ - Global step 700 Train loss 0.013109 Classification-F1 0.4796747967479675 on epoch=87
06/03/2022 06:22:26 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000207 on epoch=88
06/03/2022 06:22:31 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000153 on epoch=89
06/03/2022 06:22:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000353 on epoch=91
06/03/2022 06:22:41 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000162 on epoch=92
06/03/2022 06:22:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000757 on epoch=93
06/03/2022 06:22:47 - INFO - __main__ - Global step 750 Train loss 0.000326 Classification-F1 0.4666666666666667 on epoch=93
06/03/2022 06:22:52 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000339 on epoch=94
06/03/2022 06:22:57 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000210 on epoch=96
06/03/2022 06:23:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.001504 on epoch=97
06/03/2022 06:23:07 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000025 on epoch=98
06/03/2022 06:23:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000139 on epoch=99
06/03/2022 06:23:13 - INFO - __main__ - Global step 800 Train loss 0.000443 Classification-F1 0.47540983606557374 on epoch=99
06/03/2022 06:23:18 - INFO - __main__ - Step 810 Global step 810 Train loss 0.013911 on epoch=101
06/03/2022 06:23:23 - INFO - __main__ - Step 820 Global step 820 Train loss 0.001589 on epoch=102
06/03/2022 06:23:28 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000115 on epoch=103
06/03/2022 06:23:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000024 on epoch=104
06/03/2022 06:23:39 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000062 on epoch=106
06/03/2022 06:23:39 - INFO - __main__ - Global step 850 Train loss 0.003140 Classification-F1 0.4838709677419355 on epoch=106
06/03/2022 06:23:44 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000261 on epoch=107
06/03/2022 06:23:50 - INFO - __main__ - Step 870 Global step 870 Train loss 0.003729 on epoch=108
06/03/2022 06:23:55 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000777 on epoch=109
06/03/2022 06:24:00 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000008 on epoch=111
06/03/2022 06:24:05 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000348 on epoch=112
06/03/2022 06:24:06 - INFO - __main__ - Global step 900 Train loss 0.001025 Classification-F1 0.4838709677419355 on epoch=112
06/03/2022 06:24:11 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000010 on epoch=113
06/03/2022 06:24:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000035 on epoch=114
06/03/2022 06:24:21 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000059 on epoch=116
06/03/2022 06:24:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000365 on epoch=117
06/03/2022 06:24:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000013 on epoch=118
06/03/2022 06:24:32 - INFO - __main__ - Global step 950 Train loss 0.000096 Classification-F1 0.4796747967479675 on epoch=118
06/03/2022 06:24:37 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000018 on epoch=119
06/03/2022 06:24:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000021 on epoch=121
06/03/2022 06:24:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000030 on epoch=122
06/03/2022 06:24:52 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000007 on epoch=123
06/03/2022 06:24:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000013 on epoch=124
06/03/2022 06:24:58 - INFO - __main__ - Global step 1000 Train loss 0.000018 Classification-F1 0.4796747967479675 on epoch=124
06/03/2022 06:24:58 - INFO - __main__ - save last model!
06/03/2022 06:24:59 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 06:24:59 - INFO - __main__ - Printing 3 examples
06/03/2022 06:24:59 - INFO - __main__ -  [ethos-race] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
06/03/2022 06:24:59 - INFO - __main__ - ['false']
06/03/2022 06:24:59 - INFO - __main__ -  [ethos-race] Honestly, go fuck yourself! bitch!
06/03/2022 06:24:59 - INFO - __main__ - ['false']
06/03/2022 06:24:59 - INFO - __main__ -  [ethos-race] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
06/03/2022 06:24:59 - INFO - __main__ - ['false']
06/03/2022 06:24:59 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:24:59 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:24:59 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 06:24:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 06:24:59 - INFO - __main__ - Printing 3 examples
06/03/2022 06:24:59 - INFO - __main__ -  [ethos-race] Lol, you're not white, you're a Jew. Jews are the worst nation and they must be annihilated, so like you
06/03/2022 06:24:59 - INFO - __main__ - ['false']
06/03/2022 06:24:59 - INFO - __main__ -  [ethos-race] Indian Ned Flanders. You look like you professionally harrass subpar women on Facebook
06/03/2022 06:24:59 - INFO - __main__ - ['false']
06/03/2022 06:24:59 - INFO - __main__ -  [ethos-race] Surprised that the burqa is banned in Belgium, but not in Poland where they are is much more looked-down upon. Kill them
06/03/2022 06:24:59 - INFO - __main__ - ['false']
06/03/2022 06:24:59 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:24:59 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:24:59 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 06:25:05 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 06:25:06 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 06:25:06 - INFO - __main__ - Printing 3 examples
06/03/2022 06:25:06 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 06:25:06 - INFO - __main__ - ['true']
06/03/2022 06:25:06 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 06:25:06 - INFO - __main__ - ['false']
06/03/2022 06:25:06 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 06:25:06 - INFO - __main__ - ['false']
06/03/2022 06:25:06 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:25:06 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:25:06 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 06:25:08 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_87_0.0005_8_predictions.txt
06/03/2022 06:25:08 - INFO - __main__ - Classification-F1 on test data: 0.8138
06/03/2022 06:25:08 - INFO - __main__ - prefix=ethos-race_64_87, lr=0.0005, bsz=8, dev_performance=0.49206349206349204, test_performance=0.8137931034482759
06/03/2022 06:25:08 - INFO - __main__ - Running ... prefix=ethos-race_64_87, lr=0.0003, bsz=8 ...
06/03/2022 06:25:09 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 06:25:09 - INFO - __main__ - Printing 3 examples
06/03/2022 06:25:09 - INFO - __main__ -  [ethos-race] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
06/03/2022 06:25:09 - INFO - __main__ - ['false']
06/03/2022 06:25:09 - INFO - __main__ -  [ethos-race] Honestly, go fuck yourself! bitch!
06/03/2022 06:25:09 - INFO - __main__ - ['false']
06/03/2022 06:25:09 - INFO - __main__ -  [ethos-race] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
06/03/2022 06:25:09 - INFO - __main__ - ['false']
06/03/2022 06:25:09 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:25:09 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:25:09 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 06:25:09 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 06:25:09 - INFO - __main__ - Printing 3 examples
06/03/2022 06:25:09 - INFO - __main__ -  [ethos-race] Lol, you're not white, you're a Jew. Jews are the worst nation and they must be annihilated, so like you
06/03/2022 06:25:09 - INFO - __main__ - ['false']
06/03/2022 06:25:09 - INFO - __main__ -  [ethos-race] Indian Ned Flanders. You look like you professionally harrass subpar women on Facebook
06/03/2022 06:25:09 - INFO - __main__ - ['false']
06/03/2022 06:25:09 - INFO - __main__ -  [ethos-race] Surprised that the burqa is banned in Belgium, but not in Poland where they are is much more looked-down upon. Kill them
06/03/2022 06:25:09 - INFO - __main__ - ['false']
06/03/2022 06:25:09 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:25:09 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:25:09 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 06:25:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 06:25:12 - INFO - __main__ - Starting training!
06/03/2022 06:25:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 06:25:22 - INFO - __main__ - Starting training!
06/03/2022 06:25:26 - INFO - __main__ - Step 10 Global step 10 Train loss 23.922157 on epoch=1
06/03/2022 06:25:31 - INFO - __main__ - Step 20 Global step 20 Train loss 18.393049 on epoch=2
06/03/2022 06:25:36 - INFO - __main__ - Step 30 Global step 30 Train loss 17.221558 on epoch=3
06/03/2022 06:25:41 - INFO - __main__ - Step 40 Global step 40 Train loss 16.609324 on epoch=4
06/03/2022 06:25:47 - INFO - __main__ - Step 50 Global step 50 Train loss 14.166208 on epoch=6
06/03/2022 06:26:05 - INFO - __main__ - Global step 50 Train loss 18.062458 Classification-F1 0.0 on epoch=6
06/03/2022 06:26:11 - INFO - __main__ - Step 60 Global step 60 Train loss 14.716225 on epoch=7
06/03/2022 06:26:16 - INFO - __main__ - Step 70 Global step 70 Train loss 12.796135 on epoch=8
06/03/2022 06:26:21 - INFO - __main__ - Step 80 Global step 80 Train loss 12.103926 on epoch=9
06/03/2022 06:26:26 - INFO - __main__ - Step 90 Global step 90 Train loss 9.786348 on epoch=11
06/03/2022 06:26:31 - INFO - __main__ - Step 100 Global step 100 Train loss 7.116398 on epoch=12
06/03/2022 06:26:45 - INFO - __main__ - Global step 100 Train loss 11.303808 Classification-F1 0.0 on epoch=12
06/03/2022 06:26:50 - INFO - __main__ - Step 110 Global step 110 Train loss 3.384665 on epoch=13
06/03/2022 06:26:55 - INFO - __main__ - Step 120 Global step 120 Train loss 4.293763 on epoch=14
06/03/2022 06:27:00 - INFO - __main__ - Step 130 Global step 130 Train loss 1.131942 on epoch=16
06/03/2022 06:27:06 - INFO - __main__ - Step 140 Global step 140 Train loss 0.722165 on epoch=17
06/03/2022 06:27:11 - INFO - __main__ - Step 150 Global step 150 Train loss 0.460996 on epoch=18
06/03/2022 06:27:11 - INFO - __main__ - Global step 150 Train loss 1.998706 Classification-F1 0.49606299212598426 on epoch=18
06/03/2022 06:27:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.547447 on epoch=19
06/03/2022 06:27:22 - INFO - __main__ - Step 170 Global step 170 Train loss 0.460031 on epoch=21
06/03/2022 06:27:27 - INFO - __main__ - Step 180 Global step 180 Train loss 0.432453 on epoch=22
06/03/2022 06:27:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.397463 on epoch=23
06/03/2022 06:27:38 - INFO - __main__ - Step 200 Global step 200 Train loss 0.288903 on epoch=24
06/03/2022 06:27:38 - INFO - __main__ - Global step 200 Train loss 0.425260 Classification-F1 0.49206349206349204 on epoch=24
06/03/2022 06:27:44 - INFO - __main__ - Step 210 Global step 210 Train loss 0.270584 on epoch=26
06/03/2022 06:27:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.202519 on epoch=27
06/03/2022 06:27:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.297768 on epoch=28
06/03/2022 06:27:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.368483 on epoch=29
06/03/2022 06:28:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.304256 on epoch=31
06/03/2022 06:28:05 - INFO - __main__ - Global step 250 Train loss 0.288722 Classification-F1 0.2967032967032967 on epoch=31
06/03/2022 06:28:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.428464 on epoch=32
06/03/2022 06:28:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.210160 on epoch=33
06/03/2022 06:28:21 - INFO - __main__ - Step 280 Global step 280 Train loss 0.157873 on epoch=34
06/03/2022 06:28:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.154126 on epoch=36
06/03/2022 06:28:31 - INFO - __main__ - Step 300 Global step 300 Train loss 0.129168 on epoch=37
06/03/2022 06:28:32 - INFO - __main__ - Global step 300 Train loss 0.215958 Classification-F1 0.49206349206349204 on epoch=37
06/03/2022 06:28:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.130229 on epoch=38
06/03/2022 06:28:42 - INFO - __main__ - Step 320 Global step 320 Train loss 0.133272 on epoch=39
06/03/2022 06:28:47 - INFO - __main__ - Step 330 Global step 330 Train loss 0.099610 on epoch=41
06/03/2022 06:28:52 - INFO - __main__ - Step 340 Global step 340 Train loss 0.146461 on epoch=42
06/03/2022 06:28:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.128116 on epoch=43
06/03/2022 06:28:58 - INFO - __main__ - Global step 350 Train loss 0.127537 Classification-F1 0.3118279569892473 on epoch=43
06/03/2022 06:29:03 - INFO - __main__ - Step 360 Global step 360 Train loss 0.080618 on epoch=44
06/03/2022 06:29:09 - INFO - __main__ - Step 370 Global step 370 Train loss 0.072149 on epoch=46
06/03/2022 06:29:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.109385 on epoch=47
06/03/2022 06:29:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.047243 on epoch=48
06/03/2022 06:29:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.068580 on epoch=49
06/03/2022 06:29:25 - INFO - __main__ - Global step 400 Train loss 0.075595 Classification-F1 0.4666666666666667 on epoch=49
06/03/2022 06:29:30 - INFO - __main__ - Step 410 Global step 410 Train loss 0.075841 on epoch=51
06/03/2022 06:29:35 - INFO - __main__ - Step 420 Global step 420 Train loss 0.105877 on epoch=52
06/03/2022 06:29:40 - INFO - __main__ - Step 430 Global step 430 Train loss 0.050003 on epoch=53
06/03/2022 06:29:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.039806 on epoch=54
06/03/2022 06:29:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.062297 on epoch=56
06/03/2022 06:29:51 - INFO - __main__ - Global step 450 Train loss 0.066765 Classification-F1 0.4838709677419355 on epoch=56
06/03/2022 06:29:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.242019 on epoch=57
06/03/2022 06:30:02 - INFO - __main__ - Step 470 Global step 470 Train loss 0.072206 on epoch=58
06/03/2022 06:30:07 - INFO - __main__ - Step 480 Global step 480 Train loss 0.079528 on epoch=59
06/03/2022 06:30:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.048128 on epoch=61
06/03/2022 06:30:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.111082 on epoch=62
06/03/2022 06:30:18 - INFO - __main__ - Global step 500 Train loss 0.110593 Classification-F1 0.4838709677419355 on epoch=62
06/03/2022 06:30:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.084428 on epoch=63
06/03/2022 06:30:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.049319 on epoch=64
06/03/2022 06:30:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.040866 on epoch=66
06/03/2022 06:30:39 - INFO - __main__ - Step 540 Global step 540 Train loss 0.067468 on epoch=67
06/03/2022 06:30:44 - INFO - __main__ - Step 550 Global step 550 Train loss 0.059009 on epoch=68
06/03/2022 06:30:44 - INFO - __main__ - Global step 550 Train loss 0.060218 Classification-F1 0.452991452991453 on epoch=68
06/03/2022 06:30:50 - INFO - __main__ - Step 560 Global step 560 Train loss 0.012743 on epoch=69
06/03/2022 06:30:55 - INFO - __main__ - Step 570 Global step 570 Train loss 0.029913 on epoch=71
06/03/2022 06:31:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.053202 on epoch=72
06/03/2022 06:31:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.019493 on epoch=73
06/03/2022 06:31:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.031416 on epoch=74
06/03/2022 06:31:11 - INFO - __main__ - Global step 600 Train loss 0.029353 Classification-F1 0.47540983606557374 on epoch=74
06/03/2022 06:31:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.007345 on epoch=76
06/03/2022 06:31:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.067838 on epoch=77
06/03/2022 06:31:27 - INFO - __main__ - Step 630 Global step 630 Train loss 0.010282 on epoch=78
06/03/2022 06:31:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.036065 on epoch=79
06/03/2022 06:31:38 - INFO - __main__ - Step 650 Global step 650 Train loss 0.025364 on epoch=81
06/03/2022 06:31:38 - INFO - __main__ - Global step 650 Train loss 0.029379 Classification-F1 0.488 on epoch=81
06/03/2022 06:31:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.014527 on epoch=82
06/03/2022 06:31:49 - INFO - __main__ - Step 670 Global step 670 Train loss 0.014490 on epoch=83
06/03/2022 06:31:54 - INFO - __main__ - Step 680 Global step 680 Train loss 0.043468 on epoch=84
06/03/2022 06:32:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.033722 on epoch=86
06/03/2022 06:32:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.009188 on epoch=87
06/03/2022 06:32:05 - INFO - __main__ - Global step 700 Train loss 0.023079 Classification-F1 0.488 on epoch=87
06/03/2022 06:32:11 - INFO - __main__ - Step 710 Global step 710 Train loss 0.015180 on epoch=88
06/03/2022 06:32:16 - INFO - __main__ - Step 720 Global step 720 Train loss 0.012748 on epoch=89
06/03/2022 06:32:21 - INFO - __main__ - Step 730 Global step 730 Train loss 0.003324 on epoch=91
06/03/2022 06:32:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.076982 on epoch=92
06/03/2022 06:32:31 - INFO - __main__ - Step 750 Global step 750 Train loss 0.079107 on epoch=93
06/03/2022 06:32:32 - INFO - __main__ - Global step 750 Train loss 0.037468 Classification-F1 0.47107438016528924 on epoch=93
06/03/2022 06:32:37 - INFO - __main__ - Step 760 Global step 760 Train loss 0.113868 on epoch=94
06/03/2022 06:32:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.056422 on epoch=96
06/03/2022 06:32:47 - INFO - __main__ - Step 780 Global step 780 Train loss 0.050666 on epoch=97
06/03/2022 06:32:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.020025 on epoch=98
06/03/2022 06:32:58 - INFO - __main__ - Step 800 Global step 800 Train loss 0.005861 on epoch=99
06/03/2022 06:32:59 - INFO - __main__ - Global step 800 Train loss 0.049368 Classification-F1 0.4838709677419355 on epoch=99
06/03/2022 06:33:04 - INFO - __main__ - Step 810 Global step 810 Train loss 0.031083 on epoch=101
06/03/2022 06:33:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.030931 on epoch=102
06/03/2022 06:33:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.015206 on epoch=103
06/03/2022 06:33:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.017723 on epoch=104
06/03/2022 06:33:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.006143 on epoch=106
06/03/2022 06:33:25 - INFO - __main__ - Global step 850 Train loss 0.020217 Classification-F1 0.488 on epoch=106
06/03/2022 06:33:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.045498 on epoch=107
06/03/2022 06:33:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.002690 on epoch=108
06/03/2022 06:33:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.022270 on epoch=109
06/03/2022 06:33:46 - INFO - __main__ - Step 890 Global step 890 Train loss 0.004511 on epoch=111
06/03/2022 06:33:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.001212 on epoch=112
06/03/2022 06:33:52 - INFO - __main__ - Global step 900 Train loss 0.015236 Classification-F1 0.4838709677419355 on epoch=112
06/03/2022 06:33:57 - INFO - __main__ - Step 910 Global step 910 Train loss 0.010940 on epoch=113
06/03/2022 06:34:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.001053 on epoch=114
06/03/2022 06:34:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.002513 on epoch=116
06/03/2022 06:34:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.039990 on epoch=117
06/03/2022 06:34:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.008735 on epoch=118
06/03/2022 06:34:18 - INFO - __main__ - Global step 950 Train loss 0.012646 Classification-F1 0.4838709677419355 on epoch=118
06/03/2022 06:34:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.033324 on epoch=119
06/03/2022 06:34:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.024164 on epoch=121
06/03/2022 06:34:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.009839 on epoch=122
06/03/2022 06:34:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.029007 on epoch=123
06/03/2022 06:34:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.005773 on epoch=124
06/03/2022 06:34:45 - INFO - __main__ - Global step 1000 Train loss 0.020421 Classification-F1 0.47107438016528924 on epoch=124
06/03/2022 06:34:45 - INFO - __main__ - save last model!
06/03/2022 06:34:45 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 06:34:45 - INFO - __main__ - Printing 3 examples
06/03/2022 06:34:45 - INFO - __main__ -  [ethos-race] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
06/03/2022 06:34:45 - INFO - __main__ - ['false']
06/03/2022 06:34:45 - INFO - __main__ -  [ethos-race] Honestly, go fuck yourself! bitch!
06/03/2022 06:34:45 - INFO - __main__ - ['false']
06/03/2022 06:34:45 - INFO - __main__ -  [ethos-race] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
06/03/2022 06:34:45 - INFO - __main__ - ['false']
06/03/2022 06:34:45 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:34:45 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:34:45 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 06:34:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 06:34:45 - INFO - __main__ - Printing 3 examples
06/03/2022 06:34:45 - INFO - __main__ -  [ethos-race] Lol, you're not white, you're a Jew. Jews are the worst nation and they must be annihilated, so like you
06/03/2022 06:34:45 - INFO - __main__ - ['false']
06/03/2022 06:34:45 - INFO - __main__ -  [ethos-race] Indian Ned Flanders. You look like you professionally harrass subpar women on Facebook
06/03/2022 06:34:45 - INFO - __main__ - ['false']
06/03/2022 06:34:45 - INFO - __main__ -  [ethos-race] Surprised that the burqa is banned in Belgium, but not in Poland where they are is much more looked-down upon. Kill them
06/03/2022 06:34:45 - INFO - __main__ - ['false']
06/03/2022 06:34:45 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:34:45 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:34:45 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 06:34:51 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 06:34:52 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 06:34:52 - INFO - __main__ - Printing 3 examples
06/03/2022 06:34:52 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 06:34:52 - INFO - __main__ - ['true']
06/03/2022 06:34:52 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 06:34:52 - INFO - __main__ - ['false']
06/03/2022 06:34:52 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 06:34:52 - INFO - __main__ - ['false']
06/03/2022 06:34:52 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:34:52 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:34:52 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 06:34:54 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_87_0.0003_8_predictions.txt
06/03/2022 06:34:54 - INFO - __main__ - Classification-F1 on test data: 0.4494
06/03/2022 06:34:54 - INFO - __main__ - prefix=ethos-race_64_87, lr=0.0003, bsz=8, dev_performance=0.49606299212598426, test_performance=0.44936708860759494
06/03/2022 06:34:54 - INFO - __main__ - Running ... prefix=ethos-race_64_87, lr=0.0002, bsz=8 ...
06/03/2022 06:34:55 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 06:34:55 - INFO - __main__ - Printing 3 examples
06/03/2022 06:34:55 - INFO - __main__ -  [ethos-race] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
06/03/2022 06:34:55 - INFO - __main__ - ['false']
06/03/2022 06:34:55 - INFO - __main__ -  [ethos-race] Honestly, go fuck yourself! bitch!
06/03/2022 06:34:55 - INFO - __main__ - ['false']
06/03/2022 06:34:55 - INFO - __main__ -  [ethos-race] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
06/03/2022 06:34:55 - INFO - __main__ - ['false']
06/03/2022 06:34:55 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:34:55 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:34:55 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 06:34:55 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 06:34:55 - INFO - __main__ - Printing 3 examples
06/03/2022 06:34:55 - INFO - __main__ -  [ethos-race] Lol, you're not white, you're a Jew. Jews are the worst nation and they must be annihilated, so like you
06/03/2022 06:34:55 - INFO - __main__ - ['false']
06/03/2022 06:34:55 - INFO - __main__ -  [ethos-race] Indian Ned Flanders. You look like you professionally harrass subpar women on Facebook
06/03/2022 06:34:55 - INFO - __main__ - ['false']
06/03/2022 06:34:55 - INFO - __main__ -  [ethos-race] Surprised that the burqa is banned in Belgium, but not in Poland where they are is much more looked-down upon. Kill them
06/03/2022 06:34:55 - INFO - __main__ - ['false']
06/03/2022 06:34:55 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:34:55 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:34:55 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 06:34:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 06:34:56 - INFO - __main__ - Starting training!
06/03/2022 06:35:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 06:35:06 - INFO - __main__ - Starting training!
06/03/2022 06:35:11 - INFO - __main__ - Step 10 Global step 10 Train loss 23.680689 on epoch=1
06/03/2022 06:35:16 - INFO - __main__ - Step 20 Global step 20 Train loss 20.276321 on epoch=2
06/03/2022 06:35:21 - INFO - __main__ - Step 30 Global step 30 Train loss 18.580521 on epoch=3
06/03/2022 06:35:26 - INFO - __main__ - Step 40 Global step 40 Train loss 16.788189 on epoch=4
06/03/2022 06:35:31 - INFO - __main__ - Step 50 Global step 50 Train loss 16.957874 on epoch=6
06/03/2022 06:35:49 - INFO - __main__ - Global step 50 Train loss 19.256720 Classification-F1 0.0 on epoch=6
06/03/2022 06:35:55 - INFO - __main__ - Step 60 Global step 60 Train loss 16.545061 on epoch=7
06/03/2022 06:36:00 - INFO - __main__ - Step 70 Global step 70 Train loss 14.744232 on epoch=8
06/03/2022 06:36:05 - INFO - __main__ - Step 80 Global step 80 Train loss 14.620646 on epoch=9
06/03/2022 06:36:11 - INFO - __main__ - Step 90 Global step 90 Train loss 14.391014 on epoch=11
06/03/2022 06:36:16 - INFO - __main__ - Step 100 Global step 100 Train loss 12.816218 on epoch=12
06/03/2022 06:36:28 - INFO - __main__ - Global step 100 Train loss 14.623434 Classification-F1 0.0 on epoch=12
06/03/2022 06:36:33 - INFO - __main__ - Step 110 Global step 110 Train loss 12.176332 on epoch=13
06/03/2022 06:36:39 - INFO - __main__ - Step 120 Global step 120 Train loss 10.674926 on epoch=14
06/03/2022 06:36:44 - INFO - __main__ - Step 130 Global step 130 Train loss 8.754205 on epoch=16
06/03/2022 06:36:49 - INFO - __main__ - Step 140 Global step 140 Train loss 5.994658 on epoch=17
06/03/2022 06:36:54 - INFO - __main__ - Step 150 Global step 150 Train loss 4.779440 on epoch=18
06/03/2022 06:36:57 - INFO - __main__ - Global step 150 Train loss 8.475912 Classification-F1 0.08838383838383838 on epoch=18
06/03/2022 06:37:03 - INFO - __main__ - Step 160 Global step 160 Train loss 2.160423 on epoch=19
06/03/2022 06:37:08 - INFO - __main__ - Step 170 Global step 170 Train loss 1.399425 on epoch=21
06/03/2022 06:37:13 - INFO - __main__ - Step 180 Global step 180 Train loss 0.626342 on epoch=22
06/03/2022 06:37:18 - INFO - __main__ - Step 190 Global step 190 Train loss 1.487868 on epoch=23
06/03/2022 06:37:24 - INFO - __main__ - Step 200 Global step 200 Train loss 1.462067 on epoch=24
06/03/2022 06:37:24 - INFO - __main__ - Global step 200 Train loss 1.427225 Classification-F1 0.47540983606557374 on epoch=24
06/03/2022 06:37:30 - INFO - __main__ - Step 210 Global step 210 Train loss 1.505309 on epoch=26
06/03/2022 06:37:35 - INFO - __main__ - Step 220 Global step 220 Train loss 2.012955 on epoch=27
06/03/2022 06:37:41 - INFO - __main__ - Step 230 Global step 230 Train loss 1.654441 on epoch=28
06/03/2022 06:37:46 - INFO - __main__ - Step 240 Global step 240 Train loss 2.136172 on epoch=29
06/03/2022 06:37:51 - INFO - __main__ - Step 250 Global step 250 Train loss 1.572276 on epoch=31
06/03/2022 06:37:51 - INFO - __main__ - Global step 250 Train loss 1.776231 Classification-F1 0.4796747967479675 on epoch=31
06/03/2022 06:37:58 - INFO - __main__ - Step 260 Global step 260 Train loss 2.146125 on epoch=32
06/03/2022 06:38:03 - INFO - __main__ - Step 270 Global step 270 Train loss 2.491982 on epoch=33
06/03/2022 06:38:08 - INFO - __main__ - Step 280 Global step 280 Train loss 2.636850 on epoch=34
06/03/2022 06:38:13 - INFO - __main__ - Step 290 Global step 290 Train loss 1.214119 on epoch=36
06/03/2022 06:38:18 - INFO - __main__ - Step 300 Global step 300 Train loss 1.279725 on epoch=37
06/03/2022 06:38:19 - INFO - __main__ - Global step 300 Train loss 1.953760 Classification-F1 0.4796747967479675 on epoch=37
06/03/2022 06:38:24 - INFO - __main__ - Step 310 Global step 310 Train loss 0.779391 on epoch=38
06/03/2022 06:38:29 - INFO - __main__ - Step 320 Global step 320 Train loss 0.807381 on epoch=39
06/03/2022 06:38:34 - INFO - __main__ - Step 330 Global step 330 Train loss 1.094819 on epoch=41
06/03/2022 06:38:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.973875 on epoch=42
06/03/2022 06:38:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.890735 on epoch=43
06/03/2022 06:38:45 - INFO - __main__ - Global step 350 Train loss 0.909240 Classification-F1 0.46218487394957986 on epoch=43
06/03/2022 06:38:50 - INFO - __main__ - Step 360 Global step 360 Train loss 0.668626 on epoch=44
06/03/2022 06:38:55 - INFO - __main__ - Step 370 Global step 370 Train loss 0.613900 on epoch=46
06/03/2022 06:39:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.560986 on epoch=47
06/03/2022 06:39:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.423909 on epoch=48
06/03/2022 06:39:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.467749 on epoch=49
06/03/2022 06:39:11 - INFO - __main__ - Global step 400 Train loss 0.547034 Classification-F1 0.47540983606557374 on epoch=49
06/03/2022 06:39:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.478100 on epoch=51
06/03/2022 06:39:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.503342 on epoch=52
06/03/2022 06:39:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.489481 on epoch=53
06/03/2022 06:39:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.497676 on epoch=54
06/03/2022 06:39:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.398834 on epoch=56
06/03/2022 06:39:38 - INFO - __main__ - Global step 450 Train loss 0.473487 Classification-F1 1.0 on epoch=56
06/03/2022 06:39:44 - INFO - __main__ - Step 460 Global step 460 Train loss 0.483849 on epoch=57
06/03/2022 06:39:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.440289 on epoch=58
06/03/2022 06:39:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.426726 on epoch=59
06/03/2022 06:39:59 - INFO - __main__ - Step 490 Global step 490 Train loss 0.440526 on epoch=61
06/03/2022 06:40:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.445063 on epoch=62
06/03/2022 06:40:05 - INFO - __main__ - Global step 500 Train loss 0.447291 Classification-F1 0.36633663366336633 on epoch=62
06/03/2022 06:40:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.383539 on epoch=63
06/03/2022 06:40:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.372969 on epoch=64
06/03/2022 06:40:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.364662 on epoch=66
06/03/2022 06:40:26 - INFO - __main__ - Step 540 Global step 540 Train loss 0.378108 on epoch=67
06/03/2022 06:40:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.339229 on epoch=68
06/03/2022 06:40:31 - INFO - __main__ - Global step 550 Train loss 0.367701 Classification-F1 0.24705882352941178 on epoch=68
06/03/2022 06:40:37 - INFO - __main__ - Step 560 Global step 560 Train loss 0.393060 on epoch=69
06/03/2022 06:40:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.391515 on epoch=71
06/03/2022 06:40:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.402250 on epoch=72
06/03/2022 06:40:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.374832 on epoch=73
06/03/2022 06:40:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.342424 on epoch=74
06/03/2022 06:40:58 - INFO - __main__ - Global step 600 Train loss 0.380816 Classification-F1 0.35353535353535354 on epoch=74
06/03/2022 06:41:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.346925 on epoch=76
06/03/2022 06:41:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.383041 on epoch=77
06/03/2022 06:41:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.323922 on epoch=78
06/03/2022 06:41:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.377844 on epoch=79
06/03/2022 06:41:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.387256 on epoch=81
06/03/2022 06:41:24 - INFO - __main__ - Global step 650 Train loss 0.363798 Classification-F1 0.47107438016528924 on epoch=81
06/03/2022 06:41:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.404586 on epoch=82
06/03/2022 06:41:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.318731 on epoch=83
06/03/2022 06:41:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.338536 on epoch=84
06/03/2022 06:41:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.371361 on epoch=86
06/03/2022 06:41:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.356536 on epoch=87
06/03/2022 06:41:51 - INFO - __main__ - Global step 700 Train loss 0.357950 Classification-F1 0.3904761904761905 on epoch=87
06/03/2022 06:41:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.386146 on epoch=88
06/03/2022 06:42:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.377690 on epoch=89
06/03/2022 06:42:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.323553 on epoch=91
06/03/2022 06:42:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.391885 on epoch=92
06/03/2022 06:42:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.340277 on epoch=93
06/03/2022 06:42:18 - INFO - __main__ - Global step 750 Train loss 0.363910 Classification-F1 0.35353535353535354 on epoch=93
06/03/2022 06:42:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.354586 on epoch=94
06/03/2022 06:42:28 - INFO - __main__ - Step 770 Global step 770 Train loss 0.283239 on epoch=96
06/03/2022 06:42:33 - INFO - __main__ - Step 780 Global step 780 Train loss 0.330845 on epoch=97
06/03/2022 06:42:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.326275 on epoch=98
06/03/2022 06:42:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.303258 on epoch=99
06/03/2022 06:42:44 - INFO - __main__ - Global step 800 Train loss 0.319641 Classification-F1 0.39622641509433965 on epoch=99
06/03/2022 06:42:49 - INFO - __main__ - Step 810 Global step 810 Train loss 0.331483 on epoch=101
06/03/2022 06:42:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.306632 on epoch=102
06/03/2022 06:42:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.298708 on epoch=103
06/03/2022 06:43:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.304625 on epoch=104
06/03/2022 06:43:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.302889 on epoch=106
06/03/2022 06:43:10 - INFO - __main__ - Global step 850 Train loss 0.308867 Classification-F1 0.40186915887850466 on epoch=106
06/03/2022 06:43:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.309507 on epoch=107
06/03/2022 06:43:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.314362 on epoch=108
06/03/2022 06:43:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.330578 on epoch=109
06/03/2022 06:43:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.292818 on epoch=111
06/03/2022 06:43:36 - INFO - __main__ - Step 900 Global step 900 Train loss 0.318780 on epoch=112
06/03/2022 06:43:37 - INFO - __main__ - Global step 900 Train loss 0.313209 Classification-F1 0.4666666666666667 on epoch=112
06/03/2022 06:43:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.285114 on epoch=113
06/03/2022 06:43:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.299367 on epoch=114
06/03/2022 06:43:52 - INFO - __main__ - Step 930 Global step 930 Train loss 0.302940 on epoch=116
06/03/2022 06:43:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.275384 on epoch=117
06/03/2022 06:44:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.261719 on epoch=118
06/03/2022 06:44:04 - INFO - __main__ - Global step 950 Train loss 0.284905 Classification-F1 0.4576271186440678 on epoch=118
06/03/2022 06:44:09 - INFO - __main__ - Step 960 Global step 960 Train loss 0.268182 on epoch=119
06/03/2022 06:44:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.289360 on epoch=121
06/03/2022 06:44:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.289272 on epoch=122
06/03/2022 06:44:24 - INFO - __main__ - Step 990 Global step 990 Train loss 0.302063 on epoch=123
06/03/2022 06:44:29 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.251913 on epoch=124
06/03/2022 06:44:30 - INFO - __main__ - Global step 1000 Train loss 0.280158 Classification-F1 0.47540983606557374 on epoch=124
06/03/2022 06:44:30 - INFO - __main__ - save last model!
06/03/2022 06:44:30 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 06:44:30 - INFO - __main__ - Printing 3 examples
06/03/2022 06:44:30 - INFO - __main__ -  [ethos-race] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
06/03/2022 06:44:30 - INFO - __main__ - ['false']
06/03/2022 06:44:30 - INFO - __main__ -  [ethos-race] Honestly, go fuck yourself! bitch!
06/03/2022 06:44:30 - INFO - __main__ - ['false']
06/03/2022 06:44:30 - INFO - __main__ -  [ethos-race] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
06/03/2022 06:44:30 - INFO - __main__ - ['false']
06/03/2022 06:44:30 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:44:30 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:44:30 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 06:44:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 06:44:30 - INFO - __main__ - Printing 3 examples
06/03/2022 06:44:30 - INFO - __main__ -  [ethos-race] Lol, you're not white, you're a Jew. Jews are the worst nation and they must be annihilated, so like you
06/03/2022 06:44:30 - INFO - __main__ - ['false']
06/03/2022 06:44:30 - INFO - __main__ -  [ethos-race] Indian Ned Flanders. You look like you professionally harrass subpar women on Facebook
06/03/2022 06:44:30 - INFO - __main__ - ['false']
06/03/2022 06:44:30 - INFO - __main__ -  [ethos-race] Surprised that the burqa is banned in Belgium, but not in Poland where they are is much more looked-down upon. Kill them
06/03/2022 06:44:30 - INFO - __main__ - ['false']
06/03/2022 06:44:30 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:44:30 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:44:31 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 06:44:37 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 06:44:38 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 06:44:38 - INFO - __main__ - Printing 3 examples
06/03/2022 06:44:38 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 06:44:38 - INFO - __main__ - ['true']
06/03/2022 06:44:38 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 06:44:38 - INFO - __main__ - ['false']
06/03/2022 06:44:38 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 06:44:38 - INFO - __main__ - ['false']
06/03/2022 06:44:38 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:44:38 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:44:38 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 06:44:39 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_87_0.0002_8_predictions.txt
06/03/2022 06:44:39 - INFO - __main__ - Classification-F1 on test data: 0.4387
06/03/2022 06:44:40 - INFO - __main__ - prefix=ethos-race_64_87, lr=0.0002, bsz=8, dev_performance=1.0, test_performance=0.4387096774193549
06/03/2022 06:44:40 - INFO - __main__ - Running ... prefix=ethos-race_64_87, lr=0.0001, bsz=8 ...
06/03/2022 06:44:41 - INFO - __main__ - Start tokenizing ... 124 instances
06/03/2022 06:44:41 - INFO - __main__ - Printing 3 examples
06/03/2022 06:44:41 - INFO - __main__ -  [ethos-race] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
06/03/2022 06:44:41 - INFO - __main__ - ['false']
06/03/2022 06:44:41 - INFO - __main__ -  [ethos-race] Honestly, go fuck yourself! bitch!
06/03/2022 06:44:41 - INFO - __main__ - ['false']
06/03/2022 06:44:41 - INFO - __main__ -  [ethos-race] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
06/03/2022 06:44:41 - INFO - __main__ - ['false']
06/03/2022 06:44:41 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:44:41 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:44:41 - INFO - __main__ - Loaded 124 examples from train data
06/03/2022 06:44:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 06:44:41 - INFO - __main__ - Printing 3 examples
06/03/2022 06:44:41 - INFO - __main__ -  [ethos-race] Lol, you're not white, you're a Jew. Jews are the worst nation and they must be annihilated, so like you
06/03/2022 06:44:41 - INFO - __main__ - ['false']
06/03/2022 06:44:41 - INFO - __main__ -  [ethos-race] Indian Ned Flanders. You look like you professionally harrass subpar women on Facebook
06/03/2022 06:44:41 - INFO - __main__ - ['false']
06/03/2022 06:44:41 - INFO - __main__ -  [ethos-race] Surprised that the burqa is banned in Belgium, but not in Poland where they are is much more looked-down upon. Kill them
06/03/2022 06:44:41 - INFO - __main__ - ['false']
06/03/2022 06:44:41 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:44:41 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:44:41 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 06:44:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 06:44:43 - INFO - __main__ - Starting training!
06/03/2022 06:44:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 06:44:53 - INFO - __main__ - Starting training!
06/03/2022 06:44:58 - INFO - __main__ - Step 10 Global step 10 Train loss 24.701555 on epoch=1
06/03/2022 06:45:03 - INFO - __main__ - Step 20 Global step 20 Train loss 21.538958 on epoch=2
06/03/2022 06:45:08 - INFO - __main__ - Step 30 Global step 30 Train loss 18.579868 on epoch=3
06/03/2022 06:45:14 - INFO - __main__ - Step 40 Global step 40 Train loss 18.684109 on epoch=4
06/03/2022 06:45:19 - INFO - __main__ - Step 50 Global step 50 Train loss 18.097528 on epoch=6
06/03/2022 06:45:21 - INFO - __main__ - Global step 50 Train loss 20.320402 Classification-F1 0.0 on epoch=6
06/03/2022 06:45:27 - INFO - __main__ - Step 60 Global step 60 Train loss 17.652803 on epoch=7
06/03/2022 06:45:32 - INFO - __main__ - Step 70 Global step 70 Train loss 17.213634 on epoch=8
06/03/2022 06:45:37 - INFO - __main__ - Step 80 Global step 80 Train loss 17.041553 on epoch=9
06/03/2022 06:45:43 - INFO - __main__ - Step 90 Global step 90 Train loss 15.726689 on epoch=11
06/03/2022 06:45:48 - INFO - __main__ - Step 100 Global step 100 Train loss 16.609838 on epoch=12
06/03/2022 06:46:03 - INFO - __main__ - Global step 100 Train loss 16.848904 Classification-F1 0.0 on epoch=12
06/03/2022 06:46:08 - INFO - __main__ - Step 110 Global step 110 Train loss 15.500895 on epoch=13
06/03/2022 06:46:13 - INFO - __main__ - Step 120 Global step 120 Train loss 15.197184 on epoch=14
06/03/2022 06:46:18 - INFO - __main__ - Step 130 Global step 130 Train loss 14.727091 on epoch=16
06/03/2022 06:46:23 - INFO - __main__ - Step 140 Global step 140 Train loss 14.374521 on epoch=17
06/03/2022 06:46:28 - INFO - __main__ - Step 150 Global step 150 Train loss 14.245114 on epoch=18
06/03/2022 06:46:32 - INFO - __main__ - Global step 150 Train loss 14.808961 Classification-F1 0.0 on epoch=18
06/03/2022 06:46:37 - INFO - __main__ - Step 160 Global step 160 Train loss 13.887256 on epoch=19
06/03/2022 06:46:42 - INFO - __main__ - Step 170 Global step 170 Train loss 12.879282 on epoch=21
06/03/2022 06:46:47 - INFO - __main__ - Step 180 Global step 180 Train loss 12.465766 on epoch=22
06/03/2022 06:46:52 - INFO - __main__ - Step 190 Global step 190 Train loss 12.738741 on epoch=23
06/03/2022 06:46:58 - INFO - __main__ - Step 200 Global step 200 Train loss 11.677711 on epoch=24
06/03/2022 06:47:08 - INFO - __main__ - Global step 200 Train loss 12.729751 Classification-F1 0.0020512820512820513 on epoch=24
06/03/2022 06:47:14 - INFO - __main__ - Step 210 Global step 210 Train loss 12.220480 on epoch=26
06/03/2022 06:47:19 - INFO - __main__ - Step 220 Global step 220 Train loss 10.972784 on epoch=27
06/03/2022 06:47:25 - INFO - __main__ - Step 230 Global step 230 Train loss 10.506557 on epoch=28
06/03/2022 06:47:30 - INFO - __main__ - Step 240 Global step 240 Train loss 10.103022 on epoch=29
06/03/2022 06:47:35 - INFO - __main__ - Step 250 Global step 250 Train loss 9.197331 on epoch=31
06/03/2022 06:47:40 - INFO - __main__ - Global step 250 Train loss 10.600034 Classification-F1 0.0 on epoch=31
06/03/2022 06:47:46 - INFO - __main__ - Step 260 Global step 260 Train loss 7.110125 on epoch=32
06/03/2022 06:47:51 - INFO - __main__ - Step 270 Global step 270 Train loss 6.721712 on epoch=33
06/03/2022 06:47:56 - INFO - __main__ - Step 280 Global step 280 Train loss 5.233276 on epoch=34
06/03/2022 06:48:01 - INFO - __main__ - Step 290 Global step 290 Train loss 4.048154 on epoch=36
06/03/2022 06:48:06 - INFO - __main__ - Step 300 Global step 300 Train loss 3.632114 on epoch=37
06/03/2022 06:48:07 - INFO - __main__ - Global step 300 Train loss 5.349076 Classification-F1 0.17739130434782607 on epoch=37
06/03/2022 06:48:13 - INFO - __main__ - Step 310 Global step 310 Train loss 3.629902 on epoch=38
06/03/2022 06:48:18 - INFO - __main__ - Step 320 Global step 320 Train loss 2.539576 on epoch=39
06/03/2022 06:48:23 - INFO - __main__ - Step 330 Global step 330 Train loss 1.843220 on epoch=41
06/03/2022 06:48:28 - INFO - __main__ - Step 340 Global step 340 Train loss 1.305559 on epoch=42
06/03/2022 06:48:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.933383 on epoch=43
06/03/2022 06:48:34 - INFO - __main__ - Global step 350 Train loss 2.050328 Classification-F1 0.4074074074074074 on epoch=43
06/03/2022 06:48:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.592585 on epoch=44
06/03/2022 06:48:45 - INFO - __main__ - Step 370 Global step 370 Train loss 0.805518 on epoch=46
06/03/2022 06:48:50 - INFO - __main__ - Step 380 Global step 380 Train loss 0.485459 on epoch=47
06/03/2022 06:48:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.523521 on epoch=48
06/03/2022 06:49:01 - INFO - __main__ - Step 400 Global step 400 Train loss 0.407931 on epoch=49
06/03/2022 06:49:01 - INFO - __main__ - Global step 400 Train loss 0.563003 Classification-F1 0.4796747967479675 on epoch=49
06/03/2022 06:49:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.575347 on epoch=51
06/03/2022 06:49:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.419471 on epoch=52
06/03/2022 06:49:18 - INFO - __main__ - Step 430 Global step 430 Train loss 0.321855 on epoch=53
06/03/2022 06:49:23 - INFO - __main__ - Step 440 Global step 440 Train loss 0.317087 on epoch=54
06/03/2022 06:49:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.350186 on epoch=56
06/03/2022 06:49:28 - INFO - __main__ - Global step 450 Train loss 0.396789 Classification-F1 0.42857142857142855 on epoch=56
06/03/2022 06:49:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.268918 on epoch=57
06/03/2022 06:49:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.302632 on epoch=58
06/03/2022 06:49:44 - INFO - __main__ - Step 480 Global step 480 Train loss 0.281870 on epoch=59
06/03/2022 06:49:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.325979 on epoch=61
06/03/2022 06:49:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.274066 on epoch=62
06/03/2022 06:49:55 - INFO - __main__ - Global step 500 Train loss 0.290693 Classification-F1 0.488 on epoch=62
06/03/2022 06:50:01 - INFO - __main__ - Step 510 Global step 510 Train loss 0.251505 on epoch=63
06/03/2022 06:50:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.274784 on epoch=64
06/03/2022 06:50:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.284244 on epoch=66
06/03/2022 06:50:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.314368 on epoch=67
06/03/2022 06:50:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.278913 on epoch=68
06/03/2022 06:50:22 - INFO - __main__ - Global step 550 Train loss 0.280763 Classification-F1 0.4666666666666667 on epoch=68
06/03/2022 06:50:28 - INFO - __main__ - Step 560 Global step 560 Train loss 0.213443 on epoch=69
06/03/2022 06:50:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.209699 on epoch=71
06/03/2022 06:50:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.267147 on epoch=72
06/03/2022 06:50:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.215235 on epoch=73
06/03/2022 06:50:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.180833 on epoch=74
06/03/2022 06:50:49 - INFO - __main__ - Global step 600 Train loss 0.217272 Classification-F1 0.47540983606557374 on epoch=74
06/03/2022 06:50:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.173441 on epoch=76
06/03/2022 06:50:59 - INFO - __main__ - Step 620 Global step 620 Train loss 0.200225 on epoch=77
06/03/2022 06:51:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.183467 on epoch=78
06/03/2022 06:51:10 - INFO - __main__ - Step 640 Global step 640 Train loss 0.243101 on epoch=79
06/03/2022 06:51:15 - INFO - __main__ - Step 650 Global step 650 Train loss 0.185109 on epoch=81
06/03/2022 06:51:15 - INFO - __main__ - Global step 650 Train loss 0.197069 Classification-F1 0.4482758620689655 on epoch=81
06/03/2022 06:51:21 - INFO - __main__ - Step 660 Global step 660 Train loss 0.177850 on epoch=82
06/03/2022 06:51:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.252950 on epoch=83
06/03/2022 06:51:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.203270 on epoch=84
06/03/2022 06:51:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.147688 on epoch=86
06/03/2022 06:51:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.165642 on epoch=87
06/03/2022 06:51:42 - INFO - __main__ - Global step 700 Train loss 0.189480 Classification-F1 0.4796747967479675 on epoch=87
06/03/2022 06:51:47 - INFO - __main__ - Step 710 Global step 710 Train loss 0.131978 on epoch=88
06/03/2022 06:51:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.133852 on epoch=89
06/03/2022 06:51:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.095245 on epoch=91
06/03/2022 06:52:03 - INFO - __main__ - Step 740 Global step 740 Train loss 0.130568 on epoch=92
06/03/2022 06:52:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.131254 on epoch=93
06/03/2022 06:52:09 - INFO - __main__ - Global step 750 Train loss 0.124579 Classification-F1 0.4796747967479675 on epoch=93
06/03/2022 06:52:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.123397 on epoch=94
06/03/2022 06:52:19 - INFO - __main__ - Step 770 Global step 770 Train loss 0.071258 on epoch=96
06/03/2022 06:52:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.114652 on epoch=97
06/03/2022 06:52:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.096705 on epoch=98
06/03/2022 06:52:35 - INFO - __main__ - Step 800 Global step 800 Train loss 0.076152 on epoch=99
06/03/2022 06:52:35 - INFO - __main__ - Global step 800 Train loss 0.096433 Classification-F1 0.47107438016528924 on epoch=99
06/03/2022 06:52:40 - INFO - __main__ - Step 810 Global step 810 Train loss 0.115353 on epoch=101
06/03/2022 06:52:45 - INFO - __main__ - Step 820 Global step 820 Train loss 0.078483 on epoch=102
06/03/2022 06:52:51 - INFO - __main__ - Step 830 Global step 830 Train loss 0.090156 on epoch=103
06/03/2022 06:52:56 - INFO - __main__ - Step 840 Global step 840 Train loss 0.123029 on epoch=104
06/03/2022 06:53:01 - INFO - __main__ - Step 850 Global step 850 Train loss 0.066394 on epoch=106
06/03/2022 06:53:02 - INFO - __main__ - Global step 850 Train loss 0.094683 Classification-F1 0.488 on epoch=106
06/03/2022 06:53:07 - INFO - __main__ - Step 860 Global step 860 Train loss 0.094332 on epoch=107
06/03/2022 06:53:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.051083 on epoch=108
06/03/2022 06:53:17 - INFO - __main__ - Step 880 Global step 880 Train loss 0.060026 on epoch=109
06/03/2022 06:53:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.113535 on epoch=111
06/03/2022 06:53:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.080551 on epoch=112
06/03/2022 06:53:28 - INFO - __main__ - Global step 900 Train loss 0.079906 Classification-F1 0.488 on epoch=112
06/03/2022 06:53:33 - INFO - __main__ - Step 910 Global step 910 Train loss 0.064069 on epoch=113
06/03/2022 06:53:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.053529 on epoch=114
06/03/2022 06:53:44 - INFO - __main__ - Step 930 Global step 930 Train loss 0.061706 on epoch=116
06/03/2022 06:53:49 - INFO - __main__ - Step 940 Global step 940 Train loss 0.043254 on epoch=117
06/03/2022 06:53:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.045309 on epoch=118
06/03/2022 06:53:55 - INFO - __main__ - Global step 950 Train loss 0.053573 Classification-F1 0.4796747967479675 on epoch=118
06/03/2022 06:54:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.060807 on epoch=119
06/03/2022 06:54:05 - INFO - __main__ - Step 970 Global step 970 Train loss 0.044290 on epoch=121
06/03/2022 06:54:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.041522 on epoch=122
06/03/2022 06:54:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.025683 on epoch=123
06/03/2022 06:54:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.037136 on epoch=124
06/03/2022 06:54:22 - INFO - __main__ - Global step 1000 Train loss 0.041887 Classification-F1 0.4796747967479675 on epoch=124
06/03/2022 06:54:22 - INFO - __main__ - save last model!
06/03/2022 06:54:28 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 06:54:29 - INFO - __main__ - Start tokenizing ... 87 instances
06/03/2022 06:54:29 - INFO - __main__ - Printing 3 examples
06/03/2022 06:54:29 - INFO - __main__ -  [ethos-race] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
06/03/2022 06:54:29 - INFO - __main__ - ['true']
06/03/2022 06:54:29 - INFO - __main__ -  [ethos-race] Looks like the gay poster boy with syphilis
06/03/2022 06:54:29 - INFO - __main__ - ['false']
06/03/2022 06:54:29 - INFO - __main__ -  [ethos-race] Jewish piece of shits like him should get hanged
06/03/2022 06:54:29 - INFO - __main__ - ['false']
06/03/2022 06:54:29 - INFO - __main__ - Tokenizing Input ...
06/03/2022 06:54:29 - INFO - __main__ - Tokenizing Output ...
06/03/2022 06:54:29 - INFO - __main__ - Loaded 87 examples from test data
06/03/2022 06:54:31 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-ethos-race/ethos-race_64_87_0.0001_8_predictions.txt
06/03/2022 06:54:31 - INFO - __main__ - Classification-F1 on test data: 0.7702
06/03/2022 06:54:31 - INFO - __main__ - prefix=ethos-race_64_87, lr=0.0001, bsz=8, dev_performance=0.488, test_performance=0.7702464788732395
