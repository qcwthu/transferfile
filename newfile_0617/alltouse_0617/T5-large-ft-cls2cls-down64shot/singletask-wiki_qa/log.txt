05/21/2022 21:25:23 - INFO - __main__ - Namespace(task_dir='data_64/wiki_qa/', task_name='wiki_qa', identifier='T5-large-ft-cls2cls-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/21/2022 21:25:23 - INFO - __main__ - models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa
05/21/2022 21:25:23 - INFO - __main__ - Namespace(task_dir='data_64/wiki_qa/', task_name='wiki_qa', identifier='T5-large-ft-cls2cls-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/21/2022 21:25:23 - INFO - __main__ - models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa
05/21/2022 21:25:24 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:25:24 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:25:24 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:25:24 - INFO - __main__ - Using 2 gpus
05/21/2022 21:25:24 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:25:24 - INFO - __main__ - Using 2 gpus
05/21/2022 21:25:24 - INFO - __main__ - Fine-tuning the following samples: ['wiki_qa_64_100', 'wiki_qa_64_13', 'wiki_qa_64_21', 'wiki_qa_64_42', 'wiki_qa_64_87']
05/21/2022 21:25:24 - INFO - __main__ - Fine-tuning the following samples: ['wiki_qa_64_100', 'wiki_qa_64_13', 'wiki_qa_64_21', 'wiki_qa_64_42', 'wiki_qa_64_87']
05/21/2022 21:25:30 - INFO - __main__ - Running ... prefix=wiki_qa_64_100, lr=0.0005, bsz=8 ...
06/01/2022 22:29:48 - INFO - __main__ - Namespace(task_dir='data_64/wiki_qa/', task_name='wiki_qa', identifier='T5-large-ft-cls2cls-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
06/01/2022 22:29:48 - INFO - __main__ - models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa
06/01/2022 22:29:48 - INFO - __main__ - Namespace(task_dir='data_64/wiki_qa/', task_name='wiki_qa', identifier='T5-large-ft-cls2cls-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
06/01/2022 22:29:48 - INFO - __main__ - models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa
06/01/2022 22:29:50 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/01/2022 22:29:50 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/01/2022 22:29:50 - INFO - __main__ - args.device: cuda:0
06/01/2022 22:29:50 - INFO - __main__ - Using 2 gpus
06/01/2022 22:29:50 - INFO - __main__ - Fine-tuning the following samples: ['wiki_qa_64_100', 'wiki_qa_64_13', 'wiki_qa_64_21', 'wiki_qa_64_42', 'wiki_qa_64_87']
06/01/2022 22:29:50 - INFO - __main__ - args.device: cuda:1
06/01/2022 22:29:50 - INFO - __main__ - Using 2 gpus
06/01/2022 22:29:50 - INFO - __main__ - Fine-tuning the following samples: ['wiki_qa_64_100', 'wiki_qa_64_13', 'wiki_qa_64_21', 'wiki_qa_64_42', 'wiki_qa_64_87']
06/01/2022 22:29:54 - INFO - __main__ - Running ... prefix=wiki_qa_64_100, lr=0.0005, bsz=8 ...
06/01/2022 22:29:55 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 22:29:55 - INFO - __main__ - Printing 3 examples
06/01/2022 22:29:55 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/01/2022 22:29:55 - INFO - __main__ - ['false']
06/01/2022 22:29:55 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/01/2022 22:29:55 - INFO - __main__ - ['false']
06/01/2022 22:29:55 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/01/2022 22:29:55 - INFO - __main__ - ['false']
06/01/2022 22:29:55 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:29:55 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 22:29:55 - INFO - __main__ - Printing 3 examples
06/01/2022 22:29:55 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/01/2022 22:29:55 - INFO - __main__ - ['false']
06/01/2022 22:29:55 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/01/2022 22:29:55 - INFO - __main__ - ['false']
06/01/2022 22:29:55 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/01/2022 22:29:55 - INFO - __main__ - ['false']
06/01/2022 22:29:55 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:29:55 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:29:55 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:29:56 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 22:29:56 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 22:29:56 - INFO - __main__ - Printing 3 examples
06/01/2022 22:29:56 - INFO - __main__ -  [wiki_qa] question: when did hitler kill himself [SEP] answer: In 2009, DNA tests were performed on a skull Soviet officials had long believed to be Hitler's.
06/01/2022 22:29:56 - INFO - __main__ - ['false']
06/01/2022 22:29:56 - INFO - __main__ -  [wiki_qa] question: what is muse's lead singer's name [SEP] answer: Muse are known for their energetic and extravagant live performances and their fusion of many music genres , including space rock , progressive rock , alternative rock , heavy metal , classical music and electronica .
06/01/2022 22:29:56 - INFO - __main__ - ['false']
06/01/2022 22:29:56 - INFO - __main__ -  [wiki_qa] question: who narrates the big lebowski [SEP] answer: The film is loosely inspired by the work of Raymond Chandler .
06/01/2022 22:29:56 - INFO - __main__ - ['false']
06/01/2022 22:29:56 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:29:56 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 22:29:56 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 22:29:56 - INFO - __main__ - Printing 3 examples
06/01/2022 22:29:56 - INFO - __main__ -  [wiki_qa] question: when did hitler kill himself [SEP] answer: In 2009, DNA tests were performed on a skull Soviet officials had long believed to be Hitler's.
06/01/2022 22:29:56 - INFO - __main__ - ['false']
06/01/2022 22:29:56 - INFO - __main__ -  [wiki_qa] question: what is muse's lead singer's name [SEP] answer: Muse are known for their energetic and extravagant live performances and their fusion of many music genres , including space rock , progressive rock , alternative rock , heavy metal , classical music and electronica .
06/01/2022 22:29:56 - INFO - __main__ - ['false']
06/01/2022 22:29:56 - INFO - __main__ -  [wiki_qa] question: who narrates the big lebowski [SEP] answer: The film is loosely inspired by the work of Raymond Chandler .
06/01/2022 22:29:56 - INFO - __main__ - ['false']
06/01/2022 22:29:56 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:29:56 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:29:56 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:29:56 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 22:29:56 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 22:30:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 22:30:09 - INFO - __main__ - Starting training!
06/01/2022 22:30:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 22:30:10 - INFO - __main__ - Starting training!
06/01/2022 22:30:15 - INFO - __main__ - Step 10 Global step 10 Train loss 23.041134 on epoch=1
06/01/2022 22:30:20 - INFO - __main__ - Step 20 Global step 20 Train loss 17.059393 on epoch=2
06/01/2022 22:30:25 - INFO - __main__ - Step 30 Global step 30 Train loss 15.039343 on epoch=3
06/01/2022 22:30:30 - INFO - __main__ - Step 40 Global step 40 Train loss 13.079779 on epoch=4
06/01/2022 22:30:35 - INFO - __main__ - Step 50 Global step 50 Train loss 8.601816 on epoch=6
06/01/2022 22:30:36 - INFO - __main__ - Global step 50 Train loss 15.364293 Classification-F1 0.027777777777777776 on epoch=6
06/01/2022 22:30:42 - INFO - __main__ - Step 60 Global step 60 Train loss 2.527339 on epoch=7
06/01/2022 22:30:47 - INFO - __main__ - Step 70 Global step 70 Train loss 0.740378 on epoch=8
06/01/2022 22:30:52 - INFO - __main__ - Step 80 Global step 80 Train loss 0.545101 on epoch=9
06/01/2022 22:30:57 - INFO - __main__ - Step 90 Global step 90 Train loss 0.507598 on epoch=11
06/01/2022 22:31:02 - INFO - __main__ - Step 100 Global step 100 Train loss 1.063644 on epoch=12
06/01/2022 22:31:13 - INFO - __main__ - Global step 100 Train loss 1.076812 Classification-F1 0.2198952879581152 on epoch=12
06/01/2022 22:31:20 - INFO - __main__ - Step 110 Global step 110 Train loss 0.383398 on epoch=13
06/01/2022 22:31:25 - INFO - __main__ - Step 120 Global step 120 Train loss 0.536596 on epoch=14
06/01/2022 22:31:30 - INFO - __main__ - Step 130 Global step 130 Train loss 0.526748 on epoch=16
06/01/2022 22:31:35 - INFO - __main__ - Step 140 Global step 140 Train loss 0.467219 on epoch=17
06/01/2022 22:31:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.546214 on epoch=18
06/01/2022 22:31:42 - INFO - __main__ - Global step 150 Train loss 0.492035 Classification-F1 0.3333333333333333 on epoch=18
06/01/2022 22:31:47 - INFO - __main__ - Step 160 Global step 160 Train loss 0.454812 on epoch=19
06/01/2022 22:31:53 - INFO - __main__ - Step 170 Global step 170 Train loss 0.423284 on epoch=21
06/01/2022 22:31:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.441573 on epoch=22
06/01/2022 22:32:03 - INFO - __main__ - Step 190 Global step 190 Train loss 0.442003 on epoch=23
06/01/2022 22:32:08 - INFO - __main__ - Step 200 Global step 200 Train loss 0.418285 on epoch=24
06/01/2022 22:32:09 - INFO - __main__ - Global step 200 Train loss 0.435991 Classification-F1 0.350463149416029 on epoch=24
06/01/2022 22:32:15 - INFO - __main__ - Step 210 Global step 210 Train loss 0.384632 on epoch=26
06/01/2022 22:32:20 - INFO - __main__ - Step 220 Global step 220 Train loss 0.454080 on epoch=27
06/01/2022 22:32:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.486382 on epoch=28
06/01/2022 22:32:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.430196 on epoch=29
06/01/2022 22:32:35 - INFO - __main__ - Step 250 Global step 250 Train loss 0.465288 on epoch=31
06/01/2022 22:32:37 - INFO - __main__ - Global step 250 Train loss 0.444116 Classification-F1 0.3333333333333333 on epoch=31
06/01/2022 22:32:42 - INFO - __main__ - Step 260 Global step 260 Train loss 0.403994 on epoch=32
06/01/2022 22:32:47 - INFO - __main__ - Step 270 Global step 270 Train loss 0.379772 on epoch=33
06/01/2022 22:32:52 - INFO - __main__ - Step 280 Global step 280 Train loss 0.392591 on epoch=34
06/01/2022 22:32:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.408699 on epoch=36
06/01/2022 22:33:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.394614 on epoch=37
06/01/2022 22:33:03 - INFO - __main__ - Global step 300 Train loss 0.395934 Classification-F1 0.3333333333333333 on epoch=37
06/01/2022 22:33:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.407477 on epoch=38
06/01/2022 22:33:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.429276 on epoch=39
06/01/2022 22:33:18 - INFO - __main__ - Step 330 Global step 330 Train loss 0.385846 on epoch=41
06/01/2022 22:33:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.434452 on epoch=42
06/01/2022 22:33:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.393023 on epoch=43
06/01/2022 22:33:29 - INFO - __main__ - Global step 350 Train loss 0.410015 Classification-F1 0.27106227106227104 on epoch=43
06/01/2022 22:33:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.402557 on epoch=44
06/01/2022 22:33:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.503135 on epoch=46
06/01/2022 22:33:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.396199 on epoch=47
06/01/2022 22:33:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.377271 on epoch=48
06/01/2022 22:33:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.375194 on epoch=49
06/01/2022 22:33:56 - INFO - __main__ - Global step 400 Train loss 0.410871 Classification-F1 0.4436832412523021 on epoch=49
06/01/2022 22:34:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.369150 on epoch=51
06/01/2022 22:34:07 - INFO - __main__ - Step 420 Global step 420 Train loss 0.393098 on epoch=52
06/01/2022 22:34:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.434825 on epoch=53
06/01/2022 22:34:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.348936 on epoch=54
06/01/2022 22:34:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.360244 on epoch=56
06/01/2022 22:34:23 - INFO - __main__ - Global step 450 Train loss 0.381251 Classification-F1 0.3333333333333333 on epoch=56
06/01/2022 22:34:28 - INFO - __main__ - Step 460 Global step 460 Train loss 0.399490 on epoch=57
06/01/2022 22:34:34 - INFO - __main__ - Step 470 Global step 470 Train loss 0.363160 on epoch=58
06/01/2022 22:34:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.368056 on epoch=59
06/01/2022 22:34:44 - INFO - __main__ - Step 490 Global step 490 Train loss 0.320692 on epoch=61
06/01/2022 22:34:49 - INFO - __main__ - Step 500 Global step 500 Train loss 0.414037 on epoch=62
06/01/2022 22:34:50 - INFO - __main__ - Global step 500 Train loss 0.373087 Classification-F1 0.5175982114340467 on epoch=62
06/01/2022 22:34:56 - INFO - __main__ - Step 510 Global step 510 Train loss 0.374888 on epoch=63
06/01/2022 22:35:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.337985 on epoch=64
06/01/2022 22:35:06 - INFO - __main__ - Step 530 Global step 530 Train loss 0.418152 on epoch=66
06/01/2022 22:35:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.366507 on epoch=67
06/01/2022 22:35:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.379972 on epoch=68
06/01/2022 22:35:18 - INFO - __main__ - Global step 550 Train loss 0.375501 Classification-F1 0.4335050424435899 on epoch=68
06/01/2022 22:35:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.364834 on epoch=69
06/01/2022 22:35:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.272106 on epoch=71
06/01/2022 22:35:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.377504 on epoch=72
06/01/2022 22:35:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.293502 on epoch=73
06/01/2022 22:35:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.337237 on epoch=74
06/01/2022 22:35:45 - INFO - __main__ - Global step 600 Train loss 0.329036 Classification-F1 0.554006968641115 on epoch=74
06/01/2022 22:35:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.353705 on epoch=76
06/01/2022 22:35:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.743117 on epoch=77
06/01/2022 22:36:01 - INFO - __main__ - Step 630 Global step 630 Train loss 0.334081 on epoch=78
06/01/2022 22:36:06 - INFO - __main__ - Step 640 Global step 640 Train loss 0.332572 on epoch=79
06/01/2022 22:36:11 - INFO - __main__ - Step 650 Global step 650 Train loss 0.306481 on epoch=81
06/01/2022 22:36:12 - INFO - __main__ - Global step 650 Train loss 0.413991 Classification-F1 0.4330011074197121 on epoch=81
06/01/2022 22:36:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.290480 on epoch=82
06/01/2022 22:36:22 - INFO - __main__ - Step 670 Global step 670 Train loss 0.282823 on epoch=83
06/01/2022 22:36:27 - INFO - __main__ - Step 680 Global step 680 Train loss 0.285523 on epoch=84
06/01/2022 22:36:32 - INFO - __main__ - Step 690 Global step 690 Train loss 0.329444 on epoch=86
06/01/2022 22:36:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.207951 on epoch=87
06/01/2022 22:36:39 - INFO - __main__ - Global step 700 Train loss 0.279244 Classification-F1 0.32631578947368417 on epoch=87
06/01/2022 22:36:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.349890 on epoch=88
06/01/2022 22:36:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.300602 on epoch=89
06/01/2022 22:36:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.220545 on epoch=91
06/01/2022 22:36:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.294521 on epoch=92
06/01/2022 22:37:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.250829 on epoch=93
06/01/2022 22:37:06 - INFO - __main__ - Global step 750 Train loss 0.283277 Classification-F1 0.42482504604051563 on epoch=93
06/01/2022 22:37:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.271353 on epoch=94
06/01/2022 22:37:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.193673 on epoch=96
06/01/2022 22:37:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.198465 on epoch=97
06/01/2022 22:37:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.222137 on epoch=98
06/01/2022 22:37:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.116993 on epoch=99
06/01/2022 22:37:33 - INFO - __main__ - Global step 800 Train loss 0.200524 Classification-F1 0.5367723731828498 on epoch=99
06/01/2022 22:37:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.111225 on epoch=101
06/01/2022 22:37:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.100233 on epoch=102
06/01/2022 22:37:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.053715 on epoch=103
06/01/2022 22:37:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.044504 on epoch=104
06/01/2022 22:37:59 - INFO - __main__ - Step 850 Global step 850 Train loss 0.091425 on epoch=106
06/01/2022 22:38:00 - INFO - __main__ - Global step 850 Train loss 0.080220 Classification-F1 0.34299516908212563 on epoch=106
06/01/2022 22:38:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.072148 on epoch=107
06/01/2022 22:38:10 - INFO - __main__ - Step 870 Global step 870 Train loss 0.054942 on epoch=108
06/01/2022 22:38:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.060343 on epoch=109
06/01/2022 22:38:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.048239 on epoch=111
06/01/2022 22:38:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.079044 on epoch=112
06/01/2022 22:38:27 - INFO - __main__ - Global step 900 Train loss 0.062943 Classification-F1 0.49220246238030096 on epoch=112
06/01/2022 22:38:32 - INFO - __main__ - Step 910 Global step 910 Train loss 0.049119 on epoch=113
06/01/2022 22:38:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.019127 on epoch=114
06/01/2022 22:38:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.029673 on epoch=116
06/01/2022 22:38:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.025479 on epoch=117
06/01/2022 22:38:52 - INFO - __main__ - Step 950 Global step 950 Train loss 0.006910 on epoch=118
06/01/2022 22:38:54 - INFO - __main__ - Global step 950 Train loss 0.026062 Classification-F1 0.49703629703629704 on epoch=118
06/01/2022 22:38:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.055931 on epoch=119
06/01/2022 22:39:04 - INFO - __main__ - Step 970 Global step 970 Train loss 0.007426 on epoch=121
06/01/2022 22:39:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.018927 on epoch=122
06/01/2022 22:39:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.004611 on epoch=123
06/01/2022 22:39:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.008892 on epoch=124
06/01/2022 22:39:20 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 22:39:20 - INFO - __main__ - Printing 3 examples
06/01/2022 22:39:20 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/01/2022 22:39:20 - INFO - __main__ - ['false']
06/01/2022 22:39:20 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/01/2022 22:39:20 - INFO - __main__ - ['false']
06/01/2022 22:39:20 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/01/2022 22:39:20 - INFO - __main__ - ['false']
06/01/2022 22:39:20 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:39:20 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:39:20 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 22:39:20 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 22:39:20 - INFO - __main__ - Printing 3 examples
06/01/2022 22:39:20 - INFO - __main__ -  [wiki_qa] question: when did hitler kill himself [SEP] answer: In 2009, DNA tests were performed on a skull Soviet officials had long believed to be Hitler's.
06/01/2022 22:39:20 - INFO - __main__ - ['false']
06/01/2022 22:39:20 - INFO - __main__ -  [wiki_qa] question: what is muse's lead singer's name [SEP] answer: Muse are known for their energetic and extravagant live performances and their fusion of many music genres , including space rock , progressive rock , alternative rock , heavy metal , classical music and electronica .
06/01/2022 22:39:20 - INFO - __main__ - ['false']
06/01/2022 22:39:20 - INFO - __main__ -  [wiki_qa] question: who narrates the big lebowski [SEP] answer: The film is loosely inspired by the work of Raymond Chandler .
06/01/2022 22:39:20 - INFO - __main__ - ['false']
06/01/2022 22:39:20 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:39:20 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:39:20 - INFO - __main__ - Global step 1000 Train loss 0.019158 Classification-F1 0.497651675995625 on epoch=124
06/01/2022 22:39:20 - INFO - __main__ - save last model!
06/01/2022 22:39:21 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 22:39:28 - INFO - __main__ - Loading checkpoint on the fly
06/01/2022 22:39:29 - INFO - __main__ - Start tokenizing ... 2733 instances
06/01/2022 22:39:29 - INFO - __main__ - Printing 3 examples
06/01/2022 22:39:29 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/01/2022 22:39:29 - INFO - __main__ - ['false']
06/01/2022 22:39:29 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/01/2022 22:39:29 - INFO - __main__ - ['false']
06/01/2022 22:39:29 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/01/2022 22:39:29 - INFO - __main__ - ['false']
06/01/2022 22:39:29 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:39:30 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:39:33 - INFO - __main__ - Loaded 2733 examples from test data
06/01/2022 22:39:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 22:39:33 - INFO - __main__ - Starting training!
06/01/2022 22:40:02 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_100_0.0005_8_predictions.txt
06/01/2022 22:40:02 - INFO - __main__ - Classification-F1 on test data: 0.3907
06/01/2022 22:40:02 - INFO - __main__ - prefix=wiki_qa_64_100, lr=0.0005, bsz=8, dev_performance=0.554006968641115, test_performance=0.39068286456876
06/01/2022 22:40:02 - INFO - __main__ - Running ... prefix=wiki_qa_64_100, lr=0.0003, bsz=8 ...
06/01/2022 22:40:03 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 22:40:03 - INFO - __main__ - Printing 3 examples
06/01/2022 22:40:03 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/01/2022 22:40:03 - INFO - __main__ - ['false']
06/01/2022 22:40:03 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/01/2022 22:40:03 - INFO - __main__ - ['false']
06/01/2022 22:40:03 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/01/2022 22:40:03 - INFO - __main__ - ['false']
06/01/2022 22:40:03 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:40:03 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:40:03 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 22:40:03 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 22:40:03 - INFO - __main__ - Printing 3 examples
06/01/2022 22:40:03 - INFO - __main__ -  [wiki_qa] question: when did hitler kill himself [SEP] answer: In 2009, DNA tests were performed on a skull Soviet officials had long believed to be Hitler's.
06/01/2022 22:40:03 - INFO - __main__ - ['false']
06/01/2022 22:40:03 - INFO - __main__ -  [wiki_qa] question: what is muse's lead singer's name [SEP] answer: Muse are known for their energetic and extravagant live performances and their fusion of many music genres , including space rock , progressive rock , alternative rock , heavy metal , classical music and electronica .
06/01/2022 22:40:03 - INFO - __main__ - ['false']
06/01/2022 22:40:03 - INFO - __main__ -  [wiki_qa] question: who narrates the big lebowski [SEP] answer: The film is loosely inspired by the work of Raymond Chandler .
06/01/2022 22:40:03 - INFO - __main__ - ['false']
06/01/2022 22:40:03 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:40:03 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:40:03 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 22:40:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 22:40:14 - INFO - __main__ - Starting training!
06/01/2022 22:40:18 - INFO - __main__ - Step 10 Global step 10 Train loss 22.314186 on epoch=1
06/01/2022 22:40:23 - INFO - __main__ - Step 20 Global step 20 Train loss 17.673717 on epoch=2
06/01/2022 22:40:28 - INFO - __main__ - Step 30 Global step 30 Train loss 16.521240 on epoch=3
06/01/2022 22:40:34 - INFO - __main__ - Step 40 Global step 40 Train loss 15.574110 on epoch=4
06/01/2022 22:40:39 - INFO - __main__ - Step 50 Global step 50 Train loss 13.834493 on epoch=6
06/01/2022 22:40:40 - INFO - __main__ - Global step 50 Train loss 17.183548 Classification-F1 0.0 on epoch=6
06/01/2022 22:40:46 - INFO - __main__ - Step 60 Global step 60 Train loss 13.022410 on epoch=7
06/01/2022 22:40:51 - INFO - __main__ - Step 70 Global step 70 Train loss 10.952508 on epoch=8
06/01/2022 22:40:55 - INFO - __main__ - Step 80 Global step 80 Train loss 6.316037 on epoch=9
06/01/2022 22:41:00 - INFO - __main__ - Step 90 Global step 90 Train loss 3.862485 on epoch=11
06/01/2022 22:41:05 - INFO - __main__ - Step 100 Global step 100 Train loss 1.336196 on epoch=12
06/01/2022 22:41:06 - INFO - __main__ - Global step 100 Train loss 7.097927 Classification-F1 0.3333333333333333 on epoch=12
06/01/2022 22:41:13 - INFO - __main__ - Step 110 Global step 110 Train loss 0.793905 on epoch=13
06/01/2022 22:41:18 - INFO - __main__ - Step 120 Global step 120 Train loss 0.592263 on epoch=14
06/01/2022 22:41:23 - INFO - __main__ - Step 130 Global step 130 Train loss 0.473503 on epoch=16
06/01/2022 22:41:28 - INFO - __main__ - Step 140 Global step 140 Train loss 0.488397 on epoch=17
06/01/2022 22:41:33 - INFO - __main__ - Step 150 Global step 150 Train loss 0.870649 on epoch=18
06/01/2022 22:41:34 - INFO - __main__ - Global step 150 Train loss 0.643743 Classification-F1 0.20849875930521092 on epoch=18
06/01/2022 22:41:39 - INFO - __main__ - Step 160 Global step 160 Train loss 1.045873 on epoch=19
06/01/2022 22:41:44 - INFO - __main__ - Step 170 Global step 170 Train loss 1.886670 on epoch=21
06/01/2022 22:41:49 - INFO - __main__ - Step 180 Global step 180 Train loss 0.634867 on epoch=22
06/01/2022 22:41:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.415208 on epoch=23
06/01/2022 22:41:59 - INFO - __main__ - Step 200 Global step 200 Train loss 0.430688 on epoch=24
06/01/2022 22:42:01 - INFO - __main__ - Global step 200 Train loss 0.882661 Classification-F1 0.34673046251993617 on epoch=24
06/01/2022 22:42:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.502818 on epoch=26
06/01/2022 22:42:12 - INFO - __main__ - Step 220 Global step 220 Train loss 0.454634 on epoch=27
06/01/2022 22:42:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.438555 on epoch=28
06/01/2022 22:42:22 - INFO - __main__ - Step 240 Global step 240 Train loss 0.440082 on epoch=29
06/01/2022 22:42:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.392931 on epoch=31
06/01/2022 22:42:28 - INFO - __main__ - Global step 250 Train loss 0.445804 Classification-F1 0.34296770117665637 on epoch=31
06/01/2022 22:42:33 - INFO - __main__ - Step 260 Global step 260 Train loss 0.353234 on epoch=32
06/01/2022 22:42:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.653897 on epoch=33
06/01/2022 22:42:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.423079 on epoch=34
06/01/2022 22:42:48 - INFO - __main__ - Step 290 Global step 290 Train loss 0.442421 on epoch=36
06/01/2022 22:42:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.392964 on epoch=37
06/01/2022 22:42:55 - INFO - __main__ - Global step 300 Train loss 0.453119 Classification-F1 0.4402206822310435 on epoch=37
06/01/2022 22:43:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.395279 on epoch=38
06/01/2022 22:43:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.461339 on epoch=39
06/01/2022 22:43:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.376615 on epoch=41
06/01/2022 22:43:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.473797 on epoch=42
06/01/2022 22:43:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.417540 on epoch=43
06/01/2022 22:43:22 - INFO - __main__ - Global step 350 Train loss 0.424914 Classification-F1 0.3333333333333333 on epoch=43
06/01/2022 22:43:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.416348 on epoch=44
06/01/2022 22:43:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.399345 on epoch=46
06/01/2022 22:43:37 - INFO - __main__ - Step 380 Global step 380 Train loss 0.356344 on epoch=47
06/01/2022 22:43:42 - INFO - __main__ - Step 390 Global step 390 Train loss 0.404529 on epoch=48
06/01/2022 22:43:47 - INFO - __main__ - Step 400 Global step 400 Train loss 0.353689 on epoch=49
06/01/2022 22:43:49 - INFO - __main__ - Global step 400 Train loss 0.386051 Classification-F1 0.4452012383900929 on epoch=49
06/01/2022 22:43:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.355801 on epoch=51
06/01/2022 22:44:00 - INFO - __main__ - Step 420 Global step 420 Train loss 0.353062 on epoch=52
06/01/2022 22:44:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.390244 on epoch=53
06/01/2022 22:44:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.365997 on epoch=54
06/01/2022 22:44:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.339156 on epoch=56
06/01/2022 22:44:16 - INFO - __main__ - Global step 450 Train loss 0.360852 Classification-F1 0.3917433917433918 on epoch=56
06/01/2022 22:44:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.353998 on epoch=57
06/01/2022 22:44:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.330823 on epoch=58
06/01/2022 22:44:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.355676 on epoch=59
06/01/2022 22:44:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.432162 on epoch=61
06/01/2022 22:44:42 - INFO - __main__ - Step 500 Global step 500 Train loss 0.377321 on epoch=62
06/01/2022 22:44:43 - INFO - __main__ - Global step 500 Train loss 0.369996 Classification-F1 0.3333333333333333 on epoch=62
06/01/2022 22:44:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.376356 on epoch=63
06/01/2022 22:44:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.386661 on epoch=64
06/01/2022 22:44:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.387517 on epoch=66
06/01/2022 22:45:03 - INFO - __main__ - Step 540 Global step 540 Train loss 0.434180 on epoch=67
06/01/2022 22:45:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.341723 on epoch=68
06/01/2022 22:45:09 - INFO - __main__ - Global step 550 Train loss 0.385287 Classification-F1 0.39636200314394787 on epoch=68
06/01/2022 22:45:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.370095 on epoch=69
06/01/2022 22:45:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.387512 on epoch=71
06/01/2022 22:45:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.388133 on epoch=72
06/01/2022 22:45:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.353538 on epoch=73
06/01/2022 22:45:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.313780 on epoch=74
06/01/2022 22:45:36 - INFO - __main__ - Global step 600 Train loss 0.362612 Classification-F1 0.5572028663207315 on epoch=74
06/01/2022 22:45:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.322784 on epoch=76
06/01/2022 22:45:47 - INFO - __main__ - Step 620 Global step 620 Train loss 0.374973 on epoch=77
06/01/2022 22:45:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.290582 on epoch=78
06/01/2022 22:45:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.273551 on epoch=79
06/01/2022 22:46:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.306306 on epoch=81
06/01/2022 22:46:04 - INFO - __main__ - Global step 650 Train loss 0.313639 Classification-F1 0.46803878883831385 on epoch=81
06/01/2022 22:46:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.229992 on epoch=82
06/01/2022 22:46:14 - INFO - __main__ - Step 670 Global step 670 Train loss 0.271361 on epoch=83
06/01/2022 22:46:19 - INFO - __main__ - Step 680 Global step 680 Train loss 0.210215 on epoch=84
06/01/2022 22:46:24 - INFO - __main__ - Step 690 Global step 690 Train loss 0.252938 on epoch=86
06/01/2022 22:46:29 - INFO - __main__ - Step 700 Global step 700 Train loss 0.270477 on epoch=87
06/01/2022 22:46:30 - INFO - __main__ - Global step 700 Train loss 0.246997 Classification-F1 0.35518871580252653 on epoch=87
06/01/2022 22:46:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.248525 on epoch=88
06/01/2022 22:46:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.201403 on epoch=89
06/01/2022 22:46:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.181626 on epoch=91
06/01/2022 22:46:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.148059 on epoch=92
06/01/2022 22:46:55 - INFO - __main__ - Step 750 Global step 750 Train loss 0.214733 on epoch=93
06/01/2022 22:46:57 - INFO - __main__ - Global step 750 Train loss 0.198869 Classification-F1 0.439671682626539 on epoch=93
06/01/2022 22:47:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.138435 on epoch=94
06/01/2022 22:47:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.203716 on epoch=96
06/01/2022 22:47:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.100456 on epoch=97
06/01/2022 22:47:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.139089 on epoch=98
06/01/2022 22:47:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.059344 on epoch=99
06/01/2022 22:47:23 - INFO - __main__ - Global step 800 Train loss 0.128208 Classification-F1 0.5584268958163457 on epoch=99
06/01/2022 22:47:29 - INFO - __main__ - Step 810 Global step 810 Train loss 0.067715 on epoch=101
06/01/2022 22:47:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.139962 on epoch=102
06/01/2022 22:47:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.086127 on epoch=103
06/01/2022 22:47:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.097908 on epoch=104
06/01/2022 22:47:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.083306 on epoch=106
06/01/2022 22:47:51 - INFO - __main__ - Global step 850 Train loss 0.095004 Classification-F1 0.5440923605993613 on epoch=106
06/01/2022 22:47:56 - INFO - __main__ - Step 860 Global step 860 Train loss 0.092707 on epoch=107
06/01/2022 22:48:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.089195 on epoch=108
06/01/2022 22:48:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.081201 on epoch=109
06/01/2022 22:48:11 - INFO - __main__ - Step 890 Global step 890 Train loss 0.047271 on epoch=111
06/01/2022 22:48:16 - INFO - __main__ - Step 900 Global step 900 Train loss 0.064620 on epoch=112
06/01/2022 22:48:18 - INFO - __main__ - Global step 900 Train loss 0.074999 Classification-F1 0.3710769230769231 on epoch=112
06/01/2022 22:48:23 - INFO - __main__ - Step 910 Global step 910 Train loss 0.079668 on epoch=113
06/01/2022 22:48:28 - INFO - __main__ - Step 920 Global step 920 Train loss 0.099033 on epoch=114
06/01/2022 22:48:33 - INFO - __main__ - Step 930 Global step 930 Train loss 0.059716 on epoch=116
06/01/2022 22:48:38 - INFO - __main__ - Step 940 Global step 940 Train loss 0.037833 on epoch=117
06/01/2022 22:48:43 - INFO - __main__ - Step 950 Global step 950 Train loss 0.068971 on epoch=118
06/01/2022 22:48:44 - INFO - __main__ - Global step 950 Train loss 0.069044 Classification-F1 0.5643294758339006 on epoch=118
06/01/2022 22:48:50 - INFO - __main__ - Step 960 Global step 960 Train loss 0.031225 on epoch=119
06/01/2022 22:48:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.027841 on epoch=121
06/01/2022 22:49:00 - INFO - __main__ - Step 980 Global step 980 Train loss 0.057619 on epoch=122
06/01/2022 22:49:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.026068 on epoch=123
06/01/2022 22:49:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.027790 on epoch=124
06/01/2022 22:49:11 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 22:49:11 - INFO - __main__ - Printing 3 examples
06/01/2022 22:49:11 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/01/2022 22:49:11 - INFO - __main__ - ['false']
06/01/2022 22:49:11 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/01/2022 22:49:11 - INFO - __main__ - ['false']
06/01/2022 22:49:11 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/01/2022 22:49:11 - INFO - __main__ - ['false']
06/01/2022 22:49:11 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:49:11 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:49:11 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 22:49:11 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 22:49:11 - INFO - __main__ - Printing 3 examples
06/01/2022 22:49:11 - INFO - __main__ -  [wiki_qa] question: when did hitler kill himself [SEP] answer: In 2009, DNA tests were performed on a skull Soviet officials had long believed to be Hitler's.
06/01/2022 22:49:11 - INFO - __main__ - ['false']
06/01/2022 22:49:11 - INFO - __main__ -  [wiki_qa] question: what is muse's lead singer's name [SEP] answer: Muse are known for their energetic and extravagant live performances and their fusion of many music genres , including space rock , progressive rock , alternative rock , heavy metal , classical music and electronica .
06/01/2022 22:49:11 - INFO - __main__ - ['false']
06/01/2022 22:49:11 - INFO - __main__ -  [wiki_qa] question: who narrates the big lebowski [SEP] answer: The film is loosely inspired by the work of Raymond Chandler .
06/01/2022 22:49:11 - INFO - __main__ - ['false']
06/01/2022 22:49:11 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:49:11 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:49:11 - INFO - __main__ - Global step 1000 Train loss 0.034109 Classification-F1 0.5137254901960784 on epoch=124
06/01/2022 22:49:11 - INFO - __main__ - save last model!
06/01/2022 22:49:11 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 22:49:19 - INFO - __main__ - Loading checkpoint on the fly
06/01/2022 22:49:19 - INFO - __main__ - Start tokenizing ... 2733 instances
06/01/2022 22:49:19 - INFO - __main__ - Printing 3 examples
06/01/2022 22:49:19 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/01/2022 22:49:19 - INFO - __main__ - ['false']
06/01/2022 22:49:19 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/01/2022 22:49:19 - INFO - __main__ - ['false']
06/01/2022 22:49:19 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/01/2022 22:49:19 - INFO - __main__ - ['false']
06/01/2022 22:49:19 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:49:21 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:49:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 22:49:23 - INFO - __main__ - Starting training!
06/01/2022 22:49:23 - INFO - __main__ - Loaded 2733 examples from test data
06/01/2022 22:49:53 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_100_0.0003_8_predictions.txt
06/01/2022 22:49:53 - INFO - __main__ - Classification-F1 on test data: 0.3133
06/01/2022 22:49:53 - INFO - __main__ - prefix=wiki_qa_64_100, lr=0.0003, bsz=8, dev_performance=0.5643294758339006, test_performance=0.31325154903640084
06/01/2022 22:49:53 - INFO - __main__ - Running ... prefix=wiki_qa_64_100, lr=0.0002, bsz=8 ...
06/01/2022 22:49:54 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 22:49:54 - INFO - __main__ - Printing 3 examples
06/01/2022 22:49:54 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/01/2022 22:49:54 - INFO - __main__ - ['false']
06/01/2022 22:49:54 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/01/2022 22:49:54 - INFO - __main__ - ['false']
06/01/2022 22:49:54 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/01/2022 22:49:54 - INFO - __main__ - ['false']
06/01/2022 22:49:54 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:49:54 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:49:54 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 22:49:54 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 22:49:54 - INFO - __main__ - Printing 3 examples
06/01/2022 22:49:54 - INFO - __main__ -  [wiki_qa] question: when did hitler kill himself [SEP] answer: In 2009, DNA tests were performed on a skull Soviet officials had long believed to be Hitler's.
06/01/2022 22:49:54 - INFO - __main__ - ['false']
06/01/2022 22:49:54 - INFO - __main__ -  [wiki_qa] question: what is muse's lead singer's name [SEP] answer: Muse are known for their energetic and extravagant live performances and their fusion of many music genres , including space rock , progressive rock , alternative rock , heavy metal , classical music and electronica .
06/01/2022 22:49:54 - INFO - __main__ - ['false']
06/01/2022 22:49:54 - INFO - __main__ -  [wiki_qa] question: who narrates the big lebowski [SEP] answer: The film is loosely inspired by the work of Raymond Chandler .
06/01/2022 22:49:54 - INFO - __main__ - ['false']
06/01/2022 22:49:54 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:49:54 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:49:54 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 22:50:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 22:50:05 - INFO - __main__ - Starting training!
06/01/2022 22:50:10 - INFO - __main__ - Step 10 Global step 10 Train loss 23.762808 on epoch=1
06/01/2022 22:50:15 - INFO - __main__ - Step 20 Global step 20 Train loss 19.283865 on epoch=2
06/01/2022 22:50:20 - INFO - __main__ - Step 30 Global step 30 Train loss 17.862463 on epoch=3
06/01/2022 22:50:25 - INFO - __main__ - Step 40 Global step 40 Train loss 16.629543 on epoch=4
06/01/2022 22:50:30 - INFO - __main__ - Step 50 Global step 50 Train loss 16.403688 on epoch=6
06/01/2022 22:50:48 - INFO - __main__ - Global step 50 Train loss 18.788475 Classification-F1 0.0 on epoch=6
06/01/2022 22:50:54 - INFO - __main__ - Step 60 Global step 60 Train loss 15.007385 on epoch=7
06/01/2022 22:50:59 - INFO - __main__ - Step 70 Global step 70 Train loss 14.736471 on epoch=8
06/01/2022 22:51:04 - INFO - __main__ - Step 80 Global step 80 Train loss 13.709562 on epoch=9
06/01/2022 22:51:09 - INFO - __main__ - Step 90 Global step 90 Train loss 12.521736 on epoch=11
06/01/2022 22:51:14 - INFO - __main__ - Step 100 Global step 100 Train loss 12.334177 on epoch=12
06/01/2022 22:51:18 - INFO - __main__ - Global step 100 Train loss 13.661866 Classification-F1 0.0 on epoch=12
06/01/2022 22:51:23 - INFO - __main__ - Step 110 Global step 110 Train loss 6.862470 on epoch=13
06/01/2022 22:51:28 - INFO - __main__ - Step 120 Global step 120 Train loss 1.339555 on epoch=14
06/01/2022 22:51:33 - INFO - __main__ - Step 130 Global step 130 Train loss 1.194821 on epoch=16
06/01/2022 22:51:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.756508 on epoch=17
06/01/2022 22:51:43 - INFO - __main__ - Step 150 Global step 150 Train loss 0.531998 on epoch=18
06/01/2022 22:51:44 - INFO - __main__ - Global step 150 Train loss 2.137071 Classification-F1 0.3333333333333333 on epoch=18
06/01/2022 22:51:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.636072 on epoch=19
06/01/2022 22:51:56 - INFO - __main__ - Step 170 Global step 170 Train loss 0.419695 on epoch=21
06/01/2022 22:52:01 - INFO - __main__ - Step 180 Global step 180 Train loss 0.619557 on epoch=22
06/01/2022 22:52:06 - INFO - __main__ - Step 190 Global step 190 Train loss 3.140695 on epoch=23
06/01/2022 22:52:11 - INFO - __main__ - Step 200 Global step 200 Train loss 0.478294 on epoch=24
06/01/2022 22:52:12 - INFO - __main__ - Global step 200 Train loss 1.058863 Classification-F1 0.350463149416029 on epoch=24
06/01/2022 22:52:18 - INFO - __main__ - Step 210 Global step 210 Train loss 0.449397 on epoch=26
06/01/2022 22:52:23 - INFO - __main__ - Step 220 Global step 220 Train loss 0.355735 on epoch=27
06/01/2022 22:52:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.349143 on epoch=28
06/01/2022 22:52:33 - INFO - __main__ - Step 240 Global step 240 Train loss 0.556600 on epoch=29
06/01/2022 22:52:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.384760 on epoch=31
06/01/2022 22:52:40 - INFO - __main__ - Global step 250 Train loss 0.419127 Classification-F1 0.5623931623931624 on epoch=31
06/01/2022 22:52:46 - INFO - __main__ - Step 260 Global step 260 Train loss 0.319490 on epoch=32
06/01/2022 22:52:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.403338 on epoch=33
06/01/2022 22:52:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.399134 on epoch=34
06/01/2022 22:53:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.445108 on epoch=36
06/01/2022 22:53:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.229108 on epoch=37
06/01/2022 22:53:08 - INFO - __main__ - Global step 300 Train loss 0.359236 Classification-F1 0.5744840996048421 on epoch=37
06/01/2022 22:53:14 - INFO - __main__ - Step 310 Global step 310 Train loss 0.353903 on epoch=38
06/01/2022 22:53:19 - INFO - __main__ - Step 320 Global step 320 Train loss 0.357394 on epoch=39
06/01/2022 22:53:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.269041 on epoch=41
06/01/2022 22:53:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.346088 on epoch=42
06/01/2022 22:53:34 - INFO - __main__ - Step 350 Global step 350 Train loss 0.279399 on epoch=43
06/01/2022 22:53:36 - INFO - __main__ - Global step 350 Train loss 0.321165 Classification-F1 0.5269402839914414 on epoch=43
06/01/2022 22:53:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.388844 on epoch=44
06/01/2022 22:53:46 - INFO - __main__ - Step 370 Global step 370 Train loss 0.272976 on epoch=46
06/01/2022 22:53:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.318473 on epoch=47
06/01/2022 22:53:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.254279 on epoch=48
06/01/2022 22:54:01 - INFO - __main__ - Step 400 Global step 400 Train loss 0.191810 on epoch=49
06/01/2022 22:54:03 - INFO - __main__ - Global step 400 Train loss 0.285276 Classification-F1 0.34702003235037954 on epoch=49
06/01/2022 22:54:08 - INFO - __main__ - Step 410 Global step 410 Train loss 0.232867 on epoch=51
06/01/2022 22:54:13 - INFO - __main__ - Step 420 Global step 420 Train loss 0.310783 on epoch=52
06/01/2022 22:54:18 - INFO - __main__ - Step 430 Global step 430 Train loss 0.357845 on epoch=53
06/01/2022 22:54:23 - INFO - __main__ - Step 440 Global step 440 Train loss 0.221690 on epoch=54
06/01/2022 22:54:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.209820 on epoch=56
06/01/2022 22:54:30 - INFO - __main__ - Global step 450 Train loss 0.266601 Classification-F1 0.5018141038327066 on epoch=56
06/01/2022 22:54:35 - INFO - __main__ - Step 460 Global step 460 Train loss 0.173161 on epoch=57
06/01/2022 22:54:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.077738 on epoch=58
06/01/2022 22:54:45 - INFO - __main__ - Step 480 Global step 480 Train loss 0.072785 on epoch=59
06/01/2022 22:54:50 - INFO - __main__ - Step 490 Global step 490 Train loss 0.207803 on epoch=61
06/01/2022 22:54:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.131492 on epoch=62
06/01/2022 22:54:57 - INFO - __main__ - Global step 500 Train loss 0.132596 Classification-F1 0.546875 on epoch=62
06/01/2022 22:55:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.149393 on epoch=63
06/01/2022 22:55:07 - INFO - __main__ - Step 520 Global step 520 Train loss 0.091833 on epoch=64
06/01/2022 22:55:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.073811 on epoch=66
06/01/2022 22:55:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.160846 on epoch=67
06/01/2022 22:55:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.273902 on epoch=68
06/01/2022 22:55:24 - INFO - __main__ - Global step 550 Train loss 0.149957 Classification-F1 0.5695158322228568 on epoch=68
06/01/2022 22:55:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.144132 on epoch=69
06/01/2022 22:55:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.188753 on epoch=71
06/01/2022 22:55:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.112523 on epoch=72
06/01/2022 22:55:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.058744 on epoch=73
06/01/2022 22:55:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.034849 on epoch=74
06/01/2022 22:55:50 - INFO - __main__ - Global step 600 Train loss 0.107800 Classification-F1 0.5440923605993613 on epoch=74
06/01/2022 22:55:55 - INFO - __main__ - Step 610 Global step 610 Train loss 0.042653 on epoch=76
06/01/2022 22:56:01 - INFO - __main__ - Step 620 Global step 620 Train loss 0.088923 on epoch=77
06/01/2022 22:56:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.024070 on epoch=78
06/01/2022 22:56:11 - INFO - __main__ - Step 640 Global step 640 Train loss 0.018597 on epoch=79
06/01/2022 22:56:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.021574 on epoch=81
06/01/2022 22:56:17 - INFO - __main__ - Global step 650 Train loss 0.039163 Classification-F1 0.5515515515515517 on epoch=81
06/01/2022 22:56:22 - INFO - __main__ - Step 660 Global step 660 Train loss 0.041141 on epoch=82
06/01/2022 22:56:27 - INFO - __main__ - Step 670 Global step 670 Train loss 0.029245 on epoch=83
06/01/2022 22:56:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.025033 on epoch=84
06/01/2022 22:56:37 - INFO - __main__ - Step 690 Global step 690 Train loss 0.014077 on epoch=86
06/01/2022 22:56:42 - INFO - __main__ - Step 700 Global step 700 Train loss 0.009722 on epoch=87
06/01/2022 22:56:44 - INFO - __main__ - Global step 700 Train loss 0.023844 Classification-F1 0.5210697417653193 on epoch=87
06/01/2022 22:56:49 - INFO - __main__ - Step 710 Global step 710 Train loss 0.019572 on epoch=88
06/01/2022 22:56:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.014644 on epoch=89
06/01/2022 22:56:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.010521 on epoch=91
06/01/2022 22:57:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.034836 on epoch=92
06/01/2022 22:57:10 - INFO - __main__ - Step 750 Global step 750 Train loss 0.039921 on epoch=93
06/01/2022 22:57:11 - INFO - __main__ - Global step 750 Train loss 0.023899 Classification-F1 0.5367723731828498 on epoch=93
06/01/2022 22:57:16 - INFO - __main__ - Step 760 Global step 760 Train loss 0.013259 on epoch=94
06/01/2022 22:57:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.008949 on epoch=96
06/01/2022 22:57:26 - INFO - __main__ - Step 780 Global step 780 Train loss 0.006337 on epoch=97
06/01/2022 22:57:31 - INFO - __main__ - Step 790 Global step 790 Train loss 0.018064 on epoch=98
06/01/2022 22:57:36 - INFO - __main__ - Step 800 Global step 800 Train loss 0.002806 on epoch=99
06/01/2022 22:57:38 - INFO - __main__ - Global step 800 Train loss 0.009883 Classification-F1 0.5696139476961395 on epoch=99
06/01/2022 22:57:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.002485 on epoch=101
06/01/2022 22:57:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.001842 on epoch=102
06/01/2022 22:57:53 - INFO - __main__ - Step 830 Global step 830 Train loss 0.025909 on epoch=103
06/01/2022 22:57:58 - INFO - __main__ - Step 840 Global step 840 Train loss 0.001899 on epoch=104
06/01/2022 22:58:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.001563 on epoch=106
06/01/2022 22:58:04 - INFO - __main__ - Global step 850 Train loss 0.006740 Classification-F1 0.5859122260880181 on epoch=106
06/01/2022 22:58:10 - INFO - __main__ - Step 860 Global step 860 Train loss 0.002204 on epoch=107
06/01/2022 22:58:15 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000947 on epoch=108
06/01/2022 22:58:20 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000533 on epoch=109
06/01/2022 22:58:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.014604 on epoch=111
06/01/2022 22:58:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.005022 on epoch=112
06/01/2022 22:58:32 - INFO - __main__ - Global step 900 Train loss 0.004662 Classification-F1 0.5995828988529719 on epoch=112
06/01/2022 22:58:38 - INFO - __main__ - Step 910 Global step 910 Train loss 0.003961 on epoch=113
06/01/2022 22:58:43 - INFO - __main__ - Step 920 Global step 920 Train loss 0.001069 on epoch=114
06/01/2022 22:58:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.004241 on epoch=116
06/01/2022 22:58:53 - INFO - __main__ - Step 940 Global step 940 Train loss 0.003719 on epoch=117
06/01/2022 22:58:58 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000308 on epoch=118
06/01/2022 22:59:00 - INFO - __main__ - Global step 950 Train loss 0.002660 Classification-F1 0.5730170496664195 on epoch=118
06/01/2022 22:59:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.001143 on epoch=119
06/01/2022 22:59:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000199 on epoch=121
06/01/2022 22:59:15 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000987 on epoch=122
06/01/2022 22:59:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.001683 on epoch=123
06/01/2022 22:59:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.003527 on epoch=124
06/01/2022 22:59:26 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 22:59:26 - INFO - __main__ - Printing 3 examples
06/01/2022 22:59:26 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/01/2022 22:59:26 - INFO - __main__ - ['false']
06/01/2022 22:59:26 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/01/2022 22:59:26 - INFO - __main__ - ['false']
06/01/2022 22:59:26 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/01/2022 22:59:26 - INFO - __main__ - ['false']
06/01/2022 22:59:26 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:59:26 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:59:27 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 22:59:27 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 22:59:27 - INFO - __main__ - Printing 3 examples
06/01/2022 22:59:27 - INFO - __main__ -  [wiki_qa] question: when did hitler kill himself [SEP] answer: In 2009, DNA tests were performed on a skull Soviet officials had long believed to be Hitler's.
06/01/2022 22:59:27 - INFO - __main__ - ['false']
06/01/2022 22:59:27 - INFO - __main__ -  [wiki_qa] question: what is muse's lead singer's name [SEP] answer: Muse are known for their energetic and extravagant live performances and their fusion of many music genres , including space rock , progressive rock , alternative rock , heavy metal , classical music and electronica .
06/01/2022 22:59:27 - INFO - __main__ - ['false']
06/01/2022 22:59:27 - INFO - __main__ -  [wiki_qa] question: who narrates the big lebowski [SEP] answer: The film is loosely inspired by the work of Raymond Chandler .
06/01/2022 22:59:27 - INFO - __main__ - ['false']
06/01/2022 22:59:27 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:59:27 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:59:27 - INFO - __main__ - Global step 1000 Train loss 0.001508 Classification-F1 0.5816219549799568 on epoch=124
06/01/2022 22:59:27 - INFO - __main__ - save last model!
06/01/2022 22:59:27 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 22:59:34 - INFO - __main__ - Loading checkpoint on the fly
06/01/2022 22:59:34 - INFO - __main__ - Start tokenizing ... 2733 instances
06/01/2022 22:59:34 - INFO - __main__ - Printing 3 examples
06/01/2022 22:59:34 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/01/2022 22:59:34 - INFO - __main__ - ['false']
06/01/2022 22:59:34 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/01/2022 22:59:34 - INFO - __main__ - ['false']
06/01/2022 22:59:34 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/01/2022 22:59:34 - INFO - __main__ - ['false']
06/01/2022 22:59:34 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:59:36 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:59:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 22:59:38 - INFO - __main__ - Starting training!
06/01/2022 22:59:38 - INFO - __main__ - Loaded 2733 examples from test data
06/01/2022 23:00:07 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_100_0.0002_8_predictions.txt
06/01/2022 23:00:07 - INFO - __main__ - Classification-F1 on test data: 0.4222
06/01/2022 23:00:08 - INFO - __main__ - prefix=wiki_qa_64_100, lr=0.0002, bsz=8, dev_performance=0.5995828988529719, test_performance=0.4222308872060028
06/01/2022 23:00:08 - INFO - __main__ - Running ... prefix=wiki_qa_64_100, lr=0.0001, bsz=8 ...
06/01/2022 23:00:09 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:00:09 - INFO - __main__ - Printing 3 examples
06/01/2022 23:00:09 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/01/2022 23:00:09 - INFO - __main__ - ['false']
06/01/2022 23:00:09 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/01/2022 23:00:09 - INFO - __main__ - ['false']
06/01/2022 23:00:09 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/01/2022 23:00:09 - INFO - __main__ - ['false']
06/01/2022 23:00:09 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:00:09 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:00:09 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 23:00:09 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:00:09 - INFO - __main__ - Printing 3 examples
06/01/2022 23:00:09 - INFO - __main__ -  [wiki_qa] question: when did hitler kill himself [SEP] answer: In 2009, DNA tests were performed on a skull Soviet officials had long believed to be Hitler's.
06/01/2022 23:00:09 - INFO - __main__ - ['false']
06/01/2022 23:00:09 - INFO - __main__ -  [wiki_qa] question: what is muse's lead singer's name [SEP] answer: Muse are known for their energetic and extravagant live performances and their fusion of many music genres , including space rock , progressive rock , alternative rock , heavy metal , classical music and electronica .
06/01/2022 23:00:09 - INFO - __main__ - ['false']
06/01/2022 23:00:09 - INFO - __main__ -  [wiki_qa] question: who narrates the big lebowski [SEP] answer: The film is loosely inspired by the work of Raymond Chandler .
06/01/2022 23:00:09 - INFO - __main__ - ['false']
06/01/2022 23:00:09 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:00:09 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:00:09 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 23:00:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 23:00:21 - INFO - __main__ - Starting training!
06/01/2022 23:00:25 - INFO - __main__ - Step 10 Global step 10 Train loss 23.054571 on epoch=1
06/01/2022 23:00:30 - INFO - __main__ - Step 20 Global step 20 Train loss 21.097612 on epoch=2
06/01/2022 23:00:35 - INFO - __main__ - Step 30 Global step 30 Train loss 19.039036 on epoch=3
06/01/2022 23:00:40 - INFO - __main__ - Step 40 Global step 40 Train loss 18.018091 on epoch=4
06/01/2022 23:00:45 - INFO - __main__ - Step 50 Global step 50 Train loss 17.319979 on epoch=6
06/01/2022 23:01:11 - INFO - __main__ - Global step 50 Train loss 19.705858 Classification-F1 0.0 on epoch=6
06/01/2022 23:01:18 - INFO - __main__ - Step 60 Global step 60 Train loss 17.038025 on epoch=7
06/01/2022 23:01:23 - INFO - __main__ - Step 70 Global step 70 Train loss 17.284161 on epoch=8
06/01/2022 23:01:28 - INFO - __main__ - Step 80 Global step 80 Train loss 16.389296 on epoch=9
06/01/2022 23:01:33 - INFO - __main__ - Step 90 Global step 90 Train loss 17.131571 on epoch=11
06/01/2022 23:01:38 - INFO - __main__ - Step 100 Global step 100 Train loss 15.631862 on epoch=12
06/01/2022 23:01:57 - INFO - __main__ - Global step 100 Train loss 16.694983 Classification-F1 0.0 on epoch=12
06/01/2022 23:02:03 - INFO - __main__ - Step 110 Global step 110 Train loss 14.888637 on epoch=13
06/01/2022 23:02:08 - INFO - __main__ - Step 120 Global step 120 Train loss 14.211902 on epoch=14
06/01/2022 23:02:13 - INFO - __main__ - Step 130 Global step 130 Train loss 14.348386 on epoch=16
06/01/2022 23:02:18 - INFO - __main__ - Step 140 Global step 140 Train loss 13.764341 on epoch=17
06/01/2022 23:02:23 - INFO - __main__ - Step 150 Global step 150 Train loss 13.769818 on epoch=18
06/01/2022 23:02:36 - INFO - __main__ - Global step 150 Train loss 14.196616 Classification-F1 0.0 on epoch=18
06/01/2022 23:02:41 - INFO - __main__ - Step 160 Global step 160 Train loss 13.191785 on epoch=19
06/01/2022 23:02:46 - INFO - __main__ - Step 170 Global step 170 Train loss 12.837786 on epoch=21
06/01/2022 23:02:51 - INFO - __main__ - Step 180 Global step 180 Train loss 12.028630 on epoch=22
06/01/2022 23:02:56 - INFO - __main__ - Step 190 Global step 190 Train loss 12.353747 on epoch=23
06/01/2022 23:03:02 - INFO - __main__ - Step 200 Global step 200 Train loss 11.085823 on epoch=24
06/01/2022 23:03:04 - INFO - __main__ - Global step 200 Train loss 12.299555 Classification-F1 0.0 on epoch=24
06/01/2022 23:03:09 - INFO - __main__ - Step 210 Global step 210 Train loss 9.088961 on epoch=26
06/01/2022 23:03:14 - INFO - __main__ - Step 220 Global step 220 Train loss 4.950709 on epoch=27
06/01/2022 23:03:19 - INFO - __main__ - Step 230 Global step 230 Train loss 1.365255 on epoch=28
06/01/2022 23:03:25 - INFO - __main__ - Step 240 Global step 240 Train loss 0.758791 on epoch=29
06/01/2022 23:03:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.660593 on epoch=31
06/01/2022 23:03:31 - INFO - __main__ - Global step 250 Train loss 3.364862 Classification-F1 0.3333333333333333 on epoch=31
06/01/2022 23:03:37 - INFO - __main__ - Step 260 Global step 260 Train loss 0.560485 on epoch=32
06/01/2022 23:03:42 - INFO - __main__ - Step 270 Global step 270 Train loss 1.067469 on epoch=33
06/01/2022 23:03:48 - INFO - __main__ - Step 280 Global step 280 Train loss 1.370653 on epoch=34
06/01/2022 23:03:53 - INFO - __main__ - Step 290 Global step 290 Train loss 3.356754 on epoch=36
06/01/2022 23:03:58 - INFO - __main__ - Step 300 Global step 300 Train loss 2.401590 on epoch=37
06/01/2022 23:03:59 - INFO - __main__ - Global step 300 Train loss 1.751390 Classification-F1 0.2654311980154677 on epoch=37
06/01/2022 23:04:04 - INFO - __main__ - Step 310 Global step 310 Train loss 1.322265 on epoch=38
06/01/2022 23:04:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.829012 on epoch=39
06/01/2022 23:04:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.547124 on epoch=41
06/01/2022 23:04:20 - INFO - __main__ - Step 340 Global step 340 Train loss 0.774630 on epoch=42
06/01/2022 23:04:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.591354 on epoch=43
06/01/2022 23:04:27 - INFO - __main__ - Global step 350 Train loss 0.812877 Classification-F1 0.45071982281284606 on epoch=43
06/01/2022 23:04:33 - INFO - __main__ - Step 360 Global step 360 Train loss 0.505534 on epoch=44
06/01/2022 23:04:38 - INFO - __main__ - Step 370 Global step 370 Train loss 0.551218 on epoch=46
06/01/2022 23:04:43 - INFO - __main__ - Step 380 Global step 380 Train loss 0.535879 on epoch=47
06/01/2022 23:04:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.565537 on epoch=48
06/01/2022 23:04:53 - INFO - __main__ - Step 400 Global step 400 Train loss 0.405423 on epoch=49
06/01/2022 23:04:55 - INFO - __main__ - Global step 400 Train loss 0.512718 Classification-F1 0.5625 on epoch=49
06/01/2022 23:05:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.447887 on epoch=51
06/01/2022 23:05:06 - INFO - __main__ - Step 420 Global step 420 Train loss 0.430992 on epoch=52
06/01/2022 23:05:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.380729 on epoch=53
06/01/2022 23:05:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.446180 on epoch=54
06/01/2022 23:05:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.444154 on epoch=56
06/01/2022 23:05:23 - INFO - __main__ - Global step 450 Train loss 0.429988 Classification-F1 0.5292881534016286 on epoch=56
06/01/2022 23:05:28 - INFO - __main__ - Step 460 Global step 460 Train loss 0.527182 on epoch=57
06/01/2022 23:05:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.361615 on epoch=58
06/01/2022 23:05:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.443772 on epoch=59
06/01/2022 23:05:43 - INFO - __main__ - Step 490 Global step 490 Train loss 0.405459 on epoch=61
06/01/2022 23:05:48 - INFO - __main__ - Step 500 Global step 500 Train loss 0.408198 on epoch=62
06/01/2022 23:05:50 - INFO - __main__ - Global step 500 Train loss 0.429245 Classification-F1 0.3333333333333333 on epoch=62
06/01/2022 23:05:55 - INFO - __main__ - Step 510 Global step 510 Train loss 0.447988 on epoch=63
06/01/2022 23:06:00 - INFO - __main__ - Step 520 Global step 520 Train loss 0.442864 on epoch=64
06/01/2022 23:06:05 - INFO - __main__ - Step 530 Global step 530 Train loss 0.412328 on epoch=66
06/01/2022 23:06:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.432026 on epoch=67
06/01/2022 23:06:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.445158 on epoch=68
06/01/2022 23:06:17 - INFO - __main__ - Global step 550 Train loss 0.436073 Classification-F1 0.497651675995625 on epoch=68
06/01/2022 23:06:22 - INFO - __main__ - Step 560 Global step 560 Train loss 0.411491 on epoch=69
06/01/2022 23:06:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.447003 on epoch=71
06/01/2022 23:06:32 - INFO - __main__ - Step 580 Global step 580 Train loss 0.447884 on epoch=72
06/01/2022 23:06:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.381483 on epoch=73
06/01/2022 23:06:42 - INFO - __main__ - Step 600 Global step 600 Train loss 0.387231 on epoch=74
06/01/2022 23:06:43 - INFO - __main__ - Global step 600 Train loss 0.415018 Classification-F1 0.4980392156862745 on epoch=74
06/01/2022 23:06:49 - INFO - __main__ - Step 610 Global step 610 Train loss 0.420462 on epoch=76
06/01/2022 23:06:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.393042 on epoch=77
06/01/2022 23:06:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.395057 on epoch=78
06/01/2022 23:07:04 - INFO - __main__ - Step 640 Global step 640 Train loss 0.371933 on epoch=79
06/01/2022 23:07:09 - INFO - __main__ - Step 650 Global step 650 Train loss 0.391847 on epoch=81
06/01/2022 23:07:10 - INFO - __main__ - Global step 650 Train loss 0.394468 Classification-F1 0.5103416974648253 on epoch=81
06/01/2022 23:07:15 - INFO - __main__ - Step 660 Global step 660 Train loss 0.398794 on epoch=82
06/01/2022 23:07:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.389502 on epoch=83
06/01/2022 23:07:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.417406 on epoch=84
06/01/2022 23:07:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.459047 on epoch=86
06/01/2022 23:07:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.388866 on epoch=87
06/01/2022 23:07:37 - INFO - __main__ - Global step 700 Train loss 0.410723 Classification-F1 0.3333333333333333 on epoch=87
06/01/2022 23:07:42 - INFO - __main__ - Step 710 Global step 710 Train loss 0.420263 on epoch=88
06/01/2022 23:07:48 - INFO - __main__ - Step 720 Global step 720 Train loss 0.404217 on epoch=89
06/01/2022 23:07:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.359323 on epoch=91
06/01/2022 23:07:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.384391 on epoch=92
06/01/2022 23:08:03 - INFO - __main__ - Step 750 Global step 750 Train loss 0.385962 on epoch=93
06/01/2022 23:08:04 - INFO - __main__ - Global step 750 Train loss 0.390831 Classification-F1 0.350463149416029 on epoch=93
06/01/2022 23:08:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.416087 on epoch=94
06/01/2022 23:08:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.423073 on epoch=96
06/01/2022 23:08:20 - INFO - __main__ - Step 780 Global step 780 Train loss 0.384692 on epoch=97
06/01/2022 23:08:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.371627 on epoch=98
06/01/2022 23:08:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.419683 on epoch=99
06/01/2022 23:08:31 - INFO - __main__ - Global step 800 Train loss 0.403033 Classification-F1 0.5383580903478208 on epoch=99
06/01/2022 23:08:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.381161 on epoch=101
06/01/2022 23:08:41 - INFO - __main__ - Step 820 Global step 820 Train loss 0.406393 on epoch=102
06/01/2022 23:08:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.406594 on epoch=103
06/01/2022 23:08:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.369864 on epoch=104
06/01/2022 23:08:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.351885 on epoch=106
06/01/2022 23:08:58 - INFO - __main__ - Global step 850 Train loss 0.383179 Classification-F1 0.3992490613266583 on epoch=106
06/01/2022 23:09:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.403783 on epoch=107
06/01/2022 23:09:09 - INFO - __main__ - Step 870 Global step 870 Train loss 0.374349 on epoch=108
06/01/2022 23:09:14 - INFO - __main__ - Step 880 Global step 880 Train loss 0.396605 on epoch=109
06/01/2022 23:09:19 - INFO - __main__ - Step 890 Global step 890 Train loss 0.422409 on epoch=111
06/01/2022 23:09:24 - INFO - __main__ - Step 900 Global step 900 Train loss 0.361123 on epoch=112
06/01/2022 23:09:25 - INFO - __main__ - Global step 900 Train loss 0.391654 Classification-F1 0.44379029997196523 on epoch=112
06/01/2022 23:09:30 - INFO - __main__ - Step 910 Global step 910 Train loss 0.362859 on epoch=113
06/01/2022 23:09:35 - INFO - __main__ - Step 920 Global step 920 Train loss 0.382179 on epoch=114
06/01/2022 23:09:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.355373 on epoch=116
06/01/2022 23:09:46 - INFO - __main__ - Step 940 Global step 940 Train loss 0.425790 on epoch=117
06/01/2022 23:09:51 - INFO - __main__ - Step 950 Global step 950 Train loss 0.399482 on epoch=118
06/01/2022 23:09:52 - INFO - __main__ - Global step 950 Train loss 0.385137 Classification-F1 0.42216142270861834 on epoch=118
06/01/2022 23:09:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.333599 on epoch=119
06/01/2022 23:10:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.379559 on epoch=121
06/01/2022 23:10:08 - INFO - __main__ - Step 980 Global step 980 Train loss 0.341303 on epoch=122
06/01/2022 23:10:13 - INFO - __main__ - Step 990 Global step 990 Train loss 0.401836 on epoch=123
06/01/2022 23:10:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.367506 on epoch=124
06/01/2022 23:10:19 - INFO - __main__ - Global step 1000 Train loss 0.364761 Classification-F1 0.5515515515515517 on epoch=124
06/01/2022 23:10:19 - INFO - __main__ - save last model!
06/01/2022 23:10:19 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:10:19 - INFO - __main__ - Printing 3 examples
06/01/2022 23:10:19 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/01/2022 23:10:19 - INFO - __main__ - ['false']
06/01/2022 23:10:19 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/01/2022 23:10:19 - INFO - __main__ - ['false']
06/01/2022 23:10:19 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/01/2022 23:10:19 - INFO - __main__ - ['false']
06/01/2022 23:10:19 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:10:19 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:10:19 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 23:10:19 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:10:19 - INFO - __main__ - Printing 3 examples
06/01/2022 23:10:19 - INFO - __main__ -  [wiki_qa] question: what is a HVAC company [SEP] answer: HVAC system design is a subdiscipline of mechanical engineering , based on the principles of thermodynamics , fluid mechanics , and heat transfer .
06/01/2022 23:10:19 - INFO - __main__ - ['false']
06/01/2022 23:10:19 - INFO - __main__ -  [wiki_qa] question: what is the biggest standard size for longboards? [SEP] answer: A kicktail cruiser
06/01/2022 23:10:19 - INFO - __main__ - ['false']
06/01/2022 23:10:19 - INFO - __main__ -  [wiki_qa] question: what animal is Mint in tokyo mew mew [SEP] answer: The manga series is followed by a short sequel series, Tokyo Mew Mew a la Mode, which introduces a new Mew Mew and a new threat.
06/01/2022 23:10:19 - INFO - __main__ - ['false']
06/01/2022 23:10:19 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:10:19 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:10:19 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 23:10:26 - INFO - __main__ - Loading checkpoint on the fly
06/01/2022 23:10:26 - INFO - __main__ - Start tokenizing ... 2733 instances
06/01/2022 23:10:26 - INFO - __main__ - Printing 3 examples
06/01/2022 23:10:26 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/01/2022 23:10:26 - INFO - __main__ - ['false']
06/01/2022 23:10:26 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/01/2022 23:10:26 - INFO - __main__ - ['false']
06/01/2022 23:10:26 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/01/2022 23:10:26 - INFO - __main__ - ['false']
06/01/2022 23:10:26 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:10:28 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:10:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 23:10:30 - INFO - __main__ - Starting training!
06/01/2022 23:10:30 - INFO - __main__ - Loaded 2733 examples from test data
06/01/2022 23:10:59 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_100_0.0001_8_predictions.txt
06/01/2022 23:10:59 - INFO - __main__ - Classification-F1 on test data: 0.3805
06/01/2022 23:11:00 - INFO - __main__ - prefix=wiki_qa_64_100, lr=0.0001, bsz=8, dev_performance=0.5625, test_performance=0.3805101598817645
06/01/2022 23:11:00 - INFO - __main__ - Running ... prefix=wiki_qa_64_13, lr=0.0005, bsz=8 ...
06/01/2022 23:11:01 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:11:01 - INFO - __main__ - Printing 3 examples
06/01/2022 23:11:01 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/01/2022 23:11:01 - INFO - __main__ - ['false']
06/01/2022 23:11:01 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/01/2022 23:11:01 - INFO - __main__ - ['false']
06/01/2022 23:11:01 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/01/2022 23:11:01 - INFO - __main__ - ['false']
06/01/2022 23:11:01 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:11:01 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:11:01 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 23:11:01 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:11:01 - INFO - __main__ - Printing 3 examples
06/01/2022 23:11:01 - INFO - __main__ -  [wiki_qa] question: what is a HVAC company [SEP] answer: HVAC system design is a subdiscipline of mechanical engineering , based on the principles of thermodynamics , fluid mechanics , and heat transfer .
06/01/2022 23:11:01 - INFO - __main__ - ['false']
06/01/2022 23:11:01 - INFO - __main__ -  [wiki_qa] question: what is the biggest standard size for longboards? [SEP] answer: A kicktail cruiser
06/01/2022 23:11:01 - INFO - __main__ - ['false']
06/01/2022 23:11:01 - INFO - __main__ -  [wiki_qa] question: what animal is Mint in tokyo mew mew [SEP] answer: The manga series is followed by a short sequel series, Tokyo Mew Mew a la Mode, which introduces a new Mew Mew and a new threat.
06/01/2022 23:11:01 - INFO - __main__ - ['false']
06/01/2022 23:11:01 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:11:01 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:11:01 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 23:11:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 23:11:13 - INFO - __main__ - Starting training!
06/01/2022 23:11:18 - INFO - __main__ - Step 10 Global step 10 Train loss 22.424252 on epoch=1
06/01/2022 23:11:23 - INFO - __main__ - Step 20 Global step 20 Train loss 18.992878 on epoch=2
06/01/2022 23:11:28 - INFO - __main__ - Step 30 Global step 30 Train loss 15.398180 on epoch=3
06/01/2022 23:11:33 - INFO - __main__ - Step 40 Global step 40 Train loss 13.902560 on epoch=4
06/01/2022 23:11:39 - INFO - __main__ - Step 50 Global step 50 Train loss 9.692450 on epoch=6
06/01/2022 23:12:26 - INFO - __main__ - Global step 50 Train loss 16.082064 Classification-F1 0.002564102564102564 on epoch=6
06/01/2022 23:12:32 - INFO - __main__ - Step 60 Global step 60 Train loss 6.824964 on epoch=7
06/01/2022 23:12:37 - INFO - __main__ - Step 70 Global step 70 Train loss 1.087275 on epoch=8
06/01/2022 23:12:42 - INFO - __main__ - Step 80 Global step 80 Train loss 0.542423 on epoch=9
06/01/2022 23:12:47 - INFO - __main__ - Step 90 Global step 90 Train loss 0.625621 on epoch=11
06/01/2022 23:12:53 - INFO - __main__ - Step 100 Global step 100 Train loss 0.544147 on epoch=12
06/01/2022 23:12:54 - INFO - __main__ - Global step 100 Train loss 1.924886 Classification-F1 0.3834004580273237 on epoch=12
06/01/2022 23:13:00 - INFO - __main__ - Step 110 Global step 110 Train loss 0.507579 on epoch=13
06/01/2022 23:13:06 - INFO - __main__ - Step 120 Global step 120 Train loss 0.462245 on epoch=14
06/01/2022 23:13:11 - INFO - __main__ - Step 130 Global step 130 Train loss 0.601745 on epoch=16
06/01/2022 23:13:16 - INFO - __main__ - Step 140 Global step 140 Train loss 0.615954 on epoch=17
06/01/2022 23:13:22 - INFO - __main__ - Step 150 Global step 150 Train loss 0.439173 on epoch=18
06/01/2022 23:13:23 - INFO - __main__ - Global step 150 Train loss 0.525339 Classification-F1 0.3333333333333333 on epoch=18
06/01/2022 23:13:28 - INFO - __main__ - Step 160 Global step 160 Train loss 0.480774 on epoch=19
06/01/2022 23:13:34 - INFO - __main__ - Step 170 Global step 170 Train loss 0.453528 on epoch=21
06/01/2022 23:13:39 - INFO - __main__ - Step 180 Global step 180 Train loss 0.423407 on epoch=22
06/01/2022 23:13:44 - INFO - __main__ - Step 190 Global step 190 Train loss 0.476912 on epoch=23
06/01/2022 23:13:49 - INFO - __main__ - Step 200 Global step 200 Train loss 0.414793 on epoch=24
06/01/2022 23:13:51 - INFO - __main__ - Global step 200 Train loss 0.449883 Classification-F1 0.36318407960199 on epoch=24
06/01/2022 23:13:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.449918 on epoch=26
06/01/2022 23:14:01 - INFO - __main__ - Step 220 Global step 220 Train loss 0.381957 on epoch=27
06/01/2022 23:14:07 - INFO - __main__ - Step 230 Global step 230 Train loss 0.440426 on epoch=28
06/01/2022 23:14:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.448279 on epoch=29
06/01/2022 23:14:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.421028 on epoch=31
06/01/2022 23:14:19 - INFO - __main__ - Global step 250 Train loss 0.428322 Classification-F1 0.3333333333333333 on epoch=31
06/01/2022 23:14:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.465457 on epoch=32
06/01/2022 23:14:29 - INFO - __main__ - Step 270 Global step 270 Train loss 0.390692 on epoch=33
06/01/2022 23:14:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.450631 on epoch=34
06/01/2022 23:14:40 - INFO - __main__ - Step 290 Global step 290 Train loss 0.359631 on epoch=36
06/01/2022 23:14:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.425752 on epoch=37
06/01/2022 23:14:47 - INFO - __main__ - Global step 300 Train loss 0.418433 Classification-F1 0.5762668703845175 on epoch=37
06/01/2022 23:14:53 - INFO - __main__ - Step 310 Global step 310 Train loss 0.385267 on epoch=38
06/01/2022 23:14:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.346837 on epoch=39
06/01/2022 23:15:04 - INFO - __main__ - Step 330 Global step 330 Train loss 0.397099 on epoch=41
06/01/2022 23:15:09 - INFO - __main__ - Step 340 Global step 340 Train loss 0.375172 on epoch=42
06/01/2022 23:15:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.373284 on epoch=43
06/01/2022 23:15:15 - INFO - __main__ - Global step 350 Train loss 0.375532 Classification-F1 0.3591989987484355 on epoch=43
06/01/2022 23:15:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.346096 on epoch=44
06/01/2022 23:15:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.322966 on epoch=46
06/01/2022 23:15:31 - INFO - __main__ - Step 380 Global step 380 Train loss 0.306254 on epoch=47
06/01/2022 23:15:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.356233 on epoch=48
06/01/2022 23:15:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.302168 on epoch=49
06/01/2022 23:15:43 - INFO - __main__ - Global step 400 Train loss 0.326743 Classification-F1 0.55 on epoch=49
06/01/2022 23:15:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.307397 on epoch=51
06/01/2022 23:15:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.274154 on epoch=52
06/01/2022 23:15:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.185239 on epoch=53
06/01/2022 23:16:04 - INFO - __main__ - Step 440 Global step 440 Train loss 0.236834 on epoch=54
06/01/2022 23:16:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.296928 on epoch=56
06/01/2022 23:16:10 - INFO - __main__ - Global step 450 Train loss 0.260110 Classification-F1 0.5762668703845175 on epoch=56
06/01/2022 23:16:16 - INFO - __main__ - Step 460 Global step 460 Train loss 0.217579 on epoch=57
06/01/2022 23:16:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.199347 on epoch=58
06/01/2022 23:16:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.138519 on epoch=59
06/01/2022 23:16:32 - INFO - __main__ - Step 490 Global step 490 Train loss 0.361034 on epoch=61
06/01/2022 23:16:37 - INFO - __main__ - Step 500 Global step 500 Train loss 0.407840 on epoch=62
06/01/2022 23:16:39 - INFO - __main__ - Global step 500 Train loss 0.264864 Classification-F1 0.42840679919331603 on epoch=62
06/01/2022 23:16:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.214044 on epoch=63
06/01/2022 23:16:50 - INFO - __main__ - Step 520 Global step 520 Train loss 0.245974 on epoch=64
06/01/2022 23:16:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.228879 on epoch=66
06/01/2022 23:17:00 - INFO - __main__ - Step 540 Global step 540 Train loss 0.073288 on epoch=67
06/01/2022 23:17:06 - INFO - __main__ - Step 550 Global step 550 Train loss 0.101345 on epoch=68
06/01/2022 23:17:07 - INFO - __main__ - Global step 550 Train loss 0.172706 Classification-F1 0.5273745861981156 on epoch=68
06/01/2022 23:17:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.143166 on epoch=69
06/01/2022 23:17:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.060830 on epoch=71
06/01/2022 23:17:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.058817 on epoch=72
06/01/2022 23:17:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.013920 on epoch=73
06/01/2022 23:17:34 - INFO - __main__ - Step 600 Global step 600 Train loss 0.012265 on epoch=74
06/01/2022 23:17:35 - INFO - __main__ - Global step 600 Train loss 0.057800 Classification-F1 0.5993612264452252 on epoch=74
06/01/2022 23:17:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.017281 on epoch=76
06/01/2022 23:17:47 - INFO - __main__ - Step 620 Global step 620 Train loss 0.018024 on epoch=77
06/01/2022 23:17:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.016424 on epoch=78
06/01/2022 23:17:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.002919 on epoch=79
06/01/2022 23:18:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.010004 on epoch=81
06/01/2022 23:18:04 - INFO - __main__ - Global step 650 Train loss 0.012930 Classification-F1 0.32880082880082884 on epoch=81
06/01/2022 23:18:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.003590 on epoch=82
06/01/2022 23:18:14 - INFO - __main__ - Step 670 Global step 670 Train loss 0.011549 on epoch=83
06/01/2022 23:18:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.002761 on epoch=84
06/01/2022 23:18:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.002363 on epoch=86
06/01/2022 23:18:30 - INFO - __main__ - Step 700 Global step 700 Train loss 0.018672 on epoch=87
06/01/2022 23:18:32 - INFO - __main__ - Global step 700 Train loss 0.007787 Classification-F1 0.5696139476961395 on epoch=87
06/01/2022 23:18:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.002450 on epoch=88
06/01/2022 23:18:42 - INFO - __main__ - Step 720 Global step 720 Train loss 0.011200 on epoch=89
06/01/2022 23:18:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.009696 on epoch=91
06/01/2022 23:18:53 - INFO - __main__ - Step 740 Global step 740 Train loss 0.006475 on epoch=92
06/01/2022 23:18:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.001310 on epoch=93
06/01/2022 23:19:00 - INFO - __main__ - Global step 750 Train loss 0.006226 Classification-F1 0.3598536244397845 on epoch=93
06/01/2022 23:19:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.010228 on epoch=94
06/01/2022 23:19:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.001266 on epoch=96
06/01/2022 23:19:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.002893 on epoch=97
06/01/2022 23:19:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.007115 on epoch=98
06/01/2022 23:19:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.006983 on epoch=99
06/01/2022 23:19:28 - INFO - __main__ - Global step 800 Train loss 0.005697 Classification-F1 0.5436720142602496 on epoch=99
06/01/2022 23:19:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.002714 on epoch=101
06/01/2022 23:19:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000943 on epoch=102
06/01/2022 23:19:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.022260 on epoch=103
06/01/2022 23:19:49 - INFO - __main__ - Step 840 Global step 840 Train loss 0.002497 on epoch=104
06/01/2022 23:19:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000729 on epoch=106
06/01/2022 23:19:56 - INFO - __main__ - Global step 850 Train loss 0.005829 Classification-F1 0.5303643724696356 on epoch=106
06/01/2022 23:20:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.001129 on epoch=107
06/01/2022 23:20:06 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000353 on epoch=108
06/01/2022 23:20:11 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000047 on epoch=109
06/01/2022 23:20:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000204 on epoch=111
06/01/2022 23:20:22 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000129 on epoch=112
06/01/2022 23:20:23 - INFO - __main__ - Global step 900 Train loss 0.000372 Classification-F1 0.5413886829750433 on epoch=112
06/01/2022 23:20:29 - INFO - __main__ - Step 910 Global step 910 Train loss 0.060052 on epoch=113
06/01/2022 23:20:34 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000307 on epoch=114
06/01/2022 23:20:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000258 on epoch=116
06/01/2022 23:20:45 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000439 on epoch=117
06/01/2022 23:20:50 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000644 on epoch=118
06/01/2022 23:20:51 - INFO - __main__ - Global step 950 Train loss 0.012340 Classification-F1 0.5294117647058825 on epoch=118
06/01/2022 23:20:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000039 on epoch=119
06/01/2022 23:21:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000479 on epoch=121
06/01/2022 23:21:07 - INFO - __main__ - Step 980 Global step 980 Train loss 0.005113 on epoch=122
06/01/2022 23:21:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.001254 on epoch=123
06/01/2022 23:21:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000648 on epoch=124
06/01/2022 23:21:18 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:21:18 - INFO - __main__ - Printing 3 examples
06/01/2022 23:21:18 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/01/2022 23:21:18 - INFO - __main__ - ['false']
06/01/2022 23:21:18 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/01/2022 23:21:18 - INFO - __main__ - ['false']
06/01/2022 23:21:18 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/01/2022 23:21:18 - INFO - __main__ - ['false']
06/01/2022 23:21:18 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:21:19 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:21:19 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 23:21:19 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:21:19 - INFO - __main__ - Printing 3 examples
06/01/2022 23:21:19 - INFO - __main__ -  [wiki_qa] question: what is a HVAC company [SEP] answer: HVAC system design is a subdiscipline of mechanical engineering , based on the principles of thermodynamics , fluid mechanics , and heat transfer .
06/01/2022 23:21:19 - INFO - __main__ - ['false']
06/01/2022 23:21:19 - INFO - __main__ -  [wiki_qa] question: what is the biggest standard size for longboards? [SEP] answer: A kicktail cruiser
06/01/2022 23:21:19 - INFO - __main__ - ['false']
06/01/2022 23:21:19 - INFO - __main__ -  [wiki_qa] question: what animal is Mint in tokyo mew mew [SEP] answer: The manga series is followed by a short sequel series, Tokyo Mew Mew a la Mode, which introduces a new Mew Mew and a new threat.
06/01/2022 23:21:19 - INFO - __main__ - ['false']
06/01/2022 23:21:19 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:21:19 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:21:19 - INFO - __main__ - Global step 1000 Train loss 0.001507 Classification-F1 0.5702862723554905 on epoch=124
06/01/2022 23:21:19 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 23:21:19 - INFO - __main__ - save last model!
06/01/2022 23:21:26 - INFO - __main__ - Loading checkpoint on the fly
06/01/2022 23:21:27 - INFO - __main__ - Start tokenizing ... 2733 instances
06/01/2022 23:21:27 - INFO - __main__ - Printing 3 examples
06/01/2022 23:21:27 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/01/2022 23:21:27 - INFO - __main__ - ['false']
06/01/2022 23:21:27 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/01/2022 23:21:27 - INFO - __main__ - ['false']
06/01/2022 23:21:27 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/01/2022 23:21:27 - INFO - __main__ - ['false']
06/01/2022 23:21:27 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:21:28 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:21:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 23:21:30 - INFO - __main__ - Starting training!
06/01/2022 23:21:31 - INFO - __main__ - Loaded 2733 examples from test data
06/01/2022 23:22:27 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_13_0.0005_8_predictions.txt
06/01/2022 23:22:27 - INFO - __main__ - Classification-F1 on test data: 0.0269
06/01/2022 23:22:28 - INFO - __main__ - prefix=wiki_qa_64_13, lr=0.0005, bsz=8, dev_performance=0.5993612264452252, test_performance=0.026930063567740324
06/01/2022 23:22:28 - INFO - __main__ - Running ... prefix=wiki_qa_64_13, lr=0.0003, bsz=8 ...
06/01/2022 23:22:29 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:22:29 - INFO - __main__ - Printing 3 examples
06/01/2022 23:22:29 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/01/2022 23:22:29 - INFO - __main__ - ['false']
06/01/2022 23:22:29 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/01/2022 23:22:29 - INFO - __main__ - ['false']
06/01/2022 23:22:29 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/01/2022 23:22:29 - INFO - __main__ - ['false']
06/01/2022 23:22:29 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:22:29 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:22:29 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 23:22:29 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:22:29 - INFO - __main__ - Printing 3 examples
06/01/2022 23:22:29 - INFO - __main__ -  [wiki_qa] question: what is a HVAC company [SEP] answer: HVAC system design is a subdiscipline of mechanical engineering , based on the principles of thermodynamics , fluid mechanics , and heat transfer .
06/01/2022 23:22:29 - INFO - __main__ - ['false']
06/01/2022 23:22:29 - INFO - __main__ -  [wiki_qa] question: what is the biggest standard size for longboards? [SEP] answer: A kicktail cruiser
06/01/2022 23:22:29 - INFO - __main__ - ['false']
06/01/2022 23:22:29 - INFO - __main__ -  [wiki_qa] question: what animal is Mint in tokyo mew mew [SEP] answer: The manga series is followed by a short sequel series, Tokyo Mew Mew a la Mode, which introduces a new Mew Mew and a new threat.
06/01/2022 23:22:29 - INFO - __main__ - ['false']
06/01/2022 23:22:29 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:22:29 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:22:29 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 23:22:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 23:22:42 - INFO - __main__ - Starting training!
06/01/2022 23:22:46 - INFO - __main__ - Step 10 Global step 10 Train loss 23.359756 on epoch=1
06/01/2022 23:22:51 - INFO - __main__ - Step 20 Global step 20 Train loss 18.647663 on epoch=2
06/01/2022 23:22:57 - INFO - __main__ - Step 30 Global step 30 Train loss 17.151402 on epoch=3
06/01/2022 23:23:02 - INFO - __main__ - Step 40 Global step 40 Train loss 15.567624 on epoch=4
06/01/2022 23:23:07 - INFO - __main__ - Step 50 Global step 50 Train loss 14.245679 on epoch=6
06/01/2022 23:23:27 - INFO - __main__ - Global step 50 Train loss 17.794426 Classification-F1 0.0 on epoch=6
06/01/2022 23:23:33 - INFO - __main__ - Step 60 Global step 60 Train loss 14.053622 on epoch=7
06/01/2022 23:23:38 - INFO - __main__ - Step 70 Global step 70 Train loss 12.632257 on epoch=8
06/01/2022 23:23:44 - INFO - __main__ - Step 80 Global step 80 Train loss 6.243373 on epoch=9
06/01/2022 23:23:49 - INFO - __main__ - Step 90 Global step 90 Train loss 0.723544 on epoch=11
06/01/2022 23:23:54 - INFO - __main__ - Step 100 Global step 100 Train loss 0.516181 on epoch=12
06/01/2022 23:23:56 - INFO - __main__ - Global step 100 Train loss 6.833796 Classification-F1 0.2222222222222222 on epoch=12
06/01/2022 23:24:02 - INFO - __main__ - Step 110 Global step 110 Train loss 0.728722 on epoch=13
06/01/2022 23:24:07 - INFO - __main__ - Step 120 Global step 120 Train loss 0.488573 on epoch=14
06/01/2022 23:24:12 - INFO - __main__ - Step 130 Global step 130 Train loss 0.439367 on epoch=16
06/01/2022 23:24:17 - INFO - __main__ - Step 140 Global step 140 Train loss 0.535818 on epoch=17
06/01/2022 23:24:23 - INFO - __main__ - Step 150 Global step 150 Train loss 0.387346 on epoch=18
06/01/2022 23:24:24 - INFO - __main__ - Global step 150 Train loss 0.515965 Classification-F1 0.3674603174603175 on epoch=18
06/01/2022 23:24:30 - INFO - __main__ - Step 160 Global step 160 Train loss 0.301925 on epoch=19
06/01/2022 23:24:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.238104 on epoch=21
06/01/2022 23:24:41 - INFO - __main__ - Step 180 Global step 180 Train loss 0.232701 on epoch=22
06/01/2022 23:24:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.173088 on epoch=23
06/01/2022 23:24:51 - INFO - __main__ - Step 200 Global step 200 Train loss 0.159007 on epoch=24
06/01/2022 23:24:53 - INFO - __main__ - Global step 200 Train loss 0.220965 Classification-F1 0.7184750733137829 on epoch=24
06/01/2022 23:24:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.161242 on epoch=26
06/01/2022 23:25:04 - INFO - __main__ - Step 220 Global step 220 Train loss 0.122623 on epoch=27
06/01/2022 23:25:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.102925 on epoch=28
06/01/2022 23:25:14 - INFO - __main__ - Step 240 Global step 240 Train loss 0.034149 on epoch=29
06/01/2022 23:25:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.025557 on epoch=31
06/01/2022 23:25:21 - INFO - __main__ - Global step 250 Train loss 0.089299 Classification-F1 0.715344699777613 on epoch=31
06/01/2022 23:25:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.020379 on epoch=32
06/01/2022 23:25:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.022865 on epoch=33
06/01/2022 23:25:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.027648 on epoch=34
06/01/2022 23:25:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.014442 on epoch=36
06/01/2022 23:25:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.003476 on epoch=37
06/01/2022 23:25:48 - INFO - __main__ - Global step 300 Train loss 0.017762 Classification-F1 0.6910699919549477 on epoch=37
06/01/2022 23:25:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.005878 on epoch=38
06/01/2022 23:25:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.001980 on epoch=39
06/01/2022 23:26:04 - INFO - __main__ - Step 330 Global step 330 Train loss 0.002367 on epoch=41
06/01/2022 23:26:09 - INFO - __main__ - Step 340 Global step 340 Train loss 0.002375 on epoch=42
06/01/2022 23:26:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.006262 on epoch=43
06/01/2022 23:26:16 - INFO - __main__ - Global step 350 Train loss 0.003772 Classification-F1 0.6636636636636637 on epoch=43
06/01/2022 23:26:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.016918 on epoch=44
06/01/2022 23:26:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.002942 on epoch=46
06/01/2022 23:26:31 - INFO - __main__ - Step 380 Global step 380 Train loss 0.001285 on epoch=47
06/01/2022 23:26:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.003294 on epoch=48
06/01/2022 23:26:42 - INFO - __main__ - Step 400 Global step 400 Train loss 0.014221 on epoch=49
06/01/2022 23:26:43 - INFO - __main__ - Global step 400 Train loss 0.007732 Classification-F1 0.5758218451749735 on epoch=49
06/01/2022 23:26:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.006938 on epoch=51
06/01/2022 23:26:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.014615 on epoch=52
06/01/2022 23:26:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.006004 on epoch=53
06/01/2022 23:27:04 - INFO - __main__ - Step 440 Global step 440 Train loss 0.001548 on epoch=54
06/01/2022 23:27:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.001075 on epoch=56
06/01/2022 23:27:10 - INFO - __main__ - Global step 450 Train loss 0.006036 Classification-F1 0.6708273223358213 on epoch=56
06/01/2022 23:27:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.001127 on epoch=57
06/01/2022 23:27:20 - INFO - __main__ - Step 470 Global step 470 Train loss 0.000569 on epoch=58
06/01/2022 23:27:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.000668 on epoch=59
06/01/2022 23:27:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.005933 on epoch=61
06/01/2022 23:27:36 - INFO - __main__ - Step 500 Global step 500 Train loss 0.000407 on epoch=62
06/01/2022 23:27:37 - INFO - __main__ - Global step 500 Train loss 0.001741 Classification-F1 0.619736502195815 on epoch=62
06/01/2022 23:27:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.000943 on epoch=63
06/01/2022 23:27:48 - INFO - __main__ - Step 520 Global step 520 Train loss 0.001117 on epoch=64
06/01/2022 23:27:53 - INFO - __main__ - Step 530 Global step 530 Train loss 0.000577 on epoch=66
06/01/2022 23:27:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.000887 on epoch=67
06/01/2022 23:28:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.000682 on epoch=68
06/01/2022 23:28:05 - INFO - __main__ - Global step 550 Train loss 0.000841 Classification-F1 0.6740514387573211 on epoch=68
06/01/2022 23:28:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.000131 on epoch=69
06/01/2022 23:28:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.000168 on epoch=71
06/01/2022 23:28:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.000254 on epoch=72
06/01/2022 23:28:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.003408 on epoch=73
06/01/2022 23:28:31 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000151 on epoch=74
06/01/2022 23:28:32 - INFO - __main__ - Global step 600 Train loss 0.000822 Classification-F1 0.6796796796796798 on epoch=74
06/01/2022 23:28:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.000024 on epoch=76
06/01/2022 23:28:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.000645 on epoch=77
06/01/2022 23:28:47 - INFO - __main__ - Step 630 Global step 630 Train loss 0.033670 on epoch=78
06/01/2022 23:28:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.000615 on epoch=79
06/01/2022 23:28:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000357 on epoch=81
06/01/2022 23:28:59 - INFO - __main__ - Global step 650 Train loss 0.007062 Classification-F1 0.6561660561660563 on epoch=81
06/01/2022 23:29:04 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000449 on epoch=82
06/01/2022 23:29:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.000784 on epoch=83
06/01/2022 23:29:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000336 on epoch=84
06/01/2022 23:29:20 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000086 on epoch=86
06/01/2022 23:29:25 - INFO - __main__ - Step 700 Global step 700 Train loss 0.011287 on epoch=87
06/01/2022 23:29:27 - INFO - __main__ - Global step 700 Train loss 0.002588 Classification-F1 0.6367076631977294 on epoch=87
06/01/2022 23:29:32 - INFO - __main__ - Step 710 Global step 710 Train loss 0.001334 on epoch=88
06/01/2022 23:29:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000715 on epoch=89
06/01/2022 23:29:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.017453 on epoch=91
06/01/2022 23:29:47 - INFO - __main__ - Step 740 Global step 740 Train loss 0.003245 on epoch=92
06/01/2022 23:29:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.001789 on epoch=93
06/01/2022 23:29:54 - INFO - __main__ - Global step 750 Train loss 0.004907 Classification-F1 0.43468822516655437 on epoch=93
06/01/2022 23:29:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.004543 on epoch=94
06/01/2022 23:30:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.006137 on epoch=96
06/01/2022 23:30:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000092 on epoch=97
06/01/2022 23:30:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000101 on epoch=98
06/01/2022 23:30:20 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000164 on epoch=99
06/01/2022 23:30:21 - INFO - __main__ - Global step 800 Train loss 0.002208 Classification-F1 0.6930455635491606 on epoch=99
06/01/2022 23:30:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000235 on epoch=101
06/01/2022 23:30:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000305 on epoch=102
06/01/2022 23:30:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000048 on epoch=103
06/01/2022 23:30:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000035 on epoch=104
06/01/2022 23:30:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000126 on epoch=106
06/01/2022 23:30:49 - INFO - __main__ - Global step 850 Train loss 0.000150 Classification-F1 0.7004926108374384 on epoch=106
06/01/2022 23:30:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000364 on epoch=107
06/01/2022 23:30:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000035 on epoch=108
06/01/2022 23:31:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000078 on epoch=109
06/01/2022 23:31:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000051 on epoch=111
06/01/2022 23:31:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000028 on epoch=112
06/01/2022 23:31:17 - INFO - __main__ - Global step 900 Train loss 0.000111 Classification-F1 0.6884478562067029 on epoch=112
06/01/2022 23:31:22 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000071 on epoch=113
06/01/2022 23:31:27 - INFO - __main__ - Step 920 Global step 920 Train loss 0.001528 on epoch=114
06/01/2022 23:31:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000167 on epoch=116
06/01/2022 23:31:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000308 on epoch=117
06/01/2022 23:31:43 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000045 on epoch=118
06/01/2022 23:31:44 - INFO - __main__ - Global step 950 Train loss 0.000424 Classification-F1 0.6779874213836479 on epoch=118
06/01/2022 23:31:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000052 on epoch=119
06/01/2022 23:31:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000075 on epoch=121
06/01/2022 23:32:00 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000062 on epoch=122
06/01/2022 23:32:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000025 on epoch=123
06/01/2022 23:32:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000037 on epoch=124
06/01/2022 23:32:11 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:32:11 - INFO - __main__ - Printing 3 examples
06/01/2022 23:32:11 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/01/2022 23:32:11 - INFO - __main__ - ['false']
06/01/2022 23:32:11 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/01/2022 23:32:11 - INFO - __main__ - ['false']
06/01/2022 23:32:11 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/01/2022 23:32:11 - INFO - __main__ - ['false']
06/01/2022 23:32:11 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:32:11 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:32:12 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 23:32:12 - INFO - __main__ - Global step 1000 Train loss 0.000050 Classification-F1 0.6773043103978356 on epoch=124
06/01/2022 23:32:12 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:32:12 - INFO - __main__ - Printing 3 examples
06/01/2022 23:32:12 - INFO - __main__ -  [wiki_qa] question: what is a HVAC company [SEP] answer: HVAC system design is a subdiscipline of mechanical engineering , based on the principles of thermodynamics , fluid mechanics , and heat transfer .
06/01/2022 23:32:12 - INFO - __main__ - ['false']
06/01/2022 23:32:12 - INFO - __main__ -  [wiki_qa] question: what is the biggest standard size for longboards? [SEP] answer: A kicktail cruiser
06/01/2022 23:32:12 - INFO - __main__ - ['false']
06/01/2022 23:32:12 - INFO - __main__ -  [wiki_qa] question: what animal is Mint in tokyo mew mew [SEP] answer: The manga series is followed by a short sequel series, Tokyo Mew Mew a la Mode, which introduces a new Mew Mew and a new threat.
06/01/2022 23:32:12 - INFO - __main__ - ['false']
06/01/2022 23:32:12 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:32:12 - INFO - __main__ - save last model!
06/01/2022 23:32:12 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:32:12 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 23:32:19 - INFO - __main__ - Loading checkpoint on the fly
06/01/2022 23:32:19 - INFO - __main__ - Start tokenizing ... 2733 instances
06/01/2022 23:32:19 - INFO - __main__ - Printing 3 examples
06/01/2022 23:32:19 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/01/2022 23:32:19 - INFO - __main__ - ['false']
06/01/2022 23:32:19 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/01/2022 23:32:19 - INFO - __main__ - ['false']
06/01/2022 23:32:19 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/01/2022 23:32:19 - INFO - __main__ - ['false']
06/01/2022 23:32:19 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:32:21 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:32:23 - INFO - __main__ - Loaded 2733 examples from test data
06/01/2022 23:32:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 23:32:25 - INFO - __main__ - Starting training!
06/01/2022 23:32:52 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_13_0.0003_8_predictions.txt
06/01/2022 23:32:52 - INFO - __main__ - Classification-F1 on test data: 0.4848
06/01/2022 23:32:53 - INFO - __main__ - prefix=wiki_qa_64_13, lr=0.0003, bsz=8, dev_performance=0.7184750733137829, test_performance=0.4848131332394221
06/01/2022 23:32:53 - INFO - __main__ - Running ... prefix=wiki_qa_64_13, lr=0.0002, bsz=8 ...
06/01/2022 23:32:54 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:32:54 - INFO - __main__ - Printing 3 examples
06/01/2022 23:32:54 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/01/2022 23:32:54 - INFO - __main__ - ['false']
06/01/2022 23:32:54 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/01/2022 23:32:54 - INFO - __main__ - ['false']
06/01/2022 23:32:54 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/01/2022 23:32:54 - INFO - __main__ - ['false']
06/01/2022 23:32:54 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:32:54 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:32:54 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 23:32:54 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:32:54 - INFO - __main__ - Printing 3 examples
06/01/2022 23:32:54 - INFO - __main__ -  [wiki_qa] question: what is a HVAC company [SEP] answer: HVAC system design is a subdiscipline of mechanical engineering , based on the principles of thermodynamics , fluid mechanics , and heat transfer .
06/01/2022 23:32:54 - INFO - __main__ - ['false']
06/01/2022 23:32:54 - INFO - __main__ -  [wiki_qa] question: what is the biggest standard size for longboards? [SEP] answer: A kicktail cruiser
06/01/2022 23:32:54 - INFO - __main__ - ['false']
06/01/2022 23:32:54 - INFO - __main__ -  [wiki_qa] question: what animal is Mint in tokyo mew mew [SEP] answer: The manga series is followed by a short sequel series, Tokyo Mew Mew a la Mode, which introduces a new Mew Mew and a new threat.
06/01/2022 23:32:54 - INFO - __main__ - ['false']
06/01/2022 23:32:54 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:32:54 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:32:54 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 23:33:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 23:33:06 - INFO - __main__ - Starting training!
06/01/2022 23:33:11 - INFO - __main__ - Step 10 Global step 10 Train loss 23.042473 on epoch=1
06/01/2022 23:33:16 - INFO - __main__ - Step 20 Global step 20 Train loss 19.023544 on epoch=2
06/01/2022 23:33:21 - INFO - __main__ - Step 30 Global step 30 Train loss 16.310635 on epoch=3
06/01/2022 23:33:26 - INFO - __main__ - Step 40 Global step 40 Train loss 16.323706 on epoch=4
06/01/2022 23:33:32 - INFO - __main__ - Step 50 Global step 50 Train loss 15.080648 on epoch=6
06/01/2022 23:33:47 - INFO - __main__ - Global step 50 Train loss 17.956202 Classification-F1 0.0 on epoch=6
06/01/2022 23:33:52 - INFO - __main__ - Step 60 Global step 60 Train loss 15.111300 on epoch=7
06/01/2022 23:33:58 - INFO - __main__ - Step 70 Global step 70 Train loss 13.883615 on epoch=8
06/01/2022 23:34:03 - INFO - __main__ - Step 80 Global step 80 Train loss 13.393283 on epoch=9
06/01/2022 23:34:08 - INFO - __main__ - Step 90 Global step 90 Train loss 13.112378 on epoch=11
06/01/2022 23:34:14 - INFO - __main__ - Step 100 Global step 100 Train loss 8.932573 on epoch=12
06/01/2022 23:34:15 - INFO - __main__ - Global step 100 Train loss 12.886630 Classification-F1 0.24596273291925466 on epoch=12
06/01/2022 23:34:21 - INFO - __main__ - Step 110 Global step 110 Train loss 0.960889 on epoch=13
06/01/2022 23:34:26 - INFO - __main__ - Step 120 Global step 120 Train loss 0.501503 on epoch=14
06/01/2022 23:34:32 - INFO - __main__ - Step 130 Global step 130 Train loss 0.576623 on epoch=16
06/01/2022 23:34:37 - INFO - __main__ - Step 140 Global step 140 Train loss 0.537462 on epoch=17
06/01/2022 23:34:42 - INFO - __main__ - Step 150 Global step 150 Train loss 0.582849 on epoch=18
06/01/2022 23:34:43 - INFO - __main__ - Global step 150 Train loss 0.631865 Classification-F1 0.31758890898131403 on epoch=18
06/01/2022 23:34:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.388803 on epoch=19
06/01/2022 23:34:55 - INFO - __main__ - Step 170 Global step 170 Train loss 0.480861 on epoch=21
06/01/2022 23:35:00 - INFO - __main__ - Step 180 Global step 180 Train loss 0.391165 on epoch=22
06/01/2022 23:35:05 - INFO - __main__ - Step 190 Global step 190 Train loss 0.332558 on epoch=23
06/01/2022 23:35:10 - INFO - __main__ - Step 200 Global step 200 Train loss 0.323508 on epoch=24
06/01/2022 23:35:12 - INFO - __main__ - Global step 200 Train loss 0.383379 Classification-F1 0.4625414364640884 on epoch=24
06/01/2022 23:35:18 - INFO - __main__ - Step 210 Global step 210 Train loss 0.300555 on epoch=26
06/01/2022 23:35:23 - INFO - __main__ - Step 220 Global step 220 Train loss 0.188459 on epoch=27
06/01/2022 23:35:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.181176 on epoch=28
06/01/2022 23:35:33 - INFO - __main__ - Step 240 Global step 240 Train loss 0.264894 on epoch=29
06/01/2022 23:35:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.196084 on epoch=31
06/01/2022 23:35:40 - INFO - __main__ - Global step 250 Train loss 0.226234 Classification-F1 0.703125 on epoch=31
06/01/2022 23:35:46 - INFO - __main__ - Step 260 Global step 260 Train loss 0.187242 on epoch=32
06/01/2022 23:35:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.098010 on epoch=33
06/01/2022 23:35:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.164281 on epoch=34
06/01/2022 23:36:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.312030 on epoch=36
06/01/2022 23:36:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.347748 on epoch=37
06/01/2022 23:36:07 - INFO - __main__ - Global step 300 Train loss 0.221862 Classification-F1 0.6362696977525187 on epoch=37
06/01/2022 23:36:12 - INFO - __main__ - Step 310 Global step 310 Train loss 0.301539 on epoch=38
06/01/2022 23:36:17 - INFO - __main__ - Step 320 Global step 320 Train loss 0.334773 on epoch=39
06/01/2022 23:36:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.357545 on epoch=41
06/01/2022 23:36:28 - INFO - __main__ - Step 340 Global step 340 Train loss 0.344084 on epoch=42
06/01/2022 23:36:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.400831 on epoch=43
06/01/2022 23:36:34 - INFO - __main__ - Global step 350 Train loss 0.347754 Classification-F1 0.4487674487674488 on epoch=43
06/01/2022 23:36:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.390413 on epoch=44
06/01/2022 23:36:45 - INFO - __main__ - Step 370 Global step 370 Train loss 0.421946 on epoch=46
06/01/2022 23:36:50 - INFO - __main__ - Step 380 Global step 380 Train loss 0.253146 on epoch=47
06/01/2022 23:36:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.165254 on epoch=48
06/01/2022 23:37:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.231374 on epoch=49
06/01/2022 23:37:02 - INFO - __main__ - Global step 400 Train loss 0.292426 Classification-F1 0.5038759689922481 on epoch=49
06/01/2022 23:37:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.252296 on epoch=51
06/01/2022 23:37:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.264643 on epoch=52
06/01/2022 23:37:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.136119 on epoch=53
06/01/2022 23:37:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.242525 on epoch=54
06/01/2022 23:37:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.354786 on epoch=56
06/01/2022 23:37:29 - INFO - __main__ - Global step 450 Train loss 0.250074 Classification-F1 0.5470629865534324 on epoch=56
06/01/2022 23:37:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.353657 on epoch=57
06/01/2022 23:37:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.312490 on epoch=58
06/01/2022 23:37:45 - INFO - __main__ - Step 480 Global step 480 Train loss 0.287988 on epoch=59
06/01/2022 23:37:50 - INFO - __main__ - Step 490 Global step 490 Train loss 0.346978 on epoch=61
06/01/2022 23:37:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.330770 on epoch=62
06/01/2022 23:37:56 - INFO - __main__ - Global step 500 Train loss 0.326377 Classification-F1 0.45705196182396607 on epoch=62
06/01/2022 23:38:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.316512 on epoch=63
06/01/2022 23:38:07 - INFO - __main__ - Step 520 Global step 520 Train loss 0.370232 on epoch=64
06/01/2022 23:38:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.411526 on epoch=66
06/01/2022 23:38:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.372162 on epoch=67
06/01/2022 23:38:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.360240 on epoch=68
06/01/2022 23:38:24 - INFO - __main__ - Global step 550 Train loss 0.366134 Classification-F1 0.48529100529100533 on epoch=68
06/01/2022 23:38:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.391684 on epoch=69
06/01/2022 23:38:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.295754 on epoch=71
06/01/2022 23:38:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.328476 on epoch=72
06/01/2022 23:38:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.295217 on epoch=73
06/01/2022 23:38:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.314054 on epoch=74
06/01/2022 23:38:51 - INFO - __main__ - Global step 600 Train loss 0.325037 Classification-F1 0.578125 on epoch=74
06/01/2022 23:38:56 - INFO - __main__ - Step 610 Global step 610 Train loss 0.304538 on epoch=76
06/01/2022 23:39:01 - INFO - __main__ - Step 620 Global step 620 Train loss 0.341763 on epoch=77
06/01/2022 23:39:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.358513 on epoch=78
06/01/2022 23:39:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.359782 on epoch=79
06/01/2022 23:39:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.372752 on epoch=81
06/01/2022 23:39:18 - INFO - __main__ - Global step 650 Train loss 0.347470 Classification-F1 0.5700763358778627 on epoch=81
06/01/2022 23:39:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.456833 on epoch=82
06/01/2022 23:39:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.363366 on epoch=83
06/01/2022 23:39:34 - INFO - __main__ - Step 680 Global step 680 Train loss 0.373168 on epoch=84
06/01/2022 23:39:39 - INFO - __main__ - Step 690 Global step 690 Train loss 0.277417 on epoch=86
06/01/2022 23:39:44 - INFO - __main__ - Step 700 Global step 700 Train loss 0.241291 on epoch=87
06/01/2022 23:39:45 - INFO - __main__ - Global step 700 Train loss 0.342415 Classification-F1 0.5564563582870219 on epoch=87
06/01/2022 23:39:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.300705 on epoch=88
06/01/2022 23:39:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.324812 on epoch=89
06/01/2022 23:40:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.314207 on epoch=91
06/01/2022 23:40:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.181099 on epoch=92
06/01/2022 23:40:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.224568 on epoch=93
06/01/2022 23:40:13 - INFO - __main__ - Global step 750 Train loss 0.269078 Classification-F1 0.5156518747850017 on epoch=93
06/01/2022 23:40:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.208384 on epoch=94
06/01/2022 23:40:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.155628 on epoch=96
06/01/2022 23:40:29 - INFO - __main__ - Step 780 Global step 780 Train loss 0.227111 on epoch=97
06/01/2022 23:40:34 - INFO - __main__ - Step 790 Global step 790 Train loss 0.210099 on epoch=98
06/01/2022 23:40:39 - INFO - __main__ - Step 800 Global step 800 Train loss 0.307569 on epoch=99
06/01/2022 23:40:41 - INFO - __main__ - Global step 800 Train loss 0.221758 Classification-F1 0.5764705882352941 on epoch=99
06/01/2022 23:40:46 - INFO - __main__ - Step 810 Global step 810 Train loss 0.283202 on epoch=101
06/01/2022 23:40:51 - INFO - __main__ - Step 820 Global step 820 Train loss 0.249091 on epoch=102
06/01/2022 23:40:56 - INFO - __main__ - Step 830 Global step 830 Train loss 0.253714 on epoch=103
06/01/2022 23:41:02 - INFO - __main__ - Step 840 Global step 840 Train loss 0.213814 on epoch=104
06/01/2022 23:41:07 - INFO - __main__ - Step 850 Global step 850 Train loss 0.244754 on epoch=106
06/01/2022 23:41:08 - INFO - __main__ - Global step 850 Train loss 0.248915 Classification-F1 0.5532711466463609 on epoch=106
06/01/2022 23:41:13 - INFO - __main__ - Step 860 Global step 860 Train loss 0.250038 on epoch=107
06/01/2022 23:41:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.277069 on epoch=108
06/01/2022 23:41:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.302687 on epoch=109
06/01/2022 23:41:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.149673 on epoch=111
06/01/2022 23:41:34 - INFO - __main__ - Step 900 Global step 900 Train loss 0.249098 on epoch=112
06/01/2022 23:41:35 - INFO - __main__ - Global step 900 Train loss 0.245713 Classification-F1 0.554442748091603 on epoch=112
06/01/2022 23:41:41 - INFO - __main__ - Step 910 Global step 910 Train loss 0.229650 on epoch=113
06/01/2022 23:41:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.258181 on epoch=114
06/01/2022 23:41:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.218178 on epoch=116
06/01/2022 23:41:56 - INFO - __main__ - Step 940 Global step 940 Train loss 0.204901 on epoch=117
06/01/2022 23:42:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.233874 on epoch=118
06/01/2022 23:42:03 - INFO - __main__ - Global step 950 Train loss 0.228957 Classification-F1 0.5390343648904352 on epoch=118
06/01/2022 23:42:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.347677 on epoch=119
06/01/2022 23:42:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.258217 on epoch=121
06/01/2022 23:42:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.157518 on epoch=122
06/01/2022 23:42:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.203453 on epoch=123
06/01/2022 23:42:29 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.289344 on epoch=124
06/01/2022 23:42:30 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:42:30 - INFO - __main__ - Printing 3 examples
06/01/2022 23:42:30 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/01/2022 23:42:30 - INFO - __main__ - ['false']
06/01/2022 23:42:30 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/01/2022 23:42:30 - INFO - __main__ - ['false']
06/01/2022 23:42:30 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/01/2022 23:42:30 - INFO - __main__ - ['false']
06/01/2022 23:42:30 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:42:30 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:42:30 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 23:42:30 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:42:30 - INFO - __main__ - Printing 3 examples
06/01/2022 23:42:30 - INFO - __main__ -  [wiki_qa] question: what is a HVAC company [SEP] answer: HVAC system design is a subdiscipline of mechanical engineering , based on the principles of thermodynamics , fluid mechanics , and heat transfer .
06/01/2022 23:42:30 - INFO - __main__ - ['false']
06/01/2022 23:42:30 - INFO - __main__ -  [wiki_qa] question: what is the biggest standard size for longboards? [SEP] answer: A kicktail cruiser
06/01/2022 23:42:30 - INFO - __main__ - ['false']
06/01/2022 23:42:30 - INFO - __main__ -  [wiki_qa] question: what animal is Mint in tokyo mew mew [SEP] answer: The manga series is followed by a short sequel series, Tokyo Mew Mew a la Mode, which introduces a new Mew Mew and a new threat.
06/01/2022 23:42:30 - INFO - __main__ - ['false']
06/01/2022 23:42:30 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:42:30 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:42:30 - INFO - __main__ - Global step 1000 Train loss 0.251242 Classification-F1 0.5302177636408123 on epoch=124
06/01/2022 23:42:30 - INFO - __main__ - save last model!
06/01/2022 23:42:30 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 23:42:37 - INFO - __main__ - Loading checkpoint on the fly
06/01/2022 23:42:38 - INFO - __main__ - Start tokenizing ... 2733 instances
06/01/2022 23:42:38 - INFO - __main__ - Printing 3 examples
06/01/2022 23:42:38 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/01/2022 23:42:38 - INFO - __main__ - ['false']
06/01/2022 23:42:38 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/01/2022 23:42:38 - INFO - __main__ - ['false']
06/01/2022 23:42:38 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/01/2022 23:42:38 - INFO - __main__ - ['false']
06/01/2022 23:42:38 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:42:39 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:42:42 - INFO - __main__ - Loaded 2733 examples from test data
06/01/2022 23:42:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 23:42:43 - INFO - __main__ - Starting training!
06/01/2022 23:43:11 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_13_0.0002_8_predictions.txt
06/01/2022 23:43:12 - INFO - __main__ - Classification-F1 on test data: 0.4534
06/01/2022 23:43:12 - INFO - __main__ - prefix=wiki_qa_64_13, lr=0.0002, bsz=8, dev_performance=0.703125, test_performance=0.45340646617119507
06/01/2022 23:43:12 - INFO - __main__ - Running ... prefix=wiki_qa_64_13, lr=0.0001, bsz=8 ...
06/01/2022 23:43:13 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:43:13 - INFO - __main__ - Printing 3 examples
06/01/2022 23:43:13 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/01/2022 23:43:13 - INFO - __main__ - ['false']
06/01/2022 23:43:13 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/01/2022 23:43:13 - INFO - __main__ - ['false']
06/01/2022 23:43:13 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/01/2022 23:43:13 - INFO - __main__ - ['false']
06/01/2022 23:43:13 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:43:13 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:43:13 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 23:43:13 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:43:13 - INFO - __main__ - Printing 3 examples
06/01/2022 23:43:13 - INFO - __main__ -  [wiki_qa] question: what is a HVAC company [SEP] answer: HVAC system design is a subdiscipline of mechanical engineering , based on the principles of thermodynamics , fluid mechanics , and heat transfer .
06/01/2022 23:43:13 - INFO - __main__ - ['false']
06/01/2022 23:43:13 - INFO - __main__ -  [wiki_qa] question: what is the biggest standard size for longboards? [SEP] answer: A kicktail cruiser
06/01/2022 23:43:13 - INFO - __main__ - ['false']
06/01/2022 23:43:13 - INFO - __main__ -  [wiki_qa] question: what animal is Mint in tokyo mew mew [SEP] answer: The manga series is followed by a short sequel series, Tokyo Mew Mew a la Mode, which introduces a new Mew Mew and a new threat.
06/01/2022 23:43:13 - INFO - __main__ - ['false']
06/01/2022 23:43:13 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:43:13 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:43:13 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 23:43:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 23:43:26 - INFO - __main__ - Starting training!
06/01/2022 23:43:30 - INFO - __main__ - Step 10 Global step 10 Train loss 24.215481 on epoch=1
06/01/2022 23:43:35 - INFO - __main__ - Step 20 Global step 20 Train loss 19.403366 on epoch=2
06/01/2022 23:43:40 - INFO - __main__ - Step 30 Global step 30 Train loss 19.595924 on epoch=3
06/01/2022 23:43:46 - INFO - __main__ - Step 40 Global step 40 Train loss 17.552731 on epoch=4
06/01/2022 23:43:51 - INFO - __main__ - Step 50 Global step 50 Train loss 17.729069 on epoch=6
06/01/2022 23:44:17 - INFO - __main__ - Global step 50 Train loss 19.699314 Classification-F1 0.0 on epoch=6
06/01/2022 23:44:24 - INFO - __main__ - Step 60 Global step 60 Train loss 16.654970 on epoch=7
06/01/2022 23:44:29 - INFO - __main__ - Step 70 Global step 70 Train loss 16.487740 on epoch=8
06/01/2022 23:44:35 - INFO - __main__ - Step 80 Global step 80 Train loss 16.315378 on epoch=9
06/01/2022 23:44:40 - INFO - __main__ - Step 90 Global step 90 Train loss 15.314405 on epoch=11
06/01/2022 23:44:45 - INFO - __main__ - Step 100 Global step 100 Train loss 15.484390 on epoch=12
06/01/2022 23:45:08 - INFO - __main__ - Global step 100 Train loss 16.051376 Classification-F1 0.0 on epoch=12
06/01/2022 23:45:13 - INFO - __main__ - Step 110 Global step 110 Train loss 14.852681 on epoch=13
06/01/2022 23:45:18 - INFO - __main__ - Step 120 Global step 120 Train loss 14.235486 on epoch=14
06/01/2022 23:45:23 - INFO - __main__ - Step 130 Global step 130 Train loss 14.340411 on epoch=16
06/01/2022 23:45:28 - INFO - __main__ - Step 140 Global step 140 Train loss 13.397403 on epoch=17
06/01/2022 23:45:34 - INFO - __main__ - Step 150 Global step 150 Train loss 12.785621 on epoch=18
06/01/2022 23:45:50 - INFO - __main__ - Global step 150 Train loss 13.922320 Classification-F1 0.0 on epoch=18
06/01/2022 23:45:56 - INFO - __main__ - Step 160 Global step 160 Train loss 12.813286 on epoch=19
06/01/2022 23:46:01 - INFO - __main__ - Step 170 Global step 170 Train loss 12.552265 on epoch=21
06/01/2022 23:46:06 - INFO - __main__ - Step 180 Global step 180 Train loss 9.885887 on epoch=22
06/01/2022 23:46:11 - INFO - __main__ - Step 190 Global step 190 Train loss 7.344049 on epoch=23
06/01/2022 23:46:16 - INFO - __main__ - Step 200 Global step 200 Train loss 1.803279 on epoch=24
06/01/2022 23:46:17 - INFO - __main__ - Global step 200 Train loss 8.879753 Classification-F1 0.3333333333333333 on epoch=24
06/01/2022 23:46:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.620807 on epoch=26
06/01/2022 23:46:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.605373 on epoch=27
06/01/2022 23:46:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.619054 on epoch=28
06/01/2022 23:46:39 - INFO - __main__ - Step 240 Global step 240 Train loss 0.520295 on epoch=29
06/01/2022 23:46:44 - INFO - __main__ - Step 250 Global step 250 Train loss 0.443631 on epoch=31
06/01/2022 23:46:45 - INFO - __main__ - Global step 250 Train loss 0.561832 Classification-F1 0.350463149416029 on epoch=31
06/01/2022 23:46:52 - INFO - __main__ - Step 260 Global step 260 Train loss 0.459448 on epoch=32
06/01/2022 23:46:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.450739 on epoch=33
06/01/2022 23:47:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.429986 on epoch=34
06/01/2022 23:47:07 - INFO - __main__ - Step 290 Global step 290 Train loss 0.410324 on epoch=36
06/01/2022 23:47:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.565086 on epoch=37
06/01/2022 23:47:14 - INFO - __main__ - Global step 300 Train loss 0.463116 Classification-F1 0.6698599852616065 on epoch=37
06/01/2022 23:47:20 - INFO - __main__ - Step 310 Global step 310 Train loss 0.461404 on epoch=38
06/01/2022 23:47:25 - INFO - __main__ - Step 320 Global step 320 Train loss 0.350130 on epoch=39
06/01/2022 23:47:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.318444 on epoch=41
06/01/2022 23:47:35 - INFO - __main__ - Step 340 Global step 340 Train loss 0.350558 on epoch=42
06/01/2022 23:47:40 - INFO - __main__ - Step 350 Global step 350 Train loss 0.410463 on epoch=43
06/01/2022 23:47:42 - INFO - __main__ - Global step 350 Train loss 0.378200 Classification-F1 0.3671451355661882 on epoch=43
06/01/2022 23:47:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.328722 on epoch=44
06/01/2022 23:47:52 - INFO - __main__ - Step 370 Global step 370 Train loss 0.351646 on epoch=46
06/01/2022 23:47:57 - INFO - __main__ - Step 380 Global step 380 Train loss 0.305727 on epoch=47
06/01/2022 23:48:02 - INFO - __main__ - Step 390 Global step 390 Train loss 0.343487 on epoch=48
06/01/2022 23:48:07 - INFO - __main__ - Step 400 Global step 400 Train loss 0.374973 on epoch=49
06/01/2022 23:48:09 - INFO - __main__ - Global step 400 Train loss 0.340911 Classification-F1 0.6871945259042034 on epoch=49
06/01/2022 23:48:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.289714 on epoch=51
06/01/2022 23:48:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.279410 on epoch=52
06/01/2022 23:48:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.296066 on epoch=53
06/01/2022 23:48:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.258807 on epoch=54
06/01/2022 23:48:36 - INFO - __main__ - Step 450 Global step 450 Train loss 0.268564 on epoch=56
06/01/2022 23:48:37 - INFO - __main__ - Global step 450 Train loss 0.278512 Classification-F1 0.6414565826330533 on epoch=56
06/01/2022 23:48:42 - INFO - __main__ - Step 460 Global step 460 Train loss 0.208059 on epoch=57
06/01/2022 23:48:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.249435 on epoch=58
06/01/2022 23:48:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.276832 on epoch=59
06/01/2022 23:48:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.209890 on epoch=61
06/01/2022 23:49:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.197117 on epoch=62
06/01/2022 23:49:05 - INFO - __main__ - Global step 500 Train loss 0.228266 Classification-F1 0.6752274274398169 on epoch=62
06/01/2022 23:49:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.218307 on epoch=63
06/01/2022 23:49:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.212735 on epoch=64
06/01/2022 23:49:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.115798 on epoch=66
06/01/2022 23:49:25 - INFO - __main__ - Step 540 Global step 540 Train loss 0.166510 on epoch=67
06/01/2022 23:49:30 - INFO - __main__ - Step 550 Global step 550 Train loss 0.158598 on epoch=68
06/01/2022 23:49:32 - INFO - __main__ - Global step 550 Train loss 0.174390 Classification-F1 0.6952969182268545 on epoch=68
06/01/2022 23:49:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.116290 on epoch=69
06/01/2022 23:49:43 - INFO - __main__ - Step 570 Global step 570 Train loss 0.108005 on epoch=71
06/01/2022 23:49:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.090353 on epoch=72
06/01/2022 23:49:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.069913 on epoch=73
06/01/2022 23:49:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.101478 on epoch=74
06/01/2022 23:50:00 - INFO - __main__ - Global step 600 Train loss 0.097208 Classification-F1 0.6190476190476191 on epoch=74
06/01/2022 23:50:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.087538 on epoch=76
06/01/2022 23:50:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.063720 on epoch=77
06/01/2022 23:50:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.026647 on epoch=78
06/01/2022 23:50:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.080921 on epoch=79
06/01/2022 23:50:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.038033 on epoch=81
06/01/2022 23:50:27 - INFO - __main__ - Global step 650 Train loss 0.059372 Classification-F1 0.7499389499389499 on epoch=81
06/01/2022 23:50:33 - INFO - __main__ - Step 660 Global step 660 Train loss 0.025366 on epoch=82
06/01/2022 23:50:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.034723 on epoch=83
06/01/2022 23:50:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.037681 on epoch=84
06/01/2022 23:50:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.006360 on epoch=86
06/01/2022 23:50:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.030409 on epoch=87
06/01/2022 23:50:55 - INFO - __main__ - Global step 700 Train loss 0.026908 Classification-F1 0.7311588831233012 on epoch=87
06/01/2022 23:51:00 - INFO - __main__ - Step 710 Global step 710 Train loss 0.048659 on epoch=88
06/01/2022 23:51:05 - INFO - __main__ - Step 720 Global step 720 Train loss 0.063384 on epoch=89
06/01/2022 23:51:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.026467 on epoch=91
06/01/2022 23:51:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.053118 on epoch=92
06/01/2022 23:51:21 - INFO - __main__ - Step 750 Global step 750 Train loss 0.036038 on epoch=93
06/01/2022 23:51:22 - INFO - __main__ - Global step 750 Train loss 0.045533 Classification-F1 0.6082432156702713 on epoch=93
06/01/2022 23:51:27 - INFO - __main__ - Step 760 Global step 760 Train loss 0.030004 on epoch=94
06/01/2022 23:51:33 - INFO - __main__ - Step 770 Global step 770 Train loss 0.018632 on epoch=96
06/01/2022 23:51:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.021806 on epoch=97
06/01/2022 23:51:43 - INFO - __main__ - Step 790 Global step 790 Train loss 0.003914 on epoch=98
06/01/2022 23:51:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.009803 on epoch=99
06/01/2022 23:51:50 - INFO - __main__ - Global step 800 Train loss 0.016832 Classification-F1 0.6717948717948719 on epoch=99
06/01/2022 23:51:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.013784 on epoch=101
06/01/2022 23:52:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.005040 on epoch=102
06/01/2022 23:52:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.003809 on epoch=103
06/01/2022 23:52:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.008059 on epoch=104
06/01/2022 23:52:16 - INFO - __main__ - Step 850 Global step 850 Train loss 0.007424 on epoch=106
06/01/2022 23:52:17 - INFO - __main__ - Global step 850 Train loss 0.007623 Classification-F1 0.6736188296829029 on epoch=106
06/01/2022 23:52:22 - INFO - __main__ - Step 860 Global step 860 Train loss 0.004968 on epoch=107
06/01/2022 23:52:27 - INFO - __main__ - Step 870 Global step 870 Train loss 0.011697 on epoch=108
06/01/2022 23:52:33 - INFO - __main__ - Step 880 Global step 880 Train loss 0.007148 on epoch=109
06/01/2022 23:52:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.012242 on epoch=111
06/01/2022 23:52:43 - INFO - __main__ - Step 900 Global step 900 Train loss 0.011455 on epoch=112
06/01/2022 23:52:45 - INFO - __main__ - Global step 900 Train loss 0.009502 Classification-F1 0.6037151702786377 on epoch=112
06/01/2022 23:52:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.009597 on epoch=113
06/01/2022 23:52:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.024126 on epoch=114
06/01/2022 23:53:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.005044 on epoch=116
06/01/2022 23:53:05 - INFO - __main__ - Step 940 Global step 940 Train loss 0.005914 on epoch=117
06/01/2022 23:53:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.005245 on epoch=118
06/01/2022 23:53:12 - INFO - __main__ - Global step 950 Train loss 0.009985 Classification-F1 0.6740514387573211 on epoch=118
06/01/2022 23:53:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.007709 on epoch=119
06/01/2022 23:53:22 - INFO - __main__ - Step 970 Global step 970 Train loss 0.012697 on epoch=121
06/01/2022 23:53:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.003581 on epoch=122
06/01/2022 23:53:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.001294 on epoch=123
06/01/2022 23:53:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.002010 on epoch=124
06/01/2022 23:53:39 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:53:39 - INFO - __main__ - Printing 3 examples
06/01/2022 23:53:39 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/01/2022 23:53:39 - INFO - __main__ - ['false']
06/01/2022 23:53:39 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/01/2022 23:53:39 - INFO - __main__ - ['false']
06/01/2022 23:53:39 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/01/2022 23:53:39 - INFO - __main__ - ['false']
06/01/2022 23:53:39 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:53:39 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:53:39 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 23:53:39 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:53:39 - INFO - __main__ - Printing 3 examples
06/01/2022 23:53:39 - INFO - __main__ -  [wiki_qa] question: what happened to original pink power rangers [SEP] answer: Under the original name, "Mighty Morphin Power Rangers" the series ran from 1993 to 1995 and spawned the feature film Mighty Morphin Power Rangers: The Movie .
06/01/2022 23:53:39 - INFO - __main__ - ['false']
06/01/2022 23:53:39 - INFO - __main__ -  [wiki_qa] question: where do cruises dock in new york city [SEP] answer: The Normandie, renamed USS Lafayette, lies capsized in the frozen mud at Pier 88 in the winter of 1942
06/01/2022 23:53:39 - INFO - __main__ - ['false']
06/01/2022 23:53:39 - INFO - __main__ -  [wiki_qa] question: who plays ethan in my babysitter's a vampire [SEP] answer: The series follows the three as they take on supernatural forces and have adventures, with occasional help from fellow vampires Rory ( Cameron Kennedy ) and Erica ( Kate Todd ), while dealing with the troubles of regular high school life.
06/01/2022 23:53:39 - INFO - __main__ - ['false']
06/01/2022 23:53:39 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:53:39 - INFO - __main__ - Global step 1000 Train loss 0.005458 Classification-F1 0.7204019222367847 on epoch=124
06/01/2022 23:53:39 - INFO - __main__ - save last model!
06/01/2022 23:53:39 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:53:39 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 23:53:46 - INFO - __main__ - Loading checkpoint on the fly
06/01/2022 23:53:47 - INFO - __main__ - Start tokenizing ... 2733 instances
06/01/2022 23:53:47 - INFO - __main__ - Printing 3 examples
06/01/2022 23:53:47 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/01/2022 23:53:47 - INFO - __main__ - ['false']
06/01/2022 23:53:47 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/01/2022 23:53:47 - INFO - __main__ - ['false']
06/01/2022 23:53:47 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/01/2022 23:53:47 - INFO - __main__ - ['false']
06/01/2022 23:53:47 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:53:48 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:53:51 - INFO - __main__ - Loaded 2733 examples from test data
06/01/2022 23:53:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 23:53:52 - INFO - __main__ - Starting training!
06/01/2022 23:54:20 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_13_0.0001_8_predictions.txt
06/01/2022 23:54:20 - INFO - __main__ - Classification-F1 on test data: 0.5174
06/01/2022 23:54:20 - INFO - __main__ - prefix=wiki_qa_64_13, lr=0.0001, bsz=8, dev_performance=0.7499389499389499, test_performance=0.5174082164965618
06/01/2022 23:54:20 - INFO - __main__ - Running ... prefix=wiki_qa_64_21, lr=0.0005, bsz=8 ...
06/01/2022 23:54:21 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:54:21 - INFO - __main__ - Printing 3 examples
06/01/2022 23:54:21 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/01/2022 23:54:21 - INFO - __main__ - ['false']
06/01/2022 23:54:21 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/01/2022 23:54:21 - INFO - __main__ - ['false']
06/01/2022 23:54:21 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/01/2022 23:54:21 - INFO - __main__ - ['false']
06/01/2022 23:54:21 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:54:21 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:54:21 - INFO - __main__ - Loaded 128 examples from train data
06/01/2022 23:54:21 - INFO - __main__ - Start tokenizing ... 128 instances
06/01/2022 23:54:21 - INFO - __main__ - Printing 3 examples
06/01/2022 23:54:21 - INFO - __main__ -  [wiki_qa] question: what happened to original pink power rangers [SEP] answer: Under the original name, "Mighty Morphin Power Rangers" the series ran from 1993 to 1995 and spawned the feature film Mighty Morphin Power Rangers: The Movie .
06/01/2022 23:54:21 - INFO - __main__ - ['false']
06/01/2022 23:54:21 - INFO - __main__ -  [wiki_qa] question: where do cruises dock in new york city [SEP] answer: The Normandie, renamed USS Lafayette, lies capsized in the frozen mud at Pier 88 in the winter of 1942
06/01/2022 23:54:21 - INFO - __main__ - ['false']
06/01/2022 23:54:21 - INFO - __main__ -  [wiki_qa] question: who plays ethan in my babysitter's a vampire [SEP] answer: The series follows the three as they take on supernatural forces and have adventures, with occasional help from fellow vampires Rory ( Cameron Kennedy ) and Erica ( Kate Todd ), while dealing with the troubles of regular high school life.
06/01/2022 23:54:21 - INFO - __main__ - ['false']
06/01/2022 23:54:21 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:54:21 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:54:21 - INFO - __main__ - Loaded 128 examples from dev data
06/01/2022 23:54:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/01/2022 23:54:34 - INFO - __main__ - Starting training!
06/01/2022 23:54:38 - INFO - __main__ - Step 10 Global step 10 Train loss 23.430012 on epoch=1
06/01/2022 23:54:43 - INFO - __main__ - Step 20 Global step 20 Train loss 17.637516 on epoch=2
06/01/2022 23:54:48 - INFO - __main__ - Step 30 Global step 30 Train loss 16.229450 on epoch=3
06/01/2022 23:54:53 - INFO - __main__ - Step 40 Global step 40 Train loss 13.556581 on epoch=4
06/01/2022 23:54:58 - INFO - __main__ - Step 50 Global step 50 Train loss 9.969625 on epoch=6
06/01/2022 23:54:59 - INFO - __main__ - Global step 50 Train loss 16.164637 Classification-F1 0.0 on epoch=6
06/01/2022 23:55:05 - INFO - __main__ - Step 60 Global step 60 Train loss 6.409406 on epoch=7
06/01/2022 23:55:10 - INFO - __main__ - Step 70 Global step 70 Train loss 0.969948 on epoch=8
06/01/2022 23:55:15 - INFO - __main__ - Step 80 Global step 80 Train loss 0.661044 on epoch=9
06/01/2022 23:55:20 - INFO - __main__ - Step 90 Global step 90 Train loss 0.539724 on epoch=11
06/01/2022 23:55:26 - INFO - __main__ - Step 100 Global step 100 Train loss 0.566187 on epoch=12
06/01/2022 23:55:27 - INFO - __main__ - Global step 100 Train loss 1.829262 Classification-F1 0.3671451355661882 on epoch=12
06/01/2022 23:55:33 - INFO - __main__ - Step 110 Global step 110 Train loss 0.499569 on epoch=13
06/01/2022 23:55:38 - INFO - __main__ - Step 120 Global step 120 Train loss 0.433290 on epoch=14
06/01/2022 23:55:43 - INFO - __main__ - Step 130 Global step 130 Train loss 0.514473 on epoch=16
06/01/2022 23:55:48 - INFO - __main__ - Step 140 Global step 140 Train loss 0.416238 on epoch=17
06/01/2022 23:55:53 - INFO - __main__ - Step 150 Global step 150 Train loss 0.443334 on epoch=18
06/01/2022 23:55:54 - INFO - __main__ - Global step 150 Train loss 0.461381 Classification-F1 0.3671451355661882 on epoch=18
06/01/2022 23:55:59 - INFO - __main__ - Step 160 Global step 160 Train loss 0.404765 on epoch=19
06/01/2022 23:56:04 - INFO - __main__ - Step 170 Global step 170 Train loss 1.295793 on epoch=21
06/01/2022 23:56:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.386771 on epoch=22
06/01/2022 23:56:14 - INFO - __main__ - Step 190 Global step 190 Train loss 0.362528 on epoch=23
06/01/2022 23:56:19 - INFO - __main__ - Step 200 Global step 200 Train loss 0.334854 on epoch=24
06/01/2022 23:56:21 - INFO - __main__ - Global step 200 Train loss 0.556942 Classification-F1 0.4385964912280702 on epoch=24
06/01/2022 23:56:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.226541 on epoch=26
06/01/2022 23:56:31 - INFO - __main__ - Step 220 Global step 220 Train loss 0.243944 on epoch=27
06/01/2022 23:56:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.177283 on epoch=28
06/01/2022 23:56:42 - INFO - __main__ - Step 240 Global step 240 Train loss 0.133184 on epoch=29
06/01/2022 23:56:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.137475 on epoch=31
06/01/2022 23:56:48 - INFO - __main__ - Global step 250 Train loss 0.183685 Classification-F1 0.4965315025387971 on epoch=31
06/01/2022 23:56:54 - INFO - __main__ - Step 260 Global step 260 Train loss 0.053998 on epoch=32
06/01/2022 23:56:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.310526 on epoch=33
06/01/2022 23:57:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.132600 on epoch=34
06/01/2022 23:57:09 - INFO - __main__ - Step 290 Global step 290 Train loss 0.093254 on epoch=36
06/01/2022 23:57:14 - INFO - __main__ - Step 300 Global step 300 Train loss 0.675996 on epoch=37
06/01/2022 23:57:15 - INFO - __main__ - Global step 300 Train loss 0.253275 Classification-F1 0.5033509700176367 on epoch=37
06/01/2022 23:57:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.111384 on epoch=38
06/01/2022 23:57:26 - INFO - __main__ - Step 320 Global step 320 Train loss 0.078515 on epoch=39
06/01/2022 23:57:32 - INFO - __main__ - Step 330 Global step 330 Train loss 0.028648 on epoch=41
06/01/2022 23:57:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.011612 on epoch=42
06/01/2022 23:57:42 - INFO - __main__ - Step 350 Global step 350 Train loss 0.005778 on epoch=43
06/01/2022 23:57:43 - INFO - __main__ - Global step 350 Train loss 0.047187 Classification-F1 0.5622435020519836 on epoch=43
06/01/2022 23:57:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.013912 on epoch=44
06/01/2022 23:57:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.040034 on epoch=46
06/01/2022 23:57:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.021140 on epoch=47
06/01/2022 23:58:04 - INFO - __main__ - Step 390 Global step 390 Train loss 0.017130 on epoch=48
06/01/2022 23:58:09 - INFO - __main__ - Step 400 Global step 400 Train loss 0.001400 on epoch=49
06/01/2022 23:58:11 - INFO - __main__ - Global step 400 Train loss 0.018723 Classification-F1 0.47065225277515776 on epoch=49
06/01/2022 23:58:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.000769 on epoch=51
06/01/2022 23:58:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.102164 on epoch=52
06/01/2022 23:58:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.036615 on epoch=53
06/01/2022 23:58:31 - INFO - __main__ - Step 440 Global step 440 Train loss 0.027837 on epoch=54
06/01/2022 23:58:36 - INFO - __main__ - Step 450 Global step 450 Train loss 0.012336 on epoch=56
06/01/2022 23:58:37 - INFO - __main__ - Global step 450 Train loss 0.035944 Classification-F1 0.4155251141552511 on epoch=56
06/01/2022 23:58:42 - INFO - __main__ - Step 460 Global step 460 Train loss 0.000704 on epoch=57
06/01/2022 23:58:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.000608 on epoch=58
06/01/2022 23:58:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.000573 on epoch=59
06/01/2022 23:58:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.000592 on epoch=61
06/01/2022 23:59:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.000723 on epoch=62
06/01/2022 23:59:04 - INFO - __main__ - Global step 500 Train loss 0.000640 Classification-F1 0.41075141075141075 on epoch=62
06/01/2022 23:59:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.005224 on epoch=63
06/01/2022 23:59:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.001036 on epoch=64
06/01/2022 23:59:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.000175 on epoch=66
06/01/2022 23:59:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.000236 on epoch=67
06/01/2022 23:59:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.002434 on epoch=68
06/01/2022 23:59:30 - INFO - __main__ - Global step 550 Train loss 0.001821 Classification-F1 0.571619812583668 on epoch=68
06/01/2022 23:59:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.000691 on epoch=69
06/01/2022 23:59:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.000110 on epoch=71
06/01/2022 23:59:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.177057 on epoch=72
06/01/2022 23:59:51 - INFO - __main__ - Step 590 Global step 590 Train loss 0.005244 on epoch=73
06/01/2022 23:59:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000391 on epoch=74
06/01/2022 23:59:58 - INFO - __main__ - Global step 600 Train loss 0.036699 Classification-F1 0.4468452895419188 on epoch=74
06/02/2022 00:00:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.000373 on epoch=76
06/02/2022 00:00:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.000307 on epoch=77
06/02/2022 00:00:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.001459 on epoch=78
06/02/2022 00:00:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.017765 on epoch=79
06/02/2022 00:00:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000430 on epoch=81
06/02/2022 00:00:24 - INFO - __main__ - Global step 650 Train loss 0.004067 Classification-F1 0.5544846050870147 on epoch=81
06/02/2022 00:00:29 - INFO - __main__ - Step 660 Global step 660 Train loss 0.015386 on epoch=82
06/02/2022 00:00:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.022892 on epoch=83
06/02/2022 00:00:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000300 on epoch=84
06/02/2022 00:00:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.002689 on epoch=86
06/02/2022 00:00:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000182 on epoch=87
06/02/2022 00:00:51 - INFO - __main__ - Global step 700 Train loss 0.008290 Classification-F1 0.4782235571765716 on epoch=87
06/02/2022 00:00:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.066480 on epoch=88
06/02/2022 00:01:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.001295 on epoch=89
06/02/2022 00:01:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000536 on epoch=91
06/02/2022 00:01:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.059802 on epoch=92
06/02/2022 00:01:16 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000803 on epoch=93
06/02/2022 00:01:17 - INFO - __main__ - Global step 750 Train loss 0.025783 Classification-F1 0.4837222702391241 on epoch=93
06/02/2022 00:01:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.004072 on epoch=94
06/02/2022 00:01:28 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000603 on epoch=96
06/02/2022 00:01:33 - INFO - __main__ - Step 780 Global step 780 Train loss 0.001788 on epoch=97
06/02/2022 00:01:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.048732 on epoch=98
06/02/2022 00:01:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000406 on epoch=99
06/02/2022 00:01:44 - INFO - __main__ - Global step 800 Train loss 0.011120 Classification-F1 0.6129447339638423 on epoch=99
06/02/2022 00:01:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.077753 on epoch=101
06/02/2022 00:01:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000185 on epoch=102
06/02/2022 00:02:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000069 on epoch=103
06/02/2022 00:02:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000116 on epoch=104
06/02/2022 00:02:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000029 on epoch=106
06/02/2022 00:02:11 - INFO - __main__ - Global step 850 Train loss 0.015630 Classification-F1 0.6032033066391114 on epoch=106
06/02/2022 00:02:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000077 on epoch=107
06/02/2022 00:02:22 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000083 on epoch=108
06/02/2022 00:02:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000044 on epoch=109
06/02/2022 00:02:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000050 on epoch=111
06/02/2022 00:02:37 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000064 on epoch=112
06/02/2022 00:02:38 - INFO - __main__ - Global step 900 Train loss 0.000064 Classification-F1 0.6099332166245217 on epoch=112
06/02/2022 00:02:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000066 on epoch=113
06/02/2022 00:02:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.015280 on epoch=114
06/02/2022 00:02:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000410 on epoch=116
06/02/2022 00:02:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000685 on epoch=117
06/02/2022 00:03:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000140 on epoch=118
06/02/2022 00:03:05 - INFO - __main__ - Global step 950 Train loss 0.003316 Classification-F1 0.5607885352889725 on epoch=118
06/02/2022 00:03:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000183 on epoch=119
06/02/2022 00:03:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000101 on epoch=121
06/02/2022 00:03:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000176 on epoch=122
06/02/2022 00:03:25 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000088 on epoch=123
06/02/2022 00:03:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000078 on epoch=124
06/02/2022 00:03:31 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:03:31 - INFO - __main__ - Printing 3 examples
06/02/2022 00:03:31 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/02/2022 00:03:31 - INFO - __main__ - ['false']
06/02/2022 00:03:31 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/02/2022 00:03:31 - INFO - __main__ - ['false']
06/02/2022 00:03:31 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/02/2022 00:03:31 - INFO - __main__ - ['false']
06/02/2022 00:03:31 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:03:31 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:03:31 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 00:03:31 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:03:31 - INFO - __main__ - Printing 3 examples
06/02/2022 00:03:31 - INFO - __main__ -  [wiki_qa] question: what happened to original pink power rangers [SEP] answer: Under the original name, "Mighty Morphin Power Rangers" the series ran from 1993 to 1995 and spawned the feature film Mighty Morphin Power Rangers: The Movie .
06/02/2022 00:03:31 - INFO - __main__ - ['false']
06/02/2022 00:03:31 - INFO - __main__ -  [wiki_qa] question: where do cruises dock in new york city [SEP] answer: The Normandie, renamed USS Lafayette, lies capsized in the frozen mud at Pier 88 in the winter of 1942
06/02/2022 00:03:31 - INFO - __main__ - ['false']
06/02/2022 00:03:31 - INFO - __main__ -  [wiki_qa] question: who plays ethan in my babysitter's a vampire [SEP] answer: The series follows the three as they take on supernatural forces and have adventures, with occasional help from fellow vampires Rory ( Cameron Kennedy ) and Erica ( Kate Todd ), while dealing with the troubles of regular high school life.
06/02/2022 00:03:31 - INFO - __main__ - ['false']
06/02/2022 00:03:31 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:03:31 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:03:31 - INFO - __main__ - Global step 1000 Train loss 0.000125 Classification-F1 0.571619812583668 on epoch=124
06/02/2022 00:03:31 - INFO - __main__ - save last model!
06/02/2022 00:03:31 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 00:03:38 - INFO - __main__ - Loading checkpoint on the fly
06/02/2022 00:03:39 - INFO - __main__ - Start tokenizing ... 2733 instances
06/02/2022 00:03:39 - INFO - __main__ - Printing 3 examples
06/02/2022 00:03:39 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/02/2022 00:03:39 - INFO - __main__ - ['false']
06/02/2022 00:03:39 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/02/2022 00:03:39 - INFO - __main__ - ['false']
06/02/2022 00:03:39 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/02/2022 00:03:39 - INFO - __main__ - ['false']
06/02/2022 00:03:39 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:03:41 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:03:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 00:03:42 - INFO - __main__ - Starting training!
06/02/2022 00:03:43 - INFO - __main__ - Loaded 2733 examples from test data
06/02/2022 00:04:12 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_21_0.0005_8_predictions.txt
06/02/2022 00:04:12 - INFO - __main__ - Classification-F1 on test data: 0.3925
06/02/2022 00:04:12 - INFO - __main__ - prefix=wiki_qa_64_21, lr=0.0005, bsz=8, dev_performance=0.6129447339638423, test_performance=0.39248379637671926
06/02/2022 00:04:12 - INFO - __main__ - Running ... prefix=wiki_qa_64_21, lr=0.0003, bsz=8 ...
06/02/2022 00:04:13 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:04:13 - INFO - __main__ - Printing 3 examples
06/02/2022 00:04:13 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/02/2022 00:04:13 - INFO - __main__ - ['false']
06/02/2022 00:04:13 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/02/2022 00:04:13 - INFO - __main__ - ['false']
06/02/2022 00:04:13 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/02/2022 00:04:13 - INFO - __main__ - ['false']
06/02/2022 00:04:13 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:04:13 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:04:13 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 00:04:13 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:04:13 - INFO - __main__ - Printing 3 examples
06/02/2022 00:04:13 - INFO - __main__ -  [wiki_qa] question: what happened to original pink power rangers [SEP] answer: Under the original name, "Mighty Morphin Power Rangers" the series ran from 1993 to 1995 and spawned the feature film Mighty Morphin Power Rangers: The Movie .
06/02/2022 00:04:13 - INFO - __main__ - ['false']
06/02/2022 00:04:13 - INFO - __main__ -  [wiki_qa] question: where do cruises dock in new york city [SEP] answer: The Normandie, renamed USS Lafayette, lies capsized in the frozen mud at Pier 88 in the winter of 1942
06/02/2022 00:04:13 - INFO - __main__ - ['false']
06/02/2022 00:04:13 - INFO - __main__ -  [wiki_qa] question: who plays ethan in my babysitter's a vampire [SEP] answer: The series follows the three as they take on supernatural forces and have adventures, with occasional help from fellow vampires Rory ( Cameron Kennedy ) and Erica ( Kate Todd ), while dealing with the troubles of regular high school life.
06/02/2022 00:04:13 - INFO - __main__ - ['false']
06/02/2022 00:04:13 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:04:13 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:04:13 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 00:04:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 00:04:26 - INFO - __main__ - Starting training!
06/02/2022 00:04:30 - INFO - __main__ - Step 10 Global step 10 Train loss 23.622063 on epoch=1
06/02/2022 00:04:35 - INFO - __main__ - Step 20 Global step 20 Train loss 18.350677 on epoch=2
06/02/2022 00:04:40 - INFO - __main__ - Step 30 Global step 30 Train loss 16.865450 on epoch=3
06/02/2022 00:04:45 - INFO - __main__ - Step 40 Global step 40 Train loss 15.923279 on epoch=4
06/02/2022 00:04:50 - INFO - __main__ - Step 50 Global step 50 Train loss 14.737165 on epoch=6
06/02/2022 00:04:52 - INFO - __main__ - Global step 50 Train loss 17.899727 Classification-F1 0.0 on epoch=6
06/02/2022 00:04:57 - INFO - __main__ - Step 60 Global step 60 Train loss 15.054625 on epoch=7
06/02/2022 00:05:02 - INFO - __main__ - Step 70 Global step 70 Train loss 12.963453 on epoch=8
06/02/2022 00:05:07 - INFO - __main__ - Step 80 Global step 80 Train loss 11.803121 on epoch=9
06/02/2022 00:05:12 - INFO - __main__ - Step 90 Global step 90 Train loss 6.747710 on epoch=11
06/02/2022 00:05:16 - INFO - __main__ - Step 100 Global step 100 Train loss 4.006882 on epoch=12
06/02/2022 00:05:18 - INFO - __main__ - Global step 100 Train loss 10.115158 Classification-F1 0.3294685990338164 on epoch=12
06/02/2022 00:05:23 - INFO - __main__ - Step 110 Global step 110 Train loss 1.891307 on epoch=13
06/02/2022 00:05:28 - INFO - __main__ - Step 120 Global step 120 Train loss 0.673317 on epoch=14
06/02/2022 00:05:33 - INFO - __main__ - Step 130 Global step 130 Train loss 0.582813 on epoch=16
06/02/2022 00:05:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.405163 on epoch=17
06/02/2022 00:05:43 - INFO - __main__ - Step 150 Global step 150 Train loss 0.511618 on epoch=18
06/02/2022 00:05:45 - INFO - __main__ - Global step 150 Train loss 0.812844 Classification-F1 0.350463149416029 on epoch=18
06/02/2022 00:05:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.470803 on epoch=19
06/02/2022 00:05:56 - INFO - __main__ - Step 170 Global step 170 Train loss 0.384737 on epoch=21
06/02/2022 00:06:01 - INFO - __main__ - Step 180 Global step 180 Train loss 0.399178 on epoch=22
06/02/2022 00:06:06 - INFO - __main__ - Step 190 Global step 190 Train loss 0.425541 on epoch=23
06/02/2022 00:06:11 - INFO - __main__ - Step 200 Global step 200 Train loss 0.593140 on epoch=24
06/02/2022 00:06:12 - INFO - __main__ - Global step 200 Train loss 0.454680 Classification-F1 0.2331674678811391 on epoch=24
06/02/2022 00:06:17 - INFO - __main__ - Step 210 Global step 210 Train loss 0.534827 on epoch=26
06/02/2022 00:06:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.523982 on epoch=27
06/02/2022 00:06:27 - INFO - __main__ - Step 230 Global step 230 Train loss 0.624698 on epoch=28
06/02/2022 00:06:32 - INFO - __main__ - Step 240 Global step 240 Train loss 0.407014 on epoch=29
06/02/2022 00:06:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.417743 on epoch=31
06/02/2022 00:06:38 - INFO - __main__ - Global step 250 Train loss 0.501653 Classification-F1 0.350463149416029 on epoch=31
06/02/2022 00:06:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.383001 on epoch=32
06/02/2022 00:06:49 - INFO - __main__ - Step 270 Global step 270 Train loss 0.358504 on epoch=33
06/02/2022 00:06:54 - INFO - __main__ - Step 280 Global step 280 Train loss 0.404913 on epoch=34
06/02/2022 00:06:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.325508 on epoch=36
06/02/2022 00:07:04 - INFO - __main__ - Step 300 Global step 300 Train loss 0.301627 on epoch=37
06/02/2022 00:07:05 - INFO - __main__ - Global step 300 Train loss 0.354710 Classification-F1 0.4796747967479674 on epoch=37
06/02/2022 00:07:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.351739 on epoch=38
06/02/2022 00:07:16 - INFO - __main__ - Step 320 Global step 320 Train loss 0.261155 on epoch=39
06/02/2022 00:07:21 - INFO - __main__ - Step 330 Global step 330 Train loss 0.201741 on epoch=41
06/02/2022 00:07:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.258778 on epoch=42
06/02/2022 00:07:31 - INFO - __main__ - Step 350 Global step 350 Train loss 0.192954 on epoch=43
06/02/2022 00:07:32 - INFO - __main__ - Global step 350 Train loss 0.253273 Classification-F1 0.3992490613266583 on epoch=43
06/02/2022 00:07:37 - INFO - __main__ - Step 360 Global step 360 Train loss 0.135061 on epoch=44
06/02/2022 00:07:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.085288 on epoch=46
06/02/2022 00:07:47 - INFO - __main__ - Step 380 Global step 380 Train loss 0.047243 on epoch=47
06/02/2022 00:07:52 - INFO - __main__ - Step 390 Global step 390 Train loss 0.086702 on epoch=48
06/02/2022 00:07:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.064603 on epoch=49
06/02/2022 00:07:59 - INFO - __main__ - Global step 400 Train loss 0.083779 Classification-F1 0.5588547189819725 on epoch=49
06/02/2022 00:08:04 - INFO - __main__ - Step 410 Global step 410 Train loss 0.031380 on epoch=51
06/02/2022 00:08:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.052649 on epoch=52
06/02/2022 00:08:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.008244 on epoch=53
06/02/2022 00:08:20 - INFO - __main__ - Step 440 Global step 440 Train loss 0.017802 on epoch=54
06/02/2022 00:08:25 - INFO - __main__ - Step 450 Global step 450 Train loss 0.010602 on epoch=56
06/02/2022 00:08:26 - INFO - __main__ - Global step 450 Train loss 0.024135 Classification-F1 0.3307291666666667 on epoch=56
06/02/2022 00:08:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.003190 on epoch=57
06/02/2022 00:08:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.011935 on epoch=58
06/02/2022 00:08:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.008701 on epoch=59
06/02/2022 00:08:47 - INFO - __main__ - Step 490 Global step 490 Train loss 0.017256 on epoch=61
06/02/2022 00:08:52 - INFO - __main__ - Step 500 Global step 500 Train loss 0.031455 on epoch=62
06/02/2022 00:08:54 - INFO - __main__ - Global step 500 Train loss 0.014508 Classification-F1 0.37528344671201813 on epoch=62
06/02/2022 00:08:59 - INFO - __main__ - Step 510 Global step 510 Train loss 0.012900 on epoch=63
06/02/2022 00:09:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.008478 on epoch=64
06/02/2022 00:09:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.023667 on epoch=66
06/02/2022 00:09:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.005179 on epoch=67
06/02/2022 00:09:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.003749 on epoch=68
06/02/2022 00:09:20 - INFO - __main__ - Global step 550 Train loss 0.010795 Classification-F1 0.5801720403490316 on epoch=68
06/02/2022 00:09:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.002661 on epoch=69
06/02/2022 00:09:31 - INFO - __main__ - Step 570 Global step 570 Train loss 0.003386 on epoch=71
06/02/2022 00:09:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.003043 on epoch=72
06/02/2022 00:09:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.003502 on epoch=73
06/02/2022 00:09:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.001474 on epoch=74
06/02/2022 00:09:48 - INFO - __main__ - Global step 600 Train loss 0.002813 Classification-F1 0.37935483870967746 on epoch=74
06/02/2022 00:09:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.002190 on epoch=76
06/02/2022 00:09:58 - INFO - __main__ - Step 620 Global step 620 Train loss 0.007460 on epoch=77
06/02/2022 00:10:03 - INFO - __main__ - Step 630 Global step 630 Train loss 0.004786 on epoch=78
06/02/2022 00:10:08 - INFO - __main__ - Step 640 Global step 640 Train loss 0.019354 on epoch=79
06/02/2022 00:10:13 - INFO - __main__ - Step 650 Global step 650 Train loss 0.009537 on epoch=81
06/02/2022 00:10:15 - INFO - __main__ - Global step 650 Train loss 0.008665 Classification-F1 0.1670009460737938 on epoch=81
06/02/2022 00:10:20 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000553 on epoch=82
06/02/2022 00:10:25 - INFO - __main__ - Step 670 Global step 670 Train loss 0.003408 on epoch=83
06/02/2022 00:10:30 - INFO - __main__ - Step 680 Global step 680 Train loss 0.003411 on epoch=84
06/02/2022 00:10:35 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000582 on epoch=86
06/02/2022 00:10:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000334 on epoch=87
06/02/2022 00:10:41 - INFO - __main__ - Global step 700 Train loss 0.001657 Classification-F1 0.2383326840670043 on epoch=87
06/02/2022 00:10:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.002251 on epoch=88
06/02/2022 00:10:51 - INFO - __main__ - Step 720 Global step 720 Train loss 0.011059 on epoch=89
06/02/2022 00:10:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.009569 on epoch=91
06/02/2022 00:11:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.004301 on epoch=92
06/02/2022 00:11:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.007001 on epoch=93
06/02/2022 00:11:08 - INFO - __main__ - Global step 750 Train loss 0.006836 Classification-F1 0.25049370105549884 on epoch=93
06/02/2022 00:11:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.011280 on epoch=94
06/02/2022 00:11:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.003956 on epoch=96
06/02/2022 00:11:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.003819 on epoch=97
06/02/2022 00:11:28 - INFO - __main__ - Step 790 Global step 790 Train loss 0.001942 on epoch=98
06/02/2022 00:11:33 - INFO - __main__ - Step 800 Global step 800 Train loss 0.037838 on epoch=99
06/02/2022 00:11:35 - INFO - __main__ - Global step 800 Train loss 0.011767 Classification-F1 0.39731758336409495 on epoch=99
06/02/2022 00:11:40 - INFO - __main__ - Step 810 Global step 810 Train loss 0.011464 on epoch=101
06/02/2022 00:11:45 - INFO - __main__ - Step 820 Global step 820 Train loss 0.008281 on epoch=102
06/02/2022 00:11:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.016563 on epoch=103
06/02/2022 00:11:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.001421 on epoch=104
06/02/2022 00:12:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.001375 on epoch=106
06/02/2022 00:12:02 - INFO - __main__ - Global step 850 Train loss 0.007821 Classification-F1 0.17501859741664974 on epoch=106
06/02/2022 00:12:07 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000746 on epoch=107
06/02/2022 00:12:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000331 on epoch=108
06/02/2022 00:12:17 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000273 on epoch=109
06/02/2022 00:12:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.001375 on epoch=111
06/02/2022 00:12:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000478 on epoch=112
06/02/2022 00:12:29 - INFO - __main__ - Global step 900 Train loss 0.000641 Classification-F1 0.1899284914275868 on epoch=112
06/02/2022 00:12:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.001823 on epoch=113
06/02/2022 00:12:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.002911 on epoch=114
06/02/2022 00:12:44 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000578 on epoch=116
06/02/2022 00:12:49 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000359 on epoch=117
06/02/2022 00:12:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.001991 on epoch=118
06/02/2022 00:12:56 - INFO - __main__ - Global step 950 Train loss 0.001532 Classification-F1 0.19773242630385482 on epoch=118
06/02/2022 00:13:01 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000113 on epoch=119
06/02/2022 00:13:06 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000568 on epoch=121
06/02/2022 00:13:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.002962 on epoch=122
06/02/2022 00:13:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.003492 on epoch=123
06/02/2022 00:13:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000096 on epoch=124
06/02/2022 00:13:22 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:13:22 - INFO - __main__ - Printing 3 examples
06/02/2022 00:13:22 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/02/2022 00:13:22 - INFO - __main__ - ['false']
06/02/2022 00:13:22 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/02/2022 00:13:22 - INFO - __main__ - ['false']
06/02/2022 00:13:22 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/02/2022 00:13:22 - INFO - __main__ - ['false']
06/02/2022 00:13:22 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:13:23 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:13:23 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 00:13:23 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:13:23 - INFO - __main__ - Printing 3 examples
06/02/2022 00:13:23 - INFO - __main__ -  [wiki_qa] question: what happened to original pink power rangers [SEP] answer: Under the original name, "Mighty Morphin Power Rangers" the series ran from 1993 to 1995 and spawned the feature film Mighty Morphin Power Rangers: The Movie .
06/02/2022 00:13:23 - INFO - __main__ - ['false']
06/02/2022 00:13:23 - INFO - __main__ -  [wiki_qa] question: where do cruises dock in new york city [SEP] answer: The Normandie, renamed USS Lafayette, lies capsized in the frozen mud at Pier 88 in the winter of 1942
06/02/2022 00:13:23 - INFO - __main__ - ['false']
06/02/2022 00:13:23 - INFO - __main__ -  [wiki_qa] question: who plays ethan in my babysitter's a vampire [SEP] answer: The series follows the three as they take on supernatural forces and have adventures, with occasional help from fellow vampires Rory ( Cameron Kennedy ) and Erica ( Kate Todd ), while dealing with the troubles of regular high school life.
06/02/2022 00:13:23 - INFO - __main__ - ['false']
06/02/2022 00:13:23 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:13:23 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:13:23 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 00:13:23 - INFO - __main__ - Global step 1000 Train loss 0.001446 Classification-F1 0.20350412806453644 on epoch=124
06/02/2022 00:13:23 - INFO - __main__ - save last model!
06/02/2022 00:13:30 - INFO - __main__ - Loading checkpoint on the fly
06/02/2022 00:13:31 - INFO - __main__ - Start tokenizing ... 2733 instances
06/02/2022 00:13:31 - INFO - __main__ - Printing 3 examples
06/02/2022 00:13:31 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/02/2022 00:13:31 - INFO - __main__ - ['false']
06/02/2022 00:13:31 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/02/2022 00:13:31 - INFO - __main__ - ['false']
06/02/2022 00:13:31 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/02/2022 00:13:31 - INFO - __main__ - ['false']
06/02/2022 00:13:31 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:13:32 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:13:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 00:13:34 - INFO - __main__ - Starting training!
06/02/2022 00:13:35 - INFO - __main__ - Loaded 2733 examples from test data
06/02/2022 00:14:04 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_21_0.0003_8_predictions.txt
06/02/2022 00:14:04 - INFO - __main__ - Classification-F1 on test data: 0.1535
06/02/2022 00:14:04 - INFO - __main__ - prefix=wiki_qa_64_21, lr=0.0003, bsz=8, dev_performance=0.5801720403490316, test_performance=0.15352154861898282
06/02/2022 00:14:04 - INFO - __main__ - Running ... prefix=wiki_qa_64_21, lr=0.0002, bsz=8 ...
06/02/2022 00:14:05 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:14:05 - INFO - __main__ - Printing 3 examples
06/02/2022 00:14:05 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/02/2022 00:14:05 - INFO - __main__ - ['false']
06/02/2022 00:14:05 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/02/2022 00:14:05 - INFO - __main__ - ['false']
06/02/2022 00:14:05 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/02/2022 00:14:05 - INFO - __main__ - ['false']
06/02/2022 00:14:05 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:14:05 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:14:05 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 00:14:05 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:14:05 - INFO - __main__ - Printing 3 examples
06/02/2022 00:14:05 - INFO - __main__ -  [wiki_qa] question: what happened to original pink power rangers [SEP] answer: Under the original name, "Mighty Morphin Power Rangers" the series ran from 1993 to 1995 and spawned the feature film Mighty Morphin Power Rangers: The Movie .
06/02/2022 00:14:05 - INFO - __main__ - ['false']
06/02/2022 00:14:05 - INFO - __main__ -  [wiki_qa] question: where do cruises dock in new york city [SEP] answer: The Normandie, renamed USS Lafayette, lies capsized in the frozen mud at Pier 88 in the winter of 1942
06/02/2022 00:14:05 - INFO - __main__ - ['false']
06/02/2022 00:14:05 - INFO - __main__ -  [wiki_qa] question: who plays ethan in my babysitter's a vampire [SEP] answer: The series follows the three as they take on supernatural forces and have adventures, with occasional help from fellow vampires Rory ( Cameron Kennedy ) and Erica ( Kate Todd ), while dealing with the troubles of regular high school life.
06/02/2022 00:14:05 - INFO - __main__ - ['false']
06/02/2022 00:14:05 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:14:05 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:14:05 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 00:14:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 00:14:18 - INFO - __main__ - Starting training!
06/02/2022 00:14:22 - INFO - __main__ - Step 10 Global step 10 Train loss 22.555069 on epoch=1
06/02/2022 00:14:27 - INFO - __main__ - Step 20 Global step 20 Train loss 19.748276 on epoch=2
06/02/2022 00:14:32 - INFO - __main__ - Step 30 Global step 30 Train loss 17.064709 on epoch=3
06/02/2022 00:14:37 - INFO - __main__ - Step 40 Global step 40 Train loss 16.827841 on epoch=4
06/02/2022 00:14:42 - INFO - __main__ - Step 50 Global step 50 Train loss 16.007772 on epoch=6
06/02/2022 00:14:58 - INFO - __main__ - Global step 50 Train loss 18.440733 Classification-F1 0.0 on epoch=6
06/02/2022 00:15:03 - INFO - __main__ - Step 60 Global step 60 Train loss 15.502550 on epoch=7
06/02/2022 00:15:08 - INFO - __main__ - Step 70 Global step 70 Train loss 14.790993 on epoch=8
06/02/2022 00:15:13 - INFO - __main__ - Step 80 Global step 80 Train loss 13.386968 on epoch=9
06/02/2022 00:15:18 - INFO - __main__ - Step 90 Global step 90 Train loss 13.792654 on epoch=11
06/02/2022 00:15:23 - INFO - __main__ - Step 100 Global step 100 Train loss 12.494521 on epoch=12
06/02/2022 00:15:54 - INFO - __main__ - Global step 100 Train loss 13.993538 Classification-F1 0.0008067737039699656 on epoch=12
06/02/2022 00:16:00 - INFO - __main__ - Step 110 Global step 110 Train loss 11.078867 on epoch=13
06/02/2022 00:16:05 - INFO - __main__ - Step 120 Global step 120 Train loss 7.870476 on epoch=14
06/02/2022 00:16:10 - INFO - __main__ - Step 130 Global step 130 Train loss 2.378890 on epoch=16
06/02/2022 00:16:15 - INFO - __main__ - Step 140 Global step 140 Train loss 0.678453 on epoch=17
06/02/2022 00:16:20 - INFO - __main__ - Step 150 Global step 150 Train loss 0.536979 on epoch=18
06/02/2022 00:16:22 - INFO - __main__ - Global step 150 Train loss 4.508732 Classification-F1 0.2724050632911392 on epoch=18
06/02/2022 00:16:27 - INFO - __main__ - Step 160 Global step 160 Train loss 0.651297 on epoch=19
06/02/2022 00:16:32 - INFO - __main__ - Step 170 Global step 170 Train loss 0.587860 on epoch=21
06/02/2022 00:16:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.530646 on epoch=22
06/02/2022 00:16:43 - INFO - __main__ - Step 190 Global step 190 Train loss 0.494650 on epoch=23
06/02/2022 00:16:48 - INFO - __main__ - Step 200 Global step 200 Train loss 0.458051 on epoch=24
06/02/2022 00:16:49 - INFO - __main__ - Global step 200 Train loss 0.544501 Classification-F1 0.5696139476961395 on epoch=24
06/02/2022 00:16:55 - INFO - __main__ - Step 210 Global step 210 Train loss 0.404348 on epoch=26
06/02/2022 00:17:00 - INFO - __main__ - Step 220 Global step 220 Train loss 0.425821 on epoch=27
06/02/2022 00:17:05 - INFO - __main__ - Step 230 Global step 230 Train loss 0.475506 on epoch=28
06/02/2022 00:17:10 - INFO - __main__ - Step 240 Global step 240 Train loss 0.400142 on epoch=29
06/02/2022 00:17:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.456333 on epoch=31
06/02/2022 00:17:17 - INFO - __main__ - Global step 250 Train loss 0.432430 Classification-F1 0.3834004580273237 on epoch=31
06/02/2022 00:17:22 - INFO - __main__ - Step 260 Global step 260 Train loss 0.485975 on epoch=32
06/02/2022 00:17:27 - INFO - __main__ - Step 270 Global step 270 Train loss 0.402917 on epoch=33
06/02/2022 00:17:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.396375 on epoch=34
06/02/2022 00:17:37 - INFO - __main__ - Step 290 Global step 290 Train loss 0.379751 on epoch=36
06/02/2022 00:17:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.291080 on epoch=37
06/02/2022 00:17:43 - INFO - __main__ - Global step 300 Train loss 0.391220 Classification-F1 0.3750290630086026 on epoch=37
06/02/2022 00:17:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.339413 on epoch=38
06/02/2022 00:17:54 - INFO - __main__ - Step 320 Global step 320 Train loss 0.337165 on epoch=39
06/02/2022 00:17:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.351055 on epoch=41
06/02/2022 00:18:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.330438 on epoch=42
06/02/2022 00:18:09 - INFO - __main__ - Step 350 Global step 350 Train loss 0.286715 on epoch=43
06/02/2022 00:18:10 - INFO - __main__ - Global step 350 Train loss 0.328957 Classification-F1 0.5302177636408123 on epoch=43
06/02/2022 00:18:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.310030 on epoch=44
06/02/2022 00:18:20 - INFO - __main__ - Step 370 Global step 370 Train loss 0.275467 on epoch=46
06/02/2022 00:18:25 - INFO - __main__ - Step 380 Global step 380 Train loss 0.245234 on epoch=47
06/02/2022 00:18:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.215334 on epoch=48
06/02/2022 00:18:36 - INFO - __main__ - Step 400 Global step 400 Train loss 0.204971 on epoch=49
06/02/2022 00:18:37 - INFO - __main__ - Global step 400 Train loss 0.250207 Classification-F1 0.5599694423223835 on epoch=49
06/02/2022 00:18:42 - INFO - __main__ - Step 410 Global step 410 Train loss 0.226069 on epoch=51
06/02/2022 00:18:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.210545 on epoch=52
06/02/2022 00:18:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.252887 on epoch=53
06/02/2022 00:18:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.291104 on epoch=54
06/02/2022 00:19:02 - INFO - __main__ - Step 450 Global step 450 Train loss 0.221319 on epoch=56
06/02/2022 00:19:04 - INFO - __main__ - Global step 450 Train loss 0.240385 Classification-F1 0.48529100529100533 on epoch=56
06/02/2022 00:19:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.156403 on epoch=57
06/02/2022 00:19:14 - INFO - __main__ - Step 470 Global step 470 Train loss 0.085895 on epoch=58
06/02/2022 00:19:19 - INFO - __main__ - Step 480 Global step 480 Train loss 0.108702 on epoch=59
06/02/2022 00:19:24 - INFO - __main__ - Step 490 Global step 490 Train loss 0.123078 on epoch=61
06/02/2022 00:19:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.099834 on epoch=62
06/02/2022 00:19:31 - INFO - __main__ - Global step 500 Train loss 0.114782 Classification-F1 0.5195195195195195 on epoch=62
06/02/2022 00:19:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.078260 on epoch=63
06/02/2022 00:19:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.118660 on epoch=64
06/02/2022 00:19:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.066032 on epoch=66
06/02/2022 00:19:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.054294 on epoch=67
06/02/2022 00:19:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.066847 on epoch=68
06/02/2022 00:19:57 - INFO - __main__ - Global step 550 Train loss 0.076819 Classification-F1 0.48594377510040165 on epoch=68
06/02/2022 00:20:02 - INFO - __main__ - Step 560 Global step 560 Train loss 0.935132 on epoch=69
06/02/2022 00:20:07 - INFO - __main__ - Step 570 Global step 570 Train loss 0.962847 on epoch=71
06/02/2022 00:20:12 - INFO - __main__ - Step 580 Global step 580 Train loss 0.229356 on epoch=72
06/02/2022 00:20:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.331449 on epoch=73
06/02/2022 00:20:23 - INFO - __main__ - Step 600 Global step 600 Train loss 0.226547 on epoch=74
06/02/2022 00:20:24 - INFO - __main__ - Global step 600 Train loss 0.537066 Classification-F1 0.5058530510585305 on epoch=74
06/02/2022 00:20:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.169288 on epoch=76
06/02/2022 00:20:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.140898 on epoch=77
06/02/2022 00:20:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.189088 on epoch=78
06/02/2022 00:20:44 - INFO - __main__ - Step 640 Global step 640 Train loss 0.222253 on epoch=79
06/02/2022 00:20:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.111373 on epoch=81
06/02/2022 00:20:51 - INFO - __main__ - Global step 650 Train loss 0.166580 Classification-F1 0.5234084111579076 on epoch=81
06/02/2022 00:20:56 - INFO - __main__ - Step 660 Global step 660 Train loss 0.178837 on epoch=82
06/02/2022 00:21:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.089119 on epoch=83
06/02/2022 00:21:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.146479 on epoch=84
06/02/2022 00:21:11 - INFO - __main__ - Step 690 Global step 690 Train loss 0.070475 on epoch=86
06/02/2022 00:21:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.076241 on epoch=87
06/02/2022 00:21:18 - INFO - __main__ - Global step 700 Train loss 0.112230 Classification-F1 0.49556650246305417 on epoch=87
06/02/2022 00:21:23 - INFO - __main__ - Step 710 Global step 710 Train loss 0.060749 on epoch=88
06/02/2022 00:21:28 - INFO - __main__ - Step 720 Global step 720 Train loss 0.067957 on epoch=89
06/02/2022 00:21:33 - INFO - __main__ - Step 730 Global step 730 Train loss 0.046251 on epoch=91
06/02/2022 00:21:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.037364 on epoch=92
06/02/2022 00:21:43 - INFO - __main__ - Step 750 Global step 750 Train loss 0.023040 on epoch=93
06/02/2022 00:21:45 - INFO - __main__ - Global step 750 Train loss 0.047072 Classification-F1 0.4989748369058714 on epoch=93
06/02/2022 00:21:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.023899 on epoch=94
06/02/2022 00:21:55 - INFO - __main__ - Step 770 Global step 770 Train loss 0.060276 on epoch=96
06/02/2022 00:22:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.058844 on epoch=97
06/02/2022 00:22:05 - INFO - __main__ - Step 790 Global step 790 Train loss 0.021532 on epoch=98
06/02/2022 00:22:10 - INFO - __main__ - Step 800 Global step 800 Train loss 0.043672 on epoch=99
06/02/2022 00:22:12 - INFO - __main__ - Global step 800 Train loss 0.041645 Classification-F1 0.5137254901960784 on epoch=99
06/02/2022 00:22:17 - INFO - __main__ - Step 810 Global step 810 Train loss 0.026992 on epoch=101
06/02/2022 00:22:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.007942 on epoch=102
06/02/2022 00:22:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.009330 on epoch=103
06/02/2022 00:22:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.016250 on epoch=104
06/02/2022 00:22:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.017470 on epoch=106
06/02/2022 00:22:39 - INFO - __main__ - Global step 850 Train loss 0.015597 Classification-F1 0.5513742851872347 on epoch=106
06/02/2022 00:22:44 - INFO - __main__ - Step 860 Global step 860 Train loss 0.010003 on epoch=107
06/02/2022 00:22:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.020370 on epoch=108
06/02/2022 00:22:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.012540 on epoch=109
06/02/2022 00:22:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.023211 on epoch=111
06/02/2022 00:23:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.027801 on epoch=112
06/02/2022 00:23:05 - INFO - __main__ - Global step 900 Train loss 0.018785 Classification-F1 0.5500462534690101 on epoch=112
06/02/2022 00:23:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.017578 on epoch=113
06/02/2022 00:23:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.002860 on epoch=114
06/02/2022 00:23:21 - INFO - __main__ - Step 930 Global step 930 Train loss 0.003901 on epoch=116
06/02/2022 00:23:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.003999 on epoch=117
06/02/2022 00:23:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.012262 on epoch=118
06/02/2022 00:23:32 - INFO - __main__ - Global step 950 Train loss 0.008120 Classification-F1 0.47848230201171377 on epoch=118
06/02/2022 00:23:37 - INFO - __main__ - Step 960 Global step 960 Train loss 0.012337 on epoch=119
06/02/2022 00:23:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.003885 on epoch=121
06/02/2022 00:23:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.004069 on epoch=122
06/02/2022 00:23:52 - INFO - __main__ - Step 990 Global step 990 Train loss 0.001340 on epoch=123
06/02/2022 00:23:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.001895 on epoch=124
06/02/2022 00:23:59 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:23:59 - INFO - __main__ - Printing 3 examples
06/02/2022 00:23:59 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/02/2022 00:23:59 - INFO - __main__ - ['false']
06/02/2022 00:23:59 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/02/2022 00:23:59 - INFO - __main__ - ['false']
06/02/2022 00:23:59 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/02/2022 00:23:59 - INFO - __main__ - ['false']
06/02/2022 00:23:59 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:23:59 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:23:59 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 00:23:59 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:23:59 - INFO - __main__ - Printing 3 examples
06/02/2022 00:23:59 - INFO - __main__ -  [wiki_qa] question: what happened to original pink power rangers [SEP] answer: Under the original name, "Mighty Morphin Power Rangers" the series ran from 1993 to 1995 and spawned the feature film Mighty Morphin Power Rangers: The Movie .
06/02/2022 00:23:59 - INFO - __main__ - ['false']
06/02/2022 00:23:59 - INFO - __main__ -  [wiki_qa] question: where do cruises dock in new york city [SEP] answer: The Normandie, renamed USS Lafayette, lies capsized in the frozen mud at Pier 88 in the winter of 1942
06/02/2022 00:23:59 - INFO - __main__ - ['false']
06/02/2022 00:23:59 - INFO - __main__ -  [wiki_qa] question: who plays ethan in my babysitter's a vampire [SEP] answer: The series follows the three as they take on supernatural forces and have adventures, with occasional help from fellow vampires Rory ( Cameron Kennedy ) and Erica ( Kate Todd ), while dealing with the troubles of regular high school life.
06/02/2022 00:23:59 - INFO - __main__ - ['false']
06/02/2022 00:23:59 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:23:59 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:23:59 - INFO - __main__ - Global step 1000 Train loss 0.004705 Classification-F1 0.5515515515515517 on epoch=124
06/02/2022 00:23:59 - INFO - __main__ - save last model!
06/02/2022 00:23:59 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 00:24:06 - INFO - __main__ - Loading checkpoint on the fly
06/02/2022 00:24:06 - INFO - __main__ - Start tokenizing ... 2733 instances
06/02/2022 00:24:06 - INFO - __main__ - Printing 3 examples
06/02/2022 00:24:06 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/02/2022 00:24:06 - INFO - __main__ - ['false']
06/02/2022 00:24:06 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/02/2022 00:24:06 - INFO - __main__ - ['false']
06/02/2022 00:24:06 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/02/2022 00:24:06 - INFO - __main__ - ['false']
06/02/2022 00:24:06 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:24:08 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:24:10 - INFO - __main__ - Loaded 2733 examples from test data
06/02/2022 00:24:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 00:24:12 - INFO - __main__ - Starting training!
06/02/2022 00:24:39 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_21_0.0002_8_predictions.txt
06/02/2022 00:24:39 - INFO - __main__ - Classification-F1 on test data: 0.4417
06/02/2022 00:24:40 - INFO - __main__ - prefix=wiki_qa_64_21, lr=0.0002, bsz=8, dev_performance=0.5696139476961395, test_performance=0.4417098080172385
06/02/2022 00:24:40 - INFO - __main__ - Running ... prefix=wiki_qa_64_21, lr=0.0001, bsz=8 ...
06/02/2022 00:24:40 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:24:40 - INFO - __main__ - Printing 3 examples
06/02/2022 00:24:40 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/02/2022 00:24:40 - INFO - __main__ - ['false']
06/02/2022 00:24:40 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/02/2022 00:24:40 - INFO - __main__ - ['false']
06/02/2022 00:24:40 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/02/2022 00:24:40 - INFO - __main__ - ['false']
06/02/2022 00:24:40 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:24:41 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:24:41 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 00:24:41 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:24:41 - INFO - __main__ - Printing 3 examples
06/02/2022 00:24:41 - INFO - __main__ -  [wiki_qa] question: what happened to original pink power rangers [SEP] answer: Under the original name, "Mighty Morphin Power Rangers" the series ran from 1993 to 1995 and spawned the feature film Mighty Morphin Power Rangers: The Movie .
06/02/2022 00:24:41 - INFO - __main__ - ['false']
06/02/2022 00:24:41 - INFO - __main__ -  [wiki_qa] question: where do cruises dock in new york city [SEP] answer: The Normandie, renamed USS Lafayette, lies capsized in the frozen mud at Pier 88 in the winter of 1942
06/02/2022 00:24:41 - INFO - __main__ - ['false']
06/02/2022 00:24:41 - INFO - __main__ -  [wiki_qa] question: who plays ethan in my babysitter's a vampire [SEP] answer: The series follows the three as they take on supernatural forces and have adventures, with occasional help from fellow vampires Rory ( Cameron Kennedy ) and Erica ( Kate Todd ), while dealing with the troubles of regular high school life.
06/02/2022 00:24:41 - INFO - __main__ - ['false']
06/02/2022 00:24:41 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:24:41 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:24:41 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 00:24:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 00:24:52 - INFO - __main__ - Starting training!
06/02/2022 00:24:57 - INFO - __main__ - Step 10 Global step 10 Train loss 23.101065 on epoch=1
06/02/2022 00:25:02 - INFO - __main__ - Step 20 Global step 20 Train loss 20.408504 on epoch=2
06/02/2022 00:25:07 - INFO - __main__ - Step 30 Global step 30 Train loss 18.297474 on epoch=3
06/02/2022 00:25:12 - INFO - __main__ - Step 40 Global step 40 Train loss 18.001675 on epoch=4
06/02/2022 00:25:17 - INFO - __main__ - Step 50 Global step 50 Train loss 17.261663 on epoch=6
06/02/2022 00:25:52 - INFO - __main__ - Global step 50 Train loss 19.414078 Classification-F1 0.0 on epoch=6
06/02/2022 00:25:58 - INFO - __main__ - Step 60 Global step 60 Train loss 17.024525 on epoch=7
06/02/2022 00:26:03 - INFO - __main__ - Step 70 Global step 70 Train loss 16.643160 on epoch=8
06/02/2022 00:26:09 - INFO - __main__ - Step 80 Global step 80 Train loss 15.834852 on epoch=9
06/02/2022 00:26:14 - INFO - __main__ - Step 90 Global step 90 Train loss 16.420313 on epoch=11
06/02/2022 00:26:19 - INFO - __main__ - Step 100 Global step 100 Train loss 15.261909 on epoch=12
06/02/2022 00:26:55 - INFO - __main__ - Global step 100 Train loss 16.236950 Classification-F1 0.0 on epoch=12
06/02/2022 00:27:00 - INFO - __main__ - Step 110 Global step 110 Train loss 15.041928 on epoch=13
06/02/2022 00:27:05 - INFO - __main__ - Step 120 Global step 120 Train loss 14.561078 on epoch=14
06/02/2022 00:27:10 - INFO - __main__ - Step 130 Global step 130 Train loss 14.436374 on epoch=16
06/02/2022 00:27:16 - INFO - __main__ - Step 140 Global step 140 Train loss 13.894453 on epoch=17
06/02/2022 00:27:21 - INFO - __main__ - Step 150 Global step 150 Train loss 13.513486 on epoch=18
06/02/2022 00:27:56 - INFO - __main__ - Global step 150 Train loss 14.289463 Classification-F1 0.0 on epoch=18
06/02/2022 00:28:01 - INFO - __main__ - Step 160 Global step 160 Train loss 12.762775 on epoch=19
06/02/2022 00:28:06 - INFO - __main__ - Step 170 Global step 170 Train loss 11.831406 on epoch=21
06/02/2022 00:28:11 - INFO - __main__ - Step 180 Global step 180 Train loss 6.440155 on epoch=22
06/02/2022 00:28:16 - INFO - __main__ - Step 190 Global step 190 Train loss 1.055751 on epoch=23
06/02/2022 00:28:21 - INFO - __main__ - Step 200 Global step 200 Train loss 1.085913 on epoch=24
06/02/2022 00:28:23 - INFO - __main__ - Global step 200 Train loss 6.635200 Classification-F1 0.32275132275132273 on epoch=24
06/02/2022 00:28:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.540655 on epoch=26
06/02/2022 00:28:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.621562 on epoch=27
06/02/2022 00:28:39 - INFO - __main__ - Step 230 Global step 230 Train loss 0.464821 on epoch=28
06/02/2022 00:28:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.592079 on epoch=29
06/02/2022 00:28:49 - INFO - __main__ - Step 250 Global step 250 Train loss 0.455522 on epoch=31
06/02/2022 00:28:51 - INFO - __main__ - Global step 250 Train loss 0.534928 Classification-F1 0.350463149416029 on epoch=31
06/02/2022 00:28:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.549794 on epoch=32
06/02/2022 00:29:02 - INFO - __main__ - Step 270 Global step 270 Train loss 0.382407 on epoch=33
06/02/2022 00:29:07 - INFO - __main__ - Step 280 Global step 280 Train loss 0.490536 on epoch=34
06/02/2022 00:29:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.458098 on epoch=36
06/02/2022 00:29:17 - INFO - __main__ - Step 300 Global step 300 Train loss 0.456313 on epoch=37
06/02/2022 00:29:19 - INFO - __main__ - Global step 300 Train loss 0.467430 Classification-F1 0.6437246963562753 on epoch=37
06/02/2022 00:29:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.486147 on epoch=38
06/02/2022 00:29:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.375907 on epoch=39
06/02/2022 00:29:35 - INFO - __main__ - Step 330 Global step 330 Train loss 0.288417 on epoch=41
06/02/2022 00:29:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.414062 on epoch=42
06/02/2022 00:29:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.208056 on epoch=43
06/02/2022 00:29:47 - INFO - __main__ - Global step 350 Train loss 0.354518 Classification-F1 0.4487674487674488 on epoch=43
06/02/2022 00:29:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.235725 on epoch=44
06/02/2022 00:29:57 - INFO - __main__ - Step 370 Global step 370 Train loss 0.177404 on epoch=46
06/02/2022 00:30:02 - INFO - __main__ - Step 380 Global step 380 Train loss 0.144547 on epoch=47
06/02/2022 00:30:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.247161 on epoch=48
06/02/2022 00:30:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.136631 on epoch=49
06/02/2022 00:30:14 - INFO - __main__ - Global step 400 Train loss 0.188294 Classification-F1 0.3992490613266583 on epoch=49
06/02/2022 00:30:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.188791 on epoch=51
06/02/2022 00:30:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.162679 on epoch=52
06/02/2022 00:30:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.101090 on epoch=53
06/02/2022 00:30:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.127773 on epoch=54
06/02/2022 00:30:40 - INFO - __main__ - Step 450 Global step 450 Train loss 0.094060 on epoch=56
06/02/2022 00:30:41 - INFO - __main__ - Global step 450 Train loss 0.134878 Classification-F1 0.5335015419119707 on epoch=56
06/02/2022 00:30:46 - INFO - __main__ - Step 460 Global step 460 Train loss 0.099231 on epoch=57
06/02/2022 00:30:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.112086 on epoch=58
06/02/2022 00:30:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.213214 on epoch=59
06/02/2022 00:31:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.068501 on epoch=61
06/02/2022 00:31:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.080375 on epoch=62
06/02/2022 00:31:08 - INFO - __main__ - Global step 500 Train loss 0.114681 Classification-F1 0.41470975742075483 on epoch=62
06/02/2022 00:31:14 - INFO - __main__ - Step 510 Global step 510 Train loss 0.042403 on epoch=63
06/02/2022 00:31:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.038862 on epoch=64
06/02/2022 00:31:24 - INFO - __main__ - Step 530 Global step 530 Train loss 0.051606 on epoch=66
06/02/2022 00:31:29 - INFO - __main__ - Step 540 Global step 540 Train loss 0.070328 on epoch=67
06/02/2022 00:31:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.020227 on epoch=68
06/02/2022 00:31:36 - INFO - __main__ - Global step 550 Train loss 0.044685 Classification-F1 0.5635334234060349 on epoch=68
06/02/2022 00:31:41 - INFO - __main__ - Step 560 Global step 560 Train loss 0.037071 on epoch=69
06/02/2022 00:31:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.040112 on epoch=71
06/02/2022 00:31:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.013045 on epoch=72
06/02/2022 00:31:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.014850 on epoch=73
06/02/2022 00:32:02 - INFO - __main__ - Step 600 Global step 600 Train loss 0.008959 on epoch=74
06/02/2022 00:32:03 - INFO - __main__ - Global step 600 Train loss 0.022807 Classification-F1 0.4445374952417206 on epoch=74
06/02/2022 00:32:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.037709 on epoch=76
06/02/2022 00:32:13 - INFO - __main__ - Step 620 Global step 620 Train loss 0.011101 on epoch=77
06/02/2022 00:32:18 - INFO - __main__ - Step 630 Global step 630 Train loss 0.010474 on epoch=78
06/02/2022 00:32:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.014377 on epoch=79
06/02/2022 00:32:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.008990 on epoch=81
06/02/2022 00:32:30 - INFO - __main__ - Global step 650 Train loss 0.016530 Classification-F1 0.5148394479010227 on epoch=81
06/02/2022 00:32:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.007122 on epoch=82
06/02/2022 00:32:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.007204 on epoch=83
06/02/2022 00:32:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.015423 on epoch=84
06/02/2022 00:32:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.007951 on epoch=86
06/02/2022 00:32:56 - INFO - __main__ - Step 700 Global step 700 Train loss 0.005710 on epoch=87
06/02/2022 00:32:58 - INFO - __main__ - Global step 700 Train loss 0.008682 Classification-F1 0.46777546777546775 on epoch=87
06/02/2022 00:33:03 - INFO - __main__ - Step 710 Global step 710 Train loss 0.004766 on epoch=88
06/02/2022 00:33:08 - INFO - __main__ - Step 720 Global step 720 Train loss 0.008655 on epoch=89
06/02/2022 00:33:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.007675 on epoch=91
06/02/2022 00:33:18 - INFO - __main__ - Step 740 Global step 740 Train loss 0.003149 on epoch=92
06/02/2022 00:33:23 - INFO - __main__ - Step 750 Global step 750 Train loss 0.010659 on epoch=93
06/02/2022 00:33:25 - INFO - __main__ - Global step 750 Train loss 0.006981 Classification-F1 0.46777546777546775 on epoch=93
06/02/2022 00:33:30 - INFO - __main__ - Step 760 Global step 760 Train loss 0.002494 on epoch=94
06/02/2022 00:33:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.012549 on epoch=96
06/02/2022 00:33:40 - INFO - __main__ - Step 780 Global step 780 Train loss 0.003571 on epoch=97
06/02/2022 00:33:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000803 on epoch=98
06/02/2022 00:33:51 - INFO - __main__ - Step 800 Global step 800 Train loss 0.002027 on epoch=99
06/02/2022 00:33:52 - INFO - __main__ - Global step 800 Train loss 0.004289 Classification-F1 0.5993339993339992 on epoch=99
06/02/2022 00:33:57 - INFO - __main__ - Step 810 Global step 810 Train loss 0.002517 on epoch=101
06/02/2022 00:34:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.001029 on epoch=102
06/02/2022 00:34:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.011105 on epoch=103
06/02/2022 00:34:13 - INFO - __main__ - Step 840 Global step 840 Train loss 0.001417 on epoch=104
06/02/2022 00:34:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000545 on epoch=106
06/02/2022 00:34:19 - INFO - __main__ - Global step 850 Train loss 0.003322 Classification-F1 0.5214109347442681 on epoch=106
06/02/2022 00:34:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000905 on epoch=107
06/02/2022 00:34:29 - INFO - __main__ - Step 870 Global step 870 Train loss 0.001437 on epoch=108
06/02/2022 00:34:35 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000522 on epoch=109
06/02/2022 00:34:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000528 on epoch=111
06/02/2022 00:34:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000938 on epoch=112
06/02/2022 00:34:46 - INFO - __main__ - Global step 900 Train loss 0.000866 Classification-F1 0.6031400488158849 on epoch=112
06/02/2022 00:34:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000654 on epoch=113
06/02/2022 00:34:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000241 on epoch=114
06/02/2022 00:35:02 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000575 on epoch=116
06/02/2022 00:35:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000736 on epoch=117
06/02/2022 00:35:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.001545 on epoch=118
06/02/2022 00:35:14 - INFO - __main__ - Global step 950 Train loss 0.000750 Classification-F1 0.5993339993339992 on epoch=118
06/02/2022 00:35:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.001201 on epoch=119
06/02/2022 00:35:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000807 on epoch=121
06/02/2022 00:35:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000914 on epoch=122
06/02/2022 00:35:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.001061 on epoch=123
06/02/2022 00:35:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000456 on epoch=124
06/02/2022 00:35:40 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:35:40 - INFO - __main__ - Printing 3 examples
06/02/2022 00:35:40 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/02/2022 00:35:40 - INFO - __main__ - ['false']
06/02/2022 00:35:40 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/02/2022 00:35:40 - INFO - __main__ - ['false']
06/02/2022 00:35:40 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/02/2022 00:35:40 - INFO - __main__ - ['false']
06/02/2022 00:35:40 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:35:41 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:35:41 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 00:35:41 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:35:41 - INFO - __main__ - Printing 3 examples
06/02/2022 00:35:41 - INFO - __main__ -  [wiki_qa] question: who played the drums in the band cream back in 1968 [SEP] answer: Cream's music included songs based on traditional blues such as " Crossroads " and " Spoonful ", and modern blues such as " Born Under a Bad Sign ", as well as more eccentric songs such as " Strange Brew ", " Tales of Brave Ulysses " and " Toad ".
06/02/2022 00:35:41 - INFO - __main__ - ['false']
06/02/2022 00:35:41 - INFO - __main__ -  [wiki_qa] question: who invented geothermal energy technology [SEP] answer: Forecasts for the future of geothermal power depend on assumptions about technology, energy prices, subsidies, and interest rates.
06/02/2022 00:35:41 - INFO - __main__ - ['false']
06/02/2022 00:35:41 - INFO - __main__ -  [wiki_qa] question: how did neil armstrong affect the united states [SEP] answer: Broadcast on live TV to a world-wide audience, Armstrong stepped onto the lunar surface and described the event as "one small step for [a] man, one giant leap for mankind."
06/02/2022 00:35:41 - INFO - __main__ - ['false']
06/02/2022 00:35:41 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:35:41 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:35:41 - INFO - __main__ - Global step 1000 Train loss 0.000888 Classification-F1 0.5993339993339992 on epoch=124
06/02/2022 00:35:41 - INFO - __main__ - save last model!
06/02/2022 00:35:41 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 00:35:48 - INFO - __main__ - Loading checkpoint on the fly
06/02/2022 00:35:49 - INFO - __main__ - Start tokenizing ... 2733 instances
06/02/2022 00:35:49 - INFO - __main__ - Printing 3 examples
06/02/2022 00:35:49 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/02/2022 00:35:49 - INFO - __main__ - ['false']
06/02/2022 00:35:49 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/02/2022 00:35:49 - INFO - __main__ - ['false']
06/02/2022 00:35:49 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/02/2022 00:35:49 - INFO - __main__ - ['false']
06/02/2022 00:35:49 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:35:50 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:35:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 00:35:53 - INFO - __main__ - Starting training!
06/02/2022 00:35:53 - INFO - __main__ - Loaded 2733 examples from test data
06/02/2022 00:36:22 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_21_0.0001_8_predictions.txt
06/02/2022 00:36:22 - INFO - __main__ - Classification-F1 on test data: 0.5436
06/02/2022 00:36:23 - INFO - __main__ - prefix=wiki_qa_64_21, lr=0.0001, bsz=8, dev_performance=0.6437246963562753, test_performance=0.5436195399800986
06/02/2022 00:36:23 - INFO - __main__ - Running ... prefix=wiki_qa_64_42, lr=0.0005, bsz=8 ...
06/02/2022 00:36:24 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:36:24 - INFO - __main__ - Printing 3 examples
06/02/2022 00:36:24 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/02/2022 00:36:24 - INFO - __main__ - ['false']
06/02/2022 00:36:24 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/02/2022 00:36:24 - INFO - __main__ - ['false']
06/02/2022 00:36:24 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/02/2022 00:36:24 - INFO - __main__ - ['false']
06/02/2022 00:36:24 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:36:24 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:36:24 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 00:36:24 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:36:24 - INFO - __main__ - Printing 3 examples
06/02/2022 00:36:24 - INFO - __main__ -  [wiki_qa] question: who played the drums in the band cream back in 1968 [SEP] answer: Cream's music included songs based on traditional blues such as " Crossroads " and " Spoonful ", and modern blues such as " Born Under a Bad Sign ", as well as more eccentric songs such as " Strange Brew ", " Tales of Brave Ulysses " and " Toad ".
06/02/2022 00:36:24 - INFO - __main__ - ['false']
06/02/2022 00:36:24 - INFO - __main__ -  [wiki_qa] question: who invented geothermal energy technology [SEP] answer: Forecasts for the future of geothermal power depend on assumptions about technology, energy prices, subsidies, and interest rates.
06/02/2022 00:36:24 - INFO - __main__ - ['false']
06/02/2022 00:36:24 - INFO - __main__ -  [wiki_qa] question: how did neil armstrong affect the united states [SEP] answer: Broadcast on live TV to a world-wide audience, Armstrong stepped onto the lunar surface and described the event as "one small step for [a] man, one giant leap for mankind."
06/02/2022 00:36:24 - INFO - __main__ - ['false']
06/02/2022 00:36:24 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:36:24 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:36:24 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 00:36:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 00:36:37 - INFO - __main__ - Starting training!
06/02/2022 00:36:41 - INFO - __main__ - Step 10 Global step 10 Train loss 22.719341 on epoch=1
06/02/2022 00:36:46 - INFO - __main__ - Step 20 Global step 20 Train loss 17.630476 on epoch=2
06/02/2022 00:36:51 - INFO - __main__ - Step 30 Global step 30 Train loss 15.479660 on epoch=3
06/02/2022 00:36:56 - INFO - __main__ - Step 40 Global step 40 Train loss 14.769773 on epoch=4
06/02/2022 00:37:01 - INFO - __main__ - Step 50 Global step 50 Train loss 12.565895 on epoch=6
06/02/2022 00:37:05 - INFO - __main__ - Global step 50 Train loss 16.633028 Classification-F1 0.0 on epoch=6
06/02/2022 00:37:11 - INFO - __main__ - Step 60 Global step 60 Train loss 9.274835 on epoch=7
06/02/2022 00:37:16 - INFO - __main__ - Step 70 Global step 70 Train loss 4.149750 on epoch=8
06/02/2022 00:37:21 - INFO - __main__ - Step 80 Global step 80 Train loss 1.230790 on epoch=9
06/02/2022 00:37:26 - INFO - __main__ - Step 90 Global step 90 Train loss 0.703448 on epoch=11
06/02/2022 00:37:31 - INFO - __main__ - Step 100 Global step 100 Train loss 0.555579 on epoch=12
06/02/2022 00:37:33 - INFO - __main__ - Global step 100 Train loss 3.182880 Classification-F1 0.39756367663344405 on epoch=12
06/02/2022 00:37:39 - INFO - __main__ - Step 110 Global step 110 Train loss 0.488569 on epoch=13
06/02/2022 00:37:44 - INFO - __main__ - Step 120 Global step 120 Train loss 0.510207 on epoch=14
06/02/2022 00:37:49 - INFO - __main__ - Step 130 Global step 130 Train loss 0.372027 on epoch=16
06/02/2022 00:37:54 - INFO - __main__ - Step 140 Global step 140 Train loss 0.321982 on epoch=17
06/02/2022 00:37:59 - INFO - __main__ - Step 150 Global step 150 Train loss 0.361672 on epoch=18
06/02/2022 00:38:00 - INFO - __main__ - Global step 150 Train loss 0.410892 Classification-F1 0.3860677578987438 on epoch=18
06/02/2022 00:38:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.240970 on epoch=19
06/02/2022 00:38:11 - INFO - __main__ - Step 170 Global step 170 Train loss 0.227993 on epoch=21
06/02/2022 00:38:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.180818 on epoch=22
06/02/2022 00:38:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.208555 on epoch=23
06/02/2022 00:38:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.069621 on epoch=24
06/02/2022 00:38:27 - INFO - __main__ - Global step 200 Train loss 0.185592 Classification-F1 0.5696139476961395 on epoch=24
06/02/2022 00:38:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.070358 on epoch=26
06/02/2022 00:38:38 - INFO - __main__ - Step 220 Global step 220 Train loss 0.035600 on epoch=27
06/02/2022 00:38:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.034101 on epoch=28
06/02/2022 00:38:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.015109 on epoch=29
06/02/2022 00:38:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.023320 on epoch=31
06/02/2022 00:38:55 - INFO - __main__ - Global step 250 Train loss 0.035697 Classification-F1 0.5789473684210527 on epoch=31
06/02/2022 00:39:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.016368 on epoch=32
06/02/2022 00:39:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.004763 on epoch=33
06/02/2022 00:39:11 - INFO - __main__ - Step 280 Global step 280 Train loss 0.002588 on epoch=34
06/02/2022 00:39:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.002876 on epoch=36
06/02/2022 00:39:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.027656 on epoch=37
06/02/2022 00:39:22 - INFO - __main__ - Global step 300 Train loss 0.010850 Classification-F1 0.5397188623733247 on epoch=37
06/02/2022 00:39:27 - INFO - __main__ - Step 310 Global step 310 Train loss 0.004435 on epoch=38
06/02/2022 00:39:33 - INFO - __main__ - Step 320 Global step 320 Train loss 0.001349 on epoch=39
06/02/2022 00:39:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.007699 on epoch=41
06/02/2022 00:39:43 - INFO - __main__ - Step 340 Global step 340 Train loss 0.001408 on epoch=42
06/02/2022 00:39:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.014448 on epoch=43
06/02/2022 00:39:49 - INFO - __main__ - Global step 350 Train loss 0.005868 Classification-F1 0.5546603186229628 on epoch=43
06/02/2022 00:39:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.003424 on epoch=44
06/02/2022 00:39:59 - INFO - __main__ - Step 370 Global step 370 Train loss 0.000708 on epoch=46
06/02/2022 00:40:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.000572 on epoch=47
06/02/2022 00:40:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.000865 on epoch=48
06/02/2022 00:40:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.000773 on epoch=49
06/02/2022 00:40:16 - INFO - __main__ - Global step 400 Train loss 0.001268 Classification-F1 0.5936507936507938 on epoch=49
06/02/2022 00:40:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.000687 on epoch=51
06/02/2022 00:40:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.000704 on epoch=52
06/02/2022 00:40:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.000301 on epoch=53
06/02/2022 00:40:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.000449 on epoch=54
06/02/2022 00:40:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.000277 on epoch=56
06/02/2022 00:40:43 - INFO - __main__ - Global step 450 Train loss 0.000484 Classification-F1 0.6103137620379 on epoch=56
06/02/2022 00:40:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.001130 on epoch=57
06/02/2022 00:40:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.000263 on epoch=58
06/02/2022 00:40:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.000560 on epoch=59
06/02/2022 00:41:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.000454 on epoch=61
06/02/2022 00:41:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.000104 on epoch=62
06/02/2022 00:41:11 - INFO - __main__ - Global step 500 Train loss 0.000502 Classification-F1 0.6216748768472906 on epoch=62
06/02/2022 00:41:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.000420 on epoch=63
06/02/2022 00:41:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.000103 on epoch=64
06/02/2022 00:41:27 - INFO - __main__ - Step 530 Global step 530 Train loss 0.000178 on epoch=66
06/02/2022 00:41:32 - INFO - __main__ - Step 540 Global step 540 Train loss 0.000045 on epoch=67
06/02/2022 00:41:37 - INFO - __main__ - Step 550 Global step 550 Train loss 0.000119 on epoch=68
06/02/2022 00:41:38 - INFO - __main__ - Global step 550 Train loss 0.000173 Classification-F1 0.6289855072463768 on epoch=68
06/02/2022 00:41:44 - INFO - __main__ - Step 560 Global step 560 Train loss 0.000364 on epoch=69
06/02/2022 00:41:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.019345 on epoch=71
06/02/2022 00:41:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.001687 on epoch=72
06/02/2022 00:42:00 - INFO - __main__ - Step 590 Global step 590 Train loss 0.001518 on epoch=73
06/02/2022 00:42:05 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000150 on epoch=74
06/02/2022 00:42:06 - INFO - __main__ - Global step 600 Train loss 0.004613 Classification-F1 0.5928553951553707 on epoch=74
06/02/2022 00:42:12 - INFO - __main__ - Step 610 Global step 610 Train loss 0.053504 on epoch=76
06/02/2022 00:42:17 - INFO - __main__ - Step 620 Global step 620 Train loss 0.156738 on epoch=77
06/02/2022 00:42:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.131211 on epoch=78
06/02/2022 00:42:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.000778 on epoch=79
06/02/2022 00:42:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000874 on epoch=81
06/02/2022 00:42:34 - INFO - __main__ - Global step 650 Train loss 0.068621 Classification-F1 0.6333748443337484 on epoch=81
06/02/2022 00:42:40 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000879 on epoch=82
06/02/2022 00:42:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.000280 on epoch=83
06/02/2022 00:42:51 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000997 on epoch=84
06/02/2022 00:42:56 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000192 on epoch=86
06/02/2022 00:43:01 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000099 on epoch=87
06/02/2022 00:43:02 - INFO - __main__ - Global step 700 Train loss 0.000489 Classification-F1 0.6262193227710469 on epoch=87
06/02/2022 00:43:08 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000402 on epoch=88
06/02/2022 00:43:13 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000393 on epoch=89
06/02/2022 00:43:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000172 on epoch=91
06/02/2022 00:43:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.018498 on epoch=92
06/02/2022 00:43:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000318 on epoch=93
06/02/2022 00:43:30 - INFO - __main__ - Global step 750 Train loss 0.003957 Classification-F1 0.6085626911314985 on epoch=93
06/02/2022 00:43:35 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000346 on epoch=94
06/02/2022 00:43:40 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000209 on epoch=96
06/02/2022 00:43:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000109 on epoch=97
06/02/2022 00:43:51 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000057 on epoch=98
06/02/2022 00:43:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000047 on epoch=99
06/02/2022 00:43:57 - INFO - __main__ - Global step 800 Train loss 0.000153 Classification-F1 0.605911330049261 on epoch=99
06/02/2022 00:44:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000095 on epoch=101
06/02/2022 00:44:08 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000050 on epoch=102
06/02/2022 00:44:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000013 on epoch=103
06/02/2022 00:44:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000021 on epoch=104
06/02/2022 00:44:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000024 on epoch=106
06/02/2022 00:44:24 - INFO - __main__ - Global step 850 Train loss 0.000041 Classification-F1 0.59859804464121 on epoch=106
06/02/2022 00:44:29 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000065 on epoch=107
06/02/2022 00:44:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000306 on epoch=108
06/02/2022 00:44:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000031 on epoch=109
06/02/2022 00:44:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000009 on epoch=111
06/02/2022 00:44:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000037 on epoch=112
06/02/2022 00:44:51 - INFO - __main__ - Global step 900 Train loss 0.000090 Classification-F1 0.6289855072463768 on epoch=112
06/02/2022 00:44:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000006 on epoch=113
06/02/2022 00:45:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000066 on epoch=114
06/02/2022 00:45:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000052 on epoch=116
06/02/2022 00:45:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000028 on epoch=117
06/02/2022 00:45:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000059 on epoch=118
06/02/2022 00:45:18 - INFO - __main__ - Global step 950 Train loss 0.000042 Classification-F1 0.6245397241465394 on epoch=118
06/02/2022 00:45:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000238 on epoch=119
06/02/2022 00:45:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000013 on epoch=121
06/02/2022 00:45:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000054 on epoch=122
06/02/2022 00:45:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000007 on epoch=123
06/02/2022 00:45:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000058 on epoch=124
06/02/2022 00:45:45 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:45:45 - INFO - __main__ - Printing 3 examples
06/02/2022 00:45:45 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/02/2022 00:45:45 - INFO - __main__ - ['false']
06/02/2022 00:45:45 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/02/2022 00:45:45 - INFO - __main__ - ['false']
06/02/2022 00:45:45 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/02/2022 00:45:45 - INFO - __main__ - ['false']
06/02/2022 00:45:45 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:45:45 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:45:45 - INFO - __main__ - Global step 1000 Train loss 0.000074 Classification-F1 0.6190476190476191 on epoch=124
06/02/2022 00:45:45 - INFO - __main__ - save last model!
06/02/2022 00:45:45 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 00:45:45 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:45:45 - INFO - __main__ - Printing 3 examples
06/02/2022 00:45:45 - INFO - __main__ -  [wiki_qa] question: who played the drums in the band cream back in 1968 [SEP] answer: Cream's music included songs based on traditional blues such as " Crossroads " and " Spoonful ", and modern blues such as " Born Under a Bad Sign ", as well as more eccentric songs such as " Strange Brew ", " Tales of Brave Ulysses " and " Toad ".
06/02/2022 00:45:45 - INFO - __main__ - ['false']
06/02/2022 00:45:45 - INFO - __main__ -  [wiki_qa] question: who invented geothermal energy technology [SEP] answer: Forecasts for the future of geothermal power depend on assumptions about technology, energy prices, subsidies, and interest rates.
06/02/2022 00:45:45 - INFO - __main__ - ['false']
06/02/2022 00:45:45 - INFO - __main__ -  [wiki_qa] question: how did neil armstrong affect the united states [SEP] answer: Broadcast on live TV to a world-wide audience, Armstrong stepped onto the lunar surface and described the event as "one small step for [a] man, one giant leap for mankind."
06/02/2022 00:45:45 - INFO - __main__ - ['false']
06/02/2022 00:45:45 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:45:45 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:45:45 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 00:45:52 - INFO - __main__ - Loading checkpoint on the fly
06/02/2022 00:45:53 - INFO - __main__ - Start tokenizing ... 2733 instances
06/02/2022 00:45:53 - INFO - __main__ - Printing 3 examples
06/02/2022 00:45:53 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/02/2022 00:45:53 - INFO - __main__ - ['false']
06/02/2022 00:45:53 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/02/2022 00:45:53 - INFO - __main__ - ['false']
06/02/2022 00:45:53 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/02/2022 00:45:53 - INFO - __main__ - ['false']
06/02/2022 00:45:53 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:45:54 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:45:57 - INFO - __main__ - Loaded 2733 examples from test data
06/02/2022 00:45:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 00:45:58 - INFO - __main__ - Starting training!
06/02/2022 00:46:27 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_42_0.0005_8_predictions.txt
06/02/2022 00:46:27 - INFO - __main__ - Classification-F1 on test data: 0.1988
06/02/2022 00:46:28 - INFO - __main__ - prefix=wiki_qa_64_42, lr=0.0005, bsz=8, dev_performance=0.6333748443337484, test_performance=0.1987508296197971
06/02/2022 00:46:28 - INFO - __main__ - Running ... prefix=wiki_qa_64_42, lr=0.0003, bsz=8 ...
06/02/2022 00:46:28 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:46:28 - INFO - __main__ - Printing 3 examples
06/02/2022 00:46:28 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/02/2022 00:46:28 - INFO - __main__ - ['false']
06/02/2022 00:46:28 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/02/2022 00:46:28 - INFO - __main__ - ['false']
06/02/2022 00:46:28 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/02/2022 00:46:28 - INFO - __main__ - ['false']
06/02/2022 00:46:28 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:46:29 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:46:29 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 00:46:29 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:46:29 - INFO - __main__ - Printing 3 examples
06/02/2022 00:46:29 - INFO - __main__ -  [wiki_qa] question: who played the drums in the band cream back in 1968 [SEP] answer: Cream's music included songs based on traditional blues such as " Crossroads " and " Spoonful ", and modern blues such as " Born Under a Bad Sign ", as well as more eccentric songs such as " Strange Brew ", " Tales of Brave Ulysses " and " Toad ".
06/02/2022 00:46:29 - INFO - __main__ - ['false']
06/02/2022 00:46:29 - INFO - __main__ -  [wiki_qa] question: who invented geothermal energy technology [SEP] answer: Forecasts for the future of geothermal power depend on assumptions about technology, energy prices, subsidies, and interest rates.
06/02/2022 00:46:29 - INFO - __main__ - ['false']
06/02/2022 00:46:29 - INFO - __main__ -  [wiki_qa] question: how did neil armstrong affect the united states [SEP] answer: Broadcast on live TV to a world-wide audience, Armstrong stepped onto the lunar surface and described the event as "one small step for [a] man, one giant leap for mankind."
06/02/2022 00:46:29 - INFO - __main__ - ['false']
06/02/2022 00:46:29 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:46:29 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:46:29 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 00:46:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 00:46:40 - INFO - __main__ - Starting training!
06/02/2022 00:46:44 - INFO - __main__ - Step 10 Global step 10 Train loss 22.265636 on epoch=1
06/02/2022 00:46:49 - INFO - __main__ - Step 20 Global step 20 Train loss 19.229160 on epoch=2
06/02/2022 00:46:54 - INFO - __main__ - Step 30 Global step 30 Train loss 16.771587 on epoch=3
06/02/2022 00:46:59 - INFO - __main__ - Step 40 Global step 40 Train loss 15.654318 on epoch=4
06/02/2022 00:47:04 - INFO - __main__ - Step 50 Global step 50 Train loss 14.188507 on epoch=6
06/02/2022 00:47:13 - INFO - __main__ - Global step 50 Train loss 17.621841 Classification-F1 0.0 on epoch=6
06/02/2022 00:47:18 - INFO - __main__ - Step 60 Global step 60 Train loss 13.081546 on epoch=7
06/02/2022 00:47:24 - INFO - __main__ - Step 70 Global step 70 Train loss 12.743953 on epoch=8
06/02/2022 00:47:29 - INFO - __main__ - Step 80 Global step 80 Train loss 6.197400 on epoch=9
06/02/2022 00:47:34 - INFO - __main__ - Step 90 Global step 90 Train loss 3.561599 on epoch=11
06/02/2022 00:47:39 - INFO - __main__ - Step 100 Global step 100 Train loss 0.774269 on epoch=12
06/02/2022 00:47:40 - INFO - __main__ - Global step 100 Train loss 7.271753 Classification-F1 0.5141221128482274 on epoch=12
06/02/2022 00:47:46 - INFO - __main__ - Step 110 Global step 110 Train loss 0.590591 on epoch=13
06/02/2022 00:47:51 - INFO - __main__ - Step 120 Global step 120 Train loss 0.454461 on epoch=14
06/02/2022 00:47:56 - INFO - __main__ - Step 130 Global step 130 Train loss 0.477762 on epoch=16
06/02/2022 00:48:01 - INFO - __main__ - Step 140 Global step 140 Train loss 0.486923 on epoch=17
06/02/2022 00:48:06 - INFO - __main__ - Step 150 Global step 150 Train loss 0.432286 on epoch=18
06/02/2022 00:48:07 - INFO - __main__ - Global step 150 Train loss 0.488404 Classification-F1 0.3333333333333333 on epoch=18
06/02/2022 00:48:12 - INFO - __main__ - Step 160 Global step 160 Train loss 0.406913 on epoch=19
06/02/2022 00:48:17 - INFO - __main__ - Step 170 Global step 170 Train loss 0.445417 on epoch=21
06/02/2022 00:48:22 - INFO - __main__ - Step 180 Global step 180 Train loss 0.365481 on epoch=22
06/02/2022 00:48:27 - INFO - __main__ - Step 190 Global step 190 Train loss 0.319351 on epoch=23
06/02/2022 00:48:32 - INFO - __main__ - Step 200 Global step 200 Train loss 0.312855 on epoch=24
06/02/2022 00:48:34 - INFO - __main__ - Global step 200 Train loss 0.370003 Classification-F1 0.6044150110375275 on epoch=24
06/02/2022 00:48:40 - INFO - __main__ - Step 210 Global step 210 Train loss 0.299735 on epoch=26
06/02/2022 00:48:45 - INFO - __main__ - Step 220 Global step 220 Train loss 0.296642 on epoch=27
06/02/2022 00:48:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.271765 on epoch=28
06/02/2022 00:48:55 - INFO - __main__ - Step 240 Global step 240 Train loss 0.122857 on epoch=29
06/02/2022 00:49:00 - INFO - __main__ - Step 250 Global step 250 Train loss 0.150357 on epoch=31
06/02/2022 00:49:01 - INFO - __main__ - Global step 250 Train loss 0.228271 Classification-F1 0.6333748443337484 on epoch=31
06/02/2022 00:49:07 - INFO - __main__ - Step 260 Global step 260 Train loss 0.104857 on epoch=32
06/02/2022 00:49:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.185882 on epoch=33
06/02/2022 00:49:17 - INFO - __main__ - Step 280 Global step 280 Train loss 0.105614 on epoch=34
06/02/2022 00:49:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.053630 on epoch=36
06/02/2022 00:49:27 - INFO - __main__ - Step 300 Global step 300 Train loss 0.081486 on epoch=37
06/02/2022 00:49:29 - INFO - __main__ - Global step 300 Train loss 0.106294 Classification-F1 0.6559139784946237 on epoch=37
06/02/2022 00:49:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.014554 on epoch=38
06/02/2022 00:49:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.018226 on epoch=39
06/02/2022 00:49:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.013001 on epoch=41
06/02/2022 00:49:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.011420 on epoch=42
06/02/2022 00:49:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.016410 on epoch=43
06/02/2022 00:49:56 - INFO - __main__ - Global step 350 Train loss 0.014722 Classification-F1 0.6577540106951872 on epoch=43
06/02/2022 00:50:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.006877 on epoch=44
06/02/2022 00:50:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.002845 on epoch=46
06/02/2022 00:50:12 - INFO - __main__ - Step 380 Global step 380 Train loss 0.010998 on epoch=47
06/02/2022 00:50:17 - INFO - __main__ - Step 390 Global step 390 Train loss 0.003609 on epoch=48
06/02/2022 00:50:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.001626 on epoch=49
06/02/2022 00:50:23 - INFO - __main__ - Global step 400 Train loss 0.005191 Classification-F1 0.7044248892217437 on epoch=49
06/02/2022 00:50:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.000687 on epoch=51
06/02/2022 00:50:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.003124 on epoch=52
06/02/2022 00:50:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.000837 on epoch=53
06/02/2022 00:50:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.002963 on epoch=54
06/02/2022 00:50:49 - INFO - __main__ - Step 450 Global step 450 Train loss 0.002270 on epoch=56
06/02/2022 00:50:51 - INFO - __main__ - Global step 450 Train loss 0.001976 Classification-F1 0.6017316017316017 on epoch=56
06/02/2022 00:50:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.005855 on epoch=57
06/02/2022 00:51:01 - INFO - __main__ - Step 470 Global step 470 Train loss 0.003629 on epoch=58
06/02/2022 00:51:06 - INFO - __main__ - Step 480 Global step 480 Train loss 0.002014 on epoch=59
06/02/2022 00:51:11 - INFO - __main__ - Step 490 Global step 490 Train loss 0.002064 on epoch=61
06/02/2022 00:51:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.003980 on epoch=62
06/02/2022 00:51:18 - INFO - __main__ - Global step 500 Train loss 0.003508 Classification-F1 0.6618867924528302 on epoch=62
06/02/2022 00:51:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.002310 on epoch=63
06/02/2022 00:51:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.000459 on epoch=64
06/02/2022 00:51:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.000471 on epoch=66
06/02/2022 00:51:38 - INFO - __main__ - Step 540 Global step 540 Train loss 0.000291 on epoch=67
06/02/2022 00:51:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.001973 on epoch=68
06/02/2022 00:51:44 - INFO - __main__ - Global step 550 Train loss 0.001101 Classification-F1 0.7028347996089932 on epoch=68
06/02/2022 00:51:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.001220 on epoch=69
06/02/2022 00:51:54 - INFO - __main__ - Step 570 Global step 570 Train loss 0.000447 on epoch=71
06/02/2022 00:52:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.001048 on epoch=72
06/02/2022 00:52:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.001067 on epoch=73
06/02/2022 00:52:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.004259 on epoch=74
06/02/2022 00:52:11 - INFO - __main__ - Global step 600 Train loss 0.001608 Classification-F1 0.6739360049704877 on epoch=74
06/02/2022 00:52:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.009075 on epoch=76
06/02/2022 00:52:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.004938 on epoch=77
06/02/2022 00:52:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.000878 on epoch=78
06/02/2022 00:52:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.001231 on epoch=79
06/02/2022 00:52:36 - INFO - __main__ - Step 650 Global step 650 Train loss 0.006200 on epoch=81
06/02/2022 00:52:38 - INFO - __main__ - Global step 650 Train loss 0.004464 Classification-F1 0.414981077906825 on epoch=81
06/02/2022 00:52:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000306 on epoch=82
06/02/2022 00:52:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.004049 on epoch=83
06/02/2022 00:52:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000336 on epoch=84
06/02/2022 00:52:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.001223 on epoch=86
06/02/2022 00:53:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000141 on epoch=87
06/02/2022 00:53:05 - INFO - __main__ - Global step 700 Train loss 0.001211 Classification-F1 0.6763490595127968 on epoch=87
06/02/2022 00:53:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000042 on epoch=88
06/02/2022 00:53:15 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000042 on epoch=89
06/02/2022 00:53:20 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000034 on epoch=91
06/02/2022 00:53:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000035 on epoch=92
06/02/2022 00:53:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.001618 on epoch=93
06/02/2022 00:53:31 - INFO - __main__ - Global step 750 Train loss 0.000354 Classification-F1 0.6623934245230939 on epoch=93
06/02/2022 00:53:36 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000283 on epoch=94
06/02/2022 00:53:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000068 on epoch=96
06/02/2022 00:53:47 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000059 on epoch=97
06/02/2022 00:53:52 - INFO - __main__ - Step 790 Global step 790 Train loss 0.022709 on epoch=98
06/02/2022 00:53:57 - INFO - __main__ - Step 800 Global step 800 Train loss 0.026072 on epoch=99
06/02/2022 00:53:58 - INFO - __main__ - Global step 800 Train loss 0.009838 Classification-F1 0.5833333333333334 on epoch=99
06/02/2022 00:54:03 - INFO - __main__ - Step 810 Global step 810 Train loss 0.089976 on epoch=101
06/02/2022 00:54:08 - INFO - __main__ - Step 820 Global step 820 Train loss 0.003534 on epoch=102
06/02/2022 00:54:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000434 on epoch=103
06/02/2022 00:54:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000308 on epoch=104
06/02/2022 00:54:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000035 on epoch=106
06/02/2022 00:54:25 - INFO - __main__ - Global step 850 Train loss 0.018858 Classification-F1 0.6541390321788259 on epoch=106
06/02/2022 00:54:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000190 on epoch=107
06/02/2022 00:54:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000066 on epoch=108
06/02/2022 00:54:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000274 on epoch=109
06/02/2022 00:54:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000354 on epoch=111
06/02/2022 00:54:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000520 on epoch=112
06/02/2022 00:54:51 - INFO - __main__ - Global step 900 Train loss 0.000281 Classification-F1 0.6387129147588283 on epoch=112
06/02/2022 00:54:57 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000044 on epoch=113
06/02/2022 00:55:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000027 on epoch=114
06/02/2022 00:55:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000012 on epoch=116
06/02/2022 00:55:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000050 on epoch=117
06/02/2022 00:55:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000021 on epoch=118
06/02/2022 00:55:18 - INFO - __main__ - Global step 950 Train loss 0.000031 Classification-F1 0.6541390321788259 on epoch=118
06/02/2022 00:55:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000019 on epoch=119
06/02/2022 00:55:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000018 on epoch=121
06/02/2022 00:55:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000017 on epoch=122
06/02/2022 00:55:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000030 on epoch=123
06/02/2022 00:55:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000064 on epoch=124
06/02/2022 00:55:45 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:55:45 - INFO - __main__ - Printing 3 examples
06/02/2022 00:55:45 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/02/2022 00:55:45 - INFO - __main__ - ['false']
06/02/2022 00:55:45 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/02/2022 00:55:45 - INFO - __main__ - ['false']
06/02/2022 00:55:45 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/02/2022 00:55:45 - INFO - __main__ - ['false']
06/02/2022 00:55:45 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:55:45 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:55:45 - INFO - __main__ - Global step 1000 Train loss 0.000030 Classification-F1 0.6541390321788259 on epoch=124
06/02/2022 00:55:45 - INFO - __main__ - save last model!
06/02/2022 00:55:45 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 00:55:45 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:55:45 - INFO - __main__ - Printing 3 examples
06/02/2022 00:55:45 - INFO - __main__ -  [wiki_qa] question: who played the drums in the band cream back in 1968 [SEP] answer: Cream's music included songs based on traditional blues such as " Crossroads " and " Spoonful ", and modern blues such as " Born Under a Bad Sign ", as well as more eccentric songs such as " Strange Brew ", " Tales of Brave Ulysses " and " Toad ".
06/02/2022 00:55:45 - INFO - __main__ - ['false']
06/02/2022 00:55:45 - INFO - __main__ -  [wiki_qa] question: who invented geothermal energy technology [SEP] answer: Forecasts for the future of geothermal power depend on assumptions about technology, energy prices, subsidies, and interest rates.
06/02/2022 00:55:45 - INFO - __main__ - ['false']
06/02/2022 00:55:45 - INFO - __main__ -  [wiki_qa] question: how did neil armstrong affect the united states [SEP] answer: Broadcast on live TV to a world-wide audience, Armstrong stepped onto the lunar surface and described the event as "one small step for [a] man, one giant leap for mankind."
06/02/2022 00:55:45 - INFO - __main__ - ['false']
06/02/2022 00:55:45 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:55:45 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:55:45 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 00:55:52 - INFO - __main__ - Loading checkpoint on the fly
06/02/2022 00:55:53 - INFO - __main__ - Start tokenizing ... 2733 instances
06/02/2022 00:55:53 - INFO - __main__ - Printing 3 examples
06/02/2022 00:55:53 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/02/2022 00:55:53 - INFO - __main__ - ['false']
06/02/2022 00:55:53 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/02/2022 00:55:53 - INFO - __main__ - ['false']
06/02/2022 00:55:53 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/02/2022 00:55:53 - INFO - __main__ - ['false']
06/02/2022 00:55:53 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:55:54 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:55:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 00:55:57 - INFO - __main__ - Starting training!
06/02/2022 00:55:57 - INFO - __main__ - Loaded 2733 examples from test data
06/02/2022 00:56:26 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_42_0.0003_8_predictions.txt
06/02/2022 00:56:26 - INFO - __main__ - Classification-F1 on test data: 0.3717
06/02/2022 00:56:26 - INFO - __main__ - prefix=wiki_qa_64_42, lr=0.0003, bsz=8, dev_performance=0.7044248892217437, test_performance=0.37170524717458386
06/02/2022 00:56:26 - INFO - __main__ - Running ... prefix=wiki_qa_64_42, lr=0.0002, bsz=8 ...
06/02/2022 00:56:27 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:56:27 - INFO - __main__ - Printing 3 examples
06/02/2022 00:56:27 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/02/2022 00:56:27 - INFO - __main__ - ['false']
06/02/2022 00:56:27 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/02/2022 00:56:27 - INFO - __main__ - ['false']
06/02/2022 00:56:27 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/02/2022 00:56:27 - INFO - __main__ - ['false']
06/02/2022 00:56:27 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:56:27 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:56:27 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 00:56:27 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 00:56:27 - INFO - __main__ - Printing 3 examples
06/02/2022 00:56:27 - INFO - __main__ -  [wiki_qa] question: who played the drums in the band cream back in 1968 [SEP] answer: Cream's music included songs based on traditional blues such as " Crossroads " and " Spoonful ", and modern blues such as " Born Under a Bad Sign ", as well as more eccentric songs such as " Strange Brew ", " Tales of Brave Ulysses " and " Toad ".
06/02/2022 00:56:27 - INFO - __main__ - ['false']
06/02/2022 00:56:27 - INFO - __main__ -  [wiki_qa] question: who invented geothermal energy technology [SEP] answer: Forecasts for the future of geothermal power depend on assumptions about technology, energy prices, subsidies, and interest rates.
06/02/2022 00:56:27 - INFO - __main__ - ['false']
06/02/2022 00:56:27 - INFO - __main__ -  [wiki_qa] question: how did neil armstrong affect the united states [SEP] answer: Broadcast on live TV to a world-wide audience, Armstrong stepped onto the lunar surface and described the event as "one small step for [a] man, one giant leap for mankind."
06/02/2022 00:56:27 - INFO - __main__ - ['false']
06/02/2022 00:56:27 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:56:27 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:56:27 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 00:56:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 00:56:40 - INFO - __main__ - Starting training!
06/02/2022 00:56:44 - INFO - __main__ - Step 10 Global step 10 Train loss 23.390844 on epoch=1
06/02/2022 00:56:49 - INFO - __main__ - Step 20 Global step 20 Train loss 19.226309 on epoch=2
06/02/2022 00:56:54 - INFO - __main__ - Step 30 Global step 30 Train loss 18.488712 on epoch=3
06/02/2022 00:56:59 - INFO - __main__ - Step 40 Global step 40 Train loss 16.734243 on epoch=4
06/02/2022 00:57:04 - INFO - __main__ - Step 50 Global step 50 Train loss 16.937201 on epoch=6
06/02/2022 00:57:06 - INFO - __main__ - Global step 50 Train loss 18.955462 Classification-F1 0.0 on epoch=6
06/02/2022 00:57:12 - INFO - __main__ - Step 60 Global step 60 Train loss 15.670265 on epoch=7
06/02/2022 00:57:17 - INFO - __main__ - Step 70 Global step 70 Train loss 14.815973 on epoch=8
06/02/2022 00:57:22 - INFO - __main__ - Step 80 Global step 80 Train loss 14.206095 on epoch=9
06/02/2022 00:57:27 - INFO - __main__ - Step 90 Global step 90 Train loss 12.862152 on epoch=11
06/02/2022 00:57:32 - INFO - __main__ - Step 100 Global step 100 Train loss 11.522202 on epoch=12
06/02/2022 00:57:35 - INFO - __main__ - Global step 100 Train loss 13.815337 Classification-F1 0.0 on epoch=12
06/02/2022 00:57:40 - INFO - __main__ - Step 110 Global step 110 Train loss 10.867790 on epoch=13
06/02/2022 00:57:45 - INFO - __main__ - Step 120 Global step 120 Train loss 3.776180 on epoch=14
06/02/2022 00:57:50 - INFO - __main__ - Step 130 Global step 130 Train loss 0.672235 on epoch=16
06/02/2022 00:57:55 - INFO - __main__ - Step 140 Global step 140 Train loss 0.530249 on epoch=17
06/02/2022 00:58:00 - INFO - __main__ - Step 150 Global step 150 Train loss 0.415981 on epoch=18
06/02/2022 00:58:01 - INFO - __main__ - Global step 150 Train loss 3.252487 Classification-F1 0.3333333333333333 on epoch=18
06/02/2022 00:58:07 - INFO - __main__ - Step 160 Global step 160 Train loss 0.503647 on epoch=19
06/02/2022 00:58:12 - INFO - __main__ - Step 170 Global step 170 Train loss 0.386175 on epoch=21
06/02/2022 00:58:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.361154 on epoch=22
06/02/2022 00:58:22 - INFO - __main__ - Step 190 Global step 190 Train loss 0.315523 on epoch=23
06/02/2022 00:58:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.338378 on epoch=24
06/02/2022 00:58:29 - INFO - __main__ - Global step 200 Train loss 0.380975 Classification-F1 0.39047619047619053 on epoch=24
06/02/2022 00:58:34 - INFO - __main__ - Step 210 Global step 210 Train loss 0.341999 on epoch=26
06/02/2022 00:58:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.284134 on epoch=27
06/02/2022 00:58:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.270274 on epoch=28
06/02/2022 00:58:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.260294 on epoch=29
06/02/2022 00:58:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.233102 on epoch=31
06/02/2022 00:58:56 - INFO - __main__ - Global step 250 Train loss 0.277961 Classification-F1 0.533264533883729 on epoch=31
06/02/2022 00:59:02 - INFO - __main__ - Step 260 Global step 260 Train loss 0.181592 on epoch=32
06/02/2022 00:59:07 - INFO - __main__ - Step 270 Global step 270 Train loss 0.251669 on epoch=33
06/02/2022 00:59:12 - INFO - __main__ - Step 280 Global step 280 Train loss 0.200435 on epoch=34
06/02/2022 00:59:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.183483 on epoch=36
06/02/2022 00:59:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.125238 on epoch=37
06/02/2022 00:59:23 - INFO - __main__ - Global step 300 Train loss 0.188483 Classification-F1 0.6225641025641027 on epoch=37
06/02/2022 00:59:29 - INFO - __main__ - Step 310 Global step 310 Train loss 0.163529 on epoch=38
06/02/2022 00:59:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.103429 on epoch=39
06/02/2022 00:59:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.074266 on epoch=41
06/02/2022 00:59:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.044292 on epoch=42
06/02/2022 00:59:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.050366 on epoch=43
06/02/2022 00:59:51 - INFO - __main__ - Global step 350 Train loss 0.087177 Classification-F1 0.6435422984095551 on epoch=43
06/02/2022 00:59:56 - INFO - __main__ - Step 360 Global step 360 Train loss 0.035492 on epoch=44
06/02/2022 01:00:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.070595 on epoch=46
06/02/2022 01:00:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.023169 on epoch=47
06/02/2022 01:00:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.078937 on epoch=48
06/02/2022 01:00:17 - INFO - __main__ - Step 400 Global step 400 Train loss 0.013648 on epoch=49
06/02/2022 01:00:19 - INFO - __main__ - Global step 400 Train loss 0.044368 Classification-F1 0.6157138294474608 on epoch=49
06/02/2022 01:00:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.020025 on epoch=51
06/02/2022 01:00:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.006119 on epoch=52
06/02/2022 01:00:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.003773 on epoch=53
06/02/2022 01:00:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.015116 on epoch=54
06/02/2022 01:00:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.006098 on epoch=56
06/02/2022 01:00:45 - INFO - __main__ - Global step 450 Train loss 0.010226 Classification-F1 0.6528539892778304 on epoch=56
06/02/2022 01:00:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.005257 on epoch=57
06/02/2022 01:00:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.003083 on epoch=58
06/02/2022 01:01:02 - INFO - __main__ - Step 480 Global step 480 Train loss 0.005062 on epoch=59
06/02/2022 01:01:07 - INFO - __main__ - Step 490 Global step 490 Train loss 0.010442 on epoch=61
06/02/2022 01:01:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.009060 on epoch=62
06/02/2022 01:01:23 - INFO - __main__ - Global step 500 Train loss 0.006581 Classification-F1 0.43635684957073534 on epoch=62
06/02/2022 01:01:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.007127 on epoch=63
06/02/2022 01:01:33 - INFO - __main__ - Step 520 Global step 520 Train loss 0.021716 on epoch=64
06/02/2022 01:01:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.005573 on epoch=66
06/02/2022 01:01:43 - INFO - __main__ - Step 540 Global step 540 Train loss 0.002056 on epoch=67
06/02/2022 01:01:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.000476 on epoch=68
06/02/2022 01:01:50 - INFO - __main__ - Global step 550 Train loss 0.007390 Classification-F1 0.6333748443337484 on epoch=68
06/02/2022 01:01:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.002274 on epoch=69
06/02/2022 01:02:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.002629 on epoch=71
06/02/2022 01:02:05 - INFO - __main__ - Step 580 Global step 580 Train loss 0.009141 on epoch=72
06/02/2022 01:02:10 - INFO - __main__ - Step 590 Global step 590 Train loss 0.005438 on epoch=73
06/02/2022 01:02:15 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000480 on epoch=74
06/02/2022 01:02:26 - INFO - __main__ - Global step 600 Train loss 0.003992 Classification-F1 0.4381156857792372 on epoch=74
06/02/2022 01:02:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.003179 on epoch=76
06/02/2022 01:02:36 - INFO - __main__ - Step 620 Global step 620 Train loss 0.005189 on epoch=77
06/02/2022 01:02:41 - INFO - __main__ - Step 630 Global step 630 Train loss 0.008730 on epoch=78
06/02/2022 01:02:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.004571 on epoch=79
06/02/2022 01:02:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.001426 on epoch=81
06/02/2022 01:03:02 - INFO - __main__ - Global step 650 Train loss 0.004619 Classification-F1 0.3991193991193991 on epoch=81
06/02/2022 01:03:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000857 on epoch=82
06/02/2022 01:03:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.000836 on epoch=83
06/02/2022 01:03:18 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000357 on epoch=84
06/02/2022 01:03:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000235 on epoch=86
06/02/2022 01:03:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000225 on epoch=87
06/02/2022 01:03:39 - INFO - __main__ - Global step 700 Train loss 0.000502 Classification-F1 0.42134143767675486 on epoch=87
06/02/2022 01:03:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000463 on epoch=88
06/02/2022 01:03:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000267 on epoch=89
06/02/2022 01:03:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.001042 on epoch=91
06/02/2022 01:04:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.008580 on epoch=92
06/02/2022 01:04:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000434 on epoch=93
06/02/2022 01:04:16 - INFO - __main__ - Global step 750 Train loss 0.002157 Classification-F1 0.41523809523809524 on epoch=93
06/02/2022 01:04:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.001326 on epoch=94
06/02/2022 01:04:26 - INFO - __main__ - Step 770 Global step 770 Train loss 0.028897 on epoch=96
06/02/2022 01:04:31 - INFO - __main__ - Step 780 Global step 780 Train loss 0.001734 on epoch=97
06/02/2022 01:04:36 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000623 on epoch=98
06/02/2022 01:04:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000789 on epoch=99
06/02/2022 01:04:52 - INFO - __main__ - Global step 800 Train loss 0.006674 Classification-F1 0.41523809523809524 on epoch=99
06/02/2022 01:04:57 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000319 on epoch=101
06/02/2022 01:05:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000123 on epoch=102
06/02/2022 01:05:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000050 on epoch=103
06/02/2022 01:05:13 - INFO - __main__ - Step 840 Global step 840 Train loss 0.001073 on epoch=104
06/02/2022 01:05:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000593 on epoch=106
06/02/2022 01:05:29 - INFO - __main__ - Global step 850 Train loss 0.000431 Classification-F1 0.427380651679717 on epoch=106
06/02/2022 01:05:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000056 on epoch=107
06/02/2022 01:05:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000042 on epoch=108
06/02/2022 01:05:44 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000241 on epoch=109
06/02/2022 01:05:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.002932 on epoch=111
06/02/2022 01:05:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.002113 on epoch=112
06/02/2022 01:06:05 - INFO - __main__ - Global step 900 Train loss 0.001077 Classification-F1 0.4306369188582824 on epoch=112
06/02/2022 01:06:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000233 on epoch=113
06/02/2022 01:06:15 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000238 on epoch=114
06/02/2022 01:06:21 - INFO - __main__ - Step 930 Global step 930 Train loss 0.012907 on epoch=116
06/02/2022 01:06:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000050 on epoch=117
06/02/2022 01:06:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000434 on epoch=118
06/02/2022 01:06:42 - INFO - __main__ - Global step 950 Train loss 0.002772 Classification-F1 0.43635684957073534 on epoch=118
06/02/2022 01:06:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000152 on epoch=119
06/02/2022 01:06:52 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000084 on epoch=121
06/02/2022 01:06:57 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000068 on epoch=122
06/02/2022 01:07:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000085 on epoch=123
06/02/2022 01:07:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000350 on epoch=124
06/02/2022 01:07:09 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:07:09 - INFO - __main__ - Printing 3 examples
06/02/2022 01:07:09 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/02/2022 01:07:09 - INFO - __main__ - ['false']
06/02/2022 01:07:09 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/02/2022 01:07:09 - INFO - __main__ - ['false']
06/02/2022 01:07:09 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/02/2022 01:07:09 - INFO - __main__ - ['false']
06/02/2022 01:07:09 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:07:09 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:07:09 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 01:07:09 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:07:09 - INFO - __main__ - Printing 3 examples
06/02/2022 01:07:09 - INFO - __main__ -  [wiki_qa] question: who played the drums in the band cream back in 1968 [SEP] answer: Cream's music included songs based on traditional blues such as " Crossroads " and " Spoonful ", and modern blues such as " Born Under a Bad Sign ", as well as more eccentric songs such as " Strange Brew ", " Tales of Brave Ulysses " and " Toad ".
06/02/2022 01:07:09 - INFO - __main__ - ['false']
06/02/2022 01:07:09 - INFO - __main__ -  [wiki_qa] question: who invented geothermal energy technology [SEP] answer: Forecasts for the future of geothermal power depend on assumptions about technology, energy prices, subsidies, and interest rates.
06/02/2022 01:07:09 - INFO - __main__ - ['false']
06/02/2022 01:07:09 - INFO - __main__ -  [wiki_qa] question: how did neil armstrong affect the united states [SEP] answer: Broadcast on live TV to a world-wide audience, Armstrong stepped onto the lunar surface and described the event as "one small step for [a] man, one giant leap for mankind."
06/02/2022 01:07:09 - INFO - __main__ - ['false']
06/02/2022 01:07:09 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:07:09 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:07:09 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 01:07:19 - INFO - __main__ - Global step 1000 Train loss 0.000148 Classification-F1 0.43210501878350427 on epoch=124
06/02/2022 01:07:19 - INFO - __main__ - save last model!
06/02/2022 01:07:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 01:07:22 - INFO - __main__ - Starting training!
06/02/2022 01:07:26 - INFO - __main__ - Loading checkpoint on the fly
06/02/2022 01:07:26 - INFO - __main__ - Start tokenizing ... 2733 instances
06/02/2022 01:07:26 - INFO - __main__ - Printing 3 examples
06/02/2022 01:07:26 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/02/2022 01:07:26 - INFO - __main__ - ['false']
06/02/2022 01:07:26 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/02/2022 01:07:26 - INFO - __main__ - ['false']
06/02/2022 01:07:26 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/02/2022 01:07:26 - INFO - __main__ - ['false']
06/02/2022 01:07:26 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:07:28 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:07:30 - INFO - __main__ - Loaded 2733 examples from test data
06/02/2022 01:07:59 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_42_0.0002_8_predictions.txt
06/02/2022 01:07:59 - INFO - __main__ - Classification-F1 on test data: 0.1805
06/02/2022 01:08:00 - INFO - __main__ - prefix=wiki_qa_64_42, lr=0.0002, bsz=8, dev_performance=0.6528539892778304, test_performance=0.18053238958412576
06/02/2022 01:08:00 - INFO - __main__ - Running ... prefix=wiki_qa_64_42, lr=0.0001, bsz=8 ...
06/02/2022 01:08:01 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:08:01 - INFO - __main__ - Printing 3 examples
06/02/2022 01:08:01 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/02/2022 01:08:01 - INFO - __main__ - ['false']
06/02/2022 01:08:01 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/02/2022 01:08:01 - INFO - __main__ - ['false']
06/02/2022 01:08:01 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/02/2022 01:08:01 - INFO - __main__ - ['false']
06/02/2022 01:08:01 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:08:01 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:08:01 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 01:08:01 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:08:01 - INFO - __main__ - Printing 3 examples
06/02/2022 01:08:01 - INFO - __main__ -  [wiki_qa] question: who played the drums in the band cream back in 1968 [SEP] answer: Cream's music included songs based on traditional blues such as " Crossroads " and " Spoonful ", and modern blues such as " Born Under a Bad Sign ", as well as more eccentric songs such as " Strange Brew ", " Tales of Brave Ulysses " and " Toad ".
06/02/2022 01:08:01 - INFO - __main__ - ['false']
06/02/2022 01:08:01 - INFO - __main__ -  [wiki_qa] question: who invented geothermal energy technology [SEP] answer: Forecasts for the future of geothermal power depend on assumptions about technology, energy prices, subsidies, and interest rates.
06/02/2022 01:08:01 - INFO - __main__ - ['false']
06/02/2022 01:08:01 - INFO - __main__ -  [wiki_qa] question: how did neil armstrong affect the united states [SEP] answer: Broadcast on live TV to a world-wide audience, Armstrong stepped onto the lunar surface and described the event as "one small step for [a] man, one giant leap for mankind."
06/02/2022 01:08:01 - INFO - __main__ - ['false']
06/02/2022 01:08:01 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:08:01 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:08:01 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 01:08:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 01:08:14 - INFO - __main__ - Starting training!
06/02/2022 01:08:18 - INFO - __main__ - Step 10 Global step 10 Train loss 23.494631 on epoch=1
06/02/2022 01:08:23 - INFO - __main__ - Step 20 Global step 20 Train loss 20.163189 on epoch=2
06/02/2022 01:08:28 - INFO - __main__ - Step 30 Global step 30 Train loss 18.558697 on epoch=3
06/02/2022 01:08:33 - INFO - __main__ - Step 40 Global step 40 Train loss 18.588795 on epoch=4
06/02/2022 01:08:38 - INFO - __main__ - Step 50 Global step 50 Train loss 17.379391 on epoch=6
06/02/2022 01:09:13 - INFO - __main__ - Global step 50 Train loss 19.636940 Classification-F1 0.0 on epoch=6
06/02/2022 01:09:18 - INFO - __main__ - Step 60 Global step 60 Train loss 17.566225 on epoch=7
06/02/2022 01:09:23 - INFO - __main__ - Step 70 Global step 70 Train loss 15.923681 on epoch=8
06/02/2022 01:09:29 - INFO - __main__ - Step 80 Global step 80 Train loss 15.849344 on epoch=9
06/02/2022 01:09:34 - INFO - __main__ - Step 90 Global step 90 Train loss 15.766237 on epoch=11
06/02/2022 01:09:39 - INFO - __main__ - Step 100 Global step 100 Train loss 14.456462 on epoch=12
06/02/2022 01:10:09 - INFO - __main__ - Global step 100 Train loss 15.912390 Classification-F1 0.0 on epoch=12
06/02/2022 01:10:14 - INFO - __main__ - Step 110 Global step 110 Train loss 14.547823 on epoch=13
06/02/2022 01:10:19 - INFO - __main__ - Step 120 Global step 120 Train loss 14.390262 on epoch=14
06/02/2022 01:10:24 - INFO - __main__ - Step 130 Global step 130 Train loss 13.595990 on epoch=16
06/02/2022 01:10:29 - INFO - __main__ - Step 140 Global step 140 Train loss 14.304225 on epoch=17
06/02/2022 01:10:35 - INFO - __main__ - Step 150 Global step 150 Train loss 13.083087 on epoch=18
06/02/2022 01:11:02 - INFO - __main__ - Global step 150 Train loss 13.984278 Classification-F1 0.0 on epoch=18
06/02/2022 01:11:07 - INFO - __main__ - Step 160 Global step 160 Train loss 12.656973 on epoch=19
06/02/2022 01:11:12 - INFO - __main__ - Step 170 Global step 170 Train loss 12.226707 on epoch=21
06/02/2022 01:11:17 - INFO - __main__ - Step 180 Global step 180 Train loss 10.323219 on epoch=22
06/02/2022 01:11:22 - INFO - __main__ - Step 190 Global step 190 Train loss 5.892087 on epoch=23
06/02/2022 01:11:27 - INFO - __main__ - Step 200 Global step 200 Train loss 1.176617 on epoch=24
06/02/2022 01:11:29 - INFO - __main__ - Global step 200 Train loss 8.455120 Classification-F1 0.22338568935427575 on epoch=24
06/02/2022 01:11:34 - INFO - __main__ - Step 210 Global step 210 Train loss 0.953797 on epoch=26
06/02/2022 01:11:39 - INFO - __main__ - Step 220 Global step 220 Train loss 2.269146 on epoch=27
06/02/2022 01:11:45 - INFO - __main__ - Step 230 Global step 230 Train loss 1.100605 on epoch=28
06/02/2022 01:11:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.506710 on epoch=29
06/02/2022 01:11:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.733376 on epoch=31
06/02/2022 01:11:56 - INFO - __main__ - Global step 250 Train loss 1.112727 Classification-F1 0.3191341991341991 on epoch=31
06/02/2022 01:12:02 - INFO - __main__ - Step 260 Global step 260 Train loss 0.447007 on epoch=32
06/02/2022 01:12:07 - INFO - __main__ - Step 270 Global step 270 Train loss 0.501992 on epoch=33
06/02/2022 01:12:12 - INFO - __main__ - Step 280 Global step 280 Train loss 0.537977 on epoch=34
06/02/2022 01:12:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.423102 on epoch=36
06/02/2022 01:12:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.411132 on epoch=37
06/02/2022 01:12:24 - INFO - __main__ - Global step 300 Train loss 0.464242 Classification-F1 0.2676799007444169 on epoch=37
06/02/2022 01:12:29 - INFO - __main__ - Step 310 Global step 310 Train loss 0.530537 on epoch=38
06/02/2022 01:12:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.361118 on epoch=39
06/02/2022 01:12:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.355728 on epoch=41
06/02/2022 01:12:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.348136 on epoch=42
06/02/2022 01:12:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.363576 on epoch=43
06/02/2022 01:12:51 - INFO - __main__ - Global step 350 Train loss 0.391819 Classification-F1 0.5263124882393527 on epoch=43
06/02/2022 01:12:57 - INFO - __main__ - Step 360 Global step 360 Train loss 0.350305 on epoch=44
06/02/2022 01:13:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.346069 on epoch=46
06/02/2022 01:13:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.390940 on epoch=47
06/02/2022 01:13:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.268992 on epoch=48
06/02/2022 01:13:17 - INFO - __main__ - Step 400 Global step 400 Train loss 0.275783 on epoch=49
06/02/2022 01:13:19 - INFO - __main__ - Global step 400 Train loss 0.326418 Classification-F1 0.3566815697963239 on epoch=49
06/02/2022 01:13:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.363327 on epoch=51
06/02/2022 01:13:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.392604 on epoch=52
06/02/2022 01:13:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.373704 on epoch=53
06/02/2022 01:13:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.321371 on epoch=54
06/02/2022 01:13:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.323407 on epoch=56
06/02/2022 01:13:46 - INFO - __main__ - Global step 450 Train loss 0.354883 Classification-F1 0.36231884057971014 on epoch=56
06/02/2022 01:13:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.336080 on epoch=57
06/02/2022 01:13:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.294529 on epoch=58
06/02/2022 01:14:01 - INFO - __main__ - Step 480 Global step 480 Train loss 0.348864 on epoch=59
06/02/2022 01:14:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.341816 on epoch=61
06/02/2022 01:14:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.298326 on epoch=62
06/02/2022 01:14:12 - INFO - __main__ - Global step 500 Train loss 0.323923 Classification-F1 0.497651675995625 on epoch=62
06/02/2022 01:14:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.311213 on epoch=63
06/02/2022 01:14:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.282826 on epoch=64
06/02/2022 01:14:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.273955 on epoch=66
06/02/2022 01:14:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.217926 on epoch=67
06/02/2022 01:14:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.304735 on epoch=68
06/02/2022 01:14:39 - INFO - __main__ - Global step 550 Train loss 0.278131 Classification-F1 0.36318407960199 on epoch=68
06/02/2022 01:14:44 - INFO - __main__ - Step 560 Global step 560 Train loss 0.227824 on epoch=69
06/02/2022 01:14:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.256366 on epoch=71
06/02/2022 01:14:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.217222 on epoch=72
06/02/2022 01:15:00 - INFO - __main__ - Step 590 Global step 590 Train loss 0.282543 on epoch=73
06/02/2022 01:15:05 - INFO - __main__ - Step 600 Global step 600 Train loss 0.297524 on epoch=74
06/02/2022 01:15:06 - INFO - __main__ - Global step 600 Train loss 0.256296 Classification-F1 0.5053671103477888 on epoch=74
06/02/2022 01:15:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.190407 on epoch=76
06/02/2022 01:15:16 - INFO - __main__ - Step 620 Global step 620 Train loss 0.184394 on epoch=77
06/02/2022 01:15:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.220290 on epoch=78
06/02/2022 01:15:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.203150 on epoch=79
06/02/2022 01:15:31 - INFO - __main__ - Step 650 Global step 650 Train loss 0.167804 on epoch=81
06/02/2022 01:15:33 - INFO - __main__ - Global step 650 Train loss 0.193209 Classification-F1 0.4682306940371457 on epoch=81
06/02/2022 01:15:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.165066 on epoch=82
06/02/2022 01:15:43 - INFO - __main__ - Step 670 Global step 670 Train loss 0.161111 on epoch=83
06/02/2022 01:15:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.138205 on epoch=84
06/02/2022 01:15:53 - INFO - __main__ - Step 690 Global step 690 Train loss 0.200620 on epoch=86
06/02/2022 01:15:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.119871 on epoch=87
06/02/2022 01:16:00 - INFO - __main__ - Global step 700 Train loss 0.156975 Classification-F1 0.5110771581359816 on epoch=87
06/02/2022 01:16:05 - INFO - __main__ - Step 710 Global step 710 Train loss 0.205628 on epoch=88
06/02/2022 01:16:10 - INFO - __main__ - Step 720 Global step 720 Train loss 0.143540 on epoch=89
06/02/2022 01:16:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.096246 on epoch=91
06/02/2022 01:16:20 - INFO - __main__ - Step 740 Global step 740 Train loss 0.085530 on epoch=92
06/02/2022 01:16:25 - INFO - __main__ - Step 750 Global step 750 Train loss 0.104265 on epoch=93
06/02/2022 01:16:26 - INFO - __main__ - Global step 750 Train loss 0.127042 Classification-F1 0.5207817754933689 on epoch=93
06/02/2022 01:16:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.091009 on epoch=94
06/02/2022 01:16:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.076601 on epoch=96
06/02/2022 01:16:42 - INFO - __main__ - Step 780 Global step 780 Train loss 0.098531 on epoch=97
06/02/2022 01:16:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.085487 on epoch=98
06/02/2022 01:16:52 - INFO - __main__ - Step 800 Global step 800 Train loss 0.186565 on epoch=99
06/02/2022 01:16:53 - INFO - __main__ - Global step 800 Train loss 0.107639 Classification-F1 0.5390343648904352 on epoch=99
06/02/2022 01:16:59 - INFO - __main__ - Step 810 Global step 810 Train loss 0.113027 on epoch=101
06/02/2022 01:17:04 - INFO - __main__ - Step 820 Global step 820 Train loss 0.071714 on epoch=102
06/02/2022 01:17:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.097337 on epoch=103
06/02/2022 01:17:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.043280 on epoch=104
06/02/2022 01:17:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.059185 on epoch=106
06/02/2022 01:17:21 - INFO - __main__ - Global step 850 Train loss 0.076908 Classification-F1 0.50778245742538 on epoch=106
06/02/2022 01:17:26 - INFO - __main__ - Step 860 Global step 860 Train loss 0.126123 on epoch=107
06/02/2022 01:17:31 - INFO - __main__ - Step 870 Global step 870 Train loss 0.068199 on epoch=108
06/02/2022 01:17:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.046884 on epoch=109
06/02/2022 01:17:41 - INFO - __main__ - Step 890 Global step 890 Train loss 0.029321 on epoch=111
06/02/2022 01:17:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.074702 on epoch=112
06/02/2022 01:17:48 - INFO - __main__ - Global step 900 Train loss 0.069046 Classification-F1 0.34588059329427895 on epoch=112
06/02/2022 01:17:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.045321 on epoch=113
06/02/2022 01:17:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.037191 on epoch=114
06/02/2022 01:18:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.024467 on epoch=116
06/02/2022 01:18:08 - INFO - __main__ - Step 940 Global step 940 Train loss 0.021467 on epoch=117
06/02/2022 01:18:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.032631 on epoch=118
06/02/2022 01:18:15 - INFO - __main__ - Global step 950 Train loss 0.032215 Classification-F1 0.5283714075165806 on epoch=118
06/02/2022 01:18:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.021768 on epoch=119
06/02/2022 01:18:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.017062 on epoch=121
06/02/2022 01:18:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.011325 on epoch=122
06/02/2022 01:18:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.051680 on epoch=123
06/02/2022 01:18:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.079634 on epoch=124
06/02/2022 01:18:42 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:18:42 - INFO - __main__ - Printing 3 examples
06/02/2022 01:18:42 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/02/2022 01:18:42 - INFO - __main__ - ['false']
06/02/2022 01:18:42 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/02/2022 01:18:42 - INFO - __main__ - ['false']
06/02/2022 01:18:42 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/02/2022 01:18:42 - INFO - __main__ - ['false']
06/02/2022 01:18:42 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:18:42 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:18:42 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 01:18:42 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:18:42 - INFO - __main__ - Printing 3 examples
06/02/2022 01:18:42 - INFO - __main__ -  [wiki_qa] question: who jumped the fence at gettysburg during the civil war? [SEP] answer: The Union line was laid out in a defensive formation resembling a fishhook.
06/02/2022 01:18:42 - INFO - __main__ - ['false']
06/02/2022 01:18:42 - INFO - __main__ -  [wiki_qa] question: how many innings makes an official game [SEP] answer: If the visiting team is leading, or the game is tied, the end of the fifth inning marks this point.
06/02/2022 01:18:42 - INFO - __main__ - ['false']
06/02/2022 01:18:42 - INFO - __main__ -  [wiki_qa] question: who is shem in the bible [SEP] answer: In a few of the many extra-biblical sources that describe him, Shem is also credited with killing Nimrod , son of Cush.
06/02/2022 01:18:42 - INFO - __main__ - ['false']
06/02/2022 01:18:42 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:18:42 - INFO - __main__ - Global step 1000 Train loss 0.036294 Classification-F1 0.537733499377335 on epoch=124
06/02/2022 01:18:42 - INFO - __main__ - save last model!
06/02/2022 01:18:42 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:18:42 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 01:18:49 - INFO - __main__ - Loading checkpoint on the fly
06/02/2022 01:18:49 - INFO - __main__ - Start tokenizing ... 2733 instances
06/02/2022 01:18:49 - INFO - __main__ - Printing 3 examples
06/02/2022 01:18:49 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/02/2022 01:18:49 - INFO - __main__ - ['false']
06/02/2022 01:18:49 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/02/2022 01:18:49 - INFO - __main__ - ['false']
06/02/2022 01:18:49 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/02/2022 01:18:49 - INFO - __main__ - ['false']
06/02/2022 01:18:49 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:18:51 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:18:53 - INFO - __main__ - Loaded 2733 examples from test data
06/02/2022 01:18:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 01:18:55 - INFO - __main__ - Starting training!
06/02/2022 01:19:22 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_42_0.0001_8_predictions.txt
06/02/2022 01:19:22 - INFO - __main__ - Classification-F1 on test data: 0.3904
06/02/2022 01:19:23 - INFO - __main__ - prefix=wiki_qa_64_42, lr=0.0001, bsz=8, dev_performance=0.5390343648904352, test_performance=0.39041520152746223
06/02/2022 01:19:23 - INFO - __main__ - Running ... prefix=wiki_qa_64_87, lr=0.0005, bsz=8 ...
06/02/2022 01:19:24 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:19:24 - INFO - __main__ - Printing 3 examples
06/02/2022 01:19:24 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/02/2022 01:19:24 - INFO - __main__ - ['false']
06/02/2022 01:19:24 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/02/2022 01:19:24 - INFO - __main__ - ['false']
06/02/2022 01:19:24 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/02/2022 01:19:24 - INFO - __main__ - ['false']
06/02/2022 01:19:24 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:19:24 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:19:24 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 01:19:24 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:19:24 - INFO - __main__ - Printing 3 examples
06/02/2022 01:19:24 - INFO - __main__ -  [wiki_qa] question: who jumped the fence at gettysburg during the civil war? [SEP] answer: The Union line was laid out in a defensive formation resembling a fishhook.
06/02/2022 01:19:24 - INFO - __main__ - ['false']
06/02/2022 01:19:24 - INFO - __main__ -  [wiki_qa] question: how many innings makes an official game [SEP] answer: If the visiting team is leading, or the game is tied, the end of the fifth inning marks this point.
06/02/2022 01:19:24 - INFO - __main__ - ['false']
06/02/2022 01:19:24 - INFO - __main__ -  [wiki_qa] question: who is shem in the bible [SEP] answer: In a few of the many extra-biblical sources that describe him, Shem is also credited with killing Nimrod , son of Cush.
06/02/2022 01:19:24 - INFO - __main__ - ['false']
06/02/2022 01:19:24 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:19:24 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:19:24 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 01:19:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 01:19:35 - INFO - __main__ - Starting training!
06/02/2022 01:19:39 - INFO - __main__ - Step 10 Global step 10 Train loss 22.995657 on epoch=1
06/02/2022 01:19:45 - INFO - __main__ - Step 20 Global step 20 Train loss 18.111088 on epoch=2
06/02/2022 01:19:50 - INFO - __main__ - Step 30 Global step 30 Train loss 14.649150 on epoch=3
06/02/2022 01:19:54 - INFO - __main__ - Step 40 Global step 40 Train loss 13.720465 on epoch=4
06/02/2022 01:19:59 - INFO - __main__ - Step 50 Global step 50 Train loss 8.493451 on epoch=6
06/02/2022 01:20:02 - INFO - __main__ - Global step 50 Train loss 15.593960 Classification-F1 0.11600502269873465 on epoch=6
06/02/2022 01:20:08 - INFO - __main__ - Step 60 Global step 60 Train loss 4.285429 on epoch=7
06/02/2022 01:20:13 - INFO - __main__ - Step 70 Global step 70 Train loss 0.823503 on epoch=8
06/02/2022 01:20:18 - INFO - __main__ - Step 80 Global step 80 Train loss 0.660717 on epoch=9
06/02/2022 01:20:23 - INFO - __main__ - Step 90 Global step 90 Train loss 0.613238 on epoch=11
06/02/2022 01:20:29 - INFO - __main__ - Step 100 Global step 100 Train loss 0.441440 on epoch=12
06/02/2022 01:20:30 - INFO - __main__ - Global step 100 Train loss 1.364866 Classification-F1 0.3333333333333333 on epoch=12
06/02/2022 01:20:36 - INFO - __main__ - Step 110 Global step 110 Train loss 0.421225 on epoch=13
06/02/2022 01:20:42 - INFO - __main__ - Step 120 Global step 120 Train loss 0.492856 on epoch=14
06/02/2022 01:20:47 - INFO - __main__ - Step 130 Global step 130 Train loss 0.531479 on epoch=16
06/02/2022 01:20:52 - INFO - __main__ - Step 140 Global step 140 Train loss 0.487985 on epoch=17
06/02/2022 01:20:57 - INFO - __main__ - Step 150 Global step 150 Train loss 0.424580 on epoch=18
06/02/2022 01:20:59 - INFO - __main__ - Global step 150 Train loss 0.471625 Classification-F1 0.3834004580273237 on epoch=18
06/02/2022 01:21:05 - INFO - __main__ - Step 160 Global step 160 Train loss 0.412437 on epoch=19
06/02/2022 01:21:10 - INFO - __main__ - Step 170 Global step 170 Train loss 0.481412 on epoch=21
06/02/2022 01:21:15 - INFO - __main__ - Step 180 Global step 180 Train loss 0.488258 on epoch=22
06/02/2022 01:21:20 - INFO - __main__ - Step 190 Global step 190 Train loss 0.430407 on epoch=23
06/02/2022 01:21:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.449274 on epoch=24
06/02/2022 01:21:27 - INFO - __main__ - Global step 200 Train loss 0.452357 Classification-F1 0.3834004580273237 on epoch=24
06/02/2022 01:21:32 - INFO - __main__ - Step 210 Global step 210 Train loss 0.445698 on epoch=26
06/02/2022 01:21:38 - INFO - __main__ - Step 220 Global step 220 Train loss 0.436861 on epoch=27
06/02/2022 01:21:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.425350 on epoch=28
06/02/2022 01:21:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.390954 on epoch=29
06/02/2022 01:21:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.444095 on epoch=31
06/02/2022 01:21:55 - INFO - __main__ - Global step 250 Train loss 0.428591 Classification-F1 0.3834004580273237 on epoch=31
06/02/2022 01:22:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.408662 on epoch=32
06/02/2022 01:22:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.407117 on epoch=33
06/02/2022 01:22:10 - INFO - __main__ - Step 280 Global step 280 Train loss 0.405737 on epoch=34
06/02/2022 01:22:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.400877 on epoch=36
06/02/2022 01:22:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.371028 on epoch=37
06/02/2022 01:22:22 - INFO - __main__ - Global step 300 Train loss 0.398684 Classification-F1 0.350463149416029 on epoch=37
06/02/2022 01:22:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.489700 on epoch=38
06/02/2022 01:22:33 - INFO - __main__ - Step 320 Global step 320 Train loss 0.356801 on epoch=39
06/02/2022 01:22:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.402378 on epoch=41
06/02/2022 01:22:43 - INFO - __main__ - Step 340 Global step 340 Train loss 0.350655 on epoch=42
06/02/2022 01:22:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.394245 on epoch=43
06/02/2022 01:22:50 - INFO - __main__ - Global step 350 Train loss 0.398756 Classification-F1 0.4055576703464027 on epoch=43
06/02/2022 01:22:56 - INFO - __main__ - Step 360 Global step 360 Train loss 0.390407 on epoch=44
06/02/2022 01:23:01 - INFO - __main__ - Step 370 Global step 370 Train loss 0.372291 on epoch=46
06/02/2022 01:23:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.388534 on epoch=47
06/02/2022 01:23:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.380142 on epoch=48
06/02/2022 01:23:17 - INFO - __main__ - Step 400 Global step 400 Train loss 0.358603 on epoch=49
06/02/2022 01:23:18 - INFO - __main__ - Global step 400 Train loss 0.377996 Classification-F1 0.4202898550724638 on epoch=49
06/02/2022 01:23:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.366137 on epoch=51
06/02/2022 01:23:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.359173 on epoch=52
06/02/2022 01:23:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.386962 on epoch=53
06/02/2022 01:23:40 - INFO - __main__ - Step 440 Global step 440 Train loss 0.345785 on epoch=54
06/02/2022 01:23:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.342546 on epoch=56
06/02/2022 01:23:47 - INFO - __main__ - Global step 450 Train loss 0.360121 Classification-F1 0.42482504604051563 on epoch=56
06/02/2022 01:23:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.410737 on epoch=57
06/02/2022 01:23:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.352513 on epoch=58
06/02/2022 01:24:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.380922 on epoch=59
06/02/2022 01:24:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.336256 on epoch=61
06/02/2022 01:24:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.368524 on epoch=62
06/02/2022 01:24:15 - INFO - __main__ - Global step 500 Train loss 0.369790 Classification-F1 0.3333333333333333 on epoch=62
06/02/2022 01:24:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.367146 on epoch=63
06/02/2022 01:24:25 - INFO - __main__ - Step 520 Global step 520 Train loss 0.334302 on epoch=64
06/02/2022 01:24:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.369602 on epoch=66
06/02/2022 01:24:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.339830 on epoch=67
06/02/2022 01:24:41 - INFO - __main__ - Step 550 Global step 550 Train loss 0.337586 on epoch=68
06/02/2022 01:24:42 - INFO - __main__ - Global step 550 Train loss 0.349693 Classification-F1 0.4198830409356725 on epoch=68
06/02/2022 01:24:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.337696 on epoch=69
06/02/2022 01:24:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.366203 on epoch=71
06/02/2022 01:24:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.368762 on epoch=72
06/02/2022 01:25:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.350804 on epoch=73
06/02/2022 01:25:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.326725 on epoch=74
06/02/2022 01:25:10 - INFO - __main__ - Global step 600 Train loss 0.350038 Classification-F1 0.4198830409356725 on epoch=74
06/02/2022 01:25:15 - INFO - __main__ - Step 610 Global step 610 Train loss 0.396383 on epoch=76
06/02/2022 01:25:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.364932 on epoch=77
06/02/2022 01:25:25 - INFO - __main__ - Step 630 Global step 630 Train loss 0.348709 on epoch=78
06/02/2022 01:25:30 - INFO - __main__ - Step 640 Global step 640 Train loss 0.349190 on epoch=79
06/02/2022 01:25:36 - INFO - __main__ - Step 650 Global step 650 Train loss 0.375591 on epoch=81
06/02/2022 01:25:37 - INFO - __main__ - Global step 650 Train loss 0.366961 Classification-F1 0.4049917757276693 on epoch=81
06/02/2022 01:25:42 - INFO - __main__ - Step 660 Global step 660 Train loss 0.322242 on epoch=82
06/02/2022 01:25:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.364488 on epoch=83
06/02/2022 01:25:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.342741 on epoch=84
06/02/2022 01:25:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.326977 on epoch=86
06/02/2022 01:26:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.346158 on epoch=87
06/02/2022 01:26:05 - INFO - __main__ - Global step 700 Train loss 0.340521 Classification-F1 0.3671451355661882 on epoch=87
06/02/2022 01:26:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.352428 on epoch=88
06/02/2022 01:26:15 - INFO - __main__ - Step 720 Global step 720 Train loss 0.353437 on epoch=89
06/02/2022 01:26:20 - INFO - __main__ - Step 730 Global step 730 Train loss 0.353792 on epoch=91
06/02/2022 01:26:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.336407 on epoch=92
06/02/2022 01:26:31 - INFO - __main__ - Step 750 Global step 750 Train loss 0.344902 on epoch=93
06/02/2022 01:26:32 - INFO - __main__ - Global step 750 Train loss 0.348193 Classification-F1 0.43111111111111106 on epoch=93
06/02/2022 01:26:39 - INFO - __main__ - Step 760 Global step 760 Train loss 0.356444 on epoch=94
06/02/2022 01:26:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.343579 on epoch=96
06/02/2022 01:26:49 - INFO - __main__ - Step 780 Global step 780 Train loss 0.362682 on epoch=97
06/02/2022 01:26:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.332417 on epoch=98
06/02/2022 01:27:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.372388 on epoch=99
06/02/2022 01:27:01 - INFO - __main__ - Global step 800 Train loss 0.353502 Classification-F1 0.43111111111111106 on epoch=99
06/02/2022 01:27:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.351762 on epoch=101
06/02/2022 01:27:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.325965 on epoch=102
06/02/2022 01:27:17 - INFO - __main__ - Step 830 Global step 830 Train loss 0.345538 on epoch=103
06/02/2022 01:27:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.387116 on epoch=104
06/02/2022 01:27:28 - INFO - __main__ - Step 850 Global step 850 Train loss 0.343576 on epoch=106
06/02/2022 01:27:29 - INFO - __main__ - Global step 850 Train loss 0.350792 Classification-F1 0.43111111111111106 on epoch=106
06/02/2022 01:27:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.361505 on epoch=107
06/02/2022 01:27:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.371000 on epoch=108
06/02/2022 01:27:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.361949 on epoch=109
06/02/2022 01:27:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.338758 on epoch=111
06/02/2022 01:27:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.360247 on epoch=112
06/02/2022 01:27:57 - INFO - __main__ - Global step 900 Train loss 0.358692 Classification-F1 0.5220079583715946 on epoch=112
06/02/2022 01:28:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.375942 on epoch=113
06/02/2022 01:28:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.372047 on epoch=114
06/02/2022 01:28:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.370260 on epoch=116
06/02/2022 01:28:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.360104 on epoch=117
06/02/2022 01:28:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.375284 on epoch=118
06/02/2022 01:28:26 - INFO - __main__ - Global step 950 Train loss 0.370727 Classification-F1 0.3671451355661882 on epoch=118
06/02/2022 01:28:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.364502 on epoch=119
06/02/2022 01:28:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.352327 on epoch=121
06/02/2022 01:28:42 - INFO - __main__ - Step 980 Global step 980 Train loss 0.375255 on epoch=122
06/02/2022 01:28:47 - INFO - __main__ - Step 990 Global step 990 Train loss 0.382224 on epoch=123
06/02/2022 01:28:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.369281 on epoch=124
06/02/2022 01:28:53 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:28:53 - INFO - __main__ - Printing 3 examples
06/02/2022 01:28:53 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/02/2022 01:28:53 - INFO - __main__ - ['false']
06/02/2022 01:28:53 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/02/2022 01:28:53 - INFO - __main__ - ['false']
06/02/2022 01:28:53 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/02/2022 01:28:53 - INFO - __main__ - ['false']
06/02/2022 01:28:53 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:28:53 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:28:53 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 01:28:53 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:28:53 - INFO - __main__ - Printing 3 examples
06/02/2022 01:28:53 - INFO - __main__ -  [wiki_qa] question: who jumped the fence at gettysburg during the civil war? [SEP] answer: The Union line was laid out in a defensive formation resembling a fishhook.
06/02/2022 01:28:53 - INFO - __main__ - ['false']
06/02/2022 01:28:53 - INFO - __main__ -  [wiki_qa] question: how many innings makes an official game [SEP] answer: If the visiting team is leading, or the game is tied, the end of the fifth inning marks this point.
06/02/2022 01:28:53 - INFO - __main__ - ['false']
06/02/2022 01:28:53 - INFO - __main__ -  [wiki_qa] question: who is shem in the bible [SEP] answer: In a few of the many extra-biblical sources that describe him, Shem is also credited with killing Nimrod , son of Cush.
06/02/2022 01:28:53 - INFO - __main__ - ['false']
06/02/2022 01:28:53 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:28:54 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:28:54 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 01:28:54 - INFO - __main__ - Global step 1000 Train loss 0.368718 Classification-F1 0.3834004580273237 on epoch=124
06/02/2022 01:28:54 - INFO - __main__ - save last model!
06/02/2022 01:29:01 - INFO - __main__ - Loading checkpoint on the fly
06/02/2022 01:29:02 - INFO - __main__ - Start tokenizing ... 2733 instances
06/02/2022 01:29:02 - INFO - __main__ - Printing 3 examples
06/02/2022 01:29:02 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/02/2022 01:29:02 - INFO - __main__ - ['false']
06/02/2022 01:29:02 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/02/2022 01:29:02 - INFO - __main__ - ['false']
06/02/2022 01:29:02 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/02/2022 01:29:02 - INFO - __main__ - ['false']
06/02/2022 01:29:02 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:29:03 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:29:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 01:29:05 - INFO - __main__ - Starting training!
06/02/2022 01:29:06 - INFO - __main__ - Loaded 2733 examples from test data
06/02/2022 01:29:35 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_87_0.0005_8_predictions.txt
06/02/2022 01:29:35 - INFO - __main__ - Classification-F1 on test data: 0.4150
06/02/2022 01:29:35 - INFO - __main__ - prefix=wiki_qa_64_87, lr=0.0005, bsz=8, dev_performance=0.5220079583715946, test_performance=0.4150161711145255
06/02/2022 01:29:35 - INFO - __main__ - Running ... prefix=wiki_qa_64_87, lr=0.0003, bsz=8 ...
06/02/2022 01:29:36 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:29:36 - INFO - __main__ - Printing 3 examples
06/02/2022 01:29:36 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/02/2022 01:29:36 - INFO - __main__ - ['false']
06/02/2022 01:29:36 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/02/2022 01:29:36 - INFO - __main__ - ['false']
06/02/2022 01:29:36 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/02/2022 01:29:36 - INFO - __main__ - ['false']
06/02/2022 01:29:36 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:29:36 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:29:36 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 01:29:36 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:29:36 - INFO - __main__ - Printing 3 examples
06/02/2022 01:29:36 - INFO - __main__ -  [wiki_qa] question: who jumped the fence at gettysburg during the civil war? [SEP] answer: The Union line was laid out in a defensive formation resembling a fishhook.
06/02/2022 01:29:36 - INFO - __main__ - ['false']
06/02/2022 01:29:36 - INFO - __main__ -  [wiki_qa] question: how many innings makes an official game [SEP] answer: If the visiting team is leading, or the game is tied, the end of the fifth inning marks this point.
06/02/2022 01:29:36 - INFO - __main__ - ['false']
06/02/2022 01:29:36 - INFO - __main__ -  [wiki_qa] question: who is shem in the bible [SEP] answer: In a few of the many extra-biblical sources that describe him, Shem is also credited with killing Nimrod , son of Cush.
06/02/2022 01:29:36 - INFO - __main__ - ['false']
06/02/2022 01:29:36 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:29:36 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:29:36 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 01:29:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 01:29:49 - INFO - __main__ - Starting training!
06/02/2022 01:29:53 - INFO - __main__ - Step 10 Global step 10 Train loss 23.018728 on epoch=1
06/02/2022 01:29:58 - INFO - __main__ - Step 20 Global step 20 Train loss 18.402412 on epoch=2
06/02/2022 01:30:03 - INFO - __main__ - Step 30 Global step 30 Train loss 17.484715 on epoch=3
06/02/2022 01:30:09 - INFO - __main__ - Step 40 Global step 40 Train loss 15.632121 on epoch=4
06/02/2022 01:30:14 - INFO - __main__ - Step 50 Global step 50 Train loss 14.147997 on epoch=6
06/02/2022 01:30:15 - INFO - __main__ - Global step 50 Train loss 17.737194 Classification-F1 0.0 on epoch=6
06/02/2022 01:30:21 - INFO - __main__ - Step 60 Global step 60 Train loss 13.606339 on epoch=7
06/02/2022 01:30:26 - INFO - __main__ - Step 70 Global step 70 Train loss 9.578135 on epoch=8
06/02/2022 01:30:31 - INFO - __main__ - Step 80 Global step 80 Train loss 1.921168 on epoch=9
06/02/2022 01:30:36 - INFO - __main__ - Step 90 Global step 90 Train loss 1.024761 on epoch=11
06/02/2022 01:30:41 - INFO - __main__ - Step 100 Global step 100 Train loss 0.569410 on epoch=12
06/02/2022 01:30:43 - INFO - __main__ - Global step 100 Train loss 5.339962 Classification-F1 0.3834004580273237 on epoch=12
06/02/2022 01:30:49 - INFO - __main__ - Step 110 Global step 110 Train loss 0.472641 on epoch=13
06/02/2022 01:30:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.475924 on epoch=14
06/02/2022 01:30:59 - INFO - __main__ - Step 130 Global step 130 Train loss 0.467130 on epoch=16
06/02/2022 01:31:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.395645 on epoch=17
06/02/2022 01:31:09 - INFO - __main__ - Step 150 Global step 150 Train loss 0.410171 on epoch=18
06/02/2022 01:31:11 - INFO - __main__ - Global step 150 Train loss 0.444302 Classification-F1 0.3834004580273237 on epoch=18
06/02/2022 01:31:16 - INFO - __main__ - Step 160 Global step 160 Train loss 0.405954 on epoch=19
06/02/2022 01:31:21 - INFO - __main__ - Step 170 Global step 170 Train loss 0.365799 on epoch=21
06/02/2022 01:31:26 - INFO - __main__ - Step 180 Global step 180 Train loss 0.319083 on epoch=22
06/02/2022 01:31:31 - INFO - __main__ - Step 190 Global step 190 Train loss 0.386042 on epoch=23
06/02/2022 01:31:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.278917 on epoch=24
06/02/2022 01:31:38 - INFO - __main__ - Global step 200 Train loss 0.351159 Classification-F1 0.4445374952417206 on epoch=24
06/02/2022 01:31:43 - INFO - __main__ - Step 210 Global step 210 Train loss 0.378069 on epoch=26
06/02/2022 01:31:48 - INFO - __main__ - Step 220 Global step 220 Train loss 0.415517 on epoch=27
06/02/2022 01:31:53 - INFO - __main__ - Step 230 Global step 230 Train loss 0.268827 on epoch=28
06/02/2022 01:31:58 - INFO - __main__ - Step 240 Global step 240 Train loss 0.213811 on epoch=29
06/02/2022 01:32:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.149538 on epoch=31
06/02/2022 01:32:05 - INFO - __main__ - Global step 250 Train loss 0.285152 Classification-F1 0.6066688460281137 on epoch=31
06/02/2022 01:32:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.206845 on epoch=32
06/02/2022 01:32:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.112788 on epoch=33
06/02/2022 01:32:21 - INFO - __main__ - Step 280 Global step 280 Train loss 0.110316 on epoch=34
06/02/2022 01:32:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.686907 on epoch=36
06/02/2022 01:32:31 - INFO - __main__ - Step 300 Global step 300 Train loss 0.165512 on epoch=37
06/02/2022 01:32:32 - INFO - __main__ - Global step 300 Train loss 0.256473 Classification-F1 0.6157138294474608 on epoch=37
06/02/2022 01:32:38 - INFO - __main__ - Step 310 Global step 310 Train loss 0.081802 on epoch=38
06/02/2022 01:32:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.066868 on epoch=39
06/02/2022 01:32:48 - INFO - __main__ - Step 330 Global step 330 Train loss 0.019858 on epoch=41
06/02/2022 01:32:53 - INFO - __main__ - Step 340 Global step 340 Train loss 0.015937 on epoch=42
06/02/2022 01:32:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.026962 on epoch=43
06/02/2022 01:33:00 - INFO - __main__ - Global step 350 Train loss 0.042286 Classification-F1 0.5993339993339992 on epoch=43
06/02/2022 01:33:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.011233 on epoch=44
06/02/2022 01:33:10 - INFO - __main__ - Step 370 Global step 370 Train loss 0.053620 on epoch=46
06/02/2022 01:33:15 - INFO - __main__ - Step 380 Global step 380 Train loss 0.025434 on epoch=47
06/02/2022 01:33:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.024265 on epoch=48
06/02/2022 01:33:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.006748 on epoch=49
06/02/2022 01:33:27 - INFO - __main__ - Global step 400 Train loss 0.024260 Classification-F1 0.6000000000000001 on epoch=49
06/02/2022 01:33:32 - INFO - __main__ - Step 410 Global step 410 Train loss 0.006468 on epoch=51
06/02/2022 01:33:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.004655 on epoch=52
06/02/2022 01:33:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.004132 on epoch=53
06/02/2022 01:33:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.047691 on epoch=54
06/02/2022 01:33:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.001456 on epoch=56
06/02/2022 01:33:53 - INFO - __main__ - Global step 450 Train loss 0.012880 Classification-F1 0.6387129147588283 on epoch=56
06/02/2022 01:33:59 - INFO - __main__ - Step 460 Global step 460 Train loss 0.007688 on epoch=57
06/02/2022 01:34:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.000326 on epoch=58
06/02/2022 01:34:09 - INFO - __main__ - Step 480 Global step 480 Train loss 0.000600 on epoch=59
06/02/2022 01:34:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.001580 on epoch=61
06/02/2022 01:34:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.001334 on epoch=62
06/02/2022 01:34:21 - INFO - __main__ - Global step 500 Train loss 0.002306 Classification-F1 0.6032033066391114 on epoch=62
06/02/2022 01:34:26 - INFO - __main__ - Step 510 Global step 510 Train loss 0.001012 on epoch=63
06/02/2022 01:34:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.016994 on epoch=64
06/02/2022 01:34:36 - INFO - __main__ - Step 530 Global step 530 Train loss 0.275915 on epoch=66
06/02/2022 01:34:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.079228 on epoch=67
06/02/2022 01:34:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.048687 on epoch=68
06/02/2022 01:34:48 - INFO - __main__ - Global step 550 Train loss 0.084367 Classification-F1 0.6235294117647059 on epoch=68
06/02/2022 01:34:53 - INFO - __main__ - Step 560 Global step 560 Train loss 0.002511 on epoch=69
06/02/2022 01:34:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.008202 on epoch=71
06/02/2022 01:35:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.055094 on epoch=72
06/02/2022 01:35:08 - INFO - __main__ - Step 590 Global step 590 Train loss 0.002110 on epoch=73
06/02/2022 01:35:13 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000798 on epoch=74
06/02/2022 01:35:15 - INFO - __main__ - Global step 600 Train loss 0.013743 Classification-F1 0.6174346201743461 on epoch=74
06/02/2022 01:35:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.013923 on epoch=76
06/02/2022 01:35:25 - INFO - __main__ - Step 620 Global step 620 Train loss 0.000938 on epoch=77
06/02/2022 01:35:30 - INFO - __main__ - Step 630 Global step 630 Train loss 0.000313 on epoch=78
06/02/2022 01:35:35 - INFO - __main__ - Step 640 Global step 640 Train loss 0.000874 on epoch=79
06/02/2022 01:35:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.003279 on epoch=81
06/02/2022 01:35:42 - INFO - __main__ - Global step 650 Train loss 0.003865 Classification-F1 0.5211861524858872 on epoch=81
06/02/2022 01:35:47 - INFO - __main__ - Step 660 Global step 660 Train loss 0.006826 on epoch=82
06/02/2022 01:35:52 - INFO - __main__ - Step 670 Global step 670 Train loss 0.001106 on epoch=83
06/02/2022 01:35:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.008295 on epoch=84
06/02/2022 01:36:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000348 on epoch=86
06/02/2022 01:36:07 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000205 on epoch=87
06/02/2022 01:36:09 - INFO - __main__ - Global step 700 Train loss 0.003356 Classification-F1 0.5974842767295597 on epoch=87
06/02/2022 01:36:14 - INFO - __main__ - Step 710 Global step 710 Train loss 0.004236 on epoch=88
06/02/2022 01:36:19 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000396 on epoch=89
06/02/2022 01:36:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000442 on epoch=91
06/02/2022 01:36:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000055 on epoch=92
06/02/2022 01:36:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.009718 on epoch=93
06/02/2022 01:36:36 - INFO - __main__ - Global step 750 Train loss 0.002969 Classification-F1 0.6289855072463768 on epoch=93
06/02/2022 01:36:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.003889 on epoch=94
06/02/2022 01:36:46 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000367 on epoch=96
06/02/2022 01:36:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000497 on epoch=97
06/02/2022 01:36:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.001443 on epoch=98
06/02/2022 01:37:01 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000362 on epoch=99
06/02/2022 01:37:03 - INFO - __main__ - Global step 800 Train loss 0.001311 Classification-F1 0.5033509700176367 on epoch=99
06/02/2022 01:37:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000836 on epoch=101
06/02/2022 01:37:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.036391 on epoch=102
06/02/2022 01:37:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.067685 on epoch=103
06/02/2022 01:37:23 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000238 on epoch=104
06/02/2022 01:37:28 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000232 on epoch=106
06/02/2022 01:37:30 - INFO - __main__ - Global step 850 Train loss 0.021076 Classification-F1 0.59859804464121 on epoch=106
06/02/2022 01:37:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000188 on epoch=107
06/02/2022 01:37:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000313 on epoch=108
06/02/2022 01:37:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000171 on epoch=109
06/02/2022 01:37:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000041 on epoch=111
06/02/2022 01:37:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000121 on epoch=112
06/02/2022 01:37:57 - INFO - __main__ - Global step 900 Train loss 0.000167 Classification-F1 0.6152855302705025 on epoch=112
06/02/2022 01:38:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000116 on epoch=113
06/02/2022 01:38:07 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000077 on epoch=114
06/02/2022 01:38:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000160 on epoch=116
06/02/2022 01:38:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000118 on epoch=117
06/02/2022 01:38:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000131 on epoch=118
06/02/2022 01:38:24 - INFO - __main__ - Global step 950 Train loss 0.000120 Classification-F1 0.6009536035209977 on epoch=118
06/02/2022 01:38:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000340 on epoch=119
06/02/2022 01:38:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000139 on epoch=121
06/02/2022 01:38:39 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000069 on epoch=122
06/02/2022 01:38:44 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000098 on epoch=123
06/02/2022 01:38:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000053 on epoch=124
06/02/2022 01:38:50 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:38:50 - INFO - __main__ - Printing 3 examples
06/02/2022 01:38:50 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/02/2022 01:38:50 - INFO - __main__ - ['false']
06/02/2022 01:38:50 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/02/2022 01:38:50 - INFO - __main__ - ['false']
06/02/2022 01:38:50 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/02/2022 01:38:50 - INFO - __main__ - ['false']
06/02/2022 01:38:50 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:38:50 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:38:50 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 01:38:50 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:38:50 - INFO - __main__ - Printing 3 examples
06/02/2022 01:38:50 - INFO - __main__ -  [wiki_qa] question: who jumped the fence at gettysburg during the civil war? [SEP] answer: The Union line was laid out in a defensive formation resembling a fishhook.
06/02/2022 01:38:50 - INFO - __main__ - ['false']
06/02/2022 01:38:50 - INFO - __main__ -  [wiki_qa] question: how many innings makes an official game [SEP] answer: If the visiting team is leading, or the game is tied, the end of the fifth inning marks this point.
06/02/2022 01:38:50 - INFO - __main__ - ['false']
06/02/2022 01:38:50 - INFO - __main__ -  [wiki_qa] question: who is shem in the bible [SEP] answer: In a few of the many extra-biblical sources that describe him, Shem is also credited with killing Nimrod , son of Cush.
06/02/2022 01:38:50 - INFO - __main__ - ['false']
06/02/2022 01:38:50 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:38:50 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:38:51 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 01:38:51 - INFO - __main__ - Global step 1000 Train loss 0.000139 Classification-F1 0.6152855302705025 on epoch=124
06/02/2022 01:38:51 - INFO - __main__ - save last model!
06/02/2022 01:38:58 - INFO - __main__ - Loading checkpoint on the fly
06/02/2022 01:38:58 - INFO - __main__ - Start tokenizing ... 2733 instances
06/02/2022 01:38:58 - INFO - __main__ - Printing 3 examples
06/02/2022 01:38:58 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/02/2022 01:38:58 - INFO - __main__ - ['false']
06/02/2022 01:38:58 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/02/2022 01:38:58 - INFO - __main__ - ['false']
06/02/2022 01:38:58 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/02/2022 01:38:58 - INFO - __main__ - ['false']
06/02/2022 01:38:58 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:39:00 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:39:02 - INFO - __main__ - Loaded 2733 examples from test data
06/02/2022 01:39:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 01:39:03 - INFO - __main__ - Starting training!
06/02/2022 01:39:28 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_87_0.0003_8_predictions.txt
06/02/2022 01:39:28 - INFO - __main__ - Classification-F1 on test data: 0.4022
06/02/2022 01:39:28 - INFO - __main__ - prefix=wiki_qa_64_87, lr=0.0003, bsz=8, dev_performance=0.6387129147588283, test_performance=0.4021707712630298
06/02/2022 01:39:28 - INFO - __main__ - Running ... prefix=wiki_qa_64_87, lr=0.0002, bsz=8 ...
06/02/2022 01:39:29 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:39:29 - INFO - __main__ - Printing 3 examples
06/02/2022 01:39:29 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/02/2022 01:39:29 - INFO - __main__ - ['false']
06/02/2022 01:39:29 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/02/2022 01:39:29 - INFO - __main__ - ['false']
06/02/2022 01:39:29 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/02/2022 01:39:29 - INFO - __main__ - ['false']
06/02/2022 01:39:29 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:39:29 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:39:29 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 01:39:29 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:39:29 - INFO - __main__ - Printing 3 examples
06/02/2022 01:39:29 - INFO - __main__ -  [wiki_qa] question: who jumped the fence at gettysburg during the civil war? [SEP] answer: The Union line was laid out in a defensive formation resembling a fishhook.
06/02/2022 01:39:29 - INFO - __main__ - ['false']
06/02/2022 01:39:29 - INFO - __main__ -  [wiki_qa] question: how many innings makes an official game [SEP] answer: If the visiting team is leading, or the game is tied, the end of the fifth inning marks this point.
06/02/2022 01:39:29 - INFO - __main__ - ['false']
06/02/2022 01:39:29 - INFO - __main__ -  [wiki_qa] question: who is shem in the bible [SEP] answer: In a few of the many extra-biblical sources that describe him, Shem is also credited with killing Nimrod , son of Cush.
06/02/2022 01:39:29 - INFO - __main__ - ['false']
06/02/2022 01:39:29 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:39:29 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:39:29 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 01:39:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 01:39:41 - INFO - __main__ - Starting training!
06/02/2022 01:39:46 - INFO - __main__ - Step 10 Global step 10 Train loss 25.041487 on epoch=1
06/02/2022 01:39:51 - INFO - __main__ - Step 20 Global step 20 Train loss 20.114788 on epoch=2
06/02/2022 01:39:56 - INFO - __main__ - Step 30 Global step 30 Train loss 17.645758 on epoch=3
06/02/2022 01:40:01 - INFO - __main__ - Step 40 Global step 40 Train loss 17.000416 on epoch=4
06/02/2022 01:40:06 - INFO - __main__ - Step 50 Global step 50 Train loss 16.723061 on epoch=6
06/02/2022 01:40:19 - INFO - __main__ - Global step 50 Train loss 19.305101 Classification-F1 0.0 on epoch=6
06/02/2022 01:40:25 - INFO - __main__ - Step 60 Global step 60 Train loss 15.751287 on epoch=7
06/02/2022 01:40:30 - INFO - __main__ - Step 70 Global step 70 Train loss 15.413005 on epoch=8
06/02/2022 01:40:35 - INFO - __main__ - Step 80 Global step 80 Train loss 13.788261 on epoch=9
06/02/2022 01:40:40 - INFO - __main__ - Step 90 Global step 90 Train loss 13.172399 on epoch=11
06/02/2022 01:40:46 - INFO - __main__ - Step 100 Global step 100 Train loss 12.406929 on epoch=12
06/02/2022 01:40:50 - INFO - __main__ - Global step 100 Train loss 14.106377 Classification-F1 0.0 on epoch=12
06/02/2022 01:40:55 - INFO - __main__ - Step 110 Global step 110 Train loss 11.157762 on epoch=13
06/02/2022 01:41:00 - INFO - __main__ - Step 120 Global step 120 Train loss 8.335382 on epoch=14
06/02/2022 01:41:05 - INFO - __main__ - Step 130 Global step 130 Train loss 5.385039 on epoch=16
06/02/2022 01:41:10 - INFO - __main__ - Step 140 Global step 140 Train loss 1.213177 on epoch=17
06/02/2022 01:41:15 - INFO - __main__ - Step 150 Global step 150 Train loss 0.651657 on epoch=18
06/02/2022 01:41:17 - INFO - __main__ - Global step 150 Train loss 5.348603 Classification-F1 0.3333333333333333 on epoch=18
06/02/2022 01:41:23 - INFO - __main__ - Step 160 Global step 160 Train loss 0.551048 on epoch=19
06/02/2022 01:41:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.608217 on epoch=21
06/02/2022 01:41:33 - INFO - __main__ - Step 180 Global step 180 Train loss 0.526672 on epoch=22
06/02/2022 01:41:38 - INFO - __main__ - Step 190 Global step 190 Train loss 0.574123 on epoch=23
06/02/2022 01:41:44 - INFO - __main__ - Step 200 Global step 200 Train loss 0.344302 on epoch=24
06/02/2022 01:41:45 - INFO - __main__ - Global step 200 Train loss 0.520872 Classification-F1 0.41470975742075483 on epoch=24
06/02/2022 01:41:51 - INFO - __main__ - Step 210 Global step 210 Train loss 0.508224 on epoch=26
06/02/2022 01:41:56 - INFO - __main__ - Step 220 Global step 220 Train loss 0.403317 on epoch=27
06/02/2022 01:42:01 - INFO - __main__ - Step 230 Global step 230 Train loss 0.376018 on epoch=28
06/02/2022 01:42:07 - INFO - __main__ - Step 240 Global step 240 Train loss 0.261853 on epoch=29
06/02/2022 01:42:12 - INFO - __main__ - Step 250 Global step 250 Train loss 0.267305 on epoch=31
06/02/2022 01:42:13 - INFO - __main__ - Global step 250 Train loss 0.363343 Classification-F1 0.3834004580273237 on epoch=31
06/02/2022 01:42:19 - INFO - __main__ - Step 260 Global step 260 Train loss 0.308987 on epoch=32
06/02/2022 01:42:24 - INFO - __main__ - Step 270 Global step 270 Train loss 0.271200 on epoch=33
06/02/2022 01:42:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.233883 on epoch=34
06/02/2022 01:42:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.307010 on epoch=36
06/02/2022 01:42:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.260917 on epoch=37
06/02/2022 01:42:41 - INFO - __main__ - Global step 300 Train loss 0.276399 Classification-F1 0.3834004580273237 on epoch=37
06/02/2022 01:42:46 - INFO - __main__ - Step 310 Global step 310 Train loss 0.302162 on epoch=38
06/02/2022 01:42:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.449609 on epoch=39
06/02/2022 01:42:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.302921 on epoch=41
06/02/2022 01:43:01 - INFO - __main__ - Step 340 Global step 340 Train loss 0.560808 on epoch=42
06/02/2022 01:43:06 - INFO - __main__ - Step 350 Global step 350 Train loss 0.236443 on epoch=43
06/02/2022 01:43:08 - INFO - __main__ - Global step 350 Train loss 0.370389 Classification-F1 0.5214109347442681 on epoch=43
06/02/2022 01:43:14 - INFO - __main__ - Step 360 Global step 360 Train loss 0.245936 on epoch=44
06/02/2022 01:43:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.168716 on epoch=46
06/02/2022 01:43:24 - INFO - __main__ - Step 380 Global step 380 Train loss 0.209518 on epoch=47
06/02/2022 01:43:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.254675 on epoch=48
06/02/2022 01:43:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.267232 on epoch=49
06/02/2022 01:43:36 - INFO - __main__ - Global step 400 Train loss 0.229215 Classification-F1 0.45207864760937383 on epoch=49
06/02/2022 01:43:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.295468 on epoch=51
06/02/2022 01:43:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.268684 on epoch=52
06/02/2022 01:43:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.356752 on epoch=53
06/02/2022 01:43:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.261916 on epoch=54
06/02/2022 01:44:02 - INFO - __main__ - Step 450 Global step 450 Train loss 0.334096 on epoch=56
06/02/2022 01:44:04 - INFO - __main__ - Global step 450 Train loss 0.303383 Classification-F1 0.46293706293706294 on epoch=56
06/02/2022 01:44:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.322998 on epoch=57
06/02/2022 01:44:14 - INFO - __main__ - Step 470 Global step 470 Train loss 0.303748 on epoch=58
06/02/2022 01:44:19 - INFO - __main__ - Step 480 Global step 480 Train loss 0.351477 on epoch=59
06/02/2022 01:44:24 - INFO - __main__ - Step 490 Global step 490 Train loss 0.332093 on epoch=61
06/02/2022 01:44:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.294787 on epoch=62
06/02/2022 01:44:31 - INFO - __main__ - Global step 500 Train loss 0.321021 Classification-F1 0.5202141900937082 on epoch=62
06/02/2022 01:44:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.302548 on epoch=63
06/02/2022 01:44:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.216570 on epoch=64
06/02/2022 01:44:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.191110 on epoch=66
06/02/2022 01:44:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.262004 on epoch=67
06/02/2022 01:44:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.195266 on epoch=68
06/02/2022 01:44:58 - INFO - __main__ - Global step 550 Train loss 0.233500 Classification-F1 0.6131976564909035 on epoch=68
06/02/2022 01:45:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.175804 on epoch=69
06/02/2022 01:45:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.211736 on epoch=71
06/02/2022 01:45:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.177566 on epoch=72
06/02/2022 01:45:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.255608 on epoch=73
06/02/2022 01:45:25 - INFO - __main__ - Step 600 Global step 600 Train loss 0.292252 on epoch=74
06/02/2022 01:45:26 - INFO - __main__ - Global step 600 Train loss 0.222593 Classification-F1 0.6484160410181287 on epoch=74
06/02/2022 01:45:32 - INFO - __main__ - Step 610 Global step 610 Train loss 0.238333 on epoch=76
06/02/2022 01:45:37 - INFO - __main__ - Step 620 Global step 620 Train loss 0.258260 on epoch=77
06/02/2022 01:45:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.282965 on epoch=78
06/02/2022 01:45:48 - INFO - __main__ - Step 640 Global step 640 Train loss 0.200035 on epoch=79
06/02/2022 01:45:53 - INFO - __main__ - Step 650 Global step 650 Train loss 0.150182 on epoch=81
06/02/2022 01:45:55 - INFO - __main__ - Global step 650 Train loss 0.225955 Classification-F1 0.5652830188679245 on epoch=81
06/02/2022 01:46:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.210817 on epoch=82
06/02/2022 01:46:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.240324 on epoch=83
06/02/2022 01:46:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.251751 on epoch=84
06/02/2022 01:46:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.250536 on epoch=86
06/02/2022 01:46:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.202248 on epoch=87
06/02/2022 01:46:22 - INFO - __main__ - Global step 700 Train loss 0.231135 Classification-F1 0.554006968641115 on epoch=87
06/02/2022 01:46:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.192725 on epoch=88
06/02/2022 01:46:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.192522 on epoch=89
06/02/2022 01:46:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.182539 on epoch=91
06/02/2022 01:46:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.297734 on epoch=92
06/02/2022 01:46:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.247442 on epoch=93
06/02/2022 01:46:49 - INFO - __main__ - Global step 750 Train loss 0.222592 Classification-F1 0.5062438705459301 on epoch=93
06/02/2022 01:46:55 - INFO - __main__ - Step 760 Global step 760 Train loss 0.229517 on epoch=94
06/02/2022 01:47:00 - INFO - __main__ - Step 770 Global step 770 Train loss 0.265261 on epoch=96
06/02/2022 01:47:05 - INFO - __main__ - Step 780 Global step 780 Train loss 0.186415 on epoch=97
06/02/2022 01:47:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.192521 on epoch=98
06/02/2022 01:47:15 - INFO - __main__ - Step 800 Global step 800 Train loss 0.139687 on epoch=99
06/02/2022 01:47:17 - INFO - __main__ - Global step 800 Train loss 0.202680 Classification-F1 0.5681776360179107 on epoch=99
06/02/2022 01:47:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.087047 on epoch=101
06/02/2022 01:47:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.097758 on epoch=102
06/02/2022 01:47:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.158943 on epoch=103
06/02/2022 01:47:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.146548 on epoch=104
06/02/2022 01:47:43 - INFO - __main__ - Step 850 Global step 850 Train loss 0.063679 on epoch=106
06/02/2022 01:47:44 - INFO - __main__ - Global step 850 Train loss 0.110795 Classification-F1 0.5702862723554905 on epoch=106
06/02/2022 01:47:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.091334 on epoch=107
06/02/2022 01:47:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.106288 on epoch=108
06/02/2022 01:48:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.116014 on epoch=109
06/02/2022 01:48:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.109801 on epoch=111
06/02/2022 01:48:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.081286 on epoch=112
06/02/2022 01:48:12 - INFO - __main__ - Global step 900 Train loss 0.100944 Classification-F1 0.5816219549799568 on epoch=112
06/02/2022 01:48:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.057334 on epoch=113
06/02/2022 01:48:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.088615 on epoch=114
06/02/2022 01:48:27 - INFO - __main__ - Step 930 Global step 930 Train loss 0.111664 on epoch=116
06/02/2022 01:48:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.151264 on epoch=117
06/02/2022 01:48:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.152413 on epoch=118
06/02/2022 01:48:39 - INFO - __main__ - Global step 950 Train loss 0.112258 Classification-F1 0.45071982281284606 on epoch=118
06/02/2022 01:48:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.120502 on epoch=119
06/02/2022 01:48:50 - INFO - __main__ - Step 970 Global step 970 Train loss 0.185354 on epoch=121
06/02/2022 01:48:55 - INFO - __main__ - Step 980 Global step 980 Train loss 0.164432 on epoch=122
06/02/2022 01:49:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.193646 on epoch=123
06/02/2022 01:49:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.264754 on epoch=124
06/02/2022 01:49:06 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:49:06 - INFO - __main__ - Printing 3 examples
06/02/2022 01:49:06 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/02/2022 01:49:06 - INFO - __main__ - ['false']
06/02/2022 01:49:06 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/02/2022 01:49:06 - INFO - __main__ - ['false']
06/02/2022 01:49:06 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/02/2022 01:49:06 - INFO - __main__ - ['false']
06/02/2022 01:49:06 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:49:06 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:49:06 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 01:49:06 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:49:06 - INFO - __main__ - Printing 3 examples
06/02/2022 01:49:06 - INFO - __main__ -  [wiki_qa] question: who jumped the fence at gettysburg during the civil war? [SEP] answer: The Union line was laid out in a defensive formation resembling a fishhook.
06/02/2022 01:49:06 - INFO - __main__ - ['false']
06/02/2022 01:49:06 - INFO - __main__ -  [wiki_qa] question: how many innings makes an official game [SEP] answer: If the visiting team is leading, or the game is tied, the end of the fifth inning marks this point.
06/02/2022 01:49:06 - INFO - __main__ - ['false']
06/02/2022 01:49:06 - INFO - __main__ -  [wiki_qa] question: who is shem in the bible [SEP] answer: In a few of the many extra-biblical sources that describe him, Shem is also credited with killing Nimrod , son of Cush.
06/02/2022 01:49:06 - INFO - __main__ - ['false']
06/02/2022 01:49:06 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:49:06 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:49:07 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 01:49:07 - INFO - __main__ - Global step 1000 Train loss 0.185738 Classification-F1 0.5326443468036388 on epoch=124
06/02/2022 01:49:07 - INFO - __main__ - save last model!
06/02/2022 01:49:14 - INFO - __main__ - Loading checkpoint on the fly
06/02/2022 01:49:15 - INFO - __main__ - Start tokenizing ... 2733 instances
06/02/2022 01:49:15 - INFO - __main__ - Printing 3 examples
06/02/2022 01:49:15 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/02/2022 01:49:15 - INFO - __main__ - ['false']
06/02/2022 01:49:15 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/02/2022 01:49:15 - INFO - __main__ - ['false']
06/02/2022 01:49:15 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/02/2022 01:49:15 - INFO - __main__ - ['false']
06/02/2022 01:49:15 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:49:16 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:49:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 01:49:18 - INFO - __main__ - Starting training!
06/02/2022 01:49:19 - INFO - __main__ - Loaded 2733 examples from test data
06/02/2022 01:49:47 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_87_0.0002_8_predictions.txt
06/02/2022 01:49:47 - INFO - __main__ - Classification-F1 on test data: 0.4274
06/02/2022 01:49:48 - INFO - __main__ - prefix=wiki_qa_64_87, lr=0.0002, bsz=8, dev_performance=0.6484160410181287, test_performance=0.42737896552894916
06/02/2022 01:49:48 - INFO - __main__ - Running ... prefix=wiki_qa_64_87, lr=0.0001, bsz=8 ...
06/02/2022 01:49:49 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:49:49 - INFO - __main__ - Printing 3 examples
06/02/2022 01:49:49 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/02/2022 01:49:49 - INFO - __main__ - ['false']
06/02/2022 01:49:49 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/02/2022 01:49:49 - INFO - __main__ - ['false']
06/02/2022 01:49:49 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/02/2022 01:49:49 - INFO - __main__ - ['false']
06/02/2022 01:49:49 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:49:49 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:49:49 - INFO - __main__ - Loaded 128 examples from train data
06/02/2022 01:49:49 - INFO - __main__ - Start tokenizing ... 128 instances
06/02/2022 01:49:49 - INFO - __main__ - Printing 3 examples
06/02/2022 01:49:49 - INFO - __main__ -  [wiki_qa] question: who jumped the fence at gettysburg during the civil war? [SEP] answer: The Union line was laid out in a defensive formation resembling a fishhook.
06/02/2022 01:49:49 - INFO - __main__ - ['false']
06/02/2022 01:49:49 - INFO - __main__ -  [wiki_qa] question: how many innings makes an official game [SEP] answer: If the visiting team is leading, or the game is tied, the end of the fifth inning marks this point.
06/02/2022 01:49:49 - INFO - __main__ - ['false']
06/02/2022 01:49:49 - INFO - __main__ -  [wiki_qa] question: who is shem in the bible [SEP] answer: In a few of the many extra-biblical sources that describe him, Shem is also credited with killing Nimrod , son of Cush.
06/02/2022 01:49:49 - INFO - __main__ - ['false']
06/02/2022 01:49:49 - INFO - __main__ - Tokenizing Input ...
06/02/2022 01:49:49 - INFO - __main__ - Tokenizing Output ...
06/02/2022 01:49:49 - INFO - __main__ - Loaded 128 examples from dev data
06/02/2022 01:50:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/02/2022 01:50:02 - INFO - __main__ - Starting training!
06/02/2022 01:50:06 - INFO - __main__ - Step 10 Global step 10 Train loss 23.926605 on epoch=1
06/02/2022 01:50:11 - INFO - __main__ - Step 20 Global step 20 Train loss 21.142599 on epoch=2
06/02/2022 01:50:16 - INFO - __main__ - Step 30 Global step 30 Train loss 18.050907 on epoch=3
06/02/2022 01:50:21 - INFO - __main__ - Step 40 Global step 40 Train loss 18.564213 on epoch=4
06/02/2022 01:50:26 - INFO - __main__ - Step 50 Global step 50 Train loss 17.716196 on epoch=6
06/02/2022 01:50:52 - INFO - __main__ - Global step 50 Train loss 19.880102 Classification-F1 0.0 on epoch=6
06/02/2022 01:50:57 - INFO - __main__ - Step 60 Global step 60 Train loss 17.075401 on epoch=7
06/02/2022 01:51:02 - INFO - __main__ - Step 70 Global step 70 Train loss 18.008850 on epoch=8
06/02/2022 01:51:07 - INFO - __main__ - Step 80 Global step 80 Train loss 16.645990 on epoch=9
06/02/2022 01:51:13 - INFO - __main__ - Step 90 Global step 90 Train loss 15.753916 on epoch=11
06/02/2022 01:51:18 - INFO - __main__ - Step 100 Global step 100 Train loss 15.381880 on epoch=12
06/02/2022 01:51:38 - INFO - __main__ - Global step 100 Train loss 16.573206 Classification-F1 0.0 on epoch=12
06/02/2022 01:51:43 - INFO - __main__ - Step 110 Global step 110 Train loss 15.046847 on epoch=13
06/02/2022 01:51:48 - INFO - __main__ - Step 120 Global step 120 Train loss 15.184065 on epoch=14
06/02/2022 01:51:53 - INFO - __main__ - Step 130 Global step 130 Train loss 14.865804 on epoch=16
06/02/2022 01:51:58 - INFO - __main__ - Step 140 Global step 140 Train loss 13.980861 on epoch=17
06/02/2022 01:52:04 - INFO - __main__ - Step 150 Global step 150 Train loss 14.011348 on epoch=18
06/02/2022 01:52:22 - INFO - __main__ - Global step 150 Train loss 14.617785 Classification-F1 0.0 on epoch=18
06/02/2022 01:52:27 - INFO - __main__ - Step 160 Global step 160 Train loss 13.772369 on epoch=19
06/02/2022 01:52:32 - INFO - __main__ - Step 170 Global step 170 Train loss 13.325348 on epoch=21
06/02/2022 01:52:37 - INFO - __main__ - Step 180 Global step 180 Train loss 12.838480 on epoch=22
06/02/2022 01:52:42 - INFO - __main__ - Step 190 Global step 190 Train loss 12.936543 on epoch=23
06/02/2022 01:52:47 - INFO - __main__ - Step 200 Global step 200 Train loss 12.222409 on epoch=24
06/02/2022 01:52:58 - INFO - __main__ - Global step 200 Train loss 13.019030 Classification-F1 0.0 on epoch=24
06/02/2022 01:53:04 - INFO - __main__ - Step 210 Global step 210 Train loss 11.819024 on epoch=26
06/02/2022 01:53:09 - INFO - __main__ - Step 220 Global step 220 Train loss 11.299980 on epoch=27
06/02/2022 01:53:14 - INFO - __main__ - Step 230 Global step 230 Train loss 10.844914 on epoch=28
06/02/2022 01:53:19 - INFO - __main__ - Step 240 Global step 240 Train loss 10.113500 on epoch=29
06/02/2022 01:53:24 - INFO - __main__ - Step 250 Global step 250 Train loss 9.568583 on epoch=31
06/02/2022 01:53:33 - INFO - __main__ - Global step 250 Train loss 10.729201 Classification-F1 0.0 on epoch=31
06/02/2022 01:53:39 - INFO - __main__ - Step 260 Global step 260 Train loss 7.386203 on epoch=32
06/02/2022 01:53:44 - INFO - __main__ - Step 270 Global step 270 Train loss 7.058608 on epoch=33
06/02/2022 01:53:49 - INFO - __main__ - Step 280 Global step 280 Train loss 4.396754 on epoch=34
06/02/2022 01:53:54 - INFO - __main__ - Step 290 Global step 290 Train loss 1.464430 on epoch=36
06/02/2022 01:53:59 - INFO - __main__ - Step 300 Global step 300 Train loss 0.829580 on epoch=37
06/02/2022 01:54:00 - INFO - __main__ - Global step 300 Train loss 4.227115 Classification-F1 0.34296770117665637 on epoch=37
06/02/2022 01:54:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.849061 on epoch=38
06/02/2022 01:54:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.635702 on epoch=39
06/02/2022 01:54:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.528430 on epoch=41
06/02/2022 01:54:21 - INFO - __main__ - Step 340 Global step 340 Train loss 0.510890 on epoch=42
06/02/2022 01:54:26 - INFO - __main__ - Step 350 Global step 350 Train loss 0.868603 on epoch=43
06/02/2022 01:54:28 - INFO - __main__ - Global step 350 Train loss 0.678537 Classification-F1 0.3834004580273237 on epoch=43
06/02/2022 01:54:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.426965 on epoch=44
06/02/2022 01:54:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.414932 on epoch=46
06/02/2022 01:54:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.407228 on epoch=47
06/02/2022 01:54:48 - INFO - __main__ - Step 390 Global step 390 Train loss 1.298700 on epoch=48
06/02/2022 01:54:53 - INFO - __main__ - Step 400 Global step 400 Train loss 1.790134 on epoch=49
06/02/2022 01:54:55 - INFO - __main__ - Global step 400 Train loss 0.867592 Classification-F1 0.21432116270825946 on epoch=49
06/02/2022 01:55:00 - INFO - __main__ - Step 410 Global step 410 Train loss 1.633305 on epoch=51
06/02/2022 01:55:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.730703 on epoch=52
06/02/2022 01:55:10 - INFO - __main__ - Step 430 Global step 430 Train loss 1.000332 on epoch=53
06/02/2022 01:55:15 - INFO - __main__ - Step 440 Global step 440 Train loss 1.403635 on epoch=54
06/02/2022 01:55:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.586082 on epoch=56
06/02/2022 01:55:22 - INFO - __main__ - Global step 450 Train loss 1.070811 Classification-F1 0.39636200314394787 on epoch=56
06/02/2022 01:55:28 - INFO - __main__ - Step 460 Global step 460 Train loss 0.702706 on epoch=57
06/02/2022 01:55:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.421945 on epoch=58
06/02/2022 01:55:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.405869 on epoch=59
06/02/2022 01:55:43 - INFO - __main__ - Step 490 Global step 490 Train loss 0.334066 on epoch=61
06/02/2022 01:55:48 - INFO - __main__ - Step 500 Global step 500 Train loss 0.401281 on epoch=62
06/02/2022 01:55:50 - INFO - __main__ - Global step 500 Train loss 0.453173 Classification-F1 0.47998667998668 on epoch=62
06/02/2022 01:55:56 - INFO - __main__ - Step 510 Global step 510 Train loss 0.435423 on epoch=63
06/02/2022 01:56:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.382212 on epoch=64
06/02/2022 01:56:06 - INFO - __main__ - Step 530 Global step 530 Train loss 0.408801 on epoch=66
06/02/2022 01:56:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.422182 on epoch=67
06/02/2022 01:56:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.366992 on epoch=68
06/02/2022 01:56:17 - INFO - __main__ - Global step 550 Train loss 0.403122 Classification-F1 0.37922403003754696 on epoch=68
06/02/2022 01:56:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.410655 on epoch=69
06/02/2022 01:56:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.374491 on epoch=71
06/02/2022 01:56:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.350654 on epoch=72
06/02/2022 01:56:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.328380 on epoch=73
06/02/2022 01:56:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.360252 on epoch=74
06/02/2022 01:56:45 - INFO - __main__ - Global step 600 Train loss 0.364886 Classification-F1 0.39047619047619053 on epoch=74
06/02/2022 01:56:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.339525 on epoch=76
06/02/2022 01:56:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.380781 on epoch=77
06/02/2022 01:57:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.326637 on epoch=78
06/02/2022 01:57:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.295566 on epoch=79
06/02/2022 01:57:10 - INFO - __main__ - Step 650 Global step 650 Train loss 0.322889 on epoch=81
06/02/2022 01:57:12 - INFO - __main__ - Global step 650 Train loss 0.333080 Classification-F1 0.46723104056437387 on epoch=81
06/02/2022 01:57:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.324819 on epoch=82
06/02/2022 01:57:22 - INFO - __main__ - Step 670 Global step 670 Train loss 0.285229 on epoch=83
06/02/2022 01:57:27 - INFO - __main__ - Step 680 Global step 680 Train loss 0.306035 on epoch=84
06/02/2022 01:57:32 - INFO - __main__ - Step 690 Global step 690 Train loss 0.346073 on epoch=86
06/02/2022 01:57:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.249612 on epoch=87
06/02/2022 01:57:39 - INFO - __main__ - Global step 700 Train loss 0.302354 Classification-F1 0.5905413033933388 on epoch=87
06/02/2022 01:57:45 - INFO - __main__ - Step 710 Global step 710 Train loss 0.266030 on epoch=88
06/02/2022 01:57:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.272728 on epoch=89
06/02/2022 01:57:55 - INFO - __main__ - Step 730 Global step 730 Train loss 0.255135 on epoch=91
06/02/2022 01:58:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.363456 on epoch=92
06/02/2022 01:58:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.311455 on epoch=93
06/02/2022 01:58:07 - INFO - __main__ - Global step 750 Train loss 0.293761 Classification-F1 0.4599156118143459 on epoch=93
06/02/2022 01:58:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.244153 on epoch=94
06/02/2022 01:58:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.235666 on epoch=96
06/02/2022 01:58:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.226901 on epoch=97
06/02/2022 01:58:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.223947 on epoch=98
06/02/2022 01:58:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.255164 on epoch=99
06/02/2022 01:58:34 - INFO - __main__ - Global step 800 Train loss 0.237166 Classification-F1 0.5307917888563051 on epoch=99
06/02/2022 01:58:39 - INFO - __main__ - Step 810 Global step 810 Train loss 0.226136 on epoch=101
06/02/2022 01:58:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.275106 on epoch=102
06/02/2022 01:58:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.259523 on epoch=103
06/02/2022 01:58:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.321460 on epoch=104
06/02/2022 01:58:59 - INFO - __main__ - Step 850 Global step 850 Train loss 0.273233 on epoch=106
06/02/2022 01:59:01 - INFO - __main__ - Global step 850 Train loss 0.271092 Classification-F1 0.4436832412523021 on epoch=106
06/02/2022 01:59:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.239580 on epoch=107
06/02/2022 01:59:11 - INFO - __main__ - Step 870 Global step 870 Train loss 0.226204 on epoch=108
06/02/2022 01:59:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.205183 on epoch=109
06/02/2022 01:59:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.200599 on epoch=111
06/02/2022 01:59:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.188549 on epoch=112
06/02/2022 01:59:28 - INFO - __main__ - Global step 900 Train loss 0.212023 Classification-F1 0.5700763358778627 on epoch=112
06/02/2022 01:59:33 - INFO - __main__ - Step 910 Global step 910 Train loss 0.199487 on epoch=113
06/02/2022 01:59:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.217471 on epoch=114
06/02/2022 01:59:43 - INFO - __main__ - Step 930 Global step 930 Train loss 0.225250 on epoch=116
06/02/2022 01:59:49 - INFO - __main__ - Step 940 Global step 940 Train loss 0.191076 on epoch=117
06/02/2022 01:59:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.194976 on epoch=118
06/02/2022 01:59:55 - INFO - __main__ - Global step 950 Train loss 0.205652 Classification-F1 0.4079058031959629 on epoch=118
06/02/2022 02:00:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.175533 on epoch=119
06/02/2022 02:00:05 - INFO - __main__ - Step 970 Global step 970 Train loss 0.147818 on epoch=121
06/02/2022 02:00:10 - INFO - __main__ - Step 980 Global step 980 Train loss 0.138111 on epoch=122
06/02/2022 02:00:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.181277 on epoch=123
06/02/2022 02:00:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.142176 on epoch=124
06/02/2022 02:00:22 - INFO - __main__ - Global step 1000 Train loss 0.156983 Classification-F1 0.578502640571606 on epoch=124
06/02/2022 02:00:22 - INFO - __main__ - save last model!
06/02/2022 02:00:29 - INFO - __main__ - Loading checkpoint on the fly
06/02/2022 02:00:30 - INFO - __main__ - Start tokenizing ... 2733 instances
06/02/2022 02:00:30 - INFO - __main__ - Printing 3 examples
06/02/2022 02:00:30 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/02/2022 02:00:30 - INFO - __main__ - ['false']
06/02/2022 02:00:30 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/02/2022 02:00:30 - INFO - __main__ - ['false']
06/02/2022 02:00:30 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/02/2022 02:00:30 - INFO - __main__ - ['false']
06/02/2022 02:00:30 - INFO - __main__ - Tokenizing Input ...
06/02/2022 02:00:31 - INFO - __main__ - Tokenizing Output ...
06/02/2022 02:00:34 - INFO - __main__ - Loaded 2733 examples from test data
06/02/2022 02:01:02 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down64shot/singletask-wiki_qa/wiki_qa_64_87_0.0001_8_predictions.txt
06/02/2022 02:01:02 - INFO - __main__ - Classification-F1 on test data: 0.4669
06/02/2022 02:01:03 - INFO - __main__ - prefix=wiki_qa_64_87, lr=0.0001, bsz=8, dev_performance=0.5905413033933388, test_performance=0.4669241046513595
