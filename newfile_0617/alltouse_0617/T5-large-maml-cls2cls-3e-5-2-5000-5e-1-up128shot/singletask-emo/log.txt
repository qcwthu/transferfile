05/21/2022 06:37:22 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 06:37:22 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo
05/21/2022 06:37:22 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 06:37:22 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo
05/21/2022 06:37:23 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 06:37:23 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 06:37:23 - INFO - __main__ - args.device: cuda:0
05/21/2022 06:37:23 - INFO - __main__ - Using 2 gpus
05/21/2022 06:37:23 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/21/2022 06:37:23 - INFO - __main__ - args.device: cuda:1
05/21/2022 06:37:23 - INFO - __main__ - Using 2 gpus
05/21/2022 06:37:23 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/21/2022 06:37:28 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
05/21/2022 06:37:29 - INFO - __main__ - Start tokenizing ... 64 instances
05/21/2022 06:37:29 - INFO - __main__ - Printing 3 examples
05/21/2022 06:37:29 - INFO - __main__ -  [emo] how cause yes am listening
05/21/2022 06:37:29 - INFO - __main__ - ['others']
05/21/2022 06:37:29 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/21/2022 06:37:29 - INFO - __main__ - ['others']
05/21/2022 06:37:29 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/21/2022 06:37:29 - INFO - __main__ - ['others']
05/21/2022 06:37:29 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:37:29 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:37:29 - INFO - __main__ - Start tokenizing ... 64 instances
05/21/2022 06:37:29 - INFO - __main__ - Printing 3 examples
05/21/2022 06:37:29 - INFO - __main__ -  [emo] how cause yes am listening
05/21/2022 06:37:29 - INFO - __main__ - ['others']
05/21/2022 06:37:29 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/21/2022 06:37:29 - INFO - __main__ - ['others']
05/21/2022 06:37:29 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/21/2022 06:37:29 - INFO - __main__ - ['others']
05/21/2022 06:37:29 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:37:29 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:37:29 - INFO - __main__ - Loaded 64 examples from train data
05/21/2022 06:37:29 - INFO - __main__ - Start tokenizing ... 64 instances
05/21/2022 06:37:29 - INFO - __main__ - Printing 3 examples
05/21/2022 06:37:29 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/21/2022 06:37:29 - INFO - __main__ - ['others']
05/21/2022 06:37:29 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/21/2022 06:37:29 - INFO - __main__ - ['others']
05/21/2022 06:37:29 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/21/2022 06:37:29 - INFO - __main__ - ['others']
05/21/2022 06:37:29 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:37:29 - INFO - __main__ - Loaded 64 examples from train data
05/21/2022 06:37:29 - INFO - __main__ - Start tokenizing ... 64 instances
05/21/2022 06:37:29 - INFO - __main__ - Printing 3 examples
05/21/2022 06:37:29 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/21/2022 06:37:29 - INFO - __main__ - ['others']
05/21/2022 06:37:29 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/21/2022 06:37:29 - INFO - __main__ - ['others']
05/21/2022 06:37:29 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/21/2022 06:37:29 - INFO - __main__ - ['others']
05/21/2022 06:37:29 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:37:29 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:37:29 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:37:29 - INFO - __main__ - Loaded 64 examples from dev data
05/21/2022 06:37:29 - INFO - __main__ - Loaded 64 examples from dev data
05/21/2022 06:37:47 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:37:47 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 05:52:31 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/06/2022 05:52:31 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo
06/06/2022 05:52:31 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/06/2022 05:52:31 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo
06/06/2022 05:52:33 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/06/2022 05:52:33 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/06/2022 05:52:33 - INFO - __main__ - args.device: cuda:0
06/06/2022 05:52:33 - INFO - __main__ - Using 2 gpus
06/06/2022 05:52:33 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/06/2022 05:52:33 - INFO - __main__ - args.device: cuda:1
06/06/2022 05:52:33 - INFO - __main__ - Using 2 gpus
06/06/2022 05:52:33 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/06/2022 05:52:37 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
06/06/2022 05:52:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 05:52:38 - INFO - __main__ - Printing 3 examples
06/06/2022 05:52:38 - INFO - __main__ -  [emo] how cause yes am listening
06/06/2022 05:52:38 - INFO - __main__ - ['others']
06/06/2022 05:52:38 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/06/2022 05:52:38 - INFO - __main__ - ['others']
06/06/2022 05:52:38 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/06/2022 05:52:38 - INFO - __main__ - ['others']
06/06/2022 05:52:38 - INFO - __main__ - Tokenizing Input ...
06/06/2022 05:52:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 05:52:38 - INFO - __main__ - Printing 3 examples
06/06/2022 05:52:38 - INFO - __main__ -  [emo] how cause yes am listening
06/06/2022 05:52:38 - INFO - __main__ - ['others']
06/06/2022 05:52:38 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/06/2022 05:52:38 - INFO - __main__ - ['others']
06/06/2022 05:52:38 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/06/2022 05:52:38 - INFO - __main__ - ['others']
06/06/2022 05:52:38 - INFO - __main__ - Tokenizing Input ...
06/06/2022 05:52:38 - INFO - __main__ - Tokenizing Output ...
06/06/2022 05:52:38 - INFO - __main__ - Tokenizing Output ...
06/06/2022 05:52:38 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 05:52:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 05:52:38 - INFO - __main__ - Printing 3 examples
06/06/2022 05:52:38 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/06/2022 05:52:38 - INFO - __main__ - ['others']
06/06/2022 05:52:38 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/06/2022 05:52:38 - INFO - __main__ - ['others']
06/06/2022 05:52:38 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/06/2022 05:52:38 - INFO - __main__ - ['others']
06/06/2022 05:52:38 - INFO - __main__ - Tokenizing Input ...
06/06/2022 05:52:38 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 05:52:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 05:52:38 - INFO - __main__ - Printing 3 examples
06/06/2022 05:52:38 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/06/2022 05:52:38 - INFO - __main__ - ['others']
06/06/2022 05:52:38 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/06/2022 05:52:38 - INFO - __main__ - ['others']
06/06/2022 05:52:38 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/06/2022 05:52:38 - INFO - __main__ - ['others']
06/06/2022 05:52:38 - INFO - __main__ - Tokenizing Input ...
06/06/2022 05:52:38 - INFO - __main__ - Tokenizing Output ...
06/06/2022 05:52:38 - INFO - __main__ - Tokenizing Output ...
06/06/2022 05:52:38 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 05:52:38 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 05:52:56 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 05:52:56 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 05:52:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 05:52:57 - INFO - __main__ - Starting training!
06/06/2022 05:53:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 05:53:01 - INFO - __main__ - Starting training!
06/06/2022 05:53:05 - INFO - __main__ - Step 10 Global step 10 Train loss 3.29 on epoch=2
06/06/2022 05:53:08 - INFO - __main__ - Step 20 Global step 20 Train loss 1.57 on epoch=4
06/06/2022 05:53:10 - INFO - __main__ - Step 30 Global step 30 Train loss 1.10 on epoch=7
06/06/2022 05:53:13 - INFO - __main__ - Step 40 Global step 40 Train loss 1.02 on epoch=9
06/06/2022 05:53:15 - INFO - __main__ - Step 50 Global step 50 Train loss 0.99 on epoch=12
06/06/2022 05:53:16 - INFO - __main__ - Global step 50 Train loss 1.60 Classification-F1 0.1 on epoch=12
06/06/2022 05:53:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/06/2022 05:53:19 - INFO - __main__ - Step 60 Global step 60 Train loss 0.99 on epoch=14
06/06/2022 05:53:21 - INFO - __main__ - Step 70 Global step 70 Train loss 0.96 on epoch=17
06/06/2022 05:53:24 - INFO - __main__ - Step 80 Global step 80 Train loss 0.84 on epoch=19
06/06/2022 05:53:26 - INFO - __main__ - Step 90 Global step 90 Train loss 0.80 on epoch=22
06/06/2022 05:53:29 - INFO - __main__ - Step 100 Global step 100 Train loss 0.88 on epoch=24
06/06/2022 05:53:30 - INFO - __main__ - Global step 100 Train loss 0.89 Classification-F1 0.226447199946088 on epoch=24
06/06/2022 05:53:30 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.226447199946088 on epoch=24, global_step=100
06/06/2022 05:53:32 - INFO - __main__ - Step 110 Global step 110 Train loss 0.85 on epoch=27
06/06/2022 05:53:35 - INFO - __main__ - Step 120 Global step 120 Train loss 0.78 on epoch=29
06/06/2022 05:53:37 - INFO - __main__ - Step 130 Global step 130 Train loss 0.77 on epoch=32
06/06/2022 05:53:40 - INFO - __main__ - Step 140 Global step 140 Train loss 0.75 on epoch=34
06/06/2022 05:53:42 - INFO - __main__ - Step 150 Global step 150 Train loss 0.82 on epoch=37
06/06/2022 05:53:43 - INFO - __main__ - Global step 150 Train loss 0.80 Classification-F1 0.4034656519950638 on epoch=37
06/06/2022 05:53:43 - INFO - __main__ - Saving model with best Classification-F1: 0.226447199946088 -> 0.4034656519950638 on epoch=37, global_step=150
06/06/2022 05:53:46 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=39
06/06/2022 05:53:48 - INFO - __main__ - Step 170 Global step 170 Train loss 0.73 on epoch=42
06/06/2022 05:53:51 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=44
06/06/2022 05:53:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.58 on epoch=47
06/06/2022 05:53:56 - INFO - __main__ - Step 200 Global step 200 Train loss 0.57 on epoch=49
06/06/2022 05:53:57 - INFO - __main__ - Global step 200 Train loss 0.66 Classification-F1 0.40297202797202797 on epoch=49
06/06/2022 05:53:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.57 on epoch=52
06/06/2022 05:54:02 - INFO - __main__ - Step 220 Global step 220 Train loss 0.53 on epoch=54
06/06/2022 05:54:05 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=57
06/06/2022 05:54:07 - INFO - __main__ - Step 240 Global step 240 Train loss 0.50 on epoch=59
06/06/2022 05:54:10 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=62
06/06/2022 05:54:10 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.4609896131122546 on epoch=62
06/06/2022 05:54:11 - INFO - __main__ - Saving model with best Classification-F1: 0.4034656519950638 -> 0.4609896131122546 on epoch=62, global_step=250
06/06/2022 05:54:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.48 on epoch=64
06/06/2022 05:54:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.49 on epoch=67
06/06/2022 05:54:18 - INFO - __main__ - Step 280 Global step 280 Train loss 0.43 on epoch=69
06/06/2022 05:54:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.33 on epoch=72
06/06/2022 05:54:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.36 on epoch=74
06/06/2022 05:54:24 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.559551479701015 on epoch=74
06/06/2022 05:54:24 - INFO - __main__ - Saving model with best Classification-F1: 0.4609896131122546 -> 0.559551479701015 on epoch=74, global_step=300
06/06/2022 05:54:27 - INFO - __main__ - Step 310 Global step 310 Train loss 0.38 on epoch=77
06/06/2022 05:54:29 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=79
06/06/2022 05:54:32 - INFO - __main__ - Step 330 Global step 330 Train loss 0.33 on epoch=82
06/06/2022 05:54:34 - INFO - __main__ - Step 340 Global step 340 Train loss 0.28 on epoch=84
06/06/2022 05:54:37 - INFO - __main__ - Step 350 Global step 350 Train loss 0.31 on epoch=87
06/06/2022 05:54:37 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.6038414634146342 on epoch=87
06/06/2022 05:54:38 - INFO - __main__ - Saving model with best Classification-F1: 0.559551479701015 -> 0.6038414634146342 on epoch=87, global_step=350
06/06/2022 05:54:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=89
06/06/2022 05:54:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=92
06/06/2022 05:54:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=94
06/06/2022 05:54:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.27 on epoch=97
06/06/2022 05:54:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.18 on epoch=99
06/06/2022 05:54:51 - INFO - __main__ - Global step 400 Train loss 0.26 Classification-F1 0.6399127381990285 on epoch=99
06/06/2022 05:54:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6038414634146342 -> 0.6399127381990285 on epoch=99, global_step=400
06/06/2022 05:54:54 - INFO - __main__ - Step 410 Global step 410 Train loss 0.15 on epoch=102
06/06/2022 05:54:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=104
06/06/2022 05:54:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.15 on epoch=107
06/06/2022 05:55:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.16 on epoch=109
06/06/2022 05:55:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=112
06/06/2022 05:55:05 - INFO - __main__ - Global step 450 Train loss 0.19 Classification-F1 0.6011904761904762 on epoch=112
06/06/2022 05:55:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=114
06/06/2022 05:55:11 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=117
06/06/2022 05:55:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.14 on epoch=119
06/06/2022 05:55:16 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=122
06/06/2022 05:55:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.10 on epoch=124
06/06/2022 05:55:20 - INFO - __main__ - Global step 500 Train loss 0.15 Classification-F1 0.5958754208754208 on epoch=124
06/06/2022 05:55:22 - INFO - __main__ - Step 510 Global step 510 Train loss 0.08 on epoch=127
06/06/2022 05:55:25 - INFO - __main__ - Step 520 Global step 520 Train loss 0.10 on epoch=129
06/06/2022 05:55:27 - INFO - __main__ - Step 530 Global step 530 Train loss 0.15 on epoch=132
06/06/2022 05:55:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=134
06/06/2022 05:55:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=137
06/06/2022 05:55:34 - INFO - __main__ - Global step 550 Train loss 0.11 Classification-F1 0.6550979262672811 on epoch=137
06/06/2022 05:55:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6399127381990285 -> 0.6550979262672811 on epoch=137, global_step=550
06/06/2022 05:55:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=139
06/06/2022 05:55:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.03 on epoch=142
06/06/2022 05:55:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.07 on epoch=144
06/06/2022 05:55:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=147
06/06/2022 05:55:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=149
06/06/2022 05:55:47 - INFO - __main__ - Global step 600 Train loss 0.08 Classification-F1 0.5883922279271117 on epoch=149
06/06/2022 05:55:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=152
06/06/2022 05:55:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.03 on epoch=154
06/06/2022 05:55:55 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=157
06/06/2022 05:55:58 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=159
06/06/2022 05:56:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=162
06/06/2022 05:56:01 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.5883252063015755 on epoch=162
06/06/2022 05:56:04 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=164
06/06/2022 05:56:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=167
06/06/2022 05:56:09 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=169
06/06/2022 05:56:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=172
06/06/2022 05:56:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=174
06/06/2022 05:56:16 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.6389754398826979 on epoch=174
06/06/2022 05:56:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=177
06/06/2022 05:56:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=179
06/06/2022 05:56:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=182
06/06/2022 05:56:27 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=184
06/06/2022 05:56:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=187
06/06/2022 05:56:30 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.5363650510709335 on epoch=187
06/06/2022 05:56:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=189
06/06/2022 05:56:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=192
06/06/2022 05:56:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=194
06/06/2022 05:56:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
06/06/2022 05:56:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/06/2022 05:56:45 - INFO - __main__ - Global step 800 Train loss 0.03 Classification-F1 0.5607457059069962 on epoch=199
06/06/2022 05:56:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
06/06/2022 05:56:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=204
06/06/2022 05:56:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
06/06/2022 05:56:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=209
06/06/2022 05:56:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=212
06/06/2022 05:56:59 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.6507352941176471 on epoch=212
06/06/2022 05:57:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/06/2022 05:57:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=217
06/06/2022 05:57:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.00 on epoch=219
06/06/2022 05:57:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/06/2022 05:57:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/06/2022 05:57:13 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.6697492163009404 on epoch=224
06/06/2022 05:57:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6550979262672811 -> 0.6697492163009404 on epoch=224, global_step=900
06/06/2022 05:57:15 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/06/2022 05:57:18 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/06/2022 05:57:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=232
06/06/2022 05:57:23 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/06/2022 05:57:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/06/2022 05:57:26 - INFO - __main__ - Global step 950 Train loss 0.02 Classification-F1 0.6736694677871149 on epoch=237
06/06/2022 05:57:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6697492163009404 -> 0.6736694677871149 on epoch=237, global_step=950
06/06/2022 05:57:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=239
06/06/2022 05:57:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
06/06/2022 05:57:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/06/2022 05:57:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
06/06/2022 05:57:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/06/2022 05:57:41 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.6690774876258747 on epoch=249
06/06/2022 05:57:43 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/06/2022 05:57:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=254
06/06/2022 05:57:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=257
06/06/2022 05:57:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=259
06/06/2022 05:57:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/06/2022 05:57:55 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.6529761904761906 on epoch=262
06/06/2022 05:57:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/06/2022 05:58:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=267
06/06/2022 05:58:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=269
06/06/2022 05:58:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/06/2022 05:58:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/06/2022 05:58:09 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.6709293394777267 on epoch=274
06/06/2022 05:58:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/06/2022 05:58:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/06/2022 05:58:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/06/2022 05:58:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/06/2022 05:58:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/06/2022 05:58:23 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.671549419140697 on epoch=287
06/06/2022 05:58:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/06/2022 05:58:29 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/06/2022 05:58:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/06/2022 05:58:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=297
06/06/2022 05:58:36 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/06/2022 05:58:37 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.6843783456686683 on epoch=299
06/06/2022 05:58:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6736694677871149 -> 0.6843783456686683 on epoch=299, global_step=1200
06/06/2022 05:58:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/06/2022 05:58:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/06/2022 05:58:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/06/2022 05:58:48 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/06/2022 05:58:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/06/2022 05:58:52 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.6041338776313201 on epoch=312
06/06/2022 05:58:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/06/2022 05:58:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/06/2022 05:58:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/06/2022 05:59:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/06/2022 05:59:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=324
06/06/2022 05:59:06 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.6270968614718615 on epoch=324
06/06/2022 05:59:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/06/2022 05:59:11 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/06/2022 05:59:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/06/2022 05:59:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/06/2022 05:59:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/06/2022 05:59:19 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.7341872232764074 on epoch=337
06/06/2022 05:59:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6843783456686683 -> 0.7341872232764074 on epoch=337, global_step=1350
06/06/2022 05:59:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/06/2022 05:59:25 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/06/2022 05:59:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/06/2022 05:59:30 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/06/2022 05:59:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/06/2022 05:59:34 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.6917156119742327 on epoch=349
06/06/2022 05:59:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/06/2022 05:59:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/06/2022 05:59:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/06/2022 05:59:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/06/2022 05:59:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/06/2022 05:59:48 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.6187712639325542 on epoch=362
06/06/2022 05:59:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=364
06/06/2022 05:59:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/06/2022 05:59:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/06/2022 05:59:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/06/2022 06:00:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/06/2022 06:00:02 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.613869463869464 on epoch=374
06/06/2022 06:00:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/06/2022 06:00:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/06/2022 06:00:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/06/2022 06:00:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=384
06/06/2022 06:00:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/06/2022 06:00:17 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.5273127549128662 on epoch=387
06/06/2022 06:00:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/06/2022 06:00:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/06/2022 06:00:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/06/2022 06:00:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/06/2022 06:00:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/06/2022 06:00:31 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.6325004430267589 on epoch=399
06/06/2022 06:00:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/06/2022 06:00:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/06/2022 06:00:39 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/06/2022 06:00:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/06/2022 06:00:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/06/2022 06:00:46 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.6534167742332042 on epoch=412
06/06/2022 06:00:49 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=414
06/06/2022 06:00:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/06/2022 06:00:54 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/06/2022 06:00:57 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/06/2022 06:00:59 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/06/2022 06:01:01 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.6863544721407624 on epoch=424
06/06/2022 06:01:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/06/2022 06:01:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/06/2022 06:01:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/06/2022 06:01:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/06/2022 06:01:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/06/2022 06:01:15 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.6463882360621491 on epoch=437
06/06/2022 06:01:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/06/2022 06:01:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/06/2022 06:01:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/06/2022 06:01:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/06/2022 06:01:29 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/06/2022 06:01:30 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6698863636363636 on epoch=449
06/06/2022 06:01:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/06/2022 06:01:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/06/2022 06:01:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/06/2022 06:01:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/06/2022 06:01:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/06/2022 06:01:44 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6865609880315763 on epoch=462
06/06/2022 06:01:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/06/2022 06:01:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/06/2022 06:01:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/06/2022 06:01:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/06/2022 06:01:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/06/2022 06:01:59 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.6508658008658009 on epoch=474
06/06/2022 06:02:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/06/2022 06:02:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/06/2022 06:02:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/06/2022 06:02:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/06/2022 06:02:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/06/2022 06:02:13 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.6681559427289977 on epoch=487
06/06/2022 06:02:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/06/2022 06:02:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/06/2022 06:02:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=494
06/06/2022 06:02:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=497
06/06/2022 06:02:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/06/2022 06:02:28 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6354732771862917 on epoch=499
06/06/2022 06:02:31 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/06/2022 06:02:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/06/2022 06:02:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/06/2022 06:02:38 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/06/2022 06:02:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/06/2022 06:02:42 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.6231374807987711 on epoch=512
06/06/2022 06:02:45 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/06/2022 06:02:48 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/06/2022 06:02:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/06/2022 06:02:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/06/2022 06:02:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/06/2022 06:02:57 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.6657488209212347 on epoch=524
06/06/2022 06:03:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/06/2022 06:03:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 06:03:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/06/2022 06:03:07 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/06/2022 06:03:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/06/2022 06:03:12 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.6853640358964902 on epoch=537
06/06/2022 06:03:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/06/2022 06:03:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/06/2022 06:03:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/06/2022 06:03:22 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/06/2022 06:03:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/06/2022 06:03:26 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.667600656355099 on epoch=549
06/06/2022 06:03:29 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 06:03:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/06/2022 06:03:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=557
06/06/2022 06:03:37 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=559
06/06/2022 06:03:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/06/2022 06:03:41 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6690894748704079 on epoch=562
06/06/2022 06:03:44 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/06/2022 06:03:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/06/2022 06:03:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/06/2022 06:03:52 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/06/2022 06:03:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 06:03:56 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.6994152453343221 on epoch=574
06/06/2022 06:03:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 06:04:01 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 06:04:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/06/2022 06:04:07 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/06/2022 06:04:09 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 06:04:11 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.6846366995073891 on epoch=587
06/06/2022 06:04:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/06/2022 06:04:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/06/2022 06:04:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 06:04:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/06/2022 06:04:25 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 06:04:26 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.6893173345759553 on epoch=599
06/06/2022 06:04:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 06:04:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/06/2022 06:04:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/06/2022 06:04:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=609
06/06/2022 06:04:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 06:04:41 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.6690774876258747 on epoch=612
06/06/2022 06:04:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 06:04:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 06:04:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/06/2022 06:04:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/06/2022 06:04:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 06:04:55 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6997018620002491 on epoch=624
06/06/2022 06:04:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/06/2022 06:05:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/06/2022 06:05:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/06/2022 06:05:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/06/2022 06:05:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 06:05:11 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.6855263564454332 on epoch=637
06/06/2022 06:05:13 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 06:05:16 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/06/2022 06:05:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 06:05:21 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 06:05:24 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 06:05:25 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.6855263564454332 on epoch=649
06/06/2022 06:05:28 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/06/2022 06:05:31 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 06:05:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 06:05:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 06:05:39 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 06:05:40 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7029281784565433 on epoch=662
06/06/2022 06:05:43 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 06:05:45 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 06:05:48 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 06:05:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 06:05:53 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 06:05:56 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6689991668238697 on epoch=674
06/06/2022 06:05:58 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/06/2022 06:06:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 06:06:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/06/2022 06:06:06 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 06:06:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/06/2022 06:06:11 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6666965352449225 on epoch=687
06/06/2022 06:06:14 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 06:06:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=692
06/06/2022 06:06:19 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/06/2022 06:06:22 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 06:06:24 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=699
06/06/2022 06:06:26 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6714285714285715 on epoch=699
06/06/2022 06:06:29 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 06:06:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 06:06:34 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 06:06:37 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/06/2022 06:06:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 06:06:42 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6715012426219322 on epoch=712
06/06/2022 06:06:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 06:06:47 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 06:06:50 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 06:06:53 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/06/2022 06:06:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 06:06:58 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7166057122953675 on epoch=724
06/06/2022 06:07:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 06:07:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/06/2022 06:07:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 06:07:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 06:07:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 06:07:13 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7023946360153257 on epoch=737
06/06/2022 06:07:16 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 06:07:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 06:07:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 06:07:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/06/2022 06:07:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 06:07:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 06:07:28 - INFO - __main__ - Printing 3 examples
06/06/2022 06:07:28 - INFO - __main__ -  [emo] how cause yes am listening
06/06/2022 06:07:28 - INFO - __main__ - ['others']
06/06/2022 06:07:28 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/06/2022 06:07:28 - INFO - __main__ - ['others']
06/06/2022 06:07:28 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/06/2022 06:07:28 - INFO - __main__ - ['others']
06/06/2022 06:07:28 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:07:28 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:07:28 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 06:07:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 06:07:28 - INFO - __main__ - Printing 3 examples
06/06/2022 06:07:28 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/06/2022 06:07:28 - INFO - __main__ - ['others']
06/06/2022 06:07:28 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/06/2022 06:07:28 - INFO - __main__ - ['others']
06/06/2022 06:07:28 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/06/2022 06:07:28 - INFO - __main__ - ['others']
06/06/2022 06:07:28 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:07:28 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:07:28 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 06:07:30 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6868585043988269 on epoch=749
06/06/2022 06:07:30 - INFO - __main__ - save last model!
06/06/2022 06:07:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 06:07:30 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 06:07:30 - INFO - __main__ - Printing 3 examples
06/06/2022 06:07:30 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 06:07:30 - INFO - __main__ - ['others']
06/06/2022 06:07:30 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 06:07:30 - INFO - __main__ - ['others']
06/06/2022 06:07:30 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 06:07:30 - INFO - __main__ - ['others']
06/06/2022 06:07:30 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:07:32 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:07:38 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 06:07:47 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 06:07:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 06:07:48 - INFO - __main__ - Starting training!
06/06/2022 06:12:40 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_100_0.5_8_predictions.txt
06/06/2022 06:12:40 - INFO - __main__ - Classification-F1 on test data: 0.4246
06/06/2022 06:12:41 - INFO - __main__ - prefix=emo_16_100, lr=0.5, bsz=8, dev_performance=0.7341872232764074, test_performance=0.4246170218670077
06/06/2022 06:12:41 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.4, bsz=8 ...
06/06/2022 06:12:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 06:12:41 - INFO - __main__ - Printing 3 examples
06/06/2022 06:12:41 - INFO - __main__ -  [emo] how cause yes am listening
06/06/2022 06:12:41 - INFO - __main__ - ['others']
06/06/2022 06:12:41 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/06/2022 06:12:41 - INFO - __main__ - ['others']
06/06/2022 06:12:41 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/06/2022 06:12:41 - INFO - __main__ - ['others']
06/06/2022 06:12:41 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:12:42 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:12:42 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 06:12:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 06:12:42 - INFO - __main__ - Printing 3 examples
06/06/2022 06:12:42 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/06/2022 06:12:42 - INFO - __main__ - ['others']
06/06/2022 06:12:42 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/06/2022 06:12:42 - INFO - __main__ - ['others']
06/06/2022 06:12:42 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/06/2022 06:12:42 - INFO - __main__ - ['others']
06/06/2022 06:12:42 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:12:42 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:12:42 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 06:12:56 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 06:12:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 06:12:57 - INFO - __main__ - Starting training!
06/06/2022 06:13:00 - INFO - __main__ - Step 10 Global step 10 Train loss 3.62 on epoch=2
06/06/2022 06:13:03 - INFO - __main__ - Step 20 Global step 20 Train loss 1.97 on epoch=4
06/06/2022 06:13:06 - INFO - __main__ - Step 30 Global step 30 Train loss 1.34 on epoch=7
06/06/2022 06:13:08 - INFO - __main__ - Step 40 Global step 40 Train loss 1.10 on epoch=9
06/06/2022 06:13:11 - INFO - __main__ - Step 50 Global step 50 Train loss 1.02 on epoch=12
06/06/2022 06:13:11 - INFO - __main__ - Global step 50 Train loss 1.81 Classification-F1 0.2988615185155174 on epoch=12
06/06/2022 06:13:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2988615185155174 on epoch=12, global_step=50
06/06/2022 06:13:14 - INFO - __main__ - Step 60 Global step 60 Train loss 0.91 on epoch=14
06/06/2022 06:13:17 - INFO - __main__ - Step 70 Global step 70 Train loss 0.94 on epoch=17
06/06/2022 06:13:19 - INFO - __main__ - Step 80 Global step 80 Train loss 1.08 on epoch=19
06/06/2022 06:13:22 - INFO - __main__ - Step 90 Global step 90 Train loss 0.81 on epoch=22
06/06/2022 06:13:25 - INFO - __main__ - Step 100 Global step 100 Train loss 0.83 on epoch=24
06/06/2022 06:13:25 - INFO - __main__ - Global step 100 Train loss 0.91 Classification-F1 0.25 on epoch=24
06/06/2022 06:13:28 - INFO - __main__ - Step 110 Global step 110 Train loss 0.82 on epoch=27
06/06/2022 06:13:31 - INFO - __main__ - Step 120 Global step 120 Train loss 0.78 on epoch=29
06/06/2022 06:13:33 - INFO - __main__ - Step 130 Global step 130 Train loss 0.81 on epoch=32
06/06/2022 06:13:36 - INFO - __main__ - Step 140 Global step 140 Train loss 0.70 on epoch=34
06/06/2022 06:13:39 - INFO - __main__ - Step 150 Global step 150 Train loss 0.80 on epoch=37
06/06/2022 06:13:40 - INFO - __main__ - Global step 150 Train loss 0.78 Classification-F1 0.473903251077164 on epoch=37
06/06/2022 06:13:40 - INFO - __main__ - Saving model with best Classification-F1: 0.2988615185155174 -> 0.473903251077164 on epoch=37, global_step=150
06/06/2022 06:13:43 - INFO - __main__ - Step 160 Global step 160 Train loss 0.74 on epoch=39
06/06/2022 06:13:45 - INFO - __main__ - Step 170 Global step 170 Train loss 0.76 on epoch=42
06/06/2022 06:13:48 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=44
06/06/2022 06:13:50 - INFO - __main__ - Step 190 Global step 190 Train loss 0.68 on epoch=47
06/06/2022 06:13:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.56 on epoch=49
06/06/2022 06:13:54 - INFO - __main__ - Global step 200 Train loss 0.68 Classification-F1 0.40614035087719297 on epoch=49
06/06/2022 06:13:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.61 on epoch=52
06/06/2022 06:13:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.69 on epoch=54
06/06/2022 06:14:02 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=57
06/06/2022 06:14:05 - INFO - __main__ - Step 240 Global step 240 Train loss 0.58 on epoch=59
06/06/2022 06:14:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.53 on epoch=62
06/06/2022 06:14:08 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.5305930930930931 on epoch=62
06/06/2022 06:14:08 - INFO - __main__ - Saving model with best Classification-F1: 0.473903251077164 -> 0.5305930930930931 on epoch=62, global_step=250
06/06/2022 06:14:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=64
06/06/2022 06:14:14 - INFO - __main__ - Step 270 Global step 270 Train loss 0.50 on epoch=67
06/06/2022 06:14:16 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=69
06/06/2022 06:14:19 - INFO - __main__ - Step 290 Global step 290 Train loss 0.50 on epoch=72
06/06/2022 06:14:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.41 on epoch=74
06/06/2022 06:14:23 - INFO - __main__ - Global step 300 Train loss 0.47 Classification-F1 0.4743356643356644 on epoch=74
06/06/2022 06:14:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.39 on epoch=77
06/06/2022 06:14:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=79
06/06/2022 06:14:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=82
06/06/2022 06:14:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=84
06/06/2022 06:14:36 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=87
06/06/2022 06:14:37 - INFO - __main__ - Global step 350 Train loss 0.38 Classification-F1 0.6319095176270848 on epoch=87
06/06/2022 06:14:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5305930930930931 -> 0.6319095176270848 on epoch=87, global_step=350
06/06/2022 06:14:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=89
06/06/2022 06:14:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.34 on epoch=92
06/06/2022 06:14:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=94
06/06/2022 06:14:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/06/2022 06:14:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=99
06/06/2022 06:14:51 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.5469416027280478 on epoch=99
06/06/2022 06:14:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.36 on epoch=102
06/06/2022 06:14:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=104
06/06/2022 06:14:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=107
06/06/2022 06:15:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=109
06/06/2022 06:15:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=112
06/06/2022 06:15:05 - INFO - __main__ - Global step 450 Train loss 0.27 Classification-F1 0.5583510057194268 on epoch=112
06/06/2022 06:15:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=114
06/06/2022 06:15:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=117
06/06/2022 06:15:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=119
06/06/2022 06:15:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=122
06/06/2022 06:15:18 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=124
06/06/2022 06:15:19 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.5098443223443223 on epoch=124
06/06/2022 06:15:22 - INFO - __main__ - Step 510 Global step 510 Train loss 0.15 on epoch=127
06/06/2022 06:15:24 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=129
06/06/2022 06:15:27 - INFO - __main__ - Step 530 Global step 530 Train loss 0.10 on epoch=132
06/06/2022 06:15:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=134
06/06/2022 06:15:32 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=137
06/06/2022 06:15:34 - INFO - __main__ - Global step 550 Train loss 0.13 Classification-F1 0.557843137254902 on epoch=137
06/06/2022 06:15:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=139
06/06/2022 06:15:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=142
06/06/2022 06:15:42 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=144
06/06/2022 06:15:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.17 on epoch=147
06/06/2022 06:15:47 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=149
06/06/2022 06:15:48 - INFO - __main__ - Global step 600 Train loss 0.16 Classification-F1 0.4922743922743923 on epoch=149
06/06/2022 06:15:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=152
06/06/2022 06:15:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=154
06/06/2022 06:15:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=157
06/06/2022 06:15:58 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=159
06/06/2022 06:16:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=162
06/06/2022 06:16:02 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.5517411281418073 on epoch=162
06/06/2022 06:16:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=164
06/06/2022 06:16:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=167
06/06/2022 06:16:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=169
06/06/2022 06:16:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=172
06/06/2022 06:16:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=174
06/06/2022 06:16:16 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.5377839756592292 on epoch=174
06/06/2022 06:16:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=177
06/06/2022 06:16:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=179
06/06/2022 06:16:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/06/2022 06:16:27 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=184
06/06/2022 06:16:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=187
06/06/2022 06:16:30 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.5385383268597443 on epoch=187
06/06/2022 06:16:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=189
06/06/2022 06:16:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=192
06/06/2022 06:16:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=194
06/06/2022 06:16:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=197
06/06/2022 06:16:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
06/06/2022 06:16:45 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.5636408730158731 on epoch=199
06/06/2022 06:16:48 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=202
06/06/2022 06:16:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=204
06/06/2022 06:16:53 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=207
06/06/2022 06:16:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
06/06/2022 06:16:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=212
06/06/2022 06:16:59 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.5445468509984639 on epoch=212
06/06/2022 06:17:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/06/2022 06:17:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=217
06/06/2022 06:17:07 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=219
06/06/2022 06:17:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=222
06/06/2022 06:17:12 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=224
06/06/2022 06:17:13 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.5507822477650064 on epoch=224
06/06/2022 06:17:16 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=227
06/06/2022 06:17:18 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/06/2022 06:17:21 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=232
06/06/2022 06:17:24 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/06/2022 06:17:26 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/06/2022 06:17:27 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.6185483870967743 on epoch=237
06/06/2022 06:17:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
06/06/2022 06:17:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=242
06/06/2022 06:17:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/06/2022 06:17:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=247
06/06/2022 06:17:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=249
06/06/2022 06:17:42 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.5446098616830325 on epoch=249
06/06/2022 06:17:44 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/06/2022 06:17:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/06/2022 06:17:49 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/06/2022 06:17:52 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=259
06/06/2022 06:17:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/06/2022 06:17:56 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.5533452807646356 on epoch=262
06/06/2022 06:17:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=264
06/06/2022 06:18:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
06/06/2022 06:18:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
06/06/2022 06:18:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/06/2022 06:18:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/06/2022 06:18:10 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.5340172285097541 on epoch=274
06/06/2022 06:18:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=277
06/06/2022 06:18:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/06/2022 06:18:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/06/2022 06:18:21 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=284
06/06/2022 06:18:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/06/2022 06:18:25 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.6131400208986415 on epoch=287
06/06/2022 06:18:27 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=289
06/06/2022 06:18:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/06/2022 06:18:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/06/2022 06:18:35 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/06/2022 06:18:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/06/2022 06:18:39 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.6342777388733272 on epoch=299
06/06/2022 06:18:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6319095176270848 -> 0.6342777388733272 on epoch=299, global_step=1200
06/06/2022 06:18:42 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/06/2022 06:18:44 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/06/2022 06:18:47 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/06/2022 06:18:50 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=309
06/06/2022 06:18:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/06/2022 06:18:53 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.643560606060606 on epoch=312
06/06/2022 06:18:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6342777388733272 -> 0.643560606060606 on epoch=312, global_step=1250
06/06/2022 06:18:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/06/2022 06:18:59 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/06/2022 06:19:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/06/2022 06:19:04 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/06/2022 06:19:07 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/06/2022 06:19:08 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.5986772486772487 on epoch=324
06/06/2022 06:19:11 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=327
06/06/2022 06:19:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/06/2022 06:19:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/06/2022 06:19:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=334
06/06/2022 06:19:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/06/2022 06:19:22 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.598873167838685 on epoch=337
06/06/2022 06:19:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/06/2022 06:19:28 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/06/2022 06:19:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/06/2022 06:19:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/06/2022 06:19:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/06/2022 06:19:36 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.616207862455327 on epoch=349
06/06/2022 06:19:39 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/06/2022 06:19:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/06/2022 06:19:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/06/2022 06:19:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/06/2022 06:19:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/06/2022 06:19:51 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.598873167838685 on epoch=362
06/06/2022 06:19:53 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/06/2022 06:19:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/06/2022 06:19:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/06/2022 06:20:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/06/2022 06:20:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/06/2022 06:20:05 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.5919584842734747 on epoch=374
06/06/2022 06:20:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/06/2022 06:20:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/06/2022 06:20:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
06/06/2022 06:20:15 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/06/2022 06:20:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/06/2022 06:20:19 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.6039209028263258 on epoch=387
06/06/2022 06:20:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/06/2022 06:20:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/06/2022 06:20:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/06/2022 06:20:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/06/2022 06:20:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/06/2022 06:20:33 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.5823525936429162 on epoch=399
06/06/2022 06:20:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/06/2022 06:20:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/06/2022 06:20:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/06/2022 06:20:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/06/2022 06:20:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/06/2022 06:20:48 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.6493055555555556 on epoch=412
06/06/2022 06:20:48 - INFO - __main__ - Saving model with best Classification-F1: 0.643560606060606 -> 0.6493055555555556 on epoch=412, global_step=1650
06/06/2022 06:20:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/06/2022 06:20:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/06/2022 06:20:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/06/2022 06:20:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/06/2022 06:21:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/06/2022 06:21:02 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.6158271908271907 on epoch=424
06/06/2022 06:21:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/06/2022 06:21:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/06/2022 06:21:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/06/2022 06:21:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/06/2022 06:21:16 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/06/2022 06:21:17 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.6175534544555679 on epoch=437
06/06/2022 06:21:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/06/2022 06:21:22 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/06/2022 06:21:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/06/2022 06:21:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
06/06/2022 06:21:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/06/2022 06:21:31 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.5968253968253968 on epoch=449
06/06/2022 06:21:34 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/06/2022 06:21:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/06/2022 06:21:39 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/06/2022 06:21:42 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/06/2022 06:21:44 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/06/2022 06:21:46 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.6316974542780995 on epoch=462
06/06/2022 06:21:48 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=464
06/06/2022 06:21:51 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/06/2022 06:21:54 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/06/2022 06:21:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/06/2022 06:21:59 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=474
06/06/2022 06:22:00 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6163304572648288 on epoch=474
06/06/2022 06:22:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/06/2022 06:22:05 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/06/2022 06:22:08 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/06/2022 06:22:11 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/06/2022 06:22:13 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/06/2022 06:22:14 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.6070557491289199 on epoch=487
06/06/2022 06:22:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/06/2022 06:22:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/06/2022 06:22:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/06/2022 06:22:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/06/2022 06:22:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/06/2022 06:22:29 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.5843822843822843 on epoch=499
06/06/2022 06:22:32 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/06/2022 06:22:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/06/2022 06:22:37 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=507
06/06/2022 06:22:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/06/2022 06:22:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/06/2022 06:22:43 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.6025078369905955 on epoch=512
06/06/2022 06:22:46 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=514
06/06/2022 06:22:48 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/06/2022 06:22:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/06/2022 06:22:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/06/2022 06:22:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/06/2022 06:22:58 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6206097823744883 on epoch=524
06/06/2022 06:23:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/06/2022 06:23:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 06:23:06 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/06/2022 06:23:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/06/2022 06:23:11 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/06/2022 06:23:12 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6023136773136772 on epoch=537
06/06/2022 06:23:15 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/06/2022 06:23:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 06:23:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/06/2022 06:23:22 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/06/2022 06:23:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/06/2022 06:23:26 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.6508640855011092 on epoch=549
06/06/2022 06:23:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6493055555555556 -> 0.6508640855011092 on epoch=549, global_step=2200
06/06/2022 06:23:29 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 06:23:31 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/06/2022 06:23:34 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.17 on epoch=557
06/06/2022 06:23:37 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/06/2022 06:23:39 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/06/2022 06:23:40 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.6023136773136772 on epoch=562
06/06/2022 06:23:43 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/06/2022 06:23:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/06/2022 06:23:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=569
06/06/2022 06:23:51 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/06/2022 06:23:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 06:23:55 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.5884316245362511 on epoch=574
06/06/2022 06:23:57 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 06:24:00 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=579
06/06/2022 06:24:03 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/06/2022 06:24:05 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/06/2022 06:24:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 06:24:09 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.5816017316017317 on epoch=587
06/06/2022 06:24:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/06/2022 06:24:14 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/06/2022 06:24:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
06/06/2022 06:24:20 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=597
06/06/2022 06:24:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 06:24:24 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.5843822843822843 on epoch=599
06/06/2022 06:24:26 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=602
06/06/2022 06:24:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 06:24:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 06:24:34 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/06/2022 06:24:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 06:24:38 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.5599271585137664 on epoch=612
06/06/2022 06:24:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 06:24:43 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 06:24:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 06:24:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/06/2022 06:24:52 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 06:24:53 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6347431077694237 on epoch=624
06/06/2022 06:24:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/06/2022 06:24:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/06/2022 06:25:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.09 on epoch=632
06/06/2022 06:25:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/06/2022 06:25:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 06:25:08 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6201708201708201 on epoch=637
06/06/2022 06:25:10 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 06:25:13 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/06/2022 06:25:16 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 06:25:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 06:25:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 06:25:22 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.5641308922558923 on epoch=649
06/06/2022 06:25:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/06/2022 06:25:28 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 06:25:30 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 06:25:33 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 06:25:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/06/2022 06:25:37 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.6333369659982563 on epoch=662
06/06/2022 06:25:39 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.10 on epoch=664
06/06/2022 06:25:42 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 06:25:45 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/06/2022 06:25:48 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=672
06/06/2022 06:25:50 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 06:25:51 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.6652526395173454 on epoch=674
06/06/2022 06:25:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6508640855011092 -> 0.6652526395173454 on epoch=674, global_step=2700
06/06/2022 06:25:54 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/06/2022 06:25:57 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 06:25:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 06:26:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 06:26:05 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 06:26:06 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6298151092268739 on epoch=687
06/06/2022 06:26:09 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/06/2022 06:26:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 06:26:14 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/06/2022 06:26:17 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/06/2022 06:26:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 06:26:21 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.618646138807429 on epoch=699
06/06/2022 06:26:23 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 06:26:26 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/06/2022 06:26:29 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 06:26:31 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=709
06/06/2022 06:26:34 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 06:26:35 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.5986111111111112 on epoch=712
06/06/2022 06:26:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/06/2022 06:26:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 06:26:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 06:26:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/06/2022 06:26:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 06:26:50 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6379857781670661 on epoch=724
06/06/2022 06:26:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 06:26:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 06:26:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=732
06/06/2022 06:27:01 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 06:27:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=737
06/06/2022 06:27:05 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.641688229544017 on epoch=737
06/06/2022 06:27:07 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 06:27:10 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 06:27:13 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 06:27:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/06/2022 06:27:18 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/06/2022 06:27:19 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.5964010004332585 on epoch=749
06/06/2022 06:27:19 - INFO - __main__ - save last model!
06/06/2022 06:27:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 06:27:19 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 06:27:19 - INFO - __main__ - Printing 3 examples
06/06/2022 06:27:19 - INFO - __main__ -  [emo] how cause yes am listening
06/06/2022 06:27:19 - INFO - __main__ - ['others']
06/06/2022 06:27:19 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/06/2022 06:27:19 - INFO - __main__ - ['others']
06/06/2022 06:27:19 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/06/2022 06:27:19 - INFO - __main__ - ['others']
06/06/2022 06:27:19 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:27:19 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 06:27:19 - INFO - __main__ - Printing 3 examples
06/06/2022 06:27:19 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 06:27:19 - INFO - __main__ - ['others']
06/06/2022 06:27:19 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 06:27:19 - INFO - __main__ - ['others']
06/06/2022 06:27:19 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 06:27:19 - INFO - __main__ - ['others']
06/06/2022 06:27:19 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:27:19 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:27:19 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 06:27:19 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 06:27:19 - INFO - __main__ - Printing 3 examples
06/06/2022 06:27:19 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/06/2022 06:27:19 - INFO - __main__ - ['others']
06/06/2022 06:27:19 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/06/2022 06:27:19 - INFO - __main__ - ['others']
06/06/2022 06:27:19 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/06/2022 06:27:19 - INFO - __main__ - ['others']
06/06/2022 06:27:19 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:27:19 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:27:19 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 06:27:21 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:27:27 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 06:27:35 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 06:27:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 06:27:36 - INFO - __main__ - Starting training!
06/06/2022 06:29:02 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_100_0.4_8_predictions.txt
06/06/2022 06:29:02 - INFO - __main__ - Classification-F1 on test data: 0.4033
06/06/2022 06:29:02 - INFO - __main__ - prefix=emo_16_100, lr=0.4, bsz=8, dev_performance=0.6652526395173454, test_performance=0.40328780166295913
06/06/2022 06:29:02 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.3, bsz=8 ...
06/06/2022 06:29:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 06:29:03 - INFO - __main__ - Printing 3 examples
06/06/2022 06:29:03 - INFO - __main__ -  [emo] how cause yes am listening
06/06/2022 06:29:03 - INFO - __main__ - ['others']
06/06/2022 06:29:03 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/06/2022 06:29:03 - INFO - __main__ - ['others']
06/06/2022 06:29:03 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/06/2022 06:29:03 - INFO - __main__ - ['others']
06/06/2022 06:29:03 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:29:03 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:29:03 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 06:29:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 06:29:03 - INFO - __main__ - Printing 3 examples
06/06/2022 06:29:03 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/06/2022 06:29:03 - INFO - __main__ - ['others']
06/06/2022 06:29:03 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/06/2022 06:29:03 - INFO - __main__ - ['others']
06/06/2022 06:29:03 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/06/2022 06:29:03 - INFO - __main__ - ['others']
06/06/2022 06:29:03 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:29:03 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:29:03 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 06:29:23 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 06:29:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 06:29:24 - INFO - __main__ - Starting training!
06/06/2022 06:29:27 - INFO - __main__ - Step 10 Global step 10 Train loss 3.73 on epoch=2
06/06/2022 06:29:30 - INFO - __main__ - Step 20 Global step 20 Train loss 2.28 on epoch=4
06/06/2022 06:29:32 - INFO - __main__ - Step 30 Global step 30 Train loss 1.61 on epoch=7
06/06/2022 06:29:35 - INFO - __main__ - Step 40 Global step 40 Train loss 1.21 on epoch=9
06/06/2022 06:29:38 - INFO - __main__ - Step 50 Global step 50 Train loss 1.04 on epoch=12
06/06/2022 06:29:38 - INFO - __main__ - Global step 50 Train loss 1.97 Classification-F1 0.2657869249394673 on epoch=12
06/06/2022 06:29:39 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2657869249394673 on epoch=12, global_step=50
06/06/2022 06:29:41 - INFO - __main__ - Step 60 Global step 60 Train loss 0.98 on epoch=14
06/06/2022 06:29:44 - INFO - __main__ - Step 70 Global step 70 Train loss 1.08 on epoch=17
06/06/2022 06:29:47 - INFO - __main__ - Step 80 Global step 80 Train loss 0.90 on epoch=19
06/06/2022 06:29:49 - INFO - __main__ - Step 90 Global step 90 Train loss 1.03 on epoch=22
06/06/2022 06:29:52 - INFO - __main__ - Step 100 Global step 100 Train loss 0.96 on epoch=24
06/06/2022 06:29:53 - INFO - __main__ - Global step 100 Train loss 0.99 Classification-F1 0.2501085540599218 on epoch=24
06/06/2022 06:29:55 - INFO - __main__ - Step 110 Global step 110 Train loss 0.94 on epoch=27
06/06/2022 06:29:58 - INFO - __main__ - Step 120 Global step 120 Train loss 0.83 on epoch=29
06/06/2022 06:30:01 - INFO - __main__ - Step 130 Global step 130 Train loss 0.90 on epoch=32
06/06/2022 06:30:03 - INFO - __main__ - Step 140 Global step 140 Train loss 0.83 on epoch=34
06/06/2022 06:30:06 - INFO - __main__ - Step 150 Global step 150 Train loss 0.83 on epoch=37
06/06/2022 06:30:07 - INFO - __main__ - Global step 150 Train loss 0.87 Classification-F1 0.4038557644254796 on epoch=37
06/06/2022 06:30:07 - INFO - __main__ - Saving model with best Classification-F1: 0.2657869249394673 -> 0.4038557644254796 on epoch=37, global_step=150
06/06/2022 06:30:10 - INFO - __main__ - Step 160 Global step 160 Train loss 0.81 on epoch=39
06/06/2022 06:30:12 - INFO - __main__ - Step 170 Global step 170 Train loss 0.84 on epoch=42
06/06/2022 06:30:15 - INFO - __main__ - Step 180 Global step 180 Train loss 0.77 on epoch=44
06/06/2022 06:30:18 - INFO - __main__ - Step 190 Global step 190 Train loss 0.75 on epoch=47
06/06/2022 06:30:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.69 on epoch=49
06/06/2022 06:30:21 - INFO - __main__ - Global step 200 Train loss 0.77 Classification-F1 0.317583807716635 on epoch=49
06/06/2022 06:30:24 - INFO - __main__ - Step 210 Global step 210 Train loss 0.77 on epoch=52
06/06/2022 06:30:26 - INFO - __main__ - Step 220 Global step 220 Train loss 0.72 on epoch=54
06/06/2022 06:30:29 - INFO - __main__ - Step 230 Global step 230 Train loss 0.72 on epoch=57
06/06/2022 06:30:32 - INFO - __main__ - Step 240 Global step 240 Train loss 0.74 on epoch=59
06/06/2022 06:30:34 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=62
06/06/2022 06:30:35 - INFO - __main__ - Global step 250 Train loss 0.71 Classification-F1 0.6005081300813008 on epoch=62
06/06/2022 06:30:35 - INFO - __main__ - Saving model with best Classification-F1: 0.4038557644254796 -> 0.6005081300813008 on epoch=62, global_step=250
06/06/2022 06:30:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=64
06/06/2022 06:30:40 - INFO - __main__ - Step 270 Global step 270 Train loss 0.63 on epoch=67
06/06/2022 06:30:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.63 on epoch=69
06/06/2022 06:30:46 - INFO - __main__ - Step 290 Global step 290 Train loss 0.68 on epoch=72
06/06/2022 06:30:48 - INFO - __main__ - Step 300 Global step 300 Train loss 0.57 on epoch=74
06/06/2022 06:30:49 - INFO - __main__ - Global step 300 Train loss 0.61 Classification-F1 0.4740935800843635 on epoch=74
06/06/2022 06:30:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.52 on epoch=77
06/06/2022 06:30:54 - INFO - __main__ - Step 320 Global step 320 Train loss 0.46 on epoch=79
06/06/2022 06:30:57 - INFO - __main__ - Step 330 Global step 330 Train loss 0.60 on epoch=82
06/06/2022 06:31:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=84
06/06/2022 06:31:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.60 on epoch=87
06/06/2022 06:31:03 - INFO - __main__ - Global step 350 Train loss 0.55 Classification-F1 0.5741496932314722 on epoch=87
06/06/2022 06:31:06 - INFO - __main__ - Step 360 Global step 360 Train loss 0.43 on epoch=89
06/06/2022 06:31:09 - INFO - __main__ - Step 370 Global step 370 Train loss 0.47 on epoch=92
06/06/2022 06:31:11 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=94
06/06/2022 06:31:14 - INFO - __main__ - Step 390 Global step 390 Train loss 0.49 on epoch=97
06/06/2022 06:31:17 - INFO - __main__ - Step 400 Global step 400 Train loss 0.47 on epoch=99
06/06/2022 06:31:17 - INFO - __main__ - Global step 400 Train loss 0.44 Classification-F1 0.5248736176129623 on epoch=99
06/06/2022 06:31:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=102
06/06/2022 06:31:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.42 on epoch=104
06/06/2022 06:31:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=107
06/06/2022 06:31:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.42 on epoch=109
06/06/2022 06:31:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.40 on epoch=112
06/06/2022 06:31:31 - INFO - __main__ - Global step 450 Train loss 0.40 Classification-F1 0.5554487179487179 on epoch=112
06/06/2022 06:31:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.44 on epoch=114
06/06/2022 06:31:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.47 on epoch=117
06/06/2022 06:31:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.35 on epoch=119
06/06/2022 06:31:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.34 on epoch=122
06/06/2022 06:31:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.36 on epoch=124
06/06/2022 06:31:45 - INFO - __main__ - Global step 500 Train loss 0.39 Classification-F1 0.6211172305271441 on epoch=124
06/06/2022 06:31:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6005081300813008 -> 0.6211172305271441 on epoch=124, global_step=500
06/06/2022 06:31:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.31 on epoch=127
06/06/2022 06:31:50 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=129
06/06/2022 06:31:53 - INFO - __main__ - Step 530 Global step 530 Train loss 0.30 on epoch=132
06/06/2022 06:31:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.35 on epoch=134
06/06/2022 06:31:58 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
06/06/2022 06:31:59 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.5751099080480901 on epoch=137
06/06/2022 06:32:02 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=139
06/06/2022 06:32:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=142
06/06/2022 06:32:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=144
06/06/2022 06:32:10 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=147
06/06/2022 06:32:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=149
06/06/2022 06:32:13 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.6413829413829414 on epoch=149
06/06/2022 06:32:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6211172305271441 -> 0.6413829413829414 on epoch=149, global_step=600
06/06/2022 06:32:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=152
06/06/2022 06:32:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/06/2022 06:32:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=157
06/06/2022 06:32:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=159
06/06/2022 06:32:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=162
06/06/2022 06:32:27 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.5996349290466938 on epoch=162
06/06/2022 06:32:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=164
06/06/2022 06:32:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=167
06/06/2022 06:32:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=169
06/06/2022 06:32:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=172
06/06/2022 06:32:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=174
06/06/2022 06:32:42 - INFO - __main__ - Global step 700 Train loss 0.14 Classification-F1 0.5775171065493646 on epoch=174
06/06/2022 06:32:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=177
06/06/2022 06:32:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=179
06/06/2022 06:32:50 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=182
06/06/2022 06:32:52 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=184
06/06/2022 06:32:55 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=187
06/06/2022 06:32:56 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.5995098039215686 on epoch=187
06/06/2022 06:32:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=189
06/06/2022 06:33:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=192
06/06/2022 06:33:04 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=194
06/06/2022 06:33:07 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=197
06/06/2022 06:33:09 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
06/06/2022 06:33:10 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.5440584708877392 on epoch=199
06/06/2022 06:33:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=202
06/06/2022 06:33:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=204
06/06/2022 06:33:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/06/2022 06:33:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=209
06/06/2022 06:33:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
06/06/2022 06:33:25 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.5413967258794845 on epoch=212
06/06/2022 06:33:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/06/2022 06:33:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=217
06/06/2022 06:33:32 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=219
06/06/2022 06:33:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=222
06/06/2022 06:33:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
06/06/2022 06:33:39 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.5848039215686274 on epoch=224
06/06/2022 06:33:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/06/2022 06:33:44 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=229
06/06/2022 06:33:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=232
06/06/2022 06:33:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=234
06/06/2022 06:33:52 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
06/06/2022 06:33:54 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.5356583072100313 on epoch=237
06/06/2022 06:33:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=239
06/06/2022 06:33:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=242
06/06/2022 06:34:01 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=244
06/06/2022 06:34:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/06/2022 06:34:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/06/2022 06:34:08 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.5737179487179487 on epoch=249
06/06/2022 06:34:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=252
06/06/2022 06:34:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/06/2022 06:34:16 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/06/2022 06:34:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=259
06/06/2022 06:34:21 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=262
06/06/2022 06:34:22 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.5208428826075885 on epoch=262
06/06/2022 06:34:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=264
06/06/2022 06:34:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/06/2022 06:34:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/06/2022 06:34:33 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/06/2022 06:34:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/06/2022 06:34:37 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.5999899593649592 on epoch=274
06/06/2022 06:34:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=277
06/06/2022 06:34:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/06/2022 06:34:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/06/2022 06:34:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/06/2022 06:34:50 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/06/2022 06:34:51 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.5841573631047314 on epoch=287
06/06/2022 06:34:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/06/2022 06:34:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/06/2022 06:34:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/06/2022 06:35:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/06/2022 06:35:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
06/06/2022 06:35:06 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.5878019829632732 on epoch=299
06/06/2022 06:35:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/06/2022 06:35:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/06/2022 06:35:14 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/06/2022 06:35:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/06/2022 06:35:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/06/2022 06:35:20 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.5905566457169098 on epoch=312
06/06/2022 06:35:23 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=314
06/06/2022 06:35:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/06/2022 06:35:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/06/2022 06:35:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/06/2022 06:35:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/06/2022 06:35:35 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.6401631773399015 on epoch=324
06/06/2022 06:35:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/06/2022 06:35:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/06/2022 06:35:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=332
06/06/2022 06:35:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=334
06/06/2022 06:35:48 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/06/2022 06:35:49 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.5560185185185185 on epoch=337
06/06/2022 06:35:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/06/2022 06:35:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/06/2022 06:35:57 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/06/2022 06:36:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/06/2022 06:36:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=349
06/06/2022 06:36:03 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.6147916666666666 on epoch=349
06/06/2022 06:36:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/06/2022 06:36:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/06/2022 06:36:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/06/2022 06:36:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/06/2022 06:36:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/06/2022 06:36:18 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.6192983487101134 on epoch=362
06/06/2022 06:36:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=364
06/06/2022 06:36:23 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/06/2022 06:36:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/06/2022 06:36:28 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/06/2022 06:36:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/06/2022 06:36:32 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6125 on epoch=374
06/06/2022 06:36:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/06/2022 06:36:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/06/2022 06:36:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/06/2022 06:36:42 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.13 on epoch=384
06/06/2022 06:36:45 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/06/2022 06:36:46 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.6098290598290598 on epoch=387
06/06/2022 06:36:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/06/2022 06:36:52 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/06/2022 06:36:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/06/2022 06:36:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/06/2022 06:36:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/06/2022 06:37:01 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.5863143631436315 on epoch=399
06/06/2022 06:37:03 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=402
06/06/2022 06:37:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/06/2022 06:37:08 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/06/2022 06:37:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/06/2022 06:37:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/06/2022 06:37:15 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.6256529332380727 on epoch=412
06/06/2022 06:37:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/06/2022 06:37:20 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/06/2022 06:37:22 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/06/2022 06:37:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/06/2022 06:37:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/06/2022 06:37:29 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.6171296296296296 on epoch=424
06/06/2022 06:37:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/06/2022 06:37:34 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/06/2022 06:37:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/06/2022 06:37:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/06/2022 06:37:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/06/2022 06:37:43 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.6262724014336917 on epoch=437
06/06/2022 06:37:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/06/2022 06:37:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/06/2022 06:37:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/06/2022 06:37:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/06/2022 06:37:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/06/2022 06:37:57 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.63868518229573 on epoch=449
06/06/2022 06:38:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=452
06/06/2022 06:38:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/06/2022 06:38:05 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/06/2022 06:38:08 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/06/2022 06:38:10 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/06/2022 06:38:11 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6626283846872083 on epoch=462
06/06/2022 06:38:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6413829413829414 -> 0.6626283846872083 on epoch=462, global_step=1850
06/06/2022 06:38:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/06/2022 06:38:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/06/2022 06:38:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/06/2022 06:38:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/06/2022 06:38:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/06/2022 06:38:25 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.6028503893214683 on epoch=474
06/06/2022 06:38:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/06/2022 06:38:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/06/2022 06:38:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/06/2022 06:38:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/06/2022 06:38:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/06/2022 06:38:39 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.5723278645748393 on epoch=487
06/06/2022 06:38:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=489
06/06/2022 06:38:44 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/06/2022 06:38:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/06/2022 06:38:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/06/2022 06:38:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/06/2022 06:38:53 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.5974016713727504 on epoch=499
06/06/2022 06:38:56 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/06/2022 06:38:58 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/06/2022 06:39:01 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/06/2022 06:39:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/06/2022 06:39:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/06/2022 06:39:07 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6105057514378595 on epoch=512
06/06/2022 06:39:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=514
06/06/2022 06:39:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/06/2022 06:39:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/06/2022 06:39:17 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/06/2022 06:39:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/06/2022 06:39:21 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.6410526315789474 on epoch=524
06/06/2022 06:39:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/06/2022 06:39:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/06/2022 06:39:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/06/2022 06:39:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=534
06/06/2022 06:39:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/06/2022 06:39:35 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6327614728615841 on epoch=537
06/06/2022 06:39:38 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/06/2022 06:39:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/06/2022 06:39:43 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/06/2022 06:39:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=547
06/06/2022 06:39:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/06/2022 06:39:49 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6342405913978495 on epoch=549
06/06/2022 06:39:52 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=552
06/06/2022 06:39:54 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/06/2022 06:39:57 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/06/2022 06:40:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/06/2022 06:40:02 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/06/2022 06:40:03 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.5588904419199429 on epoch=562
06/06/2022 06:40:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/06/2022 06:40:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/06/2022 06:40:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/06/2022 06:40:14 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/06/2022 06:40:16 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 06:40:17 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6576535433693542 on epoch=574
06/06/2022 06:40:20 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 06:40:23 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 06:40:25 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/06/2022 06:40:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/06/2022 06:40:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/06/2022 06:40:32 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.5766601284893969 on epoch=587
06/06/2022 06:40:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/06/2022 06:40:37 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/06/2022 06:40:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 06:40:42 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=597
06/06/2022 06:40:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 06:40:46 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6294998644619139 on epoch=599
06/06/2022 06:40:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 06:40:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 06:40:54 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 06:40:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 06:40:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 06:41:01 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.6630520895226778 on epoch=612
06/06/2022 06:41:01 - INFO - __main__ - Saving model with best Classification-F1: 0.6626283846872083 -> 0.6630520895226778 on epoch=612, global_step=2450
06/06/2022 06:41:03 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/06/2022 06:41:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/06/2022 06:41:09 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/06/2022 06:41:11 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.12 on epoch=622
06/06/2022 06:41:14 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/06/2022 06:41:15 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.6004179728317659 on epoch=624
06/06/2022 06:41:18 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/06/2022 06:41:20 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/06/2022 06:41:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/06/2022 06:41:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/06/2022 06:41:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 06:41:29 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.5873768472906404 on epoch=637
06/06/2022 06:41:32 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 06:41:35 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=642
06/06/2022 06:41:37 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/06/2022 06:41:40 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 06:41:43 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
06/06/2022 06:41:44 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.5328557312252964 on epoch=649
06/06/2022 06:41:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/06/2022 06:41:49 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 06:41:52 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 06:41:55 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 06:41:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 06:41:58 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.5953314777327936 on epoch=662
06/06/2022 06:42:01 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 06:42:04 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 06:42:06 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 06:42:09 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/06/2022 06:42:12 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/06/2022 06:42:13 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.5490335189548082 on epoch=674
06/06/2022 06:42:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/06/2022 06:42:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 06:42:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 06:42:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 06:42:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 06:42:28 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6163322413322414 on epoch=687
06/06/2022 06:42:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/06/2022 06:42:33 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 06:42:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/06/2022 06:42:38 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 06:42:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 06:42:42 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.5949074074074074 on epoch=699
06/06/2022 06:42:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 06:42:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 06:42:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 06:42:53 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/06/2022 06:42:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 06:42:57 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6844205980501211 on epoch=712
06/06/2022 06:42:57 - INFO - __main__ - Saving model with best Classification-F1: 0.6630520895226778 -> 0.6844205980501211 on epoch=712, global_step=2850
06/06/2022 06:42:59 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 06:43:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/06/2022 06:43:05 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 06:43:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/06/2022 06:43:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 06:43:11 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6208369659982562 on epoch=724
06/06/2022 06:43:14 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 06:43:16 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=729
06/06/2022 06:43:19 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 06:43:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=734
06/06/2022 06:43:24 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 06:43:25 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6194544130649607 on epoch=737
06/06/2022 06:43:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 06:43:31 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/06/2022 06:43:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/06/2022 06:43:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.14 on epoch=747
06/06/2022 06:43:38 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 06:43:40 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 06:43:40 - INFO - __main__ - Printing 3 examples
06/06/2022 06:43:40 - INFO - __main__ -  [emo] how cause yes am listening
06/06/2022 06:43:40 - INFO - __main__ - ['others']
06/06/2022 06:43:40 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/06/2022 06:43:40 - INFO - __main__ - ['others']
06/06/2022 06:43:40 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/06/2022 06:43:40 - INFO - __main__ - ['others']
06/06/2022 06:43:40 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:43:40 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.6641667050832872 on epoch=749
06/06/2022 06:43:40 - INFO - __main__ - save last model!
06/06/2022 06:43:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 06:43:40 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:43:40 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 06:43:40 - INFO - __main__ - Printing 3 examples
06/06/2022 06:43:40 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 06:43:40 - INFO - __main__ - ['others']
06/06/2022 06:43:40 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 06:43:40 - INFO - __main__ - ['others']
06/06/2022 06:43:40 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 06:43:40 - INFO - __main__ - ['others']
06/06/2022 06:43:40 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:43:40 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 06:43:40 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 06:43:40 - INFO - __main__ - Printing 3 examples
06/06/2022 06:43:40 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/06/2022 06:43:40 - INFO - __main__ - ['others']
06/06/2022 06:43:40 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/06/2022 06:43:40 - INFO - __main__ - ['others']
06/06/2022 06:43:40 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/06/2022 06:43:40 - INFO - __main__ - ['others']
06/06/2022 06:43:40 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:43:40 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:43:40 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 06:43:42 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:43:49 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 06:44:00 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 06:44:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 06:44:00 - INFO - __main__ - Starting training!
06/06/2022 06:45:27 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_100_0.3_8_predictions.txt
06/06/2022 06:45:27 - INFO - __main__ - Classification-F1 on test data: 0.4210
06/06/2022 06:45:27 - INFO - __main__ - prefix=emo_16_100, lr=0.3, bsz=8, dev_performance=0.6844205980501211, test_performance=0.4210075452548956
06/06/2022 06:45:27 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.2, bsz=8 ...
06/06/2022 06:45:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 06:45:28 - INFO - __main__ - Printing 3 examples
06/06/2022 06:45:28 - INFO - __main__ -  [emo] how cause yes am listening
06/06/2022 06:45:28 - INFO - __main__ - ['others']
06/06/2022 06:45:28 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/06/2022 06:45:28 - INFO - __main__ - ['others']
06/06/2022 06:45:28 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/06/2022 06:45:28 - INFO - __main__ - ['others']
06/06/2022 06:45:28 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:45:28 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:45:28 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 06:45:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 06:45:28 - INFO - __main__ - Printing 3 examples
06/06/2022 06:45:28 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/06/2022 06:45:28 - INFO - __main__ - ['others']
06/06/2022 06:45:28 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/06/2022 06:45:28 - INFO - __main__ - ['others']
06/06/2022 06:45:28 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/06/2022 06:45:28 - INFO - __main__ - ['others']
06/06/2022 06:45:28 - INFO - __main__ - Tokenizing Input ...
06/06/2022 06:45:28 - INFO - __main__ - Tokenizing Output ...
06/06/2022 06:45:28 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 06:45:47 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 06:45:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 06:45:48 - INFO - __main__ - Starting training!
06/06/2022 06:45:51 - INFO - __main__ - Step 10 Global step 10 Train loss 3.88 on epoch=2
06/06/2022 06:45:53 - INFO - __main__ - Step 20 Global step 20 Train loss 2.90 on epoch=4
06/06/2022 06:45:56 - INFO - __main__ - Step 30 Global step 30 Train loss 2.24 on epoch=7
06/06/2022 06:45:59 - INFO - __main__ - Step 40 Global step 40 Train loss 1.58 on epoch=9
06/06/2022 06:46:01 - INFO - __main__ - Step 50 Global step 50 Train loss 1.40 on epoch=12
06/06/2022 06:46:02 - INFO - __main__ - Global step 50 Train loss 2.40 Classification-F1 0.1 on epoch=12
06/06/2022 06:46:02 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/06/2022 06:46:05 - INFO - __main__ - Step 60 Global step 60 Train loss 1.12 on epoch=14
06/06/2022 06:46:07 - INFO - __main__ - Step 70 Global step 70 Train loss 1.05 on epoch=17
06/06/2022 06:46:10 - INFO - __main__ - Step 80 Global step 80 Train loss 0.99 on epoch=19
06/06/2022 06:46:13 - INFO - __main__ - Step 90 Global step 90 Train loss 1.05 on epoch=22
06/06/2022 06:46:15 - INFO - __main__ - Step 100 Global step 100 Train loss 1.02 on epoch=24
06/06/2022 06:46:16 - INFO - __main__ - Global step 100 Train loss 1.05 Classification-F1 0.2705882352941177 on epoch=24
06/06/2022 06:46:16 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.2705882352941177 on epoch=24, global_step=100
06/06/2022 06:46:19 - INFO - __main__ - Step 110 Global step 110 Train loss 0.96 on epoch=27
06/06/2022 06:46:22 - INFO - __main__ - Step 120 Global step 120 Train loss 0.93 on epoch=29
06/06/2022 06:46:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.98 on epoch=32
06/06/2022 06:46:27 - INFO - __main__ - Step 140 Global step 140 Train loss 0.97 on epoch=34
06/06/2022 06:46:30 - INFO - __main__ - Step 150 Global step 150 Train loss 0.87 on epoch=37
06/06/2022 06:46:30 - INFO - __main__ - Global step 150 Train loss 0.94 Classification-F1 0.25794438927507446 on epoch=37
06/06/2022 06:46:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.90 on epoch=39
06/06/2022 06:46:36 - INFO - __main__ - Step 170 Global step 170 Train loss 0.92 on epoch=42
06/06/2022 06:46:39 - INFO - __main__ - Step 180 Global step 180 Train loss 0.87 on epoch=44
06/06/2022 06:46:41 - INFO - __main__ - Step 190 Global step 190 Train loss 0.77 on epoch=47
06/06/2022 06:46:44 - INFO - __main__ - Step 200 Global step 200 Train loss 0.76 on epoch=49
06/06/2022 06:46:45 - INFO - __main__ - Global step 200 Train loss 0.84 Classification-F1 0.2001314104724038 on epoch=49
06/06/2022 06:46:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.86 on epoch=52
06/06/2022 06:46:50 - INFO - __main__ - Step 220 Global step 220 Train loss 0.90 on epoch=54
06/06/2022 06:46:53 - INFO - __main__ - Step 230 Global step 230 Train loss 0.85 on epoch=57
06/06/2022 06:46:55 - INFO - __main__ - Step 240 Global step 240 Train loss 0.85 on epoch=59
06/06/2022 06:46:58 - INFO - __main__ - Step 250 Global step 250 Train loss 0.75 on epoch=62
06/06/2022 06:46:59 - INFO - __main__ - Global step 250 Train loss 0.84 Classification-F1 0.3921961550993809 on epoch=62
06/06/2022 06:46:59 - INFO - __main__ - Saving model with best Classification-F1: 0.2705882352941177 -> 0.3921961550993809 on epoch=62, global_step=250
06/06/2022 06:47:02 - INFO - __main__ - Step 260 Global step 260 Train loss 0.79 on epoch=64
06/06/2022 06:47:04 - INFO - __main__ - Step 270 Global step 270 Train loss 0.76 on epoch=67
06/06/2022 06:47:07 - INFO - __main__ - Step 280 Global step 280 Train loss 0.75 on epoch=69
06/06/2022 06:47:09 - INFO - __main__ - Step 290 Global step 290 Train loss 0.75 on epoch=72
06/06/2022 06:47:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.64 on epoch=74
06/06/2022 06:47:13 - INFO - __main__ - Global step 300 Train loss 0.74 Classification-F1 0.20385202135774216 on epoch=74
06/06/2022 06:47:15 - INFO - __main__ - Step 310 Global step 310 Train loss 0.76 on epoch=77
06/06/2022 06:47:18 - INFO - __main__ - Step 320 Global step 320 Train loss 0.76 on epoch=79
06/06/2022 06:47:21 - INFO - __main__ - Step 330 Global step 330 Train loss 0.66 on epoch=82
06/06/2022 06:47:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.67 on epoch=84
06/06/2022 06:47:26 - INFO - __main__ - Step 350 Global step 350 Train loss 0.74 on epoch=87
06/06/2022 06:47:27 - INFO - __main__ - Global step 350 Train loss 0.72 Classification-F1 0.3756199101026687 on epoch=87
06/06/2022 06:47:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.55 on epoch=89
06/06/2022 06:47:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.56 on epoch=92
06/06/2022 06:47:35 - INFO - __main__ - Step 380 Global step 380 Train loss 0.56 on epoch=94
06/06/2022 06:47:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.78 on epoch=97
06/06/2022 06:47:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.58 on epoch=99
06/06/2022 06:47:41 - INFO - __main__ - Global step 400 Train loss 0.61 Classification-F1 0.2355727554179567 on epoch=99
06/06/2022 06:47:44 - INFO - __main__ - Step 410 Global step 410 Train loss 0.64 on epoch=102
06/06/2022 06:47:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.61 on epoch=104
06/06/2022 06:47:49 - INFO - __main__ - Step 430 Global step 430 Train loss 0.60 on epoch=107
06/06/2022 06:47:52 - INFO - __main__ - Step 440 Global step 440 Train loss 0.48 on epoch=109
06/06/2022 06:47:54 - INFO - __main__ - Step 450 Global step 450 Train loss 0.54 on epoch=112
06/06/2022 06:47:55 - INFO - __main__ - Global step 450 Train loss 0.57 Classification-F1 0.5322134387351778 on epoch=112
06/06/2022 06:47:55 - INFO - __main__ - Saving model with best Classification-F1: 0.3921961550993809 -> 0.5322134387351778 on epoch=112, global_step=450
06/06/2022 06:47:58 - INFO - __main__ - Step 460 Global step 460 Train loss 0.46 on epoch=114
06/06/2022 06:48:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.48 on epoch=117
06/06/2022 06:48:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.43 on epoch=119
06/06/2022 06:48:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.54 on epoch=122
06/06/2022 06:48:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.37 on epoch=124
06/06/2022 06:48:09 - INFO - __main__ - Global step 500 Train loss 0.45 Classification-F1 0.5078025149453721 on epoch=124
06/06/2022 06:48:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.42 on epoch=127
06/06/2022 06:48:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.44 on epoch=129
06/06/2022 06:48:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.39 on epoch=132
06/06/2022 06:48:20 - INFO - __main__ - Step 540 Global step 540 Train loss 0.46 on epoch=134
06/06/2022 06:48:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.45 on epoch=137
06/06/2022 06:48:23 - INFO - __main__ - Global step 550 Train loss 0.43 Classification-F1 0.5609654234654236 on epoch=137
06/06/2022 06:48:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5322134387351778 -> 0.5609654234654236 on epoch=137, global_step=550
06/06/2022 06:48:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.45 on epoch=139
06/06/2022 06:48:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.43 on epoch=142
06/06/2022 06:48:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.43 on epoch=144
06/06/2022 06:48:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=147
06/06/2022 06:48:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.30 on epoch=149
06/06/2022 06:48:37 - INFO - __main__ - Global step 600 Train loss 0.39 Classification-F1 0.5154610622352558 on epoch=149
06/06/2022 06:48:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.33 on epoch=152
06/06/2022 06:48:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.40 on epoch=154
06/06/2022 06:48:45 - INFO - __main__ - Step 630 Global step 630 Train loss 0.32 on epoch=157
06/06/2022 06:48:48 - INFO - __main__ - Step 640 Global step 640 Train loss 0.38 on epoch=159
06/06/2022 06:48:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.37 on epoch=162
06/06/2022 06:48:51 - INFO - __main__ - Global step 650 Train loss 0.36 Classification-F1 0.5499018037950185 on epoch=162
06/06/2022 06:48:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.35 on epoch=164
06/06/2022 06:48:56 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=167
06/06/2022 06:48:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=169
06/06/2022 06:49:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=172
06/06/2022 06:49:04 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=174
06/06/2022 06:49:05 - INFO - __main__ - Global step 700 Train loss 0.28 Classification-F1 0.6068282444942786 on epoch=174
06/06/2022 06:49:05 - INFO - __main__ - Saving model with best Classification-F1: 0.5609654234654236 -> 0.6068282444942786 on epoch=174, global_step=700
06/06/2022 06:49:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.26 on epoch=177
06/06/2022 06:49:10 - INFO - __main__ - Step 720 Global step 720 Train loss 0.30 on epoch=179
06/06/2022 06:49:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=182
06/06/2022 06:49:15 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=184
06/06/2022 06:49:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=187
06/06/2022 06:49:19 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.602671950315165 on epoch=187
06/06/2022 06:49:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=189
06/06/2022 06:49:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=192
06/06/2022 06:49:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.30 on epoch=194
06/06/2022 06:49:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=197
06/06/2022 06:49:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=199
06/06/2022 06:49:33 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.6260416666666666 on epoch=199
06/06/2022 06:49:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6068282444942786 -> 0.6260416666666666 on epoch=199, global_step=800
06/06/2022 06:49:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=202
06/06/2022 06:49:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=204
06/06/2022 06:49:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.24 on epoch=207
06/06/2022 06:49:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=209
06/06/2022 06:49:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=212
06/06/2022 06:49:47 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.5919730392156862 on epoch=212
06/06/2022 06:49:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=214
06/06/2022 06:49:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=217
06/06/2022 06:49:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=219
06/06/2022 06:49:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=222
06/06/2022 06:50:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=224
06/06/2022 06:50:01 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.5203980801806889 on epoch=224
06/06/2022 06:50:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=227
06/06/2022 06:50:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=229
06/06/2022 06:50:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=232
06/06/2022 06:50:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=234
06/06/2022 06:50:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=237
06/06/2022 06:50:15 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.5862745098039215 on epoch=237
06/06/2022 06:50:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=239
06/06/2022 06:50:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=242
06/06/2022 06:50:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=244
06/06/2022 06:50:25 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=247
06/06/2022 06:50:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=249
06/06/2022 06:50:29 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.5666443594358079 on epoch=249
06/06/2022 06:50:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=252
06/06/2022 06:50:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=254
06/06/2022 06:50:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=257
06/06/2022 06:50:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=259
06/06/2022 06:50:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/06/2022 06:50:43 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.6 on epoch=262
06/06/2022 06:50:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=264
06/06/2022 06:50:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=267
06/06/2022 06:50:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
06/06/2022 06:50:53 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/06/2022 06:50:56 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=274
06/06/2022 06:50:57 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.5877595476455321 on epoch=274
06/06/2022 06:51:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/06/2022 06:51:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=279
06/06/2022 06:51:05 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=282
06/06/2022 06:51:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=284
06/06/2022 06:51:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.16 on epoch=287
06/06/2022 06:51:11 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.5819543359865941 on epoch=287
06/06/2022 06:51:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=289
06/06/2022 06:51:16 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=292
06/06/2022 06:51:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=294
06/06/2022 06:51:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=297
06/06/2022 06:51:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/06/2022 06:51:26 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.539369918699187 on epoch=299
06/06/2022 06:51:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=302
06/06/2022 06:51:31 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=304
06/06/2022 06:51:34 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/06/2022 06:51:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
06/06/2022 06:51:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=312
06/06/2022 06:51:40 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.5710889083108216 on epoch=312
06/06/2022 06:51:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=314
06/06/2022 06:51:45 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=317
06/06/2022 06:51:48 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
06/06/2022 06:51:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/06/2022 06:51:53 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=324
06/06/2022 06:51:55 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.6233504398826979 on epoch=324
06/06/2022 06:51:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/06/2022 06:52:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=329
06/06/2022 06:52:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/06/2022 06:52:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/06/2022 06:52:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=337
06/06/2022 06:52:09 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.6309852915116074 on epoch=337
06/06/2022 06:52:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6260416666666666 -> 0.6309852915116074 on epoch=337, global_step=1350
06/06/2022 06:52:12 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
06/06/2022 06:52:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=342
06/06/2022 06:52:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=344
06/06/2022 06:52:20 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/06/2022 06:52:22 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
06/06/2022 06:52:24 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.5894941157240928 on epoch=349
06/06/2022 06:52:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=352
06/06/2022 06:52:29 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/06/2022 06:52:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/06/2022 06:52:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/06/2022 06:52:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=362
06/06/2022 06:52:38 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.5794871794871794 on epoch=362
06/06/2022 06:52:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/06/2022 06:52:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=367
06/06/2022 06:52:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/06/2022 06:52:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/06/2022 06:52:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/06/2022 06:52:53 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6014104139104139 on epoch=374
06/06/2022 06:52:55 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=377
06/06/2022 06:52:58 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
06/06/2022 06:53:01 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=382
06/06/2022 06:53:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=384
06/06/2022 06:53:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/06/2022 06:53:07 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.5328557312252964 on epoch=387
06/06/2022 06:53:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/06/2022 06:53:13 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/06/2022 06:53:15 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=394
06/06/2022 06:53:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=397
06/06/2022 06:53:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/06/2022 06:53:22 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.5750752086433332 on epoch=399
06/06/2022 06:53:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=402
06/06/2022 06:53:27 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/06/2022 06:53:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/06/2022 06:53:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/06/2022 06:53:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/06/2022 06:53:36 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.5544775339602926 on epoch=412
06/06/2022 06:53:39 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/06/2022 06:53:42 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=417
06/06/2022 06:53:44 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/06/2022 06:53:47 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/06/2022 06:53:49 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/06/2022 06:53:51 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6324058959209127 on epoch=424
06/06/2022 06:53:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6309852915116074 -> 0.6324058959209127 on epoch=424, global_step=1700
06/06/2022 06:53:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/06/2022 06:53:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/06/2022 06:53:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/06/2022 06:54:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=434
06/06/2022 06:54:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/06/2022 06:54:05 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.6440175405692647 on epoch=437
06/06/2022 06:54:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6324058959209127 -> 0.6440175405692647 on epoch=437, global_step=1750
06/06/2022 06:54:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/06/2022 06:54:10 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=442
06/06/2022 06:54:13 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/06/2022 06:54:16 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
06/06/2022 06:54:18 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/06/2022 06:54:19 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.5815245089438638 on epoch=449
06/06/2022 06:54:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=452
06/06/2022 06:54:25 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/06/2022 06:54:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=457
06/06/2022 06:54:30 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/06/2022 06:54:33 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/06/2022 06:54:34 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6441431862484495 on epoch=462
06/06/2022 06:54:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6440175405692647 -> 0.6441431862484495 on epoch=462, global_step=1850
06/06/2022 06:54:37 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=464
06/06/2022 06:54:39 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/06/2022 06:54:42 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/06/2022 06:54:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/06/2022 06:54:47 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/06/2022 06:54:48 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6313072603395185 on epoch=474
06/06/2022 06:54:51 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/06/2022 06:54:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/06/2022 06:54:56 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/06/2022 06:54:59 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/06/2022 06:55:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/06/2022 06:55:03 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.6313072603395185 on epoch=487
06/06/2022 06:55:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/06/2022 06:55:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/06/2022 06:55:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/06/2022 06:55:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=497
06/06/2022 06:55:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/06/2022 06:55:17 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6512310606060606 on epoch=499
06/06/2022 06:55:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6441431862484495 -> 0.6512310606060606 on epoch=499, global_step=2000
06/06/2022 06:55:20 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/06/2022 06:55:23 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/06/2022 06:55:26 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/06/2022 06:55:28 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=509
06/06/2022 06:55:31 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/06/2022 06:55:32 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6143120393120394 on epoch=512
06/06/2022 06:55:35 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/06/2022 06:55:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/06/2022 06:55:40 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/06/2022 06:55:43 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/06/2022 06:55:46 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/06/2022 06:55:47 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6485074416108898 on epoch=524
06/06/2022 06:55:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/06/2022 06:55:52 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/06/2022 06:55:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=532
06/06/2022 06:55:58 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=534
06/06/2022 06:56:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=537
06/06/2022 06:56:02 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.6267761612589199 on epoch=537
06/06/2022 06:56:04 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/06/2022 06:56:07 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 06:56:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=544
06/06/2022 06:56:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/06/2022 06:56:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/06/2022 06:56:16 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6485074416108898 on epoch=549
06/06/2022 06:56:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 06:56:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=554
06/06/2022 06:56:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/06/2022 06:56:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/06/2022 06:56:30 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/06/2022 06:56:31 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.647651958178274 on epoch=562
06/06/2022 06:56:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/06/2022 06:56:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=567
06/06/2022 06:56:39 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/06/2022 06:56:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/06/2022 06:56:44 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 06:56:45 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6384826866049105 on epoch=574
06/06/2022 06:56:48 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/06/2022 06:56:51 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=579
06/06/2022 06:56:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/06/2022 06:56:56 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/06/2022 06:56:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 06:57:00 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.5870512187088274 on epoch=587
06/06/2022 06:57:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/06/2022 06:57:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/06/2022 06:57:08 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/06/2022 06:57:10 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/06/2022 06:57:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 06:57:14 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6634048821548821 on epoch=599
06/06/2022 06:57:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6512310606060606 -> 0.6634048821548821 on epoch=599, global_step=2400
06/06/2022 06:57:17 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 06:57:19 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 06:57:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=607
06/06/2022 06:57:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 06:57:27 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 06:57:28 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6634048821548821 on epoch=612
06/06/2022 06:57:31 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=614
06/06/2022 06:57:34 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 06:57:36 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/06/2022 06:57:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/06/2022 06:57:42 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 06:57:43 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6643581908287791 on epoch=624
06/06/2022 06:57:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6634048821548821 -> 0.6643581908287791 on epoch=624, global_step=2500
06/06/2022 06:57:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/06/2022 06:57:48 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=629
06/06/2022 06:57:51 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/06/2022 06:57:53 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/06/2022 06:57:56 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/06/2022 06:57:57 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.6487896203413446 on epoch=637
06/06/2022 06:58:00 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.12 on epoch=639
06/06/2022 06:58:03 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/06/2022 06:58:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 06:58:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 06:58:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 06:58:12 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.631266062300545 on epoch=649
06/06/2022 06:58:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/06/2022 06:58:17 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/06/2022 06:58:20 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 06:58:22 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/06/2022 06:58:25 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 06:58:26 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6433451417004048 on epoch=662
06/06/2022 06:58:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=664
06/06/2022 06:58:31 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=667
06/06/2022 06:58:34 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 06:58:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/06/2022 06:58:39 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 06:58:40 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.5650747102360005 on epoch=674
06/06/2022 06:58:43 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/06/2022 06:58:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/06/2022 06:58:48 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 06:58:51 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 06:58:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 06:58:55 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6476453726453727 on epoch=687
06/06/2022 06:58:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 06:59:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 06:59:03 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/06/2022 06:59:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 06:59:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 06:59:09 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.6285682342558404 on epoch=699
06/06/2022 06:59:12 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=702
06/06/2022 06:59:15 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 06:59:18 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 06:59:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.10 on epoch=709
06/06/2022 06:59:23 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.07 on epoch=712
06/06/2022 06:59:24 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.6743506493506494 on epoch=712
06/06/2022 06:59:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6643581908287791 -> 0.6743506493506494 on epoch=712, global_step=2850
06/06/2022 06:59:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=714
06/06/2022 06:59:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 06:59:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/06/2022 06:59:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/06/2022 06:59:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 06:59:38 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6309852915116074 on epoch=724
06/06/2022 06:59:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 06:59:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/06/2022 06:59:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 06:59:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/06/2022 06:59:52 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 06:59:53 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6657763074893219 on epoch=737
06/06/2022 06:59:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 06:59:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 07:00:01 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 07:00:04 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=747
06/06/2022 07:00:06 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 07:00:08 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6316797002280874 on epoch=749
06/06/2022 07:00:08 - INFO - __main__ - save last model!
06/06/2022 07:00:08 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 07:00:08 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 07:00:08 - INFO - __main__ - Printing 3 examples
06/06/2022 07:00:08 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 07:00:08 - INFO - __main__ - ['others']
06/06/2022 07:00:08 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 07:00:08 - INFO - __main__ - ['others']
06/06/2022 07:00:08 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 07:00:08 - INFO - __main__ - ['others']
06/06/2022 07:00:08 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:00:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:00:08 - INFO - __main__ - Printing 3 examples
06/06/2022 07:00:08 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/06/2022 07:00:08 - INFO - __main__ - ['others']
06/06/2022 07:00:08 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/06/2022 07:00:08 - INFO - __main__ - ['others']
06/06/2022 07:00:08 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/06/2022 07:00:08 - INFO - __main__ - ['others']
06/06/2022 07:00:08 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:00:08 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:00:08 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 07:00:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:00:08 - INFO - __main__ - Printing 3 examples
06/06/2022 07:00:08 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/06/2022 07:00:08 - INFO - __main__ - ['others']
06/06/2022 07:00:08 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/06/2022 07:00:08 - INFO - __main__ - ['others']
06/06/2022 07:00:08 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/06/2022 07:00:08 - INFO - __main__ - ['others']
06/06/2022 07:00:08 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:00:08 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:00:08 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 07:00:10 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:00:15 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 07:00:26 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 07:00:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 07:00:27 - INFO - __main__ - Starting training!
06/06/2022 07:01:52 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_100_0.2_8_predictions.txt
06/06/2022 07:01:52 - INFO - __main__ - Classification-F1 on test data: 0.2645
06/06/2022 07:01:53 - INFO - __main__ - prefix=emo_16_100, lr=0.2, bsz=8, dev_performance=0.6743506493506494, test_performance=0.26445214486965185
06/06/2022 07:01:53 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.5, bsz=8 ...
06/06/2022 07:01:54 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:01:54 - INFO - __main__ - Printing 3 examples
06/06/2022 07:01:54 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/06/2022 07:01:54 - INFO - __main__ - ['others']
06/06/2022 07:01:54 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/06/2022 07:01:54 - INFO - __main__ - ['others']
06/06/2022 07:01:54 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/06/2022 07:01:54 - INFO - __main__ - ['others']
06/06/2022 07:01:54 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:01:54 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:01:54 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 07:01:54 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:01:54 - INFO - __main__ - Printing 3 examples
06/06/2022 07:01:54 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/06/2022 07:01:54 - INFO - __main__ - ['others']
06/06/2022 07:01:54 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/06/2022 07:01:54 - INFO - __main__ - ['others']
06/06/2022 07:01:54 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/06/2022 07:01:54 - INFO - __main__ - ['others']
06/06/2022 07:01:54 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:01:54 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:01:54 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 07:02:13 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 07:02:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 07:02:13 - INFO - __main__ - Starting training!
06/06/2022 07:02:16 - INFO - __main__ - Step 10 Global step 10 Train loss 3.43 on epoch=2
06/06/2022 07:02:19 - INFO - __main__ - Step 20 Global step 20 Train loss 1.54 on epoch=4
06/06/2022 07:02:22 - INFO - __main__ - Step 30 Global step 30 Train loss 1.10 on epoch=7
06/06/2022 07:02:25 - INFO - __main__ - Step 40 Global step 40 Train loss 0.94 on epoch=9
06/06/2022 07:02:27 - INFO - __main__ - Step 50 Global step 50 Train loss 0.95 on epoch=12
06/06/2022 07:02:28 - INFO - __main__ - Global step 50 Train loss 1.59 Classification-F1 0.13067758749069247 on epoch=12
06/06/2022 07:02:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13067758749069247 on epoch=12, global_step=50
06/06/2022 07:02:31 - INFO - __main__ - Step 60 Global step 60 Train loss 0.98 on epoch=14
06/06/2022 07:02:33 - INFO - __main__ - Step 70 Global step 70 Train loss 0.89 on epoch=17
06/06/2022 07:02:36 - INFO - __main__ - Step 80 Global step 80 Train loss 0.76 on epoch=19
06/06/2022 07:02:39 - INFO - __main__ - Step 90 Global step 90 Train loss 0.74 on epoch=22
06/06/2022 07:02:41 - INFO - __main__ - Step 100 Global step 100 Train loss 0.65 on epoch=24
06/06/2022 07:02:42 - INFO - __main__ - Global step 100 Train loss 0.81 Classification-F1 0.44327413984461705 on epoch=24
06/06/2022 07:02:42 - INFO - __main__ - Saving model with best Classification-F1: 0.13067758749069247 -> 0.44327413984461705 on epoch=24, global_step=100
06/06/2022 07:02:44 - INFO - __main__ - Step 110 Global step 110 Train loss 0.69 on epoch=27
06/06/2022 07:02:47 - INFO - __main__ - Step 120 Global step 120 Train loss 0.74 on epoch=29
06/06/2022 07:02:50 - INFO - __main__ - Step 130 Global step 130 Train loss 0.68 on epoch=32
06/06/2022 07:02:52 - INFO - __main__ - Step 140 Global step 140 Train loss 0.64 on epoch=34
06/06/2022 07:02:55 - INFO - __main__ - Step 150 Global step 150 Train loss 0.56 on epoch=37
06/06/2022 07:02:56 - INFO - __main__ - Global step 150 Train loss 0.66 Classification-F1 0.7074952446079354 on epoch=37
06/06/2022 07:02:56 - INFO - __main__ - Saving model with best Classification-F1: 0.44327413984461705 -> 0.7074952446079354 on epoch=37, global_step=150
06/06/2022 07:02:59 - INFO - __main__ - Step 160 Global step 160 Train loss 0.58 on epoch=39
06/06/2022 07:03:01 - INFO - __main__ - Step 170 Global step 170 Train loss 0.52 on epoch=42
06/06/2022 07:03:04 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=44
06/06/2022 07:03:06 - INFO - __main__ - Step 190 Global step 190 Train loss 0.45 on epoch=47
06/06/2022 07:03:09 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=49
06/06/2022 07:03:10 - INFO - __main__ - Global step 200 Train loss 0.51 Classification-F1 0.44706093644354294 on epoch=49
06/06/2022 07:03:12 - INFO - __main__ - Step 210 Global step 210 Train loss 0.41 on epoch=52
06/06/2022 07:03:15 - INFO - __main__ - Step 220 Global step 220 Train loss 0.43 on epoch=54
06/06/2022 07:03:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.33 on epoch=57
06/06/2022 07:03:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.33 on epoch=59
06/06/2022 07:03:23 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=62
06/06/2022 07:03:24 - INFO - __main__ - Global step 250 Train loss 0.37 Classification-F1 0.5895431145431145 on epoch=62
06/06/2022 07:03:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.28 on epoch=64
06/06/2022 07:03:29 - INFO - __main__ - Step 270 Global step 270 Train loss 0.36 on epoch=67
06/06/2022 07:03:31 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=69
06/06/2022 07:03:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=72
06/06/2022 07:03:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.22 on epoch=74
06/06/2022 07:03:38 - INFO - __main__ - Global step 300 Train loss 0.26 Classification-F1 0.546984126984127 on epoch=74
06/06/2022 07:03:40 - INFO - __main__ - Step 310 Global step 310 Train loss 0.16 on epoch=77
06/06/2022 07:03:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=79
06/06/2022 07:03:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.16 on epoch=82
06/06/2022 07:03:48 - INFO - __main__ - Step 340 Global step 340 Train loss 0.12 on epoch=84
06/06/2022 07:03:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.19 on epoch=87
06/06/2022 07:03:51 - INFO - __main__ - Global step 350 Train loss 0.17 Classification-F1 0.747104247104247 on epoch=87
06/06/2022 07:03:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7074952446079354 -> 0.747104247104247 on epoch=87, global_step=350
06/06/2022 07:03:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=89
06/06/2022 07:03:57 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=92
06/06/2022 07:03:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.06 on epoch=94
06/06/2022 07:04:02 - INFO - __main__ - Step 390 Global step 390 Train loss 0.12 on epoch=97
06/06/2022 07:04:04 - INFO - __main__ - Step 400 Global step 400 Train loss 0.09 on epoch=99
06/06/2022 07:04:05 - INFO - __main__ - Global step 400 Train loss 0.14 Classification-F1 0.7234477124183007 on epoch=99
06/06/2022 07:04:08 - INFO - __main__ - Step 410 Global step 410 Train loss 0.08 on epoch=102
06/06/2022 07:04:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.10 on epoch=104
06/06/2022 07:04:13 - INFO - __main__ - Step 430 Global step 430 Train loss 0.13 on epoch=107
06/06/2022 07:04:16 - INFO - __main__ - Step 440 Global step 440 Train loss 0.06 on epoch=109
06/06/2022 07:04:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.09 on epoch=112
06/06/2022 07:04:19 - INFO - __main__ - Global step 450 Train loss 0.09 Classification-F1 0.7305530491014363 on epoch=112
06/06/2022 07:04:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=114
06/06/2022 07:04:24 - INFO - __main__ - Step 470 Global step 470 Train loss 0.08 on epoch=117
06/06/2022 07:04:27 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=119
06/06/2022 07:04:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.07 on epoch=122
06/06/2022 07:04:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.05 on epoch=124
06/06/2022 07:04:33 - INFO - __main__ - Global step 500 Train loss 0.11 Classification-F1 0.7341269841269842 on epoch=124
06/06/2022 07:04:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=127
06/06/2022 07:04:38 - INFO - __main__ - Step 520 Global step 520 Train loss 0.03 on epoch=129
06/06/2022 07:04:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.04 on epoch=132
06/06/2022 07:04:44 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=134
06/06/2022 07:04:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.04 on epoch=137
06/06/2022 07:04:47 - INFO - __main__ - Global step 550 Train loss 0.05 Classification-F1 0.7762659210935072 on epoch=137
06/06/2022 07:04:47 - INFO - __main__ - Saving model with best Classification-F1: 0.747104247104247 -> 0.7762659210935072 on epoch=137, global_step=550
06/06/2022 07:04:50 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=139
06/06/2022 07:04:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.08 on epoch=142
06/06/2022 07:04:55 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=144
06/06/2022 07:04:58 - INFO - __main__ - Step 590 Global step 590 Train loss 0.37 on epoch=147
06/06/2022 07:05:00 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=149
06/06/2022 07:05:02 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.7589031339031338 on epoch=149
06/06/2022 07:05:04 - INFO - __main__ - Step 610 Global step 610 Train loss 0.05 on epoch=152
06/06/2022 07:05:07 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=154
06/06/2022 07:05:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=157
06/06/2022 07:05:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=159
06/06/2022 07:05:14 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=162
06/06/2022 07:05:15 - INFO - __main__ - Global step 650 Train loss 0.07 Classification-F1 0.7798038018626253 on epoch=162
06/06/2022 07:05:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7762659210935072 -> 0.7798038018626253 on epoch=162, global_step=650
06/06/2022 07:05:18 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=164
06/06/2022 07:05:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=167
06/06/2022 07:05:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=169
06/06/2022 07:05:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.02 on epoch=172
06/06/2022 07:05:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=174
06/06/2022 07:05:30 - INFO - __main__ - Global step 700 Train loss 0.03 Classification-F1 0.7154531490015361 on epoch=174
06/06/2022 07:05:32 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=177
06/06/2022 07:05:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=179
06/06/2022 07:05:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=182
06/06/2022 07:05:40 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=184
06/06/2022 07:05:42 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=187
06/06/2022 07:05:44 - INFO - __main__ - Global step 750 Train loss 0.03 Classification-F1 0.7504007635923102 on epoch=187
06/06/2022 07:05:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=189
06/06/2022 07:05:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=192
06/06/2022 07:05:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=194
06/06/2022 07:05:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=197
06/06/2022 07:05:57 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
06/06/2022 07:05:58 - INFO - __main__ - Global step 800 Train loss 0.04 Classification-F1 0.747564935064935 on epoch=199
06/06/2022 07:06:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=202
06/06/2022 07:06:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/06/2022 07:06:06 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=207
06/06/2022 07:06:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
06/06/2022 07:06:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=212
06/06/2022 07:06:12 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.7757226137443924 on epoch=212
06/06/2022 07:06:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=214
06/06/2022 07:06:17 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=217
06/06/2022 07:06:19 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=219
06/06/2022 07:06:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/06/2022 07:06:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/06/2022 07:06:26 - INFO - __main__ - Global step 900 Train loss 0.01 Classification-F1 0.7599220272904483 on epoch=224
06/06/2022 07:06:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=227
06/06/2022 07:06:31 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=229
06/06/2022 07:06:33 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=232
06/06/2022 07:06:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.00 on epoch=234
06/06/2022 07:06:39 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/06/2022 07:06:40 - INFO - __main__ - Global step 950 Train loss 0.01 Classification-F1 0.7747833775419981 on epoch=237
06/06/2022 07:06:42 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=239
06/06/2022 07:06:45 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/06/2022 07:06:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=244
06/06/2022 07:06:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/06/2022 07:06:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/06/2022 07:06:54 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.7582532051282052 on epoch=249
06/06/2022 07:06:56 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/06/2022 07:06:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=254
06/06/2022 07:07:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=257
06/06/2022 07:07:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
06/06/2022 07:07:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/06/2022 07:07:08 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.7714285714285714 on epoch=262
06/06/2022 07:07:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/06/2022 07:07:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=267
06/06/2022 07:07:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/06/2022 07:07:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/06/2022 07:07:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/06/2022 07:07:22 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.7932678919521025 on epoch=274
06/06/2022 07:07:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7798038018626253 -> 0.7932678919521025 on epoch=274, global_step=1100
06/06/2022 07:07:24 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=277
06/06/2022 07:07:27 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/06/2022 07:07:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/06/2022 07:07:32 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=284
06/06/2022 07:07:35 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/06/2022 07:07:36 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7767967494747249 on epoch=287
06/06/2022 07:07:38 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=289
06/06/2022 07:07:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/06/2022 07:07:43 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/06/2022 07:07:46 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/06/2022 07:07:48 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/06/2022 07:07:50 - INFO - __main__ - Global step 1200 Train loss 0.00 Classification-F1 0.7926497926497926 on epoch=299
06/06/2022 07:07:52 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/06/2022 07:07:55 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/06/2022 07:07:57 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=307
06/06/2022 07:08:00 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/06/2022 07:08:02 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/06/2022 07:08:04 - INFO - __main__ - Global step 1250 Train loss 0.00 Classification-F1 0.7794289044289044 on epoch=312
06/06/2022 07:08:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/06/2022 07:08:09 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/06/2022 07:08:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/06/2022 07:08:14 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=322
06/06/2022 07:08:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=324
06/06/2022 07:08:18 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7601005165433479 on epoch=324
06/06/2022 07:08:20 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/06/2022 07:08:23 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/06/2022 07:08:25 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/06/2022 07:08:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/06/2022 07:08:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/06/2022 07:08:32 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.79931154736494 on epoch=337
06/06/2022 07:08:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7932678919521025 -> 0.79931154736494 on epoch=337, global_step=1350
06/06/2022 07:08:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/06/2022 07:08:37 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/06/2022 07:08:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/06/2022 07:08:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/06/2022 07:08:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/06/2022 07:08:46 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7813910999394871 on epoch=349
06/06/2022 07:08:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/06/2022 07:08:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/06/2022 07:08:54 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/06/2022 07:08:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/06/2022 07:08:59 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/06/2022 07:09:00 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.8102971102971104 on epoch=362
06/06/2022 07:09:00 - INFO - __main__ - Saving model with best Classification-F1: 0.79931154736494 -> 0.8102971102971104 on epoch=362, global_step=1450
06/06/2022 07:09:03 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/06/2022 07:09:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/06/2022 07:09:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/06/2022 07:09:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/06/2022 07:09:13 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/06/2022 07:09:14 - INFO - __main__ - Global step 1500 Train loss 0.00 Classification-F1 0.7577838827838828 on epoch=374
06/06/2022 07:09:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/06/2022 07:09:19 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/06/2022 07:09:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/06/2022 07:09:24 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/06/2022 07:09:27 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/06/2022 07:09:28 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7473750673750674 on epoch=387
06/06/2022 07:09:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/06/2022 07:09:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/06/2022 07:09:36 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/06/2022 07:09:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/06/2022 07:09:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/06/2022 07:09:43 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.812546992481203 on epoch=399
06/06/2022 07:09:43 - INFO - __main__ - Saving model with best Classification-F1: 0.8102971102971104 -> 0.812546992481203 on epoch=399, global_step=1600
06/06/2022 07:09:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/06/2022 07:09:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/06/2022 07:09:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/06/2022 07:09:53 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=409
06/06/2022 07:09:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/06/2022 07:09:57 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7950103950103949 on epoch=412
06/06/2022 07:10:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/06/2022 07:10:02 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/06/2022 07:10:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/06/2022 07:10:08 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/06/2022 07:10:10 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/06/2022 07:10:12 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.7931436379712241 on epoch=424
06/06/2022 07:10:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/06/2022 07:10:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/06/2022 07:10:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/06/2022 07:10:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/06/2022 07:10:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/06/2022 07:10:26 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7350934622010203 on epoch=437
06/06/2022 07:10:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/06/2022 07:10:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/06/2022 07:10:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=444
06/06/2022 07:10:36 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/06/2022 07:10:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/06/2022 07:10:40 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.75026689660836 on epoch=449
06/06/2022 07:10:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/06/2022 07:10:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/06/2022 07:10:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/06/2022 07:10:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/06/2022 07:10:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/06/2022 07:10:54 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.7697833775419982 on epoch=462
06/06/2022 07:10:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/06/2022 07:10:59 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/06/2022 07:11:02 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/06/2022 07:11:04 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=472
06/06/2022 07:11:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/06/2022 07:11:08 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8011183060543462 on epoch=474
06/06/2022 07:11:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/06/2022 07:11:13 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/06/2022 07:11:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/06/2022 07:11:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/06/2022 07:11:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/06/2022 07:11:21 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7954828751164957 on epoch=487
06/06/2022 07:11:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/06/2022 07:11:26 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/06/2022 07:11:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/06/2022 07:11:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/06/2022 07:11:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/06/2022 07:11:35 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.7841178307280994 on epoch=499
06/06/2022 07:11:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/06/2022 07:11:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/06/2022 07:11:43 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/06/2022 07:11:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/06/2022 07:11:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=512
06/06/2022 07:11:49 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7449921773967461 on epoch=512
06/06/2022 07:11:51 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/06/2022 07:11:54 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/06/2022 07:11:56 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/06/2022 07:11:59 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=522
06/06/2022 07:12:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/06/2022 07:12:03 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7532232898086557 on epoch=524
06/06/2022 07:12:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/06/2022 07:12:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 07:12:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/06/2022 07:12:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/06/2022 07:12:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/06/2022 07:12:16 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.745776606646172 on epoch=537
06/06/2022 07:12:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/06/2022 07:12:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 07:12:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/06/2022 07:12:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/06/2022 07:12:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/06/2022 07:12:30 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.777618135376756 on epoch=549
06/06/2022 07:12:33 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 07:12:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/06/2022 07:12:38 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/06/2022 07:12:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/06/2022 07:12:43 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/06/2022 07:12:44 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7401898353958909 on epoch=562
06/06/2022 07:12:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/06/2022 07:12:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/06/2022 07:12:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/06/2022 07:12:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/06/2022 07:12:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 07:12:58 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.781799718732568 on epoch=574
06/06/2022 07:13:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 07:13:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 07:13:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=582
06/06/2022 07:13:08 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=584
06/06/2022 07:13:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 07:13:12 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7809027777777777 on epoch=587
06/06/2022 07:13:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/06/2022 07:13:17 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/06/2022 07:13:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/06/2022 07:13:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/06/2022 07:13:25 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 07:13:26 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7643544873146391 on epoch=599
06/06/2022 07:13:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 07:13:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 07:13:33 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.09 on epoch=607
06/06/2022 07:13:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/06/2022 07:13:38 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 07:13:39 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7483101431740269 on epoch=612
06/06/2022 07:13:42 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 07:13:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 07:13:47 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 07:13:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/06/2022 07:13:52 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 07:13:53 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7696492165242166 on epoch=624
06/06/2022 07:13:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/06/2022 07:13:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/06/2022 07:14:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/06/2022 07:14:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=634
06/06/2022 07:14:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 07:14:07 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7502164502164502 on epoch=637
06/06/2022 07:14:10 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 07:14:12 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/06/2022 07:14:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 07:14:17 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 07:14:20 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 07:14:21 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7265358797873789 on epoch=649
06/06/2022 07:14:23 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/06/2022 07:14:26 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 07:14:28 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 07:14:31 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 07:14:34 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 07:14:35 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.750224412887365 on epoch=662
06/06/2022 07:14:37 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 07:14:40 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 07:14:42 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 07:14:45 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 07:14:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 07:14:48 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6919568661896027 on epoch=674
06/06/2022 07:14:51 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=677
06/06/2022 07:14:54 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/06/2022 07:14:56 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 07:14:59 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 07:15:01 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 07:15:02 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.714031339031339 on epoch=687
06/06/2022 07:15:05 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 07:15:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 07:15:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/06/2022 07:15:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 07:15:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 07:15:16 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7784749034749034 on epoch=699
06/06/2022 07:15:19 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/06/2022 07:15:22 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 07:15:24 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 07:15:27 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=709
06/06/2022 07:15:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/06/2022 07:15:31 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.779485387244008 on epoch=712
06/06/2022 07:15:33 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 07:15:36 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 07:15:39 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 07:15:41 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=722
06/06/2022 07:15:44 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 07:15:45 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7811552859727302 on epoch=724
06/06/2022 07:15:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 07:15:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 07:15:53 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 07:15:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 07:15:58 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 07:15:59 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.781799718732568 on epoch=737
06/06/2022 07:16:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
06/06/2022 07:16:04 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 07:16:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 07:16:09 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/06/2022 07:16:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 07:16:13 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7543103448275862 on epoch=749
06/06/2022 07:16:13 - INFO - __main__ - save last model!
06/06/2022 07:16:13 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 07:16:13 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 07:16:13 - INFO - __main__ - Printing 3 examples
06/06/2022 07:16:13 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 07:16:13 - INFO - __main__ - ['others']
06/06/2022 07:16:13 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 07:16:13 - INFO - __main__ - ['others']
06/06/2022 07:16:13 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 07:16:13 - INFO - __main__ - ['others']
06/06/2022 07:16:13 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:16:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:16:13 - INFO - __main__ - Printing 3 examples
06/06/2022 07:16:13 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/06/2022 07:16:13 - INFO - __main__ - ['others']
06/06/2022 07:16:13 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/06/2022 07:16:13 - INFO - __main__ - ['others']
06/06/2022 07:16:13 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/06/2022 07:16:13 - INFO - __main__ - ['others']
06/06/2022 07:16:13 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:16:13 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:16:13 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 07:16:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:16:13 - INFO - __main__ - Printing 3 examples
06/06/2022 07:16:13 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/06/2022 07:16:13 - INFO - __main__ - ['others']
06/06/2022 07:16:13 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/06/2022 07:16:13 - INFO - __main__ - ['others']
06/06/2022 07:16:13 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/06/2022 07:16:13 - INFO - __main__ - ['others']
06/06/2022 07:16:13 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:16:13 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:16:13 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 07:16:15 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:16:21 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 07:16:30 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 07:16:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 07:16:31 - INFO - __main__ - Starting training!
06/06/2022 07:17:54 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_13_0.5_8_predictions.txt
06/06/2022 07:17:54 - INFO - __main__ - Classification-F1 on test data: 0.2700
06/06/2022 07:17:54 - INFO - __main__ - prefix=emo_16_13, lr=0.5, bsz=8, dev_performance=0.812546992481203, test_performance=0.26995282396497433
06/06/2022 07:17:54 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.4, bsz=8 ...
06/06/2022 07:17:55 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:17:55 - INFO - __main__ - Printing 3 examples
06/06/2022 07:17:55 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/06/2022 07:17:55 - INFO - __main__ - ['others']
06/06/2022 07:17:55 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/06/2022 07:17:55 - INFO - __main__ - ['others']
06/06/2022 07:17:55 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/06/2022 07:17:55 - INFO - __main__ - ['others']
06/06/2022 07:17:55 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:17:55 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:17:55 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 07:17:55 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:17:55 - INFO - __main__ - Printing 3 examples
06/06/2022 07:17:55 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/06/2022 07:17:55 - INFO - __main__ - ['others']
06/06/2022 07:17:55 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/06/2022 07:17:55 - INFO - __main__ - ['others']
06/06/2022 07:17:55 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/06/2022 07:17:55 - INFO - __main__ - ['others']
06/06/2022 07:17:55 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:17:55 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:17:55 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 07:18:13 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 07:18:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 07:18:14 - INFO - __main__ - Starting training!
06/06/2022 07:18:18 - INFO - __main__ - Step 10 Global step 10 Train loss 3.53 on epoch=2
06/06/2022 07:18:20 - INFO - __main__ - Step 20 Global step 20 Train loss 2.04 on epoch=4
06/06/2022 07:18:23 - INFO - __main__ - Step 30 Global step 30 Train loss 1.27 on epoch=7
06/06/2022 07:18:25 - INFO - __main__ - Step 40 Global step 40 Train loss 1.07 on epoch=9
06/06/2022 07:18:28 - INFO - __main__ - Step 50 Global step 50 Train loss 0.93 on epoch=12
06/06/2022 07:18:29 - INFO - __main__ - Global step 50 Train loss 1.77 Classification-F1 0.1 on epoch=12
06/06/2022 07:18:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/06/2022 07:18:31 - INFO - __main__ - Step 60 Global step 60 Train loss 0.97 on epoch=14
06/06/2022 07:18:34 - INFO - __main__ - Step 70 Global step 70 Train loss 0.90 on epoch=17
06/06/2022 07:18:36 - INFO - __main__ - Step 80 Global step 80 Train loss 0.85 on epoch=19
06/06/2022 07:18:39 - INFO - __main__ - Step 90 Global step 90 Train loss 0.76 on epoch=22
06/06/2022 07:18:41 - INFO - __main__ - Step 100 Global step 100 Train loss 0.88 on epoch=24
06/06/2022 07:18:42 - INFO - __main__ - Global step 100 Train loss 0.87 Classification-F1 0.27121212121212124 on epoch=24
06/06/2022 07:18:42 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.27121212121212124 on epoch=24, global_step=100
06/06/2022 07:18:45 - INFO - __main__ - Step 110 Global step 110 Train loss 0.78 on epoch=27
06/06/2022 07:18:47 - INFO - __main__ - Step 120 Global step 120 Train loss 0.85 on epoch=29
06/06/2022 07:18:50 - INFO - __main__ - Step 130 Global step 130 Train loss 0.71 on epoch=32
06/06/2022 07:18:52 - INFO - __main__ - Step 140 Global step 140 Train loss 0.70 on epoch=34
06/06/2022 07:18:55 - INFO - __main__ - Step 150 Global step 150 Train loss 0.66 on epoch=37
06/06/2022 07:18:56 - INFO - __main__ - Global step 150 Train loss 0.74 Classification-F1 0.6349505614211496 on epoch=37
06/06/2022 07:18:56 - INFO - __main__ - Saving model with best Classification-F1: 0.27121212121212124 -> 0.6349505614211496 on epoch=37, global_step=150
06/06/2022 07:18:58 - INFO - __main__ - Step 160 Global step 160 Train loss 0.57 on epoch=39
06/06/2022 07:19:01 - INFO - __main__ - Step 170 Global step 170 Train loss 0.62 on epoch=42
06/06/2022 07:19:03 - INFO - __main__ - Step 180 Global step 180 Train loss 0.58 on epoch=44
06/06/2022 07:19:06 - INFO - __main__ - Step 190 Global step 190 Train loss 0.48 on epoch=47
06/06/2022 07:19:09 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=49
06/06/2022 07:19:10 - INFO - __main__ - Global step 200 Train loss 0.54 Classification-F1 0.544040404040404 on epoch=49
06/06/2022 07:19:12 - INFO - __main__ - Step 210 Global step 210 Train loss 0.49 on epoch=52
06/06/2022 07:19:15 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=54
06/06/2022 07:19:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.48 on epoch=57
06/06/2022 07:19:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.41 on epoch=59
06/06/2022 07:19:22 - INFO - __main__ - Step 250 Global step 250 Train loss 0.39 on epoch=62
06/06/2022 07:19:23 - INFO - __main__ - Global step 250 Train loss 0.45 Classification-F1 0.7162532684223453 on epoch=62
06/06/2022 07:19:23 - INFO - __main__ - Saving model with best Classification-F1: 0.6349505614211496 -> 0.7162532684223453 on epoch=62, global_step=250
06/06/2022 07:19:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.35 on epoch=64
06/06/2022 07:19:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=67
06/06/2022 07:19:31 - INFO - __main__ - Step 280 Global step 280 Train loss 0.35 on epoch=69
06/06/2022 07:19:33 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=72
06/06/2022 07:19:36 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=74
06/06/2022 07:19:37 - INFO - __main__ - Global step 300 Train loss 0.33 Classification-F1 0.5845959595959596 on epoch=74
06/06/2022 07:19:39 - INFO - __main__ - Step 310 Global step 310 Train loss 0.22 on epoch=77
06/06/2022 07:19:42 - INFO - __main__ - Step 320 Global step 320 Train loss 0.23 on epoch=79
06/06/2022 07:19:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.20 on epoch=82
06/06/2022 07:19:47 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=84
06/06/2022 07:19:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=87
06/06/2022 07:19:50 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.6990105719707238 on epoch=87
06/06/2022 07:19:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.19 on epoch=89
06/06/2022 07:19:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.16 on epoch=92
06/06/2022 07:19:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.16 on epoch=94
06/06/2022 07:20:02 - INFO - __main__ - Step 390 Global step 390 Train loss 0.15 on epoch=97
06/06/2022 07:20:05 - INFO - __main__ - Step 400 Global step 400 Train loss 0.14 on epoch=99
06/06/2022 07:20:06 - INFO - __main__ - Global step 400 Train loss 0.16 Classification-F1 0.7304316967763108 on epoch=99
06/06/2022 07:20:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7162532684223453 -> 0.7304316967763108 on epoch=99, global_step=400
06/06/2022 07:20:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.13 on epoch=102
06/06/2022 07:20:11 - INFO - __main__ - Step 420 Global step 420 Train loss 0.14 on epoch=104
06/06/2022 07:20:14 - INFO - __main__ - Step 430 Global step 430 Train loss 0.14 on epoch=107
06/06/2022 07:20:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.08 on epoch=109
06/06/2022 07:20:19 - INFO - __main__ - Step 450 Global step 450 Train loss 0.12 on epoch=112
06/06/2022 07:20:20 - INFO - __main__ - Global step 450 Train loss 0.12 Classification-F1 0.7192652329749104 on epoch=112
06/06/2022 07:20:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.07 on epoch=114
06/06/2022 07:20:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.10 on epoch=117
06/06/2022 07:20:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.08 on epoch=119
06/06/2022 07:20:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.11 on epoch=122
06/06/2022 07:20:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.17 on epoch=124
06/06/2022 07:20:35 - INFO - __main__ - Global step 500 Train loss 0.11 Classification-F1 0.7120583717357911 on epoch=124
06/06/2022 07:20:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.08 on epoch=127
06/06/2022 07:20:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.09 on epoch=129
06/06/2022 07:20:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.15 on epoch=132
06/06/2022 07:20:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=134
06/06/2022 07:20:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=137
06/06/2022 07:20:49 - INFO - __main__ - Global step 550 Train loss 0.11 Classification-F1 0.5965024600075496 on epoch=137
06/06/2022 07:20:51 - INFO - __main__ - Step 560 Global step 560 Train loss 0.10 on epoch=139
06/06/2022 07:20:54 - INFO - __main__ - Step 570 Global step 570 Train loss 0.06 on epoch=142
06/06/2022 07:20:57 - INFO - __main__ - Step 580 Global step 580 Train loss 0.09 on epoch=144
06/06/2022 07:20:59 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=147
06/06/2022 07:21:02 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=149
06/06/2022 07:21:03 - INFO - __main__ - Global step 600 Train loss 0.08 Classification-F1 0.7717753214527409 on epoch=149
06/06/2022 07:21:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7304316967763108 -> 0.7717753214527409 on epoch=149, global_step=600
06/06/2022 07:21:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=152
06/06/2022 07:21:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=154
06/06/2022 07:21:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=157
06/06/2022 07:21:13 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=159
06/06/2022 07:21:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=162
06/06/2022 07:21:17 - INFO - __main__ - Global step 650 Train loss 0.07 Classification-F1 0.7607084748160724 on epoch=162
06/06/2022 07:21:19 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=164
06/06/2022 07:21:22 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=167
06/06/2022 07:21:24 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=169
06/06/2022 07:21:27 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=172
06/06/2022 07:21:30 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=174
06/06/2022 07:21:31 - INFO - __main__ - Global step 700 Train loss 0.03 Classification-F1 0.7735372735372735 on epoch=174
06/06/2022 07:21:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7717753214527409 -> 0.7735372735372735 on epoch=174, global_step=700
06/06/2022 07:21:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=177
06/06/2022 07:21:36 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=179
06/06/2022 07:21:39 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=182
06/06/2022 07:21:41 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/06/2022 07:21:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=187
06/06/2022 07:21:45 - INFO - __main__ - Global step 750 Train loss 0.04 Classification-F1 0.7763746057863705 on epoch=187
06/06/2022 07:21:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7735372735372735 -> 0.7763746057863705 on epoch=187, global_step=750
06/06/2022 07:21:47 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=189
06/06/2022 07:21:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=192
06/06/2022 07:21:52 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=194
06/06/2022 07:21:55 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=197
06/06/2022 07:21:58 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=199
06/06/2022 07:21:59 - INFO - __main__ - Global step 800 Train loss 0.04 Classification-F1 0.7149383484867357 on epoch=199
06/06/2022 07:22:01 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=202
06/06/2022 07:22:04 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=204
06/06/2022 07:22:06 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=207
06/06/2022 07:22:09 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=209
06/06/2022 07:22:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
06/06/2022 07:22:13 - INFO - __main__ - Global step 850 Train loss 0.03 Classification-F1 0.7714583333333334 on epoch=212
06/06/2022 07:22:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=214
06/06/2022 07:22:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=217
06/06/2022 07:22:20 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=219
06/06/2022 07:22:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=222
06/06/2022 07:22:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/06/2022 07:22:27 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.736969696969697 on epoch=224
06/06/2022 07:22:29 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/06/2022 07:22:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/06/2022 07:22:34 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
06/06/2022 07:22:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/06/2022 07:22:39 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
06/06/2022 07:22:41 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.7317498278575645 on epoch=237
06/06/2022 07:22:43 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=239
06/06/2022 07:22:46 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=242
06/06/2022 07:22:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=244
06/06/2022 07:22:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
06/06/2022 07:22:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/06/2022 07:22:55 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.756969696969697 on epoch=249
06/06/2022 07:22:57 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/06/2022 07:23:00 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/06/2022 07:23:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/06/2022 07:23:05 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
06/06/2022 07:23:07 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/06/2022 07:23:09 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.7048047366786024 on epoch=262
06/06/2022 07:23:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/06/2022 07:23:14 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=267
06/06/2022 07:23:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/06/2022 07:23:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/06/2022 07:23:22 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/06/2022 07:23:23 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.7419444444444444 on epoch=274
06/06/2022 07:23:25 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=277
06/06/2022 07:23:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=279
06/06/2022 07:23:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/06/2022 07:23:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=284
06/06/2022 07:23:36 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/06/2022 07:23:37 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.7157960352025459 on epoch=287
06/06/2022 07:23:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=289
06/06/2022 07:23:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/06/2022 07:23:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=294
06/06/2022 07:23:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/06/2022 07:23:49 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/06/2022 07:23:50 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.739213150397361 on epoch=299
06/06/2022 07:23:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/06/2022 07:23:56 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/06/2022 07:23:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/06/2022 07:24:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=309
06/06/2022 07:24:03 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/06/2022 07:24:05 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7726146331738437 on epoch=312
06/06/2022 07:24:07 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/06/2022 07:24:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/06/2022 07:24:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
06/06/2022 07:24:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/06/2022 07:24:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/06/2022 07:24:18 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.7754010695187167 on epoch=324
06/06/2022 07:24:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/06/2022 07:24:23 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/06/2022 07:24:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/06/2022 07:24:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/06/2022 07:24:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/06/2022 07:24:32 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.757296494355318 on epoch=337
06/06/2022 07:24:35 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/06/2022 07:24:38 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/06/2022 07:24:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/06/2022 07:24:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/06/2022 07:24:46 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/06/2022 07:24:47 - INFO - __main__ - Global step 1400 Train loss 0.00 Classification-F1 0.7309282036613272 on epoch=349
06/06/2022 07:24:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/06/2022 07:24:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/06/2022 07:24:55 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/06/2022 07:24:58 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/06/2022 07:25:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/06/2022 07:25:02 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7313969813969814 on epoch=362
06/06/2022 07:25:04 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/06/2022 07:25:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/06/2022 07:25:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=369
06/06/2022 07:25:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/06/2022 07:25:15 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/06/2022 07:25:16 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.7602493227493228 on epoch=374
06/06/2022 07:25:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/06/2022 07:25:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/06/2022 07:25:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
06/06/2022 07:25:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/06/2022 07:25:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/06/2022 07:25:30 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7900653400653401 on epoch=387
06/06/2022 07:25:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7763746057863705 -> 0.7900653400653401 on epoch=387, global_step=1550
06/06/2022 07:25:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/06/2022 07:25:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/06/2022 07:25:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/06/2022 07:25:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/06/2022 07:25:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/06/2022 07:25:44 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.7723801220575415 on epoch=399
06/06/2022 07:25:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/06/2022 07:25:49 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/06/2022 07:25:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/06/2022 07:25:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/06/2022 07:25:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/06/2022 07:25:57 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7944170771756978 on epoch=412
06/06/2022 07:25:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7900653400653401 -> 0.7944170771756978 on epoch=412, global_step=1650
06/06/2022 07:26:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/06/2022 07:26:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/06/2022 07:26:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/06/2022 07:26:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=422
06/06/2022 07:26:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/06/2022 07:26:12 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7603950103950103 on epoch=424
06/06/2022 07:26:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/06/2022 07:26:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/06/2022 07:26:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/06/2022 07:26:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/06/2022 07:26:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/06/2022 07:26:26 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.8090782908145338 on epoch=437
06/06/2022 07:26:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7944170771756978 -> 0.8090782908145338 on epoch=437, global_step=1750
06/06/2022 07:26:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/06/2022 07:26:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/06/2022 07:26:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/06/2022 07:26:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/06/2022 07:26:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/06/2022 07:26:40 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.810436907495731 on epoch=449
06/06/2022 07:26:40 - INFO - __main__ - Saving model with best Classification-F1: 0.8090782908145338 -> 0.810436907495731 on epoch=449, global_step=1800
06/06/2022 07:26:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/06/2022 07:26:46 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/06/2022 07:26:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/06/2022 07:26:51 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/06/2022 07:26:54 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/06/2022 07:26:55 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.8119101787965886 on epoch=462
06/06/2022 07:26:55 - INFO - __main__ - Saving model with best Classification-F1: 0.810436907495731 -> 0.8119101787965886 on epoch=462, global_step=1850
06/06/2022 07:26:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/06/2022 07:27:00 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/06/2022 07:27:03 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/06/2022 07:27:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/06/2022 07:27:08 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/06/2022 07:27:09 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.7787660256410256 on epoch=474
06/06/2022 07:27:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/06/2022 07:27:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/06/2022 07:27:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/06/2022 07:27:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/06/2022 07:27:22 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/06/2022 07:27:23 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7411764705882353 on epoch=487
06/06/2022 07:27:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/06/2022 07:27:29 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/06/2022 07:27:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/06/2022 07:27:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/06/2022 07:27:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/06/2022 07:27:37 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.757968017645437 on epoch=499
06/06/2022 07:27:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/06/2022 07:27:43 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/06/2022 07:27:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/06/2022 07:27:48 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/06/2022 07:27:50 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/06/2022 07:27:52 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.7458998174168453 on epoch=512
06/06/2022 07:27:54 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/06/2022 07:27:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/06/2022 07:27:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/06/2022 07:28:02 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/06/2022 07:28:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/06/2022 07:28:06 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7608089826839827 on epoch=524
06/06/2022 07:28:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/06/2022 07:28:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 07:28:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/06/2022 07:28:17 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/06/2022 07:28:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/06/2022 07:28:20 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7723801220575415 on epoch=537
06/06/2022 07:28:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/06/2022 07:28:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 07:28:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/06/2022 07:28:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/06/2022 07:28:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/06/2022 07:28:35 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7304946011842564 on epoch=549
06/06/2022 07:28:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 07:28:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=554
06/06/2022 07:28:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/06/2022 07:28:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/06/2022 07:28:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/06/2022 07:28:49 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.757968017645437 on epoch=562
06/06/2022 07:28:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/06/2022 07:28:54 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/06/2022 07:28:56 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/06/2022 07:28:59 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/06/2022 07:29:02 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 07:29:03 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7602493227493228 on epoch=574
06/06/2022 07:29:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 07:29:08 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 07:29:11 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/06/2022 07:29:14 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=584
06/06/2022 07:29:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/06/2022 07:29:17 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7941312008674438 on epoch=587
06/06/2022 07:29:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/06/2022 07:29:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/06/2022 07:29:26 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/06/2022 07:29:28 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/06/2022 07:29:31 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 07:29:32 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7904876373626373 on epoch=599
06/06/2022 07:29:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 07:29:37 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 07:29:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 07:29:42 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 07:29:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/06/2022 07:29:46 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7582223109957056 on epoch=612
06/06/2022 07:29:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 07:29:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 07:29:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 07:29:57 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/06/2022 07:30:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/06/2022 07:30:01 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7609681372549019 on epoch=624
06/06/2022 07:30:04 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/06/2022 07:30:06 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/06/2022 07:30:09 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/06/2022 07:30:11 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/06/2022 07:30:14 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 07:30:15 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7941312008674438 on epoch=637
06/06/2022 07:30:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 07:30:20 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/06/2022 07:30:23 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 07:30:26 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 07:30:28 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 07:30:29 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.8110972976509848 on epoch=649
06/06/2022 07:30:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/06/2022 07:30:35 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 07:30:37 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 07:30:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 07:30:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 07:30:44 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7292240627724499 on epoch=662
06/06/2022 07:30:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=664
06/06/2022 07:30:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 07:30:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 07:30:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 07:30:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 07:30:58 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7904176093514329 on epoch=674
06/06/2022 07:31:01 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/06/2022 07:31:04 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 07:31:06 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 07:31:09 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 07:31:11 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 07:31:13 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.796135752688172 on epoch=687
06/06/2022 07:31:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 07:31:18 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.08 on epoch=692
06/06/2022 07:31:21 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/06/2022 07:31:23 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=697
06/06/2022 07:31:26 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 07:31:27 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7452377536380406 on epoch=699
06/06/2022 07:31:29 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/06/2022 07:31:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 07:31:35 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 07:31:37 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/06/2022 07:31:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/06/2022 07:31:41 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6908730158730159 on epoch=712
06/06/2022 07:31:44 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 07:31:47 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 07:31:49 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 07:31:52 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/06/2022 07:31:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 07:31:56 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7375694444444444 on epoch=724
06/06/2022 07:31:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 07:32:01 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/06/2022 07:32:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=732
06/06/2022 07:32:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 07:32:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 07:32:10 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6948247921708934 on epoch=737
06/06/2022 07:32:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=739
06/06/2022 07:32:15 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 07:32:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 07:32:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=747
06/06/2022 07:32:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 07:32:25 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7011562998405104 on epoch=749
06/06/2022 07:32:25 - INFO - __main__ - save last model!
06/06/2022 07:32:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 07:32:25 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 07:32:25 - INFO - __main__ - Printing 3 examples
06/06/2022 07:32:25 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 07:32:25 - INFO - __main__ - ['others']
06/06/2022 07:32:25 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 07:32:25 - INFO - __main__ - ['others']
06/06/2022 07:32:25 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 07:32:25 - INFO - __main__ - ['others']
06/06/2022 07:32:25 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:32:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:32:25 - INFO - __main__ - Printing 3 examples
06/06/2022 07:32:25 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/06/2022 07:32:25 - INFO - __main__ - ['others']
06/06/2022 07:32:25 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/06/2022 07:32:25 - INFO - __main__ - ['others']
06/06/2022 07:32:25 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/06/2022 07:32:25 - INFO - __main__ - ['others']
06/06/2022 07:32:25 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:32:25 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:32:25 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 07:32:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:32:25 - INFO - __main__ - Printing 3 examples
06/06/2022 07:32:25 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/06/2022 07:32:25 - INFO - __main__ - ['others']
06/06/2022 07:32:25 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/06/2022 07:32:25 - INFO - __main__ - ['others']
06/06/2022 07:32:25 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/06/2022 07:32:25 - INFO - __main__ - ['others']
06/06/2022 07:32:25 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:32:25 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:32:25 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 07:32:27 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:32:32 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 07:32:40 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 07:32:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 07:32:41 - INFO - __main__ - Starting training!
06/06/2022 07:34:13 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_13_0.4_8_predictions.txt
06/06/2022 07:34:13 - INFO - __main__ - Classification-F1 on test data: 0.1522
06/06/2022 07:34:14 - INFO - __main__ - prefix=emo_16_13, lr=0.4, bsz=8, dev_performance=0.8119101787965886, test_performance=0.15216724972583842
06/06/2022 07:34:14 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.3, bsz=8 ...
06/06/2022 07:34:14 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:34:14 - INFO - __main__ - Printing 3 examples
06/06/2022 07:34:14 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/06/2022 07:34:14 - INFO - __main__ - ['others']
06/06/2022 07:34:14 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/06/2022 07:34:14 - INFO - __main__ - ['others']
06/06/2022 07:34:14 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/06/2022 07:34:14 - INFO - __main__ - ['others']
06/06/2022 07:34:14 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:34:14 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:34:15 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 07:34:15 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:34:15 - INFO - __main__ - Printing 3 examples
06/06/2022 07:34:15 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/06/2022 07:34:15 - INFO - __main__ - ['others']
06/06/2022 07:34:15 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/06/2022 07:34:15 - INFO - __main__ - ['others']
06/06/2022 07:34:15 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/06/2022 07:34:15 - INFO - __main__ - ['others']
06/06/2022 07:34:15 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:34:15 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:34:15 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 07:34:31 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 07:34:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 07:34:32 - INFO - __main__ - Starting training!
06/06/2022 07:34:35 - INFO - __main__ - Step 10 Global step 10 Train loss 3.67 on epoch=2
06/06/2022 07:34:38 - INFO - __main__ - Step 20 Global step 20 Train loss 2.16 on epoch=4
06/06/2022 07:34:40 - INFO - __main__ - Step 30 Global step 30 Train loss 1.52 on epoch=7
06/06/2022 07:34:43 - INFO - __main__ - Step 40 Global step 40 Train loss 1.09 on epoch=9
06/06/2022 07:34:46 - INFO - __main__ - Step 50 Global step 50 Train loss 0.98 on epoch=12
06/06/2022 07:34:46 - INFO - __main__ - Global step 50 Train loss 1.88 Classification-F1 0.16138763197586728 on epoch=12
06/06/2022 07:34:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.16138763197586728 on epoch=12, global_step=50
06/06/2022 07:34:49 - INFO - __main__ - Step 60 Global step 60 Train loss 0.86 on epoch=14
06/06/2022 07:34:52 - INFO - __main__ - Step 70 Global step 70 Train loss 0.83 on epoch=17
06/06/2022 07:34:54 - INFO - __main__ - Step 80 Global step 80 Train loss 0.87 on epoch=19
06/06/2022 07:34:57 - INFO - __main__ - Step 90 Global step 90 Train loss 0.91 on epoch=22
06/06/2022 07:34:59 - INFO - __main__ - Step 100 Global step 100 Train loss 0.88 on epoch=24
06/06/2022 07:35:00 - INFO - __main__ - Global step 100 Train loss 0.87 Classification-F1 0.28582202111613875 on epoch=24
06/06/2022 07:35:00 - INFO - __main__ - Saving model with best Classification-F1: 0.16138763197586728 -> 0.28582202111613875 on epoch=24, global_step=100
06/06/2022 07:35:03 - INFO - __main__ - Step 110 Global step 110 Train loss 0.77 on epoch=27
06/06/2022 07:35:06 - INFO - __main__ - Step 120 Global step 120 Train loss 0.83 on epoch=29
06/06/2022 07:35:08 - INFO - __main__ - Step 130 Global step 130 Train loss 0.87 on epoch=32
06/06/2022 07:35:11 - INFO - __main__ - Step 140 Global step 140 Train loss 0.68 on epoch=34
06/06/2022 07:35:13 - INFO - __main__ - Step 150 Global step 150 Train loss 0.68 on epoch=37
06/06/2022 07:35:14 - INFO - __main__ - Global step 150 Train loss 0.77 Classification-F1 0.5305685069553135 on epoch=37
06/06/2022 07:35:14 - INFO - __main__ - Saving model with best Classification-F1: 0.28582202111613875 -> 0.5305685069553135 on epoch=37, global_step=150
06/06/2022 07:35:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.67 on epoch=39
06/06/2022 07:35:19 - INFO - __main__ - Step 170 Global step 170 Train loss 0.68 on epoch=42
06/06/2022 07:35:22 - INFO - __main__ - Step 180 Global step 180 Train loss 0.63 on epoch=44
06/06/2022 07:35:24 - INFO - __main__ - Step 190 Global step 190 Train loss 0.59 on epoch=47
06/06/2022 07:35:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.66 on epoch=49
06/06/2022 07:35:28 - INFO - __main__ - Global step 200 Train loss 0.65 Classification-F1 0.5913419913419913 on epoch=49
06/06/2022 07:35:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5305685069553135 -> 0.5913419913419913 on epoch=49, global_step=200
06/06/2022 07:35:30 - INFO - __main__ - Step 210 Global step 210 Train loss 0.48 on epoch=52
06/06/2022 07:35:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=54
06/06/2022 07:35:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.60 on epoch=57
06/06/2022 07:35:38 - INFO - __main__ - Step 240 Global step 240 Train loss 0.53 on epoch=59
06/06/2022 07:35:41 - INFO - __main__ - Step 250 Global step 250 Train loss 0.45 on epoch=62
06/06/2022 07:35:42 - INFO - __main__ - Global step 250 Train loss 0.52 Classification-F1 0.7227150537634409 on epoch=62
06/06/2022 07:35:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5913419913419913 -> 0.7227150537634409 on epoch=62, global_step=250
06/06/2022 07:35:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.61 on epoch=64
06/06/2022 07:35:47 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=67
06/06/2022 07:35:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=69
06/06/2022 07:35:52 - INFO - __main__ - Step 290 Global step 290 Train loss 0.47 on epoch=72
06/06/2022 07:35:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.40 on epoch=74
06/06/2022 07:35:56 - INFO - __main__ - Global step 300 Train loss 0.49 Classification-F1 0.5781794425087108 on epoch=74
06/06/2022 07:35:58 - INFO - __main__ - Step 310 Global step 310 Train loss 0.36 on epoch=77
06/06/2022 07:36:01 - INFO - __main__ - Step 320 Global step 320 Train loss 0.36 on epoch=79
06/06/2022 07:36:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=82
06/06/2022 07:36:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=84
06/06/2022 07:36:09 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=87
06/06/2022 07:36:09 - INFO - __main__ - Global step 350 Train loss 0.36 Classification-F1 0.7226574500768049 on epoch=87
06/06/2022 07:36:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=89
06/06/2022 07:36:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=92
06/06/2022 07:36:17 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=94
06/06/2022 07:36:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=97
06/06/2022 07:36:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=99
06/06/2022 07:36:24 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.6271273045466593 on epoch=99
06/06/2022 07:36:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/06/2022 07:36:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=104
06/06/2022 07:36:31 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=107
06/06/2022 07:36:34 - INFO - __main__ - Step 440 Global step 440 Train loss 0.18 on epoch=109
06/06/2022 07:36:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=112
06/06/2022 07:36:38 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.7347875304771856 on epoch=112
06/06/2022 07:36:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7227150537634409 -> 0.7347875304771856 on epoch=112, global_step=450
06/06/2022 07:36:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=114
06/06/2022 07:36:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.14 on epoch=117
06/06/2022 07:36:46 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=119
06/06/2022 07:36:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=122
06/06/2022 07:36:51 - INFO - __main__ - Step 500 Global step 500 Train loss 0.12 on epoch=124
06/06/2022 07:36:52 - INFO - __main__ - Global step 500 Train loss 0.17 Classification-F1 0.7057868601986248 on epoch=124
06/06/2022 07:36:55 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=127
06/06/2022 07:36:57 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=129
06/06/2022 07:37:00 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=132
06/06/2022 07:37:02 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=134
06/06/2022 07:37:05 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=137
06/06/2022 07:37:06 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.6986891616803405 on epoch=137
06/06/2022 07:37:08 - INFO - __main__ - Step 560 Global step 560 Train loss 0.10 on epoch=139
06/06/2022 07:37:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=142
06/06/2022 07:37:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=144
06/06/2022 07:37:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.07 on epoch=147
06/06/2022 07:37:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=149
06/06/2022 07:37:20 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.7058823529411766 on epoch=149
06/06/2022 07:37:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.05 on epoch=152
06/06/2022 07:37:25 - INFO - __main__ - Step 620 Global step 620 Train loss 0.10 on epoch=154
06/06/2022 07:37:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=157
06/06/2022 07:37:30 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=159
06/06/2022 07:37:33 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=162
06/06/2022 07:37:34 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.7986175115207375 on epoch=162
06/06/2022 07:37:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7347875304771856 -> 0.7986175115207375 on epoch=162, global_step=650
06/06/2022 07:37:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.05 on epoch=164
06/06/2022 07:37:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=167
06/06/2022 07:37:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=169
06/06/2022 07:37:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=172
06/06/2022 07:37:47 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=174
06/06/2022 07:37:48 - INFO - __main__ - Global step 700 Train loss 0.07 Classification-F1 0.6581397599690283 on epoch=174
06/06/2022 07:37:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=177
06/06/2022 07:37:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=179
06/06/2022 07:37:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.06 on epoch=182
06/06/2022 07:37:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=184
06/06/2022 07:38:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=187
06/06/2022 07:38:03 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.7810693138279345 on epoch=187
06/06/2022 07:38:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=189
06/06/2022 07:38:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=192
06/06/2022 07:38:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/06/2022 07:38:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=197
06/06/2022 07:38:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
06/06/2022 07:38:17 - INFO - __main__ - Global step 800 Train loss 0.07 Classification-F1 0.6959279533292693 on epoch=199
06/06/2022 07:38:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=202
06/06/2022 07:38:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=204
06/06/2022 07:38:25 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=207
06/06/2022 07:38:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=209
06/06/2022 07:38:30 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=212
06/06/2022 07:38:31 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.6982142857142857 on epoch=212
06/06/2022 07:38:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=214
06/06/2022 07:38:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=217
06/06/2022 07:38:38 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=219
06/06/2022 07:38:41 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/06/2022 07:38:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/06/2022 07:38:45 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.5762302763375281 on epoch=224
06/06/2022 07:38:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/06/2022 07:38:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=229
06/06/2022 07:38:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=232
06/06/2022 07:38:55 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/06/2022 07:38:58 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/06/2022 07:38:59 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.5601483836777954 on epoch=237
06/06/2022 07:39:02 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=239
06/06/2022 07:39:04 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
06/06/2022 07:39:07 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/06/2022 07:39:09 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/06/2022 07:39:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
06/06/2022 07:39:13 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.7905764966740576 on epoch=249
06/06/2022 07:39:16 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/06/2022 07:39:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=254
06/06/2022 07:39:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
06/06/2022 07:39:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=259
06/06/2022 07:39:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/06/2022 07:39:27 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.6374210526315789 on epoch=262
06/06/2022 07:39:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/06/2022 07:39:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=267
06/06/2022 07:39:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/06/2022 07:39:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/06/2022 07:39:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/06/2022 07:39:42 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.6052290374541014 on epoch=274
06/06/2022 07:39:45 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=277
06/06/2022 07:39:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/06/2022 07:39:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/06/2022 07:39:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/06/2022 07:39:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/06/2022 07:39:56 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.730335173883561 on epoch=287
06/06/2022 07:39:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/06/2022 07:40:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/06/2022 07:40:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/06/2022 07:40:06 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/06/2022 07:40:09 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
06/06/2022 07:40:10 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.7961041271347249 on epoch=299
06/06/2022 07:40:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/06/2022 07:40:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/06/2022 07:40:18 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/06/2022 07:40:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=309
06/06/2022 07:40:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/06/2022 07:40:24 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.6256237006237007 on epoch=312
06/06/2022 07:40:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/06/2022 07:40:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/06/2022 07:40:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/06/2022 07:40:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/06/2022 07:40:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/06/2022 07:40:39 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.5964450127877238 on epoch=324
06/06/2022 07:40:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/06/2022 07:40:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/06/2022 07:40:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/06/2022 07:40:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/06/2022 07:40:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/06/2022 07:40:53 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7781870347394542 on epoch=337
06/06/2022 07:40:55 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/06/2022 07:40:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/06/2022 07:41:01 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/06/2022 07:41:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/06/2022 07:41:06 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/06/2022 07:41:07 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.8119336934861129 on epoch=349
06/06/2022 07:41:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7986175115207375 -> 0.8119336934861129 on epoch=349, global_step=1400
06/06/2022 07:41:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/06/2022 07:41:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/06/2022 07:41:15 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/06/2022 07:41:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/06/2022 07:41:20 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/06/2022 07:41:21 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7058343560840424 on epoch=362
06/06/2022 07:41:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/06/2022 07:41:27 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/06/2022 07:41:29 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/06/2022 07:41:32 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=372
06/06/2022 07:41:35 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/06/2022 07:41:36 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.8085139203294975 on epoch=374
06/06/2022 07:41:38 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/06/2022 07:41:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/06/2022 07:41:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/06/2022 07:41:46 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/06/2022 07:41:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/06/2022 07:41:50 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7953560255926554 on epoch=387
06/06/2022 07:41:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/06/2022 07:41:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/06/2022 07:41:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/06/2022 07:42:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/06/2022 07:42:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
06/06/2022 07:42:04 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7658914361500568 on epoch=399
06/06/2022 07:42:07 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/06/2022 07:42:10 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/06/2022 07:42:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/06/2022 07:42:15 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=409
06/06/2022 07:42:17 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/06/2022 07:42:19 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7945350042124236 on epoch=412
06/06/2022 07:42:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/06/2022 07:42:24 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/06/2022 07:42:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/06/2022 07:42:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/06/2022 07:42:32 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/06/2022 07:42:33 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.6946202054897708 on epoch=424
06/06/2022 07:42:36 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/06/2022 07:42:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=429
06/06/2022 07:42:41 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/06/2022 07:42:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/06/2022 07:42:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=437
06/06/2022 07:42:48 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.757362200910588 on epoch=437
06/06/2022 07:42:50 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/06/2022 07:42:53 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/06/2022 07:42:55 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/06/2022 07:42:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/06/2022 07:43:01 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/06/2022 07:43:02 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7102547211242864 on epoch=449
06/06/2022 07:43:04 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/06/2022 07:43:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/06/2022 07:43:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/06/2022 07:43:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/06/2022 07:43:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/06/2022 07:43:16 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.8096682290230677 on epoch=462
06/06/2022 07:43:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=464
06/06/2022 07:43:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/06/2022 07:43:24 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/06/2022 07:43:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/06/2022 07:43:29 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/06/2022 07:43:30 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6278451178451178 on epoch=474
06/06/2022 07:43:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/06/2022 07:43:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/06/2022 07:43:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/06/2022 07:43:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/06/2022 07:43:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/06/2022 07:43:44 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7762406015037594 on epoch=487
06/06/2022 07:43:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/06/2022 07:43:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/06/2022 07:43:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/06/2022 07:43:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/06/2022 07:43:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/06/2022 07:43:59 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6380479735318445 on epoch=499
06/06/2022 07:44:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/06/2022 07:44:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/06/2022 07:44:07 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/06/2022 07:44:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/06/2022 07:44:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.16 on epoch=512
06/06/2022 07:44:13 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.729906204906205 on epoch=512
06/06/2022 07:44:16 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=514
06/06/2022 07:44:18 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/06/2022 07:44:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/06/2022 07:44:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/06/2022 07:44:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/06/2022 07:44:27 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.698727146263911 on epoch=524
06/06/2022 07:44:30 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=527
06/06/2022 07:44:32 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 07:44:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/06/2022 07:44:37 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/06/2022 07:44:40 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/06/2022 07:44:41 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.796973803071364 on epoch=537
06/06/2022 07:44:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/06/2022 07:44:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 07:44:49 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/06/2022 07:44:51 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/06/2022 07:44:54 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/06/2022 07:44:55 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8249007936507936 on epoch=549
06/06/2022 07:44:55 - INFO - __main__ - Saving model with best Classification-F1: 0.8119336934861129 -> 0.8249007936507936 on epoch=549, global_step=2200
06/06/2022 07:44:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 07:45:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/06/2022 07:45:03 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/06/2022 07:45:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/06/2022 07:45:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/06/2022 07:45:09 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.677950937950938 on epoch=562
06/06/2022 07:45:11 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/06/2022 07:45:14 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/06/2022 07:45:17 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/06/2022 07:45:19 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/06/2022 07:45:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 07:45:23 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.6415956727518595 on epoch=574
06/06/2022 07:45:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 07:45:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 07:45:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/06/2022 07:45:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/06/2022 07:45:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 07:45:37 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.6384598307985405 on epoch=587
06/06/2022 07:45:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/06/2022 07:45:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/06/2022 07:45:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 07:45:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/06/2022 07:45:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 07:45:52 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7932449903038138 on epoch=599
06/06/2022 07:45:54 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 07:45:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/06/2022 07:46:00 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/06/2022 07:46:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/06/2022 07:46:05 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 07:46:06 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7870410839160839 on epoch=612
06/06/2022 07:46:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 07:46:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 07:46:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 07:46:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/06/2022 07:46:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 07:46:21 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.5946803069053708 on epoch=624
06/06/2022 07:46:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=627
06/06/2022 07:46:26 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=629
06/06/2022 07:46:28 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=632
06/06/2022 07:46:31 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/06/2022 07:46:34 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/06/2022 07:46:35 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7735632183908046 on epoch=637
06/06/2022 07:46:38 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.08 on epoch=639
06/06/2022 07:46:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/06/2022 07:46:43 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 07:46:46 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=647
06/06/2022 07:46:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 07:46:50 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7596288515406162 on epoch=649
06/06/2022 07:46:52 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=652
06/06/2022 07:46:55 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/06/2022 07:46:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 07:47:00 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 07:47:03 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 07:47:04 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7748926868044514 on epoch=662
06/06/2022 07:47:07 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 07:47:09 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 07:47:12 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=669
06/06/2022 07:47:15 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 07:47:18 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/06/2022 07:47:19 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6541035541035541 on epoch=674
06/06/2022 07:47:21 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/06/2022 07:47:24 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 07:47:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 07:47:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 07:47:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 07:47:33 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7506930603741706 on epoch=687
06/06/2022 07:47:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 07:47:39 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 07:47:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/06/2022 07:47:44 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 07:47:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 07:47:48 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.6137662337662338 on epoch=699
06/06/2022 07:47:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 07:47:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/06/2022 07:47:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 07:47:59 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/06/2022 07:48:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/06/2022 07:48:02 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.722536986502527 on epoch=712
06/06/2022 07:48:05 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 07:48:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 07:48:11 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 07:48:13 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/06/2022 07:48:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 07:48:17 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7554290081849832 on epoch=724
06/06/2022 07:48:20 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 07:48:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 07:48:25 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 07:48:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 07:48:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/06/2022 07:48:32 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7389260497956149 on epoch=737
06/06/2022 07:48:35 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 07:48:38 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 07:48:40 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 07:48:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/06/2022 07:48:46 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/06/2022 07:48:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:48:47 - INFO - __main__ - Printing 3 examples
06/06/2022 07:48:47 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/06/2022 07:48:47 - INFO - __main__ - ['others']
06/06/2022 07:48:47 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/06/2022 07:48:47 - INFO - __main__ - ['others']
06/06/2022 07:48:47 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/06/2022 07:48:47 - INFO - __main__ - ['others']
06/06/2022 07:48:47 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:48:47 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6418808777429467 on epoch=749
06/06/2022 07:48:47 - INFO - __main__ - save last model!
06/06/2022 07:48:47 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:48:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 07:48:47 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 07:48:47 - INFO - __main__ - Printing 3 examples
06/06/2022 07:48:47 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 07:48:47 - INFO - __main__ - ['others']
06/06/2022 07:48:47 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 07:48:47 - INFO - __main__ - ['others']
06/06/2022 07:48:47 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 07:48:47 - INFO - __main__ - ['others']
06/06/2022 07:48:47 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:48:47 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 07:48:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:48:47 - INFO - __main__ - Printing 3 examples
06/06/2022 07:48:47 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/06/2022 07:48:47 - INFO - __main__ - ['others']
06/06/2022 07:48:47 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/06/2022 07:48:47 - INFO - __main__ - ['others']
06/06/2022 07:48:47 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/06/2022 07:48:47 - INFO - __main__ - ['others']
06/06/2022 07:48:47 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:48:47 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:48:47 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 07:48:49 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:48:56 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 07:49:06 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 07:49:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 07:49:07 - INFO - __main__ - Starting training!
06/06/2022 07:50:36 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_13_0.3_8_predictions.txt
06/06/2022 07:50:36 - INFO - __main__ - Classification-F1 on test data: 0.3248
06/06/2022 07:50:36 - INFO - __main__ - prefix=emo_16_13, lr=0.3, bsz=8, dev_performance=0.8249007936507936, test_performance=0.3248482976482282
06/06/2022 07:50:36 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.2, bsz=8 ...
06/06/2022 07:50:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:50:37 - INFO - __main__ - Printing 3 examples
06/06/2022 07:50:37 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/06/2022 07:50:37 - INFO - __main__ - ['others']
06/06/2022 07:50:37 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/06/2022 07:50:37 - INFO - __main__ - ['others']
06/06/2022 07:50:37 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/06/2022 07:50:37 - INFO - __main__ - ['others']
06/06/2022 07:50:37 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:50:37 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:50:37 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 07:50:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 07:50:37 - INFO - __main__ - Printing 3 examples
06/06/2022 07:50:37 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/06/2022 07:50:37 - INFO - __main__ - ['others']
06/06/2022 07:50:37 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/06/2022 07:50:37 - INFO - __main__ - ['others']
06/06/2022 07:50:37 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/06/2022 07:50:37 - INFO - __main__ - ['others']
06/06/2022 07:50:37 - INFO - __main__ - Tokenizing Input ...
06/06/2022 07:50:37 - INFO - __main__ - Tokenizing Output ...
06/06/2022 07:50:37 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 07:50:57 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 07:50:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 07:50:58 - INFO - __main__ - Starting training!
06/06/2022 07:51:01 - INFO - __main__ - Step 10 Global step 10 Train loss 4.06 on epoch=2
06/06/2022 07:51:04 - INFO - __main__ - Step 20 Global step 20 Train loss 2.91 on epoch=4
06/06/2022 07:51:07 - INFO - __main__ - Step 30 Global step 30 Train loss 2.07 on epoch=7
06/06/2022 07:51:09 - INFO - __main__ - Step 40 Global step 40 Train loss 1.53 on epoch=9
06/06/2022 07:51:12 - INFO - __main__ - Step 50 Global step 50 Train loss 1.26 on epoch=12
06/06/2022 07:51:13 - INFO - __main__ - Global step 50 Train loss 2.37 Classification-F1 0.09493670886075949 on epoch=12
06/06/2022 07:51:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09493670886075949 on epoch=12, global_step=50
06/06/2022 07:51:15 - INFO - __main__ - Step 60 Global step 60 Train loss 1.15 on epoch=14
06/06/2022 07:51:18 - INFO - __main__ - Step 70 Global step 70 Train loss 1.01 on epoch=17
06/06/2022 07:51:21 - INFO - __main__ - Step 80 Global step 80 Train loss 0.97 on epoch=19
06/06/2022 07:51:23 - INFO - __main__ - Step 90 Global step 90 Train loss 1.05 on epoch=22
06/06/2022 07:51:26 - INFO - __main__ - Step 100 Global step 100 Train loss 0.96 on epoch=24
06/06/2022 07:51:27 - INFO - __main__ - Global step 100 Train loss 1.03 Classification-F1 0.1856338028169014 on epoch=24
06/06/2022 07:51:27 - INFO - __main__ - Saving model with best Classification-F1: 0.09493670886075949 -> 0.1856338028169014 on epoch=24, global_step=100
06/06/2022 07:51:29 - INFO - __main__ - Step 110 Global step 110 Train loss 0.91 on epoch=27
06/06/2022 07:51:32 - INFO - __main__ - Step 120 Global step 120 Train loss 0.87 on epoch=29
06/06/2022 07:51:34 - INFO - __main__ - Step 130 Global step 130 Train loss 0.89 on epoch=32
06/06/2022 07:51:37 - INFO - __main__ - Step 140 Global step 140 Train loss 0.89 on epoch=34
06/06/2022 07:51:39 - INFO - __main__ - Step 150 Global step 150 Train loss 0.89 on epoch=37
06/06/2022 07:51:40 - INFO - __main__ - Global step 150 Train loss 0.89 Classification-F1 0.44791449968795505 on epoch=37
06/06/2022 07:51:40 - INFO - __main__ - Saving model with best Classification-F1: 0.1856338028169014 -> 0.44791449968795505 on epoch=37, global_step=150
06/06/2022 07:51:43 - INFO - __main__ - Step 160 Global step 160 Train loss 0.75 on epoch=39
06/06/2022 07:51:45 - INFO - __main__ - Step 170 Global step 170 Train loss 0.69 on epoch=42
06/06/2022 07:51:48 - INFO - __main__ - Step 180 Global step 180 Train loss 0.75 on epoch=44
06/06/2022 07:51:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.76 on epoch=47
06/06/2022 07:51:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.80 on epoch=49
06/06/2022 07:51:54 - INFO - __main__ - Global step 200 Train loss 0.75 Classification-F1 0.5702927103855896 on epoch=49
06/06/2022 07:51:54 - INFO - __main__ - Saving model with best Classification-F1: 0.44791449968795505 -> 0.5702927103855896 on epoch=49, global_step=200
06/06/2022 07:51:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.81 on epoch=52
06/06/2022 07:51:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.66 on epoch=54
06/06/2022 07:52:02 - INFO - __main__ - Step 230 Global step 230 Train loss 0.73 on epoch=57
06/06/2022 07:52:04 - INFO - __main__ - Step 240 Global step 240 Train loss 0.69 on epoch=59
06/06/2022 07:52:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=62
06/06/2022 07:52:08 - INFO - __main__ - Global step 250 Train loss 0.70 Classification-F1 0.5546296296296296 on epoch=62
06/06/2022 07:52:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.63 on epoch=64
06/06/2022 07:52:13 - INFO - __main__ - Step 270 Global step 270 Train loss 0.68 on epoch=67
06/06/2022 07:52:16 - INFO - __main__ - Step 280 Global step 280 Train loss 0.57 on epoch=69
06/06/2022 07:52:18 - INFO - __main__ - Step 290 Global step 290 Train loss 0.64 on epoch=72
06/06/2022 07:52:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.57 on epoch=74
06/06/2022 07:52:22 - INFO - __main__ - Global step 300 Train loss 0.62 Classification-F1 0.6679320003863615 on epoch=74
06/06/2022 07:52:22 - INFO - __main__ - Saving model with best Classification-F1: 0.5702927103855896 -> 0.6679320003863615 on epoch=74, global_step=300
06/06/2022 07:52:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.59 on epoch=77
06/06/2022 07:52:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.55 on epoch=79
06/06/2022 07:52:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.49 on epoch=82
06/06/2022 07:52:32 - INFO - __main__ - Step 340 Global step 340 Train loss 0.55 on epoch=84
06/06/2022 07:52:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.48 on epoch=87
06/06/2022 07:52:36 - INFO - __main__ - Global step 350 Train loss 0.53 Classification-F1 0.6867108995058179 on epoch=87
06/06/2022 07:52:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6679320003863615 -> 0.6867108995058179 on epoch=87, global_step=350
06/06/2022 07:52:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=89
06/06/2022 07:52:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.57 on epoch=92
06/06/2022 07:52:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.46 on epoch=94
06/06/2022 07:52:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.51 on epoch=97
06/06/2022 07:52:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.58 on epoch=99
06/06/2022 07:52:50 - INFO - __main__ - Global step 400 Train loss 0.53 Classification-F1 0.6208333333333333 on epoch=99
06/06/2022 07:52:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.36 on epoch=102
06/06/2022 07:52:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.39 on epoch=104
06/06/2022 07:52:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=107
06/06/2022 07:53:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.41 on epoch=109
06/06/2022 07:53:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.43 on epoch=112
06/06/2022 07:53:04 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.6808465862970868 on epoch=112
06/06/2022 07:53:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=114
06/06/2022 07:53:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.41 on epoch=117
06/06/2022 07:53:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.36 on epoch=119
06/06/2022 07:53:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.34 on epoch=122
06/06/2022 07:53:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.39 on epoch=124
06/06/2022 07:53:18 - INFO - __main__ - Global step 500 Train loss 0.36 Classification-F1 0.7299462520050755 on epoch=124
06/06/2022 07:53:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6867108995058179 -> 0.7299462520050755 on epoch=124, global_step=500
06/06/2022 07:53:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=127
06/06/2022 07:53:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=129
06/06/2022 07:53:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.29 on epoch=132
06/06/2022 07:53:29 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=134
06/06/2022 07:53:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=137
06/06/2022 07:53:32 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.7168393731826787 on epoch=137
06/06/2022 07:53:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=139
06/06/2022 07:53:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=142
06/06/2022 07:53:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=144
06/06/2022 07:53:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=147
06/06/2022 07:53:45 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=149
06/06/2022 07:53:46 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.7238275613275613 on epoch=149
06/06/2022 07:53:49 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=152
06/06/2022 07:53:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=154
06/06/2022 07:53:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=157
06/06/2022 07:53:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=159
06/06/2022 07:54:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.26 on epoch=162
06/06/2022 07:54:01 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.7314863445378151 on epoch=162
06/06/2022 07:54:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7299462520050755 -> 0.7314863445378151 on epoch=162, global_step=650
06/06/2022 07:54:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=164
06/06/2022 07:54:06 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=167
06/06/2022 07:54:09 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=169
06/06/2022 07:54:11 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=172
06/06/2022 07:54:14 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=174
06/06/2022 07:54:15 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.7103585339059224 on epoch=174
06/06/2022 07:54:17 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=177
06/06/2022 07:54:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=179
06/06/2022 07:54:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=182
06/06/2022 07:54:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=184
06/06/2022 07:54:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=187
06/06/2022 07:54:29 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.7397983870967743 on epoch=187
06/06/2022 07:54:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7314863445378151 -> 0.7397983870967743 on epoch=187, global_step=750
06/06/2022 07:54:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=189
06/06/2022 07:54:34 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=192
06/06/2022 07:54:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=194
06/06/2022 07:54:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=197
06/06/2022 07:54:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=199
06/06/2022 07:54:43 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.6924931543444868 on epoch=199
06/06/2022 07:54:46 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=202
06/06/2022 07:54:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=204
06/06/2022 07:54:51 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=207
06/06/2022 07:54:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=209
06/06/2022 07:54:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=212
06/06/2022 07:54:58 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.7452415264915265 on epoch=212
06/06/2022 07:54:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7397983870967743 -> 0.7452415264915265 on epoch=212, global_step=850
06/06/2022 07:55:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=214
06/06/2022 07:55:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=217
06/06/2022 07:55:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=219
06/06/2022 07:55:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
06/06/2022 07:55:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
06/06/2022 07:55:12 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.7400754147812971 on epoch=224
06/06/2022 07:55:15 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=227
06/06/2022 07:55:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=229
06/06/2022 07:55:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=232
06/06/2022 07:55:23 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=234
06/06/2022 07:55:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
06/06/2022 07:55:26 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.7443066801619433 on epoch=237
06/06/2022 07:55:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=239
06/06/2022 07:55:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=242
06/06/2022 07:55:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
06/06/2022 07:55:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=247
06/06/2022 07:55:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=249
06/06/2022 07:55:41 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.6818376068376067 on epoch=249
06/06/2022 07:55:43 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=252
06/06/2022 07:55:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=254
06/06/2022 07:55:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=257
06/06/2022 07:55:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=259
06/06/2022 07:55:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
06/06/2022 07:55:55 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.7291510025062657 on epoch=262
06/06/2022 07:55:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=264
06/06/2022 07:56:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
06/06/2022 07:56:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=269
06/06/2022 07:56:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/06/2022 07:56:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/06/2022 07:56:09 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7438317384370016 on epoch=274
06/06/2022 07:56:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/06/2022 07:56:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=279
06/06/2022 07:56:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/06/2022 07:56:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/06/2022 07:56:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=287
06/06/2022 07:56:24 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.6897450110864745 on epoch=287
06/06/2022 07:56:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=289
06/06/2022 07:56:29 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/06/2022 07:56:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=294
06/06/2022 07:56:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=297
06/06/2022 07:56:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=299
06/06/2022 07:56:38 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.6901121794871795 on epoch=299
06/06/2022 07:56:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=302
06/06/2022 07:56:44 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=304
06/06/2022 07:56:46 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/06/2022 07:56:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
06/06/2022 07:56:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/06/2022 07:56:53 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7234841628959277 on epoch=312
06/06/2022 07:56:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
06/06/2022 07:56:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/06/2022 07:57:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
06/06/2022 07:57:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/06/2022 07:57:06 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=324
06/06/2022 07:57:07 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7036490683229812 on epoch=324
06/06/2022 07:57:10 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=327
06/06/2022 07:57:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/06/2022 07:57:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=332
06/06/2022 07:57:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=334
06/06/2022 07:57:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/06/2022 07:57:22 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.778838808250573 on epoch=337
06/06/2022 07:57:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7452415264915265 -> 0.778838808250573 on epoch=337, global_step=1350
06/06/2022 07:57:24 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
06/06/2022 07:57:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/06/2022 07:57:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/06/2022 07:57:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=347
06/06/2022 07:57:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=349
06/06/2022 07:57:36 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7010716069110158 on epoch=349
06/06/2022 07:57:39 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=352
06/06/2022 07:57:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=354
06/06/2022 07:57:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/06/2022 07:57:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/06/2022 07:57:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/06/2022 07:57:51 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7278656597774245 on epoch=362
06/06/2022 07:57:53 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/06/2022 07:57:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/06/2022 07:57:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/06/2022 07:58:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/06/2022 07:58:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/06/2022 07:58:06 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6996462639109698 on epoch=374
06/06/2022 07:58:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=377
06/06/2022 07:58:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/06/2022 07:58:14 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/06/2022 07:58:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/06/2022 07:58:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/06/2022 07:58:20 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.750172706516012 on epoch=387
06/06/2022 07:58:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/06/2022 07:58:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=392
06/06/2022 07:58:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/06/2022 07:58:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/06/2022 07:58:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/06/2022 07:58:35 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.728870858688303 on epoch=399
06/06/2022 07:58:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/06/2022 07:58:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/06/2022 07:58:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/06/2022 07:58:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/06/2022 07:58:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=412
06/06/2022 07:58:49 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7315496814135654 on epoch=412
06/06/2022 07:58:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/06/2022 07:58:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/06/2022 07:58:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=419
06/06/2022 07:59:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/06/2022 07:59:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/06/2022 07:59:04 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7330633484867356 on epoch=424
06/06/2022 07:59:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/06/2022 07:59:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/06/2022 07:59:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/06/2022 07:59:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/06/2022 07:59:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/06/2022 07:59:18 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7615914786967418 on epoch=437
06/06/2022 07:59:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=439
06/06/2022 07:59:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/06/2022 07:59:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=444
06/06/2022 07:59:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/06/2022 07:59:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/06/2022 07:59:33 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7467411044997252 on epoch=449
06/06/2022 07:59:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/06/2022 07:59:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/06/2022 07:59:40 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/06/2022 07:59:43 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/06/2022 07:59:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/06/2022 07:59:47 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.762199032062916 on epoch=462
06/06/2022 07:59:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/06/2022 07:59:52 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/06/2022 07:59:55 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=469
06/06/2022 07:59:58 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=472
06/06/2022 08:00:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/06/2022 08:00:02 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7630678708264915 on epoch=474
06/06/2022 08:00:04 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/06/2022 08:00:07 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=479
06/06/2022 08:00:10 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/06/2022 08:00:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/06/2022 08:00:15 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/06/2022 08:00:16 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7669998892468303 on epoch=487
06/06/2022 08:00:19 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/06/2022 08:00:22 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/06/2022 08:00:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/06/2022 08:00:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.13 on epoch=497
06/06/2022 08:00:30 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/06/2022 08:00:31 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7480119415603287 on epoch=499
06/06/2022 08:00:34 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/06/2022 08:00:36 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/06/2022 08:00:39 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=507
06/06/2022 08:00:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=509
06/06/2022 08:00:44 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/06/2022 08:00:45 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7629305776364599 on epoch=512
06/06/2022 08:00:48 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/06/2022 08:00:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/06/2022 08:00:53 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/06/2022 08:00:56 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/06/2022 08:00:59 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/06/2022 08:01:00 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7320859320859321 on epoch=524
06/06/2022 08:01:02 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/06/2022 08:01:05 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 08:01:08 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=532
06/06/2022 08:01:10 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/06/2022 08:01:13 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/06/2022 08:01:14 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7002491668238697 on epoch=537
06/06/2022 08:01:17 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/06/2022 08:01:20 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/06/2022 08:01:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/06/2022 08:01:25 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/06/2022 08:01:28 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/06/2022 08:01:29 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7794343044343045 on epoch=549
06/06/2022 08:01:29 - INFO - __main__ - Saving model with best Classification-F1: 0.778838808250573 -> 0.7794343044343045 on epoch=549, global_step=2200
06/06/2022 08:01:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 08:01:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/06/2022 08:01:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/06/2022 08:01:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/06/2022 08:01:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/06/2022 08:01:43 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7471672539983735 on epoch=562
06/06/2022 08:01:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/06/2022 08:01:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/06/2022 08:01:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=569
06/06/2022 08:01:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/06/2022 08:01:56 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=574
06/06/2022 08:01:58 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7166965352449224 on epoch=574
06/06/2022 08:02:00 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.13 on epoch=577
06/06/2022 08:02:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/06/2022 08:02:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/06/2022 08:02:08 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/06/2022 08:02:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/06/2022 08:02:12 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7287031799899447 on epoch=587
06/06/2022 08:02:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=589
06/06/2022 08:02:17 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/06/2022 08:02:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 08:02:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/06/2022 08:02:25 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 08:02:26 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7155237854251013 on epoch=599
06/06/2022 08:02:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/06/2022 08:02:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 08:02:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/06/2022 08:02:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 08:02:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/06/2022 08:02:40 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7430132387028938 on epoch=612
06/06/2022 08:02:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/06/2022 08:02:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=617
06/06/2022 08:02:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 08:02:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=622
06/06/2022 08:02:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/06/2022 08:02:55 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7296150696150697 on epoch=624
06/06/2022 08:02:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/06/2022 08:03:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/06/2022 08:03:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/06/2022 08:03:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/06/2022 08:03:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 08:03:09 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7451753372806004 on epoch=637
06/06/2022 08:03:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/06/2022 08:03:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/06/2022 08:03:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 08:03:20 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 08:03:22 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 08:03:24 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7497519841269842 on epoch=649
06/06/2022 08:03:26 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/06/2022 08:03:29 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 08:03:32 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=657
06/06/2022 08:03:34 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 08:03:37 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 08:03:38 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7144650113400113 on epoch=662
06/06/2022 08:03:41 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=664
06/06/2022 08:03:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 08:03:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/06/2022 08:03:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 08:03:51 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 08:03:53 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.733128078817734 on epoch=674
06/06/2022 08:03:55 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.13 on epoch=677
06/06/2022 08:03:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 08:04:00 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 08:04:03 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/06/2022 08:04:06 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 08:04:07 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7293785935426803 on epoch=687
06/06/2022 08:04:09 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 08:04:12 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 08:04:14 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=694
06/06/2022 08:04:17 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 08:04:20 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 08:04:21 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7372557622557622 on epoch=699
06/06/2022 08:04:24 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 08:04:26 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/06/2022 08:04:29 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/06/2022 08:04:31 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/06/2022 08:04:34 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 08:04:35 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7300052635536507 on epoch=712
06/06/2022 08:04:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/06/2022 08:04:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 08:04:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/06/2022 08:04:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/06/2022 08:04:48 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 08:04:49 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7673850574712644 on epoch=724
06/06/2022 08:04:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
06/06/2022 08:04:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 08:04:57 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 08:05:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 08:05:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 08:05:04 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7297077922077922 on epoch=737
06/06/2022 08:05:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 08:05:09 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/06/2022 08:05:12 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 08:05:14 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/06/2022 08:05:17 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 08:05:18 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:05:18 - INFO - __main__ - Printing 3 examples
06/06/2022 08:05:18 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/06/2022 08:05:18 - INFO - __main__ - ['sad']
06/06/2022 08:05:18 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/06/2022 08:05:18 - INFO - __main__ - ['sad']
06/06/2022 08:05:18 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/06/2022 08:05:18 - INFO - __main__ - ['sad']
06/06/2022 08:05:18 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:05:18 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7127504848093084 on epoch=749
06/06/2022 08:05:18 - INFO - __main__ - save last model!
06/06/2022 08:05:18 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:05:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 08:05:18 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 08:05:18 - INFO - __main__ - Printing 3 examples
06/06/2022 08:05:18 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 08:05:18 - INFO - __main__ - ['others']
06/06/2022 08:05:18 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 08:05:18 - INFO - __main__ - ['others']
06/06/2022 08:05:18 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 08:05:18 - INFO - __main__ - ['others']
06/06/2022 08:05:18 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:05:18 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 08:05:18 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:05:18 - INFO - __main__ - Printing 3 examples
06/06/2022 08:05:18 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/06/2022 08:05:18 - INFO - __main__ - ['sad']
06/06/2022 08:05:18 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/06/2022 08:05:18 - INFO - __main__ - ['sad']
06/06/2022 08:05:18 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/06/2022 08:05:18 - INFO - __main__ - ['sad']
06/06/2022 08:05:18 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:05:18 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:05:18 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 08:05:21 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:05:27 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 08:05:37 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 08:05:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 08:05:37 - INFO - __main__ - Starting training!
06/06/2022 08:07:05 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_13_0.2_8_predictions.txt
06/06/2022 08:07:05 - INFO - __main__ - Classification-F1 on test data: 0.3012
06/06/2022 08:07:06 - INFO - __main__ - prefix=emo_16_13, lr=0.2, bsz=8, dev_performance=0.7794343044343045, test_performance=0.30121473224422934
06/06/2022 08:07:06 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.5, bsz=8 ...
06/06/2022 08:07:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:07:06 - INFO - __main__ - Printing 3 examples
06/06/2022 08:07:06 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/06/2022 08:07:06 - INFO - __main__ - ['sad']
06/06/2022 08:07:06 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/06/2022 08:07:06 - INFO - __main__ - ['sad']
06/06/2022 08:07:06 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/06/2022 08:07:06 - INFO - __main__ - ['sad']
06/06/2022 08:07:06 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:07:06 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:07:07 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 08:07:07 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:07:07 - INFO - __main__ - Printing 3 examples
06/06/2022 08:07:07 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/06/2022 08:07:07 - INFO - __main__ - ['sad']
06/06/2022 08:07:07 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/06/2022 08:07:07 - INFO - __main__ - ['sad']
06/06/2022 08:07:07 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/06/2022 08:07:07 - INFO - __main__ - ['sad']
06/06/2022 08:07:07 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:07:07 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:07:07 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 08:07:22 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 08:07:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 08:07:23 - INFO - __main__ - Starting training!
06/06/2022 08:07:26 - INFO - __main__ - Step 10 Global step 10 Train loss 3.51 on epoch=2
06/06/2022 08:07:29 - INFO - __main__ - Step 20 Global step 20 Train loss 1.79 on epoch=4
06/06/2022 08:07:31 - INFO - __main__ - Step 30 Global step 30 Train loss 1.24 on epoch=7
06/06/2022 08:07:34 - INFO - __main__ - Step 40 Global step 40 Train loss 1.11 on epoch=9
06/06/2022 08:07:37 - INFO - __main__ - Step 50 Global step 50 Train loss 1.08 on epoch=12
06/06/2022 08:07:37 - INFO - __main__ - Global step 50 Train loss 1.75 Classification-F1 0.26222062004325886 on epoch=12
06/06/2022 08:07:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.26222062004325886 on epoch=12, global_step=50
06/06/2022 08:07:40 - INFO - __main__ - Step 60 Global step 60 Train loss 0.95 on epoch=14
06/06/2022 08:07:43 - INFO - __main__ - Step 70 Global step 70 Train loss 0.81 on epoch=17
06/06/2022 08:07:45 - INFO - __main__ - Step 80 Global step 80 Train loss 0.73 on epoch=19
06/06/2022 08:07:48 - INFO - __main__ - Step 90 Global step 90 Train loss 0.66 on epoch=22
06/06/2022 08:07:50 - INFO - __main__ - Step 100 Global step 100 Train loss 0.65 on epoch=24
06/06/2022 08:07:51 - INFO - __main__ - Global step 100 Train loss 0.76 Classification-F1 0.43270833333333336 on epoch=24
06/06/2022 08:07:51 - INFO - __main__ - Saving model with best Classification-F1: 0.26222062004325886 -> 0.43270833333333336 on epoch=24, global_step=100
06/06/2022 08:07:54 - INFO - __main__ - Step 110 Global step 110 Train loss 0.69 on epoch=27
06/06/2022 08:07:56 - INFO - __main__ - Step 120 Global step 120 Train loss 0.63 on epoch=29
06/06/2022 08:07:59 - INFO - __main__ - Step 130 Global step 130 Train loss 0.55 on epoch=32
06/06/2022 08:08:01 - INFO - __main__ - Step 140 Global step 140 Train loss 0.51 on epoch=34
06/06/2022 08:08:04 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=37
06/06/2022 08:08:05 - INFO - __main__ - Global step 150 Train loss 0.59 Classification-F1 0.6748584244463135 on epoch=37
06/06/2022 08:08:05 - INFO - __main__ - Saving model with best Classification-F1: 0.43270833333333336 -> 0.6748584244463135 on epoch=37, global_step=150
06/06/2022 08:08:07 - INFO - __main__ - Step 160 Global step 160 Train loss 0.52 on epoch=39
06/06/2022 08:08:10 - INFO - __main__ - Step 170 Global step 170 Train loss 0.47 on epoch=42
06/06/2022 08:08:12 - INFO - __main__ - Step 180 Global step 180 Train loss 0.48 on epoch=44
06/06/2022 08:08:15 - INFO - __main__ - Step 190 Global step 190 Train loss 0.40 on epoch=47
06/06/2022 08:08:17 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=49
06/06/2022 08:08:18 - INFO - __main__ - Global step 200 Train loss 0.46 Classification-F1 0.6109125690187382 on epoch=49
06/06/2022 08:08:21 - INFO - __main__ - Step 210 Global step 210 Train loss 0.42 on epoch=52
06/06/2022 08:08:23 - INFO - __main__ - Step 220 Global step 220 Train loss 0.41 on epoch=54
06/06/2022 08:08:26 - INFO - __main__ - Step 230 Global step 230 Train loss 0.35 on epoch=57
06/06/2022 08:08:29 - INFO - __main__ - Step 240 Global step 240 Train loss 0.32 on epoch=59
06/06/2022 08:08:31 - INFO - __main__ - Step 250 Global step 250 Train loss 0.32 on epoch=62
06/06/2022 08:08:32 - INFO - __main__ - Global step 250 Train loss 0.36 Classification-F1 0.6765359480538476 on epoch=62
06/06/2022 08:08:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6748584244463135 -> 0.6765359480538476 on epoch=62, global_step=250
06/06/2022 08:08:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.27 on epoch=64
06/06/2022 08:08:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=67
06/06/2022 08:08:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=69
06/06/2022 08:08:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.21 on epoch=72
06/06/2022 08:08:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=74
06/06/2022 08:08:46 - INFO - __main__ - Global step 300 Train loss 0.25 Classification-F1 0.7252781133595088 on epoch=74
06/06/2022 08:08:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6765359480538476 -> 0.7252781133595088 on epoch=74, global_step=300
06/06/2022 08:08:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.20 on epoch=77
06/06/2022 08:08:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.16 on epoch=79
06/06/2022 08:08:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=82
06/06/2022 08:08:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.15 on epoch=84
06/06/2022 08:08:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.08 on epoch=87
06/06/2022 08:09:00 - INFO - __main__ - Global step 350 Train loss 0.17 Classification-F1 0.7243453302373581 on epoch=87
06/06/2022 08:09:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.12 on epoch=89
06/06/2022 08:09:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.12 on epoch=92
06/06/2022 08:09:08 - INFO - __main__ - Step 380 Global step 380 Train loss 0.11 on epoch=94
06/06/2022 08:09:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.12 on epoch=97
06/06/2022 08:09:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.07 on epoch=99
06/06/2022 08:09:14 - INFO - __main__ - Global step 400 Train loss 0.11 Classification-F1 0.7233585858585859 on epoch=99
06/06/2022 08:09:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.08 on epoch=102
06/06/2022 08:09:19 - INFO - __main__ - Step 420 Global step 420 Train loss 0.14 on epoch=104
06/06/2022 08:09:22 - INFO - __main__ - Step 430 Global step 430 Train loss 0.09 on epoch=107
06/06/2022 08:09:24 - INFO - __main__ - Step 440 Global step 440 Train loss 0.04 on epoch=109
06/06/2022 08:09:27 - INFO - __main__ - Step 450 Global step 450 Train loss 0.08 on epoch=112
06/06/2022 08:09:28 - INFO - __main__ - Global step 450 Train loss 0.09 Classification-F1 0.724054730152291 on epoch=112
06/06/2022 08:09:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.07 on epoch=114
06/06/2022 08:09:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.15 on epoch=117
06/06/2022 08:09:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.07 on epoch=119
06/06/2022 08:09:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.07 on epoch=122
06/06/2022 08:09:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.06 on epoch=124
06/06/2022 08:09:41 - INFO - __main__ - Global step 500 Train loss 0.08 Classification-F1 0.6903266999019287 on epoch=124
06/06/2022 08:09:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=127
06/06/2022 08:09:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.05 on epoch=129
06/06/2022 08:09:49 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=132
06/06/2022 08:09:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.09 on epoch=134
06/06/2022 08:09:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.10 on epoch=137
06/06/2022 08:09:55 - INFO - __main__ - Global step 550 Train loss 0.08 Classification-F1 0.6954378342245989 on epoch=137
06/06/2022 08:09:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.07 on epoch=139
06/06/2022 08:10:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=142
06/06/2022 08:10:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=144
06/06/2022 08:10:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.05 on epoch=147
06/06/2022 08:10:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=149
06/06/2022 08:10:09 - INFO - __main__ - Global step 600 Train loss 0.08 Classification-F1 0.7426219512195121 on epoch=149
06/06/2022 08:10:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7252781133595088 -> 0.7426219512195121 on epoch=149, global_step=600
06/06/2022 08:10:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=152
06/06/2022 08:10:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=154
06/06/2022 08:10:16 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=157
06/06/2022 08:10:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=159
06/06/2022 08:10:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=162
06/06/2022 08:10:22 - INFO - __main__ - Global step 650 Train loss 0.05 Classification-F1 0.7238095238095238 on epoch=162
06/06/2022 08:10:25 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=164
06/06/2022 08:10:27 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=167
06/06/2022 08:10:30 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=169
06/06/2022 08:10:32 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=172
06/06/2022 08:10:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=174
06/06/2022 08:10:36 - INFO - __main__ - Global step 700 Train loss 0.05 Classification-F1 0.6871564393303523 on epoch=174
06/06/2022 08:10:39 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=177
06/06/2022 08:10:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=179
06/06/2022 08:10:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=182
06/06/2022 08:10:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=184
06/06/2022 08:10:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=187
06/06/2022 08:10:50 - INFO - __main__ - Global step 750 Train loss 0.02 Classification-F1 0.725944170771757 on epoch=187
06/06/2022 08:10:52 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=189
06/06/2022 08:10:55 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=192
06/06/2022 08:10:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=194
06/06/2022 08:11:00 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=197
06/06/2022 08:11:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=199
06/06/2022 08:11:03 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.7375366568914956 on epoch=199
06/06/2022 08:11:06 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=202
06/06/2022 08:11:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/06/2022 08:11:11 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=207
06/06/2022 08:11:14 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/06/2022 08:11:16 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=212
06/06/2022 08:11:17 - INFO - __main__ - Global step 850 Train loss 0.02 Classification-F1 0.7106981981981981 on epoch=212
06/06/2022 08:11:20 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=214
06/06/2022 08:11:22 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=217
06/06/2022 08:11:25 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=219
06/06/2022 08:11:27 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=222
06/06/2022 08:11:30 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=224
06/06/2022 08:11:31 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7588666085440279 on epoch=224
06/06/2022 08:11:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7426219512195121 -> 0.7588666085440279 on epoch=224, global_step=900
06/06/2022 08:11:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/06/2022 08:11:36 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=229
06/06/2022 08:11:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=232
06/06/2022 08:11:41 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/06/2022 08:11:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/06/2022 08:11:45 - INFO - __main__ - Global step 950 Train loss 0.01 Classification-F1 0.7287028657616893 on epoch=237
06/06/2022 08:11:48 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=239
06/06/2022 08:11:50 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=242
06/06/2022 08:11:53 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/06/2022 08:11:55 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=247
06/06/2022 08:11:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/06/2022 08:11:59 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.7262763966853782 on epoch=249
06/06/2022 08:12:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/06/2022 08:12:04 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/06/2022 08:12:07 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/06/2022 08:12:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=259
06/06/2022 08:12:12 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=262
06/06/2022 08:12:13 - INFO - __main__ - Global step 1050 Train loss 0.01 Classification-F1 0.7589881999133471 on epoch=262
06/06/2022 08:12:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7588666085440279 -> 0.7589881999133471 on epoch=262, global_step=1050
06/06/2022 08:12:16 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=264
06/06/2022 08:12:18 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/06/2022 08:12:21 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/06/2022 08:12:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/06/2022 08:12:26 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/06/2022 08:12:27 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.7781870347394542 on epoch=274
06/06/2022 08:12:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7589881999133471 -> 0.7781870347394542 on epoch=274, global_step=1100
06/06/2022 08:12:29 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=277
06/06/2022 08:12:32 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/06/2022 08:12:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/06/2022 08:12:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=284
06/06/2022 08:12:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/06/2022 08:12:41 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7589548086322281 on epoch=287
06/06/2022 08:12:43 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/06/2022 08:12:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/06/2022 08:12:48 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/06/2022 08:12:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=297
06/06/2022 08:12:53 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/06/2022 08:12:55 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.7448727422003284 on epoch=299
06/06/2022 08:12:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/06/2022 08:13:00 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/06/2022 08:13:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=307
06/06/2022 08:13:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/06/2022 08:13:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/06/2022 08:13:08 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7100439882697948 on epoch=312
06/06/2022 08:13:11 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/06/2022 08:13:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/06/2022 08:13:16 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/06/2022 08:13:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=322
06/06/2022 08:13:21 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/06/2022 08:13:23 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.7435477609697456 on epoch=324
06/06/2022 08:13:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/06/2022 08:13:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/06/2022 08:13:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/06/2022 08:13:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/06/2022 08:13:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/06/2022 08:13:37 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7446774193548388 on epoch=337
06/06/2022 08:13:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/06/2022 08:13:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=342
06/06/2022 08:13:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/06/2022 08:13:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/06/2022 08:13:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/06/2022 08:13:51 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7504003040693537 on epoch=349
06/06/2022 08:13:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/06/2022 08:13:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/06/2022 08:13:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/06/2022 08:14:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/06/2022 08:14:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/06/2022 08:14:05 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7338543809132045 on epoch=362
06/06/2022 08:14:08 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/06/2022 08:14:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/06/2022 08:14:13 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/06/2022 08:14:16 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/06/2022 08:14:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/06/2022 08:14:20 - INFO - __main__ - Global step 1500 Train loss 0.00 Classification-F1 0.7204545454545455 on epoch=374
06/06/2022 08:14:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/06/2022 08:14:25 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/06/2022 08:14:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/06/2022 08:14:30 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/06/2022 08:14:33 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/06/2022 08:14:34 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.6871212121212121 on epoch=387
06/06/2022 08:14:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/06/2022 08:14:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=392
06/06/2022 08:14:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
06/06/2022 08:14:44 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/06/2022 08:14:47 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/06/2022 08:14:48 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7959935897435898 on epoch=399
06/06/2022 08:14:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7781870347394542 -> 0.7959935897435898 on epoch=399, global_step=1600
06/06/2022 08:14:51 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/06/2022 08:14:53 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/06/2022 08:14:56 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/06/2022 08:14:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/06/2022 08:15:01 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/06/2022 08:15:02 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7898076923076923 on epoch=412
06/06/2022 08:15:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/06/2022 08:15:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/06/2022 08:15:10 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/06/2022 08:15:13 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/06/2022 08:15:15 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/06/2022 08:15:17 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.7571875819564647 on epoch=424
06/06/2022 08:15:19 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=427
06/06/2022 08:15:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/06/2022 08:15:24 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/06/2022 08:15:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/06/2022 08:15:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/06/2022 08:15:31 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7889314516129032 on epoch=437
06/06/2022 08:15:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/06/2022 08:15:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/06/2022 08:15:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/06/2022 08:15:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/06/2022 08:15:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/06/2022 08:15:45 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.7412126140778893 on epoch=449
06/06/2022 08:15:48 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/06/2022 08:15:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/06/2022 08:15:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/06/2022 08:15:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/06/2022 08:15:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/06/2022 08:16:00 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.7940053259093385 on epoch=462
06/06/2022 08:16:03 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/06/2022 08:16:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/06/2022 08:16:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=469
06/06/2022 08:16:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/06/2022 08:16:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/06/2022 08:16:15 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8085607940446651 on epoch=474
06/06/2022 08:16:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7959935897435898 -> 0.8085607940446651 on epoch=474, global_step=1900
06/06/2022 08:16:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/06/2022 08:16:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/06/2022 08:16:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/06/2022 08:16:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/06/2022 08:16:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/06/2022 08:16:29 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.817817599067599 on epoch=487
06/06/2022 08:16:29 - INFO - __main__ - Saving model with best Classification-F1: 0.8085607940446651 -> 0.817817599067599 on epoch=487, global_step=1950
06/06/2022 08:16:32 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/06/2022 08:16:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/06/2022 08:16:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/06/2022 08:16:40 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/06/2022 08:16:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/06/2022 08:16:44 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.8136404697380306 on epoch=499
06/06/2022 08:16:46 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/06/2022 08:16:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/06/2022 08:16:51 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/06/2022 08:16:54 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/06/2022 08:16:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/06/2022 08:16:58 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.7782204260205732 on epoch=512
06/06/2022 08:17:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/06/2022 08:17:03 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/06/2022 08:17:06 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/06/2022 08:17:09 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/06/2022 08:17:11 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/06/2022 08:17:12 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7669852338969986 on epoch=524
06/06/2022 08:17:15 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/06/2022 08:17:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 08:17:20 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/06/2022 08:17:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/06/2022 08:17:26 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/06/2022 08:17:27 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7889314516129032 on epoch=537
06/06/2022 08:17:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/06/2022 08:17:32 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 08:17:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/06/2022 08:17:37 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/06/2022 08:17:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/06/2022 08:17:42 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7940053259093385 on epoch=549
06/06/2022 08:17:44 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 08:17:47 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/06/2022 08:17:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/06/2022 08:17:53 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/06/2022 08:17:55 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/06/2022 08:17:57 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7889314516129032 on epoch=562
06/06/2022 08:17:59 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/06/2022 08:18:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=567
06/06/2022 08:18:05 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/06/2022 08:18:07 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/06/2022 08:18:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 08:18:11 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7749136178861789 on epoch=574
06/06/2022 08:18:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 08:18:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 08:18:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/06/2022 08:18:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/06/2022 08:18:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/06/2022 08:18:26 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7802197802197801 on epoch=587
06/06/2022 08:18:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/06/2022 08:18:31 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/06/2022 08:18:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 08:18:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/06/2022 08:18:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 08:18:40 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7741063237837432 on epoch=599
06/06/2022 08:18:43 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 08:18:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/06/2022 08:18:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 08:18:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 08:18:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 08:18:54 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7606912442396314 on epoch=612
06/06/2022 08:18:57 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 08:19:00 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 08:19:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 08:19:06 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/06/2022 08:19:08 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 08:19:09 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7596212121212121 on epoch=624
06/06/2022 08:19:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/06/2022 08:19:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/06/2022 08:19:17 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/06/2022 08:19:20 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/06/2022 08:19:23 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 08:19:24 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7601536098310292 on epoch=637
06/06/2022 08:19:27 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 08:19:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/06/2022 08:19:32 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 08:19:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 08:19:38 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 08:19:39 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7545916481892092 on epoch=649
06/06/2022 08:19:41 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/06/2022 08:19:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 08:19:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 08:19:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 08:19:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 08:19:53 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7337363785639648 on epoch=662
06/06/2022 08:19:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 08:19:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 08:20:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 08:20:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 08:20:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 08:20:07 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7606912442396314 on epoch=674
06/06/2022 08:20:10 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/06/2022 08:20:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=679
06/06/2022 08:20:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 08:20:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 08:20:20 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 08:20:22 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7596212121212121 on epoch=687
06/06/2022 08:20:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 08:20:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 08:20:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/06/2022 08:20:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 08:20:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 08:20:36 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7654452737852899 on epoch=699
06/06/2022 08:20:39 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 08:20:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 08:20:44 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/06/2022 08:20:47 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/06/2022 08:20:49 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 08:20:51 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6910245161510153 on epoch=712
06/06/2022 08:20:53 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 08:20:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 08:20:58 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 08:21:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/06/2022 08:21:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 08:21:05 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7652294254882401 on epoch=724
06/06/2022 08:21:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 08:21:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 08:21:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 08:21:15 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 08:21:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 08:21:19 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7602789046653144 on epoch=737
06/06/2022 08:21:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 08:21:25 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 08:21:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 08:21:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/06/2022 08:21:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 08:21:34 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7884274193548387 on epoch=749
06/06/2022 08:21:34 - INFO - __main__ - save last model!
06/06/2022 08:21:34 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 08:21:34 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 08:21:34 - INFO - __main__ - Printing 3 examples
06/06/2022 08:21:34 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 08:21:34 - INFO - __main__ - ['others']
06/06/2022 08:21:34 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 08:21:34 - INFO - __main__ - ['others']
06/06/2022 08:21:34 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 08:21:34 - INFO - __main__ - ['others']
06/06/2022 08:21:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:21:34 - INFO - __main__ - Printing 3 examples
06/06/2022 08:21:34 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/06/2022 08:21:34 - INFO - __main__ - ['sad']
06/06/2022 08:21:34 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/06/2022 08:21:34 - INFO - __main__ - ['sad']
06/06/2022 08:21:34 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/06/2022 08:21:34 - INFO - __main__ - ['sad']
06/06/2022 08:21:34 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:21:34 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:21:34 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:21:34 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 08:21:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:21:34 - INFO - __main__ - Printing 3 examples
06/06/2022 08:21:34 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/06/2022 08:21:34 - INFO - __main__ - ['sad']
06/06/2022 08:21:34 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/06/2022 08:21:34 - INFO - __main__ - ['sad']
06/06/2022 08:21:34 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/06/2022 08:21:34 - INFO - __main__ - ['sad']
06/06/2022 08:21:34 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:21:34 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:21:34 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 08:21:36 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:21:42 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 08:21:53 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 08:21:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 08:21:54 - INFO - __main__ - Starting training!
06/06/2022 08:23:18 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_21_0.5_8_predictions.txt
06/06/2022 08:23:18 - INFO - __main__ - Classification-F1 on test data: 0.1678
06/06/2022 08:23:18 - INFO - __main__ - prefix=emo_16_21, lr=0.5, bsz=8, dev_performance=0.817817599067599, test_performance=0.16780963961542011
06/06/2022 08:23:18 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.4, bsz=8 ...
06/06/2022 08:23:19 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:23:19 - INFO - __main__ - Printing 3 examples
06/06/2022 08:23:19 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/06/2022 08:23:19 - INFO - __main__ - ['sad']
06/06/2022 08:23:19 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/06/2022 08:23:19 - INFO - __main__ - ['sad']
06/06/2022 08:23:19 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/06/2022 08:23:19 - INFO - __main__ - ['sad']
06/06/2022 08:23:19 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:23:19 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:23:20 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 08:23:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:23:20 - INFO - __main__ - Printing 3 examples
06/06/2022 08:23:20 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/06/2022 08:23:20 - INFO - __main__ - ['sad']
06/06/2022 08:23:20 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/06/2022 08:23:20 - INFO - __main__ - ['sad']
06/06/2022 08:23:20 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/06/2022 08:23:20 - INFO - __main__ - ['sad']
06/06/2022 08:23:20 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:23:20 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:23:20 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 08:23:35 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 08:23:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 08:23:36 - INFO - __main__ - Starting training!
06/06/2022 08:23:39 - INFO - __main__ - Step 10 Global step 10 Train loss 3.75 on epoch=2
06/06/2022 08:23:42 - INFO - __main__ - Step 20 Global step 20 Train loss 2.35 on epoch=4
06/06/2022 08:23:45 - INFO - __main__ - Step 30 Global step 30 Train loss 1.34 on epoch=7
06/06/2022 08:23:47 - INFO - __main__ - Step 40 Global step 40 Train loss 1.02 on epoch=9
06/06/2022 08:23:50 - INFO - __main__ - Step 50 Global step 50 Train loss 0.88 on epoch=12
06/06/2022 08:23:51 - INFO - __main__ - Global step 50 Train loss 1.87 Classification-F1 0.18284347231715653 on epoch=12
06/06/2022 08:23:51 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.18284347231715653 on epoch=12, global_step=50
06/06/2022 08:23:54 - INFO - __main__ - Step 60 Global step 60 Train loss 1.02 on epoch=14
06/06/2022 08:23:56 - INFO - __main__ - Step 70 Global step 70 Train loss 0.97 on epoch=17
06/06/2022 08:23:59 - INFO - __main__ - Step 80 Global step 80 Train loss 0.91 on epoch=19
06/06/2022 08:24:02 - INFO - __main__ - Step 90 Global step 90 Train loss 0.86 on epoch=22
06/06/2022 08:24:04 - INFO - __main__ - Step 100 Global step 100 Train loss 0.83 on epoch=24
06/06/2022 08:24:05 - INFO - __main__ - Global step 100 Train loss 0.92 Classification-F1 0.5276742993848257 on epoch=24
06/06/2022 08:24:05 - INFO - __main__ - Saving model with best Classification-F1: 0.18284347231715653 -> 0.5276742993848257 on epoch=24, global_step=100
06/06/2022 08:24:08 - INFO - __main__ - Step 110 Global step 110 Train loss 0.91 on epoch=27
06/06/2022 08:24:11 - INFO - __main__ - Step 120 Global step 120 Train loss 0.82 on epoch=29
06/06/2022 08:24:13 - INFO - __main__ - Step 130 Global step 130 Train loss 0.87 on epoch=32
06/06/2022 08:24:16 - INFO - __main__ - Step 140 Global step 140 Train loss 0.79 on epoch=34
06/06/2022 08:24:19 - INFO - __main__ - Step 150 Global step 150 Train loss 0.82 on epoch=37
06/06/2022 08:24:20 - INFO - __main__ - Global step 150 Train loss 0.84 Classification-F1 0.5790839874180557 on epoch=37
06/06/2022 08:24:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5276742993848257 -> 0.5790839874180557 on epoch=37, global_step=150
06/06/2022 08:24:22 - INFO - __main__ - Step 160 Global step 160 Train loss 0.66 on epoch=39
06/06/2022 08:24:25 - INFO - __main__ - Step 170 Global step 170 Train loss 0.54 on epoch=42
06/06/2022 08:24:28 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=44
06/06/2022 08:24:30 - INFO - __main__ - Step 190 Global step 190 Train loss 0.56 on epoch=47
06/06/2022 08:24:33 - INFO - __main__ - Step 200 Global step 200 Train loss 0.51 on epoch=49
06/06/2022 08:24:34 - INFO - __main__ - Global step 200 Train loss 0.59 Classification-F1 0.6307105492589364 on epoch=49
06/06/2022 08:24:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5790839874180557 -> 0.6307105492589364 on epoch=49, global_step=200
06/06/2022 08:24:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.58 on epoch=52
06/06/2022 08:24:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.54 on epoch=54
06/06/2022 08:24:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.46 on epoch=57
06/06/2022 08:24:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.51 on epoch=59
06/06/2022 08:24:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.36 on epoch=62
06/06/2022 08:24:48 - INFO - __main__ - Global step 250 Train loss 0.49 Classification-F1 0.7678981711239776 on epoch=62
06/06/2022 08:24:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6307105492589364 -> 0.7678981711239776 on epoch=62, global_step=250
06/06/2022 08:24:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.42 on epoch=64
06/06/2022 08:24:53 - INFO - __main__ - Step 270 Global step 270 Train loss 0.43 on epoch=67
06/06/2022 08:24:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.32 on epoch=69
06/06/2022 08:24:58 - INFO - __main__ - Step 290 Global step 290 Train loss 0.27 on epoch=72
06/06/2022 08:25:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=74
06/06/2022 08:25:02 - INFO - __main__ - Global step 300 Train loss 0.35 Classification-F1 0.6924137441964268 on epoch=74
06/06/2022 08:25:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.25 on epoch=77
06/06/2022 08:25:07 - INFO - __main__ - Step 320 Global step 320 Train loss 0.41 on epoch=79
06/06/2022 08:25:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.32 on epoch=82
06/06/2022 08:25:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=84
06/06/2022 08:25:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=87
06/06/2022 08:25:16 - INFO - __main__ - Global step 350 Train loss 0.32 Classification-F1 0.7212047491318903 on epoch=87
06/06/2022 08:25:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.18 on epoch=89
06/06/2022 08:25:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=92
06/06/2022 08:25:24 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=94
06/06/2022 08:25:26 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=97
06/06/2022 08:25:29 - INFO - __main__ - Step 400 Global step 400 Train loss 0.24 on epoch=99
06/06/2022 08:25:30 - INFO - __main__ - Global step 400 Train loss 0.22 Classification-F1 0.6989441452856087 on epoch=99
06/06/2022 08:25:32 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=102
06/06/2022 08:25:35 - INFO - __main__ - Step 420 Global step 420 Train loss 0.15 on epoch=104
06/06/2022 08:25:37 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=107
06/06/2022 08:25:40 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=109
06/06/2022 08:25:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.13 on epoch=112
06/06/2022 08:25:44 - INFO - __main__ - Global step 450 Train loss 0.18 Classification-F1 0.7173655226466464 on epoch=112
06/06/2022 08:25:47 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=114
06/06/2022 08:25:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=117
06/06/2022 08:25:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.11 on epoch=119
06/06/2022 08:25:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=122
06/06/2022 08:25:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=124
06/06/2022 08:25:58 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.6760117623604466 on epoch=124
06/06/2022 08:26:01 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=127
06/06/2022 08:26:03 - INFO - __main__ - Step 520 Global step 520 Train loss 0.11 on epoch=129
06/06/2022 08:26:06 - INFO - __main__ - Step 530 Global step 530 Train loss 0.10 on epoch=132
06/06/2022 08:26:09 - INFO - __main__ - Step 540 Global step 540 Train loss 0.05 on epoch=134
06/06/2022 08:26:11 - INFO - __main__ - Step 550 Global step 550 Train loss 0.09 on epoch=137
06/06/2022 08:26:12 - INFO - __main__ - Global step 550 Train loss 0.09 Classification-F1 0.748332882410808 on epoch=137
06/06/2022 08:26:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.10 on epoch=139
06/06/2022 08:26:17 - INFO - __main__ - Step 570 Global step 570 Train loss 0.08 on epoch=142
06/06/2022 08:26:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=144
06/06/2022 08:26:22 - INFO - __main__ - Step 590 Global step 590 Train loss 0.17 on epoch=147
06/06/2022 08:26:25 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=149
06/06/2022 08:26:26 - INFO - __main__ - Global step 600 Train loss 0.10 Classification-F1 0.6891774891774891 on epoch=149
06/06/2022 08:26:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=152
06/06/2022 08:26:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=154
06/06/2022 08:26:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.04 on epoch=157
06/06/2022 08:26:36 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=159
06/06/2022 08:26:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=162
06/06/2022 08:26:40 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.6964188927603561 on epoch=162
06/06/2022 08:26:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=164
06/06/2022 08:26:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=167
06/06/2022 08:26:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=169
06/06/2022 08:26:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=172
06/06/2022 08:26:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=174
06/06/2022 08:26:54 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.6709013209013209 on epoch=174
06/06/2022 08:26:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=177
06/06/2022 08:26:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=179
06/06/2022 08:27:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=182
06/06/2022 08:27:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/06/2022 08:27:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=187
06/06/2022 08:27:08 - INFO - __main__ - Global step 750 Train loss 0.03 Classification-F1 0.7095238095238094 on epoch=187
06/06/2022 08:27:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=189
06/06/2022 08:27:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=192
06/06/2022 08:27:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=194
06/06/2022 08:27:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=197
06/06/2022 08:27:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/06/2022 08:27:22 - INFO - __main__ - Global step 800 Train loss 0.03 Classification-F1 0.6865619313895176 on epoch=199
06/06/2022 08:27:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=202
06/06/2022 08:27:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/06/2022 08:27:30 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=207
06/06/2022 08:27:33 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=209
06/06/2022 08:27:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=212
06/06/2022 08:27:37 - INFO - __main__ - Global step 850 Train loss 0.03 Classification-F1 0.7238095238095238 on epoch=212
06/06/2022 08:27:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=214
06/06/2022 08:27:42 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=217
06/06/2022 08:27:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=219
06/06/2022 08:27:47 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/06/2022 08:27:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/06/2022 08:27:51 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.7314390867693843 on epoch=224
06/06/2022 08:27:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/06/2022 08:27:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/06/2022 08:27:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=232
06/06/2022 08:28:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/06/2022 08:28:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
06/06/2022 08:28:06 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.7001536098310291 on epoch=237
06/06/2022 08:28:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
06/06/2022 08:28:11 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
06/06/2022 08:28:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=244
06/06/2022 08:28:17 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
06/06/2022 08:28:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/06/2022 08:28:20 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.7402298850574712 on epoch=249
06/06/2022 08:28:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/06/2022 08:28:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/06/2022 08:28:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=257
06/06/2022 08:28:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/06/2022 08:28:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
06/06/2022 08:28:35 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7250835818198248 on epoch=262
06/06/2022 08:28:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/06/2022 08:28:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
06/06/2022 08:28:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/06/2022 08:28:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/06/2022 08:28:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=274
06/06/2022 08:28:49 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.7486384583158777 on epoch=274
06/06/2022 08:28:52 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/06/2022 08:28:54 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/06/2022 08:28:57 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/06/2022 08:29:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/06/2022 08:29:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/06/2022 08:29:04 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.7403950216450217 on epoch=287
06/06/2022 08:29:06 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/06/2022 08:29:09 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=292
06/06/2022 08:29:11 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=294
06/06/2022 08:29:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/06/2022 08:29:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/06/2022 08:29:18 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.733541055718475 on epoch=299
06/06/2022 08:29:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/06/2022 08:29:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/06/2022 08:29:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/06/2022 08:29:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=309
06/06/2022 08:29:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/06/2022 08:29:32 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7029456051195182 on epoch=312
06/06/2022 08:29:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/06/2022 08:29:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/06/2022 08:29:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/06/2022 08:29:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/06/2022 08:29:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/06/2022 08:29:47 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.7331809947299077 on epoch=324
06/06/2022 08:29:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/06/2022 08:29:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/06/2022 08:29:55 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/06/2022 08:29:57 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/06/2022 08:30:00 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/06/2022 08:30:01 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.7268927621515769 on epoch=337
06/06/2022 08:30:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/06/2022 08:30:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/06/2022 08:30:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/06/2022 08:30:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/06/2022 08:30:14 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/06/2022 08:30:15 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7403950216450217 on epoch=349
06/06/2022 08:30:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/06/2022 08:30:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/06/2022 08:30:23 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/06/2022 08:30:26 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/06/2022 08:30:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/06/2022 08:30:29 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7643398268398268 on epoch=362
06/06/2022 08:30:32 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/06/2022 08:30:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/06/2022 08:30:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/06/2022 08:30:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/06/2022 08:30:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=374
06/06/2022 08:30:44 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7179347826086955 on epoch=374
06/06/2022 08:30:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/06/2022 08:30:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/06/2022 08:30:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=382
06/06/2022 08:30:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/06/2022 08:30:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/06/2022 08:30:58 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.6952204006192402 on epoch=387
06/06/2022 08:31:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=389
06/06/2022 08:31:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/06/2022 08:31:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/06/2022 08:31:09 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/06/2022 08:31:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/06/2022 08:31:12 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7116518676707505 on epoch=399
06/06/2022 08:31:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=402
06/06/2022 08:31:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/06/2022 08:31:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/06/2022 08:31:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/06/2022 08:31:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/06/2022 08:31:27 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7493383924397248 on epoch=412
06/06/2022 08:31:29 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/06/2022 08:31:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/06/2022 08:31:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/06/2022 08:31:37 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/06/2022 08:31:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/06/2022 08:31:41 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.7643398268398268 on epoch=424
06/06/2022 08:31:43 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/06/2022 08:31:46 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/06/2022 08:31:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/06/2022 08:31:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/06/2022 08:31:54 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/06/2022 08:31:55 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7905386178861789 on epoch=437
06/06/2022 08:31:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7678981711239776 -> 0.7905386178861789 on epoch=437, global_step=1750
06/06/2022 08:31:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/06/2022 08:32:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/06/2022 08:32:03 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/06/2022 08:32:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/06/2022 08:32:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/06/2022 08:32:10 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.7493383924397248 on epoch=449
06/06/2022 08:32:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/06/2022 08:32:15 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=454
06/06/2022 08:32:18 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/06/2022 08:32:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/06/2022 08:32:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=462
06/06/2022 08:32:24 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7643398268398268 on epoch=462
06/06/2022 08:32:27 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/06/2022 08:32:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/06/2022 08:32:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/06/2022 08:32:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/06/2022 08:32:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/06/2022 08:32:38 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7905386178861789 on epoch=474
06/06/2022 08:32:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/06/2022 08:32:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/06/2022 08:32:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/06/2022 08:32:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/06/2022 08:32:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/06/2022 08:32:52 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7905386178861789 on epoch=487
06/06/2022 08:32:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/06/2022 08:32:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/06/2022 08:33:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/06/2022 08:33:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/06/2022 08:33:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=499
06/06/2022 08:33:07 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7626204827068837 on epoch=499
06/06/2022 08:33:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/06/2022 08:33:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/06/2022 08:33:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.11 on epoch=507
06/06/2022 08:33:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/06/2022 08:33:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/06/2022 08:33:22 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7693827039076843 on epoch=512
06/06/2022 08:33:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/06/2022 08:33:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/06/2022 08:33:30 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/06/2022 08:33:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/06/2022 08:33:35 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/06/2022 08:33:36 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7496988518727649 on epoch=524
06/06/2022 08:33:39 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/06/2022 08:33:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 08:33:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/06/2022 08:33:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/06/2022 08:33:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/06/2022 08:33:51 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.727780899928815 on epoch=537
06/06/2022 08:33:54 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/06/2022 08:33:57 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/06/2022 08:33:59 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/06/2022 08:34:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/06/2022 08:34:04 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/06/2022 08:34:06 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7470453598791638 on epoch=549
06/06/2022 08:34:08 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 08:34:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/06/2022 08:34:14 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/06/2022 08:34:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/06/2022 08:34:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/06/2022 08:34:20 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7509792701860087 on epoch=562
06/06/2022 08:34:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/06/2022 08:34:26 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/06/2022 08:34:28 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/06/2022 08:34:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/06/2022 08:34:33 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/06/2022 08:34:34 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.74938884644767 on epoch=574
06/06/2022 08:34:37 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 08:34:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 08:34:42 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/06/2022 08:34:45 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/06/2022 08:34:48 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 08:34:49 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7647674905739422 on epoch=587
06/06/2022 08:34:51 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/06/2022 08:34:54 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=592
06/06/2022 08:34:57 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 08:34:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/06/2022 08:35:02 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 08:35:03 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7830451251646904 on epoch=599
06/06/2022 08:35:06 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 08:35:08 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 08:35:11 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 08:35:14 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 08:35:16 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/06/2022 08:35:17 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7677336853394935 on epoch=612
06/06/2022 08:35:20 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 08:35:22 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/06/2022 08:35:25 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.24 on epoch=619
06/06/2022 08:35:28 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=622
06/06/2022 08:35:30 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 08:35:31 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.6964033262207705 on epoch=624
06/06/2022 08:35:34 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=627
06/06/2022 08:35:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/06/2022 08:35:39 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=632
06/06/2022 08:35:42 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/06/2022 08:35:44 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 08:35:46 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7268927621515769 on epoch=637
06/06/2022 08:35:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 08:35:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/06/2022 08:35:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/06/2022 08:35:56 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 08:35:59 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 08:36:00 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7486384583158777 on epoch=649
06/06/2022 08:36:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/06/2022 08:36:05 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 08:36:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/06/2022 08:36:10 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 08:36:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 08:36:14 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7345313601127554 on epoch=662
06/06/2022 08:36:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 08:36:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 08:36:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 08:36:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 08:36:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 08:36:29 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7643398268398268 on epoch=674
06/06/2022 08:36:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/06/2022 08:36:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 08:36:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 08:36:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 08:36:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 08:36:43 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7643398268398268 on epoch=687
06/06/2022 08:36:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/06/2022 08:36:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 08:36:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/06/2022 08:36:54 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/06/2022 08:36:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 08:36:58 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7388019232083077 on epoch=699
06/06/2022 08:37:00 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.13 on epoch=702
06/06/2022 08:37:03 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 08:37:06 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 08:37:08 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/06/2022 08:37:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 08:37:12 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7623567997043607 on epoch=712
06/06/2022 08:37:15 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 08:37:17 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 08:37:20 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 08:37:23 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/06/2022 08:37:25 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=724
06/06/2022 08:37:27 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7345313601127554 on epoch=724
06/06/2022 08:37:29 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 08:37:32 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 08:37:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=732
06/06/2022 08:37:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 08:37:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 08:37:41 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7351602433530391 on epoch=737
06/06/2022 08:37:44 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 08:37:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 08:37:49 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 08:37:52 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/06/2022 08:37:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 08:37:56 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7551319648093843 on epoch=749
06/06/2022 08:37:56 - INFO - __main__ - save last model!
06/06/2022 08:37:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 08:37:56 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 08:37:56 - INFO - __main__ - Printing 3 examples
06/06/2022 08:37:56 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 08:37:56 - INFO - __main__ - ['others']
06/06/2022 08:37:56 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 08:37:56 - INFO - __main__ - ['others']
06/06/2022 08:37:56 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 08:37:56 - INFO - __main__ - ['others']
06/06/2022 08:37:56 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:37:56 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:37:56 - INFO - __main__ - Printing 3 examples
06/06/2022 08:37:56 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/06/2022 08:37:56 - INFO - __main__ - ['sad']
06/06/2022 08:37:56 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/06/2022 08:37:56 - INFO - __main__ - ['sad']
06/06/2022 08:37:56 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/06/2022 08:37:56 - INFO - __main__ - ['sad']
06/06/2022 08:37:56 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:37:56 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:37:56 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 08:37:56 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:37:56 - INFO - __main__ - Printing 3 examples
06/06/2022 08:37:56 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/06/2022 08:37:56 - INFO - __main__ - ['sad']
06/06/2022 08:37:56 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/06/2022 08:37:56 - INFO - __main__ - ['sad']
06/06/2022 08:37:56 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/06/2022 08:37:56 - INFO - __main__ - ['sad']
06/06/2022 08:37:56 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:37:56 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:37:56 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 08:37:58 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:38:03 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 08:38:15 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 08:38:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 08:38:16 - INFO - __main__ - Starting training!
06/06/2022 08:39:41 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_21_0.4_8_predictions.txt
06/06/2022 08:39:41 - INFO - __main__ - Classification-F1 on test data: 0.2371
06/06/2022 08:39:41 - INFO - __main__ - prefix=emo_16_21, lr=0.4, bsz=8, dev_performance=0.7905386178861789, test_performance=0.23710142506998796
06/06/2022 08:39:41 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.3, bsz=8 ...
06/06/2022 08:39:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:39:42 - INFO - __main__ - Printing 3 examples
06/06/2022 08:39:42 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/06/2022 08:39:42 - INFO - __main__ - ['sad']
06/06/2022 08:39:42 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/06/2022 08:39:42 - INFO - __main__ - ['sad']
06/06/2022 08:39:42 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/06/2022 08:39:42 - INFO - __main__ - ['sad']
06/06/2022 08:39:42 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:39:42 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:39:42 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 08:39:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:39:42 - INFO - __main__ - Printing 3 examples
06/06/2022 08:39:42 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/06/2022 08:39:42 - INFO - __main__ - ['sad']
06/06/2022 08:39:42 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/06/2022 08:39:42 - INFO - __main__ - ['sad']
06/06/2022 08:39:42 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/06/2022 08:39:42 - INFO - __main__ - ['sad']
06/06/2022 08:39:42 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:39:42 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:39:42 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 08:39:58 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 08:39:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 08:39:59 - INFO - __main__ - Starting training!
06/06/2022 08:40:02 - INFO - __main__ - Step 10 Global step 10 Train loss 3.99 on epoch=2
06/06/2022 08:40:05 - INFO - __main__ - Step 20 Global step 20 Train loss 2.41 on epoch=4
06/06/2022 08:40:08 - INFO - __main__ - Step 30 Global step 30 Train loss 1.78 on epoch=7
06/06/2022 08:40:10 - INFO - __main__ - Step 40 Global step 40 Train loss 1.28 on epoch=9
06/06/2022 08:40:13 - INFO - __main__ - Step 50 Global step 50 Train loss 1.12 on epoch=12
06/06/2022 08:40:14 - INFO - __main__ - Global step 50 Train loss 2.12 Classification-F1 0.20526315789473687 on epoch=12
06/06/2022 08:40:14 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.20526315789473687 on epoch=12, global_step=50
06/06/2022 08:40:17 - INFO - __main__ - Step 60 Global step 60 Train loss 0.98 on epoch=14
06/06/2022 08:40:19 - INFO - __main__ - Step 70 Global step 70 Train loss 0.95 on epoch=17
06/06/2022 08:40:22 - INFO - __main__ - Step 80 Global step 80 Train loss 0.97 on epoch=19
06/06/2022 08:40:25 - INFO - __main__ - Step 90 Global step 90 Train loss 0.85 on epoch=22
06/06/2022 08:40:27 - INFO - __main__ - Step 100 Global step 100 Train loss 0.80 on epoch=24
06/06/2022 08:40:28 - INFO - __main__ - Global step 100 Train loss 0.91 Classification-F1 0.3484294871794872 on epoch=24
06/06/2022 08:40:28 - INFO - __main__ - Saving model with best Classification-F1: 0.20526315789473687 -> 0.3484294871794872 on epoch=24, global_step=100
06/06/2022 08:40:31 - INFO - __main__ - Step 110 Global step 110 Train loss 0.85 on epoch=27
06/06/2022 08:40:33 - INFO - __main__ - Step 120 Global step 120 Train loss 0.77 on epoch=29
06/06/2022 08:40:36 - INFO - __main__ - Step 130 Global step 130 Train loss 0.80 on epoch=32
06/06/2022 08:40:39 - INFO - __main__ - Step 140 Global step 140 Train loss 0.75 on epoch=34
06/06/2022 08:40:41 - INFO - __main__ - Step 150 Global step 150 Train loss 0.84 on epoch=37
06/06/2022 08:40:42 - INFO - __main__ - Global step 150 Train loss 0.80 Classification-F1 0.6930458768873403 on epoch=37
06/06/2022 08:40:42 - INFO - __main__ - Saving model with best Classification-F1: 0.3484294871794872 -> 0.6930458768873403 on epoch=37, global_step=150
06/06/2022 08:40:45 - INFO - __main__ - Step 160 Global step 160 Train loss 0.72 on epoch=39
06/06/2022 08:40:47 - INFO - __main__ - Step 170 Global step 170 Train loss 0.75 on epoch=42
06/06/2022 08:40:50 - INFO - __main__ - Step 180 Global step 180 Train loss 0.63 on epoch=44
06/06/2022 08:40:53 - INFO - __main__ - Step 190 Global step 190 Train loss 0.69 on epoch=47
06/06/2022 08:40:55 - INFO - __main__ - Step 200 Global step 200 Train loss 0.70 on epoch=49
06/06/2022 08:40:56 - INFO - __main__ - Global step 200 Train loss 0.70 Classification-F1 0.5662212702298381 on epoch=49
06/06/2022 08:40:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.64 on epoch=52
06/06/2022 08:41:01 - INFO - __main__ - Step 220 Global step 220 Train loss 0.58 on epoch=54
06/06/2022 08:41:04 - INFO - __main__ - Step 230 Global step 230 Train loss 0.62 on epoch=57
06/06/2022 08:41:06 - INFO - __main__ - Step 240 Global step 240 Train loss 0.46 on epoch=59
06/06/2022 08:41:09 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=62
06/06/2022 08:41:10 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.6973039215686275 on epoch=62
06/06/2022 08:41:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6930458768873403 -> 0.6973039215686275 on epoch=62, global_step=250
06/06/2022 08:41:12 - INFO - __main__ - Step 260 Global step 260 Train loss 0.48 on epoch=64
06/06/2022 08:41:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.46 on epoch=67
06/06/2022 08:41:18 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=69
06/06/2022 08:41:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=72
06/06/2022 08:41:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.51 on epoch=74
06/06/2022 08:41:24 - INFO - __main__ - Global step 300 Train loss 0.49 Classification-F1 0.6320519435844514 on epoch=74
06/06/2022 08:41:26 - INFO - __main__ - Step 310 Global step 310 Train loss 0.51 on epoch=77
06/06/2022 08:41:29 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=79
06/06/2022 08:41:31 - INFO - __main__ - Step 330 Global step 330 Train loss 0.35 on epoch=82
06/06/2022 08:41:34 - INFO - __main__ - Step 340 Global step 340 Train loss 0.40 on epoch=84
06/06/2022 08:41:37 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=87
06/06/2022 08:41:38 - INFO - __main__ - Global step 350 Train loss 0.39 Classification-F1 0.6948566376152583 on epoch=87
06/06/2022 08:41:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=89
06/06/2022 08:41:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=92
06/06/2022 08:41:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.35 on epoch=94
06/06/2022 08:41:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=97
06/06/2022 08:41:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.34 on epoch=99
06/06/2022 08:41:52 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.574936673233887 on epoch=99
06/06/2022 08:41:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=102
06/06/2022 08:41:58 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=104
06/06/2022 08:42:00 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=107
06/06/2022 08:42:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=109
06/06/2022 08:42:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.14 on epoch=112
06/06/2022 08:42:06 - INFO - __main__ - Global step 450 Train loss 0.25 Classification-F1 0.7115173473869126 on epoch=112
06/06/2022 08:42:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6973039215686275 -> 0.7115173473869126 on epoch=112, global_step=450
06/06/2022 08:42:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=114
06/06/2022 08:42:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=117
06/06/2022 08:42:14 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=119
06/06/2022 08:42:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=122
06/06/2022 08:42:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=124
06/06/2022 08:42:21 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.7315656565656565 on epoch=124
06/06/2022 08:42:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7115173473869126 -> 0.7315656565656565 on epoch=124, global_step=500
06/06/2022 08:42:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=127
06/06/2022 08:42:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.12 on epoch=129
06/06/2022 08:42:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=132
06/06/2022 08:42:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=134
06/06/2022 08:42:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=137
06/06/2022 08:42:35 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.6832837301587301 on epoch=137
06/06/2022 08:42:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/06/2022 08:42:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.08 on epoch=142
06/06/2022 08:42:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=144
06/06/2022 08:42:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.12 on epoch=147
06/06/2022 08:42:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=149
06/06/2022 08:42:50 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.7495337995337996 on epoch=149
06/06/2022 08:42:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7315656565656565 -> 0.7495337995337996 on epoch=149, global_step=600
06/06/2022 08:42:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=152
06/06/2022 08:42:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=154
06/06/2022 08:42:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=157
06/06/2022 08:43:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=159
06/06/2022 08:43:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=162
06/06/2022 08:43:04 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.712594696969697 on epoch=162
06/06/2022 08:43:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=164
06/06/2022 08:43:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=167
06/06/2022 08:43:12 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=169
06/06/2022 08:43:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=172
06/06/2022 08:43:18 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=174
06/06/2022 08:43:19 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.7224747474747475 on epoch=174
06/06/2022 08:43:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=177
06/06/2022 08:43:24 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=179
06/06/2022 08:43:27 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/06/2022 08:43:30 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=184
06/06/2022 08:43:32 - INFO - __main__ - Step 750 Global step 750 Train loss 0.04 on epoch=187
06/06/2022 08:43:33 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.7446830286168522 on epoch=187
06/06/2022 08:43:36 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=189
06/06/2022 08:43:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=192
06/06/2022 08:43:41 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=194
06/06/2022 08:43:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=197
06/06/2022 08:43:46 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/06/2022 08:43:48 - INFO - __main__ - Global step 800 Train loss 0.07 Classification-F1 0.6686411149825783 on epoch=199
06/06/2022 08:43:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=202
06/06/2022 08:43:53 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=204
06/06/2022 08:43:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=207
06/06/2022 08:43:58 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=209
06/06/2022 08:44:01 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/06/2022 08:44:02 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.7263515446224257 on epoch=212
06/06/2022 08:44:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/06/2022 08:44:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=217
06/06/2022 08:44:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=219
06/06/2022 08:44:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=222
06/06/2022 08:44:16 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=224
06/06/2022 08:44:17 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.7770250582750583 on epoch=224
06/06/2022 08:44:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7495337995337996 -> 0.7770250582750583 on epoch=224, global_step=900
06/06/2022 08:44:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/06/2022 08:44:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=229
06/06/2022 08:44:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=232
06/06/2022 08:44:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
06/06/2022 08:44:30 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=237
06/06/2022 08:44:31 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.7413385118854965 on epoch=237
06/06/2022 08:44:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=239
06/06/2022 08:44:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
06/06/2022 08:44:40 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=244
06/06/2022 08:44:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/06/2022 08:44:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/06/2022 08:44:46 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.7328709893048129 on epoch=249
06/06/2022 08:44:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/06/2022 08:44:52 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/06/2022 08:44:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/06/2022 08:44:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/06/2022 08:45:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/06/2022 08:45:01 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7759274193548388 on epoch=262
06/06/2022 08:45:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=264
06/06/2022 08:45:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
06/06/2022 08:45:10 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/06/2022 08:45:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/06/2022 08:45:15 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/06/2022 08:45:16 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.7552336853394935 on epoch=274
06/06/2022 08:45:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/06/2022 08:45:21 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/06/2022 08:45:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/06/2022 08:45:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/06/2022 08:45:29 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/06/2022 08:45:30 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.7613621794871795 on epoch=287
06/06/2022 08:45:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/06/2022 08:45:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/06/2022 08:45:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/06/2022 08:45:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/06/2022 08:45:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/06/2022 08:45:44 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.7297619047619047 on epoch=299
06/06/2022 08:45:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/06/2022 08:45:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=304
06/06/2022 08:45:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/06/2022 08:45:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/06/2022 08:45:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=312
06/06/2022 08:45:59 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7436570782159018 on epoch=312
06/06/2022 08:46:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/06/2022 08:46:04 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/06/2022 08:46:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/06/2022 08:46:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/06/2022 08:46:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=324
06/06/2022 08:46:13 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.7058823529411764 on epoch=324
06/06/2022 08:46:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/06/2022 08:46:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/06/2022 08:46:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/06/2022 08:46:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/06/2022 08:46:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/06/2022 08:46:27 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7392156862745098 on epoch=337
06/06/2022 08:46:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/06/2022 08:46:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/06/2022 08:46:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/06/2022 08:46:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/06/2022 08:46:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/06/2022 08:46:42 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.695993932942607 on epoch=349
06/06/2022 08:46:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/06/2022 08:46:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/06/2022 08:46:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/06/2022 08:46:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/06/2022 08:46:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/06/2022 08:46:57 - INFO - __main__ - Global step 1450 Train loss 0.00 Classification-F1 0.7192439648181648 on epoch=362
06/06/2022 08:46:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/06/2022 08:47:02 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/06/2022 08:47:05 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/06/2022 08:47:07 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/06/2022 08:47:10 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/06/2022 08:47:11 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.667480725239346 on epoch=374
06/06/2022 08:47:13 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/06/2022 08:47:16 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=379
06/06/2022 08:47:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/06/2022 08:47:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/06/2022 08:47:24 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=387
06/06/2022 08:47:25 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.6887663236988574 on epoch=387
06/06/2022 08:47:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/06/2022 08:47:30 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/06/2022 08:47:33 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/06/2022 08:47:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/06/2022 08:47:38 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/06/2022 08:47:39 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7117063492063492 on epoch=399
06/06/2022 08:47:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/06/2022 08:47:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
06/06/2022 08:47:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/06/2022 08:47:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/06/2022 08:47:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/06/2022 08:47:54 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.728870858688303 on epoch=412
06/06/2022 08:47:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/06/2022 08:47:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=417
06/06/2022 08:48:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/06/2022 08:48:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/06/2022 08:48:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/06/2022 08:48:08 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.743122538381159 on epoch=424
06/06/2022 08:48:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/06/2022 08:48:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=429
06/06/2022 08:48:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/06/2022 08:48:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/06/2022 08:48:21 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/06/2022 08:48:22 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7456317204301076 on epoch=437
06/06/2022 08:48:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=439
06/06/2022 08:48:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/06/2022 08:48:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/06/2022 08:48:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/06/2022 08:48:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/06/2022 08:48:37 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7330321852060981 on epoch=449
06/06/2022 08:48:39 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/06/2022 08:48:42 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/06/2022 08:48:44 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/06/2022 08:48:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/06/2022 08:48:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/06/2022 08:48:51 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.7118040873854827 on epoch=462
06/06/2022 08:48:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/06/2022 08:48:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/06/2022 08:48:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/06/2022 08:49:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/06/2022 08:49:04 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/06/2022 08:49:05 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.7332093601816603 on epoch=474
06/06/2022 08:49:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/06/2022 08:49:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/06/2022 08:49:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=482
06/06/2022 08:49:15 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/06/2022 08:49:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=487
06/06/2022 08:49:19 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7377622377622378 on epoch=487
06/06/2022 08:49:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/06/2022 08:49:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/06/2022 08:49:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/06/2022 08:49:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/06/2022 08:49:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/06/2022 08:49:34 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.7217851158454386 on epoch=499
06/06/2022 08:49:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/06/2022 08:49:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/06/2022 08:49:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/06/2022 08:49:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/06/2022 08:49:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/06/2022 08:49:48 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.7336544795783926 on epoch=512
06/06/2022 08:49:51 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=514
06/06/2022 08:49:53 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/06/2022 08:49:56 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/06/2022 08:49:59 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/06/2022 08:50:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/06/2022 08:50:03 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7128652597402597 on epoch=524
06/06/2022 08:50:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/06/2022 08:50:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 08:50:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/06/2022 08:50:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/06/2022 08:50:16 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/06/2022 08:50:17 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.6798965262379897 on epoch=537
06/06/2022 08:50:20 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/06/2022 08:50:23 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 08:50:25 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/06/2022 08:50:28 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/06/2022 08:50:31 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/06/2022 08:50:32 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7430375253549697 on epoch=549
06/06/2022 08:50:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 08:50:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/06/2022 08:50:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/06/2022 08:50:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/06/2022 08:50:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/06/2022 08:50:46 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7759274193548388 on epoch=562
06/06/2022 08:50:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/06/2022 08:50:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=567
06/06/2022 08:50:54 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=569
06/06/2022 08:50:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/06/2022 08:50:59 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 08:51:00 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7292932202206396 on epoch=574
06/06/2022 08:51:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/06/2022 08:51:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 08:51:08 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/06/2022 08:51:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/06/2022 08:51:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 08:51:14 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.719290465631929 on epoch=587
06/06/2022 08:51:17 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/06/2022 08:51:20 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/06/2022 08:51:22 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 08:51:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/06/2022 08:51:28 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.22 on epoch=599
06/06/2022 08:51:29 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.7268927621515769 on epoch=599
06/06/2022 08:51:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 08:51:34 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 08:51:37 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 08:51:40 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/06/2022 08:51:42 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 08:51:44 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7498424246977893 on epoch=612
06/06/2022 08:51:46 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 08:51:49 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 08:51:52 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 08:51:54 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/06/2022 08:51:57 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 08:51:58 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7281102946191094 on epoch=624
06/06/2022 08:52:01 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/06/2022 08:52:03 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/06/2022 08:52:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/06/2022 08:52:09 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=634
06/06/2022 08:52:11 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
06/06/2022 08:52:12 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7932214927121548 on epoch=637
06/06/2022 08:52:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7770250582750583 -> 0.7932214927121548 on epoch=637, global_step=2550
06/06/2022 08:52:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 08:52:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/06/2022 08:52:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 08:52:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 08:52:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/06/2022 08:52:26 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7419013966853782 on epoch=649
06/06/2022 08:52:29 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/06/2022 08:52:32 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/06/2022 08:52:34 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/06/2022 08:52:37 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 08:52:40 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 08:52:41 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7467317997043607 on epoch=662
06/06/2022 08:52:44 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 08:52:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 08:52:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 08:52:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 08:52:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/06/2022 08:52:55 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7268927621515769 on epoch=674
06/06/2022 08:52:58 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/06/2022 08:53:00 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 08:53:03 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 08:53:06 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 08:53:08 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 08:53:10 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7741397150648622 on epoch=687
06/06/2022 08:53:12 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 08:53:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 08:53:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/06/2022 08:53:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 08:53:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 08:53:24 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7166170634920636 on epoch=699
06/06/2022 08:53:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/06/2022 08:53:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 08:53:32 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 08:53:34 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/06/2022 08:53:37 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 08:53:38 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7375717656789764 on epoch=712
06/06/2022 08:53:41 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/06/2022 08:53:43 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 08:53:46 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 08:53:49 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/06/2022 08:53:51 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 08:53:52 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6995670995670996 on epoch=724
06/06/2022 08:53:55 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 08:53:58 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 08:54:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 08:54:03 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 08:54:06 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 08:54:07 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7247700216450217 on epoch=737
06/06/2022 08:54:10 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=739
06/06/2022 08:54:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 08:54:15 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/06/2022 08:54:17 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=747
06/06/2022 08:54:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=749
06/06/2022 08:54:21 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7166170634920636 on epoch=749
06/06/2022 08:54:21 - INFO - __main__ - save last model!
06/06/2022 08:54:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 08:54:21 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 08:54:21 - INFO - __main__ - Printing 3 examples
06/06/2022 08:54:21 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 08:54:21 - INFO - __main__ - ['others']
06/06/2022 08:54:21 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 08:54:21 - INFO - __main__ - ['others']
06/06/2022 08:54:21 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 08:54:21 - INFO - __main__ - ['others']
06/06/2022 08:54:21 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:54:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:54:21 - INFO - __main__ - Printing 3 examples
06/06/2022 08:54:21 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/06/2022 08:54:21 - INFO - __main__ - ['sad']
06/06/2022 08:54:21 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/06/2022 08:54:21 - INFO - __main__ - ['sad']
06/06/2022 08:54:21 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/06/2022 08:54:21 - INFO - __main__ - ['sad']
06/06/2022 08:54:21 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:54:21 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:54:22 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 08:54:22 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:54:22 - INFO - __main__ - Printing 3 examples
06/06/2022 08:54:22 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/06/2022 08:54:22 - INFO - __main__ - ['sad']
06/06/2022 08:54:22 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/06/2022 08:54:22 - INFO - __main__ - ['sad']
06/06/2022 08:54:22 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/06/2022 08:54:22 - INFO - __main__ - ['sad']
06/06/2022 08:54:22 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:54:22 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:54:22 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 08:54:24 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:54:30 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 08:54:38 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 08:54:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 08:54:38 - INFO - __main__ - Starting training!
06/06/2022 08:56:06 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_21_0.3_8_predictions.txt
06/06/2022 08:56:06 - INFO - __main__ - Classification-F1 on test data: 0.1782
06/06/2022 08:56:06 - INFO - __main__ - prefix=emo_16_21, lr=0.3, bsz=8, dev_performance=0.7932214927121548, test_performance=0.17817156791436103
06/06/2022 08:56:06 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.2, bsz=8 ...
06/06/2022 08:56:07 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:56:07 - INFO - __main__ - Printing 3 examples
06/06/2022 08:56:07 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/06/2022 08:56:07 - INFO - __main__ - ['sad']
06/06/2022 08:56:07 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/06/2022 08:56:07 - INFO - __main__ - ['sad']
06/06/2022 08:56:07 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/06/2022 08:56:07 - INFO - __main__ - ['sad']
06/06/2022 08:56:07 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:56:07 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:56:08 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 08:56:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 08:56:08 - INFO - __main__ - Printing 3 examples
06/06/2022 08:56:08 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/06/2022 08:56:08 - INFO - __main__ - ['sad']
06/06/2022 08:56:08 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/06/2022 08:56:08 - INFO - __main__ - ['sad']
06/06/2022 08:56:08 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/06/2022 08:56:08 - INFO - __main__ - ['sad']
06/06/2022 08:56:08 - INFO - __main__ - Tokenizing Input ...
06/06/2022 08:56:08 - INFO - __main__ - Tokenizing Output ...
06/06/2022 08:56:08 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 08:56:23 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 08:56:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 08:56:24 - INFO - __main__ - Starting training!
06/06/2022 08:56:27 - INFO - __main__ - Step 10 Global step 10 Train loss 4.00 on epoch=2
06/06/2022 08:56:30 - INFO - __main__ - Step 20 Global step 20 Train loss 2.99 on epoch=4
06/06/2022 08:56:32 - INFO - __main__ - Step 30 Global step 30 Train loss 2.39 on epoch=7
06/06/2022 08:56:35 - INFO - __main__ - Step 40 Global step 40 Train loss 1.70 on epoch=9
06/06/2022 08:56:38 - INFO - __main__ - Step 50 Global step 50 Train loss 1.34 on epoch=12
06/06/2022 08:56:39 - INFO - __main__ - Global step 50 Train loss 2.48 Classification-F1 0.18284347231715653 on epoch=12
06/06/2022 08:56:39 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.18284347231715653 on epoch=12, global_step=50
06/06/2022 08:56:41 - INFO - __main__ - Step 60 Global step 60 Train loss 1.05 on epoch=14
06/06/2022 08:56:44 - INFO - __main__ - Step 70 Global step 70 Train loss 1.10 on epoch=17
06/06/2022 08:56:47 - INFO - __main__ - Step 80 Global step 80 Train loss 0.97 on epoch=19
06/06/2022 08:56:49 - INFO - __main__ - Step 90 Global step 90 Train loss 1.03 on epoch=22
06/06/2022 08:56:52 - INFO - __main__ - Step 100 Global step 100 Train loss 0.91 on epoch=24
06/06/2022 08:56:52 - INFO - __main__ - Global step 100 Train loss 1.01 Classification-F1 0.1542857142857143 on epoch=24
06/06/2022 08:56:55 - INFO - __main__ - Step 110 Global step 110 Train loss 0.96 on epoch=27
06/06/2022 08:56:58 - INFO - __main__ - Step 120 Global step 120 Train loss 0.99 on epoch=29
06/06/2022 08:57:00 - INFO - __main__ - Step 130 Global step 130 Train loss 1.01 on epoch=32
06/06/2022 08:57:03 - INFO - __main__ - Step 140 Global step 140 Train loss 0.84 on epoch=34
06/06/2022 08:57:05 - INFO - __main__ - Step 150 Global step 150 Train loss 0.92 on epoch=37
06/06/2022 08:57:06 - INFO - __main__ - Global step 150 Train loss 0.94 Classification-F1 0.39517345399698345 on epoch=37
06/06/2022 08:57:06 - INFO - __main__ - Saving model with best Classification-F1: 0.18284347231715653 -> 0.39517345399698345 on epoch=37, global_step=150
06/06/2022 08:57:09 - INFO - __main__ - Step 160 Global step 160 Train loss 0.84 on epoch=39
06/06/2022 08:57:12 - INFO - __main__ - Step 170 Global step 170 Train loss 0.72 on epoch=42
06/06/2022 08:57:14 - INFO - __main__ - Step 180 Global step 180 Train loss 0.77 on epoch=44
06/06/2022 08:57:17 - INFO - __main__ - Step 190 Global step 190 Train loss 0.84 on epoch=47
06/06/2022 08:57:19 - INFO - __main__ - Step 200 Global step 200 Train loss 0.70 on epoch=49
06/06/2022 08:57:20 - INFO - __main__ - Global step 200 Train loss 0.77 Classification-F1 0.5489923617267954 on epoch=49
06/06/2022 08:57:20 - INFO - __main__ - Saving model with best Classification-F1: 0.39517345399698345 -> 0.5489923617267954 on epoch=49, global_step=200
06/06/2022 08:57:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.78 on epoch=52
06/06/2022 08:57:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.77 on epoch=54
06/06/2022 08:57:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.76 on epoch=57
06/06/2022 08:57:31 - INFO - __main__ - Step 240 Global step 240 Train loss 0.61 on epoch=59
06/06/2022 08:57:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.75 on epoch=62
06/06/2022 08:57:34 - INFO - __main__ - Global step 250 Train loss 0.73 Classification-F1 0.5042571687515799 on epoch=62
06/06/2022 08:57:37 - INFO - __main__ - Step 260 Global step 260 Train loss 0.77 on epoch=64
06/06/2022 08:57:39 - INFO - __main__ - Step 270 Global step 270 Train loss 0.65 on epoch=67
06/06/2022 08:57:42 - INFO - __main__ - Step 280 Global step 280 Train loss 0.62 on epoch=69
06/06/2022 08:57:44 - INFO - __main__ - Step 290 Global step 290 Train loss 0.69 on epoch=72
06/06/2022 08:57:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.59 on epoch=74
06/06/2022 08:57:48 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.5665156890726442 on epoch=74
06/06/2022 08:57:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5489923617267954 -> 0.5665156890726442 on epoch=74, global_step=300
06/06/2022 08:57:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.63 on epoch=77
06/06/2022 08:57:54 - INFO - __main__ - Step 320 Global step 320 Train loss 0.53 on epoch=79
06/06/2022 08:57:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.57 on epoch=82
06/06/2022 08:57:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.44 on epoch=84
06/06/2022 08:58:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.50 on epoch=87
06/06/2022 08:58:03 - INFO - __main__ - Global step 350 Train loss 0.54 Classification-F1 0.674520804114072 on epoch=87
06/06/2022 08:58:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5665156890726442 -> 0.674520804114072 on epoch=87, global_step=350
06/06/2022 08:58:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.54 on epoch=89
06/06/2022 08:58:08 - INFO - __main__ - Step 370 Global step 370 Train loss 0.48 on epoch=92
06/06/2022 08:58:11 - INFO - __main__ - Step 380 Global step 380 Train loss 0.52 on epoch=94
06/06/2022 08:58:13 - INFO - __main__ - Step 390 Global step 390 Train loss 0.46 on epoch=97
06/06/2022 08:58:16 - INFO - __main__ - Step 400 Global step 400 Train loss 0.45 on epoch=99
06/06/2022 08:58:17 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.6585850107589237 on epoch=99
06/06/2022 08:58:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.47 on epoch=102
06/06/2022 08:58:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.50 on epoch=104
06/06/2022 08:58:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.47 on epoch=107
06/06/2022 08:58:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=109
06/06/2022 08:58:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=112
06/06/2022 08:58:32 - INFO - __main__ - Global step 450 Train loss 0.44 Classification-F1 0.7012681159420289 on epoch=112
06/06/2022 08:58:32 - INFO - __main__ - Saving model with best Classification-F1: 0.674520804114072 -> 0.7012681159420289 on epoch=112, global_step=450
06/06/2022 08:58:35 - INFO - __main__ - Step 460 Global step 460 Train loss 0.48 on epoch=114
06/06/2022 08:58:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.44 on epoch=117
06/06/2022 08:58:40 - INFO - __main__ - Step 480 Global step 480 Train loss 0.37 on epoch=119
06/06/2022 08:58:43 - INFO - __main__ - Step 490 Global step 490 Train loss 0.32 on epoch=122
06/06/2022 08:58:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=124
06/06/2022 08:58:46 - INFO - __main__ - Global step 500 Train loss 0.38 Classification-F1 0.6703800173645895 on epoch=124
06/06/2022 08:58:49 - INFO - __main__ - Step 510 Global step 510 Train loss 0.44 on epoch=127
06/06/2022 08:58:52 - INFO - __main__ - Step 520 Global step 520 Train loss 0.31 on epoch=129
06/06/2022 08:58:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.31 on epoch=132
06/06/2022 08:58:57 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=134
06/06/2022 08:59:00 - INFO - __main__ - Step 550 Global step 550 Train loss 0.31 on epoch=137
06/06/2022 08:59:01 - INFO - __main__ - Global step 550 Train loss 0.34 Classification-F1 0.690301633850021 on epoch=137
06/06/2022 08:59:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=139
06/06/2022 08:59:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.36 on epoch=142
06/06/2022 08:59:08 - INFO - __main__ - Step 580 Global step 580 Train loss 0.22 on epoch=144
06/06/2022 08:59:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=147
06/06/2022 08:59:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=149
06/06/2022 08:59:15 - INFO - __main__ - Global step 600 Train loss 0.25 Classification-F1 0.6901002506265665 on epoch=149
06/06/2022 08:59:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=152
06/06/2022 08:59:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=154
06/06/2022 08:59:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=157
06/06/2022 08:59:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=159
06/06/2022 08:59:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=162
06/06/2022 08:59:29 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.6288515406162465 on epoch=162
06/06/2022 08:59:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=164
06/06/2022 08:59:34 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=167
06/06/2022 08:59:37 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=169
06/06/2022 08:59:39 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=172
06/06/2022 08:59:42 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=174
06/06/2022 08:59:43 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.6845808942583137 on epoch=174
06/06/2022 08:59:45 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=177
06/06/2022 08:59:48 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=179
06/06/2022 08:59:50 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=182
06/06/2022 08:59:53 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=184
06/06/2022 08:59:56 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=187
06/06/2022 08:59:57 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.7034534534534534 on epoch=187
06/06/2022 08:59:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7012681159420289 -> 0.7034534534534534 on epoch=187, global_step=750
06/06/2022 08:59:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=189
06/06/2022 09:00:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=192
06/06/2022 09:00:04 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/06/2022 09:00:07 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=197
06/06/2022 09:00:09 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
06/06/2022 09:00:11 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.7108417157759263 on epoch=199
06/06/2022 09:00:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7034534534534534 -> 0.7108417157759263 on epoch=199, global_step=800
06/06/2022 09:00:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/06/2022 09:00:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=204
06/06/2022 09:00:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=207
06/06/2022 09:00:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=209
06/06/2022 09:00:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=212
06/06/2022 09:00:25 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.718904303581723 on epoch=212
06/06/2022 09:00:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7108417157759263 -> 0.718904303581723 on epoch=212, global_step=850
06/06/2022 09:00:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=214
06/06/2022 09:00:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=217
06/06/2022 09:00:32 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=219
06/06/2022 09:00:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
06/06/2022 09:00:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=224
06/06/2022 09:00:39 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.7313805282555282 on epoch=224
06/06/2022 09:00:39 - INFO - __main__ - Saving model with best Classification-F1: 0.718904303581723 -> 0.7313805282555282 on epoch=224, global_step=900
06/06/2022 09:00:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=227
06/06/2022 09:00:44 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=229
06/06/2022 09:00:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=232
06/06/2022 09:00:49 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
06/06/2022 09:00:52 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=237
06/06/2022 09:00:53 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.7130855594270228 on epoch=237
06/06/2022 09:00:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
06/06/2022 09:00:58 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=242
06/06/2022 09:01:01 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=244
06/06/2022 09:01:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=247
06/06/2022 09:01:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=249
06/06/2022 09:01:07 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.6618552292894397 on epoch=249
06/06/2022 09:01:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
06/06/2022 09:01:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=254
06/06/2022 09:01:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=257
06/06/2022 09:01:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
06/06/2022 09:01:20 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
06/06/2022 09:01:21 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.6599208965062623 on epoch=262
06/06/2022 09:01:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=264
06/06/2022 09:01:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
06/06/2022 09:01:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
06/06/2022 09:01:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/06/2022 09:01:34 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/06/2022 09:01:35 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7247512528584635 on epoch=274
06/06/2022 09:01:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=277
06/06/2022 09:01:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/06/2022 09:01:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/06/2022 09:01:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/06/2022 09:01:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=287
06/06/2022 09:01:49 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.6606060606060606 on epoch=287
06/06/2022 09:01:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=289
06/06/2022 09:01:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=292
06/06/2022 09:01:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/06/2022 09:02:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=297
06/06/2022 09:02:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=299
06/06/2022 09:02:04 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.6899044795783926 on epoch=299
06/06/2022 09:02:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=302
06/06/2022 09:02:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=304
06/06/2022 09:02:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/06/2022 09:02:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/06/2022 09:02:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/06/2022 09:02:18 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.7584962406015038 on epoch=312
06/06/2022 09:02:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7313805282555282 -> 0.7584962406015038 on epoch=312, global_step=1250
06/06/2022 09:02:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/06/2022 09:02:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/06/2022 09:02:25 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=319
06/06/2022 09:02:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=322
06/06/2022 09:02:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=324
06/06/2022 09:02:32 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.6963578797195096 on epoch=324
06/06/2022 09:02:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/06/2022 09:02:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=329
06/06/2022 09:02:39 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/06/2022 09:02:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/06/2022 09:02:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/06/2022 09:02:46 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7034703491926493 on epoch=337
06/06/2022 09:02:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=339
06/06/2022 09:02:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
06/06/2022 09:02:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=344
06/06/2022 09:02:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=347
06/06/2022 09:02:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/06/2022 09:03:00 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6763440860215054 on epoch=349
06/06/2022 09:03:02 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=352
06/06/2022 09:03:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=354
06/06/2022 09:03:07 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=357
06/06/2022 09:03:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/06/2022 09:03:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/06/2022 09:03:14 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.6809942387528595 on epoch=362
06/06/2022 09:03:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/06/2022 09:03:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=367
06/06/2022 09:03:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=369
06/06/2022 09:03:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/06/2022 09:03:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/06/2022 09:03:28 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7203709893048129 on epoch=374
06/06/2022 09:03:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/06/2022 09:03:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
06/06/2022 09:03:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=382
06/06/2022 09:03:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=384
06/06/2022 09:03:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/06/2022 09:03:42 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7047846889952153 on epoch=387
06/06/2022 09:03:45 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/06/2022 09:03:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/06/2022 09:03:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=394
06/06/2022 09:03:53 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=397
06/06/2022 09:03:55 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/06/2022 09:03:56 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7324938574938575 on epoch=399
06/06/2022 09:03:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=402
06/06/2022 09:04:02 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/06/2022 09:04:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/06/2022 09:04:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/06/2022 09:04:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/06/2022 09:04:11 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7502007933385786 on epoch=412
06/06/2022 09:04:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/06/2022 09:04:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=417
06/06/2022 09:04:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/06/2022 09:04:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/06/2022 09:04:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/06/2022 09:04:25 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7600754147812971 on epoch=424
06/06/2022 09:04:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7584962406015038 -> 0.7600754147812971 on epoch=424, global_step=1700
06/06/2022 09:04:28 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/06/2022 09:04:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/06/2022 09:04:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/06/2022 09:04:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
06/06/2022 09:04:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/06/2022 09:04:39 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.6885110076540677 on epoch=437
06/06/2022 09:04:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/06/2022 09:04:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/06/2022 09:04:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/06/2022 09:04:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
06/06/2022 09:04:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/06/2022 09:04:54 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7353267700041894 on epoch=449
06/06/2022 09:04:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/06/2022 09:04:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/06/2022 09:05:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/06/2022 09:05:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/06/2022 09:05:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/06/2022 09:05:08 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6731004484075565 on epoch=462
06/06/2022 09:05:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/06/2022 09:05:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/06/2022 09:05:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/06/2022 09:05:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/06/2022 09:05:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/06/2022 09:05:22 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.671969696969697 on epoch=474
06/06/2022 09:05:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=477
06/06/2022 09:05:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/06/2022 09:05:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/06/2022 09:05:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/06/2022 09:05:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.09 on epoch=487
06/06/2022 09:05:37 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6807928913192072 on epoch=487
06/06/2022 09:05:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/06/2022 09:05:42 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/06/2022 09:05:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/06/2022 09:05:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/06/2022 09:05:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/06/2022 09:05:51 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7085326024754337 on epoch=499
06/06/2022 09:05:53 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/06/2022 09:05:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/06/2022 09:05:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/06/2022 09:06:01 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=509
06/06/2022 09:06:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/06/2022 09:06:05 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6990842490842492 on epoch=512
06/06/2022 09:06:08 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/06/2022 09:06:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=517
06/06/2022 09:06:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/06/2022 09:06:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=522
06/06/2022 09:06:18 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/06/2022 09:06:19 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7085483870967743 on epoch=524
06/06/2022 09:06:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/06/2022 09:06:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/06/2022 09:06:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/06/2022 09:06:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/06/2022 09:06:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/06/2022 09:06:34 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7081882302470539 on epoch=537
06/06/2022 09:06:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/06/2022 09:06:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/06/2022 09:06:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/06/2022 09:06:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/06/2022 09:06:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/06/2022 09:06:48 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6954032809295968 on epoch=549
06/06/2022 09:06:50 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 09:06:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/06/2022 09:06:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/06/2022 09:06:58 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/06/2022 09:07:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/06/2022 09:07:02 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7249417249417249 on epoch=562
06/06/2022 09:07:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/06/2022 09:07:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=567
06/06/2022 09:07:10 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/06/2022 09:07:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/06/2022 09:07:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 09:07:16 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7217489287735468 on epoch=574
06/06/2022 09:07:19 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/06/2022 09:07:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 09:07:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/06/2022 09:07:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/06/2022 09:07:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 09:07:30 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7539423716230824 on epoch=587
06/06/2022 09:07:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/06/2022 09:07:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/06/2022 09:07:38 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 09:07:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/06/2022 09:07:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 09:07:44 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7344468390804597 on epoch=599
06/06/2022 09:07:47 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=602
06/06/2022 09:07:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 09:07:52 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/06/2022 09:07:54 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 09:07:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/06/2022 09:07:58 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7539423716230824 on epoch=612
06/06/2022 09:08:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 09:08:03 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 09:08:06 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=619
06/06/2022 09:08:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=622
06/06/2022 09:08:11 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 09:08:12 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7073423423423424 on epoch=624
06/06/2022 09:08:15 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/06/2022 09:08:17 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/06/2022 09:08:20 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=632
06/06/2022 09:08:23 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=634
06/06/2022 09:08:25 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 09:08:26 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7095606663718119 on epoch=637
06/06/2022 09:08:29 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 09:08:31 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/06/2022 09:08:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
06/06/2022 09:08:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/06/2022 09:08:39 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 09:08:40 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6858089826839827 on epoch=649
06/06/2022 09:08:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/06/2022 09:08:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 09:08:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=657
06/06/2022 09:08:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 09:08:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 09:08:55 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6748119152353024 on epoch=662
06/06/2022 09:08:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 09:09:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=667
06/06/2022 09:09:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 09:09:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 09:09:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 09:09:09 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7249417249417249 on epoch=674
06/06/2022 09:09:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/06/2022 09:09:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/06/2022 09:09:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 09:09:19 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.14 on epoch=684
06/06/2022 09:09:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 09:09:23 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6776458041140719 on epoch=687
06/06/2022 09:09:26 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 09:09:28 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.10 on epoch=692
06/06/2022 09:09:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/06/2022 09:09:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 09:09:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 09:09:37 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6988702354556013 on epoch=699
06/06/2022 09:09:40 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 09:09:43 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 09:09:45 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/06/2022 09:09:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/06/2022 09:09:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 09:09:51 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7141144716996111 on epoch=712
06/06/2022 09:09:54 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 09:09:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/06/2022 09:09:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 09:10:02 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/06/2022 09:10:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 09:10:06 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7249417249417249 on epoch=724
06/06/2022 09:10:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 09:10:11 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 09:10:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=732
06/06/2022 09:10:16 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=734
06/06/2022 09:10:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 09:10:20 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6943053197509904 on epoch=737
06/06/2022 09:10:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 09:10:25 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/06/2022 09:10:28 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 09:10:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/06/2022 09:10:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/06/2022 09:10:34 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7191484985602632 on epoch=749
06/06/2022 09:10:34 - INFO - __main__ - save last model!
06/06/2022 09:10:34 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 09:10:34 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 09:10:34 - INFO - __main__ - Printing 3 examples
06/06/2022 09:10:34 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 09:10:34 - INFO - __main__ - ['others']
06/06/2022 09:10:34 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 09:10:34 - INFO - __main__ - ['others']
06/06/2022 09:10:34 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 09:10:34 - INFO - __main__ - ['others']
06/06/2022 09:10:34 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:10:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 09:10:34 - INFO - __main__ - Printing 3 examples
06/06/2022 09:10:34 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/06/2022 09:10:34 - INFO - __main__ - ['happy']
06/06/2022 09:10:34 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/06/2022 09:10:34 - INFO - __main__ - ['happy']
06/06/2022 09:10:34 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/06/2022 09:10:34 - INFO - __main__ - ['happy']
06/06/2022 09:10:34 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:10:34 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:10:34 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 09:10:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 09:10:34 - INFO - __main__ - Printing 3 examples
06/06/2022 09:10:34 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/06/2022 09:10:34 - INFO - __main__ - ['happy']
06/06/2022 09:10:34 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/06/2022 09:10:34 - INFO - __main__ - ['happy']
06/06/2022 09:10:34 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/06/2022 09:10:34 - INFO - __main__ - ['happy']
06/06/2022 09:10:34 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:10:34 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:10:34 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 09:10:36 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:10:41 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 09:10:51 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 09:10:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 09:10:51 - INFO - __main__ - Starting training!
06/06/2022 09:12:19 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_21_0.2_8_predictions.txt
06/06/2022 09:12:19 - INFO - __main__ - Classification-F1 on test data: 0.1571
06/06/2022 09:12:20 - INFO - __main__ - prefix=emo_16_21, lr=0.2, bsz=8, dev_performance=0.7600754147812971, test_performance=0.15708134832835427
06/06/2022 09:12:20 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.5, bsz=8 ...
06/06/2022 09:12:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 09:12:21 - INFO - __main__ - Printing 3 examples
06/06/2022 09:12:21 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/06/2022 09:12:21 - INFO - __main__ - ['happy']
06/06/2022 09:12:21 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/06/2022 09:12:21 - INFO - __main__ - ['happy']
06/06/2022 09:12:21 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/06/2022 09:12:21 - INFO - __main__ - ['happy']
06/06/2022 09:12:21 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:12:21 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:12:21 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 09:12:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 09:12:21 - INFO - __main__ - Printing 3 examples
06/06/2022 09:12:21 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/06/2022 09:12:21 - INFO - __main__ - ['happy']
06/06/2022 09:12:21 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/06/2022 09:12:21 - INFO - __main__ - ['happy']
06/06/2022 09:12:21 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/06/2022 09:12:21 - INFO - __main__ - ['happy']
06/06/2022 09:12:21 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:12:21 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:12:21 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 09:12:40 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 09:12:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 09:12:40 - INFO - __main__ - Starting training!
06/06/2022 09:12:43 - INFO - __main__ - Step 10 Global step 10 Train loss 3.66 on epoch=2
06/06/2022 09:12:46 - INFO - __main__ - Step 20 Global step 20 Train loss 2.02 on epoch=4
06/06/2022 09:12:49 - INFO - __main__ - Step 30 Global step 30 Train loss 1.14 on epoch=7
06/06/2022 09:12:51 - INFO - __main__ - Step 40 Global step 40 Train loss 1.05 on epoch=9
06/06/2022 09:12:54 - INFO - __main__ - Step 50 Global step 50 Train loss 1.01 on epoch=12
06/06/2022 09:12:55 - INFO - __main__ - Global step 50 Train loss 1.78 Classification-F1 0.26933551198257083 on epoch=12
06/06/2022 09:12:55 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.26933551198257083 on epoch=12, global_step=50
06/06/2022 09:12:57 - INFO - __main__ - Step 60 Global step 60 Train loss 0.90 on epoch=14
06/06/2022 09:13:00 - INFO - __main__ - Step 70 Global step 70 Train loss 0.97 on epoch=17
06/06/2022 09:13:03 - INFO - __main__ - Step 80 Global step 80 Train loss 0.86 on epoch=19
06/06/2022 09:13:05 - INFO - __main__ - Step 90 Global step 90 Train loss 0.77 on epoch=22
06/06/2022 09:13:08 - INFO - __main__ - Step 100 Global step 100 Train loss 0.72 on epoch=24
06/06/2022 09:13:09 - INFO - __main__ - Global step 100 Train loss 0.84 Classification-F1 0.46193609022556387 on epoch=24
06/06/2022 09:13:09 - INFO - __main__ - Saving model with best Classification-F1: 0.26933551198257083 -> 0.46193609022556387 on epoch=24, global_step=100
06/06/2022 09:13:12 - INFO - __main__ - Step 110 Global step 110 Train loss 0.73 on epoch=27
06/06/2022 09:13:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.67 on epoch=29
06/06/2022 09:13:17 - INFO - __main__ - Step 130 Global step 130 Train loss 0.60 on epoch=32
06/06/2022 09:13:20 - INFO - __main__ - Step 140 Global step 140 Train loss 0.68 on epoch=34
06/06/2022 09:13:22 - INFO - __main__ - Step 150 Global step 150 Train loss 0.53 on epoch=37
06/06/2022 09:13:23 - INFO - __main__ - Global step 150 Train loss 0.64 Classification-F1 0.5354601518026566 on epoch=37
06/06/2022 09:13:23 - INFO - __main__ - Saving model with best Classification-F1: 0.46193609022556387 -> 0.5354601518026566 on epoch=37, global_step=150
06/06/2022 09:13:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.61 on epoch=39
06/06/2022 09:13:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.56 on epoch=42
06/06/2022 09:13:31 - INFO - __main__ - Step 180 Global step 180 Train loss 0.58 on epoch=44
06/06/2022 09:13:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.49 on epoch=47
06/06/2022 09:13:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.53 on epoch=49
06/06/2022 09:13:37 - INFO - __main__ - Global step 200 Train loss 0.56 Classification-F1 0.717503078817734 on epoch=49
06/06/2022 09:13:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5354601518026566 -> 0.717503078817734 on epoch=49, global_step=200
06/06/2022 09:13:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.56 on epoch=52
06/06/2022 09:13:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.43 on epoch=54
06/06/2022 09:13:45 - INFO - __main__ - Step 230 Global step 230 Train loss 0.48 on epoch=57
06/06/2022 09:13:47 - INFO - __main__ - Step 240 Global step 240 Train loss 0.43 on epoch=59
06/06/2022 09:13:50 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=62
06/06/2022 09:13:51 - INFO - __main__ - Global step 250 Train loss 0.45 Classification-F1 0.6520183866731182 on epoch=62
06/06/2022 09:13:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.35 on epoch=64
06/06/2022 09:13:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.39 on epoch=67
06/06/2022 09:13:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.41 on epoch=69
06/06/2022 09:14:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.33 on epoch=72
06/06/2022 09:14:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.33 on epoch=74
06/06/2022 09:14:04 - INFO - __main__ - Global step 300 Train loss 0.36 Classification-F1 0.7185574229691876 on epoch=74
06/06/2022 09:14:04 - INFO - __main__ - Saving model with best Classification-F1: 0.717503078817734 -> 0.7185574229691876 on epoch=74, global_step=300
06/06/2022 09:14:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.27 on epoch=77
06/06/2022 09:14:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=79
06/06/2022 09:14:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=82
06/06/2022 09:14:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.32 on epoch=84
06/06/2022 09:14:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=87
06/06/2022 09:14:19 - INFO - __main__ - Global step 350 Train loss 0.27 Classification-F1 0.7009900370300814 on epoch=87
06/06/2022 09:14:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.25 on epoch=89
06/06/2022 09:14:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=92
06/06/2022 09:14:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=94
06/06/2022 09:14:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.15 on epoch=97
06/06/2022 09:14:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.13 on epoch=99
06/06/2022 09:14:33 - INFO - __main__ - Global step 400 Train loss 0.19 Classification-F1 0.7008212375859435 on epoch=99
06/06/2022 09:14:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.15 on epoch=102
06/06/2022 09:14:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.10 on epoch=104
06/06/2022 09:14:40 - INFO - __main__ - Step 430 Global step 430 Train loss 0.16 on epoch=107
06/06/2022 09:14:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.15 on epoch=109
06/06/2022 09:14:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.10 on epoch=112
06/06/2022 09:14:46 - INFO - __main__ - Global step 450 Train loss 0.13 Classification-F1 0.7178887034977135 on epoch=112
06/06/2022 09:14:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=114
06/06/2022 09:14:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=117
06/06/2022 09:14:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.09 on epoch=119
06/06/2022 09:14:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.08 on epoch=122
06/06/2022 09:14:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.09 on epoch=124
06/06/2022 09:15:00 - INFO - __main__ - Global step 500 Train loss 0.13 Classification-F1 0.6527458492975735 on epoch=124
06/06/2022 09:15:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.09 on epoch=127
06/06/2022 09:15:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.12 on epoch=129
06/06/2022 09:15:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=132
06/06/2022 09:15:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=134
06/06/2022 09:15:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=137
06/06/2022 09:15:14 - INFO - __main__ - Global step 550 Train loss 0.10 Classification-F1 0.7270604395604396 on epoch=137
06/06/2022 09:15:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7185574229691876 -> 0.7270604395604396 on epoch=137, global_step=550
06/06/2022 09:15:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=139
06/06/2022 09:15:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=142
06/06/2022 09:15:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.09 on epoch=144
06/06/2022 09:15:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.07 on epoch=147
06/06/2022 09:15:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=149
06/06/2022 09:15:28 - INFO - __main__ - Global step 600 Train loss 0.09 Classification-F1 0.7785714285714286 on epoch=149
06/06/2022 09:15:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7270604395604396 -> 0.7785714285714286 on epoch=149, global_step=600
06/06/2022 09:15:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=152
06/06/2022 09:15:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=154
06/06/2022 09:15:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=157
06/06/2022 09:15:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=159
06/06/2022 09:15:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=162
06/06/2022 09:15:42 - INFO - __main__ - Global step 650 Train loss 0.07 Classification-F1 0.7364283638477186 on epoch=162
06/06/2022 09:15:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=164
06/06/2022 09:15:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=167
06/06/2022 09:15:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=169
06/06/2022 09:15:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=172
06/06/2022 09:15:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=174
06/06/2022 09:15:56 - INFO - __main__ - Global step 700 Train loss 0.07 Classification-F1 0.7287984006734007 on epoch=174
06/06/2022 09:15:59 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=177
06/06/2022 09:16:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=179
06/06/2022 09:16:04 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=182
06/06/2022 09:16:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=184
06/06/2022 09:16:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=187
06/06/2022 09:16:10 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.7967986314760509 on epoch=187
06/06/2022 09:16:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7785714285714286 -> 0.7967986314760509 on epoch=187, global_step=750
06/06/2022 09:16:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=189
06/06/2022 09:16:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=192
06/06/2022 09:16:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=194
06/06/2022 09:16:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=197
06/06/2022 09:16:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/06/2022 09:16:24 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.7652462121212121 on epoch=199
06/06/2022 09:16:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=202
06/06/2022 09:16:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/06/2022 09:16:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
06/06/2022 09:16:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=209
06/06/2022 09:16:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=212
06/06/2022 09:16:38 - INFO - __main__ - Global step 850 Train loss 0.02 Classification-F1 0.8128971163245358 on epoch=212
06/06/2022 09:16:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7967986314760509 -> 0.8128971163245358 on epoch=212, global_step=850
06/06/2022 09:16:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=214
06/06/2022 09:16:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/06/2022 09:16:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
06/06/2022 09:16:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.00 on epoch=222
06/06/2022 09:16:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=224
06/06/2022 09:16:52 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7204545454545453 on epoch=224
06/06/2022 09:16:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=227
06/06/2022 09:16:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=229
06/06/2022 09:17:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
06/06/2022 09:17:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/06/2022 09:17:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=237
06/06/2022 09:17:06 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.8447261663286003 on epoch=237
06/06/2022 09:17:06 - INFO - __main__ - Saving model with best Classification-F1: 0.8128971163245358 -> 0.8447261663286003 on epoch=237, global_step=950
06/06/2022 09:17:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=239
06/06/2022 09:17:11 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/06/2022 09:17:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=244
06/06/2022 09:17:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
06/06/2022 09:17:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/06/2022 09:17:20 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.7945658866995073 on epoch=249
06/06/2022 09:17:22 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=252
06/06/2022 09:17:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/06/2022 09:17:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=257
06/06/2022 09:17:30 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=259
06/06/2022 09:17:33 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=262
06/06/2022 09:17:34 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.7650140518084066 on epoch=262
06/06/2022 09:17:36 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/06/2022 09:17:39 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/06/2022 09:17:42 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=269
06/06/2022 09:17:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/06/2022 09:17:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=274
06/06/2022 09:17:48 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.7578616912233211 on epoch=274
06/06/2022 09:17:50 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/06/2022 09:17:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/06/2022 09:17:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/06/2022 09:17:58 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=284
06/06/2022 09:18:01 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/06/2022 09:18:02 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7905597722960153 on epoch=287
06/06/2022 09:18:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=289
06/06/2022 09:18:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/06/2022 09:18:09 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/06/2022 09:18:12 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/06/2022 09:18:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/06/2022 09:18:16 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.7597402597402597 on epoch=299
06/06/2022 09:18:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/06/2022 09:18:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/06/2022 09:18:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/06/2022 09:18:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/06/2022 09:18:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/06/2022 09:18:30 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.777529761904762 on epoch=312
06/06/2022 09:18:32 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/06/2022 09:18:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=317
06/06/2022 09:18:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/06/2022 09:18:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/06/2022 09:18:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/06/2022 09:18:44 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.7781634024577573 on epoch=324
06/06/2022 09:18:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/06/2022 09:18:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/06/2022 09:18:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/06/2022 09:18:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/06/2022 09:18:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/06/2022 09:18:58 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.7602150537634409 on epoch=337
06/06/2022 09:19:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/06/2022 09:19:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/06/2022 09:19:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/06/2022 09:19:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/06/2022 09:19:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/06/2022 09:19:12 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7778361344537815 on epoch=349
06/06/2022 09:19:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/06/2022 09:19:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/06/2022 09:19:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=357
06/06/2022 09:19:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/06/2022 09:19:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/06/2022 09:19:26 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7965245417831625 on epoch=362
06/06/2022 09:19:29 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/06/2022 09:19:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/06/2022 09:19:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/06/2022 09:19:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=372
06/06/2022 09:19:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/06/2022 09:19:40 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.747104247104247 on epoch=374
06/06/2022 09:19:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/06/2022 09:19:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/06/2022 09:19:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/06/2022 09:19:50 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/06/2022 09:19:53 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/06/2022 09:19:54 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7785714285714286 on epoch=387
06/06/2022 09:19:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/06/2022 09:19:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/06/2022 09:20:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/06/2022 09:20:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/06/2022 09:20:07 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/06/2022 09:20:08 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.746907591559544 on epoch=399
06/06/2022 09:20:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/06/2022 09:20:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/06/2022 09:20:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/06/2022 09:20:19 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/06/2022 09:20:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/06/2022 09:20:22 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.7781951085621831 on epoch=412
06/06/2022 09:20:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/06/2022 09:20:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/06/2022 09:20:30 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/06/2022 09:20:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/06/2022 09:20:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/06/2022 09:20:36 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.7791500359876988 on epoch=424
06/06/2022 09:20:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/06/2022 09:20:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/06/2022 09:20:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/06/2022 09:20:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/06/2022 09:20:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/06/2022 09:20:50 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7443693693693694 on epoch=437
06/06/2022 09:20:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/06/2022 09:20:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/06/2022 09:20:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/06/2022 09:21:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/06/2022 09:21:03 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/06/2022 09:21:04 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7471408430143218 on epoch=449
06/06/2022 09:21:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/06/2022 09:21:09 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/06/2022 09:21:12 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/06/2022 09:21:14 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/06/2022 09:21:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=462
06/06/2022 09:21:18 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.8149356137439302 on epoch=462
06/06/2022 09:21:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/06/2022 09:21:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/06/2022 09:21:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/06/2022 09:21:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/06/2022 09:21:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/06/2022 09:21:32 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.7639093942764688 on epoch=474
06/06/2022 09:21:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/06/2022 09:21:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/06/2022 09:21:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/06/2022 09:21:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/06/2022 09:21:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/06/2022 09:21:46 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7965245417831625 on epoch=487
06/06/2022 09:21:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=489
06/06/2022 09:21:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/06/2022 09:21:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/06/2022 09:21:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/06/2022 09:21:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=499
06/06/2022 09:21:59 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7660663410663411 on epoch=499
06/06/2022 09:22:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/06/2022 09:22:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/06/2022 09:22:07 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/06/2022 09:22:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/06/2022 09:22:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/06/2022 09:22:14 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.7975490196078432 on epoch=512
06/06/2022 09:22:16 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/06/2022 09:22:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/06/2022 09:22:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/06/2022 09:22:24 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/06/2022 09:22:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/06/2022 09:22:28 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7303030303030302 on epoch=524
06/06/2022 09:22:30 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/06/2022 09:22:33 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 09:22:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=532
06/06/2022 09:22:38 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/06/2022 09:22:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/06/2022 09:22:42 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.814336917562724 on epoch=537
06/06/2022 09:22:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/06/2022 09:22:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 09:22:49 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/06/2022 09:22:52 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/06/2022 09:22:54 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/06/2022 09:22:55 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7990020380912222 on epoch=549
06/06/2022 09:22:58 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=552
06/06/2022 09:23:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/06/2022 09:23:03 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/06/2022 09:23:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/06/2022 09:23:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/06/2022 09:23:09 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7422631422631423 on epoch=562
06/06/2022 09:23:12 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/06/2022 09:23:14 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/06/2022 09:23:17 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/06/2022 09:23:19 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/06/2022 09:23:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=574
06/06/2022 09:23:23 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7312378167641325 on epoch=574
06/06/2022 09:23:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 09:23:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 09:23:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/06/2022 09:23:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/06/2022 09:23:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 09:23:37 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7242618492618493 on epoch=587
06/06/2022 09:23:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/06/2022 09:23:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/06/2022 09:23:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 09:23:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/06/2022 09:23:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 09:23:51 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7394567384370017 on epoch=599
06/06/2022 09:23:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 09:23:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 09:23:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 09:24:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 09:24:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 09:24:05 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7784003630777824 on epoch=612
06/06/2022 09:24:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 09:24:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 09:24:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 09:24:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/06/2022 09:24:18 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 09:24:19 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7317216567216567 on epoch=624
06/06/2022 09:24:22 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/06/2022 09:24:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/06/2022 09:24:27 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/06/2022 09:24:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/06/2022 09:24:32 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/06/2022 09:24:33 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7981060606060606 on epoch=637
06/06/2022 09:24:36 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 09:24:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=642
06/06/2022 09:24:41 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 09:24:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 09:24:46 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
06/06/2022 09:24:47 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7619883437245867 on epoch=649
06/06/2022 09:24:50 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/06/2022 09:24:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=654
06/06/2022 09:24:55 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 09:24:57 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 09:25:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 09:25:01 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7103215121041946 on epoch=662
06/06/2022 09:25:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 09:25:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 09:25:09 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 09:25:12 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 09:25:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 09:25:15 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7244515341289535 on epoch=674
06/06/2022 09:25:18 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/06/2022 09:25:20 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 09:25:23 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 09:25:26 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/06/2022 09:25:28 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 09:25:29 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6950190889619202 on epoch=687
06/06/2022 09:25:32 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 09:25:35 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/06/2022 09:25:37 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/06/2022 09:25:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 09:25:43 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 09:25:44 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7246830286168522 on epoch=699
06/06/2022 09:25:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 09:25:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 09:25:52 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 09:25:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/06/2022 09:25:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 09:25:59 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7236805555555555 on epoch=712
06/06/2022 09:26:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 09:26:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 09:26:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 09:26:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/06/2022 09:26:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 09:26:13 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7232582582582583 on epoch=724
06/06/2022 09:26:16 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
06/06/2022 09:26:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 09:26:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 09:26:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 09:26:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 09:26:28 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.730044699872286 on epoch=737
06/06/2022 09:26:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 09:26:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/06/2022 09:26:36 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 09:26:38 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/06/2022 09:26:41 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/06/2022 09:26:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 09:26:42 - INFO - __main__ - Printing 3 examples
06/06/2022 09:26:42 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/06/2022 09:26:42 - INFO - __main__ - ['happy']
06/06/2022 09:26:42 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/06/2022 09:26:42 - INFO - __main__ - ['happy']
06/06/2022 09:26:42 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/06/2022 09:26:42 - INFO - __main__ - ['happy']
06/06/2022 09:26:42 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:26:42 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:26:42 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 09:26:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 09:26:42 - INFO - __main__ - Printing 3 examples
06/06/2022 09:26:42 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/06/2022 09:26:42 - INFO - __main__ - ['happy']
06/06/2022 09:26:42 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/06/2022 09:26:42 - INFO - __main__ - ['happy']
06/06/2022 09:26:42 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/06/2022 09:26:42 - INFO - __main__ - ['happy']
06/06/2022 09:26:42 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:26:42 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:26:42 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 09:26:43 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7638188608776845 on epoch=749
06/06/2022 09:26:43 - INFO - __main__ - save last model!
06/06/2022 09:26:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 09:26:43 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 09:26:43 - INFO - __main__ - Printing 3 examples
06/06/2022 09:26:43 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 09:26:43 - INFO - __main__ - ['others']
06/06/2022 09:26:43 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 09:26:43 - INFO - __main__ - ['others']
06/06/2022 09:26:43 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 09:26:43 - INFO - __main__ - ['others']
06/06/2022 09:26:43 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:26:45 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:26:51 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 09:27:01 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 09:27:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 09:27:02 - INFO - __main__ - Starting training!
06/06/2022 09:28:45 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_42_0.5_8_predictions.txt
06/06/2022 09:28:45 - INFO - __main__ - Classification-F1 on test data: 0.4323
06/06/2022 09:28:45 - INFO - __main__ - prefix=emo_16_42, lr=0.5, bsz=8, dev_performance=0.8447261663286003, test_performance=0.43233877247425123
06/06/2022 09:28:45 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.4, bsz=8 ...
06/06/2022 09:28:46 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 09:28:46 - INFO - __main__ - Printing 3 examples
06/06/2022 09:28:46 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/06/2022 09:28:46 - INFO - __main__ - ['happy']
06/06/2022 09:28:46 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/06/2022 09:28:46 - INFO - __main__ - ['happy']
06/06/2022 09:28:46 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/06/2022 09:28:46 - INFO - __main__ - ['happy']
06/06/2022 09:28:46 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:28:46 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:28:46 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 09:28:46 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 09:28:46 - INFO - __main__ - Printing 3 examples
06/06/2022 09:28:46 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/06/2022 09:28:46 - INFO - __main__ - ['happy']
06/06/2022 09:28:46 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/06/2022 09:28:46 - INFO - __main__ - ['happy']
06/06/2022 09:28:46 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/06/2022 09:28:46 - INFO - __main__ - ['happy']
06/06/2022 09:28:46 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:28:46 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:28:46 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 09:29:05 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 09:29:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 09:29:06 - INFO - __main__ - Starting training!
06/06/2022 09:29:09 - INFO - __main__ - Step 10 Global step 10 Train loss 3.51 on epoch=2
06/06/2022 09:29:11 - INFO - __main__ - Step 20 Global step 20 Train loss 2.07 on epoch=4
06/06/2022 09:29:14 - INFO - __main__ - Step 30 Global step 30 Train loss 1.26 on epoch=7
06/06/2022 09:29:16 - INFO - __main__ - Step 40 Global step 40 Train loss 1.08 on epoch=9
06/06/2022 09:29:19 - INFO - __main__ - Step 50 Global step 50 Train loss 1.03 on epoch=12
06/06/2022 09:29:20 - INFO - __main__ - Global step 50 Train loss 1.79 Classification-F1 0.39640382317801676 on epoch=12
06/06/2022 09:29:20 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.39640382317801676 on epoch=12, global_step=50
06/06/2022 09:29:23 - INFO - __main__ - Step 60 Global step 60 Train loss 1.05 on epoch=14
06/06/2022 09:29:25 - INFO - __main__ - Step 70 Global step 70 Train loss 1.00 on epoch=17
06/06/2022 09:29:28 - INFO - __main__ - Step 80 Global step 80 Train loss 0.92 on epoch=19
06/06/2022 09:29:31 - INFO - __main__ - Step 90 Global step 90 Train loss 0.96 on epoch=22
06/06/2022 09:29:33 - INFO - __main__ - Step 100 Global step 100 Train loss 0.81 on epoch=24
06/06/2022 09:29:34 - INFO - __main__ - Global step 100 Train loss 0.95 Classification-F1 0.4486293859649123 on epoch=24
06/06/2022 09:29:34 - INFO - __main__ - Saving model with best Classification-F1: 0.39640382317801676 -> 0.4486293859649123 on epoch=24, global_step=100
06/06/2022 09:29:37 - INFO - __main__ - Step 110 Global step 110 Train loss 0.75 on epoch=27
06/06/2022 09:29:39 - INFO - __main__ - Step 120 Global step 120 Train loss 0.79 on epoch=29
06/06/2022 09:29:42 - INFO - __main__ - Step 130 Global step 130 Train loss 0.74 on epoch=32
06/06/2022 09:29:45 - INFO - __main__ - Step 140 Global step 140 Train loss 0.71 on epoch=34
06/06/2022 09:29:47 - INFO - __main__ - Step 150 Global step 150 Train loss 0.68 on epoch=37
06/06/2022 09:29:48 - INFO - __main__ - Global step 150 Train loss 0.73 Classification-F1 0.5693694682173944 on epoch=37
06/06/2022 09:29:48 - INFO - __main__ - Saving model with best Classification-F1: 0.4486293859649123 -> 0.5693694682173944 on epoch=37, global_step=150
06/06/2022 09:29:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.74 on epoch=39
06/06/2022 09:29:53 - INFO - __main__ - Step 170 Global step 170 Train loss 0.63 on epoch=42
06/06/2022 09:29:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.72 on epoch=44
06/06/2022 09:29:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.60 on epoch=47
06/06/2022 09:30:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.67 on epoch=49
06/06/2022 09:30:02 - INFO - __main__ - Global step 200 Train loss 0.67 Classification-F1 0.5623989923976319 on epoch=49
06/06/2022 09:30:05 - INFO - __main__ - Step 210 Global step 210 Train loss 0.54 on epoch=52
06/06/2022 09:30:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.54 on epoch=54
06/06/2022 09:30:10 - INFO - __main__ - Step 230 Global step 230 Train loss 0.56 on epoch=57
06/06/2022 09:30:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.62 on epoch=59
06/06/2022 09:30:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.51 on epoch=62
06/06/2022 09:30:16 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.6107991753577493 on epoch=62
06/06/2022 09:30:16 - INFO - __main__ - Saving model with best Classification-F1: 0.5693694682173944 -> 0.6107991753577493 on epoch=62, global_step=250
06/06/2022 09:30:19 - INFO - __main__ - Step 260 Global step 260 Train loss 0.51 on epoch=64
06/06/2022 09:30:21 - INFO - __main__ - Step 270 Global step 270 Train loss 0.38 on epoch=67
06/06/2022 09:30:24 - INFO - __main__ - Step 280 Global step 280 Train loss 0.48 on epoch=69
06/06/2022 09:30:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.43 on epoch=72
06/06/2022 09:30:29 - INFO - __main__ - Step 300 Global step 300 Train loss 0.43 on epoch=74
06/06/2022 09:30:30 - INFO - __main__ - Global step 300 Train loss 0.44 Classification-F1 0.6866401802656547 on epoch=74
06/06/2022 09:30:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6107991753577493 -> 0.6866401802656547 on epoch=74, global_step=300
06/06/2022 09:30:33 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=77
06/06/2022 09:30:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.49 on epoch=79
06/06/2022 09:30:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.35 on epoch=82
06/06/2022 09:30:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.50 on epoch=84
06/06/2022 09:30:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=87
06/06/2022 09:30:44 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.6830203201970444 on epoch=87
06/06/2022 09:30:46 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=89
06/06/2022 09:30:49 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=92
06/06/2022 09:30:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=94
06/06/2022 09:30:54 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=97
06/06/2022 09:30:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=99
06/06/2022 09:30:58 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.6648809523809525 on epoch=99
06/06/2022 09:31:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=102
06/06/2022 09:31:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/06/2022 09:31:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=107
06/06/2022 09:31:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=109
06/06/2022 09:31:11 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=112
06/06/2022 09:31:12 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.6783771929824562 on epoch=112
06/06/2022 09:31:14 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=114
06/06/2022 09:31:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=117
06/06/2022 09:31:19 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=119
06/06/2022 09:31:22 - INFO - __main__ - Step 490 Global step 490 Train loss 0.13 on epoch=122
06/06/2022 09:31:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=124
06/06/2022 09:31:25 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.7136886102403344 on epoch=124
06/06/2022 09:31:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6866401802656547 -> 0.7136886102403344 on epoch=124, global_step=500
06/06/2022 09:31:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=127
06/06/2022 09:31:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.16 on epoch=129
06/06/2022 09:31:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=132
06/06/2022 09:31:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=134
06/06/2022 09:31:39 - INFO - __main__ - Step 550 Global step 550 Train loss 0.08 on epoch=137
06/06/2022 09:31:40 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.7686059907834102 on epoch=137
06/06/2022 09:31:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7136886102403344 -> 0.7686059907834102 on epoch=137, global_step=550
06/06/2022 09:31:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=139
06/06/2022 09:31:45 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=142
06/06/2022 09:31:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=144
06/06/2022 09:31:50 - INFO - __main__ - Step 590 Global step 590 Train loss 0.09 on epoch=147
06/06/2022 09:31:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=149
06/06/2022 09:31:53 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.712821492233257 on epoch=149
06/06/2022 09:31:56 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=152
06/06/2022 09:31:59 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=154
06/06/2022 09:32:01 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=157
06/06/2022 09:32:04 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=159
06/06/2022 09:32:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=162
06/06/2022 09:32:07 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.7096453859321507 on epoch=162
06/06/2022 09:32:10 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=164
06/06/2022 09:32:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=167
06/06/2022 09:32:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=169
06/06/2022 09:32:17 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=172
06/06/2022 09:32:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=174
06/06/2022 09:32:21 - INFO - __main__ - Global step 700 Train loss 0.07 Classification-F1 0.7522118369291291 on epoch=174
06/06/2022 09:32:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=177
06/06/2022 09:32:26 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=179
06/06/2022 09:32:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=182
06/06/2022 09:32:31 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=184
06/06/2022 09:32:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=187
06/06/2022 09:32:35 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.7667613636363635 on epoch=187
06/06/2022 09:32:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=189
06/06/2022 09:32:40 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=192
06/06/2022 09:32:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=194
06/06/2022 09:32:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=197
06/06/2022 09:32:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
06/06/2022 09:32:49 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.7140506868891757 on epoch=199
06/06/2022 09:32:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=202
06/06/2022 09:32:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=204
06/06/2022 09:32:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=207
06/06/2022 09:33:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
06/06/2022 09:33:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=212
06/06/2022 09:33:04 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.693800752624282 on epoch=212
06/06/2022 09:33:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=214
06/06/2022 09:33:09 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=217
06/06/2022 09:33:12 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=219
06/06/2022 09:33:14 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=222
06/06/2022 09:33:17 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=224
06/06/2022 09:33:18 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7152555126611269 on epoch=224
06/06/2022 09:33:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=227
06/06/2022 09:33:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=229
06/06/2022 09:33:26 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
06/06/2022 09:33:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=234
06/06/2022 09:33:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
06/06/2022 09:33:32 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.7108089826839827 on epoch=237
06/06/2022 09:33:35 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/06/2022 09:33:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/06/2022 09:33:40 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/06/2022 09:33:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=247
06/06/2022 09:33:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/06/2022 09:33:46 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.7318014705882353 on epoch=249
06/06/2022 09:33:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/06/2022 09:33:52 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/06/2022 09:33:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/06/2022 09:33:57 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/06/2022 09:34:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
06/06/2022 09:34:01 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.7176470588235294 on epoch=262
06/06/2022 09:34:03 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=264
06/06/2022 09:34:06 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/06/2022 09:34:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/06/2022 09:34:11 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/06/2022 09:34:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/06/2022 09:34:15 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.7287037037037036 on epoch=274
06/06/2022 09:34:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/06/2022 09:34:20 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=279
06/06/2022 09:34:23 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/06/2022 09:34:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=284
06/06/2022 09:34:28 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/06/2022 09:34:29 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7063194444444444 on epoch=287
06/06/2022 09:34:32 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/06/2022 09:34:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
06/06/2022 09:34:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/06/2022 09:34:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/06/2022 09:34:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/06/2022 09:34:44 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.7087193272677144 on epoch=299
06/06/2022 09:34:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/06/2022 09:34:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=304
06/06/2022 09:34:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/06/2022 09:34:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/06/2022 09:34:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/06/2022 09:34:58 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7466543313317506 on epoch=312
06/06/2022 09:35:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
06/06/2022 09:35:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/06/2022 09:35:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/06/2022 09:35:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=322
06/06/2022 09:35:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/06/2022 09:35:12 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7347306077856363 on epoch=324
06/06/2022 09:35:15 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/06/2022 09:35:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/06/2022 09:35:20 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/06/2022 09:35:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/06/2022 09:35:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/06/2022 09:35:27 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7138079255726315 on epoch=337
06/06/2022 09:35:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/06/2022 09:35:32 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/06/2022 09:35:34 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/06/2022 09:35:37 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/06/2022 09:35:40 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/06/2022 09:35:41 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7474866029822925 on epoch=349
06/06/2022 09:35:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/06/2022 09:35:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/06/2022 09:35:48 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/06/2022 09:35:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/06/2022 09:35:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/06/2022 09:35:55 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.729016029016029 on epoch=362
06/06/2022 09:35:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/06/2022 09:36:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/06/2022 09:36:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/06/2022 09:36:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/06/2022 09:36:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/06/2022 09:36:09 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7347306077856363 on epoch=374
06/06/2022 09:36:12 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=377
06/06/2022 09:36:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/06/2022 09:36:17 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/06/2022 09:36:20 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/06/2022 09:36:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/06/2022 09:36:23 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7837622549019608 on epoch=387
06/06/2022 09:36:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7686059907834102 -> 0.7837622549019608 on epoch=387, global_step=1550
06/06/2022 09:36:26 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/06/2022 09:36:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/06/2022 09:36:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/06/2022 09:36:34 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/06/2022 09:36:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/06/2022 09:36:38 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7287037037037036 on epoch=399
06/06/2022 09:36:40 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/06/2022 09:36:43 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/06/2022 09:36:46 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/06/2022 09:36:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/06/2022 09:36:51 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/06/2022 09:36:52 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7843137254901961 on epoch=412
06/06/2022 09:36:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7837622549019608 -> 0.7843137254901961 on epoch=412, global_step=1650
06/06/2022 09:36:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/06/2022 09:36:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/06/2022 09:37:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/06/2022 09:37:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/06/2022 09:37:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/06/2022 09:37:06 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.7283350840336135 on epoch=424
06/06/2022 09:37:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/06/2022 09:37:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/06/2022 09:37:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/06/2022 09:37:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/06/2022 09:37:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/06/2022 09:37:21 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7320215862236236 on epoch=437
06/06/2022 09:37:23 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/06/2022 09:37:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/06/2022 09:37:29 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/06/2022 09:37:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/06/2022 09:37:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/06/2022 09:37:35 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7672667050691244 on epoch=449
06/06/2022 09:37:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=452
06/06/2022 09:37:40 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/06/2022 09:37:43 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/06/2022 09:37:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/06/2022 09:37:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/06/2022 09:37:49 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7488843813387425 on epoch=462
06/06/2022 09:37:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/06/2022 09:37:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=467
06/06/2022 09:37:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/06/2022 09:38:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/06/2022 09:38:02 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/06/2022 09:38:04 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7339333717357911 on epoch=474
06/06/2022 09:38:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/06/2022 09:38:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=479
06/06/2022 09:38:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=482
06/06/2022 09:38:14 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/06/2022 09:38:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/06/2022 09:38:18 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7639093942764688 on epoch=487
06/06/2022 09:38:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/06/2022 09:38:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/06/2022 09:38:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/06/2022 09:38:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/06/2022 09:38:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=499
06/06/2022 09:38:33 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7829545454545455 on epoch=499
06/06/2022 09:38:35 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=502
06/06/2022 09:38:38 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/06/2022 09:38:41 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/06/2022 09:38:43 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/06/2022 09:38:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/06/2022 09:38:47 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7471521942110178 on epoch=512
06/06/2022 09:38:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/06/2022 09:38:52 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/06/2022 09:38:55 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/06/2022 09:38:58 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/06/2022 09:39:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/06/2022 09:39:02 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7490196078431373 on epoch=524
06/06/2022 09:39:04 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/06/2022 09:39:07 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 09:39:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/06/2022 09:39:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/06/2022 09:39:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/06/2022 09:39:16 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7321428571428572 on epoch=537
06/06/2022 09:39:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/06/2022 09:39:21 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 09:39:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/06/2022 09:39:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/06/2022 09:39:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/06/2022 09:39:30 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7497556207233627 on epoch=549
06/06/2022 09:39:33 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 09:39:36 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/06/2022 09:39:38 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/06/2022 09:39:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/06/2022 09:39:43 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/06/2022 09:39:45 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7497556207233627 on epoch=562
06/06/2022 09:39:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/06/2022 09:39:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/06/2022 09:39:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/06/2022 09:39:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/06/2022 09:39:58 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 09:39:59 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7474801061007957 on epoch=574
06/06/2022 09:40:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 09:40:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 09:40:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/06/2022 09:40:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/06/2022 09:40:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.11 on epoch=587
06/06/2022 09:40:13 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7087989317590836 on epoch=587
06/06/2022 09:40:16 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/06/2022 09:40:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/06/2022 09:40:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 09:40:24 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/06/2022 09:40:27 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 09:40:28 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7661764705882352 on epoch=599
06/06/2022 09:40:31 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 09:40:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 09:40:36 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 09:40:38 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 09:40:41 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 09:40:42 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7488850195503421 on epoch=612
06/06/2022 09:40:45 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 09:40:48 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 09:40:50 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 09:40:53 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.24 on epoch=622
06/06/2022 09:40:56 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/06/2022 09:40:57 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.7283068783068782 on epoch=624
06/06/2022 09:40:59 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/06/2022 09:41:02 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/06/2022 09:41:05 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/06/2022 09:41:07 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/06/2022 09:41:10 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=637
06/06/2022 09:41:11 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7329313272056671 on epoch=637
06/06/2022 09:41:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 09:41:16 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/06/2022 09:41:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 09:41:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 09:41:24 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 09:41:26 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7474866029822925 on epoch=649
06/06/2022 09:41:28 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/06/2022 09:41:31 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 09:41:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 09:41:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 09:41:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 09:41:39 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7474866029822925 on epoch=662
06/06/2022 09:41:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 09:41:45 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 09:41:47 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 09:41:50 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 09:41:53 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 09:41:54 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7336805555555556 on epoch=674
06/06/2022 09:41:56 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/06/2022 09:41:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/06/2022 09:42:01 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/06/2022 09:42:04 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 09:42:06 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 09:42:08 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7515232974910394 on epoch=687
06/06/2022 09:42:10 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 09:42:13 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 09:42:15 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/06/2022 09:42:18 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/06/2022 09:42:21 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 09:42:22 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.765625 on epoch=699
06/06/2022 09:42:24 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 09:42:27 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 09:42:29 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 09:42:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/06/2022 09:42:35 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 09:42:36 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7329839981969799 on epoch=712
06/06/2022 09:42:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 09:42:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.08 on epoch=717
06/06/2022 09:42:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/06/2022 09:42:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=722
06/06/2022 09:42:48 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 09:42:50 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7458593114665222 on epoch=724
06/06/2022 09:42:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 09:42:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 09:42:57 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 09:43:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 09:43:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 09:43:04 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7608981092436975 on epoch=737
06/06/2022 09:43:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=739
06/06/2022 09:43:09 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 09:43:12 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/06/2022 09:43:14 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/06/2022 09:43:17 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 09:43:18 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.715000294412059 on epoch=749
06/06/2022 09:43:18 - INFO - __main__ - save last model!
06/06/2022 09:43:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 09:43:18 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 09:43:18 - INFO - __main__ - Printing 3 examples
06/06/2022 09:43:18 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 09:43:18 - INFO - __main__ - ['others']
06/06/2022 09:43:18 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 09:43:18 - INFO - __main__ - ['others']
06/06/2022 09:43:18 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 09:43:18 - INFO - __main__ - ['others']
06/06/2022 09:43:18 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:43:18 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 09:43:18 - INFO - __main__ - Printing 3 examples
06/06/2022 09:43:18 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/06/2022 09:43:18 - INFO - __main__ - ['happy']
06/06/2022 09:43:18 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/06/2022 09:43:18 - INFO - __main__ - ['happy']
06/06/2022 09:43:18 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/06/2022 09:43:18 - INFO - __main__ - ['happy']
06/06/2022 09:43:18 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:43:18 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:43:18 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 09:43:18 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 09:43:18 - INFO - __main__ - Printing 3 examples
06/06/2022 09:43:18 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/06/2022 09:43:18 - INFO - __main__ - ['happy']
06/06/2022 09:43:18 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/06/2022 09:43:18 - INFO - __main__ - ['happy']
06/06/2022 09:43:18 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/06/2022 09:43:18 - INFO - __main__ - ['happy']
06/06/2022 09:43:18 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:43:18 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:43:18 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 09:43:20 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:43:25 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 09:43:37 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 09:43:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 09:43:37 - INFO - __main__ - Starting training!
06/06/2022 09:45:03 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_42_0.4_8_predictions.txt
06/06/2022 09:45:03 - INFO - __main__ - Classification-F1 on test data: 0.2244
06/06/2022 09:45:04 - INFO - __main__ - prefix=emo_16_42, lr=0.4, bsz=8, dev_performance=0.7843137254901961, test_performance=0.22436023078121764
06/06/2022 09:45:04 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.3, bsz=8 ...
06/06/2022 09:45:04 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 09:45:04 - INFO - __main__ - Printing 3 examples
06/06/2022 09:45:04 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/06/2022 09:45:04 - INFO - __main__ - ['happy']
06/06/2022 09:45:04 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/06/2022 09:45:04 - INFO - __main__ - ['happy']
06/06/2022 09:45:04 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/06/2022 09:45:04 - INFO - __main__ - ['happy']
06/06/2022 09:45:04 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:45:04 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:45:05 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 09:45:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 09:45:05 - INFO - __main__ - Printing 3 examples
06/06/2022 09:45:05 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/06/2022 09:45:05 - INFO - __main__ - ['happy']
06/06/2022 09:45:05 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/06/2022 09:45:05 - INFO - __main__ - ['happy']
06/06/2022 09:45:05 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/06/2022 09:45:05 - INFO - __main__ - ['happy']
06/06/2022 09:45:05 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:45:05 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:45:05 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 09:45:21 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 09:45:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 09:45:22 - INFO - __main__ - Starting training!
06/06/2022 09:45:25 - INFO - __main__ - Step 10 Global step 10 Train loss 3.66 on epoch=2
06/06/2022 09:45:27 - INFO - __main__ - Step 20 Global step 20 Train loss 2.48 on epoch=4
06/06/2022 09:45:30 - INFO - __main__ - Step 30 Global step 30 Train loss 1.57 on epoch=7
06/06/2022 09:45:32 - INFO - __main__ - Step 40 Global step 40 Train loss 1.26 on epoch=9
06/06/2022 09:45:35 - INFO - __main__ - Step 50 Global step 50 Train loss 1.00 on epoch=12
06/06/2022 09:45:36 - INFO - __main__ - Global step 50 Train loss 2.00 Classification-F1 0.181924882629108 on epoch=12
06/06/2022 09:45:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.181924882629108 on epoch=12, global_step=50
06/06/2022 09:45:38 - INFO - __main__ - Step 60 Global step 60 Train loss 0.94 on epoch=14
06/06/2022 09:45:41 - INFO - __main__ - Step 70 Global step 70 Train loss 0.99 on epoch=17
06/06/2022 09:45:43 - INFO - __main__ - Step 80 Global step 80 Train loss 0.95 on epoch=19
06/06/2022 09:45:46 - INFO - __main__ - Step 90 Global step 90 Train loss 0.93 on epoch=22
06/06/2022 09:45:49 - INFO - __main__ - Step 100 Global step 100 Train loss 0.92 on epoch=24
06/06/2022 09:45:49 - INFO - __main__ - Global step 100 Train loss 0.95 Classification-F1 0.24321647851059616 on epoch=24
06/06/2022 09:45:50 - INFO - __main__ - Saving model with best Classification-F1: 0.181924882629108 -> 0.24321647851059616 on epoch=24, global_step=100
06/06/2022 09:45:52 - INFO - __main__ - Step 110 Global step 110 Train loss 0.89 on epoch=27
06/06/2022 09:45:55 - INFO - __main__ - Step 120 Global step 120 Train loss 0.83 on epoch=29
06/06/2022 09:45:57 - INFO - __main__ - Step 130 Global step 130 Train loss 0.85 on epoch=32
06/06/2022 09:46:00 - INFO - __main__ - Step 140 Global step 140 Train loss 0.81 on epoch=34
06/06/2022 09:46:02 - INFO - __main__ - Step 150 Global step 150 Train loss 0.77 on epoch=37
06/06/2022 09:46:03 - INFO - __main__ - Global step 150 Train loss 0.83 Classification-F1 0.4566736694677871 on epoch=37
06/06/2022 09:46:03 - INFO - __main__ - Saving model with best Classification-F1: 0.24321647851059616 -> 0.4566736694677871 on epoch=37, global_step=150
06/06/2022 09:46:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.79 on epoch=39
06/06/2022 09:46:09 - INFO - __main__ - Step 170 Global step 170 Train loss 0.73 on epoch=42
06/06/2022 09:46:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.76 on epoch=44
06/06/2022 09:46:14 - INFO - __main__ - Step 190 Global step 190 Train loss 0.66 on epoch=47
06/06/2022 09:46:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.81 on epoch=49
06/06/2022 09:46:17 - INFO - __main__ - Global step 200 Train loss 0.75 Classification-F1 0.47178175618073315 on epoch=49
06/06/2022 09:46:17 - INFO - __main__ - Saving model with best Classification-F1: 0.4566736694677871 -> 0.47178175618073315 on epoch=49, global_step=200
06/06/2022 09:46:20 - INFO - __main__ - Step 210 Global step 210 Train loss 0.74 on epoch=52
06/06/2022 09:46:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.63 on epoch=54
06/06/2022 09:46:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.67 on epoch=57
06/06/2022 09:46:28 - INFO - __main__ - Step 240 Global step 240 Train loss 0.65 on epoch=59
06/06/2022 09:46:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=62
06/06/2022 09:46:31 - INFO - __main__ - Global step 250 Train loss 0.66 Classification-F1 0.5523310023310022 on epoch=62
06/06/2022 09:46:31 - INFO - __main__ - Saving model with best Classification-F1: 0.47178175618073315 -> 0.5523310023310022 on epoch=62, global_step=250
06/06/2022 09:46:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.67 on epoch=64
06/06/2022 09:46:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.60 on epoch=67
06/06/2022 09:46:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.56 on epoch=69
06/06/2022 09:46:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.55 on epoch=72
06/06/2022 09:46:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.61 on epoch=74
06/06/2022 09:46:45 - INFO - __main__ - Global step 300 Train loss 0.60 Classification-F1 0.5663413621262459 on epoch=74
06/06/2022 09:46:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5523310023310022 -> 0.5663413621262459 on epoch=74, global_step=300
06/06/2022 09:46:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=77
06/06/2022 09:46:50 - INFO - __main__ - Step 320 Global step 320 Train loss 0.50 on epoch=79
06/06/2022 09:46:53 - INFO - __main__ - Step 330 Global step 330 Train loss 0.61 on epoch=82
06/06/2022 09:46:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.47 on epoch=84
06/06/2022 09:46:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.44 on epoch=87
06/06/2022 09:46:59 - INFO - __main__ - Global step 350 Train loss 0.50 Classification-F1 0.5749759012916908 on epoch=87
06/06/2022 09:46:59 - INFO - __main__ - Saving model with best Classification-F1: 0.5663413621262459 -> 0.5749759012916908 on epoch=87, global_step=350
06/06/2022 09:47:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.42 on epoch=89
06/06/2022 09:47:04 - INFO - __main__ - Step 370 Global step 370 Train loss 0.39 on epoch=92
06/06/2022 09:47:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.39 on epoch=94
06/06/2022 09:47:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.36 on epoch=97
06/06/2022 09:47:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=99
06/06/2022 09:47:13 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.5950592885375494 on epoch=99
06/06/2022 09:47:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5749759012916908 -> 0.5950592885375494 on epoch=99, global_step=400
06/06/2022 09:47:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.39 on epoch=102
06/06/2022 09:47:18 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=104
06/06/2022 09:47:21 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=107
06/06/2022 09:47:23 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=109
06/06/2022 09:47:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=112
06/06/2022 09:47:27 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.669142316017316 on epoch=112
06/06/2022 09:47:27 - INFO - __main__ - Saving model with best Classification-F1: 0.5950592885375494 -> 0.669142316017316 on epoch=112, global_step=450
06/06/2022 09:47:29 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=114
06/06/2022 09:47:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=117
06/06/2022 09:47:34 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=119
06/06/2022 09:47:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.32 on epoch=122
06/06/2022 09:47:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=124
06/06/2022 09:47:41 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.6660957285957285 on epoch=124
06/06/2022 09:47:43 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=127
06/06/2022 09:47:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=129
06/06/2022 09:47:48 - INFO - __main__ - Step 530 Global step 530 Train loss 0.25 on epoch=132
06/06/2022 09:47:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=134
06/06/2022 09:47:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=137
06/06/2022 09:47:55 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.6301171193114927 on epoch=137
06/06/2022 09:47:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=139
06/06/2022 09:48:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=142
06/06/2022 09:48:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=144
06/06/2022 09:48:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=147
06/06/2022 09:48:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=149
06/06/2022 09:48:09 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.6829682623800271 on epoch=149
06/06/2022 09:48:09 - INFO - __main__ - Saving model with best Classification-F1: 0.669142316017316 -> 0.6829682623800271 on epoch=149, global_step=600
06/06/2022 09:48:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=152
06/06/2022 09:48:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=154
06/06/2022 09:48:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=157
06/06/2022 09:48:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=159
06/06/2022 09:48:22 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=162
06/06/2022 09:48:23 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.6668593022493278 on epoch=162
06/06/2022 09:48:25 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=164
06/06/2022 09:48:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=167
06/06/2022 09:48:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=169
06/06/2022 09:48:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=172
06/06/2022 09:48:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=174
06/06/2022 09:48:37 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.7304316967763108 on epoch=174
06/06/2022 09:48:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6829682623800271 -> 0.7304316967763108 on epoch=174, global_step=700
06/06/2022 09:48:39 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=177
06/06/2022 09:48:42 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=179
06/06/2022 09:48:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=182
06/06/2022 09:48:47 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=184
06/06/2022 09:48:50 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=187
06/06/2022 09:48:51 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.7164346612622474 on epoch=187
06/06/2022 09:48:53 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=189
06/06/2022 09:48:56 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=192
06/06/2022 09:48:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=194
06/06/2022 09:49:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=197
06/06/2022 09:49:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
06/06/2022 09:49:05 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.7026707234617985 on epoch=199
06/06/2022 09:49:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
06/06/2022 09:49:10 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/06/2022 09:49:12 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=207
06/06/2022 09:49:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=209
06/06/2022 09:49:17 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/06/2022 09:49:19 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.7113304093567252 on epoch=212
06/06/2022 09:49:21 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=214
06/06/2022 09:49:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=217
06/06/2022 09:49:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=219
06/06/2022 09:49:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=222
06/06/2022 09:49:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=224
06/06/2022 09:49:32 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.7219653755137627 on epoch=224
06/06/2022 09:49:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=227
06/06/2022 09:49:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/06/2022 09:49:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=232
06/06/2022 09:49:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=234
06/06/2022 09:49:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=237
06/06/2022 09:49:46 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.6873737373737374 on epoch=237
06/06/2022 09:49:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=239
06/06/2022 09:49:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=242
06/06/2022 09:49:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=244
06/06/2022 09:49:57 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
06/06/2022 09:49:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=249
06/06/2022 09:50:00 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.7076587301587302 on epoch=249
06/06/2022 09:50:03 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=252
06/06/2022 09:50:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=254
06/06/2022 09:50:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/06/2022 09:50:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/06/2022 09:50:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=262
06/06/2022 09:50:14 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.7080555555555555 on epoch=262
06/06/2022 09:50:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/06/2022 09:50:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
06/06/2022 09:50:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=269
06/06/2022 09:50:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=272
06/06/2022 09:50:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/06/2022 09:50:29 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.7117263891457439 on epoch=274
06/06/2022 09:50:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=277
06/06/2022 09:50:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=279
06/06/2022 09:50:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/06/2022 09:50:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=284
06/06/2022 09:50:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/06/2022 09:50:43 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.650935025935026 on epoch=287
06/06/2022 09:50:45 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
06/06/2022 09:50:48 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/06/2022 09:50:50 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/06/2022 09:50:53 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/06/2022 09:50:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/06/2022 09:50:57 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.7124408384043273 on epoch=299
06/06/2022 09:50:59 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/06/2022 09:51:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/06/2022 09:51:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/06/2022 09:51:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/06/2022 09:51:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/06/2022 09:51:11 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7437262793799296 on epoch=312
06/06/2022 09:51:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7304316967763108 -> 0.7437262793799296 on epoch=312, global_step=1250
06/06/2022 09:51:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/06/2022 09:51:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/06/2022 09:51:18 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/06/2022 09:51:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=322
06/06/2022 09:51:24 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/06/2022 09:51:25 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.5565062523683213 on epoch=324
06/06/2022 09:51:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/06/2022 09:51:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/06/2022 09:51:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/06/2022 09:51:35 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/06/2022 09:51:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/06/2022 09:51:39 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.6926961926961928 on epoch=337
06/06/2022 09:51:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/06/2022 09:51:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/06/2022 09:51:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/06/2022 09:51:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/06/2022 09:51:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/06/2022 09:51:53 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.6991477272727273 on epoch=349
06/06/2022 09:51:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=352
06/06/2022 09:51:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/06/2022 09:52:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/06/2022 09:52:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/06/2022 09:52:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=362
06/06/2022 09:52:07 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7116311684622879 on epoch=362
06/06/2022 09:52:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/06/2022 09:52:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/06/2022 09:52:15 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/06/2022 09:52:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/06/2022 09:52:20 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/06/2022 09:52:21 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7116311684622879 on epoch=374
06/06/2022 09:52:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/06/2022 09:52:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/06/2022 09:52:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/06/2022 09:52:31 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/06/2022 09:52:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/06/2022 09:52:35 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.5616774193548386 on epoch=387
06/06/2022 09:52:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/06/2022 09:52:40 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/06/2022 09:52:43 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/06/2022 09:52:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/06/2022 09:52:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/06/2022 09:52:49 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7090524193548388 on epoch=399
06/06/2022 09:52:52 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/06/2022 09:52:55 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/06/2022 09:52:57 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/06/2022 09:53:00 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/06/2022 09:53:02 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/06/2022 09:53:04 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7069838056680162 on epoch=412
06/06/2022 09:53:06 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/06/2022 09:53:09 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/06/2022 09:53:11 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=419
06/06/2022 09:53:14 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/06/2022 09:53:16 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=424
06/06/2022 09:53:18 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.6928063517427344 on epoch=424
06/06/2022 09:53:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/06/2022 09:53:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/06/2022 09:53:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/06/2022 09:53:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=434
06/06/2022 09:53:31 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/06/2022 09:53:32 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.6596484570058923 on epoch=437
06/06/2022 09:53:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/06/2022 09:53:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/06/2022 09:53:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/06/2022 09:53:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/06/2022 09:53:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/06/2022 09:53:46 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7112817887011434 on epoch=449
06/06/2022 09:53:48 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=452
06/06/2022 09:53:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/06/2022 09:53:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/06/2022 09:53:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/06/2022 09:53:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/06/2022 09:54:00 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7123493623493624 on epoch=462
06/06/2022 09:54:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=464
06/06/2022 09:54:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/06/2022 09:54:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/06/2022 09:54:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/06/2022 09:54:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/06/2022 09:54:14 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7261042003985553 on epoch=474
06/06/2022 09:54:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/06/2022 09:54:19 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/06/2022 09:54:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/06/2022 09:54:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/06/2022 09:54:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/06/2022 09:54:28 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.706696744116099 on epoch=487
06/06/2022 09:54:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/06/2022 09:54:33 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/06/2022 09:54:36 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/06/2022 09:54:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/06/2022 09:54:41 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/06/2022 09:54:42 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.6971672539983735 on epoch=499
06/06/2022 09:54:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/06/2022 09:54:48 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/06/2022 09:54:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/06/2022 09:54:53 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=509
06/06/2022 09:54:55 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/06/2022 09:54:56 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7021284271284272 on epoch=512
06/06/2022 09:54:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/06/2022 09:55:02 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/06/2022 09:55:04 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/06/2022 09:55:07 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/06/2022 09:55:10 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/06/2022 09:55:11 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7230050415534287 on epoch=524
06/06/2022 09:55:13 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/06/2022 09:55:16 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=529
06/06/2022 09:55:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/06/2022 09:55:21 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/06/2022 09:55:24 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/06/2022 09:55:25 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7149447098082836 on epoch=537
06/06/2022 09:55:28 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/06/2022 09:55:30 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 09:55:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/06/2022 09:55:35 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/06/2022 09:55:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/06/2022 09:55:39 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7084758378876026 on epoch=549
06/06/2022 09:55:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/06/2022 09:55:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/06/2022 09:55:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/06/2022 09:55:49 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/06/2022 09:55:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/06/2022 09:55:53 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7062131180223286 on epoch=562
06/06/2022 09:55:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/06/2022 09:55:58 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=567
06/06/2022 09:56:01 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/06/2022 09:56:04 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/06/2022 09:56:06 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=574
06/06/2022 09:56:07 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6733613445378152 on epoch=574
06/06/2022 09:56:10 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 09:56:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
06/06/2022 09:56:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/06/2022 09:56:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/06/2022 09:56:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 09:56:21 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7074674317617865 on epoch=587
06/06/2022 09:56:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/06/2022 09:56:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=592
06/06/2022 09:56:29 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/06/2022 09:56:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/06/2022 09:56:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=599
06/06/2022 09:56:35 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.729202202040691 on epoch=599
06/06/2022 09:56:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 09:56:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 09:56:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 09:56:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 09:56:48 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/06/2022 09:56:50 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.6932149627395807 on epoch=612
06/06/2022 09:56:52 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 09:56:55 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 09:56:57 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 09:57:00 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/06/2022 09:57:03 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 09:57:04 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7243512682850919 on epoch=624
06/06/2022 09:57:07 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/06/2022 09:57:09 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/06/2022 09:57:12 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/06/2022 09:57:14 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/06/2022 09:57:17 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 09:57:18 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.5827335907335908 on epoch=637
06/06/2022 09:57:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/06/2022 09:57:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/06/2022 09:57:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 09:57:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=647
06/06/2022 09:57:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 09:57:32 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7803921568627451 on epoch=649
06/06/2022 09:57:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7437262793799296 -> 0.7803921568627451 on epoch=649, global_step=2600
06/06/2022 09:57:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=652
06/06/2022 09:57:38 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=654
06/06/2022 09:57:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 09:57:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 09:57:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 09:57:47 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.775853889943074 on epoch=662
06/06/2022 09:57:49 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=664
06/06/2022 09:57:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 09:57:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 09:57:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 09:58:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 09:58:01 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7578388047138047 on epoch=674
06/06/2022 09:58:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/06/2022 09:58:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 09:58:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 09:58:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 09:58:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 09:58:15 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7766942260775278 on epoch=687
06/06/2022 09:58:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 09:58:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=692
06/06/2022 09:58:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/06/2022 09:58:25 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/06/2022 09:58:28 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/06/2022 09:58:29 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7440009638285501 on epoch=699
06/06/2022 09:58:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 09:58:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 09:58:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 09:58:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=709
06/06/2022 09:58:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 09:58:43 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7277062655086849 on epoch=712
06/06/2022 09:58:46 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 09:58:49 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/06/2022 09:58:51 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 09:58:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/06/2022 09:58:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 09:58:58 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7440009638285501 on epoch=724
06/06/2022 09:59:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
06/06/2022 09:59:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 09:59:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 09:59:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 09:59:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
06/06/2022 09:59:12 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7773245073891626 on epoch=737
06/06/2022 09:59:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 09:59:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 09:59:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=744
06/06/2022 09:59:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/06/2022 09:59:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 09:59:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 09:59:26 - INFO - __main__ - Printing 3 examples
06/06/2022 09:59:26 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/06/2022 09:59:26 - INFO - __main__ - ['happy']
06/06/2022 09:59:26 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/06/2022 09:59:26 - INFO - __main__ - ['happy']
06/06/2022 09:59:26 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/06/2022 09:59:26 - INFO - __main__ - ['happy']
06/06/2022 09:59:26 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:59:26 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.76268533098344 on epoch=749
06/06/2022 09:59:26 - INFO - __main__ - save last model!
06/06/2022 09:59:26 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:59:26 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 09:59:26 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 09:59:26 - INFO - __main__ - Printing 3 examples
06/06/2022 09:59:26 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 09:59:26 - INFO - __main__ - ['others']
06/06/2022 09:59:26 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 09:59:26 - INFO - __main__ - ['others']
06/06/2022 09:59:26 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 09:59:26 - INFO - __main__ - ['others']
06/06/2022 09:59:26 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:59:26 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 09:59:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 09:59:26 - INFO - __main__ - Printing 3 examples
06/06/2022 09:59:26 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/06/2022 09:59:26 - INFO - __main__ - ['happy']
06/06/2022 09:59:26 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/06/2022 09:59:26 - INFO - __main__ - ['happy']
06/06/2022 09:59:26 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/06/2022 09:59:26 - INFO - __main__ - ['happy']
06/06/2022 09:59:26 - INFO - __main__ - Tokenizing Input ...
06/06/2022 09:59:26 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:59:26 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 09:59:29 - INFO - __main__ - Tokenizing Output ...
06/06/2022 09:59:34 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 09:59:45 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 09:59:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 09:59:46 - INFO - __main__ - Starting training!
06/06/2022 10:01:19 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_42_0.3_8_predictions.txt
06/06/2022 10:01:19 - INFO - __main__ - Classification-F1 on test data: 0.1482
06/06/2022 10:01:19 - INFO - __main__ - prefix=emo_16_42, lr=0.3, bsz=8, dev_performance=0.7803921568627451, test_performance=0.14820897903881217
06/06/2022 10:01:19 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.2, bsz=8 ...
06/06/2022 10:01:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 10:01:20 - INFO - __main__ - Printing 3 examples
06/06/2022 10:01:20 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/06/2022 10:01:20 - INFO - __main__ - ['happy']
06/06/2022 10:01:20 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/06/2022 10:01:20 - INFO - __main__ - ['happy']
06/06/2022 10:01:20 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/06/2022 10:01:20 - INFO - __main__ - ['happy']
06/06/2022 10:01:20 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:01:20 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:01:20 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 10:01:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 10:01:20 - INFO - __main__ - Printing 3 examples
06/06/2022 10:01:20 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/06/2022 10:01:20 - INFO - __main__ - ['happy']
06/06/2022 10:01:20 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/06/2022 10:01:20 - INFO - __main__ - ['happy']
06/06/2022 10:01:20 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/06/2022 10:01:20 - INFO - __main__ - ['happy']
06/06/2022 10:01:20 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:01:20 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:01:20 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 10:01:39 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 10:01:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 10:01:40 - INFO - __main__ - Starting training!
06/06/2022 10:01:43 - INFO - __main__ - Step 10 Global step 10 Train loss 3.96 on epoch=2
06/06/2022 10:01:46 - INFO - __main__ - Step 20 Global step 20 Train loss 2.98 on epoch=4
06/06/2022 10:01:49 - INFO - __main__ - Step 30 Global step 30 Train loss 2.08 on epoch=7
06/06/2022 10:01:51 - INFO - __main__ - Step 40 Global step 40 Train loss 1.76 on epoch=9
06/06/2022 10:01:54 - INFO - __main__ - Step 50 Global step 50 Train loss 1.33 on epoch=12
06/06/2022 10:01:55 - INFO - __main__ - Global step 50 Train loss 2.42 Classification-F1 0.09493670886075949 on epoch=12
06/06/2022 10:01:55 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09493670886075949 on epoch=12, global_step=50
06/06/2022 10:01:57 - INFO - __main__ - Step 60 Global step 60 Train loss 1.16 on epoch=14
06/06/2022 10:02:00 - INFO - __main__ - Step 70 Global step 70 Train loss 1.16 on epoch=17
06/06/2022 10:02:03 - INFO - __main__ - Step 80 Global step 80 Train loss 0.95 on epoch=19
06/06/2022 10:02:05 - INFO - __main__ - Step 90 Global step 90 Train loss 1.02 on epoch=22
06/06/2022 10:02:08 - INFO - __main__ - Step 100 Global step 100 Train loss 0.89 on epoch=24
06/06/2022 10:02:09 - INFO - __main__ - Global step 100 Train loss 1.03 Classification-F1 0.23680347845352828 on epoch=24
06/06/2022 10:02:09 - INFO - __main__ - Saving model with best Classification-F1: 0.09493670886075949 -> 0.23680347845352828 on epoch=24, global_step=100
06/06/2022 10:02:11 - INFO - __main__ - Step 110 Global step 110 Train loss 0.93 on epoch=27
06/06/2022 10:02:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=29
06/06/2022 10:02:16 - INFO - __main__ - Step 130 Global step 130 Train loss 0.96 on epoch=32
06/06/2022 10:02:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.95 on epoch=34
06/06/2022 10:02:22 - INFO - __main__ - Step 150 Global step 150 Train loss 0.82 on epoch=37
06/06/2022 10:02:23 - INFO - __main__ - Global step 150 Train loss 0.91 Classification-F1 0.5112230816409977 on epoch=37
06/06/2022 10:02:23 - INFO - __main__ - Saving model with best Classification-F1: 0.23680347845352828 -> 0.5112230816409977 on epoch=37, global_step=150
06/06/2022 10:02:25 - INFO - __main__ - Step 160 Global step 160 Train loss 0.91 on epoch=39
06/06/2022 10:02:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.92 on epoch=42
06/06/2022 10:02:30 - INFO - __main__ - Step 180 Global step 180 Train loss 0.81 on epoch=44
06/06/2022 10:02:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.88 on epoch=47
06/06/2022 10:02:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.81 on epoch=49
06/06/2022 10:02:37 - INFO - __main__ - Global step 200 Train loss 0.86 Classification-F1 0.5692567567567568 on epoch=49
06/06/2022 10:02:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5112230816409977 -> 0.5692567567567568 on epoch=49, global_step=200
06/06/2022 10:02:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.79 on epoch=52
06/06/2022 10:02:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.88 on epoch=54
06/06/2022 10:02:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.85 on epoch=57
06/06/2022 10:02:47 - INFO - __main__ - Step 240 Global step 240 Train loss 0.74 on epoch=59
06/06/2022 10:02:49 - INFO - __main__ - Step 250 Global step 250 Train loss 0.72 on epoch=62
06/06/2022 10:02:50 - INFO - __main__ - Global step 250 Train loss 0.80 Classification-F1 0.5448139025725233 on epoch=62
06/06/2022 10:02:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.70 on epoch=64
06/06/2022 10:02:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.70 on epoch=67
06/06/2022 10:02:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.70 on epoch=69
06/06/2022 10:03:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.68 on epoch=72
06/06/2022 10:03:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.59 on epoch=74
06/06/2022 10:03:04 - INFO - __main__ - Global step 300 Train loss 0.67 Classification-F1 0.48046029301978344 on epoch=74
06/06/2022 10:03:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.70 on epoch=77
06/06/2022 10:03:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.61 on epoch=79
06/06/2022 10:03:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.64 on epoch=82
06/06/2022 10:03:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.70 on epoch=84
06/06/2022 10:03:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.59 on epoch=87
06/06/2022 10:03:18 - INFO - __main__ - Global step 350 Train loss 0.65 Classification-F1 0.5687324929971989 on epoch=87
06/06/2022 10:03:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.68 on epoch=89
06/06/2022 10:03:23 - INFO - __main__ - Step 370 Global step 370 Train loss 0.58 on epoch=92
06/06/2022 10:03:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.60 on epoch=94
06/06/2022 10:03:28 - INFO - __main__ - Step 390 Global step 390 Train loss 0.54 on epoch=97
06/06/2022 10:03:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.60 on epoch=99
06/06/2022 10:03:32 - INFO - __main__ - Global step 400 Train loss 0.60 Classification-F1 0.5127361673414306 on epoch=99
06/06/2022 10:03:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.55 on epoch=102
06/06/2022 10:03:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.56 on epoch=104
06/06/2022 10:03:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.52 on epoch=107
06/06/2022 10:03:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.55 on epoch=109
06/06/2022 10:03:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.54 on epoch=112
06/06/2022 10:03:45 - INFO - __main__ - Global step 450 Train loss 0.54 Classification-F1 0.5578248690780659 on epoch=112
06/06/2022 10:03:48 - INFO - __main__ - Step 460 Global step 460 Train loss 0.49 on epoch=114
06/06/2022 10:03:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.46 on epoch=117
06/06/2022 10:03:53 - INFO - __main__ - Step 480 Global step 480 Train loss 0.48 on epoch=119
06/06/2022 10:03:56 - INFO - __main__ - Step 490 Global step 490 Train loss 0.45 on epoch=122
06/06/2022 10:03:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.46 on epoch=124
06/06/2022 10:03:59 - INFO - __main__ - Global step 500 Train loss 0.47 Classification-F1 0.6071483948013425 on epoch=124
06/06/2022 10:03:59 - INFO - __main__ - Saving model with best Classification-F1: 0.5692567567567568 -> 0.6071483948013425 on epoch=124, global_step=500
06/06/2022 10:04:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.51 on epoch=127
06/06/2022 10:04:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.46 on epoch=129
06/06/2022 10:04:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=132
06/06/2022 10:04:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.40 on epoch=134
06/06/2022 10:04:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.43 on epoch=137
06/06/2022 10:04:13 - INFO - __main__ - Global step 550 Train loss 0.44 Classification-F1 0.6523140430261174 on epoch=137
06/06/2022 10:04:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6071483948013425 -> 0.6523140430261174 on epoch=137, global_step=550
06/06/2022 10:04:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.47 on epoch=139
06/06/2022 10:04:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.38 on epoch=142
06/06/2022 10:04:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.42 on epoch=144
06/06/2022 10:04:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.37 on epoch=147
06/06/2022 10:04:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.34 on epoch=149
06/06/2022 10:04:27 - INFO - __main__ - Global step 600 Train loss 0.40 Classification-F1 0.656257957728546 on epoch=149
06/06/2022 10:04:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6523140430261174 -> 0.656257957728546 on epoch=149, global_step=600
06/06/2022 10:04:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=152
06/06/2022 10:04:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.41 on epoch=154
06/06/2022 10:04:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.32 on epoch=157
06/06/2022 10:04:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.32 on epoch=159
06/06/2022 10:04:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.35 on epoch=162
06/06/2022 10:04:41 - INFO - __main__ - Global step 650 Train loss 0.33 Classification-F1 0.7160752560133365 on epoch=162
06/06/2022 10:04:41 - INFO - __main__ - Saving model with best Classification-F1: 0.656257957728546 -> 0.7160752560133365 on epoch=162, global_step=650
06/06/2022 10:04:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=164
06/06/2022 10:04:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=167
06/06/2022 10:04:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=169
06/06/2022 10:04:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=172
06/06/2022 10:04:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.38 on epoch=174
06/06/2022 10:04:54 - INFO - __main__ - Global step 700 Train loss 0.25 Classification-F1 0.6437677265263473 on epoch=174
06/06/2022 10:04:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=177
06/06/2022 10:05:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.31 on epoch=179
06/06/2022 10:05:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=182
06/06/2022 10:05:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.24 on epoch=184
06/06/2022 10:05:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=187
06/06/2022 10:05:08 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.6483945696848923 on epoch=187
06/06/2022 10:05:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=189
06/06/2022 10:05:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=192
06/06/2022 10:05:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.26 on epoch=194
06/06/2022 10:05:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=197
06/06/2022 10:05:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=199
06/06/2022 10:05:22 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.6572465322465323 on epoch=199
06/06/2022 10:05:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=202
06/06/2022 10:05:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=204
06/06/2022 10:05:30 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=207
06/06/2022 10:05:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=209
06/06/2022 10:05:35 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=212
06/06/2022 10:05:36 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.7488850195503421 on epoch=212
06/06/2022 10:05:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7160752560133365 -> 0.7488850195503421 on epoch=212, global_step=850
06/06/2022 10:05:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=214
06/06/2022 10:05:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.25 on epoch=217
06/06/2022 10:05:44 - INFO - __main__ - Step 880 Global step 880 Train loss 0.23 on epoch=219
06/06/2022 10:05:46 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=222
06/06/2022 10:05:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=224
06/06/2022 10:05:50 - INFO - __main__ - Global step 900 Train loss 0.22 Classification-F1 0.7313717532467532 on epoch=224
06/06/2022 10:05:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=227
06/06/2022 10:05:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.22 on epoch=229
06/06/2022 10:05:57 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=232
06/06/2022 10:06:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=234
06/06/2022 10:06:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=237
06/06/2022 10:06:03 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.7314350400557296 on epoch=237
06/06/2022 10:06:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=239
06/06/2022 10:06:08 - INFO - __main__ - Step 970 Global step 970 Train loss 0.23 on epoch=242
06/06/2022 10:06:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=244
06/06/2022 10:06:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=247
06/06/2022 10:06:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=249
06/06/2022 10:06:17 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.7640365347018573 on epoch=249
06/06/2022 10:06:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7488850195503421 -> 0.7640365347018573 on epoch=249, global_step=1000
06/06/2022 10:06:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=252
06/06/2022 10:06:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=254
06/06/2022 10:06:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=257
06/06/2022 10:06:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=259
06/06/2022 10:06:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/06/2022 10:06:31 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.7302449076642624 on epoch=262
06/06/2022 10:06:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=264
06/06/2022 10:06:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.15 on epoch=267
06/06/2022 10:06:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
06/06/2022 10:06:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=272
06/06/2022 10:06:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=274
06/06/2022 10:06:45 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.7077362996480643 on epoch=274
06/06/2022 10:06:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=277
06/06/2022 10:06:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=279
06/06/2022 10:06:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=282
06/06/2022 10:06:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=284
06/06/2022 10:06:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/06/2022 10:06:59 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.7784743991640544 on epoch=287
06/06/2022 10:06:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7640365347018573 -> 0.7784743991640544 on epoch=287, global_step=1150
06/06/2022 10:07:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/06/2022 10:07:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=292
06/06/2022 10:07:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/06/2022 10:07:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=297
06/06/2022 10:07:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/06/2022 10:07:13 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.7820136852394918 on epoch=299
06/06/2022 10:07:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7784743991640544 -> 0.7820136852394918 on epoch=299, global_step=1200
06/06/2022 10:07:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/06/2022 10:07:18 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=304
06/06/2022 10:07:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/06/2022 10:07:23 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=309
06/06/2022 10:07:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/06/2022 10:07:26 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.7457974137931034 on epoch=312
06/06/2022 10:07:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=314
06/06/2022 10:07:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/06/2022 10:07:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=319
06/06/2022 10:07:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=322
06/06/2022 10:07:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/06/2022 10:07:40 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7466680149661239 on epoch=324
06/06/2022 10:07:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=327
06/06/2022 10:07:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=329
06/06/2022 10:07:48 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=332
06/06/2022 10:07:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=334
06/06/2022 10:07:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/06/2022 10:07:54 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.7649071358748778 on epoch=337
06/06/2022 10:07:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=339
06/06/2022 10:07:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
06/06/2022 10:08:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=344
06/06/2022 10:08:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/06/2022 10:08:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=349
06/06/2022 10:08:08 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7656575240066701 on epoch=349
06/06/2022 10:08:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/06/2022 10:08:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/06/2022 10:08:15 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/06/2022 10:08:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/06/2022 10:08:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
06/06/2022 10:08:22 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.6141354422604423 on epoch=362
06/06/2022 10:08:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=364
06/06/2022 10:08:27 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/06/2022 10:08:29 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=369
06/06/2022 10:08:32 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=372
06/06/2022 10:08:35 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/06/2022 10:08:36 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7668560606060605 on epoch=374
06/06/2022 10:08:38 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=377
06/06/2022 10:08:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/06/2022 10:08:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=382
06/06/2022 10:08:46 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/06/2022 10:08:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/06/2022 10:08:50 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7649071358748778 on epoch=387
06/06/2022 10:08:52 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/06/2022 10:08:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/06/2022 10:08:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/06/2022 10:09:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/06/2022 10:09:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
06/06/2022 10:09:03 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7317376989980946 on epoch=399
06/06/2022 10:09:06 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=402
06/06/2022 10:09:09 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/06/2022 10:09:11 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=407
06/06/2022 10:09:14 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/06/2022 10:09:16 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=412
06/06/2022 10:09:18 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7668560606060605 on epoch=412
06/06/2022 10:09:20 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/06/2022 10:09:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=417
06/06/2022 10:09:25 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/06/2022 10:09:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=422
06/06/2022 10:09:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=424
06/06/2022 10:09:32 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.7708458187350175 on epoch=424
06/06/2022 10:09:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/06/2022 10:09:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/06/2022 10:09:39 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/06/2022 10:09:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/06/2022 10:09:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/06/2022 10:09:46 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7363815284178188 on epoch=437
06/06/2022 10:09:48 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=439
06/06/2022 10:09:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/06/2022 10:09:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/06/2022 10:09:56 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/06/2022 10:09:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/06/2022 10:10:00 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7649071358748778 on epoch=449
06/06/2022 10:10:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=452
06/06/2022 10:10:05 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/06/2022 10:10:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/06/2022 10:10:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.13 on epoch=459
06/06/2022 10:10:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/06/2022 10:10:14 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7472027743244128 on epoch=462
06/06/2022 10:10:17 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/06/2022 10:10:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/06/2022 10:10:22 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/06/2022 10:10:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/06/2022 10:10:27 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/06/2022 10:10:28 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7649071358748778 on epoch=474
06/06/2022 10:10:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=477
06/06/2022 10:10:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=479
06/06/2022 10:10:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/06/2022 10:10:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=484
06/06/2022 10:10:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/06/2022 10:10:42 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7304709401483596 on epoch=487
06/06/2022 10:10:45 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=489
06/06/2022 10:10:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/06/2022 10:10:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=494
06/06/2022 10:10:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=497
06/06/2022 10:10:55 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/06/2022 10:10:56 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7824810606060605 on epoch=499
06/06/2022 10:10:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7820136852394918 -> 0.7824810606060605 on epoch=499, global_step=2000
06/06/2022 10:10:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/06/2022 10:11:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/06/2022 10:11:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/06/2022 10:11:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/06/2022 10:11:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/06/2022 10:11:10 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7619883437245867 on epoch=512
06/06/2022 10:11:13 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/06/2022 10:11:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/06/2022 10:11:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=519
06/06/2022 10:11:21 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=522
06/06/2022 10:11:23 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/06/2022 10:11:24 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7609816653934302 on epoch=524
06/06/2022 10:11:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/06/2022 10:11:29 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/06/2022 10:11:32 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/06/2022 10:11:35 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/06/2022 10:11:38 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/06/2022 10:11:39 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7157102378876573 on epoch=537
06/06/2022 10:11:41 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/06/2022 10:11:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=542
06/06/2022 10:11:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/06/2022 10:11:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/06/2022 10:11:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=549
06/06/2022 10:11:53 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7640446207808637 on epoch=549
06/06/2022 10:11:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 10:11:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=554
06/06/2022 10:12:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/06/2022 10:12:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/06/2022 10:12:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/06/2022 10:12:07 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7472027743244128 on epoch=562
06/06/2022 10:12:09 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/06/2022 10:12:12 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/06/2022 10:12:14 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=569
06/06/2022 10:12:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=572
06/06/2022 10:12:20 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 10:12:21 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7649071358748778 on epoch=574
06/06/2022 10:12:23 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 10:12:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 10:12:28 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/06/2022 10:12:31 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/06/2022 10:12:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 10:12:35 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7459979485524617 on epoch=587
06/06/2022 10:12:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/06/2022 10:12:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/06/2022 10:12:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 10:12:45 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/06/2022 10:12:48 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 10:12:49 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7656575240066701 on epoch=599
06/06/2022 10:12:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 10:12:54 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 10:12:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 10:12:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/06/2022 10:13:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 10:13:03 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7668560606060605 on epoch=612
06/06/2022 10:13:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/06/2022 10:13:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 10:13:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/06/2022 10:13:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/06/2022 10:13:16 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 10:13:17 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7668560606060605 on epoch=624
06/06/2022 10:13:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=627
06/06/2022 10:13:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=629
06/06/2022 10:13:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=632
06/06/2022 10:13:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/06/2022 10:13:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/06/2022 10:13:31 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7668560606060605 on epoch=637
06/06/2022 10:13:33 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/06/2022 10:13:35 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/06/2022 10:13:38 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 10:13:40 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=647
06/06/2022 10:13:43 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/06/2022 10:13:44 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7442634759997189 on epoch=649
06/06/2022 10:13:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/06/2022 10:13:49 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/06/2022 10:13:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/06/2022 10:13:54 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/06/2022 10:13:56 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 10:13:57 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.746275783040489 on epoch=662
06/06/2022 10:14:00 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=664
06/06/2022 10:14:02 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 10:14:05 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/06/2022 10:14:07 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/06/2022 10:14:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 10:14:11 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7080672268907564 on epoch=674
06/06/2022 10:14:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/06/2022 10:14:16 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 10:14:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=682
06/06/2022 10:14:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 10:14:23 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 10:14:24 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7649071358748778 on epoch=687
06/06/2022 10:14:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=689
06/06/2022 10:14:29 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 10:14:32 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=694
06/06/2022 10:14:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/06/2022 10:14:37 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 10:14:38 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7847439916405433 on epoch=699
06/06/2022 10:14:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7824810606060605 -> 0.7847439916405433 on epoch=699, global_step=2800
06/06/2022 10:14:40 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 10:14:43 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 10:14:46 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 10:14:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/06/2022 10:14:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/06/2022 10:14:51 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7824810606060605 on epoch=712
06/06/2022 10:14:54 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 10:14:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 10:14:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 10:15:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/06/2022 10:15:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=724
06/06/2022 10:15:05 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.766188330170778 on epoch=724
06/06/2022 10:15:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 10:15:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 10:15:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/06/2022 10:15:15 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/06/2022 10:15:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 10:15:19 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7642045454545454 on epoch=737
06/06/2022 10:15:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 10:15:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 10:15:26 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 10:15:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=747
06/06/2022 10:15:31 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 10:15:32 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7818181818181817 on epoch=749
06/06/2022 10:15:32 - INFO - __main__ - save last model!
06/06/2022 10:15:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 10:15:32 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 10:15:32 - INFO - __main__ - Printing 3 examples
06/06/2022 10:15:32 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 10:15:32 - INFO - __main__ - ['others']
06/06/2022 10:15:32 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 10:15:32 - INFO - __main__ - ['others']
06/06/2022 10:15:32 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 10:15:32 - INFO - __main__ - ['others']
06/06/2022 10:15:32 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 10:15:32 - INFO - __main__ - Printing 3 examples
06/06/2022 10:15:32 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/06/2022 10:15:32 - INFO - __main__ - ['others']
06/06/2022 10:15:32 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/06/2022 10:15:32 - INFO - __main__ - ['others']
06/06/2022 10:15:32 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/06/2022 10:15:32 - INFO - __main__ - ['others']
06/06/2022 10:15:32 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:15:32 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:15:32 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:15:33 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 10:15:33 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 10:15:33 - INFO - __main__ - Printing 3 examples
06/06/2022 10:15:33 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/06/2022 10:15:33 - INFO - __main__ - ['others']
06/06/2022 10:15:33 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/06/2022 10:15:33 - INFO - __main__ - ['others']
06/06/2022 10:15:33 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/06/2022 10:15:33 - INFO - __main__ - ['others']
06/06/2022 10:15:33 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:15:33 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:15:33 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 10:15:35 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:15:41 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 10:15:49 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 10:15:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 10:15:50 - INFO - __main__ - Starting training!
06/06/2022 10:17:19 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_42_0.2_8_predictions.txt
06/06/2022 10:17:19 - INFO - __main__ - Classification-F1 on test data: 0.1893
06/06/2022 10:17:19 - INFO - __main__ - prefix=emo_16_42, lr=0.2, bsz=8, dev_performance=0.7847439916405433, test_performance=0.18927299456217828
06/06/2022 10:17:19 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.5, bsz=8 ...
06/06/2022 10:17:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 10:17:20 - INFO - __main__ - Printing 3 examples
06/06/2022 10:17:20 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/06/2022 10:17:20 - INFO - __main__ - ['others']
06/06/2022 10:17:20 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/06/2022 10:17:20 - INFO - __main__ - ['others']
06/06/2022 10:17:20 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/06/2022 10:17:20 - INFO - __main__ - ['others']
06/06/2022 10:17:20 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:17:20 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:17:20 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 10:17:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 10:17:20 - INFO - __main__ - Printing 3 examples
06/06/2022 10:17:20 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/06/2022 10:17:20 - INFO - __main__ - ['others']
06/06/2022 10:17:20 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/06/2022 10:17:20 - INFO - __main__ - ['others']
06/06/2022 10:17:20 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/06/2022 10:17:20 - INFO - __main__ - ['others']
06/06/2022 10:17:20 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:17:20 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:17:21 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 10:17:39 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 10:17:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 10:17:40 - INFO - __main__ - Starting training!
06/06/2022 10:17:43 - INFO - __main__ - Step 10 Global step 10 Train loss 3.17 on epoch=2
06/06/2022 10:17:46 - INFO - __main__ - Step 20 Global step 20 Train loss 1.50 on epoch=4
06/06/2022 10:17:49 - INFO - __main__ - Step 30 Global step 30 Train loss 1.04 on epoch=7
06/06/2022 10:17:51 - INFO - __main__ - Step 40 Global step 40 Train loss 1.02 on epoch=9
06/06/2022 10:17:54 - INFO - __main__ - Step 50 Global step 50 Train loss 1.03 on epoch=12
06/06/2022 10:17:55 - INFO - __main__ - Global step 50 Train loss 1.55 Classification-F1 0.13067758749069247 on epoch=12
06/06/2022 10:17:55 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13067758749069247 on epoch=12, global_step=50
06/06/2022 10:17:57 - INFO - __main__ - Step 60 Global step 60 Train loss 0.88 on epoch=14
06/06/2022 10:18:00 - INFO - __main__ - Step 70 Global step 70 Train loss 0.92 on epoch=17
06/06/2022 10:18:02 - INFO - __main__ - Step 80 Global step 80 Train loss 0.87 on epoch=19
06/06/2022 10:18:05 - INFO - __main__ - Step 90 Global step 90 Train loss 0.99 on epoch=22
06/06/2022 10:18:07 - INFO - __main__ - Step 100 Global step 100 Train loss 0.86 on epoch=24
06/06/2022 10:18:08 - INFO - __main__ - Global step 100 Train loss 0.90 Classification-F1 0.17142857142857143 on epoch=24
06/06/2022 10:18:08 - INFO - __main__ - Saving model with best Classification-F1: 0.13067758749069247 -> 0.17142857142857143 on epoch=24, global_step=100
06/06/2022 10:18:11 - INFO - __main__ - Step 110 Global step 110 Train loss 0.85 on epoch=27
06/06/2022 10:18:13 - INFO - __main__ - Step 120 Global step 120 Train loss 0.89 on epoch=29
06/06/2022 10:18:16 - INFO - __main__ - Step 130 Global step 130 Train loss 0.74 on epoch=32
06/06/2022 10:18:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.82 on epoch=34
06/06/2022 10:18:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.70 on epoch=37
06/06/2022 10:18:22 - INFO - __main__ - Global step 150 Train loss 0.80 Classification-F1 0.5164141414141414 on epoch=37
06/06/2022 10:18:22 - INFO - __main__ - Saving model with best Classification-F1: 0.17142857142857143 -> 0.5164141414141414 on epoch=37, global_step=150
06/06/2022 10:18:25 - INFO - __main__ - Step 160 Global step 160 Train loss 0.64 on epoch=39
06/06/2022 10:18:27 - INFO - __main__ - Step 170 Global step 170 Train loss 0.52 on epoch=42
06/06/2022 10:18:30 - INFO - __main__ - Step 180 Global step 180 Train loss 0.59 on epoch=44
06/06/2022 10:18:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.50 on epoch=47
06/06/2022 10:18:35 - INFO - __main__ - Step 200 Global step 200 Train loss 0.58 on epoch=49
06/06/2022 10:18:36 - INFO - __main__ - Global step 200 Train loss 0.57 Classification-F1 0.5439390331031198 on epoch=49
06/06/2022 10:18:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5164141414141414 -> 0.5439390331031198 on epoch=49, global_step=200
06/06/2022 10:18:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.56 on epoch=52
06/06/2022 10:18:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.46 on epoch=54
06/06/2022 10:18:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.41 on epoch=57
06/06/2022 10:18:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.46 on epoch=59
06/06/2022 10:18:49 - INFO - __main__ - Step 250 Global step 250 Train loss 0.35 on epoch=62
06/06/2022 10:18:50 - INFO - __main__ - Global step 250 Train loss 0.45 Classification-F1 0.5968404934437543 on epoch=62
06/06/2022 10:18:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5439390331031198 -> 0.5968404934437543 on epoch=62, global_step=250
06/06/2022 10:18:52 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=64
06/06/2022 10:18:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.33 on epoch=67
06/06/2022 10:18:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=69
06/06/2022 10:19:00 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=72
06/06/2022 10:19:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=74
06/06/2022 10:19:04 - INFO - __main__ - Global step 300 Train loss 0.33 Classification-F1 0.5634398496240601 on epoch=74
06/06/2022 10:19:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.30 on epoch=77
06/06/2022 10:19:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=79
06/06/2022 10:19:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=82
06/06/2022 10:19:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=84
06/06/2022 10:19:16 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=87
06/06/2022 10:19:17 - INFO - __main__ - Global step 350 Train loss 0.24 Classification-F1 0.7372474747474748 on epoch=87
06/06/2022 10:19:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5968404934437543 -> 0.7372474747474748 on epoch=87, global_step=350
06/06/2022 10:19:20 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=89
06/06/2022 10:19:22 - INFO - __main__ - Step 370 Global step 370 Train loss 0.20 on epoch=92
06/06/2022 10:19:25 - INFO - __main__ - Step 380 Global step 380 Train loss 0.27 on epoch=94
06/06/2022 10:19:27 - INFO - __main__ - Step 390 Global step 390 Train loss 0.17 on epoch=97
06/06/2022 10:19:30 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=99
06/06/2022 10:19:31 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.7218253968253968 on epoch=99
06/06/2022 10:19:33 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/06/2022 10:19:36 - INFO - __main__ - Step 420 Global step 420 Train loss 0.16 on epoch=104
06/06/2022 10:19:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=107
06/06/2022 10:19:41 - INFO - __main__ - Step 440 Global step 440 Train loss 0.13 on epoch=109
06/06/2022 10:19:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.11 on epoch=112
06/06/2022 10:19:45 - INFO - __main__ - Global step 450 Train loss 0.16 Classification-F1 0.7452139179470416 on epoch=112
06/06/2022 10:19:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7372474747474748 -> 0.7452139179470416 on epoch=112, global_step=450
06/06/2022 10:19:47 - INFO - __main__ - Step 460 Global step 460 Train loss 0.11 on epoch=114
06/06/2022 10:19:50 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=117
06/06/2022 10:19:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.14 on epoch=119
06/06/2022 10:19:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.13 on epoch=122
06/06/2022 10:19:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=124
06/06/2022 10:19:59 - INFO - __main__ - Global step 500 Train loss 0.12 Classification-F1 0.7160556976413752 on epoch=124
06/06/2022 10:20:01 - INFO - __main__ - Step 510 Global step 510 Train loss 0.07 on epoch=127
06/06/2022 10:20:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=129
06/06/2022 10:20:06 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=132
06/06/2022 10:20:09 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=134
06/06/2022 10:20:11 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=137
06/06/2022 10:20:13 - INFO - __main__ - Global step 550 Train loss 0.09 Classification-F1 0.7218253968253968 on epoch=137
06/06/2022 10:20:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=139
06/06/2022 10:20:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=142
06/06/2022 10:20:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=144
06/06/2022 10:20:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=147
06/06/2022 10:20:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=149
06/06/2022 10:20:26 - INFO - __main__ - Global step 600 Train loss 0.08 Classification-F1 0.7521739130434781 on epoch=149
06/06/2022 10:20:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7452139179470416 -> 0.7521739130434781 on epoch=149, global_step=600
06/06/2022 10:20:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=152
06/06/2022 10:20:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=154
06/06/2022 10:20:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=157
06/06/2022 10:20:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=159
06/06/2022 10:20:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=162
06/06/2022 10:20:40 - INFO - __main__ - Global step 650 Train loss 0.07 Classification-F1 0.786764705882353 on epoch=162
06/06/2022 10:20:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7521739130434781 -> 0.786764705882353 on epoch=162, global_step=650
06/06/2022 10:20:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=164
06/06/2022 10:20:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=167
06/06/2022 10:20:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=169
06/06/2022 10:20:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=172
06/06/2022 10:20:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=174
06/06/2022 10:20:54 - INFO - __main__ - Global step 700 Train loss 0.03 Classification-F1 0.771969696969697 on epoch=174
06/06/2022 10:20:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=177
06/06/2022 10:20:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=179
06/06/2022 10:21:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=182
06/06/2022 10:21:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/06/2022 10:21:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=187
06/06/2022 10:21:08 - INFO - __main__ - Global step 750 Train loss 0.02 Classification-F1 0.7728715728715728 on epoch=187
06/06/2022 10:21:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=189
06/06/2022 10:21:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=192
06/06/2022 10:21:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=194
06/06/2022 10:21:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
06/06/2022 10:21:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/06/2022 10:21:22 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.7449486920075156 on epoch=199
06/06/2022 10:21:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=202
06/06/2022 10:21:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/06/2022 10:21:29 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=207
06/06/2022 10:21:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=209
06/06/2022 10:21:35 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=212
06/06/2022 10:21:36 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.7443693693693694 on epoch=212
06/06/2022 10:21:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=214
06/06/2022 10:21:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=217
06/06/2022 10:21:43 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=219
06/06/2022 10:21:46 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/06/2022 10:21:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/06/2022 10:21:50 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.7806753136037025 on epoch=224
06/06/2022 10:21:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=227
06/06/2022 10:21:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=229
06/06/2022 10:21:57 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=232
06/06/2022 10:22:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/06/2022 10:22:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=237
06/06/2022 10:22:04 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.7449486920075155 on epoch=237
06/06/2022 10:22:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
06/06/2022 10:22:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
06/06/2022 10:22:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=244
06/06/2022 10:22:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=247
06/06/2022 10:22:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/06/2022 10:22:18 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.7445285239402887 on epoch=249
06/06/2022 10:22:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/06/2022 10:22:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/06/2022 10:22:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=257
06/06/2022 10:22:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
06/06/2022 10:22:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=262
06/06/2022 10:22:32 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.7450237670825905 on epoch=262
06/06/2022 10:22:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=264
06/06/2022 10:22:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/06/2022 10:22:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/06/2022 10:22:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/06/2022 10:22:45 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=274
06/06/2022 10:22:46 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.7589126559714795 on epoch=274
06/06/2022 10:22:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/06/2022 10:22:51 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=279
06/06/2022 10:22:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/06/2022 10:22:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=284
06/06/2022 10:22:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/06/2022 10:23:00 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.8011561160966933 on epoch=287
06/06/2022 10:23:00 - INFO - __main__ - Saving model with best Classification-F1: 0.786764705882353 -> 0.8011561160966933 on epoch=287, global_step=1150
06/06/2022 10:23:02 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/06/2022 10:23:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/06/2022 10:23:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/06/2022 10:23:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/06/2022 10:23:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=299
06/06/2022 10:23:14 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.8354621848739495 on epoch=299
06/06/2022 10:23:14 - INFO - __main__ - Saving model with best Classification-F1: 0.8011561160966933 -> 0.8354621848739495 on epoch=299, global_step=1200
06/06/2022 10:23:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/06/2022 10:23:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/06/2022 10:23:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/06/2022 10:23:24 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/06/2022 10:23:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/06/2022 10:23:28 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.7806753136037025 on epoch=312
06/06/2022 10:23:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=314
06/06/2022 10:23:33 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/06/2022 10:23:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/06/2022 10:23:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/06/2022 10:23:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/06/2022 10:23:42 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.7589126559714795 on epoch=324
06/06/2022 10:23:45 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/06/2022 10:23:47 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=329
06/06/2022 10:23:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/06/2022 10:23:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/06/2022 10:23:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/06/2022 10:23:56 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.7806753136037025 on epoch=337
06/06/2022 10:23:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/06/2022 10:24:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/06/2022 10:24:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/06/2022 10:24:06 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/06/2022 10:24:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/06/2022 10:24:10 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7806753136037025 on epoch=349
06/06/2022 10:24:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/06/2022 10:24:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/06/2022 10:24:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/06/2022 10:24:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/06/2022 10:24:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/06/2022 10:24:24 - INFO - __main__ - Global step 1450 Train loss 0.00 Classification-F1 0.7732683982683983 on epoch=362
06/06/2022 10:24:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/06/2022 10:24:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/06/2022 10:24:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/06/2022 10:24:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/06/2022 10:24:37 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/06/2022 10:24:38 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.8210427807486631 on epoch=374
06/06/2022 10:24:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/06/2022 10:24:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/06/2022 10:24:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/06/2022 10:24:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/06/2022 10:24:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/06/2022 10:24:52 - INFO - __main__ - Global step 1550 Train loss 0.00 Classification-F1 0.744343891402715 on epoch=387
06/06/2022 10:24:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/06/2022 10:24:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/06/2022 10:25:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/06/2022 10:25:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/06/2022 10:25:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/06/2022 10:25:07 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7954096762482817 on epoch=399
06/06/2022 10:25:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/06/2022 10:25:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/06/2022 10:25:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/06/2022 10:25:17 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/06/2022 10:25:20 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/06/2022 10:25:21 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7806753136037025 on epoch=412
06/06/2022 10:25:23 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/06/2022 10:25:26 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/06/2022 10:25:29 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/06/2022 10:25:31 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/06/2022 10:25:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/06/2022 10:25:35 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7589126559714795 on epoch=424
06/06/2022 10:25:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/06/2022 10:25:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=429
06/06/2022 10:25:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/06/2022 10:25:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/06/2022 10:25:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/06/2022 10:25:49 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7445285239402887 on epoch=437
06/06/2022 10:25:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/06/2022 10:25:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/06/2022 10:25:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/06/2022 10:25:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/06/2022 10:26:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/06/2022 10:26:03 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7445285239402887 on epoch=449
06/06/2022 10:26:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/06/2022 10:26:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/06/2022 10:26:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/06/2022 10:26:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/06/2022 10:26:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/06/2022 10:26:17 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.7874538021596845 on epoch=462
06/06/2022 10:26:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=464
06/06/2022 10:26:22 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/06/2022 10:26:24 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/06/2022 10:26:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/06/2022 10:26:30 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/06/2022 10:26:31 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8158263305322129 on epoch=474
06/06/2022 10:26:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=477
06/06/2022 10:26:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/06/2022 10:26:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/06/2022 10:26:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/06/2022 10:26:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/06/2022 10:26:45 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7732683982683983 on epoch=487
06/06/2022 10:26:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/06/2022 10:26:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=492
06/06/2022 10:26:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/06/2022 10:26:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/06/2022 10:26:57 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/06/2022 10:26:58 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7806753136037025 on epoch=499
06/06/2022 10:27:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/06/2022 10:27:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/06/2022 10:27:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/06/2022 10:27:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/06/2022 10:27:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/06/2022 10:27:12 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.8014705882352942 on epoch=512
06/06/2022 10:27:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/06/2022 10:27:17 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/06/2022 10:27:20 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/06/2022 10:27:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/06/2022 10:27:25 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/06/2022 10:27:26 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7661320270015923 on epoch=524
06/06/2022 10:27:29 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/06/2022 10:27:32 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 10:27:34 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/06/2022 10:27:37 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/06/2022 10:27:39 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/06/2022 10:27:40 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7874538021596845 on epoch=537
06/06/2022 10:27:43 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/06/2022 10:27:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 10:27:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/06/2022 10:27:51 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/06/2022 10:27:53 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=549
06/06/2022 10:27:54 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7874538021596845 on epoch=549
06/06/2022 10:27:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 10:28:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/06/2022 10:28:02 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/06/2022 10:28:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/06/2022 10:28:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/06/2022 10:28:09 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7947589969648794 on epoch=562
06/06/2022 10:28:11 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/06/2022 10:28:14 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=567
06/06/2022 10:28:16 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/06/2022 10:28:19 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/06/2022 10:28:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 10:28:23 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7874538021596845 on epoch=574
06/06/2022 10:28:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 10:28:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 10:28:30 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/06/2022 10:28:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/06/2022 10:28:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 10:28:37 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7732683982683983 on epoch=587
06/06/2022 10:28:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/06/2022 10:28:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/06/2022 10:28:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=594
06/06/2022 10:28:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/06/2022 10:28:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=599
06/06/2022 10:28:51 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7641854038912863 on epoch=599
06/06/2022 10:28:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/06/2022 10:28:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/06/2022 10:28:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 10:29:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 10:29:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 10:29:04 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7589361831689198 on epoch=612
06/06/2022 10:29:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/06/2022 10:29:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 10:29:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 10:29:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/06/2022 10:29:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 10:29:18 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7732683982683983 on epoch=624
06/06/2022 10:29:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/06/2022 10:29:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/06/2022 10:29:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/06/2022 10:29:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/06/2022 10:29:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 10:29:32 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7732683982683983 on epoch=637
06/06/2022 10:29:35 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 10:29:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/06/2022 10:29:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 10:29:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/06/2022 10:29:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 10:29:46 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.758982683982684 on epoch=649
06/06/2022 10:29:49 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/06/2022 10:29:51 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 10:29:54 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 10:29:57 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 10:29:59 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 10:30:00 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7874538021596845 on epoch=662
06/06/2022 10:30:03 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/06/2022 10:30:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 10:30:08 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 10:30:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 10:30:13 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 10:30:14 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.758982683982684 on epoch=674
06/06/2022 10:30:17 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/06/2022 10:30:19 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/06/2022 10:30:22 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 10:30:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=684
06/06/2022 10:30:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 10:30:28 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.758982683982684 on epoch=687
06/06/2022 10:30:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 10:30:33 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 10:30:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=694
06/06/2022 10:30:38 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 10:30:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/06/2022 10:30:42 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7806753136037025 on epoch=699
06/06/2022 10:30:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 10:30:47 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 10:30:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 10:30:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/06/2022 10:30:55 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 10:30:56 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.8056526806526807 on epoch=712
06/06/2022 10:30:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/06/2022 10:31:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 10:31:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 10:31:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/06/2022 10:31:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 10:31:10 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.780961791831357 on epoch=724
06/06/2022 10:31:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
06/06/2022 10:31:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 10:31:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/06/2022 10:31:20 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 10:31:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 10:31:24 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7874538021596845 on epoch=737
06/06/2022 10:31:27 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 10:31:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 10:31:32 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 10:31:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/06/2022 10:31:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 10:31:38 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.758982683982684 on epoch=749
06/06/2022 10:31:38 - INFO - __main__ - save last model!
06/06/2022 10:31:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 10:31:38 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 10:31:38 - INFO - __main__ - Printing 3 examples
06/06/2022 10:31:38 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 10:31:38 - INFO - __main__ - ['others']
06/06/2022 10:31:38 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 10:31:38 - INFO - __main__ - ['others']
06/06/2022 10:31:38 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 10:31:38 - INFO - __main__ - ['others']
06/06/2022 10:31:38 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:31:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 10:31:38 - INFO - __main__ - Printing 3 examples
06/06/2022 10:31:38 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/06/2022 10:31:38 - INFO - __main__ - ['others']
06/06/2022 10:31:38 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/06/2022 10:31:38 - INFO - __main__ - ['others']
06/06/2022 10:31:38 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/06/2022 10:31:38 - INFO - __main__ - ['others']
06/06/2022 10:31:38 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:31:38 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:31:38 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 10:31:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 10:31:38 - INFO - __main__ - Printing 3 examples
06/06/2022 10:31:38 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/06/2022 10:31:38 - INFO - __main__ - ['others']
06/06/2022 10:31:38 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/06/2022 10:31:38 - INFO - __main__ - ['others']
06/06/2022 10:31:38 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/06/2022 10:31:38 - INFO - __main__ - ['others']
06/06/2022 10:31:38 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:31:38 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:31:38 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 10:31:40 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:31:45 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 10:31:55 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 10:31:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 10:31:56 - INFO - __main__ - Starting training!
06/06/2022 10:33:22 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_87_0.5_8_predictions.txt
06/06/2022 10:33:22 - INFO - __main__ - Classification-F1 on test data: 0.2331
06/06/2022 10:33:23 - INFO - __main__ - prefix=emo_16_87, lr=0.5, bsz=8, dev_performance=0.8354621848739495, test_performance=0.23314053916916724
06/06/2022 10:33:23 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.4, bsz=8 ...
06/06/2022 10:33:24 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 10:33:24 - INFO - __main__ - Printing 3 examples
06/06/2022 10:33:24 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/06/2022 10:33:24 - INFO - __main__ - ['others']
06/06/2022 10:33:24 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/06/2022 10:33:24 - INFO - __main__ - ['others']
06/06/2022 10:33:24 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/06/2022 10:33:24 - INFO - __main__ - ['others']
06/06/2022 10:33:24 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:33:24 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:33:24 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 10:33:24 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 10:33:24 - INFO - __main__ - Printing 3 examples
06/06/2022 10:33:24 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/06/2022 10:33:24 - INFO - __main__ - ['others']
06/06/2022 10:33:24 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/06/2022 10:33:24 - INFO - __main__ - ['others']
06/06/2022 10:33:24 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/06/2022 10:33:24 - INFO - __main__ - ['others']
06/06/2022 10:33:24 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:33:24 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:33:24 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 10:33:41 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 10:33:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 10:33:42 - INFO - __main__ - Starting training!
06/06/2022 10:33:45 - INFO - __main__ - Step 10 Global step 10 Train loss 3.82 on epoch=2
06/06/2022 10:33:48 - INFO - __main__ - Step 20 Global step 20 Train loss 2.05 on epoch=4
06/06/2022 10:33:50 - INFO - __main__ - Step 30 Global step 30 Train loss 1.32 on epoch=7
06/06/2022 10:33:53 - INFO - __main__ - Step 40 Global step 40 Train loss 1.15 on epoch=9
06/06/2022 10:33:55 - INFO - __main__ - Step 50 Global step 50 Train loss 0.96 on epoch=12
06/06/2022 10:33:56 - INFO - __main__ - Global step 50 Train loss 1.86 Classification-F1 0.1 on epoch=12
06/06/2022 10:33:56 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/06/2022 10:33:59 - INFO - __main__ - Step 60 Global step 60 Train loss 1.00 on epoch=14
06/06/2022 10:34:01 - INFO - __main__ - Step 70 Global step 70 Train loss 0.79 on epoch=17
06/06/2022 10:34:04 - INFO - __main__ - Step 80 Global step 80 Train loss 0.89 on epoch=19
06/06/2022 10:34:06 - INFO - __main__ - Step 90 Global step 90 Train loss 0.92 on epoch=22
06/06/2022 10:34:09 - INFO - __main__ - Step 100 Global step 100 Train loss 0.95 on epoch=24
06/06/2022 10:34:10 - INFO - __main__ - Global step 100 Train loss 0.91 Classification-F1 0.16938405797101447 on epoch=24
06/06/2022 10:34:10 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.16938405797101447 on epoch=24, global_step=100
06/06/2022 10:34:12 - INFO - __main__ - Step 110 Global step 110 Train loss 0.91 on epoch=27
06/06/2022 10:34:15 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=29
06/06/2022 10:34:18 - INFO - __main__ - Step 130 Global step 130 Train loss 0.87 on epoch=32
06/06/2022 10:34:20 - INFO - __main__ - Step 140 Global step 140 Train loss 0.82 on epoch=34
06/06/2022 10:34:23 - INFO - __main__ - Step 150 Global step 150 Train loss 0.74 on epoch=37
06/06/2022 10:34:23 - INFO - __main__ - Global step 150 Train loss 0.85 Classification-F1 0.5197567697567698 on epoch=37
06/06/2022 10:34:23 - INFO - __main__ - Saving model with best Classification-F1: 0.16938405797101447 -> 0.5197567697567698 on epoch=37, global_step=150
06/06/2022 10:34:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.75 on epoch=39
06/06/2022 10:34:29 - INFO - __main__ - Step 170 Global step 170 Train loss 0.77 on epoch=42
06/06/2022 10:34:31 - INFO - __main__ - Step 180 Global step 180 Train loss 0.60 on epoch=44
06/06/2022 10:34:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.55 on epoch=47
06/06/2022 10:34:37 - INFO - __main__ - Step 200 Global step 200 Train loss 0.52 on epoch=49
06/06/2022 10:34:37 - INFO - __main__ - Global step 200 Train loss 0.64 Classification-F1 0.5432618785559963 on epoch=49
06/06/2022 10:34:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5197567697567698 -> 0.5432618785559963 on epoch=49, global_step=200
06/06/2022 10:34:40 - INFO - __main__ - Step 210 Global step 210 Train loss 0.49 on epoch=52
06/06/2022 10:34:43 - INFO - __main__ - Step 220 Global step 220 Train loss 0.43 on epoch=54
06/06/2022 10:34:45 - INFO - __main__ - Step 230 Global step 230 Train loss 0.40 on epoch=57
06/06/2022 10:34:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=59
06/06/2022 10:34:51 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=62
06/06/2022 10:34:51 - INFO - __main__ - Global step 250 Train loss 0.42 Classification-F1 0.6100384440167722 on epoch=62
06/06/2022 10:34:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5432618785559963 -> 0.6100384440167722 on epoch=62, global_step=250
06/06/2022 10:34:54 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=64
06/06/2022 10:34:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=67
06/06/2022 10:34:59 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=69
06/06/2022 10:35:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=72
06/06/2022 10:35:04 - INFO - __main__ - Step 300 Global step 300 Train loss 0.31 on epoch=74
06/06/2022 10:35:05 - INFO - __main__ - Global step 300 Train loss 0.33 Classification-F1 0.5646213073538655 on epoch=74
06/06/2022 10:35:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=77
06/06/2022 10:35:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.36 on epoch=79
06/06/2022 10:35:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=82
06/06/2022 10:35:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.18 on epoch=84
06/06/2022 10:35:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.17 on epoch=87
06/06/2022 10:35:19 - INFO - __main__ - Global step 350 Train loss 0.24 Classification-F1 0.7232582582582583 on epoch=87
06/06/2022 10:35:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6100384440167722 -> 0.7232582582582583 on epoch=87, global_step=350
06/06/2022 10:35:22 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=89
06/06/2022 10:35:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.18 on epoch=92
06/06/2022 10:35:27 - INFO - __main__ - Step 380 Global step 380 Train loss 0.16 on epoch=94
06/06/2022 10:35:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.14 on epoch=97
06/06/2022 10:35:32 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=99
06/06/2022 10:35:33 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.6694444444444444 on epoch=99
06/06/2022 10:35:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.17 on epoch=102
06/06/2022 10:35:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=104
06/06/2022 10:35:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=107
06/06/2022 10:35:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=109
06/06/2022 10:35:46 - INFO - __main__ - Step 450 Global step 450 Train loss 0.09 on epoch=112
06/06/2022 10:35:47 - INFO - __main__ - Global step 450 Train loss 0.17 Classification-F1 0.673327213382293 on epoch=112
06/06/2022 10:35:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.10 on epoch=114
06/06/2022 10:35:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.11 on epoch=117
06/06/2022 10:35:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.11 on epoch=119
06/06/2022 10:35:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.10 on epoch=122
06/06/2022 10:35:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.12 on epoch=124
06/06/2022 10:36:00 - INFO - __main__ - Global step 500 Train loss 0.11 Classification-F1 0.6833333333333333 on epoch=124
06/06/2022 10:36:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.15 on epoch=127
06/06/2022 10:36:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.06 on epoch=129
06/06/2022 10:36:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.11 on epoch=132
06/06/2022 10:36:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=134
06/06/2022 10:36:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.08 on epoch=137
06/06/2022 10:36:14 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.7381535947712419 on epoch=137
06/06/2022 10:36:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7232582582582583 -> 0.7381535947712419 on epoch=137, global_step=550
06/06/2022 10:36:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.06 on epoch=139
06/06/2022 10:36:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=142
06/06/2022 10:36:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=144
06/06/2022 10:36:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=147
06/06/2022 10:36:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=149
06/06/2022 10:36:28 - INFO - __main__ - Global step 600 Train loss 0.09 Classification-F1 0.6838063295493636 on epoch=149
06/06/2022 10:36:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=152
06/06/2022 10:36:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.02 on epoch=154
06/06/2022 10:36:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=157
06/06/2022 10:36:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=159
06/06/2022 10:36:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=162
06/06/2022 10:36:42 - INFO - __main__ - Global step 650 Train loss 0.04 Classification-F1 0.7034703491926493 on epoch=162
06/06/2022 10:36:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=164
06/06/2022 10:36:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=167
06/06/2022 10:36:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=169
06/06/2022 10:36:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=172
06/06/2022 10:36:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=174
06/06/2022 10:36:56 - INFO - __main__ - Global step 700 Train loss 0.05 Classification-F1 0.6292476687213528 on epoch=174
06/06/2022 10:36:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=177
06/06/2022 10:37:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=179
06/06/2022 10:37:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=182
06/06/2022 10:37:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=184
06/06/2022 10:37:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.04 on epoch=187
06/06/2022 10:37:10 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.7186049686049686 on epoch=187
06/06/2022 10:37:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=189
06/06/2022 10:37:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=192
06/06/2022 10:37:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=194
06/06/2022 10:37:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=197
06/06/2022 10:37:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=199
06/06/2022 10:37:24 - INFO - __main__ - Global step 800 Train loss 0.03 Classification-F1 0.7061553030303029 on epoch=199
06/06/2022 10:37:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=202
06/06/2022 10:37:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=204
06/06/2022 10:37:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=207
06/06/2022 10:37:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=209
06/06/2022 10:37:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=212
06/06/2022 10:37:38 - INFO - __main__ - Global step 850 Train loss 0.03 Classification-F1 0.6926786663628768 on epoch=212
06/06/2022 10:37:40 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=214
06/06/2022 10:37:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=217
06/06/2022 10:37:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=219
06/06/2022 10:37:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/06/2022 10:37:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=224
06/06/2022 10:37:52 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.6808821808821809 on epoch=224
06/06/2022 10:37:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=227
06/06/2022 10:37:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/06/2022 10:38:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=232
06/06/2022 10:38:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
06/06/2022 10:38:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=237
06/06/2022 10:38:06 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.6826839826839828 on epoch=237
06/06/2022 10:38:09 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=239
06/06/2022 10:38:11 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/06/2022 10:38:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/06/2022 10:38:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
06/06/2022 10:38:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/06/2022 10:38:20 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.7528400168055572 on epoch=249
06/06/2022 10:38:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7381535947712419 -> 0.7528400168055572 on epoch=249, global_step=1000
06/06/2022 10:38:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=252
06/06/2022 10:38:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/06/2022 10:38:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=257
06/06/2022 10:38:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/06/2022 10:38:33 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/06/2022 10:38:34 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7091264651748523 on epoch=262
06/06/2022 10:38:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/06/2022 10:38:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=267
06/06/2022 10:38:42 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/06/2022 10:38:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/06/2022 10:38:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=274
06/06/2022 10:38:49 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.7367698726394378 on epoch=274
06/06/2022 10:38:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/06/2022 10:38:54 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/06/2022 10:38:57 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/06/2022 10:38:59 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/06/2022 10:39:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/06/2022 10:39:03 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7120829620829621 on epoch=287
06/06/2022 10:39:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/06/2022 10:39:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/06/2022 10:39:11 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/06/2022 10:39:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=297
06/06/2022 10:39:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/06/2022 10:39:17 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.7120829620829621 on epoch=299
06/06/2022 10:39:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/06/2022 10:39:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/06/2022 10:39:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/06/2022 10:39:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/06/2022 10:39:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=312
06/06/2022 10:39:31 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7434640522875817 on epoch=312
06/06/2022 10:39:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/06/2022 10:39:36 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/06/2022 10:39:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/06/2022 10:39:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/06/2022 10:39:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/06/2022 10:39:45 - INFO - __main__ - Global step 1300 Train loss 0.00 Classification-F1 0.7239292818576706 on epoch=324
06/06/2022 10:39:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/06/2022 10:39:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/06/2022 10:39:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/06/2022 10:39:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/06/2022 10:39:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/06/2022 10:39:59 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7239292818576706 on epoch=337
06/06/2022 10:40:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/06/2022 10:40:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/06/2022 10:40:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/06/2022 10:40:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/06/2022 10:40:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/06/2022 10:40:13 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7276587301587302 on epoch=349
06/06/2022 10:40:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/06/2022 10:40:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/06/2022 10:40:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/06/2022 10:40:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/06/2022 10:40:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/06/2022 10:40:27 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7250434454718343 on epoch=362
06/06/2022 10:40:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/06/2022 10:40:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/06/2022 10:40:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=369
06/06/2022 10:40:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/06/2022 10:40:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/06/2022 10:40:41 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7315842940842939 on epoch=374
06/06/2022 10:40:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/06/2022 10:40:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/06/2022 10:40:49 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=382
06/06/2022 10:40:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=384
06/06/2022 10:40:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/06/2022 10:40:55 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7245306069172001 on epoch=387
06/06/2022 10:40:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/06/2022 10:41:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/06/2022 10:41:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/06/2022 10:41:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/06/2022 10:41:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=399
06/06/2022 10:41:09 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7383327992023644 on epoch=399
06/06/2022 10:41:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/06/2022 10:41:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/06/2022 10:41:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/06/2022 10:41:19 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/06/2022 10:41:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/06/2022 10:41:23 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7521739130434782 on epoch=412
06/06/2022 10:41:26 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/06/2022 10:41:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/06/2022 10:41:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/06/2022 10:41:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/06/2022 10:41:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/06/2022 10:41:37 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7732323232323232 on epoch=424
06/06/2022 10:41:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7528400168055572 -> 0.7732323232323232 on epoch=424, global_step=1700
06/06/2022 10:41:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/06/2022 10:41:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/06/2022 10:41:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/06/2022 10:41:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/06/2022 10:41:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/06/2022 10:41:51 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7249084122485657 on epoch=437
06/06/2022 10:41:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/06/2022 10:41:56 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/06/2022 10:41:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/06/2022 10:42:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/06/2022 10:42:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/06/2022 10:42:05 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.7249084122485657 on epoch=449
06/06/2022 10:42:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=452
06/06/2022 10:42:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/06/2022 10:42:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/06/2022 10:42:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/06/2022 10:42:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/06/2022 10:42:19 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7109270793817839 on epoch=462
06/06/2022 10:42:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/06/2022 10:42:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/06/2022 10:42:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/06/2022 10:42:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/06/2022 10:42:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/06/2022 10:42:33 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7249084122485657 on epoch=474
06/06/2022 10:42:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/06/2022 10:42:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=479
06/06/2022 10:42:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/06/2022 10:42:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/06/2022 10:42:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/06/2022 10:42:46 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7392364892701412 on epoch=487
06/06/2022 10:42:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/06/2022 10:42:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/06/2022 10:42:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/06/2022 10:42:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/06/2022 10:42:59 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/06/2022 10:43:00 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7549201251646904 on epoch=499
06/06/2022 10:43:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/06/2022 10:43:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/06/2022 10:43:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/06/2022 10:43:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/06/2022 10:43:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/06/2022 10:43:14 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.7728758169934641 on epoch=512
06/06/2022 10:43:16 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/06/2022 10:43:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/06/2022 10:43:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/06/2022 10:43:24 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/06/2022 10:43:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/06/2022 10:43:27 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7728758169934641 on epoch=524
06/06/2022 10:43:30 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/06/2022 10:43:32 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 10:43:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/06/2022 10:43:38 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/06/2022 10:43:40 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/06/2022 10:43:41 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7557401568437222 on epoch=537
06/06/2022 10:43:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/06/2022 10:43:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 10:43:49 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/06/2022 10:43:51 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/06/2022 10:43:54 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/06/2022 10:43:55 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7732323232323232 on epoch=549
06/06/2022 10:43:58 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/06/2022 10:44:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/06/2022 10:44:03 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/06/2022 10:44:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/06/2022 10:44:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.11 on epoch=562
06/06/2022 10:44:09 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7670729029424681 on epoch=562
06/06/2022 10:44:12 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/06/2022 10:44:14 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/06/2022 10:44:17 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/06/2022 10:44:19 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/06/2022 10:44:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 10:44:23 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7582633053221288 on epoch=574
06/06/2022 10:44:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 10:44:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/06/2022 10:44:30 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/06/2022 10:44:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=584
06/06/2022 10:44:35 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 10:44:36 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7534843143538795 on epoch=587
06/06/2022 10:44:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/06/2022 10:44:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/06/2022 10:44:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 10:44:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/06/2022 10:44:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 10:44:50 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7534843143538795 on epoch=599
06/06/2022 10:44:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 10:44:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 10:44:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 10:45:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 10:45:03 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 10:45:04 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7534843143538795 on epoch=612
06/06/2022 10:45:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 10:45:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 10:45:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 10:45:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/06/2022 10:45:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 10:45:18 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7466748937337173 on epoch=624
06/06/2022 10:45:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/06/2022 10:45:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/06/2022 10:45:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/06/2022 10:45:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/06/2022 10:45:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 10:45:32 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7466748937337173 on epoch=637
06/06/2022 10:45:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 10:45:37 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.11 on epoch=642
06/06/2022 10:45:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=644
06/06/2022 10:45:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 10:45:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/06/2022 10:45:46 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7386118215402103 on epoch=649
06/06/2022 10:45:49 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=652
06/06/2022 10:45:51 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 10:45:54 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/06/2022 10:45:56 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=659
06/06/2022 10:45:59 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/06/2022 10:46:00 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7386118215402103 on epoch=662
06/06/2022 10:46:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 10:46:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 10:46:08 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=669
06/06/2022 10:46:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 10:46:13 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 10:46:14 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7392951251646904 on epoch=674
06/06/2022 10:46:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=677
06/06/2022 10:46:19 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 10:46:22 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 10:46:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 10:46:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 10:46:28 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7621449792038028 on epoch=687
06/06/2022 10:46:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 10:46:33 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 10:46:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/06/2022 10:46:38 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 10:46:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 10:46:42 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7621449792038028 on epoch=699
06/06/2022 10:46:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 10:46:47 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 10:46:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 10:46:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/06/2022 10:46:55 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 10:46:56 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7770588235294118 on epoch=712
06/06/2022 10:46:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7732323232323232 -> 0.7770588235294118 on epoch=712, global_step=2850
06/06/2022 10:46:59 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 10:47:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 10:47:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 10:47:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/06/2022 10:47:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=724
06/06/2022 10:47:10 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7763261648745521 on epoch=724
06/06/2022 10:47:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
06/06/2022 10:47:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 10:47:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 10:47:20 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 10:47:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 10:47:24 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7914583333333334 on epoch=737
06/06/2022 10:47:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7770588235294118 -> 0.7914583333333334 on epoch=737, global_step=2950
06/06/2022 10:47:27 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=739
06/06/2022 10:47:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.10 on epoch=742
06/06/2022 10:47:32 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 10:47:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/06/2022 10:47:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 10:47:38 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.776201923076923 on epoch=749
06/06/2022 10:47:38 - INFO - __main__ - save last model!
06/06/2022 10:47:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 10:47:38 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 10:47:38 - INFO - __main__ - Printing 3 examples
06/06/2022 10:47:38 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 10:47:38 - INFO - __main__ - ['others']
06/06/2022 10:47:38 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 10:47:38 - INFO - __main__ - ['others']
06/06/2022 10:47:38 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 10:47:38 - INFO - __main__ - ['others']
06/06/2022 10:47:38 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:47:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 10:47:38 - INFO - __main__ - Printing 3 examples
06/06/2022 10:47:38 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/06/2022 10:47:38 - INFO - __main__ - ['others']
06/06/2022 10:47:38 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/06/2022 10:47:38 - INFO - __main__ - ['others']
06/06/2022 10:47:38 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/06/2022 10:47:38 - INFO - __main__ - ['others']
06/06/2022 10:47:38 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:47:38 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:47:38 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 10:47:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 10:47:38 - INFO - __main__ - Printing 3 examples
06/06/2022 10:47:38 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/06/2022 10:47:38 - INFO - __main__ - ['others']
06/06/2022 10:47:38 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/06/2022 10:47:38 - INFO - __main__ - ['others']
06/06/2022 10:47:38 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/06/2022 10:47:38 - INFO - __main__ - ['others']
06/06/2022 10:47:38 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:47:38 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:47:38 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 10:47:40 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:47:46 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 10:47:55 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 10:47:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 10:47:56 - INFO - __main__ - Starting training!
06/06/2022 10:49:23 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_87_0.4_8_predictions.txt
06/06/2022 10:49:23 - INFO - __main__ - Classification-F1 on test data: 0.1404
06/06/2022 10:49:24 - INFO - __main__ - prefix=emo_16_87, lr=0.4, bsz=8, dev_performance=0.7914583333333334, test_performance=0.14035241278546784
06/06/2022 10:49:24 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.3, bsz=8 ...
06/06/2022 10:49:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 10:49:25 - INFO - __main__ - Printing 3 examples
06/06/2022 10:49:25 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/06/2022 10:49:25 - INFO - __main__ - ['others']
06/06/2022 10:49:25 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/06/2022 10:49:25 - INFO - __main__ - ['others']
06/06/2022 10:49:25 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/06/2022 10:49:25 - INFO - __main__ - ['others']
06/06/2022 10:49:25 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:49:25 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:49:25 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 10:49:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 10:49:25 - INFO - __main__ - Printing 3 examples
06/06/2022 10:49:25 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/06/2022 10:49:25 - INFO - __main__ - ['others']
06/06/2022 10:49:25 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/06/2022 10:49:25 - INFO - __main__ - ['others']
06/06/2022 10:49:25 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/06/2022 10:49:25 - INFO - __main__ - ['others']
06/06/2022 10:49:25 - INFO - __main__ - Tokenizing Input ...
06/06/2022 10:49:25 - INFO - __main__ - Tokenizing Output ...
06/06/2022 10:49:25 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 10:49:43 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 10:49:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 10:49:44 - INFO - __main__ - Starting training!
06/06/2022 10:49:47 - INFO - __main__ - Step 10 Global step 10 Train loss 3.55 on epoch=2
06/06/2022 10:49:50 - INFO - __main__ - Step 20 Global step 20 Train loss 2.22 on epoch=4
06/06/2022 10:49:53 - INFO - __main__ - Step 30 Global step 30 Train loss 1.51 on epoch=7
06/06/2022 10:49:55 - INFO - __main__ - Step 40 Global step 40 Train loss 1.22 on epoch=9
06/06/2022 10:49:58 - INFO - __main__ - Step 50 Global step 50 Train loss 1.12 on epoch=12
06/06/2022 10:49:59 - INFO - __main__ - Global step 50 Train loss 1.92 Classification-F1 0.1565276828434723 on epoch=12
06/06/2022 10:49:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1565276828434723 on epoch=12, global_step=50
06/06/2022 10:50:01 - INFO - __main__ - Step 60 Global step 60 Train loss 1.01 on epoch=14
06/06/2022 10:50:04 - INFO - __main__ - Step 70 Global step 70 Train loss 1.00 on epoch=17
06/06/2022 10:50:06 - INFO - __main__ - Step 80 Global step 80 Train loss 1.01 on epoch=19
06/06/2022 10:50:09 - INFO - __main__ - Step 90 Global step 90 Train loss 0.99 on epoch=22
06/06/2022 10:50:11 - INFO - __main__ - Step 100 Global step 100 Train loss 0.84 on epoch=24
06/06/2022 10:50:12 - INFO - __main__ - Global step 100 Train loss 0.97 Classification-F1 0.1 on epoch=24
06/06/2022 10:50:15 - INFO - __main__ - Step 110 Global step 110 Train loss 0.89 on epoch=27
06/06/2022 10:50:17 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=29
06/06/2022 10:50:20 - INFO - __main__ - Step 130 Global step 130 Train loss 0.90 on epoch=32
06/06/2022 10:50:22 - INFO - __main__ - Step 140 Global step 140 Train loss 0.83 on epoch=34
06/06/2022 10:50:25 - INFO - __main__ - Step 150 Global step 150 Train loss 0.89 on epoch=37
06/06/2022 10:50:26 - INFO - __main__ - Global step 150 Train loss 0.88 Classification-F1 0.23723653395784544 on epoch=37
06/06/2022 10:50:26 - INFO - __main__ - Saving model with best Classification-F1: 0.1565276828434723 -> 0.23723653395784544 on epoch=37, global_step=150
06/06/2022 10:50:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.92 on epoch=39
06/06/2022 10:50:31 - INFO - __main__ - Step 170 Global step 170 Train loss 0.79 on epoch=42
06/06/2022 10:50:34 - INFO - __main__ - Step 180 Global step 180 Train loss 0.84 on epoch=44
06/06/2022 10:50:36 - INFO - __main__ - Step 190 Global step 190 Train loss 0.79 on epoch=47
06/06/2022 10:50:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.69 on epoch=49
06/06/2022 10:50:39 - INFO - __main__ - Global step 200 Train loss 0.81 Classification-F1 0.28543220710838085 on epoch=49
06/06/2022 10:50:40 - INFO - __main__ - Saving model with best Classification-F1: 0.23723653395784544 -> 0.28543220710838085 on epoch=49, global_step=200
06/06/2022 10:50:42 - INFO - __main__ - Step 210 Global step 210 Train loss 0.62 on epoch=52
06/06/2022 10:50:45 - INFO - __main__ - Step 220 Global step 220 Train loss 0.56 on epoch=54
06/06/2022 10:50:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=57
06/06/2022 10:50:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.51 on epoch=59
06/06/2022 10:50:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.53 on epoch=62
06/06/2022 10:50:53 - INFO - __main__ - Global step 250 Train loss 0.57 Classification-F1 0.5902132782937737 on epoch=62
06/06/2022 10:50:53 - INFO - __main__ - Saving model with best Classification-F1: 0.28543220710838085 -> 0.5902132782937737 on epoch=62, global_step=250
06/06/2022 10:50:56 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=64
06/06/2022 10:50:58 - INFO - __main__ - Step 270 Global step 270 Train loss 0.49 on epoch=67
06/06/2022 10:51:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=69
06/06/2022 10:51:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.42 on epoch=72
06/06/2022 10:51:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.43 on epoch=74
06/06/2022 10:51:07 - INFO - __main__ - Global step 300 Train loss 0.46 Classification-F1 0.5864927517304428 on epoch=74
06/06/2022 10:51:09 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=77
06/06/2022 10:51:12 - INFO - __main__ - Step 320 Global step 320 Train loss 0.31 on epoch=79
06/06/2022 10:51:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=82
06/06/2022 10:51:17 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=84
06/06/2022 10:51:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=87
06/06/2022 10:51:21 - INFO - __main__ - Global step 350 Train loss 0.36 Classification-F1 0.6381530165149982 on epoch=87
06/06/2022 10:51:21 - INFO - __main__ - Saving model with best Classification-F1: 0.5902132782937737 -> 0.6381530165149982 on epoch=87, global_step=350
06/06/2022 10:51:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.55 on epoch=89
06/06/2022 10:51:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=92
06/06/2022 10:51:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=94
06/06/2022 10:51:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=97
06/06/2022 10:51:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=99
06/06/2022 10:51:34 - INFO - __main__ - Global step 400 Train loss 0.33 Classification-F1 0.7731944444444444 on epoch=99
06/06/2022 10:51:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6381530165149982 -> 0.7731944444444444 on epoch=99, global_step=400
06/06/2022 10:51:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=102
06/06/2022 10:51:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/06/2022 10:51:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=107
06/06/2022 10:51:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.18 on epoch=109
06/06/2022 10:51:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=112
06/06/2022 10:51:48 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.7385101010101011 on epoch=112
06/06/2022 10:51:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.19 on epoch=114
06/06/2022 10:51:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=117
06/06/2022 10:51:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=119
06/06/2022 10:51:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=122
06/06/2022 10:52:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=124
06/06/2022 10:52:01 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.7621062271062271 on epoch=124
06/06/2022 10:52:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=127
06/06/2022 10:52:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=129
06/06/2022 10:52:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=132
06/06/2022 10:52:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/06/2022 10:52:14 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=137
06/06/2022 10:52:15 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.7492388940664803 on epoch=137
06/06/2022 10:52:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.06 on epoch=139
06/06/2022 10:52:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=142
06/06/2022 10:52:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=144
06/06/2022 10:52:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.11 on epoch=147
06/06/2022 10:52:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=149
06/06/2022 10:52:29 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.743840579710145 on epoch=149
06/06/2022 10:52:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=152
06/06/2022 10:52:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=154
06/06/2022 10:52:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=157
06/06/2022 10:52:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=159
06/06/2022 10:52:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=162
06/06/2022 10:52:42 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.814656015100954 on epoch=162
06/06/2022 10:52:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7731944444444444 -> 0.814656015100954 on epoch=162, global_step=650
06/06/2022 10:52:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=164
06/06/2022 10:52:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=167
06/06/2022 10:52:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=169
06/06/2022 10:52:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=172
06/06/2022 10:52:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=174
06/06/2022 10:52:56 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.71565887224455 on epoch=174
06/06/2022 10:52:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=177
06/06/2022 10:53:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=179
06/06/2022 10:53:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=182
06/06/2022 10:53:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=184
06/06/2022 10:53:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=187
06/06/2022 10:53:10 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.6845373237014104 on epoch=187
06/06/2022 10:53:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=189
06/06/2022 10:53:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=192
06/06/2022 10:53:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=194
06/06/2022 10:53:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=197
06/06/2022 10:53:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/06/2022 10:53:23 - INFO - __main__ - Global step 800 Train loss 0.04 Classification-F1 0.7763746057863705 on epoch=199
06/06/2022 10:53:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=202
06/06/2022 10:53:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/06/2022 10:53:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=207
06/06/2022 10:53:33 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=209
06/06/2022 10:53:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/06/2022 10:53:37 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.77845155062897 on epoch=212
06/06/2022 10:53:40 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=214
06/06/2022 10:53:42 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=217
06/06/2022 10:53:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
06/06/2022 10:53:47 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
06/06/2022 10:53:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
06/06/2022 10:53:51 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7571726190476191 on epoch=224
06/06/2022 10:53:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=227
06/06/2022 10:53:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=229
06/06/2022 10:53:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=232
06/06/2022 10:54:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/06/2022 10:54:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
06/06/2022 10:54:05 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.7745007680491551 on epoch=237
06/06/2022 10:54:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
06/06/2022 10:54:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
06/06/2022 10:54:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/06/2022 10:54:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=247
06/06/2022 10:54:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/06/2022 10:54:18 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.805366202425026 on epoch=249
06/06/2022 10:54:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=252
06/06/2022 10:54:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/06/2022 10:54:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=257
06/06/2022 10:54:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/06/2022 10:54:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/06/2022 10:54:32 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7717647058823529 on epoch=262
06/06/2022 10:54:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/06/2022 10:54:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
06/06/2022 10:54:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
06/06/2022 10:54:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/06/2022 10:54:45 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/06/2022 10:54:46 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.695993932942607 on epoch=274
06/06/2022 10:54:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/06/2022 10:54:51 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/06/2022 10:54:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=282
06/06/2022 10:54:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=284
06/06/2022 10:54:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/06/2022 10:55:00 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7806753136037025 on epoch=287
06/06/2022 10:55:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/06/2022 10:55:06 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/06/2022 10:55:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/06/2022 10:55:11 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=297
06/06/2022 10:55:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/06/2022 10:55:15 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.7709839180427417 on epoch=299
06/06/2022 10:55:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/06/2022 10:55:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/06/2022 10:55:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/06/2022 10:55:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/06/2022 10:55:28 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/06/2022 10:55:29 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7601450257522364 on epoch=312
06/06/2022 10:55:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/06/2022 10:55:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/06/2022 10:55:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/06/2022 10:55:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/06/2022 10:55:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/06/2022 10:55:43 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.7561188811188813 on epoch=324
06/06/2022 10:55:45 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/06/2022 10:55:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=329
06/06/2022 10:55:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/06/2022 10:55:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/06/2022 10:55:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/06/2022 10:55:57 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7561188811188813 on epoch=337
06/06/2022 10:55:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/06/2022 10:56:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/06/2022 10:56:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/06/2022 10:56:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/06/2022 10:56:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/06/2022 10:56:10 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7561188811188813 on epoch=349
06/06/2022 10:56:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/06/2022 10:56:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/06/2022 10:56:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/06/2022 10:56:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/06/2022 10:56:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/06/2022 10:56:24 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7905597722960153 on epoch=362
06/06/2022 10:56:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/06/2022 10:56:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/06/2022 10:56:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/06/2022 10:56:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=372
06/06/2022 10:56:37 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/06/2022 10:56:38 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7935518782292976 on epoch=374
06/06/2022 10:56:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/06/2022 10:56:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/06/2022 10:56:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/06/2022 10:56:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/06/2022 10:56:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=387
06/06/2022 10:56:52 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7711853832442068 on epoch=387
06/06/2022 10:56:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/06/2022 10:56:57 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/06/2022 10:57:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/06/2022 10:57:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=397
06/06/2022 10:57:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/06/2022 10:57:06 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.8092382154882155 on epoch=399
06/06/2022 10:57:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/06/2022 10:57:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/06/2022 10:57:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/06/2022 10:57:17 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/06/2022 10:57:19 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/06/2022 10:57:20 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.8092382154882155 on epoch=412
06/06/2022 10:57:23 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/06/2022 10:57:26 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=417
06/06/2022 10:57:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/06/2022 10:57:31 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/06/2022 10:57:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/06/2022 10:57:35 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8116248693834901 on epoch=424
06/06/2022 10:57:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/06/2022 10:57:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/06/2022 10:57:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/06/2022 10:57:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/06/2022 10:57:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/06/2022 10:57:49 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.8441613366703745 on epoch=437
06/06/2022 10:57:49 - INFO - __main__ - Saving model with best Classification-F1: 0.814656015100954 -> 0.8441613366703745 on epoch=437, global_step=1750
06/06/2022 10:57:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/06/2022 10:57:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/06/2022 10:57:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/06/2022 10:57:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
06/06/2022 10:58:01 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/06/2022 10:58:03 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.8119032721542455 on epoch=449
06/06/2022 10:58:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=452
06/06/2022 10:58:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/06/2022 10:58:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/06/2022 10:58:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/06/2022 10:58:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/06/2022 10:58:17 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7572964943553179 on epoch=462
06/06/2022 10:58:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/06/2022 10:58:22 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/06/2022 10:58:24 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/06/2022 10:58:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=472
06/06/2022 10:58:29 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=474
06/06/2022 10:58:31 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7860504201680674 on epoch=474
06/06/2022 10:58:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/06/2022 10:58:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/06/2022 10:58:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/06/2022 10:58:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/06/2022 10:58:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=487
06/06/2022 10:58:45 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7711853832442068 on epoch=487
06/06/2022 10:58:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/06/2022 10:58:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/06/2022 10:58:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/06/2022 10:58:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/06/2022 10:58:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=499
06/06/2022 10:58:59 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.791339398075641 on epoch=499
06/06/2022 10:59:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/06/2022 10:59:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/06/2022 10:59:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/06/2022 10:59:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/06/2022 10:59:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/06/2022 10:59:12 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.7860504201680674 on epoch=512
06/06/2022 10:59:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/06/2022 10:59:18 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/06/2022 10:59:20 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/06/2022 10:59:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=522
06/06/2022 10:59:25 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/06/2022 10:59:26 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7905011655011656 on epoch=524
06/06/2022 10:59:29 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/06/2022 10:59:31 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 10:59:34 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/06/2022 10:59:37 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/06/2022 10:59:39 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/06/2022 10:59:40 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.805366202425026 on epoch=537
06/06/2022 10:59:43 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/06/2022 10:59:45 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 10:59:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/06/2022 10:59:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/06/2022 10:59:53 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/06/2022 10:59:54 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.8269199573600297 on epoch=549
06/06/2022 10:59:56 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 10:59:59 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/06/2022 11:00:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/06/2022 11:00:04 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/06/2022 11:00:07 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/06/2022 11:00:08 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8087647306397306 on epoch=562
06/06/2022 11:00:10 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/06/2022 11:00:13 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=567
06/06/2022 11:00:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/06/2022 11:00:18 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/06/2022 11:00:21 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 11:00:22 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7711853832442068 on epoch=574
06/06/2022 11:00:24 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 11:00:27 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 11:00:29 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/06/2022 11:00:32 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/06/2022 11:00:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 11:00:35 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7757117269984917 on epoch=587
06/06/2022 11:00:38 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/06/2022 11:00:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=592
06/06/2022 11:00:43 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 11:00:46 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/06/2022 11:00:48 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 11:00:50 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.805366202425026 on epoch=599
06/06/2022 11:00:52 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 11:00:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 11:00:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 11:01:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 11:01:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 11:01:03 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7711853832442068 on epoch=612
06/06/2022 11:01:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/06/2022 11:01:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 11:01:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/06/2022 11:01:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/06/2022 11:01:16 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 11:01:17 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7754008379008379 on epoch=624
06/06/2022 11:01:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=627
06/06/2022 11:01:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/06/2022 11:01:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/06/2022 11:01:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/06/2022 11:01:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 11:01:31 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7780812324929972 on epoch=637
06/06/2022 11:01:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 11:01:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/06/2022 11:01:39 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 11:01:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 11:01:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 11:01:45 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7560850556438792 on epoch=649
06/06/2022 11:01:48 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/06/2022 11:01:50 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 11:01:53 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/06/2022 11:01:55 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 11:01:58 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/06/2022 11:01:59 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.77845155062897 on epoch=662
06/06/2022 11:02:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 11:02:04 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.10 on epoch=667
06/06/2022 11:02:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 11:02:09 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 11:02:12 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 11:02:13 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7860504201680674 on epoch=674
06/06/2022 11:02:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/06/2022 11:02:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 11:02:20 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.19 on epoch=682
06/06/2022 11:02:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 11:02:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 11:02:27 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7860504201680674 on epoch=687
06/06/2022 11:02:29 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 11:02:32 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/06/2022 11:02:34 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/06/2022 11:02:37 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.18 on epoch=697
06/06/2022 11:02:39 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 11:02:40 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7711853832442068 on epoch=699
06/06/2022 11:02:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 11:02:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/06/2022 11:02:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.08 on epoch=707
06/06/2022 11:02:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/06/2022 11:02:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 11:02:54 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7561188811188813 on epoch=712
06/06/2022 11:02:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 11:02:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 11:03:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 11:03:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/06/2022 11:03:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/06/2022 11:03:08 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7868347338935574 on epoch=724
06/06/2022 11:03:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 11:03:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.10 on epoch=729
06/06/2022 11:03:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 11:03:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 11:03:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 11:03:22 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7860504201680674 on epoch=737
06/06/2022 11:03:24 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 11:03:27 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 11:03:29 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/06/2022 11:03:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/06/2022 11:03:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 11:03:36 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7860504201680674 on epoch=749
06/06/2022 11:03:36 - INFO - __main__ - save last model!
06/06/2022 11:03:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 11:03:36 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 11:03:36 - INFO - __main__ - Printing 3 examples
06/06/2022 11:03:36 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 11:03:36 - INFO - __main__ - ['others']
06/06/2022 11:03:36 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 11:03:36 - INFO - __main__ - ['others']
06/06/2022 11:03:36 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 11:03:36 - INFO - __main__ - ['others']
06/06/2022 11:03:36 - INFO - __main__ - Tokenizing Input ...
06/06/2022 11:03:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 11:03:36 - INFO - __main__ - Printing 3 examples
06/06/2022 11:03:36 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/06/2022 11:03:36 - INFO - __main__ - ['others']
06/06/2022 11:03:36 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/06/2022 11:03:36 - INFO - __main__ - ['others']
06/06/2022 11:03:36 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/06/2022 11:03:36 - INFO - __main__ - ['others']
06/06/2022 11:03:36 - INFO - __main__ - Tokenizing Input ...
06/06/2022 11:03:36 - INFO - __main__ - Tokenizing Output ...
06/06/2022 11:03:36 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 11:03:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 11:03:36 - INFO - __main__ - Printing 3 examples
06/06/2022 11:03:36 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/06/2022 11:03:36 - INFO - __main__ - ['others']
06/06/2022 11:03:36 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/06/2022 11:03:36 - INFO - __main__ - ['others']
06/06/2022 11:03:36 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/06/2022 11:03:36 - INFO - __main__ - ['others']
06/06/2022 11:03:36 - INFO - __main__ - Tokenizing Input ...
06/06/2022 11:03:36 - INFO - __main__ - Tokenizing Output ...
06/06/2022 11:03:36 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 11:03:38 - INFO - __main__ - Tokenizing Output ...
06/06/2022 11:03:43 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 11:03:52 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 11:03:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 11:03:53 - INFO - __main__ - Starting training!
06/06/2022 11:05:21 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_87_0.3_8_predictions.txt
06/06/2022 11:05:21 - INFO - __main__ - Classification-F1 on test data: 0.3486
06/06/2022 11:05:21 - INFO - __main__ - prefix=emo_16_87, lr=0.3, bsz=8, dev_performance=0.8441613366703745, test_performance=0.3485863510165856
06/06/2022 11:05:21 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.2, bsz=8 ...
06/06/2022 11:05:22 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 11:05:22 - INFO - __main__ - Printing 3 examples
06/06/2022 11:05:22 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/06/2022 11:05:22 - INFO - __main__ - ['others']
06/06/2022 11:05:22 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/06/2022 11:05:22 - INFO - __main__ - ['others']
06/06/2022 11:05:22 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/06/2022 11:05:22 - INFO - __main__ - ['others']
06/06/2022 11:05:22 - INFO - __main__ - Tokenizing Input ...
06/06/2022 11:05:22 - INFO - __main__ - Tokenizing Output ...
06/06/2022 11:05:22 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 11:05:22 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 11:05:22 - INFO - __main__ - Printing 3 examples
06/06/2022 11:05:22 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/06/2022 11:05:22 - INFO - __main__ - ['others']
06/06/2022 11:05:22 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/06/2022 11:05:22 - INFO - __main__ - ['others']
06/06/2022 11:05:22 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/06/2022 11:05:22 - INFO - __main__ - ['others']
06/06/2022 11:05:22 - INFO - __main__ - Tokenizing Input ...
06/06/2022 11:05:22 - INFO - __main__ - Tokenizing Output ...
06/06/2022 11:05:22 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 11:05:38 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 11:05:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 11:05:39 - INFO - __main__ - Starting training!
06/06/2022 11:05:43 - INFO - __main__ - Step 10 Global step 10 Train loss 3.89 on epoch=2
06/06/2022 11:05:45 - INFO - __main__ - Step 20 Global step 20 Train loss 2.68 on epoch=4
06/06/2022 11:05:48 - INFO - __main__ - Step 30 Global step 30 Train loss 2.06 on epoch=7
06/06/2022 11:05:50 - INFO - __main__ - Step 40 Global step 40 Train loss 1.62 on epoch=9
06/06/2022 11:05:53 - INFO - __main__ - Step 50 Global step 50 Train loss 1.26 on epoch=12
06/06/2022 11:05:54 - INFO - __main__ - Global step 50 Train loss 2.30 Classification-F1 0.0974025974025974 on epoch=12
06/06/2022 11:05:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0974025974025974 on epoch=12, global_step=50
06/06/2022 11:05:57 - INFO - __main__ - Step 60 Global step 60 Train loss 1.08 on epoch=14
06/06/2022 11:05:59 - INFO - __main__ - Step 70 Global step 70 Train loss 1.06 on epoch=17
06/06/2022 11:06:02 - INFO - __main__ - Step 80 Global step 80 Train loss 1.04 on epoch=19
06/06/2022 11:06:04 - INFO - __main__ - Step 90 Global step 90 Train loss 0.87 on epoch=22
06/06/2022 11:06:07 - INFO - __main__ - Step 100 Global step 100 Train loss 0.91 on epoch=24
06/06/2022 11:06:08 - INFO - __main__ - Global step 100 Train loss 0.99 Classification-F1 0.1 on epoch=24
06/06/2022 11:06:08 - INFO - __main__ - Saving model with best Classification-F1: 0.0974025974025974 -> 0.1 on epoch=24, global_step=100
06/06/2022 11:06:10 - INFO - __main__ - Step 110 Global step 110 Train loss 0.93 on epoch=27
06/06/2022 11:06:13 - INFO - __main__ - Step 120 Global step 120 Train loss 1.02 on epoch=29
06/06/2022 11:06:15 - INFO - __main__ - Step 130 Global step 130 Train loss 0.96 on epoch=32
06/06/2022 11:06:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.84 on epoch=34
06/06/2022 11:06:20 - INFO - __main__ - Step 150 Global step 150 Train loss 0.94 on epoch=37
06/06/2022 11:06:21 - INFO - __main__ - Global step 150 Train loss 0.94 Classification-F1 0.28225516621743035 on epoch=37
06/06/2022 11:06:21 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.28225516621743035 on epoch=37, global_step=150
06/06/2022 11:06:24 - INFO - __main__ - Step 160 Global step 160 Train loss 0.93 on epoch=39
06/06/2022 11:06:27 - INFO - __main__ - Step 170 Global step 170 Train loss 0.94 on epoch=42
06/06/2022 11:06:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.95 on epoch=44
06/06/2022 11:06:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.86 on epoch=47
06/06/2022 11:06:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.89 on epoch=49
06/06/2022 11:06:35 - INFO - __main__ - Global step 200 Train loss 0.92 Classification-F1 0.17142857142857143 on epoch=49
06/06/2022 11:06:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.87 on epoch=52
06/06/2022 11:06:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.79 on epoch=54
06/06/2022 11:06:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.85 on epoch=57
06/06/2022 11:06:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.86 on epoch=59
06/06/2022 11:06:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.85 on epoch=62
06/06/2022 11:06:49 - INFO - __main__ - Global step 250 Train loss 0.84 Classification-F1 0.2862937062937063 on epoch=62
06/06/2022 11:06:49 - INFO - __main__ - Saving model with best Classification-F1: 0.28225516621743035 -> 0.2862937062937063 on epoch=62, global_step=250
06/06/2022 11:06:52 - INFO - __main__ - Step 260 Global step 260 Train loss 0.85 on epoch=64
06/06/2022 11:06:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.77 on epoch=67
06/06/2022 11:06:57 - INFO - __main__ - Step 280 Global step 280 Train loss 0.79 on epoch=69
06/06/2022 11:06:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.80 on epoch=72
06/06/2022 11:07:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.75 on epoch=74
06/06/2022 11:07:03 - INFO - __main__ - Global step 300 Train loss 0.79 Classification-F1 0.3581196977423392 on epoch=74
06/06/2022 11:07:03 - INFO - __main__ - Saving model with best Classification-F1: 0.2862937062937063 -> 0.3581196977423392 on epoch=74, global_step=300
06/06/2022 11:07:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.74 on epoch=77
06/06/2022 11:07:08 - INFO - __main__ - Step 320 Global step 320 Train loss 0.69 on epoch=79
06/06/2022 11:07:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.62 on epoch=82
06/06/2022 11:07:13 - INFO - __main__ - Step 340 Global step 340 Train loss 0.62 on epoch=84
06/06/2022 11:07:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.62 on epoch=87
06/06/2022 11:07:16 - INFO - __main__ - Global step 350 Train loss 0.66 Classification-F1 0.5805555555555555 on epoch=87
06/06/2022 11:07:16 - INFO - __main__ - Saving model with best Classification-F1: 0.3581196977423392 -> 0.5805555555555555 on epoch=87, global_step=350
06/06/2022 11:07:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.64 on epoch=89
06/06/2022 11:07:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.56 on epoch=92
06/06/2022 11:07:24 - INFO - __main__ - Step 380 Global step 380 Train loss 0.58 on epoch=94
06/06/2022 11:07:26 - INFO - __main__ - Step 390 Global step 390 Train loss 0.56 on epoch=97
06/06/2022 11:07:29 - INFO - __main__ - Step 400 Global step 400 Train loss 0.46 on epoch=99
06/06/2022 11:07:30 - INFO - __main__ - Global step 400 Train loss 0.56 Classification-F1 0.5032020872865275 on epoch=99
06/06/2022 11:07:32 - INFO - __main__ - Step 410 Global step 410 Train loss 0.52 on epoch=102
06/06/2022 11:07:35 - INFO - __main__ - Step 420 Global step 420 Train loss 0.54 on epoch=104
06/06/2022 11:07:38 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=107
06/06/2022 11:07:40 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=109
06/06/2022 11:07:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=112
06/06/2022 11:07:43 - INFO - __main__ - Global step 450 Train loss 0.44 Classification-F1 0.5623335886493781 on epoch=112
06/06/2022 11:07:46 - INFO - __main__ - Step 460 Global step 460 Train loss 0.49 on epoch=114
06/06/2022 11:07:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.45 on epoch=117
06/06/2022 11:07:51 - INFO - __main__ - Step 480 Global step 480 Train loss 0.34 on epoch=119
06/06/2022 11:07:54 - INFO - __main__ - Step 490 Global step 490 Train loss 0.34 on epoch=122
06/06/2022 11:07:56 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=124
06/06/2022 11:07:57 - INFO - __main__ - Global step 500 Train loss 0.39 Classification-F1 0.6558558558558558 on epoch=124
06/06/2022 11:07:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5805555555555555 -> 0.6558558558558558 on epoch=124, global_step=500
06/06/2022 11:08:00 - INFO - __main__ - Step 510 Global step 510 Train loss 0.35 on epoch=127
06/06/2022 11:08:02 - INFO - __main__ - Step 520 Global step 520 Train loss 0.35 on epoch=129
06/06/2022 11:08:05 - INFO - __main__ - Step 530 Global step 530 Train loss 0.33 on epoch=132
06/06/2022 11:08:08 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=134
06/06/2022 11:08:10 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=137
06/06/2022 11:08:11 - INFO - __main__ - Global step 550 Train loss 0.32 Classification-F1 0.6577048682311841 on epoch=137
06/06/2022 11:08:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6558558558558558 -> 0.6577048682311841 on epoch=137, global_step=550
06/06/2022 11:08:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=139
06/06/2022 11:08:16 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=142
06/06/2022 11:08:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=144
06/06/2022 11:08:21 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=147
06/06/2022 11:08:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.29 on epoch=149
06/06/2022 11:08:25 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.6564745196324143 on epoch=149
06/06/2022 11:08:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=152
06/06/2022 11:08:30 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=154
06/06/2022 11:08:32 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=157
06/06/2022 11:08:35 - INFO - __main__ - Step 640 Global step 640 Train loss 0.28 on epoch=159
06/06/2022 11:08:37 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=162
06/06/2022 11:08:38 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.6952039188881294 on epoch=162
06/06/2022 11:08:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6577048682311841 -> 0.6952039188881294 on epoch=162, global_step=650
06/06/2022 11:08:41 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=164
06/06/2022 11:08:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=167
06/06/2022 11:08:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=169
06/06/2022 11:08:49 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=172
06/06/2022 11:08:51 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=174
06/06/2022 11:08:52 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.6417424211541859 on epoch=174
06/06/2022 11:08:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.27 on epoch=177
06/06/2022 11:08:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=179
06/06/2022 11:09:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=182
06/06/2022 11:09:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=184
06/06/2022 11:09:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=187
06/06/2022 11:09:06 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.6584345479082321 on epoch=187
06/06/2022 11:09:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=189
06/06/2022 11:09:11 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=192
06/06/2022 11:09:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=194
06/06/2022 11:09:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=197
06/06/2022 11:09:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=199
06/06/2022 11:09:20 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.6965818759936407 on epoch=199
06/06/2022 11:09:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6952039188881294 -> 0.6965818759936407 on epoch=199, global_step=800
06/06/2022 11:09:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/06/2022 11:09:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=204
06/06/2022 11:09:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=207
06/06/2022 11:09:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=209
06/06/2022 11:09:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=212
06/06/2022 11:09:33 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.6873423423423424 on epoch=212
06/06/2022 11:09:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=214
06/06/2022 11:09:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=217
06/06/2022 11:09:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=219
06/06/2022 11:09:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=222
06/06/2022 11:09:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=224
06/06/2022 11:09:47 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.7074646074646075 on epoch=224
06/06/2022 11:09:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6965818759936407 -> 0.7074646074646075 on epoch=224, global_step=900
06/06/2022 11:09:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=227
06/06/2022 11:09:52 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=229
06/06/2022 11:09:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=232
06/06/2022 11:09:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=234
06/06/2022 11:10:00 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=237
06/06/2022 11:10:01 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.7303921568627452 on epoch=237
06/06/2022 11:10:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7074646074646075 -> 0.7303921568627452 on epoch=237, global_step=950
06/06/2022 11:10:03 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/06/2022 11:10:06 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=242
06/06/2022 11:10:08 - INFO - __main__ - Step 980 Global step 980 Train loss 0.20 on epoch=244
06/06/2022 11:10:11 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=247
06/06/2022 11:10:13 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=249
06/06/2022 11:10:14 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.7285857285857286 on epoch=249
06/06/2022 11:10:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=252
06/06/2022 11:10:19 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=254
06/06/2022 11:10:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/06/2022 11:10:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=259
06/06/2022 11:10:27 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=262
06/06/2022 11:10:28 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.724009009009009 on epoch=262
06/06/2022 11:10:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=264
06/06/2022 11:10:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=267
06/06/2022 11:10:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=269
06/06/2022 11:10:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=272
06/06/2022 11:10:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/06/2022 11:10:42 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7025573961057832 on epoch=274
06/06/2022 11:10:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=277
06/06/2022 11:10:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=279
06/06/2022 11:10:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=282
06/06/2022 11:10:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=284
06/06/2022 11:10:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/06/2022 11:10:56 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.7285857285857286 on epoch=287
06/06/2022 11:10:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/06/2022 11:11:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=292
06/06/2022 11:11:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=294
06/06/2022 11:11:06 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=297
06/06/2022 11:11:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=299
06/06/2022 11:11:10 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.6932298226415874 on epoch=299
06/06/2022 11:11:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=302
06/06/2022 11:11:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=304
06/06/2022 11:11:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/06/2022 11:11:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/06/2022 11:11:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/06/2022 11:11:24 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7373753217503218 on epoch=312
06/06/2022 11:11:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7303921568627452 -> 0.7373753217503218 on epoch=312, global_step=1250
06/06/2022 11:11:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/06/2022 11:11:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/06/2022 11:11:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
06/06/2022 11:11:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/06/2022 11:11:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/06/2022 11:11:38 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7376885016540421 on epoch=324
06/06/2022 11:11:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7373753217503218 -> 0.7376885016540421 on epoch=324, global_step=1300
06/06/2022 11:11:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/06/2022 11:11:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/06/2022 11:11:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/06/2022 11:11:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=334
06/06/2022 11:11:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/06/2022 11:11:52 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7716310160427807 on epoch=337
06/06/2022 11:11:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7376885016540421 -> 0.7716310160427807 on epoch=337, global_step=1350
06/06/2022 11:11:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=339
06/06/2022 11:11:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=342
06/06/2022 11:11:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/06/2022 11:12:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/06/2022 11:12:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/06/2022 11:12:06 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.757004173290938 on epoch=349
06/06/2022 11:12:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.16 on epoch=352
06/06/2022 11:12:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/06/2022 11:12:14 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/06/2022 11:12:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/06/2022 11:12:19 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
06/06/2022 11:12:20 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7520021645021645 on epoch=362
06/06/2022 11:12:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=364
06/06/2022 11:12:25 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=367
06/06/2022 11:12:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/06/2022 11:12:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=372
06/06/2022 11:12:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/06/2022 11:12:34 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.757004173290938 on epoch=374
06/06/2022 11:12:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/06/2022 11:12:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
06/06/2022 11:12:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
06/06/2022 11:12:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/06/2022 11:12:46 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/06/2022 11:12:47 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.757004173290938 on epoch=387
06/06/2022 11:12:50 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/06/2022 11:12:52 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=392
06/06/2022 11:12:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/06/2022 11:12:58 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=397
06/06/2022 11:13:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/06/2022 11:13:01 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7218253968253968 on epoch=399
06/06/2022 11:13:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/06/2022 11:13:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/06/2022 11:13:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/06/2022 11:13:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/06/2022 11:13:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/06/2022 11:13:15 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7512254901960784 on epoch=412
06/06/2022 11:13:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=414
06/06/2022 11:13:20 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/06/2022 11:13:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/06/2022 11:13:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.14 on epoch=422
06/06/2022 11:13:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/06/2022 11:13:29 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7662077505827507 on epoch=424
06/06/2022 11:13:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/06/2022 11:13:34 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/06/2022 11:13:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/06/2022 11:13:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
06/06/2022 11:13:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/06/2022 11:13:43 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7226399786883658 on epoch=437
06/06/2022 11:13:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=439
06/06/2022 11:13:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/06/2022 11:13:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/06/2022 11:13:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/06/2022 11:13:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/06/2022 11:13:57 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.757004173290938 on epoch=449
06/06/2022 11:13:59 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=452
06/06/2022 11:14:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/06/2022 11:14:04 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/06/2022 11:14:07 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=459
06/06/2022 11:14:09 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/06/2022 11:14:10 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7726670520788168 on epoch=462
06/06/2022 11:14:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7716310160427807 -> 0.7726670520788168 on epoch=462, global_step=1850
06/06/2022 11:14:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/06/2022 11:14:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=467
06/06/2022 11:14:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/06/2022 11:14:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=472
06/06/2022 11:14:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/06/2022 11:14:24 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7376885016540421 on epoch=474
06/06/2022 11:14:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/06/2022 11:14:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/06/2022 11:14:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/06/2022 11:14:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/06/2022 11:14:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/06/2022 11:14:38 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7520021645021645 on epoch=487
06/06/2022 11:14:41 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/06/2022 11:14:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/06/2022 11:14:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/06/2022 11:14:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/06/2022 11:14:51 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/06/2022 11:14:52 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7716310160427807 on epoch=499
06/06/2022 11:14:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/06/2022 11:14:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/06/2022 11:15:00 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/06/2022 11:15:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/06/2022 11:15:05 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/06/2022 11:15:06 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.7716310160427807 on epoch=512
06/06/2022 11:15:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/06/2022 11:15:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=517
06/06/2022 11:15:14 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=519
06/06/2022 11:15:17 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=522
06/06/2022 11:15:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=524
06/06/2022 11:15:20 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.7871212121212121 on epoch=524
06/06/2022 11:15:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7726670520788168 -> 0.7871212121212121 on epoch=524, global_step=2100
06/06/2022 11:15:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/06/2022 11:15:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.10 on epoch=529
06/06/2022 11:15:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=532
06/06/2022 11:15:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/06/2022 11:15:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/06/2022 11:15:34 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7520021645021645 on epoch=537
06/06/2022 11:15:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/06/2022 11:15:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 11:15:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/06/2022 11:15:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/06/2022 11:15:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/06/2022 11:15:48 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.757004173290938 on epoch=549
06/06/2022 11:15:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/06/2022 11:15:54 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=554
06/06/2022 11:15:56 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/06/2022 11:15:59 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=559
06/06/2022 11:16:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=562
06/06/2022 11:16:02 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7360360360360361 on epoch=562
06/06/2022 11:16:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/06/2022 11:16:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/06/2022 11:16:10 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/06/2022 11:16:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/06/2022 11:16:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/06/2022 11:16:16 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.771251089799477 on epoch=574
06/06/2022 11:16:19 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/06/2022 11:16:22 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/06/2022 11:16:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=582
06/06/2022 11:16:27 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/06/2022 11:16:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/06/2022 11:16:30 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7571726190476191 on epoch=587
06/06/2022 11:16:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/06/2022 11:16:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/06/2022 11:16:38 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 11:16:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/06/2022 11:16:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/06/2022 11:16:45 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7582086550836551 on epoch=599
06/06/2022 11:16:47 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/06/2022 11:16:50 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 11:16:52 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 11:16:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=609
06/06/2022 11:16:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 11:16:59 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7571726190476191 on epoch=612
06/06/2022 11:17:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 11:17:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 11:17:06 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/06/2022 11:17:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=622
06/06/2022 11:17:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/06/2022 11:17:13 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.751921387790953 on epoch=624
06/06/2022 11:17:15 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/06/2022 11:17:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/06/2022 11:17:20 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/06/2022 11:17:23 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/06/2022 11:17:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 11:17:27 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7375605984301636 on epoch=637
06/06/2022 11:17:29 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/06/2022 11:17:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/06/2022 11:17:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/06/2022 11:17:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 11:17:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/06/2022 11:17:41 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7726670520788168 on epoch=649
06/06/2022 11:17:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=652
06/06/2022 11:17:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/06/2022 11:17:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 11:17:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/06/2022 11:17:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=662
06/06/2022 11:17:55 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7160849985927384 on epoch=662
06/06/2022 11:17:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 11:18:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 11:18:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/06/2022 11:18:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 11:18:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/06/2022 11:18:09 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.787041083916084 on epoch=674
06/06/2022 11:18:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/06/2022 11:18:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 11:18:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/06/2022 11:18:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.08 on epoch=684
06/06/2022 11:18:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 11:18:23 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7227566198103956 on epoch=687
06/06/2022 11:18:26 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=689
06/06/2022 11:18:29 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 11:18:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/06/2022 11:18:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.09 on epoch=697
06/06/2022 11:18:37 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 11:18:38 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7716310160427807 on epoch=699
06/06/2022 11:18:40 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/06/2022 11:18:43 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 11:18:45 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=707
06/06/2022 11:18:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/06/2022 11:18:51 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 11:18:52 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7419653755137626 on epoch=712
06/06/2022 11:18:54 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/06/2022 11:18:57 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=717
06/06/2022 11:18:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=719
06/06/2022 11:19:02 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/06/2022 11:19:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=724
06/06/2022 11:19:06 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7571726190476191 on epoch=724
06/06/2022 11:19:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 11:19:11 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 11:19:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 11:19:16 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 11:19:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 11:19:19 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7571726190476191 on epoch=737
06/06/2022 11:19:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
06/06/2022 11:19:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/06/2022 11:19:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 11:19:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/06/2022 11:19:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 11:19:33 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7515331890331891 on epoch=749
06/06/2022 11:19:33 - INFO - __main__ - save last model!
06/06/2022 11:19:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 11:19:33 - INFO - __main__ - Start tokenizing ... 5509 instances
06/06/2022 11:19:33 - INFO - __main__ - Printing 3 examples
06/06/2022 11:19:33 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/06/2022 11:19:33 - INFO - __main__ - ['others']
06/06/2022 11:19:33 - INFO - __main__ -  [emo] what you like very little things ok
06/06/2022 11:19:33 - INFO - __main__ - ['others']
06/06/2022 11:19:33 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/06/2022 11:19:33 - INFO - __main__ - ['others']
06/06/2022 11:19:33 - INFO - __main__ - Tokenizing Input ...
06/06/2022 11:19:36 - INFO - __main__ - Tokenizing Output ...
06/06/2022 11:19:41 - INFO - __main__ - Loaded 5509 examples from test data
06/06/2022 11:21:15 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-emo/emo_16_87_0.2_8_predictions.txt
06/06/2022 11:21:15 - INFO - __main__ - Classification-F1 on test data: 0.3330
06/06/2022 11:21:16 - INFO - __main__ - prefix=emo_16_87, lr=0.2, bsz=8, dev_performance=0.7871212121212121, test_performance=0.33303053165936464
