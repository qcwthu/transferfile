05/21/2022 06:36:24 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 06:36:24 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14
05/21/2022 06:36:24 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 06:36:24 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14
05/21/2022 06:36:25 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 06:36:25 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 06:36:25 - INFO - __main__ - args.device: cuda:1
05/21/2022 06:36:25 - INFO - __main__ - args.device: cuda:0
05/21/2022 06:36:25 - INFO - __main__ - Using 2 gpus
05/21/2022 06:36:25 - INFO - __main__ - Using 2 gpus
05/21/2022 06:36:25 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/21/2022 06:36:25 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/21/2022 06:36:30 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
05/21/2022 06:36:31 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:36:31 - INFO - __main__ - Printing 3 examples
05/21/2022 06:36:31 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/21/2022 06:36:31 - INFO - __main__ - ['Animal']
05/21/2022 06:36:31 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/21/2022 06:36:31 - INFO - __main__ - ['Animal']
05/21/2022 06:36:31 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/21/2022 06:36:31 - INFO - __main__ - ['Animal']
05/21/2022 06:36:31 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:36:31 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:36:31 - INFO - __main__ - Printing 3 examples
05/21/2022 06:36:31 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/21/2022 06:36:31 - INFO - __main__ - ['Animal']
05/21/2022 06:36:31 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/21/2022 06:36:31 - INFO - __main__ - ['Animal']
05/21/2022 06:36:31 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/21/2022 06:36:31 - INFO - __main__ - ['Animal']
05/21/2022 06:36:31 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:36:31 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:36:31 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:36:31 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:36:31 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:36:31 - INFO - __main__ - Printing 3 examples
05/21/2022 06:36:31 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/21/2022 06:36:31 - INFO - __main__ - ['Animal']
05/21/2022 06:36:31 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/21/2022 06:36:31 - INFO - __main__ - ['Animal']
05/21/2022 06:36:31 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/21/2022 06:36:31 - INFO - __main__ - ['Animal']
05/21/2022 06:36:31 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:36:31 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:36:31 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:36:31 - INFO - __main__ - Printing 3 examples
05/21/2022 06:36:31 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/21/2022 06:36:31 - INFO - __main__ - ['Animal']
05/21/2022 06:36:31 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/21/2022 06:36:31 - INFO - __main__ - ['Animal']
05/21/2022 06:36:31 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/21/2022 06:36:31 - INFO - __main__ - ['Animal']
05/21/2022 06:36:31 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:36:31 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:36:31 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:36:31 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:36:32 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:36:49 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:36:49 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 18:37:17 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/05/2022 18:37:17 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14
06/05/2022 18:37:17 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-128shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/05/2022 18:37:17 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14
06/05/2022 18:37:18 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/05/2022 18:37:18 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/05/2022 18:37:18 - INFO - __main__ - args.device: cuda:0
06/05/2022 18:37:18 - INFO - __main__ - Using 2 gpus
06/05/2022 18:37:18 - INFO - __main__ - args.device: cuda:1
06/05/2022 18:37:18 - INFO - __main__ - Using 2 gpus
06/05/2022 18:37:18 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/05/2022 18:37:18 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/05/2022 18:37:23 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
06/05/2022 18:37:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 18:37:24 - INFO - __main__ - Printing 3 examples
06/05/2022 18:37:24 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/05/2022 18:37:24 - INFO - __main__ - ['Animal']
06/05/2022 18:37:24 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/05/2022 18:37:24 - INFO - __main__ - ['Animal']
06/05/2022 18:37:24 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/05/2022 18:37:24 - INFO - __main__ - ['Animal']
06/05/2022 18:37:24 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:37:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 18:37:24 - INFO - __main__ - Printing 3 examples
06/05/2022 18:37:24 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/05/2022 18:37:24 - INFO - __main__ - ['Animal']
06/05/2022 18:37:24 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/05/2022 18:37:24 - INFO - __main__ - ['Animal']
06/05/2022 18:37:24 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/05/2022 18:37:24 - INFO - __main__ - ['Animal']
06/05/2022 18:37:24 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:37:24 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:37:24 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:37:24 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 18:37:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 18:37:24 - INFO - __main__ - Printing 3 examples
06/05/2022 18:37:24 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/05/2022 18:37:24 - INFO - __main__ - ['Animal']
06/05/2022 18:37:24 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/05/2022 18:37:24 - INFO - __main__ - ['Animal']
06/05/2022 18:37:24 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/05/2022 18:37:24 - INFO - __main__ - ['Animal']
06/05/2022 18:37:24 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:37:24 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 18:37:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 18:37:24 - INFO - __main__ - Printing 3 examples
06/05/2022 18:37:24 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/05/2022 18:37:24 - INFO - __main__ - ['Animal']
06/05/2022 18:37:24 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/05/2022 18:37:24 - INFO - __main__ - ['Animal']
06/05/2022 18:37:24 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/05/2022 18:37:24 - INFO - __main__ - ['Animal']
06/05/2022 18:37:24 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:37:24 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:37:24 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:37:24 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 18:37:24 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 18:37:43 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 18:37:44 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 18:37:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 18:37:44 - INFO - __main__ - Starting training!
06/05/2022 18:37:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 18:37:48 - INFO - __main__ - Starting training!
06/05/2022 18:37:52 - INFO - __main__ - Step 10 Global step 10 Train loss 5.28 on epoch=0
06/05/2022 18:37:55 - INFO - __main__ - Step 20 Global step 20 Train loss 3.67 on epoch=1
06/05/2022 18:37:57 - INFO - __main__ - Step 30 Global step 30 Train loss 2.91 on epoch=2
06/05/2022 18:38:00 - INFO - __main__ - Step 40 Global step 40 Train loss 2.31 on epoch=2
06/05/2022 18:38:03 - INFO - __main__ - Step 50 Global step 50 Train loss 2.04 on epoch=3
06/05/2022 18:38:08 - INFO - __main__ - Global step 50 Train loss 3.24 Classification-F1 0.09278175058644145 on epoch=3
06/05/2022 18:38:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09278175058644145 on epoch=3, global_step=50
06/05/2022 18:38:10 - INFO - __main__ - Step 60 Global step 60 Train loss 1.81 on epoch=4
06/05/2022 18:38:13 - INFO - __main__ - Step 70 Global step 70 Train loss 1.31 on epoch=4
06/05/2022 18:38:16 - INFO - __main__ - Step 80 Global step 80 Train loss 1.25 on epoch=5
06/05/2022 18:38:18 - INFO - __main__ - Step 90 Global step 90 Train loss 1.13 on epoch=6
06/05/2022 18:38:21 - INFO - __main__ - Step 100 Global step 100 Train loss 1.04 on epoch=7
06/05/2022 18:38:28 - INFO - __main__ - Global step 100 Train loss 1.31 Classification-F1 0.39569894419224244 on epoch=7
06/05/2022 18:38:28 - INFO - __main__ - Saving model with best Classification-F1: 0.09278175058644145 -> 0.39569894419224244 on epoch=7, global_step=100
06/05/2022 18:38:30 - INFO - __main__ - Step 110 Global step 110 Train loss 0.89 on epoch=7
06/05/2022 18:38:33 - INFO - __main__ - Step 120 Global step 120 Train loss 0.82 on epoch=8
06/05/2022 18:38:36 - INFO - __main__ - Step 130 Global step 130 Train loss 0.83 on epoch=9
06/05/2022 18:38:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.59 on epoch=9
06/05/2022 18:38:41 - INFO - __main__ - Step 150 Global step 150 Train loss 0.75 on epoch=10
06/05/2022 18:38:49 - INFO - __main__ - Global step 150 Train loss 0.77 Classification-F1 0.5126742072181583 on epoch=10
06/05/2022 18:38:49 - INFO - __main__ - Saving model with best Classification-F1: 0.39569894419224244 -> 0.5126742072181583 on epoch=10, global_step=150
06/05/2022 18:38:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.68 on epoch=11
06/05/2022 18:38:54 - INFO - __main__ - Step 170 Global step 170 Train loss 0.58 on epoch=12
06/05/2022 18:38:57 - INFO - __main__ - Step 180 Global step 180 Train loss 0.47 on epoch=12
06/05/2022 18:38:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.49 on epoch=13
06/05/2022 18:39:02 - INFO - __main__ - Step 200 Global step 200 Train loss 0.57 on epoch=14
06/05/2022 18:39:10 - INFO - __main__ - Global step 200 Train loss 0.56 Classification-F1 0.7814737733406852 on epoch=14
06/05/2022 18:39:10 - INFO - __main__ - Saving model with best Classification-F1: 0.5126742072181583 -> 0.7814737733406852 on epoch=14, global_step=200
06/05/2022 18:39:13 - INFO - __main__ - Step 210 Global step 210 Train loss 0.50 on epoch=14
06/05/2022 18:39:16 - INFO - __main__ - Step 220 Global step 220 Train loss 0.51 on epoch=15
06/05/2022 18:39:18 - INFO - __main__ - Step 230 Global step 230 Train loss 0.44 on epoch=16
06/05/2022 18:39:21 - INFO - __main__ - Step 240 Global step 240 Train loss 0.45 on epoch=17
06/05/2022 18:39:24 - INFO - __main__ - Step 250 Global step 250 Train loss 0.36 on epoch=17
06/05/2022 18:39:31 - INFO - __main__ - Global step 250 Train loss 0.45 Classification-F1 0.7840410566466679 on epoch=17
06/05/2022 18:39:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7814737733406852 -> 0.7840410566466679 on epoch=17, global_step=250
06/05/2022 18:39:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=18
06/05/2022 18:39:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.38 on epoch=19
06/05/2022 18:39:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.38 on epoch=19
06/05/2022 18:39:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.30 on epoch=20
06/05/2022 18:39:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.36 on epoch=21
06/05/2022 18:39:51 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.8163875517623147 on epoch=21
06/05/2022 18:39:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7840410566466679 -> 0.8163875517623147 on epoch=21, global_step=300
06/05/2022 18:39:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.26 on epoch=22
06/05/2022 18:39:57 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=22
06/05/2022 18:40:00 - INFO - __main__ - Step 330 Global step 330 Train loss 0.31 on epoch=23
06/05/2022 18:40:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.21 on epoch=24
06/05/2022 18:40:05 - INFO - __main__ - Step 350 Global step 350 Train loss 0.18 on epoch=24
06/05/2022 18:40:12 - INFO - __main__ - Global step 350 Train loss 0.24 Classification-F1 0.7533665149110406 on epoch=24
06/05/2022 18:40:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.18 on epoch=25
06/05/2022 18:40:18 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=26
06/05/2022 18:40:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=27
06/05/2022 18:40:23 - INFO - __main__ - Step 390 Global step 390 Train loss 0.18 on epoch=27
06/05/2022 18:40:26 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=28
06/05/2022 18:40:33 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.7184524562513178 on epoch=28
06/05/2022 18:40:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.15 on epoch=29
06/05/2022 18:40:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.18 on epoch=29
06/05/2022 18:40:40 - INFO - __main__ - Step 430 Global step 430 Train loss 0.17 on epoch=30
06/05/2022 18:40:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=31
06/05/2022 18:40:46 - INFO - __main__ - Step 450 Global step 450 Train loss 0.13 on epoch=32
06/05/2022 18:40:53 - INFO - __main__ - Global step 450 Train loss 0.17 Classification-F1 0.7636968183680986 on epoch=32
06/05/2022 18:40:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=32
06/05/2022 18:40:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.15 on epoch=33
06/05/2022 18:41:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.15 on epoch=34
06/05/2022 18:41:03 - INFO - __main__ - Step 490 Global step 490 Train loss 0.12 on epoch=34
06/05/2022 18:41:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=35
06/05/2022 18:41:13 - INFO - __main__ - Global step 500 Train loss 0.15 Classification-F1 0.7792061435771671 on epoch=35
06/05/2022 18:41:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=36
06/05/2022 18:41:18 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=37
06/05/2022 18:41:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.15 on epoch=37
06/05/2022 18:41:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=38
06/05/2022 18:41:26 - INFO - __main__ - Step 550 Global step 550 Train loss 0.16 on epoch=39
06/05/2022 18:41:32 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.6974410322857342 on epoch=39
06/05/2022 18:41:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=39
06/05/2022 18:41:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=40
06/05/2022 18:41:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=41
06/05/2022 18:41:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=42
06/05/2022 18:41:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=42
06/05/2022 18:41:52 - INFO - __main__ - Global step 600 Train loss 0.12 Classification-F1 0.838968160862535 on epoch=42
06/05/2022 18:41:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8163875517623147 -> 0.838968160862535 on epoch=42, global_step=600
06/05/2022 18:41:55 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=43
06/05/2022 18:41:58 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=44
06/05/2022 18:42:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=44
06/05/2022 18:42:03 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=45
06/05/2022 18:42:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=46
06/05/2022 18:42:12 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.741483803552769 on epoch=46
06/05/2022 18:42:15 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=47
06/05/2022 18:42:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=47
06/05/2022 18:42:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=48
06/05/2022 18:42:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=49
06/05/2022 18:42:25 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=49
06/05/2022 18:42:32 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.7817031798056466 on epoch=49
06/05/2022 18:42:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=50
06/05/2022 18:42:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=51
06/05/2022 18:42:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=52
06/05/2022 18:42:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=52
06/05/2022 18:42:45 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=53
06/05/2022 18:42:51 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.7278437920094499 on epoch=53
06/05/2022 18:42:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=54
06/05/2022 18:42:56 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=54
06/05/2022 18:42:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=55
06/05/2022 18:43:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=56
06/05/2022 18:43:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=57
06/05/2022 18:43:10 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.7405664427169802 on epoch=57
06/05/2022 18:43:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=57
06/05/2022 18:43:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=58
06/05/2022 18:43:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=59
06/05/2022 18:43:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=59
06/05/2022 18:43:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=60
06/05/2022 18:43:29 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.6054160654160655 on epoch=60
06/05/2022 18:43:32 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=61
06/05/2022 18:43:34 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=62
06/05/2022 18:43:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=62
06/05/2022 18:43:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=63
06/05/2022 18:43:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=64
06/05/2022 18:43:48 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.628698365411115 on epoch=64
06/05/2022 18:43:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=64
06/05/2022 18:43:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=65
06/05/2022 18:43:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
06/05/2022 18:43:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=67
06/05/2022 18:44:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
06/05/2022 18:44:08 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.7607389856539238 on epoch=67
06/05/2022 18:44:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=68
06/05/2022 18:44:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=69
06/05/2022 18:44:16 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=69
06/05/2022 18:44:18 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
06/05/2022 18:44:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=71
06/05/2022 18:44:27 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.7825325472607536 on epoch=71
06/05/2022 18:44:30 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
06/05/2022 18:44:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=72
06/05/2022 18:44:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
06/05/2022 18:44:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/05/2022 18:44:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=74
06/05/2022 18:44:47 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.7530133322472032 on epoch=74
06/05/2022 18:44:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=75
06/05/2022 18:44:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=76
06/05/2022 18:44:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
06/05/2022 18:44:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=77
06/05/2022 18:45:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/05/2022 18:45:07 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.8436645763510683 on epoch=78
06/05/2022 18:45:08 - INFO - __main__ - Saving model with best Classification-F1: 0.838968160862535 -> 0.8436645763510683 on epoch=78, global_step=1100
06/05/2022 18:45:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
06/05/2022 18:45:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
06/05/2022 18:45:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=80
06/05/2022 18:45:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=81
06/05/2022 18:45:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=82
06/05/2022 18:45:28 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.7419699638206312 on epoch=82
06/05/2022 18:45:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=82
06/05/2022 18:45:33 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
06/05/2022 18:45:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=84
06/05/2022 18:45:38 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=84
06/05/2022 18:45:41 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=85
06/05/2022 18:45:47 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.9016484811472707 on epoch=85
06/05/2022 18:45:47 - INFO - __main__ - Saving model with best Classification-F1: 0.8436645763510683 -> 0.9016484811472707 on epoch=85, global_step=1200
06/05/2022 18:45:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=86
06/05/2022 18:45:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=87
06/05/2022 18:45:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
06/05/2022 18:45:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
06/05/2022 18:46:01 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
06/05/2022 18:46:08 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.9778741995331858 on epoch=89
06/05/2022 18:46:08 - INFO - __main__ - Saving model with best Classification-F1: 0.9016484811472707 -> 0.9778741995331858 on epoch=89, global_step=1250
06/05/2022 18:46:10 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
06/05/2022 18:46:13 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
06/05/2022 18:46:15 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
06/05/2022 18:46:18 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/05/2022 18:46:21 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
06/05/2022 18:46:27 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.9776041795017127 on epoch=92
06/05/2022 18:46:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
06/05/2022 18:46:33 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/05/2022 18:46:35 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
06/05/2022 18:46:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
06/05/2022 18:46:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
06/05/2022 18:46:47 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.8413000977517107 on epoch=96
06/05/2022 18:46:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
06/05/2022 18:46:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
06/05/2022 18:46:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=98
06/05/2022 18:46:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/05/2022 18:47:00 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/05/2022 18:47:06 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7956154637117915 on epoch=99
06/05/2022 18:47:09 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
06/05/2022 18:47:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/05/2022 18:47:14 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
06/05/2022 18:47:17 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/05/2022 18:47:20 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
06/05/2022 18:47:26 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.849251498619976 on epoch=103
06/05/2022 18:47:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=104
06/05/2022 18:47:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/05/2022 18:47:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
06/05/2022 18:47:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/05/2022 18:47:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/05/2022 18:47:46 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7921289336849109 on epoch=107
06/05/2022 18:47:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=107
06/05/2022 18:47:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
06/05/2022 18:47:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
06/05/2022 18:47:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/05/2022 18:47:59 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
06/05/2022 18:48:05 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9017951814156748 on epoch=110
06/05/2022 18:48:08 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
06/05/2022 18:48:11 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
06/05/2022 18:48:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/05/2022 18:48:16 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/05/2022 18:48:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
06/05/2022 18:48:26 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=114
06/05/2022 18:48:26 - INFO - __main__ - Saving model with best Classification-F1: 0.9778741995331858 -> 0.9865940511101802 on epoch=114, global_step=1600
06/05/2022 18:48:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
06/05/2022 18:48:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
06/05/2022 18:48:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/05/2022 18:48:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/05/2022 18:48:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/05/2022 18:48:46 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.9144793763057522 on epoch=117
06/05/2022 18:48:49 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/05/2022 18:48:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/05/2022 18:48:54 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/05/2022 18:48:57 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
06/05/2022 18:49:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
06/05/2022 18:49:06 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.9734142777345544 on epoch=121
06/05/2022 18:49:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/05/2022 18:49:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
06/05/2022 18:49:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/05/2022 18:49:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/05/2022 18:49:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=124
06/05/2022 18:49:26 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.8474148765583693 on epoch=124
06/05/2022 18:49:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/05/2022 18:49:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/05/2022 18:49:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
06/05/2022 18:49:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/05/2022 18:49:40 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/05/2022 18:49:46 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.795790944461276 on epoch=128
06/05/2022 18:49:48 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
06/05/2022 18:49:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/05/2022 18:49:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
06/05/2022 18:49:57 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/05/2022 18:49:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/05/2022 18:50:05 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.9056929581756187 on epoch=132
06/05/2022 18:50:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/05/2022 18:50:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/05/2022 18:50:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
06/05/2022 18:50:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/05/2022 18:50:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/05/2022 18:50:25 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9821034792216007 on epoch=135
06/05/2022 18:50:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/05/2022 18:50:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/05/2022 18:50:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/05/2022 18:50:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/05/2022 18:50:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/05/2022 18:50:44 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8896491822535467 on epoch=139
06/05/2022 18:50:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/05/2022 18:50:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/05/2022 18:50:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/05/2022 18:50:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/05/2022 18:50:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/05/2022 18:51:04 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7055912993806663 on epoch=142
06/05/2022 18:51:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/05/2022 18:51:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/05/2022 18:51:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/05/2022 18:51:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/05/2022 18:51:18 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/05/2022 18:51:24 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7896424361068853 on epoch=146
06/05/2022 18:51:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/05/2022 18:51:29 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=147
06/05/2022 18:51:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/05/2022 18:51:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
06/05/2022 18:51:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/05/2022 18:51:44 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7985154472346124 on epoch=149
06/05/2022 18:51:47 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/05/2022 18:51:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/05/2022 18:51:52 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/05/2022 18:51:55 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/05/2022 18:51:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/05/2022 18:52:04 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7071299583269023 on epoch=153
06/05/2022 18:52:06 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/05/2022 18:52:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/05/2022 18:52:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
06/05/2022 18:52:15 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/05/2022 18:52:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/05/2022 18:52:23 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9103372434017596 on epoch=157
06/05/2022 18:52:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
06/05/2022 18:52:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/05/2022 18:52:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/05/2022 18:52:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/05/2022 18:52:37 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/05/2022 18:52:44 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.851267627652234 on epoch=160
06/05/2022 18:52:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/05/2022 18:52:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/05/2022 18:52:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/05/2022 18:52:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/05/2022 18:52:58 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=164
06/05/2022 18:53:05 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7942213837598368 on epoch=164
06/05/2022 18:53:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/05/2022 18:53:10 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/05/2022 18:53:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/05/2022 18:53:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/05/2022 18:53:18 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/05/2022 18:53:25 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9121854694957162 on epoch=167
06/05/2022 18:53:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
06/05/2022 18:53:30 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
06/05/2022 18:53:33 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/05/2022 18:53:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/05/2022 18:53:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/05/2022 18:53:45 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7919050444528101 on epoch=171
06/05/2022 18:53:47 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/05/2022 18:53:50 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
06/05/2022 18:53:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/05/2022 18:53:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/05/2022 18:53:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/05/2022 18:54:06 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8452681573501581 on epoch=174
06/05/2022 18:54:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
06/05/2022 18:54:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/05/2022 18:54:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/05/2022 18:54:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/05/2022 18:54:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/05/2022 18:54:26 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6916354453966103 on epoch=178
06/05/2022 18:54:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
06/05/2022 18:54:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/05/2022 18:54:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
06/05/2022 18:54:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/05/2022 18:54:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/05/2022 18:54:47 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9139286356333076 on epoch=182
06/05/2022 18:54:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/05/2022 18:54:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/05/2022 18:54:55 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/05/2022 18:54:58 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/05/2022 18:55:01 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/05/2022 18:55:08 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.914360540892799 on epoch=185
06/05/2022 18:55:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/05/2022 18:55:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/05/2022 18:55:16 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/05/2022 18:55:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/05/2022 18:55:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/05/2022 18:55:28 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9080188028290496 on epoch=189
06/05/2022 18:55:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/05/2022 18:55:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/05/2022 18:55:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/05/2022 18:55:38 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/05/2022 18:55:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/05/2022 18:55:48 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.863147605083089 on epoch=192
06/05/2022 18:55:51 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/05/2022 18:55:53 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/05/2022 18:55:56 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/05/2022 18:55:59 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/05/2022 18:56:01 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/05/2022 18:56:08 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9103086366511415 on epoch=196
06/05/2022 18:56:11 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/05/2022 18:56:13 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/05/2022 18:56:16 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/05/2022 18:56:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/05/2022 18:56:21 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/05/2022 18:56:29 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.859241355083089 on epoch=199
06/05/2022 18:56:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/05/2022 18:56:35 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/05/2022 18:56:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/05/2022 18:56:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/05/2022 18:56:43 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/05/2022 18:56:50 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8592375366568915 on epoch=203
06/05/2022 18:56:53 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/05/2022 18:56:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/05/2022 18:56:58 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/05/2022 18:57:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/05/2022 18:57:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=207
06/05/2022 18:57:11 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9059945278209037 on epoch=207
06/05/2022 18:57:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/05/2022 18:57:16 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/05/2022 18:57:19 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/05/2022 18:57:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/05/2022 18:57:24 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/05/2022 18:57:31 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.8468344071922701 on epoch=210
06/05/2022 18:57:34 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/05/2022 18:57:36 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/05/2022 18:57:39 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/05/2022 18:57:42 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/05/2022 18:57:45 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/05/2022 18:57:46 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 18:57:46 - INFO - __main__ - Printing 3 examples
06/05/2022 18:57:46 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/05/2022 18:57:46 - INFO - __main__ - ['Animal']
06/05/2022 18:57:46 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/05/2022 18:57:46 - INFO - __main__ - ['Animal']
06/05/2022 18:57:46 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/05/2022 18:57:46 - INFO - __main__ - ['Animal']
06/05/2022 18:57:46 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:57:46 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:57:47 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 18:57:47 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 18:57:47 - INFO - __main__ - Printing 3 examples
06/05/2022 18:57:47 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/05/2022 18:57:47 - INFO - __main__ - ['Animal']
06/05/2022 18:57:47 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/05/2022 18:57:47 - INFO - __main__ - ['Animal']
06/05/2022 18:57:47 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/05/2022 18:57:47 - INFO - __main__ - ['Animal']
06/05/2022 18:57:47 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:57:47 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:57:47 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 18:57:51 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.8310117494578476 on epoch=214
06/05/2022 18:57:51 - INFO - __main__ - save last model!
06/05/2022 18:57:51 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 18:57:51 - INFO - __main__ - Start tokenizing ... 3500 instances
06/05/2022 18:57:51 - INFO - __main__ - Printing 3 examples
06/05/2022 18:57:51 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/05/2022 18:57:51 - INFO - __main__ - ['Animal']
06/05/2022 18:57:51 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/05/2022 18:57:51 - INFO - __main__ - ['Animal']
06/05/2022 18:57:51 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/05/2022 18:57:51 - INFO - __main__ - ['Village']
06/05/2022 18:57:51 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:57:53 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:57:56 - INFO - __main__ - Loaded 3500 examples from test data
06/05/2022 18:58:07 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 18:58:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 18:58:07 - INFO - __main__ - Starting training!
06/05/2022 19:00:06 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
06/05/2022 19:00:06 - INFO - __main__ - Classification-F1 on test data: 0.5499
06/05/2022 19:00:06 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.9865940511101802, test_performance=0.5499494051506374
06/05/2022 19:00:06 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
06/05/2022 19:00:07 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 19:00:07 - INFO - __main__ - Printing 3 examples
06/05/2022 19:00:07 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/05/2022 19:00:07 - INFO - __main__ - ['Animal']
06/05/2022 19:00:07 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/05/2022 19:00:07 - INFO - __main__ - ['Animal']
06/05/2022 19:00:07 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/05/2022 19:00:07 - INFO - __main__ - ['Animal']
06/05/2022 19:00:07 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:00:07 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:00:07 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 19:00:07 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 19:00:07 - INFO - __main__ - Printing 3 examples
06/05/2022 19:00:07 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/05/2022 19:00:07 - INFO - __main__ - ['Animal']
06/05/2022 19:00:07 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/05/2022 19:00:07 - INFO - __main__ - ['Animal']
06/05/2022 19:00:07 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/05/2022 19:00:07 - INFO - __main__ - ['Animal']
06/05/2022 19:00:07 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:00:08 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:00:08 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 19:00:27 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 19:00:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 19:00:28 - INFO - __main__ - Starting training!
06/05/2022 19:00:32 - INFO - __main__ - Step 10 Global step 10 Train loss 5.58 on epoch=0
06/05/2022 19:00:34 - INFO - __main__ - Step 20 Global step 20 Train loss 4.08 on epoch=1
06/05/2022 19:00:37 - INFO - __main__ - Step 30 Global step 30 Train loss 3.25 on epoch=2
06/05/2022 19:00:40 - INFO - __main__ - Step 40 Global step 40 Train loss 2.66 on epoch=2
06/05/2022 19:00:42 - INFO - __main__ - Step 50 Global step 50 Train loss 2.25 on epoch=3
06/05/2022 19:00:48 - INFO - __main__ - Global step 50 Train loss 3.56 Classification-F1 0.07351090678887141 on epoch=3
06/05/2022 19:00:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07351090678887141 on epoch=3, global_step=50
06/05/2022 19:00:50 - INFO - __main__ - Step 60 Global step 60 Train loss 2.01 on epoch=4
06/05/2022 19:00:53 - INFO - __main__ - Step 70 Global step 70 Train loss 1.57 on epoch=4
06/05/2022 19:00:55 - INFO - __main__ - Step 80 Global step 80 Train loss 1.42 on epoch=5
06/05/2022 19:00:58 - INFO - __main__ - Step 90 Global step 90 Train loss 1.16 on epoch=6
06/05/2022 19:01:01 - INFO - __main__ - Step 100 Global step 100 Train loss 1.13 on epoch=7
06/05/2022 19:01:07 - INFO - __main__ - Global step 100 Train loss 1.46 Classification-F1 0.29974964336480975 on epoch=7
06/05/2022 19:01:07 - INFO - __main__ - Saving model with best Classification-F1: 0.07351090678887141 -> 0.29974964336480975 on epoch=7, global_step=100
06/05/2022 19:01:10 - INFO - __main__ - Step 110 Global step 110 Train loss 1.01 on epoch=7
06/05/2022 19:01:13 - INFO - __main__ - Step 120 Global step 120 Train loss 0.94 on epoch=8
06/05/2022 19:01:15 - INFO - __main__ - Step 130 Global step 130 Train loss 0.91 on epoch=9
06/05/2022 19:01:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.72 on epoch=9
06/05/2022 19:01:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.79 on epoch=10
06/05/2022 19:01:28 - INFO - __main__ - Global step 150 Train loss 0.87 Classification-F1 0.4553315469123195 on epoch=10
06/05/2022 19:01:28 - INFO - __main__ - Saving model with best Classification-F1: 0.29974964336480975 -> 0.4553315469123195 on epoch=10, global_step=150
06/05/2022 19:01:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.69 on epoch=11
06/05/2022 19:01:33 - INFO - __main__ - Step 170 Global step 170 Train loss 0.59 on epoch=12
06/05/2022 19:01:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.66 on epoch=12
06/05/2022 19:01:39 - INFO - __main__ - Step 190 Global step 190 Train loss 0.62 on epoch=13
06/05/2022 19:01:41 - INFO - __main__ - Step 200 Global step 200 Train loss 0.62 on epoch=14
06/05/2022 19:01:48 - INFO - __main__ - Global step 200 Train loss 0.63 Classification-F1 0.7372675023824573 on epoch=14
06/05/2022 19:01:48 - INFO - __main__ - Saving model with best Classification-F1: 0.4553315469123195 -> 0.7372675023824573 on epoch=14, global_step=200
06/05/2022 19:01:51 - INFO - __main__ - Step 210 Global step 210 Train loss 0.58 on epoch=14
06/05/2022 19:01:54 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=15
06/05/2022 19:01:56 - INFO - __main__ - Step 230 Global step 230 Train loss 0.57 on epoch=16
06/05/2022 19:01:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.52 on epoch=17
06/05/2022 19:02:02 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=17
06/05/2022 19:02:10 - INFO - __main__ - Global step 250 Train loss 0.52 Classification-F1 0.7808867046592066 on epoch=17
06/05/2022 19:02:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7372675023824573 -> 0.7808867046592066 on epoch=17, global_step=250
06/05/2022 19:02:12 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=18
06/05/2022 19:02:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=19
06/05/2022 19:02:18 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=19
06/05/2022 19:02:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.41 on epoch=20
06/05/2022 19:02:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.45 on epoch=21
06/05/2022 19:02:31 - INFO - __main__ - Global step 300 Train loss 0.46 Classification-F1 0.7912164149930186 on epoch=21
06/05/2022 19:02:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7808867046592066 -> 0.7912164149930186 on epoch=21, global_step=300
06/05/2022 19:02:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=22
06/05/2022 19:02:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.32 on epoch=22
06/05/2022 19:02:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.34 on epoch=23
06/05/2022 19:02:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=24
06/05/2022 19:02:45 - INFO - __main__ - Step 350 Global step 350 Train loss 0.31 on epoch=24
06/05/2022 19:02:52 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.8693199700178128 on epoch=24
06/05/2022 19:02:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7912164149930186 -> 0.8693199700178128 on epoch=24, global_step=350
06/05/2022 19:02:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=25
06/05/2022 19:02:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=26
06/05/2022 19:03:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.34 on epoch=27
06/05/2022 19:03:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.25 on epoch=27
06/05/2022 19:03:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=28
06/05/2022 19:03:13 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.6909081716090634 on epoch=28
06/05/2022 19:03:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=29
06/05/2022 19:03:18 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=29
06/05/2022 19:03:21 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=30
06/05/2022 19:03:24 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=31
06/05/2022 19:03:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=32
06/05/2022 19:03:33 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.8101883076666639 on epoch=32
06/05/2022 19:03:36 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=32
06/05/2022 19:03:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=33
06/05/2022 19:03:41 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=34
06/05/2022 19:03:44 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=34
06/05/2022 19:03:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=35
06/05/2022 19:03:54 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.8293428861519223 on epoch=35
06/05/2022 19:03:56 - INFO - __main__ - Step 510 Global step 510 Train loss 0.17 on epoch=36
06/05/2022 19:03:59 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=37
06/05/2022 19:04:02 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=37
06/05/2022 19:04:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=38
06/05/2022 19:04:07 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=39
06/05/2022 19:04:15 - INFO - __main__ - Global step 550 Train loss 0.17 Classification-F1 0.6353714582118283 on epoch=39
06/05/2022 19:04:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=39
06/05/2022 19:04:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=40
06/05/2022 19:04:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=41
06/05/2022 19:04:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.17 on epoch=42
06/05/2022 19:04:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=42
06/05/2022 19:04:34 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.7199498807327425 on epoch=42
06/05/2022 19:04:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=43
06/05/2022 19:04:39 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=44
06/05/2022 19:04:42 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=44
06/05/2022 19:04:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=45
06/05/2022 19:04:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=46
06/05/2022 19:04:54 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.8273044465778152 on epoch=46
06/05/2022 19:04:57 - INFO - __main__ - Step 660 Global step 660 Train loss 0.10 on epoch=47
06/05/2022 19:05:00 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=47
06/05/2022 19:05:02 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=48
06/05/2022 19:05:05 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=49
06/05/2022 19:05:07 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=49
06/05/2022 19:05:15 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.8008300220684896 on epoch=49
06/05/2022 19:05:17 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=50
06/05/2022 19:05:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=51
06/05/2022 19:05:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
06/05/2022 19:05:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=52
06/05/2022 19:05:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=53
06/05/2022 19:05:35 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.8952843150945619 on epoch=53
06/05/2022 19:05:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8693199700178128 -> 0.8952843150945619 on epoch=53, global_step=750
06/05/2022 19:05:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=54
06/05/2022 19:05:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=54
06/05/2022 19:05:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=55
06/05/2022 19:05:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=56
06/05/2022 19:05:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=57
06/05/2022 19:05:55 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.7476932512985643 on epoch=57
06/05/2022 19:05:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=57
06/05/2022 19:06:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=58
06/05/2022 19:06:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=59
06/05/2022 19:06:06 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=59
06/05/2022 19:06:08 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=60
06/05/2022 19:06:15 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.839247003786852 on epoch=60
06/05/2022 19:06:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=61
06/05/2022 19:06:20 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=62
06/05/2022 19:06:23 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=62
06/05/2022 19:06:25 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=63
06/05/2022 19:06:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=64
06/05/2022 19:06:34 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.9061207904471662 on epoch=64
06/05/2022 19:06:34 - INFO - __main__ - Saving model with best Classification-F1: 0.8952843150945619 -> 0.9061207904471662 on epoch=64, global_step=900
06/05/2022 19:06:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=64
06/05/2022 19:06:40 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=65
06/05/2022 19:06:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=66
06/05/2022 19:06:45 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=67
06/05/2022 19:06:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
06/05/2022 19:06:54 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.7496048403069276 on epoch=67
06/05/2022 19:06:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=68
06/05/2022 19:07:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=69
06/05/2022 19:07:03 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=69
06/05/2022 19:07:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
06/05/2022 19:07:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=71
06/05/2022 19:07:14 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.9641420892353302 on epoch=71
06/05/2022 19:07:14 - INFO - __main__ - Saving model with best Classification-F1: 0.9061207904471662 -> 0.9641420892353302 on epoch=71, global_step=1000
06/05/2022 19:07:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=72
06/05/2022 19:07:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=72
06/05/2022 19:07:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=73
06/05/2022 19:07:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
06/05/2022 19:07:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
06/05/2022 19:07:35 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.9059774212715389 on epoch=74
06/05/2022 19:07:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
06/05/2022 19:07:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=76
06/05/2022 19:07:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=77
06/05/2022 19:07:46 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=77
06/05/2022 19:07:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/05/2022 19:07:55 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.9018861519731768 on epoch=78
06/05/2022 19:07:58 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=79
06/05/2022 19:08:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
06/05/2022 19:08:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=80
06/05/2022 19:08:06 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
06/05/2022 19:08:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=82
06/05/2022 19:08:16 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.9776165011459128 on epoch=82
06/05/2022 19:08:16 - INFO - __main__ - Saving model with best Classification-F1: 0.9641420892353302 -> 0.9776165011459128 on epoch=82, global_step=1150
06/05/2022 19:08:19 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
06/05/2022 19:08:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
06/05/2022 19:08:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=84
06/05/2022 19:08:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=84
06/05/2022 19:08:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=85
06/05/2022 19:08:36 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.9776427873202066 on epoch=85
06/05/2022 19:08:36 - INFO - __main__ - Saving model with best Classification-F1: 0.9776165011459128 -> 0.9776427873202066 on epoch=85, global_step=1200
06/05/2022 19:08:39 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
06/05/2022 19:08:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/05/2022 19:08:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
06/05/2022 19:08:47 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=88
06/05/2022 19:08:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
06/05/2022 19:08:56 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.9103086366511415 on epoch=89
06/05/2022 19:08:59 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=89
06/05/2022 19:09:02 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
06/05/2022 19:09:04 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
06/05/2022 19:09:07 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/05/2022 19:09:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
06/05/2022 19:09:16 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.9144868035190615 on epoch=92
06/05/2022 19:09:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
06/05/2022 19:09:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
06/05/2022 19:09:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=94
06/05/2022 19:09:27 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
06/05/2022 19:09:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
06/05/2022 19:09:36 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.9821034792216007 on epoch=96
06/05/2022 19:09:36 - INFO - __main__ - Saving model with best Classification-F1: 0.9776427873202066 -> 0.9821034792216007 on epoch=96, global_step=1350
06/05/2022 19:09:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
06/05/2022 19:09:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
06/05/2022 19:09:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/05/2022 19:09:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
06/05/2022 19:09:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
06/05/2022 19:09:56 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.9821034792216007 on epoch=99
06/05/2022 19:09:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/05/2022 19:10:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/05/2022 19:10:04 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
06/05/2022 19:10:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/05/2022 19:10:09 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
06/05/2022 19:10:16 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.880667171476404 on epoch=103
06/05/2022 19:10:18 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=104
06/05/2022 19:10:21 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=104
06/05/2022 19:10:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=105
06/05/2022 19:10:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
06/05/2022 19:10:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
06/05/2022 19:10:36 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.8810405996760114 on epoch=107
06/05/2022 19:10:38 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=107
06/05/2022 19:10:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/05/2022 19:10:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
06/05/2022 19:10:46 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/05/2022 19:10:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/05/2022 19:10:55 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.8114651038201204 on epoch=110
06/05/2022 19:10:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
06/05/2022 19:11:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
06/05/2022 19:11:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
06/05/2022 19:11:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
06/05/2022 19:11:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/05/2022 19:11:14 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.8854638414505587 on epoch=114
06/05/2022 19:11:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=114
06/05/2022 19:11:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/05/2022 19:11:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
06/05/2022 19:11:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/05/2022 19:11:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
06/05/2022 19:11:33 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.8809858476710536 on epoch=117
06/05/2022 19:11:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
06/05/2022 19:11:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/05/2022 19:11:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/05/2022 19:11:44 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
06/05/2022 19:11:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
06/05/2022 19:11:52 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9596235045742435 on epoch=121
06/05/2022 19:11:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
06/05/2022 19:11:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
06/05/2022 19:12:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/05/2022 19:12:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/05/2022 19:12:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
06/05/2022 19:12:12 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.893478954631706 on epoch=124
06/05/2022 19:12:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/05/2022 19:12:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
06/05/2022 19:12:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/05/2022 19:12:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/05/2022 19:12:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/05/2022 19:12:31 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8848141553786716 on epoch=128
06/05/2022 19:12:34 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
06/05/2022 19:12:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/05/2022 19:12:40 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/05/2022 19:12:43 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/05/2022 19:12:45 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/05/2022 19:12:52 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9019140168286278 on epoch=132
06/05/2022 19:12:55 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/05/2022 19:12:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/05/2022 19:13:01 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/05/2022 19:13:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=134
06/05/2022 19:13:06 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/05/2022 19:13:13 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9503418229461873 on epoch=135
06/05/2022 19:13:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=136
06/05/2022 19:13:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=137
06/05/2022 19:13:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/05/2022 19:13:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/05/2022 19:13:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/05/2022 19:13:32 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.8932791138500096 on epoch=139
06/05/2022 19:13:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
06/05/2022 19:13:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/05/2022 19:13:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/05/2022 19:13:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/05/2022 19:13:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/05/2022 19:13:51 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.843443171585552 on epoch=142
06/05/2022 19:13:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
06/05/2022 19:13:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/05/2022 19:13:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/05/2022 19:14:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/05/2022 19:14:05 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/05/2022 19:14:11 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8435282617445805 on epoch=146
06/05/2022 19:14:13 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/05/2022 19:14:16 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/05/2022 19:14:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/05/2022 19:14:21 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/05/2022 19:14:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/05/2022 19:14:30 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9103290974258715 on epoch=149
06/05/2022 19:14:33 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/05/2022 19:14:36 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/05/2022 19:14:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/05/2022 19:14:41 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
06/05/2022 19:14:44 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/05/2022 19:14:50 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8356997243545512 on epoch=153
06/05/2022 19:14:53 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/05/2022 19:14:55 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/05/2022 19:14:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/05/2022 19:15:01 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/05/2022 19:15:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/05/2022 19:15:09 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9103127096390854 on epoch=157
06/05/2022 19:15:12 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/05/2022 19:15:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/05/2022 19:15:17 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/05/2022 19:15:20 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.19 on epoch=159
06/05/2022 19:15:22 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/05/2022 19:15:29 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.9640484123672728 on epoch=160
06/05/2022 19:15:32 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
06/05/2022 19:15:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=162
06/05/2022 19:15:37 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/05/2022 19:15:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/05/2022 19:15:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/05/2022 19:15:49 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.9640484123672728 on epoch=164
06/05/2022 19:15:52 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/05/2022 19:15:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/05/2022 19:15:57 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/05/2022 19:16:00 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/05/2022 19:16:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/05/2022 19:16:09 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.977639193507315 on epoch=167
06/05/2022 19:16:11 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/05/2022 19:16:14 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
06/05/2022 19:16:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/05/2022 19:16:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/05/2022 19:16:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/05/2022 19:16:28 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8976279805750461 on epoch=171
06/05/2022 19:16:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/05/2022 19:16:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/05/2022 19:16:36 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/05/2022 19:16:39 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/05/2022 19:16:42 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/05/2022 19:16:48 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9684900353103119 on epoch=174
06/05/2022 19:16:51 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/05/2022 19:16:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/05/2022 19:16:56 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/05/2022 19:16:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
06/05/2022 19:17:01 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/05/2022 19:17:08 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9775743242994438 on epoch=178
06/05/2022 19:17:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/05/2022 19:17:13 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/05/2022 19:17:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/05/2022 19:17:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/05/2022 19:17:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/05/2022 19:17:28 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.964083426372875 on epoch=182
06/05/2022 19:17:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/05/2022 19:17:33 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/05/2022 19:17:36 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
06/05/2022 19:17:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/05/2022 19:17:42 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/05/2022 19:17:48 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9596060489116265 on epoch=185
06/05/2022 19:17:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/05/2022 19:17:54 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/05/2022 19:17:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/05/2022 19:17:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/05/2022 19:18:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
06/05/2022 19:18:08 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8902547086856452 on epoch=189
06/05/2022 19:18:11 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/05/2022 19:18:14 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/05/2022 19:18:16 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/05/2022 19:18:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/05/2022 19:18:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/05/2022 19:18:28 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9731144025008123 on epoch=192
06/05/2022 19:18:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/05/2022 19:18:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/05/2022 19:18:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/05/2022 19:18:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/05/2022 19:18:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/05/2022 19:18:49 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9775743242994438 on epoch=196
06/05/2022 19:18:51 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/05/2022 19:18:54 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/05/2022 19:18:57 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/05/2022 19:19:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/05/2022 19:19:02 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/05/2022 19:19:09 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9775743242994438 on epoch=199
06/05/2022 19:19:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/05/2022 19:19:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/05/2022 19:19:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/05/2022 19:19:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/05/2022 19:19:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/05/2022 19:19:29 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9731144025008123 on epoch=203
06/05/2022 19:19:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/05/2022 19:19:34 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/05/2022 19:19:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/05/2022 19:19:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/05/2022 19:19:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/05/2022 19:19:49 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9731144025008123 on epoch=207
06/05/2022 19:19:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/05/2022 19:19:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/05/2022 19:19:57 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/05/2022 19:20:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/05/2022 19:20:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/05/2022 19:20:12 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9060568916277876 on epoch=210
06/05/2022 19:20:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/05/2022 19:20:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/05/2022 19:20:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/05/2022 19:20:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/05/2022 19:20:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/05/2022 19:20:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 19:20:27 - INFO - __main__ - Printing 3 examples
06/05/2022 19:20:27 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/05/2022 19:20:27 - INFO - __main__ - ['Animal']
06/05/2022 19:20:27 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/05/2022 19:20:27 - INFO - __main__ - ['Animal']
06/05/2022 19:20:27 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/05/2022 19:20:27 - INFO - __main__ - ['Animal']
06/05/2022 19:20:27 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:20:27 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:20:27 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 19:20:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 19:20:27 - INFO - __main__ - Printing 3 examples
06/05/2022 19:20:27 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/05/2022 19:20:27 - INFO - __main__ - ['Animal']
06/05/2022 19:20:27 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/05/2022 19:20:27 - INFO - __main__ - ['Animal']
06/05/2022 19:20:27 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/05/2022 19:20:27 - INFO - __main__ - ['Animal']
06/05/2022 19:20:27 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:20:27 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:20:27 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 19:20:32 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9775743242994438 on epoch=214
06/05/2022 19:20:32 - INFO - __main__ - save last model!
06/05/2022 19:20:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 19:20:32 - INFO - __main__ - Start tokenizing ... 3500 instances
06/05/2022 19:20:32 - INFO - __main__ - Printing 3 examples
06/05/2022 19:20:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/05/2022 19:20:32 - INFO - __main__ - ['Animal']
06/05/2022 19:20:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/05/2022 19:20:32 - INFO - __main__ - ['Animal']
06/05/2022 19:20:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/05/2022 19:20:32 - INFO - __main__ - ['Village']
06/05/2022 19:20:32 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:20:34 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:20:38 - INFO - __main__ - Loaded 3500 examples from test data
06/05/2022 19:20:44 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 19:20:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 19:20:45 - INFO - __main__ - Starting training!
06/05/2022 19:22:50 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
06/05/2022 19:22:50 - INFO - __main__ - Classification-F1 on test data: 0.6197
06/05/2022 19:22:51 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.9821034792216007, test_performance=0.619680699750653
06/05/2022 19:22:51 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
06/05/2022 19:22:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 19:22:52 - INFO - __main__ - Printing 3 examples
06/05/2022 19:22:52 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/05/2022 19:22:52 - INFO - __main__ - ['Animal']
06/05/2022 19:22:52 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/05/2022 19:22:52 - INFO - __main__ - ['Animal']
06/05/2022 19:22:52 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/05/2022 19:22:52 - INFO - __main__ - ['Animal']
06/05/2022 19:22:52 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:22:52 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:22:52 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 19:22:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 19:22:52 - INFO - __main__ - Printing 3 examples
06/05/2022 19:22:52 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/05/2022 19:22:52 - INFO - __main__ - ['Animal']
06/05/2022 19:22:52 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/05/2022 19:22:52 - INFO - __main__ - ['Animal']
06/05/2022 19:22:52 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/05/2022 19:22:52 - INFO - __main__ - ['Animal']
06/05/2022 19:22:52 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:22:52 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:22:52 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 19:23:12 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 19:23:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 19:23:13 - INFO - __main__ - Starting training!
06/05/2022 19:23:17 - INFO - __main__ - Step 10 Global step 10 Train loss 5.70 on epoch=0
06/05/2022 19:23:20 - INFO - __main__ - Step 20 Global step 20 Train loss 4.32 on epoch=1
06/05/2022 19:23:23 - INFO - __main__ - Step 30 Global step 30 Train loss 3.47 on epoch=2
06/05/2022 19:23:25 - INFO - __main__ - Step 40 Global step 40 Train loss 3.08 on epoch=2
06/05/2022 19:23:28 - INFO - __main__ - Step 50 Global step 50 Train loss 2.66 on epoch=3
06/05/2022 19:23:34 - INFO - __main__ - Global step 50 Train loss 3.85 Classification-F1 0.046932332846223127 on epoch=3
06/05/2022 19:23:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.046932332846223127 on epoch=3, global_step=50
06/05/2022 19:23:37 - INFO - __main__ - Step 60 Global step 60 Train loss 2.54 on epoch=4
06/05/2022 19:23:40 - INFO - __main__ - Step 70 Global step 70 Train loss 2.00 on epoch=4
06/05/2022 19:23:42 - INFO - __main__ - Step 80 Global step 80 Train loss 1.97 on epoch=5
06/05/2022 19:23:45 - INFO - __main__ - Step 90 Global step 90 Train loss 1.64 on epoch=6
06/05/2022 19:23:48 - INFO - __main__ - Step 100 Global step 100 Train loss 1.62 on epoch=7
06/05/2022 19:23:53 - INFO - __main__ - Global step 100 Train loss 1.96 Classification-F1 0.16532130198397071 on epoch=7
06/05/2022 19:23:53 - INFO - __main__ - Saving model with best Classification-F1: 0.046932332846223127 -> 0.16532130198397071 on epoch=7, global_step=100
06/05/2022 19:23:56 - INFO - __main__ - Step 110 Global step 110 Train loss 1.41 on epoch=7
06/05/2022 19:23:59 - INFO - __main__ - Step 120 Global step 120 Train loss 1.25 on epoch=8
06/05/2022 19:24:01 - INFO - __main__ - Step 130 Global step 130 Train loss 1.23 on epoch=9
06/05/2022 19:24:04 - INFO - __main__ - Step 140 Global step 140 Train loss 1.06 on epoch=9
06/05/2022 19:24:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.91 on epoch=10
06/05/2022 19:24:13 - INFO - __main__ - Global step 150 Train loss 1.17 Classification-F1 0.43137450189490484 on epoch=10
06/05/2022 19:24:13 - INFO - __main__ - Saving model with best Classification-F1: 0.16532130198397071 -> 0.43137450189490484 on epoch=10, global_step=150
06/05/2022 19:24:16 - INFO - __main__ - Step 160 Global step 160 Train loss 0.90 on epoch=11
06/05/2022 19:24:19 - INFO - __main__ - Step 170 Global step 170 Train loss 0.76 on epoch=12
06/05/2022 19:24:21 - INFO - __main__ - Step 180 Global step 180 Train loss 0.86 on epoch=12
06/05/2022 19:24:24 - INFO - __main__ - Step 190 Global step 190 Train loss 0.71 on epoch=13
06/05/2022 19:24:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.69 on epoch=14
06/05/2022 19:24:33 - INFO - __main__ - Global step 200 Train loss 0.78 Classification-F1 0.540892399835458 on epoch=14
06/05/2022 19:24:33 - INFO - __main__ - Saving model with best Classification-F1: 0.43137450189490484 -> 0.540892399835458 on epoch=14, global_step=200
06/05/2022 19:24:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.64 on epoch=14
06/05/2022 19:24:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.67 on epoch=15
06/05/2022 19:24:41 - INFO - __main__ - Step 230 Global step 230 Train loss 0.61 on epoch=16
06/05/2022 19:24:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.74 on epoch=17
06/05/2022 19:24:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=17
06/05/2022 19:24:54 - INFO - __main__ - Global step 250 Train loss 0.64 Classification-F1 0.6097829030598667 on epoch=17
06/05/2022 19:24:54 - INFO - __main__ - Saving model with best Classification-F1: 0.540892399835458 -> 0.6097829030598667 on epoch=17, global_step=250
06/05/2022 19:24:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=18
06/05/2022 19:25:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.58 on epoch=19
06/05/2022 19:25:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.55 on epoch=19
06/05/2022 19:25:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=20
06/05/2022 19:25:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=21
06/05/2022 19:25:15 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.756353440334253 on epoch=21
06/05/2022 19:25:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6097829030598667 -> 0.756353440334253 on epoch=21, global_step=300
06/05/2022 19:25:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.54 on epoch=22
06/05/2022 19:25:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.40 on epoch=22
06/05/2022 19:25:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=23
06/05/2022 19:25:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.46 on epoch=24
06/05/2022 19:25:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.39 on epoch=24
06/05/2022 19:25:36 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.7880968234289463 on epoch=24
06/05/2022 19:25:36 - INFO - __main__ - Saving model with best Classification-F1: 0.756353440334253 -> 0.7880968234289463 on epoch=24, global_step=350
06/05/2022 19:25:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.48 on epoch=25
06/05/2022 19:25:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.42 on epoch=26
06/05/2022 19:25:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=27
06/05/2022 19:25:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.36 on epoch=27
06/05/2022 19:25:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.40 on epoch=28
06/05/2022 19:25:57 - INFO - __main__ - Global step 400 Train loss 0.42 Classification-F1 0.791806210828039 on epoch=28
06/05/2022 19:25:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7880968234289463 -> 0.791806210828039 on epoch=28, global_step=400
06/05/2022 19:26:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.38 on epoch=29
06/05/2022 19:26:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=29
06/05/2022 19:26:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.36 on epoch=30
06/05/2022 19:26:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=31
06/05/2022 19:26:11 - INFO - __main__ - Step 450 Global step 450 Train loss 0.41 on epoch=32
06/05/2022 19:26:18 - INFO - __main__ - Global step 450 Train loss 0.37 Classification-F1 0.8151547213755223 on epoch=32
06/05/2022 19:26:18 - INFO - __main__ - Saving model with best Classification-F1: 0.791806210828039 -> 0.8151547213755223 on epoch=32, global_step=450
06/05/2022 19:26:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.33 on epoch=32
06/05/2022 19:26:24 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=33
06/05/2022 19:26:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.33 on epoch=34
06/05/2022 19:26:29 - INFO - __main__ - Step 490 Global step 490 Train loss 0.36 on epoch=34
06/05/2022 19:26:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.29 on epoch=35
06/05/2022 19:26:39 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.819706820166972 on epoch=35
06/05/2022 19:26:39 - INFO - __main__ - Saving model with best Classification-F1: 0.8151547213755223 -> 0.819706820166972 on epoch=35, global_step=500
06/05/2022 19:26:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=36
06/05/2022 19:26:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=37
06/05/2022 19:26:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.34 on epoch=37
06/05/2022 19:26:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=38
06/05/2022 19:26:53 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=39
06/05/2022 19:27:01 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.8533727919174162 on epoch=39
06/05/2022 19:27:01 - INFO - __main__ - Saving model with best Classification-F1: 0.819706820166972 -> 0.8533727919174162 on epoch=39, global_step=550
06/05/2022 19:27:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=39
06/05/2022 19:27:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=40
06/05/2022 19:27:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=41
06/05/2022 19:27:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=42
06/05/2022 19:27:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=42
06/05/2022 19:27:21 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.6995797728905877 on epoch=42
06/05/2022 19:27:24 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=43
06/05/2022 19:27:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=44
06/05/2022 19:27:30 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=44
06/05/2022 19:27:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=45
06/05/2022 19:27:35 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=46
06/05/2022 19:27:43 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.7043027586992239 on epoch=46
06/05/2022 19:27:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=47
06/05/2022 19:27:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=47
06/05/2022 19:27:51 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=48
06/05/2022 19:27:53 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=49
06/05/2022 19:27:56 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=49
06/05/2022 19:28:03 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.6095522573900682 on epoch=49
06/05/2022 19:28:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=50
06/05/2022 19:28:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=51
06/05/2022 19:28:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=52
06/05/2022 19:28:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=52
06/05/2022 19:28:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=53
06/05/2022 19:28:24 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.6240443743479795 on epoch=53
06/05/2022 19:28:26 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=54
06/05/2022 19:28:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=54
06/05/2022 19:28:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=55
06/05/2022 19:28:35 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=56
06/05/2022 19:28:37 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=57
06/05/2022 19:28:44 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.6203249442410194 on epoch=57
06/05/2022 19:28:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=57
06/05/2022 19:28:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=58
06/05/2022 19:28:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=59
06/05/2022 19:28:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=59
06/05/2022 19:28:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=60
06/05/2022 19:29:05 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.7367406619713104 on epoch=60
06/05/2022 19:29:07 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=61
06/05/2022 19:29:10 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=62
06/05/2022 19:29:13 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=62
06/05/2022 19:29:16 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
06/05/2022 19:29:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=64
06/05/2022 19:29:25 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.6482947739386029 on epoch=64
06/05/2022 19:29:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=64
06/05/2022 19:29:31 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=65
06/05/2022 19:29:33 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=66
06/05/2022 19:29:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=67
06/05/2022 19:29:39 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=67
06/05/2022 19:29:46 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.6860220166634872 on epoch=67
06/05/2022 19:29:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=68
06/05/2022 19:29:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=69
06/05/2022 19:29:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=69
06/05/2022 19:29:57 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=70
06/05/2022 19:29:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/05/2022 19:30:06 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.7410101010101011 on epoch=71
06/05/2022 19:30:08 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=72
06/05/2022 19:30:11 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=72
06/05/2022 19:30:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
06/05/2022 19:30:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=74
06/05/2022 19:30:20 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
06/05/2022 19:30:26 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.830671036743143 on epoch=74
06/05/2022 19:30:29 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
06/05/2022 19:30:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=76
06/05/2022 19:30:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
06/05/2022 19:30:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
06/05/2022 19:30:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
06/05/2022 19:30:46 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.8399302960024022 on epoch=78
06/05/2022 19:30:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=79
06/05/2022 19:30:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
06/05/2022 19:30:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=80
06/05/2022 19:30:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
06/05/2022 19:31:00 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/05/2022 19:31:07 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7328552157708736 on epoch=82
06/05/2022 19:31:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=82
06/05/2022 19:31:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
06/05/2022 19:31:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/05/2022 19:31:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/05/2022 19:31:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=85
06/05/2022 19:31:27 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7854880989829087 on epoch=85
06/05/2022 19:31:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
06/05/2022 19:31:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
06/05/2022 19:31:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=87
06/05/2022 19:31:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=88
06/05/2022 19:31:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
06/05/2022 19:31:47 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.8399302960024023 on epoch=89
06/05/2022 19:31:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
06/05/2022 19:31:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
06/05/2022 19:31:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=91
06/05/2022 19:31:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=92
06/05/2022 19:32:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=92
06/05/2022 19:32:07 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.7078397217815973 on epoch=92
06/05/2022 19:32:10 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
06/05/2022 19:32:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
06/05/2022 19:32:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
06/05/2022 19:32:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
06/05/2022 19:32:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
06/05/2022 19:32:28 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.798784339210216 on epoch=96
06/05/2022 19:32:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
06/05/2022 19:32:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
06/05/2022 19:32:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/05/2022 19:32:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
06/05/2022 19:32:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/05/2022 19:32:48 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.9821297653958945 on epoch=99
06/05/2022 19:32:48 - INFO - __main__ - Saving model with best Classification-F1: 0.8533727919174162 -> 0.9821297653958945 on epoch=99, global_step=1400
06/05/2022 19:32:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
06/05/2022 19:32:53 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/05/2022 19:32:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/05/2022 19:32:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
06/05/2022 19:33:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/05/2022 19:33:08 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.9010732067121519 on epoch=103
06/05/2022 19:33:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
06/05/2022 19:33:14 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
06/05/2022 19:33:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/05/2022 19:33:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/05/2022 19:33:22 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
06/05/2022 19:33:30 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.9078787878787878 on epoch=107
06/05/2022 19:33:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/05/2022 19:33:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/05/2022 19:33:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
06/05/2022 19:33:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/05/2022 19:33:43 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/05/2022 19:33:50 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.9144868035190615 on epoch=110
06/05/2022 19:33:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/05/2022 19:33:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/05/2022 19:33:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/05/2022 19:34:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/05/2022 19:34:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/05/2022 19:34:09 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.8553190676930597 on epoch=114
06/05/2022 19:34:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/05/2022 19:34:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
06/05/2022 19:34:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/05/2022 19:34:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=117
06/05/2022 19:34:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/05/2022 19:34:29 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.9103201368523949 on epoch=117
06/05/2022 19:34:32 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/05/2022 19:34:35 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/05/2022 19:34:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=119
06/05/2022 19:34:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
06/05/2022 19:34:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/05/2022 19:34:49 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.8474989308406647 on epoch=121
06/05/2022 19:34:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/05/2022 19:34:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
06/05/2022 19:34:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/05/2022 19:35:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
06/05/2022 19:35:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/05/2022 19:35:09 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.841154907710885 on epoch=124
06/05/2022 19:35:12 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
06/05/2022 19:35:14 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/05/2022 19:35:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
06/05/2022 19:35:20 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/05/2022 19:35:22 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/05/2022 19:35:29 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.9776427873202066 on epoch=128
06/05/2022 19:35:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/05/2022 19:35:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/05/2022 19:35:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/05/2022 19:35:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
06/05/2022 19:35:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/05/2022 19:35:49 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9731478515159729 on epoch=132
06/05/2022 19:35:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
06/05/2022 19:35:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
06/05/2022 19:35:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/05/2022 19:36:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/05/2022 19:36:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=135
06/05/2022 19:36:10 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.9776427873202066 on epoch=135
06/05/2022 19:36:13 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/05/2022 19:36:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/05/2022 19:36:19 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/05/2022 19:36:21 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/05/2022 19:36:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/05/2022 19:36:31 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9776165011459128 on epoch=139
06/05/2022 19:36:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/05/2022 19:36:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/05/2022 19:36:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/05/2022 19:36:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/05/2022 19:36:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/05/2022 19:36:52 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9776165011459128 on epoch=142
06/05/2022 19:36:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/05/2022 19:36:58 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/05/2022 19:37:01 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/05/2022 19:37:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/05/2022 19:37:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/05/2022 19:37:14 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9821114369501466 on epoch=146
06/05/2022 19:37:16 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/05/2022 19:37:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/05/2022 19:37:22 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/05/2022 19:37:24 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/05/2022 19:37:27 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/05/2022 19:37:34 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9686529157117392 on epoch=149
06/05/2022 19:37:37 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/05/2022 19:37:40 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/05/2022 19:37:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/05/2022 19:37:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/05/2022 19:37:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/05/2022 19:37:55 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9637477966209236 on epoch=153
06/05/2022 19:37:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/05/2022 19:38:01 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/05/2022 19:38:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/05/2022 19:38:06 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/05/2022 19:38:09 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/05/2022 19:38:16 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.8472315511615203 on epoch=157
06/05/2022 19:38:18 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/05/2022 19:38:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/05/2022 19:38:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/05/2022 19:38:26 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/05/2022 19:38:29 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/05/2022 19:38:36 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8945652787019012 on epoch=160
06/05/2022 19:38:39 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/05/2022 19:38:41 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/05/2022 19:38:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/05/2022 19:38:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/05/2022 19:38:49 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/05/2022 19:38:56 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.842575798647905 on epoch=164
06/05/2022 19:38:58 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
06/05/2022 19:39:01 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=165
06/05/2022 19:39:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/05/2022 19:39:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/05/2022 19:39:09 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/05/2022 19:39:15 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.9102915301017768 on epoch=167
06/05/2022 19:39:18 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/05/2022 19:39:21 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/05/2022 19:39:23 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/05/2022 19:39:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/05/2022 19:39:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/05/2022 19:39:35 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9121928967090257 on epoch=171
06/05/2022 19:39:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/05/2022 19:39:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/05/2022 19:39:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/05/2022 19:39:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/05/2022 19:39:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/05/2022 19:39:56 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9061207904471662 on epoch=174
06/05/2022 19:39:59 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/05/2022 19:40:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/05/2022 19:40:04 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/05/2022 19:40:07 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/05/2022 19:40:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/05/2022 19:40:17 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9776165011459128 on epoch=178
06/05/2022 19:40:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/05/2022 19:40:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/05/2022 19:40:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/05/2022 19:40:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/05/2022 19:40:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/05/2022 19:40:38 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9101611944875704 on epoch=182
06/05/2022 19:40:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/05/2022 19:40:44 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/05/2022 19:40:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/05/2022 19:40:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/05/2022 19:40:52 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/05/2022 19:41:00 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9773073553417727 on epoch=185
06/05/2022 19:41:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/05/2022 19:41:05 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/05/2022 19:41:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/05/2022 19:41:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/05/2022 19:41:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/05/2022 19:41:21 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9686931664161265 on epoch=189
06/05/2022 19:41:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/05/2022 19:41:26 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/05/2022 19:41:29 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/05/2022 19:41:31 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=192
06/05/2022 19:41:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/05/2022 19:41:41 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9061338240085868 on epoch=192
06/05/2022 19:41:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/05/2022 19:41:47 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
06/05/2022 19:41:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
06/05/2022 19:41:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/05/2022 19:41:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/05/2022 19:42:02 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9776654796816088 on epoch=196
06/05/2022 19:42:05 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/05/2022 19:42:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/05/2022 19:42:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
06/05/2022 19:42:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/05/2022 19:42:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/05/2022 19:42:23 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9641311757790385 on epoch=199
06/05/2022 19:42:26 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/05/2022 19:42:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/05/2022 19:42:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/05/2022 19:42:34 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/05/2022 19:42:37 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/05/2022 19:42:47 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9060272075594656 on epoch=203
06/05/2022 19:42:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/05/2022 19:42:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/05/2022 19:42:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/05/2022 19:42:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/05/2022 19:43:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/05/2022 19:43:08 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9731924661360145 on epoch=207
06/05/2022 19:43:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/05/2022 19:43:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/05/2022 19:43:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/05/2022 19:43:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/05/2022 19:43:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/05/2022 19:43:29 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9686975303317809 on epoch=210
06/05/2022 19:43:31 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/05/2022 19:43:34 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/05/2022 19:43:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/05/2022 19:43:40 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/05/2022 19:43:42 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/05/2022 19:43:44 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 19:43:44 - INFO - __main__ - Printing 3 examples
06/05/2022 19:43:44 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/05/2022 19:43:44 - INFO - __main__ - ['Animal']
06/05/2022 19:43:44 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/05/2022 19:43:44 - INFO - __main__ - ['Animal']
06/05/2022 19:43:44 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/05/2022 19:43:44 - INFO - __main__ - ['Animal']
06/05/2022 19:43:44 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:43:44 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:43:45 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 19:43:45 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 19:43:45 - INFO - __main__ - Printing 3 examples
06/05/2022 19:43:45 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/05/2022 19:43:45 - INFO - __main__ - ['Animal']
06/05/2022 19:43:45 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/05/2022 19:43:45 - INFO - __main__ - ['Animal']
06/05/2022 19:43:45 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/05/2022 19:43:45 - INFO - __main__ - ['Animal']
06/05/2022 19:43:45 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:43:45 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:43:45 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 19:43:50 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9731661799617208 on epoch=214
06/05/2022 19:43:50 - INFO - __main__ - save last model!
06/05/2022 19:43:50 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 19:43:50 - INFO - __main__ - Start tokenizing ... 3500 instances
06/05/2022 19:43:50 - INFO - __main__ - Printing 3 examples
06/05/2022 19:43:50 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/05/2022 19:43:50 - INFO - __main__ - ['Animal']
06/05/2022 19:43:50 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/05/2022 19:43:50 - INFO - __main__ - ['Animal']
06/05/2022 19:43:50 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/05/2022 19:43:50 - INFO - __main__ - ['Village']
06/05/2022 19:43:50 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:43:52 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:43:55 - INFO - __main__ - Loaded 3500 examples from test data
06/05/2022 19:44:01 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 19:44:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 19:44:02 - INFO - __main__ - Starting training!
06/05/2022 19:46:28 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
06/05/2022 19:46:28 - INFO - __main__ - Classification-F1 on test data: 0.7196
06/05/2022 19:46:28 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.9821297653958945, test_performance=0.71959257088941
06/05/2022 19:46:28 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
06/05/2022 19:46:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 19:46:29 - INFO - __main__ - Printing 3 examples
06/05/2022 19:46:29 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/05/2022 19:46:29 - INFO - __main__ - ['Animal']
06/05/2022 19:46:29 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/05/2022 19:46:29 - INFO - __main__ - ['Animal']
06/05/2022 19:46:29 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/05/2022 19:46:29 - INFO - __main__ - ['Animal']
06/05/2022 19:46:29 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:46:30 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:46:30 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 19:46:30 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 19:46:30 - INFO - __main__ - Printing 3 examples
06/05/2022 19:46:30 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/05/2022 19:46:30 - INFO - __main__ - ['Animal']
06/05/2022 19:46:30 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/05/2022 19:46:30 - INFO - __main__ - ['Animal']
06/05/2022 19:46:30 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/05/2022 19:46:30 - INFO - __main__ - ['Animal']
06/05/2022 19:46:30 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:46:30 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:46:30 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 19:46:49 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 19:46:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 19:46:50 - INFO - __main__ - Starting training!
06/05/2022 19:46:54 - INFO - __main__ - Step 10 Global step 10 Train loss 6.24 on epoch=0
06/05/2022 19:46:56 - INFO - __main__ - Step 20 Global step 20 Train loss 4.89 on epoch=1
06/05/2022 19:46:59 - INFO - __main__ - Step 30 Global step 30 Train loss 4.16 on epoch=2
06/05/2022 19:47:02 - INFO - __main__ - Step 40 Global step 40 Train loss 3.59 on epoch=2
06/05/2022 19:47:05 - INFO - __main__ - Step 50 Global step 50 Train loss 3.40 on epoch=3
06/05/2022 19:47:11 - INFO - __main__ - Global step 50 Train loss 4.46 Classification-F1 0.01854485770617306 on epoch=3
06/05/2022 19:47:11 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.01854485770617306 on epoch=3, global_step=50
06/05/2022 19:47:14 - INFO - __main__ - Step 60 Global step 60 Train loss 3.23 on epoch=4
06/05/2022 19:47:16 - INFO - __main__ - Step 70 Global step 70 Train loss 2.78 on epoch=4
06/05/2022 19:47:19 - INFO - __main__ - Step 80 Global step 80 Train loss 2.63 on epoch=5
06/05/2022 19:47:22 - INFO - __main__ - Step 90 Global step 90 Train loss 2.35 on epoch=6
06/05/2022 19:47:24 - INFO - __main__ - Step 100 Global step 100 Train loss 2.18 on epoch=7
06/05/2022 19:47:30 - INFO - __main__ - Global step 100 Train loss 2.63 Classification-F1 0.07063876985383337 on epoch=7
06/05/2022 19:47:30 - INFO - __main__ - Saving model with best Classification-F1: 0.01854485770617306 -> 0.07063876985383337 on epoch=7, global_step=100
06/05/2022 19:47:33 - INFO - __main__ - Step 110 Global step 110 Train loss 2.09 on epoch=7
06/05/2022 19:47:36 - INFO - __main__ - Step 120 Global step 120 Train loss 1.87 on epoch=8
06/05/2022 19:47:38 - INFO - __main__ - Step 130 Global step 130 Train loss 1.87 on epoch=9
06/05/2022 19:47:41 - INFO - __main__ - Step 140 Global step 140 Train loss 1.47 on epoch=9
06/05/2022 19:47:44 - INFO - __main__ - Step 150 Global step 150 Train loss 1.55 on epoch=10
06/05/2022 19:47:50 - INFO - __main__ - Global step 150 Train loss 1.77 Classification-F1 0.1456490708282823 on epoch=10
06/05/2022 19:47:50 - INFO - __main__ - Saving model with best Classification-F1: 0.07063876985383337 -> 0.1456490708282823 on epoch=10, global_step=150
06/05/2022 19:47:52 - INFO - __main__ - Step 160 Global step 160 Train loss 1.37 on epoch=11
06/05/2022 19:47:55 - INFO - __main__ - Step 170 Global step 170 Train loss 1.18 on epoch=12
06/05/2022 19:47:58 - INFO - __main__ - Step 180 Global step 180 Train loss 1.13 on epoch=12
06/05/2022 19:48:01 - INFO - __main__ - Step 190 Global step 190 Train loss 1.12 on epoch=13
06/05/2022 19:48:03 - INFO - __main__ - Step 200 Global step 200 Train loss 1.08 on epoch=14
06/05/2022 19:48:10 - INFO - __main__ - Global step 200 Train loss 1.17 Classification-F1 0.36418497607509154 on epoch=14
06/05/2022 19:48:10 - INFO - __main__ - Saving model with best Classification-F1: 0.1456490708282823 -> 0.36418497607509154 on epoch=14, global_step=200
06/05/2022 19:48:13 - INFO - __main__ - Step 210 Global step 210 Train loss 0.93 on epoch=14
06/05/2022 19:48:16 - INFO - __main__ - Step 220 Global step 220 Train loss 0.95 on epoch=15
06/05/2022 19:48:18 - INFO - __main__ - Step 230 Global step 230 Train loss 0.87 on epoch=16
06/05/2022 19:48:21 - INFO - __main__ - Step 240 Global step 240 Train loss 0.82 on epoch=17
06/05/2022 19:48:24 - INFO - __main__ - Step 250 Global step 250 Train loss 0.76 on epoch=17
06/05/2022 19:48:30 - INFO - __main__ - Global step 250 Train loss 0.86 Classification-F1 0.45521524549355896 on epoch=17
06/05/2022 19:48:30 - INFO - __main__ - Saving model with best Classification-F1: 0.36418497607509154 -> 0.45521524549355896 on epoch=17, global_step=250
06/05/2022 19:48:33 - INFO - __main__ - Step 260 Global step 260 Train loss 0.82 on epoch=18
06/05/2022 19:48:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.81 on epoch=19
06/05/2022 19:48:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.64 on epoch=19
06/05/2022 19:48:41 - INFO - __main__ - Step 290 Global step 290 Train loss 0.68 on epoch=20
06/05/2022 19:48:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.66 on epoch=21
06/05/2022 19:48:51 - INFO - __main__ - Global step 300 Train loss 0.72 Classification-F1 0.48059201703030463 on epoch=21
06/05/2022 19:48:51 - INFO - __main__ - Saving model with best Classification-F1: 0.45521524549355896 -> 0.48059201703030463 on epoch=21, global_step=300
06/05/2022 19:48:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.63 on epoch=22
06/05/2022 19:48:57 - INFO - __main__ - Step 320 Global step 320 Train loss 0.53 on epoch=22
06/05/2022 19:49:00 - INFO - __main__ - Step 330 Global step 330 Train loss 0.60 on epoch=23
06/05/2022 19:49:02 - INFO - __main__ - Step 340 Global step 340 Train loss 0.66 on epoch=24
06/05/2022 19:49:05 - INFO - __main__ - Step 350 Global step 350 Train loss 0.58 on epoch=24
06/05/2022 19:49:13 - INFO - __main__ - Global step 350 Train loss 0.60 Classification-F1 0.6096897068580309 on epoch=24
06/05/2022 19:49:13 - INFO - __main__ - Saving model with best Classification-F1: 0.48059201703030463 -> 0.6096897068580309 on epoch=24, global_step=350
06/05/2022 19:49:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.57 on epoch=25
06/05/2022 19:49:18 - INFO - __main__ - Step 370 Global step 370 Train loss 0.61 on epoch=26
06/05/2022 19:49:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.61 on epoch=27
06/05/2022 19:49:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.49 on epoch=27
06/05/2022 19:49:26 - INFO - __main__ - Step 400 Global step 400 Train loss 0.55 on epoch=28
06/05/2022 19:49:34 - INFO - __main__ - Global step 400 Train loss 0.57 Classification-F1 0.6985369895307312 on epoch=28
06/05/2022 19:49:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6096897068580309 -> 0.6985369895307312 on epoch=28, global_step=400
06/05/2022 19:49:36 - INFO - __main__ - Step 410 Global step 410 Train loss 0.54 on epoch=29
06/05/2022 19:49:39 - INFO - __main__ - Step 420 Global step 420 Train loss 0.45 on epoch=29
06/05/2022 19:49:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.52 on epoch=30
06/05/2022 19:49:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.53 on epoch=31
06/05/2022 19:49:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.49 on epoch=32
06/05/2022 19:49:54 - INFO - __main__ - Global step 450 Train loss 0.51 Classification-F1 0.7438657413959834 on epoch=32
06/05/2022 19:49:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6985369895307312 -> 0.7438657413959834 on epoch=32, global_step=450
06/05/2022 19:49:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.46 on epoch=32
06/05/2022 19:50:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.48 on epoch=33
06/05/2022 19:50:02 - INFO - __main__ - Step 480 Global step 480 Train loss 0.51 on epoch=34
06/05/2022 19:50:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.47 on epoch=34
06/05/2022 19:50:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.39 on epoch=35
06/05/2022 19:50:15 - INFO - __main__ - Global step 500 Train loss 0.46 Classification-F1 0.7397816254671093 on epoch=35
06/05/2022 19:50:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.48 on epoch=36
06/05/2022 19:50:20 - INFO - __main__ - Step 520 Global step 520 Train loss 0.48 on epoch=37
06/05/2022 19:50:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.38 on epoch=37
06/05/2022 19:50:26 - INFO - __main__ - Step 540 Global step 540 Train loss 0.43 on epoch=38
06/05/2022 19:50:28 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=39
06/05/2022 19:50:35 - INFO - __main__ - Global step 550 Train loss 0.44 Classification-F1 0.7928343546607304 on epoch=39
06/05/2022 19:50:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7438657413959834 -> 0.7928343546607304 on epoch=39, global_step=550
06/05/2022 19:50:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.32 on epoch=39
06/05/2022 19:50:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.36 on epoch=40
06/05/2022 19:50:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.43 on epoch=41
06/05/2022 19:50:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.35 on epoch=42
06/05/2022 19:50:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.40 on epoch=42
06/05/2022 19:50:56 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.7984984047925676 on epoch=42
06/05/2022 19:50:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7928343546607304 -> 0.7984984047925676 on epoch=42, global_step=600
06/05/2022 19:50:58 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=43
06/05/2022 19:51:01 - INFO - __main__ - Step 620 Global step 620 Train loss 0.42 on epoch=44
06/05/2022 19:51:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.36 on epoch=44
06/05/2022 19:51:06 - INFO - __main__ - Step 640 Global step 640 Train loss 0.26 on epoch=45
06/05/2022 19:51:09 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=46
06/05/2022 19:51:17 - INFO - __main__ - Global step 650 Train loss 0.33 Classification-F1 0.7499271742956515 on epoch=46
06/05/2022 19:51:19 - INFO - __main__ - Step 660 Global step 660 Train loss 0.30 on epoch=47
06/05/2022 19:51:22 - INFO - __main__ - Step 670 Global step 670 Train loss 0.29 on epoch=47
06/05/2022 19:51:25 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=48
06/05/2022 19:51:28 - INFO - __main__ - Step 690 Global step 690 Train loss 0.31 on epoch=49
06/05/2022 19:51:30 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=49
06/05/2022 19:51:38 - INFO - __main__ - Global step 700 Train loss 0.28 Classification-F1 0.8106294922661147 on epoch=49
06/05/2022 19:51:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7984984047925676 -> 0.8106294922661147 on epoch=49, global_step=700
06/05/2022 19:51:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=50
06/05/2022 19:51:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.25 on epoch=51
06/05/2022 19:51:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.30 on epoch=52
06/05/2022 19:51:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=52
06/05/2022 19:51:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=53
06/05/2022 19:51:59 - INFO - __main__ - Global step 750 Train loss 0.25 Classification-F1 0.725373107312069 on epoch=53
06/05/2022 19:52:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.35 on epoch=54
06/05/2022 19:52:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.27 on epoch=54
06/05/2022 19:52:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.33 on epoch=55
06/05/2022 19:52:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.27 on epoch=56
06/05/2022 19:52:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.32 on epoch=57
06/05/2022 19:52:20 - INFO - __main__ - Global step 800 Train loss 0.31 Classification-F1 0.7158794387070904 on epoch=57
06/05/2022 19:52:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=57
06/05/2022 19:52:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=58
06/05/2022 19:52:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=59
06/05/2022 19:52:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=59
06/05/2022 19:52:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=60
06/05/2022 19:52:40 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.8253968600832252 on epoch=60
06/05/2022 19:52:40 - INFO - __main__ - Saving model with best Classification-F1: 0.8106294922661147 -> 0.8253968600832252 on epoch=60, global_step=850
06/05/2022 19:52:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=61
06/05/2022 19:52:45 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=62
06/05/2022 19:52:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=62
06/05/2022 19:52:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=63
06/05/2022 19:52:53 - INFO - __main__ - Step 900 Global step 900 Train loss 0.26 on epoch=64
06/05/2022 19:53:00 - INFO - __main__ - Global step 900 Train loss 0.22 Classification-F1 0.8254298160385602 on epoch=64
06/05/2022 19:53:00 - INFO - __main__ - Saving model with best Classification-F1: 0.8253968600832252 -> 0.8254298160385602 on epoch=64, global_step=900
06/05/2022 19:53:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=64
06/05/2022 19:53:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=65
06/05/2022 19:53:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=66
06/05/2022 19:53:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=67
06/05/2022 19:53:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.27 on epoch=67
06/05/2022 19:53:20 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.8293306011611788 on epoch=67
06/05/2022 19:53:20 - INFO - __main__ - Saving model with best Classification-F1: 0.8254298160385602 -> 0.8293306011611788 on epoch=67, global_step=950
06/05/2022 19:53:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=68
06/05/2022 19:53:26 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=69
06/05/2022 19:53:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=69
06/05/2022 19:53:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=70
06/05/2022 19:53:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=71
06/05/2022 19:53:40 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.8937836577985763 on epoch=71
06/05/2022 19:53:40 - INFO - __main__ - Saving model with best Classification-F1: 0.8293306011611788 -> 0.8937836577985763 on epoch=71, global_step=1000
06/05/2022 19:53:43 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.23 on epoch=72
06/05/2022 19:53:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
06/05/2022 19:53:49 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.24 on epoch=73
06/05/2022 19:53:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=74
06/05/2022 19:53:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=74
06/05/2022 19:54:01 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.8236212919014071 on epoch=74
06/05/2022 19:54:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=75
06/05/2022 19:54:06 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=76
06/05/2022 19:54:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.19 on epoch=77
06/05/2022 19:54:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=77
06/05/2022 19:54:15 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=78
06/05/2022 19:54:21 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.882703332858407 on epoch=78
06/05/2022 19:54:24 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=79
06/05/2022 19:54:27 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
06/05/2022 19:54:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=80
06/05/2022 19:54:32 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=81
06/05/2022 19:54:35 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=82
06/05/2022 19:54:42 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.8238318633717117 on epoch=82
06/05/2022 19:54:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=82
06/05/2022 19:54:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=83
06/05/2022 19:54:50 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=84
06/05/2022 19:54:53 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=84
06/05/2022 19:54:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
06/05/2022 19:55:02 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.8288790549716701 on epoch=85
06/05/2022 19:55:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
06/05/2022 19:55:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=87
06/05/2022 19:55:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
06/05/2022 19:55:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
06/05/2022 19:55:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=89
06/05/2022 19:55:22 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.7805451608331395 on epoch=89
06/05/2022 19:55:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=89
06/05/2022 19:55:28 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=90
06/05/2022 19:55:30 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=91
06/05/2022 19:55:33 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=92
06/05/2022 19:55:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=92
06/05/2022 19:55:42 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.8389413420338305 on epoch=92
06/05/2022 19:55:45 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=93
06/05/2022 19:55:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=94
06/05/2022 19:55:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=94
06/05/2022 19:55:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=95
06/05/2022 19:55:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=96
06/05/2022 19:56:02 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.8415229141509977 on epoch=96
06/05/2022 19:56:05 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
06/05/2022 19:56:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
06/05/2022 19:56:10 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
06/05/2022 19:56:13 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
06/05/2022 19:56:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=99
06/05/2022 19:56:22 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.8320996492438618 on epoch=99
06/05/2022 19:56:25 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/05/2022 19:56:27 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
06/05/2022 19:56:30 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=102
06/05/2022 19:56:33 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=102
06/05/2022 19:56:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
06/05/2022 19:56:42 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7745812610544214 on epoch=103
06/05/2022 19:56:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
06/05/2022 19:56:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
06/05/2022 19:56:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
06/05/2022 19:56:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=106
06/05/2022 19:56:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=107
06/05/2022 19:57:02 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.8930055481099124 on epoch=107
06/05/2022 19:57:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=107
06/05/2022 19:57:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
06/05/2022 19:57:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
06/05/2022 19:57:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/05/2022 19:57:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=110
06/05/2022 19:57:22 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.8240486752391321 on epoch=110
06/05/2022 19:57:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=111
06/05/2022 19:57:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/05/2022 19:57:30 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
06/05/2022 19:57:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
06/05/2022 19:57:35 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=114
06/05/2022 19:57:41 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8419586439984922 on epoch=114
06/05/2022 19:57:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=114
06/05/2022 19:57:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=115
06/05/2022 19:57:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/05/2022 19:57:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/05/2022 19:57:55 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/05/2022 19:58:01 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.9728247411817392 on epoch=117
06/05/2022 19:58:01 - INFO - __main__ - Saving model with best Classification-F1: 0.8937836577985763 -> 0.9728247411817392 on epoch=117, global_step=1650
06/05/2022 19:58:04 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=118
06/05/2022 19:58:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/05/2022 19:58:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
06/05/2022 19:58:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/05/2022 19:58:15 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
06/05/2022 19:58:21 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.8988663539707182 on epoch=121
06/05/2022 19:58:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
06/05/2022 19:58:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/05/2022 19:58:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=123
06/05/2022 19:58:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/05/2022 19:58:34 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/05/2022 19:58:41 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.9029182582123758 on epoch=124
06/05/2022 19:58:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
06/05/2022 19:58:46 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
06/05/2022 19:58:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/05/2022 19:58:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/05/2022 19:58:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=128
06/05/2022 19:59:01 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.8777120622599403 on epoch=128
06/05/2022 19:59:04 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/05/2022 19:59:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
06/05/2022 19:59:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=130
06/05/2022 19:59:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
06/05/2022 19:59:14 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=132
06/05/2022 19:59:21 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.8930055481099124 on epoch=132
06/05/2022 19:59:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/05/2022 19:59:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
06/05/2022 19:59:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
06/05/2022 19:59:31 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=134
06/05/2022 19:59:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/05/2022 19:59:41 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.8897234968278611 on epoch=135
06/05/2022 19:59:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/05/2022 19:59:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/05/2022 19:59:49 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
06/05/2022 19:59:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/05/2022 19:59:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=139
06/05/2022 20:00:01 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.8937754010695187 on epoch=139
06/05/2022 20:00:03 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/05/2022 20:00:06 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/05/2022 20:00:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/05/2022 20:00:11 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
06/05/2022 20:00:14 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/05/2022 20:00:20 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8141068025956464 on epoch=142
06/05/2022 20:00:23 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/05/2022 20:00:26 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=144
06/05/2022 20:00:28 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=144
06/05/2022 20:00:31 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/05/2022 20:00:34 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/05/2022 20:00:40 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.8247489977626333 on epoch=146
06/05/2022 20:00:43 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/05/2022 20:00:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
06/05/2022 20:00:48 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
06/05/2022 20:00:51 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/05/2022 20:00:54 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/05/2022 20:01:00 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.8724420677361854 on epoch=149
06/05/2022 20:01:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/05/2022 20:01:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/05/2022 20:01:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/05/2022 20:01:11 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=152
06/05/2022 20:01:14 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/05/2022 20:01:21 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.8418242353963417 on epoch=153
06/05/2022 20:01:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/05/2022 20:01:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
06/05/2022 20:01:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/05/2022 20:01:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
06/05/2022 20:01:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/05/2022 20:01:40 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8915721751822865 on epoch=157
06/05/2022 20:01:43 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/05/2022 20:01:46 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/05/2022 20:01:48 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
06/05/2022 20:01:51 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/05/2022 20:01:54 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/05/2022 20:02:01 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.890219845513963 on epoch=160
06/05/2022 20:02:03 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/05/2022 20:02:06 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/05/2022 20:02:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/05/2022 20:02:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.08 on epoch=163
06/05/2022 20:02:14 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/05/2022 20:02:21 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8325649761370824 on epoch=164
06/05/2022 20:02:24 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/05/2022 20:02:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=165
06/05/2022 20:02:29 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/05/2022 20:02:32 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/05/2022 20:02:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/05/2022 20:02:41 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9014936117703898 on epoch=167
06/05/2022 20:02:43 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/05/2022 20:02:46 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/05/2022 20:02:49 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/05/2022 20:02:51 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/05/2022 20:02:54 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/05/2022 20:03:00 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9776165011459128 on epoch=171
06/05/2022 20:03:00 - INFO - __main__ - Saving model with best Classification-F1: 0.9728247411817392 -> 0.9776165011459128 on epoch=171, global_step=2400
06/05/2022 20:03:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/05/2022 20:03:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/05/2022 20:03:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/05/2022 20:03:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
06/05/2022 20:03:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/05/2022 20:03:20 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9010732067121519 on epoch=174
06/05/2022 20:03:23 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/05/2022 20:03:26 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/05/2022 20:03:29 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=177
06/05/2022 20:03:31 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/05/2022 20:03:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/05/2022 20:03:41 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9055455160120474 on epoch=178
06/05/2022 20:03:44 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/05/2022 20:03:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/05/2022 20:03:49 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=180
06/05/2022 20:03:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.07 on epoch=181
06/05/2022 20:03:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/05/2022 20:04:02 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.9102915301017768 on epoch=182
06/05/2022 20:04:04 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/05/2022 20:04:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=183
06/05/2022 20:04:10 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/05/2022 20:04:13 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/05/2022 20:04:15 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/05/2022 20:04:22 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9062396258601191 on epoch=185
06/05/2022 20:04:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/05/2022 20:04:28 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/05/2022 20:04:30 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/05/2022 20:04:33 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/05/2022 20:04:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/05/2022 20:04:42 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9776165011459128 on epoch=189
06/05/2022 20:04:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/05/2022 20:04:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/05/2022 20:04:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/05/2022 20:04:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/05/2022 20:04:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/05/2022 20:05:02 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9144793763057522 on epoch=192
06/05/2022 20:05:05 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/05/2022 20:05:07 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/05/2022 20:05:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/05/2022 20:05:13 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/05/2022 20:05:16 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
06/05/2022 20:05:23 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9144793763057522 on epoch=196
06/05/2022 20:05:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/05/2022 20:05:28 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/05/2022 20:05:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/05/2022 20:05:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/05/2022 20:05:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/05/2022 20:05:43 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9058192208018812 on epoch=199
06/05/2022 20:05:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/05/2022 20:05:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/05/2022 20:05:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/05/2022 20:05:54 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/05/2022 20:05:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
06/05/2022 20:06:03 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9776165011459128 on epoch=203
06/05/2022 20:06:05 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/05/2022 20:06:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/05/2022 20:06:11 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/05/2022 20:06:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/05/2022 20:06:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
06/05/2022 20:06:23 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9061338240085868 on epoch=207
06/05/2022 20:06:25 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=207
06/05/2022 20:06:28 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/05/2022 20:06:31 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/05/2022 20:06:33 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/05/2022 20:06:36 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=210
06/05/2022 20:06:43 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9731618160460664 on epoch=210
06/05/2022 20:06:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/05/2022 20:06:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/05/2022 20:06:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/05/2022 20:06:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/05/2022 20:06:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/05/2022 20:06:59 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 20:06:59 - INFO - __main__ - Printing 3 examples
06/05/2022 20:06:59 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/05/2022 20:06:59 - INFO - __main__ - ['Animal']
06/05/2022 20:06:59 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/05/2022 20:06:59 - INFO - __main__ - ['Animal']
06/05/2022 20:06:59 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/05/2022 20:06:59 - INFO - __main__ - ['Animal']
06/05/2022 20:06:59 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:06:59 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:06:59 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 20:06:59 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 20:06:59 - INFO - __main__ - Printing 3 examples
06/05/2022 20:06:59 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/05/2022 20:06:59 - INFO - __main__ - ['Animal']
06/05/2022 20:06:59 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/05/2022 20:06:59 - INFO - __main__ - ['Animal']
06/05/2022 20:06:59 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/05/2022 20:06:59 - INFO - __main__ - ['Animal']
06/05/2022 20:06:59 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:06:59 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:07:00 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 20:07:04 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9731618160460664 on epoch=214
06/05/2022 20:07:04 - INFO - __main__ - save last model!
06/05/2022 20:07:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 20:07:04 - INFO - __main__ - Start tokenizing ... 3500 instances
06/05/2022 20:07:04 - INFO - __main__ - Printing 3 examples
06/05/2022 20:07:04 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/05/2022 20:07:04 - INFO - __main__ - ['Animal']
06/05/2022 20:07:04 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/05/2022 20:07:04 - INFO - __main__ - ['Animal']
06/05/2022 20:07:04 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/05/2022 20:07:04 - INFO - __main__ - ['Village']
06/05/2022 20:07:04 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:07:06 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:07:10 - INFO - __main__ - Loaded 3500 examples from test data
06/05/2022 20:07:16 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 20:07:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 20:07:17 - INFO - __main__ - Starting training!
06/05/2022 20:09:24 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
06/05/2022 20:09:24 - INFO - __main__ - Classification-F1 on test data: 0.6521
06/05/2022 20:09:24 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.9776165011459128, test_performance=0.6521495315499288
06/05/2022 20:09:24 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
06/05/2022 20:09:25 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 20:09:25 - INFO - __main__ - Printing 3 examples
06/05/2022 20:09:25 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/05/2022 20:09:25 - INFO - __main__ - ['Animal']
06/05/2022 20:09:25 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/05/2022 20:09:25 - INFO - __main__ - ['Animal']
06/05/2022 20:09:25 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/05/2022 20:09:25 - INFO - __main__ - ['Animal']
06/05/2022 20:09:25 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:09:25 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:09:25 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 20:09:25 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 20:09:25 - INFO - __main__ - Printing 3 examples
06/05/2022 20:09:25 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/05/2022 20:09:25 - INFO - __main__ - ['Animal']
06/05/2022 20:09:25 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/05/2022 20:09:25 - INFO - __main__ - ['Animal']
06/05/2022 20:09:25 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/05/2022 20:09:25 - INFO - __main__ - ['Animal']
06/05/2022 20:09:25 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:09:25 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:09:26 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 20:09:45 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 20:09:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 20:09:46 - INFO - __main__ - Starting training!
06/05/2022 20:09:49 - INFO - __main__ - Step 10 Global step 10 Train loss 5.22 on epoch=0
06/05/2022 20:09:52 - INFO - __main__ - Step 20 Global step 20 Train loss 3.87 on epoch=1
06/05/2022 20:09:54 - INFO - __main__ - Step 30 Global step 30 Train loss 2.86 on epoch=2
06/05/2022 20:09:57 - INFO - __main__ - Step 40 Global step 40 Train loss 2.10 on epoch=2
06/05/2022 20:10:00 - INFO - __main__ - Step 50 Global step 50 Train loss 1.82 on epoch=3
06/05/2022 20:10:06 - INFO - __main__ - Global step 50 Train loss 3.18 Classification-F1 0.11459920037377516 on epoch=3
06/05/2022 20:10:06 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11459920037377516 on epoch=3, global_step=50
06/05/2022 20:10:08 - INFO - __main__ - Step 60 Global step 60 Train loss 1.58 on epoch=4
06/05/2022 20:10:11 - INFO - __main__ - Step 70 Global step 70 Train loss 1.29 on epoch=4
06/05/2022 20:10:14 - INFO - __main__ - Step 80 Global step 80 Train loss 1.10 on epoch=5
06/05/2022 20:10:16 - INFO - __main__ - Step 90 Global step 90 Train loss 0.97 on epoch=6
06/05/2022 20:10:19 - INFO - __main__ - Step 100 Global step 100 Train loss 0.85 on epoch=7
06/05/2022 20:10:26 - INFO - __main__ - Global step 100 Train loss 1.16 Classification-F1 0.3746314532028818 on epoch=7
06/05/2022 20:10:27 - INFO - __main__ - Saving model with best Classification-F1: 0.11459920037377516 -> 0.3746314532028818 on epoch=7, global_step=100
06/05/2022 20:10:29 - INFO - __main__ - Step 110 Global step 110 Train loss 0.72 on epoch=7
06/05/2022 20:10:32 - INFO - __main__ - Step 120 Global step 120 Train loss 0.67 on epoch=8
06/05/2022 20:10:34 - INFO - __main__ - Step 130 Global step 130 Train loss 0.58 on epoch=9
06/05/2022 20:10:37 - INFO - __main__ - Step 140 Global step 140 Train loss 0.56 on epoch=9
06/05/2022 20:10:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.60 on epoch=10
06/05/2022 20:10:47 - INFO - __main__ - Global step 150 Train loss 0.62 Classification-F1 0.6508591947020266 on epoch=10
06/05/2022 20:10:47 - INFO - __main__ - Saving model with best Classification-F1: 0.3746314532028818 -> 0.6508591947020266 on epoch=10, global_step=150
06/05/2022 20:10:50 - INFO - __main__ - Step 160 Global step 160 Train loss 0.53 on epoch=11
06/05/2022 20:10:52 - INFO - __main__ - Step 170 Global step 170 Train loss 0.51 on epoch=12
06/05/2022 20:10:55 - INFO - __main__ - Step 180 Global step 180 Train loss 0.55 on epoch=12
06/05/2022 20:10:58 - INFO - __main__ - Step 190 Global step 190 Train loss 0.47 on epoch=13
06/05/2022 20:11:00 - INFO - __main__ - Step 200 Global step 200 Train loss 0.39 on epoch=14
06/05/2022 20:11:07 - INFO - __main__ - Global step 200 Train loss 0.49 Classification-F1 0.7577534757509671 on epoch=14
06/05/2022 20:11:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6508591947020266 -> 0.7577534757509671 on epoch=14, global_step=200
06/05/2022 20:11:10 - INFO - __main__ - Step 210 Global step 210 Train loss 0.36 on epoch=14
06/05/2022 20:11:12 - INFO - __main__ - Step 220 Global step 220 Train loss 0.40 on epoch=15
06/05/2022 20:11:15 - INFO - __main__ - Step 230 Global step 230 Train loss 0.33 on epoch=16
06/05/2022 20:11:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.51 on epoch=17
06/05/2022 20:11:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.34 on epoch=17
06/05/2022 20:11:27 - INFO - __main__ - Global step 250 Train loss 0.39 Classification-F1 0.6362585383134984 on epoch=17
06/05/2022 20:11:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.28 on epoch=18
06/05/2022 20:11:32 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=19
06/05/2022 20:11:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.28 on epoch=19
06/05/2022 20:11:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.35 on epoch=20
06/05/2022 20:11:41 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=21
06/05/2022 20:11:49 - INFO - __main__ - Global step 300 Train loss 0.31 Classification-F1 0.6600594183783021 on epoch=21
06/05/2022 20:11:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=22
06/05/2022 20:11:54 - INFO - __main__ - Step 320 Global step 320 Train loss 0.29 on epoch=22
06/05/2022 20:11:57 - INFO - __main__ - Step 330 Global step 330 Train loss 0.20 on epoch=23
06/05/2022 20:11:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=24
06/05/2022 20:12:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.26 on epoch=24
06/05/2022 20:12:09 - INFO - __main__ - Global step 350 Train loss 0.26 Classification-F1 0.6722819553987313 on epoch=24
06/05/2022 20:12:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=25
06/05/2022 20:12:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=26
06/05/2022 20:12:17 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=27
06/05/2022 20:12:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.17 on epoch=27
06/05/2022 20:12:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.16 on epoch=28
06/05/2022 20:12:30 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.5776038687584928 on epoch=28
06/05/2022 20:12:33 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=29
06/05/2022 20:12:35 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=29
06/05/2022 20:12:38 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=30
06/05/2022 20:12:41 - INFO - __main__ - Step 440 Global step 440 Train loss 0.13 on epoch=31
06/05/2022 20:12:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=32
06/05/2022 20:12:51 - INFO - __main__ - Global step 450 Train loss 0.18 Classification-F1 0.7419783148726111 on epoch=32
06/05/2022 20:12:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=32
06/05/2022 20:12:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=33
06/05/2022 20:12:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=34
06/05/2022 20:13:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=34
06/05/2022 20:13:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=35
06/05/2022 20:13:11 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.7344215133533744 on epoch=35
06/05/2022 20:13:14 - INFO - __main__ - Step 510 Global step 510 Train loss 0.10 on epoch=36
06/05/2022 20:13:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.16 on epoch=37
06/05/2022 20:13:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=37
06/05/2022 20:13:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.08 on epoch=38
06/05/2022 20:13:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.07 on epoch=39
06/05/2022 20:13:31 - INFO - __main__ - Global step 550 Train loss 0.12 Classification-F1 0.7647880834238128 on epoch=39
06/05/2022 20:13:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7577534757509671 -> 0.7647880834238128 on epoch=39, global_step=550
06/05/2022 20:13:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=39
06/05/2022 20:13:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.07 on epoch=40
06/05/2022 20:13:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=41
06/05/2022 20:13:42 - INFO - __main__ - Step 590 Global step 590 Train loss 0.11 on epoch=42
06/05/2022 20:13:44 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=42
06/05/2022 20:13:51 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.8170437474843311 on epoch=42
06/05/2022 20:13:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7647880834238128 -> 0.8170437474843311 on epoch=42, global_step=600
06/05/2022 20:13:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=43
06/05/2022 20:13:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=44
06/05/2022 20:13:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=44
06/05/2022 20:14:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=45
06/05/2022 20:14:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=46
06/05/2022 20:14:11 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.8149232334568473 on epoch=46
06/05/2022 20:14:13 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=47
06/05/2022 20:14:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=47
06/05/2022 20:14:18 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=48
06/05/2022 20:14:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=49
06/05/2022 20:14:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=49
06/05/2022 20:14:30 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.7995371357222689 on epoch=49
06/05/2022 20:14:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=50
06/05/2022 20:14:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=51
06/05/2022 20:14:38 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=52
06/05/2022 20:14:41 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
06/05/2022 20:14:43 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=53
06/05/2022 20:14:50 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.7663885055488471 on epoch=53
06/05/2022 20:14:53 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=54
06/05/2022 20:14:55 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=54
06/05/2022 20:14:58 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
06/05/2022 20:15:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=56
06/05/2022 20:15:03 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=57
06/05/2022 20:15:10 - INFO - __main__ - Global step 800 Train loss 0.07 Classification-F1 0.8708660326016644 on epoch=57
06/05/2022 20:15:10 - INFO - __main__ - Saving model with best Classification-F1: 0.8170437474843311 -> 0.8708660326016644 on epoch=57, global_step=800
06/05/2022 20:15:12 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=57
06/05/2022 20:15:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=58
06/05/2022 20:15:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=59
06/05/2022 20:15:20 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=59
06/05/2022 20:15:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=60
06/05/2022 20:15:29 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.7919843778463602 on epoch=60
06/05/2022 20:15:32 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=61
06/05/2022 20:15:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=62
06/05/2022 20:15:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=62
06/05/2022 20:15:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=63
06/05/2022 20:15:43 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=64
06/05/2022 20:15:49 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7750881906340586 on epoch=64
06/05/2022 20:15:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=64
06/05/2022 20:15:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=65
06/05/2022 20:15:57 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=66
06/05/2022 20:16:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=67
06/05/2022 20:16:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
06/05/2022 20:16:09 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.8414313617675809 on epoch=67
06/05/2022 20:16:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=68
06/05/2022 20:16:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=69
06/05/2022 20:16:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=69
06/05/2022 20:16:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
06/05/2022 20:16:23 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=71
06/05/2022 20:16:29 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.8655659531956865 on epoch=71
06/05/2022 20:16:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=72
06/05/2022 20:16:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=72
06/05/2022 20:16:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=73
06/05/2022 20:16:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=74
06/05/2022 20:16:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=74
06/05/2022 20:16:49 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.9730561533947182 on epoch=74
06/05/2022 20:16:49 - INFO - __main__ - Saving model with best Classification-F1: 0.8708660326016644 -> 0.9730561533947182 on epoch=74, global_step=1050
06/05/2022 20:16:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=75
06/05/2022 20:16:55 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=76
06/05/2022 20:16:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=77
06/05/2022 20:17:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=77
06/05/2022 20:17:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=78
06/05/2022 20:17:09 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.8993954727541064 on epoch=78
06/05/2022 20:17:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=79
06/05/2022 20:17:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=79
06/05/2022 20:17:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/05/2022 20:17:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=81
06/05/2022 20:17:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=82
06/05/2022 20:17:29 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.9643137539689264 on epoch=82
06/05/2022 20:17:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
06/05/2022 20:17:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=83
06/05/2022 20:17:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=84
06/05/2022 20:17:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=84
06/05/2022 20:17:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
06/05/2022 20:17:48 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.9687148274215137 on epoch=85
06/05/2022 20:17:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
06/05/2022 20:17:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=87
06/05/2022 20:17:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=87
06/05/2022 20:17:59 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=88
06/05/2022 20:18:02 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
06/05/2022 20:18:08 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.9058117935885718 on epoch=89
06/05/2022 20:18:11 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
06/05/2022 20:18:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=90
06/05/2022 20:18:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=91
06/05/2022 20:18:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=92
06/05/2022 20:18:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
06/05/2022 20:18:29 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.9728167834531932 on epoch=92
06/05/2022 20:18:32 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
06/05/2022 20:18:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=94
06/05/2022 20:18:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
06/05/2022 20:18:40 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=95
06/05/2022 20:18:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
06/05/2022 20:18:49 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.972812419537539 on epoch=96
06/05/2022 20:18:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
06/05/2022 20:18:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
06/05/2022 20:18:57 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
06/05/2022 20:19:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
06/05/2022 20:19:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=99
06/05/2022 20:19:09 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.8890078320606681 on epoch=99
06/05/2022 20:19:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
06/05/2022 20:19:14 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=101
06/05/2022 20:19:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
06/05/2022 20:19:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=102
06/05/2022 20:19:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
06/05/2022 20:19:28 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.9505876231862499 on epoch=103
06/05/2022 20:19:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=104
06/05/2022 20:19:34 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/05/2022 20:19:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
06/05/2022 20:19:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/05/2022 20:19:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/05/2022 20:19:48 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.9689149780146662 on epoch=107
06/05/2022 20:19:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
06/05/2022 20:19:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
06/05/2022 20:19:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/05/2022 20:19:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/05/2022 20:20:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
06/05/2022 20:20:08 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9685918676804324 on epoch=110
06/05/2022 20:20:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/05/2022 20:20:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
06/05/2022 20:20:16 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/05/2022 20:20:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/05/2022 20:20:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/05/2022 20:20:28 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.9774768558449772 on epoch=114
06/05/2022 20:20:28 - INFO - __main__ - Saving model with best Classification-F1: 0.9730561533947182 -> 0.9774768558449772 on epoch=114, global_step=1600
06/05/2022 20:20:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=114
06/05/2022 20:20:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
06/05/2022 20:20:37 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/05/2022 20:20:40 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/05/2022 20:20:42 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/05/2022 20:20:48 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.9643296520414888 on epoch=117
06/05/2022 20:20:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/05/2022 20:20:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/05/2022 20:20:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/05/2022 20:20:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/05/2022 20:21:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
06/05/2022 20:21:08 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9688312376219574 on epoch=121
06/05/2022 20:21:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/05/2022 20:21:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
06/05/2022 20:21:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=123
06/05/2022 20:21:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
06/05/2022 20:21:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
06/05/2022 20:21:28 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8895195702802194 on epoch=124
06/05/2022 20:21:31 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/05/2022 20:21:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/05/2022 20:21:37 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/05/2022 20:21:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/05/2022 20:21:42 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/05/2022 20:21:48 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.9774390429141623 on epoch=128
06/05/2022 20:21:51 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/05/2022 20:21:54 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/05/2022 20:21:56 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/05/2022 20:21:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
06/05/2022 20:22:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/05/2022 20:22:08 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9058077206006279 on epoch=132
06/05/2022 20:22:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/05/2022 20:22:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/05/2022 20:22:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/05/2022 20:22:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/05/2022 20:22:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/05/2022 20:22:28 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9689423108880185 on epoch=135
06/05/2022 20:22:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/05/2022 20:22:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/05/2022 20:22:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=137
06/05/2022 20:22:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/05/2022 20:22:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/05/2022 20:22:48 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.964250541707228 on epoch=139
06/05/2022 20:22:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/05/2022 20:22:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/05/2022 20:22:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/05/2022 20:22:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/05/2022 20:23:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/05/2022 20:23:08 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9819717916492109 on epoch=142
06/05/2022 20:23:08 - INFO - __main__ - Saving model with best Classification-F1: 0.9774768558449772 -> 0.9819717916492109 on epoch=142, global_step=2000
06/05/2022 20:23:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/05/2022 20:23:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=144
06/05/2022 20:23:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/05/2022 20:23:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/05/2022 20:23:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/05/2022 20:23:27 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.9143564679048549 on epoch=146
06/05/2022 20:23:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/05/2022 20:23:33 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/05/2022 20:23:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/05/2022 20:23:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/05/2022 20:23:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/05/2022 20:23:47 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9777205897021565 on epoch=149
06/05/2022 20:23:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/05/2022 20:23:52 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=151
06/05/2022 20:23:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
06/05/2022 20:23:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/05/2022 20:24:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/05/2022 20:24:06 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9818181818181818 on epoch=153
06/05/2022 20:24:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=154
06/05/2022 20:24:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=154
06/05/2022 20:24:14 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/05/2022 20:24:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=156
06/05/2022 20:24:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/05/2022 20:24:25 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9142130987292276 on epoch=157
06/05/2022 20:24:28 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
06/05/2022 20:24:30 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
06/05/2022 20:24:33 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
06/05/2022 20:24:36 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/05/2022 20:24:38 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
06/05/2022 20:24:45 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.9818181818181818 on epoch=160
06/05/2022 20:24:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/05/2022 20:24:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
06/05/2022 20:24:53 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/05/2022 20:24:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
06/05/2022 20:24:59 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=164
06/05/2022 20:25:06 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9819455054749172 on epoch=164
06/05/2022 20:25:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
06/05/2022 20:25:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/05/2022 20:25:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=166
06/05/2022 20:25:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/05/2022 20:25:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/05/2022 20:25:26 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9774768558449772 on epoch=167
06/05/2022 20:25:29 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/05/2022 20:25:31 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/05/2022 20:25:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/05/2022 20:25:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/05/2022 20:25:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/05/2022 20:25:46 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9817760049717127 on epoch=171
06/05/2022 20:25:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/05/2022 20:25:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/05/2022 20:25:54 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
06/05/2022 20:25:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
06/05/2022 20:26:00 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/05/2022 20:26:06 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9774768558449772 on epoch=174
06/05/2022 20:26:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/05/2022 20:26:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/05/2022 20:26:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
06/05/2022 20:26:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
06/05/2022 20:26:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/05/2022 20:26:26 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9685875037647781 on epoch=178
06/05/2022 20:26:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=179
06/05/2022 20:26:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/05/2022 20:26:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/05/2022 20:26:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
06/05/2022 20:26:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/05/2022 20:26:47 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9774390429141623 on epoch=182
06/05/2022 20:26:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/05/2022 20:26:53 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
06/05/2022 20:26:56 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
06/05/2022 20:26:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/05/2022 20:27:01 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
06/05/2022 20:27:08 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9774768558449772 on epoch=185
06/05/2022 20:27:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/05/2022 20:27:14 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/05/2022 20:27:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/05/2022 20:27:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/05/2022 20:27:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/05/2022 20:27:29 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9771537455107434 on epoch=189
06/05/2022 20:27:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/05/2022 20:27:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
06/05/2022 20:27:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/05/2022 20:27:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/05/2022 20:27:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/05/2022 20:27:49 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9731122947712808 on epoch=192
06/05/2022 20:27:51 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/05/2022 20:27:54 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
06/05/2022 20:27:57 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/05/2022 20:27:59 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/05/2022 20:28:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/05/2022 20:28:09 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9774812197606314 on epoch=196
06/05/2022 20:28:11 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/05/2022 20:28:14 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/05/2022 20:28:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/05/2022 20:28:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/05/2022 20:28:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
06/05/2022 20:28:29 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9818181818181818 on epoch=199
06/05/2022 20:28:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/05/2022 20:28:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/05/2022 20:28:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/05/2022 20:28:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/05/2022 20:28:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/05/2022 20:28:49 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.9771537455107434 on epoch=203
06/05/2022 20:28:52 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/05/2022 20:28:55 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/05/2022 20:28:57 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/05/2022 20:29:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/05/2022 20:29:03 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/05/2022 20:29:09 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.9771537455107434 on epoch=207
06/05/2022 20:29:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/05/2022 20:29:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/05/2022 20:29:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/05/2022 20:29:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
06/05/2022 20:29:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/05/2022 20:29:30 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9776041795017127 on epoch=210
06/05/2022 20:29:33 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/05/2022 20:29:36 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/05/2022 20:29:38 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/05/2022 20:29:41 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/05/2022 20:29:44 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/05/2022 20:29:45 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 20:29:45 - INFO - __main__ - Printing 3 examples
06/05/2022 20:29:45 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/05/2022 20:29:45 - INFO - __main__ - ['Animal']
06/05/2022 20:29:45 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/05/2022 20:29:45 - INFO - __main__ - ['Animal']
06/05/2022 20:29:45 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/05/2022 20:29:45 - INFO - __main__ - ['Animal']
06/05/2022 20:29:45 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:29:45 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:29:45 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 20:29:45 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 20:29:45 - INFO - __main__ - Printing 3 examples
06/05/2022 20:29:45 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/05/2022 20:29:45 - INFO - __main__ - ['Animal']
06/05/2022 20:29:45 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/05/2022 20:29:45 - INFO - __main__ - ['Animal']
06/05/2022 20:29:45 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/05/2022 20:29:45 - INFO - __main__ - ['Animal']
06/05/2022 20:29:45 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:29:46 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:29:46 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 20:29:50 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9776041795017127 on epoch=214
06/05/2022 20:29:50 - INFO - __main__ - save last model!
06/05/2022 20:29:51 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 20:29:51 - INFO - __main__ - Start tokenizing ... 3500 instances
06/05/2022 20:29:51 - INFO - __main__ - Printing 3 examples
06/05/2022 20:29:51 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/05/2022 20:29:51 - INFO - __main__ - ['Animal']
06/05/2022 20:29:51 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/05/2022 20:29:51 - INFO - __main__ - ['Animal']
06/05/2022 20:29:51 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/05/2022 20:29:51 - INFO - __main__ - ['Village']
06/05/2022 20:29:51 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:29:52 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:29:56 - INFO - __main__ - Loaded 3500 examples from test data
06/05/2022 20:30:04 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 20:30:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 20:30:05 - INFO - __main__ - Starting training!
06/05/2022 20:32:20 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
06/05/2022 20:32:20 - INFO - __main__ - Classification-F1 on test data: 0.8068
06/05/2022 20:32:20 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.9819717916492109, test_performance=0.8067927970831726
06/05/2022 20:32:20 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
06/05/2022 20:32:21 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 20:32:21 - INFO - __main__ - Printing 3 examples
06/05/2022 20:32:21 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/05/2022 20:32:21 - INFO - __main__ - ['Animal']
06/05/2022 20:32:21 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/05/2022 20:32:21 - INFO - __main__ - ['Animal']
06/05/2022 20:32:21 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/05/2022 20:32:21 - INFO - __main__ - ['Animal']
06/05/2022 20:32:21 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:32:21 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:32:22 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 20:32:22 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 20:32:22 - INFO - __main__ - Printing 3 examples
06/05/2022 20:32:22 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/05/2022 20:32:22 - INFO - __main__ - ['Animal']
06/05/2022 20:32:22 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/05/2022 20:32:22 - INFO - __main__ - ['Animal']
06/05/2022 20:32:22 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/05/2022 20:32:22 - INFO - __main__ - ['Animal']
06/05/2022 20:32:22 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:32:22 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:32:22 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 20:32:41 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 20:32:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 20:32:42 - INFO - __main__ - Starting training!
06/05/2022 20:32:45 - INFO - __main__ - Step 10 Global step 10 Train loss 5.35 on epoch=0
06/05/2022 20:32:48 - INFO - __main__ - Step 20 Global step 20 Train loss 4.02 on epoch=1
06/05/2022 20:32:51 - INFO - __main__ - Step 30 Global step 30 Train loss 3.38 on epoch=2
06/05/2022 20:32:53 - INFO - __main__ - Step 40 Global step 40 Train loss 2.55 on epoch=2
06/05/2022 20:32:56 - INFO - __main__ - Step 50 Global step 50 Train loss 2.17 on epoch=3
06/05/2022 20:33:02 - INFO - __main__ - Global step 50 Train loss 3.49 Classification-F1 0.07813931722720363 on epoch=3
06/05/2022 20:33:02 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07813931722720363 on epoch=3, global_step=50
06/05/2022 20:33:05 - INFO - __main__ - Step 60 Global step 60 Train loss 1.94 on epoch=4
06/05/2022 20:33:07 - INFO - __main__ - Step 70 Global step 70 Train loss 1.52 on epoch=4
06/05/2022 20:33:10 - INFO - __main__ - Step 80 Global step 80 Train loss 1.26 on epoch=5
06/05/2022 20:33:12 - INFO - __main__ - Step 90 Global step 90 Train loss 1.28 on epoch=6
06/05/2022 20:33:15 - INFO - __main__ - Step 100 Global step 100 Train loss 1.05 on epoch=7
06/05/2022 20:33:22 - INFO - __main__ - Global step 100 Train loss 1.41 Classification-F1 0.3710998690196319 on epoch=7
06/05/2022 20:33:22 - INFO - __main__ - Saving model with best Classification-F1: 0.07813931722720363 -> 0.3710998690196319 on epoch=7, global_step=100
06/05/2022 20:33:25 - INFO - __main__ - Step 110 Global step 110 Train loss 0.94 on epoch=7
06/05/2022 20:33:28 - INFO - __main__ - Step 120 Global step 120 Train loss 0.92 on epoch=8
06/05/2022 20:33:30 - INFO - __main__ - Step 130 Global step 130 Train loss 0.84 on epoch=9
06/05/2022 20:33:33 - INFO - __main__ - Step 140 Global step 140 Train loss 0.73 on epoch=9
06/05/2022 20:33:36 - INFO - __main__ - Step 150 Global step 150 Train loss 0.70 on epoch=10
06/05/2022 20:33:43 - INFO - __main__ - Global step 150 Train loss 0.82 Classification-F1 0.46389017241821423 on epoch=10
06/05/2022 20:33:43 - INFO - __main__ - Saving model with best Classification-F1: 0.3710998690196319 -> 0.46389017241821423 on epoch=10, global_step=150
06/05/2022 20:33:46 - INFO - __main__ - Step 160 Global step 160 Train loss 0.59 on epoch=11
06/05/2022 20:33:49 - INFO - __main__ - Step 170 Global step 170 Train loss 0.57 on epoch=12
06/05/2022 20:33:51 - INFO - __main__ - Step 180 Global step 180 Train loss 0.59 on epoch=12
06/05/2022 20:33:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.62 on epoch=13
06/05/2022 20:33:57 - INFO - __main__ - Step 200 Global step 200 Train loss 0.59 on epoch=14
06/05/2022 20:34:04 - INFO - __main__ - Global step 200 Train loss 0.59 Classification-F1 0.7203637701815314 on epoch=14
06/05/2022 20:34:04 - INFO - __main__ - Saving model with best Classification-F1: 0.46389017241821423 -> 0.7203637701815314 on epoch=14, global_step=200
06/05/2022 20:34:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.45 on epoch=14
06/05/2022 20:34:10 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=15
06/05/2022 20:34:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.36 on epoch=16
06/05/2022 20:34:15 - INFO - __main__ - Step 240 Global step 240 Train loss 0.47 on epoch=17
06/05/2022 20:34:18 - INFO - __main__ - Step 250 Global step 250 Train loss 0.42 on epoch=17
06/05/2022 20:34:25 - INFO - __main__ - Global step 250 Train loss 0.44 Classification-F1 0.7230590223014914 on epoch=17
06/05/2022 20:34:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7203637701815314 -> 0.7230590223014914 on epoch=17, global_step=250
06/05/2022 20:34:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.47 on epoch=18
06/05/2022 20:34:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.39 on epoch=19
06/05/2022 20:34:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=19
06/05/2022 20:34:35 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=20
06/05/2022 20:34:38 - INFO - __main__ - Step 300 Global step 300 Train loss 0.38 on epoch=21
06/05/2022 20:34:45 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.6423417108264308 on epoch=21
06/05/2022 20:34:47 - INFO - __main__ - Step 310 Global step 310 Train loss 0.36 on epoch=22
06/05/2022 20:34:50 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=22
06/05/2022 20:34:52 - INFO - __main__ - Step 330 Global step 330 Train loss 0.28 on epoch=23
06/05/2022 20:34:55 - INFO - __main__ - Step 340 Global step 340 Train loss 0.37 on epoch=24
06/05/2022 20:34:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.31 on epoch=24
06/05/2022 20:35:04 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.5038097531786171 on epoch=24
06/05/2022 20:35:07 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=25
06/05/2022 20:35:10 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=26
06/05/2022 20:35:12 - INFO - __main__ - Step 380 Global step 380 Train loss 0.29 on epoch=27
06/05/2022 20:35:15 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=27
06/05/2022 20:35:17 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=28
06/05/2022 20:35:24 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.5504611898700569 on epoch=28
06/05/2022 20:35:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=29
06/05/2022 20:35:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=29
06/05/2022 20:35:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=30
06/05/2022 20:35:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.15 on epoch=31
06/05/2022 20:35:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=32
06/05/2022 20:35:44 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.5251007655401013 on epoch=32
06/05/2022 20:35:47 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=32
06/05/2022 20:35:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=33
06/05/2022 20:35:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=34
06/05/2022 20:35:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=34
06/05/2022 20:35:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=35
06/05/2022 20:36:04 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.6962745347693444 on epoch=35
06/05/2022 20:36:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=36
06/05/2022 20:36:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=37
06/05/2022 20:36:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=37
06/05/2022 20:36:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=38
06/05/2022 20:36:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=39
06/05/2022 20:36:23 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.6186091900875181 on epoch=39
06/05/2022 20:36:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=39
06/05/2022 20:36:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=40
06/05/2022 20:36:32 - INFO - __main__ - Step 580 Global step 580 Train loss 0.10 on epoch=41
06/05/2022 20:36:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=42
06/05/2022 20:36:37 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=42
06/05/2022 20:36:43 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.6664635976079126 on epoch=42
06/05/2022 20:36:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.13 on epoch=43
06/05/2022 20:36:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=44
06/05/2022 20:36:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=44
06/05/2022 20:36:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=45
06/05/2022 20:36:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=46
06/05/2022 20:37:03 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.6958317745594287 on epoch=46
06/05/2022 20:37:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=47
06/05/2022 20:37:09 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=47
06/05/2022 20:37:11 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=48
06/05/2022 20:37:14 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=49
06/05/2022 20:37:17 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=49
06/05/2022 20:37:23 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.7738893812270229 on epoch=49
06/05/2022 20:37:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7230590223014914 -> 0.7738893812270229 on epoch=49, global_step=700
06/05/2022 20:37:26 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=50
06/05/2022 20:37:28 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=51
06/05/2022 20:37:31 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=52
06/05/2022 20:37:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
06/05/2022 20:37:36 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=53
06/05/2022 20:37:43 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.8177363301340412 on epoch=53
06/05/2022 20:37:43 - INFO - __main__ - Saving model with best Classification-F1: 0.7738893812270229 -> 0.8177363301340412 on epoch=53, global_step=750
06/05/2022 20:37:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=54
06/05/2022 20:37:48 - INFO - __main__ - Step 770 Global step 770 Train loss 0.09 on epoch=54
06/05/2022 20:37:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=55
06/05/2022 20:37:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=56
06/05/2022 20:37:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=57
06/05/2022 20:38:02 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7729132849110573 on epoch=57
06/05/2022 20:38:05 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=57
06/05/2022 20:38:07 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=58
06/05/2022 20:38:10 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=59
06/05/2022 20:38:13 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=59
06/05/2022 20:38:15 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=60
06/05/2022 20:38:22 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.8432398093540683 on epoch=60
06/05/2022 20:38:22 - INFO - __main__ - Saving model with best Classification-F1: 0.8177363301340412 -> 0.8432398093540683 on epoch=60, global_step=850
06/05/2022 20:38:25 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=61
06/05/2022 20:38:27 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=62
06/05/2022 20:38:30 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=62
06/05/2022 20:38:33 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=63
06/05/2022 20:38:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=64
06/05/2022 20:38:42 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.8374714741101719 on epoch=64
06/05/2022 20:38:45 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=64
06/05/2022 20:38:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=65
06/05/2022 20:38:50 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
06/05/2022 20:38:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=67
06/05/2022 20:38:55 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=67
06/05/2022 20:39:02 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.8361246727633707 on epoch=67
06/05/2022 20:39:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=68
06/05/2022 20:39:07 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=69
06/05/2022 20:39:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=69
06/05/2022 20:39:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
06/05/2022 20:39:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
06/05/2022 20:39:21 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.7424124819813657 on epoch=71
06/05/2022 20:39:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/05/2022 20:39:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
06/05/2022 20:39:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=73
06/05/2022 20:39:32 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=74
06/05/2022 20:39:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
06/05/2022 20:39:42 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.8471201429618769 on epoch=74
06/05/2022 20:39:42 - INFO - __main__ - Saving model with best Classification-F1: 0.8432398093540683 -> 0.8471201429618769 on epoch=74, global_step=1050
06/05/2022 20:39:44 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
06/05/2022 20:39:47 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
06/05/2022 20:39:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
06/05/2022 20:39:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
06/05/2022 20:39:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=78
06/05/2022 20:40:01 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.9027879225981692 on epoch=78
06/05/2022 20:40:01 - INFO - __main__ - Saving model with best Classification-F1: 0.8471201429618769 -> 0.9027879225981692 on epoch=78, global_step=1100
06/05/2022 20:40:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=79
06/05/2022 20:40:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
06/05/2022 20:40:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
06/05/2022 20:40:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=81
06/05/2022 20:40:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/05/2022 20:40:21 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.9018644658793844 on epoch=82
06/05/2022 20:40:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=82
06/05/2022 20:40:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=83
06/05/2022 20:40:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=84
06/05/2022 20:40:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=84
06/05/2022 20:40:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
06/05/2022 20:40:41 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.9058077206006279 on epoch=85
06/05/2022 20:40:41 - INFO - __main__ - Saving model with best Classification-F1: 0.9027879225981692 -> 0.9058077206006279 on epoch=85, global_step=1200
06/05/2022 20:40:44 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
06/05/2022 20:40:47 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
06/05/2022 20:40:49 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
06/05/2022 20:40:52 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/05/2022 20:40:55 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
06/05/2022 20:41:02 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.9012206488757232 on epoch=89
06/05/2022 20:41:04 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=89
06/05/2022 20:41:07 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
06/05/2022 20:41:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
06/05/2022 20:41:12 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
06/05/2022 20:41:15 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
06/05/2022 20:41:22 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.8432482098917027 on epoch=92
06/05/2022 20:41:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
06/05/2022 20:41:27 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
06/05/2022 20:41:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
06/05/2022 20:41:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
06/05/2022 20:41:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
06/05/2022 20:41:42 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.8976129415598106 on epoch=96
06/05/2022 20:41:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
06/05/2022 20:41:48 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
06/05/2022 20:41:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
06/05/2022 20:41:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
06/05/2022 20:41:56 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/05/2022 20:42:02 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.8975782219045975 on epoch=99
06/05/2022 20:42:05 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/05/2022 20:42:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/05/2022 20:42:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/05/2022 20:42:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
06/05/2022 20:42:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/05/2022 20:42:22 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.9774768558449772 on epoch=103
06/05/2022 20:42:23 - INFO - __main__ - Saving model with best Classification-F1: 0.9058077206006279 -> 0.9774768558449772 on epoch=103, global_step=1450
06/05/2022 20:42:25 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=104
06/05/2022 20:42:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/05/2022 20:42:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/05/2022 20:42:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
06/05/2022 20:42:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/05/2022 20:42:43 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.839277701233694 on epoch=107
06/05/2022 20:42:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/05/2022 20:42:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/05/2022 20:42:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/05/2022 20:42:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/05/2022 20:42:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/05/2022 20:43:04 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9685439205007516 on epoch=110
06/05/2022 20:43:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
06/05/2022 20:43:10 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
06/05/2022 20:43:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/05/2022 20:43:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/05/2022 20:43:18 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/05/2022 20:43:26 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9058756924079503 on epoch=114
06/05/2022 20:43:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/05/2022 20:43:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=115
06/05/2022 20:43:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/05/2022 20:43:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/05/2022 20:43:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/05/2022 20:43:47 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.9640935993165594 on epoch=117
06/05/2022 20:43:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/05/2022 20:43:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/05/2022 20:43:55 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/05/2022 20:43:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
06/05/2022 20:44:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/05/2022 20:44:08 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.9685702066750453 on epoch=121
06/05/2022 20:44:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/05/2022 20:44:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
06/05/2022 20:44:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/05/2022 20:44:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/05/2022 20:44:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
06/05/2022 20:44:29 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.9642288807018409 on epoch=124
06/05/2022 20:44:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
06/05/2022 20:44:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/05/2022 20:44:37 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/05/2022 20:44:40 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/05/2022 20:44:42 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/05/2022 20:44:49 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.9143319341421808 on epoch=128
06/05/2022 20:44:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
06/05/2022 20:44:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/05/2022 20:44:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/05/2022 20:45:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/05/2022 20:45:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/05/2022 20:45:12 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9143319341421808 on epoch=132
06/05/2022 20:45:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/05/2022 20:45:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/05/2022 20:45:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
06/05/2022 20:45:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/05/2022 20:45:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/05/2022 20:45:33 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.851236990397332 on epoch=135
06/05/2022 20:45:36 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/05/2022 20:45:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/05/2022 20:45:41 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/05/2022 20:45:44 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/05/2022 20:45:47 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/05/2022 20:45:54 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.9686405940675391 on epoch=139
06/05/2022 20:45:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/05/2022 20:45:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/05/2022 20:46:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=141
06/05/2022 20:46:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/05/2022 20:46:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/05/2022 20:46:14 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.9143319341421808 on epoch=142
06/05/2022 20:46:17 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/05/2022 20:46:20 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=144
06/05/2022 20:46:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/05/2022 20:46:25 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/05/2022 20:46:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/05/2022 20:46:35 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9730308985764393 on epoch=146
06/05/2022 20:46:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/05/2022 20:46:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/05/2022 20:46:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/05/2022 20:46:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/05/2022 20:46:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/05/2022 20:46:56 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9730388563049853 on epoch=149
06/05/2022 20:46:59 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/05/2022 20:47:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/05/2022 20:47:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/05/2022 20:47:07 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/05/2022 20:47:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/05/2022 20:47:17 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9687148274215137 on epoch=153
06/05/2022 20:47:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/05/2022 20:47:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/05/2022 20:47:25 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
06/05/2022 20:47:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/05/2022 20:47:30 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
06/05/2022 20:47:37 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9819455054749172 on epoch=157
06/05/2022 20:47:37 - INFO - __main__ - Saving model with best Classification-F1: 0.9774768558449772 -> 0.9819455054749172 on epoch=157, global_step=2200
06/05/2022 20:47:40 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/05/2022 20:47:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/05/2022 20:47:45 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/05/2022 20:47:48 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/05/2022 20:47:51 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/05/2022 20:47:57 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9771537455107435 on epoch=160
06/05/2022 20:48:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/05/2022 20:48:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/05/2022 20:48:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/05/2022 20:48:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/05/2022 20:48:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/05/2022 20:48:18 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9726894597964577 on epoch=164
06/05/2022 20:48:21 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/05/2022 20:48:23 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/05/2022 20:48:26 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/05/2022 20:48:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/05/2022 20:48:32 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/05/2022 20:48:38 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9727034243265512 on epoch=167
06/05/2022 20:48:41 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/05/2022 20:48:44 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
06/05/2022 20:48:47 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/05/2022 20:48:49 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
06/05/2022 20:48:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
06/05/2022 20:48:59 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9819455054749172 on epoch=171
06/05/2022 20:49:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/05/2022 20:49:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/05/2022 20:49:07 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
06/05/2022 20:49:10 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/05/2022 20:49:12 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/05/2022 20:49:19 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9730388563049853 on epoch=174
06/05/2022 20:49:22 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/05/2022 20:49:25 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/05/2022 20:49:27 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/05/2022 20:49:30 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
06/05/2022 20:49:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/05/2022 20:49:40 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9728545963840081 on epoch=178
06/05/2022 20:49:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/05/2022 20:49:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/05/2022 20:49:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/05/2022 20:49:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/05/2022 20:49:53 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/05/2022 20:50:00 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9773678606339897 on epoch=182
06/05/2022 20:50:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
06/05/2022 20:50:06 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/05/2022 20:50:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/05/2022 20:50:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/05/2022 20:50:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/05/2022 20:50:21 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9729397431942743 on epoch=185
06/05/2022 20:50:23 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
06/05/2022 20:50:26 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/05/2022 20:50:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/05/2022 20:50:32 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/05/2022 20:50:34 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/05/2022 20:50:41 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9771537455107435 on epoch=189
06/05/2022 20:50:44 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/05/2022 20:50:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
06/05/2022 20:50:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/05/2022 20:50:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/05/2022 20:50:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/05/2022 20:51:02 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.977281069167479 on epoch=192
06/05/2022 20:51:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/05/2022 20:51:07 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/05/2022 20:51:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/05/2022 20:51:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/05/2022 20:51:15 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/05/2022 20:51:22 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.972812419537539 on epoch=196
06/05/2022 20:51:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/05/2022 20:51:28 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/05/2022 20:51:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/05/2022 20:51:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/05/2022 20:51:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/05/2022 20:51:42 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.9728167834531932 on epoch=199
06/05/2022 20:51:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/05/2022 20:51:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/05/2022 20:51:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=202
06/05/2022 20:51:53 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/05/2022 20:51:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/05/2022 20:52:03 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9688204900728621 on epoch=203
06/05/2022 20:52:05 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=204
06/05/2022 20:52:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/05/2022 20:52:11 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/05/2022 20:52:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/05/2022 20:52:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/05/2022 20:52:23 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.973139893787427 on epoch=207
06/05/2022 20:52:25 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/05/2022 20:52:28 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/05/2022 20:52:31 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/05/2022 20:52:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/05/2022 20:52:36 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/05/2022 20:52:44 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.9774768558449775 on epoch=210
06/05/2022 20:52:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/05/2022 20:52:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/05/2022 20:52:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/05/2022 20:52:55 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/05/2022 20:52:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/05/2022 20:52:59 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 20:52:59 - INFO - __main__ - Printing 3 examples
06/05/2022 20:52:59 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/05/2022 20:52:59 - INFO - __main__ - ['Animal']
06/05/2022 20:52:59 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/05/2022 20:52:59 - INFO - __main__ - ['Animal']
06/05/2022 20:52:59 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/05/2022 20:52:59 - INFO - __main__ - ['Animal']
06/05/2022 20:52:59 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:52:59 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:52:59 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 20:52:59 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 20:52:59 - INFO - __main__ - Printing 3 examples
06/05/2022 20:52:59 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/05/2022 20:52:59 - INFO - __main__ - ['Animal']
06/05/2022 20:52:59 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/05/2022 20:52:59 - INFO - __main__ - ['Animal']
06/05/2022 20:52:59 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/05/2022 20:52:59 - INFO - __main__ - ['Animal']
06/05/2022 20:52:59 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:52:59 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:52:59 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 20:53:05 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9774768558449775 on epoch=214
06/05/2022 20:53:05 - INFO - __main__ - save last model!
06/05/2022 20:53:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 20:53:05 - INFO - __main__ - Start tokenizing ... 3500 instances
06/05/2022 20:53:05 - INFO - __main__ - Printing 3 examples
06/05/2022 20:53:05 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/05/2022 20:53:05 - INFO - __main__ - ['Animal']
06/05/2022 20:53:05 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/05/2022 20:53:05 - INFO - __main__ - ['Animal']
06/05/2022 20:53:05 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/05/2022 20:53:05 - INFO - __main__ - ['Village']
06/05/2022 20:53:05 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:53:07 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:53:10 - INFO - __main__ - Loaded 3500 examples from test data
06/05/2022 20:53:18 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 20:53:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 20:53:19 - INFO - __main__ - Starting training!
06/05/2022 20:55:22 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
06/05/2022 20:55:22 - INFO - __main__ - Classification-F1 on test data: 0.7617
06/05/2022 20:55:23 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.9819455054749172, test_performance=0.7617439371679219
06/05/2022 20:55:23 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
06/05/2022 20:55:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 20:55:24 - INFO - __main__ - Printing 3 examples
06/05/2022 20:55:24 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/05/2022 20:55:24 - INFO - __main__ - ['Animal']
06/05/2022 20:55:24 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/05/2022 20:55:24 - INFO - __main__ - ['Animal']
06/05/2022 20:55:24 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/05/2022 20:55:24 - INFO - __main__ - ['Animal']
06/05/2022 20:55:24 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:55:24 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:55:24 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 20:55:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 20:55:24 - INFO - __main__ - Printing 3 examples
06/05/2022 20:55:24 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/05/2022 20:55:24 - INFO - __main__ - ['Animal']
06/05/2022 20:55:24 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/05/2022 20:55:24 - INFO - __main__ - ['Animal']
06/05/2022 20:55:24 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/05/2022 20:55:24 - INFO - __main__ - ['Animal']
06/05/2022 20:55:24 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:55:24 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:55:25 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 20:55:43 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 20:55:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 20:55:44 - INFO - __main__ - Starting training!
06/05/2022 20:55:48 - INFO - __main__ - Step 10 Global step 10 Train loss 5.50 on epoch=0
06/05/2022 20:55:51 - INFO - __main__ - Step 20 Global step 20 Train loss 4.26 on epoch=1
06/05/2022 20:55:54 - INFO - __main__ - Step 30 Global step 30 Train loss 3.65 on epoch=2
06/05/2022 20:55:56 - INFO - __main__ - Step 40 Global step 40 Train loss 3.11 on epoch=2
06/05/2022 20:55:59 - INFO - __main__ - Step 50 Global step 50 Train loss 2.71 on epoch=3
06/05/2022 20:56:05 - INFO - __main__ - Global step 50 Train loss 3.84 Classification-F1 0.0547473052831545 on epoch=3
06/05/2022 20:56:05 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0547473052831545 on epoch=3, global_step=50
06/05/2022 20:56:07 - INFO - __main__ - Step 60 Global step 60 Train loss 2.43 on epoch=4
06/05/2022 20:56:10 - INFO - __main__ - Step 70 Global step 70 Train loss 1.99 on epoch=4
06/05/2022 20:56:13 - INFO - __main__ - Step 80 Global step 80 Train loss 1.84 on epoch=5
06/05/2022 20:56:16 - INFO - __main__ - Step 90 Global step 90 Train loss 1.63 on epoch=6
06/05/2022 20:56:18 - INFO - __main__ - Step 100 Global step 100 Train loss 1.50 on epoch=7
06/05/2022 20:56:24 - INFO - __main__ - Global step 100 Train loss 1.88 Classification-F1 0.22944599536054583 on epoch=7
06/05/2022 20:56:25 - INFO - __main__ - Saving model with best Classification-F1: 0.0547473052831545 -> 0.22944599536054583 on epoch=7, global_step=100
06/05/2022 20:56:27 - INFO - __main__ - Step 110 Global step 110 Train loss 1.20 on epoch=7
06/05/2022 20:56:30 - INFO - __main__ - Step 120 Global step 120 Train loss 1.12 on epoch=8
06/05/2022 20:56:33 - INFO - __main__ - Step 130 Global step 130 Train loss 1.00 on epoch=9
06/05/2022 20:56:35 - INFO - __main__ - Step 140 Global step 140 Train loss 0.84 on epoch=9
06/05/2022 20:56:38 - INFO - __main__ - Step 150 Global step 150 Train loss 0.83 on epoch=10
06/05/2022 20:56:45 - INFO - __main__ - Global step 150 Train loss 1.00 Classification-F1 0.34804501395013726 on epoch=10
06/05/2022 20:56:45 - INFO - __main__ - Saving model with best Classification-F1: 0.22944599536054583 -> 0.34804501395013726 on epoch=10, global_step=150
06/05/2022 20:56:48 - INFO - __main__ - Step 160 Global step 160 Train loss 0.85 on epoch=11
06/05/2022 20:56:51 - INFO - __main__ - Step 170 Global step 170 Train loss 0.68 on epoch=12
06/05/2022 20:56:54 - INFO - __main__ - Step 180 Global step 180 Train loss 0.74 on epoch=12
06/05/2022 20:56:56 - INFO - __main__ - Step 190 Global step 190 Train loss 0.63 on epoch=13
06/05/2022 20:56:59 - INFO - __main__ - Step 200 Global step 200 Train loss 0.71 on epoch=14
06/05/2022 20:57:06 - INFO - __main__ - Global step 200 Train loss 0.72 Classification-F1 0.5540772656075112 on epoch=14
06/05/2022 20:57:06 - INFO - __main__ - Saving model with best Classification-F1: 0.34804501395013726 -> 0.5540772656075112 on epoch=14, global_step=200
06/05/2022 20:57:09 - INFO - __main__ - Step 210 Global step 210 Train loss 0.53 on epoch=14
06/05/2022 20:57:12 - INFO - __main__ - Step 220 Global step 220 Train loss 0.49 on epoch=15
06/05/2022 20:57:14 - INFO - __main__ - Step 230 Global step 230 Train loss 0.55 on epoch=16
06/05/2022 20:57:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.62 on epoch=17
06/05/2022 20:57:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=17
06/05/2022 20:57:27 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.6969617908046226 on epoch=17
06/05/2022 20:57:27 - INFO - __main__ - Saving model with best Classification-F1: 0.5540772656075112 -> 0.6969617908046226 on epoch=17, global_step=250
06/05/2022 20:57:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.51 on epoch=18
06/05/2022 20:57:32 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=19
06/05/2022 20:57:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=19
06/05/2022 20:57:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.47 on epoch=20
06/05/2022 20:57:41 - INFO - __main__ - Step 300 Global step 300 Train loss 0.40 on epoch=21
06/05/2022 20:57:48 - INFO - __main__ - Global step 300 Train loss 0.47 Classification-F1 0.7001820557095252 on epoch=21
06/05/2022 20:57:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6969617908046226 -> 0.7001820557095252 on epoch=21, global_step=300
06/05/2022 20:57:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.45 on epoch=22
06/05/2022 20:57:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=22
06/05/2022 20:57:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.44 on epoch=23
06/05/2022 20:57:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=24
06/05/2022 20:58:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=24
06/05/2022 20:58:08 - INFO - __main__ - Global step 350 Train loss 0.39 Classification-F1 0.8006284133281171 on epoch=24
06/05/2022 20:58:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7001820557095252 -> 0.8006284133281171 on epoch=24, global_step=350
06/05/2022 20:58:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.37 on epoch=25
06/05/2022 20:58:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.40 on epoch=26
06/05/2022 20:58:17 - INFO - __main__ - Step 380 Global step 380 Train loss 0.39 on epoch=27
06/05/2022 20:58:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=27
06/05/2022 20:58:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=28
06/05/2022 20:58:29 - INFO - __main__ - Global step 400 Train loss 0.33 Classification-F1 0.8228769212812092 on epoch=28
06/05/2022 20:58:29 - INFO - __main__ - Saving model with best Classification-F1: 0.8006284133281171 -> 0.8228769212812092 on epoch=28, global_step=400
06/05/2022 20:58:32 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=29
06/05/2022 20:58:35 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=29
06/05/2022 20:58:37 - INFO - __main__ - Step 430 Global step 430 Train loss 0.32 on epoch=30
06/05/2022 20:58:40 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=31
06/05/2022 20:58:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=32
06/05/2022 20:58:50 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.7111369846239516 on epoch=32
06/05/2022 20:58:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=32
06/05/2022 20:58:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=33
06/05/2022 20:58:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.34 on epoch=34
06/05/2022 20:59:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.26 on epoch=34
06/05/2022 20:59:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=35
06/05/2022 20:59:10 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.6856208435767509 on epoch=35
06/05/2022 20:59:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=36
06/05/2022 20:59:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=37
06/05/2022 20:59:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=37
06/05/2022 20:59:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=38
06/05/2022 20:59:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=39
06/05/2022 20:59:31 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.77159476503092 on epoch=39
06/05/2022 20:59:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=39
06/05/2022 20:59:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=40
06/05/2022 20:59:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=41
06/05/2022 20:59:42 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=42
06/05/2022 20:59:44 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=42
06/05/2022 20:59:51 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.7283879963657283 on epoch=42
06/05/2022 20:59:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=43
06/05/2022 20:59:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=44
06/05/2022 20:59:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=44
06/05/2022 21:00:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=45
06/05/2022 21:00:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=46
06/05/2022 21:00:12 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.6492112926180875 on epoch=46
06/05/2022 21:00:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=47
06/05/2022 21:00:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=47
06/05/2022 21:00:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=48
06/05/2022 21:00:22 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=49
06/05/2022 21:00:25 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=49
06/05/2022 21:00:32 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.7241738970176561 on epoch=49
06/05/2022 21:00:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=50
06/05/2022 21:00:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=51
06/05/2022 21:00:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=52
06/05/2022 21:00:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=52
06/05/2022 21:00:45 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=53
06/05/2022 21:00:52 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.6945624945427286 on epoch=53
06/05/2022 21:00:55 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=54
06/05/2022 21:00:57 - INFO - __main__ - Step 770 Global step 770 Train loss 0.09 on epoch=54
06/05/2022 21:01:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=55
06/05/2022 21:01:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=56
06/05/2022 21:01:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=57
06/05/2022 21:01:12 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.755679915892889 on epoch=57
06/05/2022 21:01:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=57
06/05/2022 21:01:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=58
06/05/2022 21:01:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=59
06/05/2022 21:01:23 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=59
06/05/2022 21:01:26 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=60
06/05/2022 21:01:32 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.7990780864520783 on epoch=60
06/05/2022 21:01:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=61
06/05/2022 21:01:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=62
06/05/2022 21:01:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=62
06/05/2022 21:01:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=63
06/05/2022 21:01:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=64
06/05/2022 21:01:52 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.8855351440674021 on epoch=64
06/05/2022 21:01:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8228769212812092 -> 0.8855351440674021 on epoch=64, global_step=900
06/05/2022 21:01:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=64
06/05/2022 21:01:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=65
06/05/2022 21:02:01 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=66
06/05/2022 21:02:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=67
06/05/2022 21:02:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=67
06/05/2022 21:02:12 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.8186479036262599 on epoch=67
06/05/2022 21:02:15 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=68
06/05/2022 21:02:18 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
06/05/2022 21:02:21 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=69
06/05/2022 21:02:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=70
06/05/2022 21:02:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=71
06/05/2022 21:02:33 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.7644454951604187 on epoch=71
06/05/2022 21:02:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=72
06/05/2022 21:02:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
06/05/2022 21:02:41 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=73
06/05/2022 21:02:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=74
06/05/2022 21:02:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
06/05/2022 21:02:52 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.7591592582939862 on epoch=74
06/05/2022 21:02:55 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=75
06/05/2022 21:02:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
06/05/2022 21:03:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
06/05/2022 21:03:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=77
06/05/2022 21:03:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=78
06/05/2022 21:03:12 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.7829615893278131 on epoch=78
06/05/2022 21:03:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=79
06/05/2022 21:03:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
06/05/2022 21:03:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
06/05/2022 21:03:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
06/05/2022 21:03:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/05/2022 21:03:32 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.7513834488427077 on epoch=82
06/05/2022 21:03:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=82
06/05/2022 21:03:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=83
06/05/2022 21:03:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/05/2022 21:03:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/05/2022 21:03:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
06/05/2022 21:03:52 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.7381570288591163 on epoch=85
06/05/2022 21:03:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=86
06/05/2022 21:03:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=87
06/05/2022 21:04:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=87
06/05/2022 21:04:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/05/2022 21:04:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
06/05/2022 21:04:12 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7765004416989063 on epoch=89
06/05/2022 21:04:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
06/05/2022 21:04:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
06/05/2022 21:04:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
06/05/2022 21:04:22 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/05/2022 21:04:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=92
06/05/2022 21:04:31 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7824284974274294 on epoch=92
06/05/2022 21:04:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
06/05/2022 21:04:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
06/05/2022 21:04:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
06/05/2022 21:04:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
06/05/2022 21:04:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
06/05/2022 21:04:52 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.851259990799839 on epoch=96
06/05/2022 21:04:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=97
06/05/2022 21:04:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
06/05/2022 21:05:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/05/2022 21:05:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=99
06/05/2022 21:05:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
06/05/2022 21:05:11 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6968968220101746 on epoch=99
06/05/2022 21:05:14 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
06/05/2022 21:05:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
06/05/2022 21:05:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
06/05/2022 21:05:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
06/05/2022 21:05:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/05/2022 21:05:31 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.8469589155310219 on epoch=103
06/05/2022 21:05:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
06/05/2022 21:05:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
06/05/2022 21:05:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
06/05/2022 21:05:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/05/2022 21:05:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
06/05/2022 21:05:51 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.7417911670218155 on epoch=107
06/05/2022 21:05:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
06/05/2022 21:05:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/05/2022 21:06:00 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
06/05/2022 21:06:02 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
06/05/2022 21:06:05 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
06/05/2022 21:06:11 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.6723016603270203 on epoch=110
06/05/2022 21:06:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/05/2022 21:06:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/05/2022 21:06:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
06/05/2022 21:06:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/05/2022 21:06:25 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/05/2022 21:06:31 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.6865610654273867 on epoch=114
06/05/2022 21:06:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/05/2022 21:06:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/05/2022 21:06:39 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/05/2022 21:06:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/05/2022 21:06:45 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/05/2022 21:06:51 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.890439289748326 on epoch=117
06/05/2022 21:06:51 - INFO - __main__ - Saving model with best Classification-F1: 0.8855351440674021 -> 0.890439289748326 on epoch=117, global_step=1650
06/05/2022 21:06:53 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/05/2022 21:06:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
06/05/2022 21:06:59 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/05/2022 21:07:02 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/05/2022 21:07:04 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/05/2022 21:07:11 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8530195215916279 on epoch=121
06/05/2022 21:07:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/05/2022 21:07:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/05/2022 21:07:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/05/2022 21:07:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/05/2022 21:07:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/05/2022 21:07:31 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.9060075613823242 on epoch=124
06/05/2022 21:07:31 - INFO - __main__ - Saving model with best Classification-F1: 0.890439289748326 -> 0.9060075613823242 on epoch=124, global_step=1750
06/05/2022 21:07:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/05/2022 21:07:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/05/2022 21:07:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/05/2022 21:07:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/05/2022 21:07:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/05/2022 21:07:51 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.901852394916911 on epoch=128
06/05/2022 21:07:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
06/05/2022 21:07:56 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/05/2022 21:07:59 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/05/2022 21:08:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/05/2022 21:08:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/05/2022 21:08:10 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.8934245887993517 on epoch=132
06/05/2022 21:08:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/05/2022 21:08:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/05/2022 21:08:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/05/2022 21:08:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/05/2022 21:08:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/05/2022 21:08:30 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9683560915517992 on epoch=135
06/05/2022 21:08:30 - INFO - __main__ - Saving model with best Classification-F1: 0.9060075613823242 -> 0.9683560915517992 on epoch=135, global_step=1900
06/05/2022 21:08:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/05/2022 21:08:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/05/2022 21:08:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
06/05/2022 21:08:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/05/2022 21:08:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/05/2022 21:08:51 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9640892354009053 on epoch=139
06/05/2022 21:08:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/05/2022 21:08:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/05/2022 21:08:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/05/2022 21:09:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/05/2022 21:09:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=142
06/05/2022 21:09:11 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9774812197606314 on epoch=142
06/05/2022 21:09:11 - INFO - __main__ - Saving model with best Classification-F1: 0.9683560915517992 -> 0.9774812197606314 on epoch=142, global_step=2000
06/05/2022 21:09:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/05/2022 21:09:16 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/05/2022 21:09:19 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/05/2022 21:09:22 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/05/2022 21:09:24 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/05/2022 21:09:30 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9101726946888237 on epoch=146
06/05/2022 21:09:33 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
06/05/2022 21:09:36 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/05/2022 21:09:39 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/05/2022 21:09:41 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/05/2022 21:09:44 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=149
06/05/2022 21:09:51 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.906006028022157 on epoch=149
06/05/2022 21:09:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/05/2022 21:09:56 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/05/2022 21:09:59 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/05/2022 21:10:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/05/2022 21:10:04 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/05/2022 21:10:11 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9596205857709652 on epoch=153
06/05/2022 21:10:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/05/2022 21:10:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/05/2022 21:10:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/05/2022 21:10:22 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/05/2022 21:10:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/05/2022 21:10:30 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.968348133823253 on epoch=157
06/05/2022 21:10:33 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/05/2022 21:10:36 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
06/05/2022 21:10:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/05/2022 21:10:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/05/2022 21:10:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/05/2022 21:10:51 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9143319341421808 on epoch=160
06/05/2022 21:10:53 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/05/2022 21:10:56 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/05/2022 21:10:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=162
06/05/2022 21:11:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/05/2022 21:11:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/05/2022 21:11:10 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9018685388673283 on epoch=164
06/05/2022 21:11:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/05/2022 21:11:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/05/2022 21:11:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/05/2022 21:11:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/05/2022 21:11:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/05/2022 21:11:31 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9732795390883625 on epoch=167
06/05/2022 21:11:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/05/2022 21:11:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/05/2022 21:11:39 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/05/2022 21:11:42 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/05/2022 21:11:44 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/05/2022 21:11:50 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8512638092260365 on epoch=171
06/05/2022 21:11:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/05/2022 21:11:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/05/2022 21:11:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/05/2022 21:12:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/05/2022 21:12:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/05/2022 21:12:10 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9728545963840082 on epoch=174
06/05/2022 21:12:13 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/05/2022 21:12:16 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/05/2022 21:12:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/05/2022 21:12:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=177
06/05/2022 21:12:24 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/05/2022 21:12:30 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9020341665502957 on epoch=178
06/05/2022 21:12:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/05/2022 21:12:36 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/05/2022 21:12:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/05/2022 21:12:41 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/05/2022 21:12:44 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/05/2022 21:12:50 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9732935036184561 on epoch=182
06/05/2022 21:12:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/05/2022 21:12:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/05/2022 21:12:58 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
06/05/2022 21:13:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/05/2022 21:13:04 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/05/2022 21:13:10 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9103086366511413 on epoch=185
06/05/2022 21:13:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/05/2022 21:13:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/05/2022 21:13:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/05/2022 21:13:21 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/05/2022 21:13:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/05/2022 21:13:29 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9728167834531932 on epoch=189
06/05/2022 21:13:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/05/2022 21:13:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/05/2022 21:13:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/05/2022 21:13:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/05/2022 21:13:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/05/2022 21:13:49 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8953550687137024 on epoch=192
06/05/2022 21:13:52 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/05/2022 21:13:55 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/05/2022 21:13:58 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/05/2022 21:14:00 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/05/2022 21:14:03 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/05/2022 21:14:09 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9730248917748917 on epoch=196
06/05/2022 21:14:12 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
06/05/2022 21:14:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/05/2022 21:14:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/05/2022 21:14:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/05/2022 21:14:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/05/2022 21:14:29 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9774891774891774 on epoch=199
06/05/2022 21:14:29 - INFO - __main__ - Saving model with best Classification-F1: 0.9774812197606314 -> 0.9774891774891774 on epoch=199, global_step=2800
06/05/2022 21:14:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
06/05/2022 21:14:35 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/05/2022 21:14:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/05/2022 21:14:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/05/2022 21:14:43 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/05/2022 21:14:50 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9730205278592374 on epoch=203
06/05/2022 21:14:52 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/05/2022 21:14:55 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/05/2022 21:14:58 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/05/2022 21:15:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/05/2022 21:15:03 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/05/2022 21:15:10 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9774891774891774 on epoch=207
06/05/2022 21:15:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/05/2022 21:15:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/05/2022 21:15:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/05/2022 21:15:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/05/2022 21:15:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/05/2022 21:15:29 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9774891774891774 on epoch=210
06/05/2022 21:15:32 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/05/2022 21:15:35 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/05/2022 21:15:38 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/05/2022 21:15:40 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/05/2022 21:15:43 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/05/2022 21:15:45 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 21:15:45 - INFO - __main__ - Printing 3 examples
06/05/2022 21:15:45 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/05/2022 21:15:45 - INFO - __main__ - ['Animal']
06/05/2022 21:15:45 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/05/2022 21:15:45 - INFO - __main__ - ['Animal']
06/05/2022 21:15:45 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/05/2022 21:15:45 - INFO - __main__ - ['Animal']
06/05/2022 21:15:45 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:15:45 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:15:45 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 21:15:45 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 21:15:45 - INFO - __main__ - Printing 3 examples
06/05/2022 21:15:45 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/05/2022 21:15:45 - INFO - __main__ - ['Animal']
06/05/2022 21:15:45 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/05/2022 21:15:45 - INFO - __main__ - ['Animal']
06/05/2022 21:15:45 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/05/2022 21:15:45 - INFO - __main__ - ['Animal']
06/05/2022 21:15:45 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:15:45 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:15:45 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 21:15:49 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9730205278592374 on epoch=214
06/05/2022 21:15:49 - INFO - __main__ - save last model!
06/05/2022 21:15:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 21:15:49 - INFO - __main__ - Start tokenizing ... 3500 instances
06/05/2022 21:15:49 - INFO - __main__ - Printing 3 examples
06/05/2022 21:15:49 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/05/2022 21:15:49 - INFO - __main__ - ['Animal']
06/05/2022 21:15:49 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/05/2022 21:15:49 - INFO - __main__ - ['Animal']
06/05/2022 21:15:49 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/05/2022 21:15:49 - INFO - __main__ - ['Village']
06/05/2022 21:15:49 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:15:51 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:15:55 - INFO - __main__ - Loaded 3500 examples from test data
06/05/2022 21:16:01 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 21:16:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 21:16:02 - INFO - __main__ - Starting training!
06/05/2022 21:18:03 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
06/05/2022 21:18:03 - INFO - __main__ - Classification-F1 on test data: 0.8071
06/05/2022 21:18:03 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.9774891774891774, test_performance=0.807106023829734
06/05/2022 21:18:03 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
06/05/2022 21:18:04 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 21:18:04 - INFO - __main__ - Printing 3 examples
06/05/2022 21:18:04 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/05/2022 21:18:04 - INFO - __main__ - ['Animal']
06/05/2022 21:18:04 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/05/2022 21:18:04 - INFO - __main__ - ['Animal']
06/05/2022 21:18:04 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/05/2022 21:18:04 - INFO - __main__ - ['Animal']
06/05/2022 21:18:04 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:18:04 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:18:04 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 21:18:04 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 21:18:04 - INFO - __main__ - Printing 3 examples
06/05/2022 21:18:04 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/05/2022 21:18:04 - INFO - __main__ - ['Animal']
06/05/2022 21:18:04 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/05/2022 21:18:04 - INFO - __main__ - ['Animal']
06/05/2022 21:18:04 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/05/2022 21:18:04 - INFO - __main__ - ['Animal']
06/05/2022 21:18:04 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:18:04 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:18:05 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 21:18:20 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 21:18:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 21:18:21 - INFO - __main__ - Starting training!
06/05/2022 21:18:25 - INFO - __main__ - Step 10 Global step 10 Train loss 5.69 on epoch=0
06/05/2022 21:18:27 - INFO - __main__ - Step 20 Global step 20 Train loss 4.76 on epoch=1
06/05/2022 21:18:30 - INFO - __main__ - Step 30 Global step 30 Train loss 4.21 on epoch=2
06/05/2022 21:18:33 - INFO - __main__ - Step 40 Global step 40 Train loss 3.47 on epoch=2
06/05/2022 21:18:35 - INFO - __main__ - Step 50 Global step 50 Train loss 3.25 on epoch=3
06/05/2022 21:18:42 - INFO - __main__ - Global step 50 Train loss 4.27 Classification-F1 0.022574660362678797 on epoch=3
06/05/2022 21:18:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.022574660362678797 on epoch=3, global_step=50
06/05/2022 21:18:45 - INFO - __main__ - Step 60 Global step 60 Train loss 2.94 on epoch=4
06/05/2022 21:18:47 - INFO - __main__ - Step 70 Global step 70 Train loss 2.71 on epoch=4
06/05/2022 21:18:50 - INFO - __main__ - Step 80 Global step 80 Train loss 2.39 on epoch=5
06/05/2022 21:18:53 - INFO - __main__ - Step 90 Global step 90 Train loss 2.20 on epoch=6
06/05/2022 21:18:55 - INFO - __main__ - Step 100 Global step 100 Train loss 2.02 on epoch=7
06/05/2022 21:19:02 - INFO - __main__ - Global step 100 Train loss 2.45 Classification-F1 0.08201085431610794 on epoch=7
06/05/2022 21:19:02 - INFO - __main__ - Saving model with best Classification-F1: 0.022574660362678797 -> 0.08201085431610794 on epoch=7, global_step=100
06/05/2022 21:19:04 - INFO - __main__ - Step 110 Global step 110 Train loss 1.77 on epoch=7
06/05/2022 21:19:07 - INFO - __main__ - Step 120 Global step 120 Train loss 1.66 on epoch=8
06/05/2022 21:19:10 - INFO - __main__ - Step 130 Global step 130 Train loss 1.59 on epoch=9
06/05/2022 21:19:12 - INFO - __main__ - Step 140 Global step 140 Train loss 1.28 on epoch=9
06/05/2022 21:19:15 - INFO - __main__ - Step 150 Global step 150 Train loss 1.29 on epoch=10
06/05/2022 21:19:21 - INFO - __main__ - Global step 150 Train loss 1.52 Classification-F1 0.19724590649663645 on epoch=10
06/05/2022 21:19:21 - INFO - __main__ - Saving model with best Classification-F1: 0.08201085431610794 -> 0.19724590649663645 on epoch=10, global_step=150
06/05/2022 21:19:24 - INFO - __main__ - Step 160 Global step 160 Train loss 1.13 on epoch=11
06/05/2022 21:19:26 - INFO - __main__ - Step 170 Global step 170 Train loss 1.18 on epoch=12
06/05/2022 21:19:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.97 on epoch=12
06/05/2022 21:19:32 - INFO - __main__ - Step 190 Global step 190 Train loss 1.02 on epoch=13
06/05/2022 21:19:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.93 on epoch=14
06/05/2022 21:19:42 - INFO - __main__ - Global step 200 Train loss 1.05 Classification-F1 0.32037447515601725 on epoch=14
06/05/2022 21:19:42 - INFO - __main__ - Saving model with best Classification-F1: 0.19724590649663645 -> 0.32037447515601725 on epoch=14, global_step=200
06/05/2022 21:19:44 - INFO - __main__ - Step 210 Global step 210 Train loss 0.89 on epoch=14
06/05/2022 21:19:47 - INFO - __main__ - Step 220 Global step 220 Train loss 0.87 on epoch=15
06/05/2022 21:19:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.77 on epoch=16
06/05/2022 21:19:53 - INFO - __main__ - Step 240 Global step 240 Train loss 0.80 on epoch=17
06/05/2022 21:19:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.73 on epoch=17
06/05/2022 21:20:03 - INFO - __main__ - Global step 250 Train loss 0.81 Classification-F1 0.31035046666745547 on epoch=17
06/05/2022 21:20:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.62 on epoch=18
06/05/2022 21:20:08 - INFO - __main__ - Step 270 Global step 270 Train loss 0.71 on epoch=19
06/05/2022 21:20:11 - INFO - __main__ - Step 280 Global step 280 Train loss 0.66 on epoch=19
06/05/2022 21:20:14 - INFO - __main__ - Step 290 Global step 290 Train loss 0.67 on epoch=20
06/05/2022 21:20:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.63 on epoch=21
06/05/2022 21:20:24 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.6721603454422596 on epoch=21
06/05/2022 21:20:24 - INFO - __main__ - Saving model with best Classification-F1: 0.32037447515601725 -> 0.6721603454422596 on epoch=21, global_step=300
06/05/2022 21:20:27 - INFO - __main__ - Step 310 Global step 310 Train loss 0.59 on epoch=22
06/05/2022 21:20:29 - INFO - __main__ - Step 320 Global step 320 Train loss 0.60 on epoch=22
06/05/2022 21:20:32 - INFO - __main__ - Step 330 Global step 330 Train loss 0.65 on epoch=23
06/05/2022 21:20:35 - INFO - __main__ - Step 340 Global step 340 Train loss 0.60 on epoch=24
06/05/2022 21:20:37 - INFO - __main__ - Step 350 Global step 350 Train loss 0.43 on epoch=24
06/05/2022 21:20:45 - INFO - __main__ - Global step 350 Train loss 0.57 Classification-F1 0.5439355918935427 on epoch=24
06/05/2022 21:20:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.46 on epoch=25
06/05/2022 21:20:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.45 on epoch=26
06/05/2022 21:20:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=27
06/05/2022 21:20:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.51 on epoch=27
06/05/2022 21:20:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.51 on epoch=28
06/05/2022 21:21:06 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.7356796653167621 on epoch=28
06/05/2022 21:21:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6721603454422596 -> 0.7356796653167621 on epoch=28, global_step=400
06/05/2022 21:21:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.50 on epoch=29
06/05/2022 21:21:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.49 on epoch=29
06/05/2022 21:21:14 - INFO - __main__ - Step 430 Global step 430 Train loss 0.49 on epoch=30
06/05/2022 21:21:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.45 on epoch=31
06/05/2022 21:21:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.47 on epoch=32
06/05/2022 21:21:27 - INFO - __main__ - Global step 450 Train loss 0.48 Classification-F1 0.6898702071824073 on epoch=32
06/05/2022 21:21:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.38 on epoch=32
06/05/2022 21:21:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=33
06/05/2022 21:21:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.47 on epoch=34
06/05/2022 21:21:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.40 on epoch=34
06/05/2022 21:21:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.42 on epoch=35
06/05/2022 21:21:48 - INFO - __main__ - Global step 500 Train loss 0.40 Classification-F1 0.7475476223628842 on epoch=35
06/05/2022 21:21:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7356796653167621 -> 0.7475476223628842 on epoch=35, global_step=500
06/05/2022 21:21:50 - INFO - __main__ - Step 510 Global step 510 Train loss 0.29 on epoch=36
06/05/2022 21:21:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.42 on epoch=37
06/05/2022 21:21:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.34 on epoch=37
06/05/2022 21:21:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=38
06/05/2022 21:22:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=39
06/05/2022 21:22:08 - INFO - __main__ - Global step 550 Train loss 0.35 Classification-F1 0.7253874997872285 on epoch=39
06/05/2022 21:22:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.33 on epoch=39
06/05/2022 21:22:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.37 on epoch=40
06/05/2022 21:22:16 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=41
06/05/2022 21:22:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=42
06/05/2022 21:22:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.33 on epoch=42
06/05/2022 21:22:29 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.6586771788477388 on epoch=42
06/05/2022 21:22:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.34 on epoch=43
06/05/2022 21:22:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.38 on epoch=44
06/05/2022 21:22:37 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=44
06/05/2022 21:22:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=45
06/05/2022 21:22:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=46
06/05/2022 21:22:49 - INFO - __main__ - Global step 650 Train loss 0.32 Classification-F1 0.6245608600455399 on epoch=46
06/05/2022 21:22:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.29 on epoch=47
06/05/2022 21:22:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.30 on epoch=47
06/05/2022 21:22:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.31 on epoch=48
06/05/2022 21:23:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.30 on epoch=49
06/05/2022 21:23:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.27 on epoch=49
06/05/2022 21:23:09 - INFO - __main__ - Global step 700 Train loss 0.30 Classification-F1 0.5494020008996967 on epoch=49
06/05/2022 21:23:12 - INFO - __main__ - Step 710 Global step 710 Train loss 0.33 on epoch=50
06/05/2022 21:23:14 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=51
06/05/2022 21:23:17 - INFO - __main__ - Step 730 Global step 730 Train loss 0.26 on epoch=52
06/05/2022 21:23:20 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=52
06/05/2022 21:23:23 - INFO - __main__ - Step 750 Global step 750 Train loss 0.24 on epoch=53
06/05/2022 21:23:29 - INFO - __main__ - Global step 750 Train loss 0.25 Classification-F1 0.518827022123986 on epoch=53
06/05/2022 21:23:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.25 on epoch=54
06/05/2022 21:23:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=54
06/05/2022 21:23:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=55
06/05/2022 21:23:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=56
06/05/2022 21:23:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=57
06/05/2022 21:23:50 - INFO - __main__ - Global step 800 Train loss 0.24 Classification-F1 0.5605635076799349 on epoch=57
06/05/2022 21:23:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=57
06/05/2022 21:23:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=58
06/05/2022 21:23:58 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=59
06/05/2022 21:24:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=59
06/05/2022 21:24:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=60
06/05/2022 21:24:11 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.6071095322293141 on epoch=60
06/05/2022 21:24:13 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=61
06/05/2022 21:24:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.22 on epoch=62
06/05/2022 21:24:19 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=62
06/05/2022 21:24:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=63
06/05/2022 21:24:24 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=64
06/05/2022 21:24:31 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.5785069008052879 on epoch=64
06/05/2022 21:24:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=64
06/05/2022 21:24:36 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=65
06/05/2022 21:24:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=66
06/05/2022 21:24:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.24 on epoch=67
06/05/2022 21:24:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=67
06/05/2022 21:24:51 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.5137972030567338 on epoch=67
06/05/2022 21:24:54 - INFO - __main__ - Step 960 Global step 960 Train loss 0.21 on epoch=68
06/05/2022 21:24:57 - INFO - __main__ - Step 970 Global step 970 Train loss 0.27 on epoch=69
06/05/2022 21:24:59 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=69
06/05/2022 21:25:02 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=70
06/05/2022 21:25:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=71
06/05/2022 21:25:12 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.6448423909880268 on epoch=71
06/05/2022 21:25:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=72
06/05/2022 21:25:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.19 on epoch=72
06/05/2022 21:25:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=73
06/05/2022 21:25:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.22 on epoch=74
06/05/2022 21:25:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=74
06/05/2022 21:25:32 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.6501167619095258 on epoch=74
06/05/2022 21:25:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=75
06/05/2022 21:25:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=76
06/05/2022 21:25:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=77
06/05/2022 21:25:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=77
06/05/2022 21:25:45 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
06/05/2022 21:25:52 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.7324281217445104 on epoch=78
06/05/2022 21:25:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=79
06/05/2022 21:25:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
06/05/2022 21:26:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=80
06/05/2022 21:26:03 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
06/05/2022 21:26:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=82
06/05/2022 21:26:12 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.719862247961943 on epoch=82
06/05/2022 21:26:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=82
06/05/2022 21:26:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=83
06/05/2022 21:26:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=84
06/05/2022 21:26:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
06/05/2022 21:26:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
06/05/2022 21:26:33 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.6993020647232672 on epoch=85
06/05/2022 21:26:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=86
06/05/2022 21:26:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=87
06/05/2022 21:26:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=87
06/05/2022 21:26:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=88
06/05/2022 21:26:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=89
06/05/2022 21:26:53 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.7576228656636625 on epoch=89
06/05/2022 21:26:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7475476223628842 -> 0.7576228656636625 on epoch=89, global_step=1250
06/05/2022 21:26:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=89
06/05/2022 21:26:59 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=90
06/05/2022 21:27:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=91
06/05/2022 21:27:04 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=92
06/05/2022 21:27:07 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=92
06/05/2022 21:27:14 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.8351903679866122 on epoch=92
06/05/2022 21:27:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7576228656636625 -> 0.8351903679866122 on epoch=92, global_step=1300
06/05/2022 21:27:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/05/2022 21:27:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=94
06/05/2022 21:27:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=94
06/05/2022 21:27:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=95
06/05/2022 21:27:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/05/2022 21:27:35 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.9018122879650394 on epoch=96
06/05/2022 21:27:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8351903679866122 -> 0.9018122879650394 on epoch=96, global_step=1350
06/05/2022 21:27:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
06/05/2022 21:27:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
06/05/2022 21:27:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
06/05/2022 21:27:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=99
06/05/2022 21:27:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/05/2022 21:27:55 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.8977874571138327 on epoch=99
06/05/2022 21:27:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
06/05/2022 21:28:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
06/05/2022 21:28:02 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=102
06/05/2022 21:28:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=102
06/05/2022 21:28:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/05/2022 21:28:14 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.9642192800874015 on epoch=103
06/05/2022 21:28:14 - INFO - __main__ - Saving model with best Classification-F1: 0.9018122879650394 -> 0.9642192800874015 on epoch=103, global_step=1450
06/05/2022 21:28:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=104
06/05/2022 21:28:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=104
06/05/2022 21:28:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
06/05/2022 21:28:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
06/05/2022 21:28:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=107
06/05/2022 21:28:34 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.8981297044722093 on epoch=107
06/05/2022 21:28:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.13 on epoch=107
06/05/2022 21:28:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/05/2022 21:28:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=109
06/05/2022 21:28:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
06/05/2022 21:28:48 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/05/2022 21:28:54 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.8954894773158532 on epoch=110
06/05/2022 21:28:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
06/05/2022 21:28:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=112
06/05/2022 21:29:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
06/05/2022 21:29:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
06/05/2022 21:29:07 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=114
06/05/2022 21:29:14 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.8996717171717172 on epoch=114
06/05/2022 21:29:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/05/2022 21:29:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=115
06/05/2022 21:29:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
06/05/2022 21:29:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=117
06/05/2022 21:29:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=117
06/05/2022 21:29:34 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.9060019550342131 on epoch=117
06/05/2022 21:29:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
06/05/2022 21:29:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/05/2022 21:29:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/05/2022 21:29:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
06/05/2022 21:29:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=121
06/05/2022 21:29:55 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.9686712441574868 on epoch=121
06/05/2022 21:29:55 - INFO - __main__ - Saving model with best Classification-F1: 0.9642192800874015 -> 0.9686712441574868 on epoch=121, global_step=1700
06/05/2022 21:29:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
06/05/2022 21:30:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
06/05/2022 21:30:03 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/05/2022 21:30:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=124
06/05/2022 21:30:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/05/2022 21:30:15 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.9643299181842825 on epoch=124
06/05/2022 21:30:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=125
06/05/2022 21:30:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/05/2022 21:30:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/05/2022 21:30:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/05/2022 21:30:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/05/2022 21:30:35 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.9685395565850973 on epoch=128
06/05/2022 21:30:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=129
06/05/2022 21:30:41 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
06/05/2022 21:30:43 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/05/2022 21:30:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/05/2022 21:30:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/05/2022 21:30:56 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.906006028022157 on epoch=132
06/05/2022 21:30:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
06/05/2022 21:31:01 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
06/05/2022 21:31:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=134
06/05/2022 21:31:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/05/2022 21:31:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=135
06/05/2022 21:31:16 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.9774891774891774 on epoch=135
06/05/2022 21:31:16 - INFO - __main__ - Saving model with best Classification-F1: 0.9686712441574868 -> 0.9774891774891774 on epoch=135, global_step=1900
06/05/2022 21:31:18 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
06/05/2022 21:31:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/05/2022 21:31:24 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/05/2022 21:31:26 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/05/2022 21:31:29 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/05/2022 21:31:36 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9774812197606314 on epoch=139
06/05/2022 21:31:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
06/05/2022 21:31:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
06/05/2022 21:31:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/05/2022 21:31:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/05/2022 21:31:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/05/2022 21:31:56 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.9774891774891774 on epoch=142
06/05/2022 21:31:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/05/2022 21:32:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=144
06/05/2022 21:32:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/05/2022 21:32:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/05/2022 21:32:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/05/2022 21:32:16 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.9685395565850973 on epoch=146
06/05/2022 21:32:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
06/05/2022 21:32:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
06/05/2022 21:32:24 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=148
06/05/2022 21:32:27 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/05/2022 21:32:29 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/05/2022 21:32:36 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9594019007812111 on epoch=149
06/05/2022 21:32:39 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/05/2022 21:32:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
06/05/2022 21:32:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/05/2022 21:32:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=152
06/05/2022 21:32:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/05/2022 21:32:57 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9774812197606314 on epoch=153
06/05/2022 21:32:59 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/05/2022 21:33:02 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=154
06/05/2022 21:33:04 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/05/2022 21:33:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/05/2022 21:33:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/05/2022 21:33:16 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.9685395565850973 on epoch=157
06/05/2022 21:33:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/05/2022 21:33:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/05/2022 21:33:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/05/2022 21:33:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/05/2022 21:33:30 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/05/2022 21:33:36 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9774812197606314 on epoch=160
06/05/2022 21:33:39 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/05/2022 21:33:42 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.09 on epoch=162
06/05/2022 21:33:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=162
06/05/2022 21:33:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/05/2022 21:33:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/05/2022 21:33:56 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.973147851515973 on epoch=164
06/05/2022 21:33:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/05/2022 21:34:02 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/05/2022 21:34:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/05/2022 21:34:07 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/05/2022 21:34:10 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/05/2022 21:34:16 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9686835658016874 on epoch=167
06/05/2022 21:34:19 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/05/2022 21:34:22 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/05/2022 21:34:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/05/2022 21:34:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=170
06/05/2022 21:34:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
06/05/2022 21:34:36 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.9730205278592374 on epoch=171
06/05/2022 21:34:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
06/05/2022 21:34:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/05/2022 21:34:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/05/2022 21:34:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
06/05/2022 21:34:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/05/2022 21:34:56 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9730205278592374 on epoch=174
06/05/2022 21:34:59 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
06/05/2022 21:35:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/05/2022 21:35:04 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/05/2022 21:35:07 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/05/2022 21:35:09 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/05/2022 21:35:16 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9774891774891774 on epoch=178
06/05/2022 21:35:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/05/2022 21:35:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
06/05/2022 21:35:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=180
06/05/2022 21:35:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/05/2022 21:35:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/05/2022 21:35:36 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.9685562421449517 on epoch=182
06/05/2022 21:35:38 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/05/2022 21:35:41 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/05/2022 21:35:43 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/05/2022 21:35:46 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/05/2022 21:35:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/05/2022 21:35:55 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9684834152085345 on epoch=185
06/05/2022 21:35:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/05/2022 21:36:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
06/05/2022 21:36:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=187
06/05/2022 21:36:05 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/05/2022 21:36:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/05/2022 21:36:14 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.9730388563049853 on epoch=189
06/05/2022 21:36:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/05/2022 21:36:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/05/2022 21:36:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/05/2022 21:36:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/05/2022 21:36:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/05/2022 21:36:34 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9685395565850973 on epoch=192
06/05/2022 21:36:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.07 on epoch=193
06/05/2022 21:36:40 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/05/2022 21:36:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=194
06/05/2022 21:36:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/05/2022 21:36:48 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/05/2022 21:36:54 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.9730248917748917 on epoch=196
06/05/2022 21:36:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/05/2022 21:36:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/05/2022 21:37:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/05/2022 21:37:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/05/2022 21:37:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/05/2022 21:37:14 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9774891774891774 on epoch=199
06/05/2022 21:37:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/05/2022 21:37:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
06/05/2022 21:37:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/05/2022 21:37:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/05/2022 21:37:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/05/2022 21:37:34 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9774891774891774 on epoch=203
06/05/2022 21:37:36 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/05/2022 21:37:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/05/2022 21:37:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/05/2022 21:37:44 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/05/2022 21:37:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/05/2022 21:37:54 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9685395565850973 on epoch=207
06/05/2022 21:37:56 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/05/2022 21:37:59 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/05/2022 21:38:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/05/2022 21:38:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/05/2022 21:38:06 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/05/2022 21:38:12 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9730248917748917 on epoch=210
06/05/2022 21:38:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/05/2022 21:38:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/05/2022 21:38:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/05/2022 21:38:23 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/05/2022 21:38:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/05/2022 21:38:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 21:38:27 - INFO - __main__ - Printing 3 examples
06/05/2022 21:38:27 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/05/2022 21:38:27 - INFO - __main__ - ['Plant']
06/05/2022 21:38:27 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/05/2022 21:38:27 - INFO - __main__ - ['Plant']
06/05/2022 21:38:27 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/05/2022 21:38:27 - INFO - __main__ - ['Plant']
06/05/2022 21:38:27 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:38:27 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:38:27 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 21:38:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 21:38:27 - INFO - __main__ - Printing 3 examples
06/05/2022 21:38:27 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/05/2022 21:38:27 - INFO - __main__ - ['Plant']
06/05/2022 21:38:27 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/05/2022 21:38:27 - INFO - __main__ - ['Plant']
06/05/2022 21:38:27 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/05/2022 21:38:27 - INFO - __main__ - ['Plant']
06/05/2022 21:38:27 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:38:27 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:38:28 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 21:38:32 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9774812197606314 on epoch=214
06/05/2022 21:38:32 - INFO - __main__ - save last model!
06/05/2022 21:38:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 21:38:32 - INFO - __main__ - Start tokenizing ... 3500 instances
06/05/2022 21:38:32 - INFO - __main__ - Printing 3 examples
06/05/2022 21:38:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/05/2022 21:38:32 - INFO - __main__ - ['Animal']
06/05/2022 21:38:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/05/2022 21:38:32 - INFO - __main__ - ['Animal']
06/05/2022 21:38:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/05/2022 21:38:32 - INFO - __main__ - ['Village']
06/05/2022 21:38:32 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:38:33 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:38:37 - INFO - __main__ - Loaded 3500 examples from test data
06/05/2022 21:38:43 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 21:38:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 21:38:44 - INFO - __main__ - Starting training!
06/05/2022 21:40:49 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
06/05/2022 21:40:49 - INFO - __main__ - Classification-F1 on test data: 0.8066
06/05/2022 21:40:49 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.9774891774891774, test_performance=0.806605177244389
06/05/2022 21:40:49 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
06/05/2022 21:40:50 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 21:40:50 - INFO - __main__ - Printing 3 examples
06/05/2022 21:40:50 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/05/2022 21:40:50 - INFO - __main__ - ['Plant']
06/05/2022 21:40:50 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/05/2022 21:40:50 - INFO - __main__ - ['Plant']
06/05/2022 21:40:50 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/05/2022 21:40:50 - INFO - __main__ - ['Plant']
06/05/2022 21:40:50 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:40:50 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:40:51 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 21:40:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 21:40:51 - INFO - __main__ - Printing 3 examples
06/05/2022 21:40:51 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/05/2022 21:40:51 - INFO - __main__ - ['Plant']
06/05/2022 21:40:51 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/05/2022 21:40:51 - INFO - __main__ - ['Plant']
06/05/2022 21:40:51 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/05/2022 21:40:51 - INFO - __main__ - ['Plant']
06/05/2022 21:40:51 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:40:51 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:40:51 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 21:41:10 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 21:41:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 21:41:11 - INFO - __main__ - Starting training!
06/05/2022 21:41:14 - INFO - __main__ - Step 10 Global step 10 Train loss 5.10 on epoch=0
06/05/2022 21:41:17 - INFO - __main__ - Step 20 Global step 20 Train loss 3.60 on epoch=1
06/05/2022 21:41:20 - INFO - __main__ - Step 30 Global step 30 Train loss 2.80 on epoch=2
06/05/2022 21:41:22 - INFO - __main__ - Step 40 Global step 40 Train loss 2.25 on epoch=2
06/05/2022 21:41:25 - INFO - __main__ - Step 50 Global step 50 Train loss 1.76 on epoch=3
06/05/2022 21:41:31 - INFO - __main__ - Global step 50 Train loss 3.10 Classification-F1 0.1000764325748513 on epoch=3
06/05/2022 21:41:31 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1000764325748513 on epoch=3, global_step=50
06/05/2022 21:41:34 - INFO - __main__ - Step 60 Global step 60 Train loss 1.56 on epoch=4
06/05/2022 21:41:36 - INFO - __main__ - Step 70 Global step 70 Train loss 1.32 on epoch=4
06/05/2022 21:41:39 - INFO - __main__ - Step 80 Global step 80 Train loss 1.07 on epoch=5
06/05/2022 21:41:42 - INFO - __main__ - Step 90 Global step 90 Train loss 0.92 on epoch=6
06/05/2022 21:41:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.86 on epoch=7
06/05/2022 21:41:52 - INFO - __main__ - Global step 100 Train loss 1.15 Classification-F1 0.34754405908384195 on epoch=7
06/05/2022 21:41:52 - INFO - __main__ - Saving model with best Classification-F1: 0.1000764325748513 -> 0.34754405908384195 on epoch=7, global_step=100
06/05/2022 21:41:54 - INFO - __main__ - Step 110 Global step 110 Train loss 0.70 on epoch=7
06/05/2022 21:41:57 - INFO - __main__ - Step 120 Global step 120 Train loss 0.71 on epoch=8
06/05/2022 21:42:00 - INFO - __main__ - Step 130 Global step 130 Train loss 0.62 on epoch=9
06/05/2022 21:42:02 - INFO - __main__ - Step 140 Global step 140 Train loss 0.60 on epoch=9
06/05/2022 21:42:05 - INFO - __main__ - Step 150 Global step 150 Train loss 0.51 on epoch=10
06/05/2022 21:42:13 - INFO - __main__ - Global step 150 Train loss 0.63 Classification-F1 0.6527928352735963 on epoch=10
06/05/2022 21:42:13 - INFO - __main__ - Saving model with best Classification-F1: 0.34754405908384195 -> 0.6527928352735963 on epoch=10, global_step=150
06/05/2022 21:42:15 - INFO - __main__ - Step 160 Global step 160 Train loss 0.51 on epoch=11
06/05/2022 21:42:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.40 on epoch=12
06/05/2022 21:42:21 - INFO - __main__ - Step 180 Global step 180 Train loss 0.44 on epoch=12
06/05/2022 21:42:24 - INFO - __main__ - Step 190 Global step 190 Train loss 0.47 on epoch=13
06/05/2022 21:42:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.52 on epoch=14
06/05/2022 21:42:34 - INFO - __main__ - Global step 200 Train loss 0.47 Classification-F1 0.6063243251873894 on epoch=14
06/05/2022 21:42:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.44 on epoch=14
06/05/2022 21:42:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.36 on epoch=15
06/05/2022 21:42:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.37 on epoch=16
06/05/2022 21:42:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.37 on epoch=17
06/05/2022 21:42:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.34 on epoch=17
06/05/2022 21:42:55 - INFO - __main__ - Global step 250 Train loss 0.38 Classification-F1 0.819749994166012 on epoch=17
06/05/2022 21:42:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6527928352735963 -> 0.819749994166012 on epoch=17, global_step=250
06/05/2022 21:42:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.37 on epoch=18
06/05/2022 21:43:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.36 on epoch=19
06/05/2022 21:43:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.38 on epoch=19
06/05/2022 21:43:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.39 on epoch=20
06/05/2022 21:43:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=21
06/05/2022 21:43:16 - INFO - __main__ - Global step 300 Train loss 0.36 Classification-F1 0.7858335469355207 on epoch=21
06/05/2022 21:43:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=22
06/05/2022 21:43:22 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=22
06/05/2022 21:43:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.34 on epoch=23
06/05/2022 21:43:27 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=24
06/05/2022 21:43:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=24
06/05/2022 21:43:37 - INFO - __main__ - Global step 350 Train loss 0.28 Classification-F1 0.8616087611392995 on epoch=24
06/05/2022 21:43:37 - INFO - __main__ - Saving model with best Classification-F1: 0.819749994166012 -> 0.8616087611392995 on epoch=24, global_step=350
06/05/2022 21:43:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=25
06/05/2022 21:43:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=26
06/05/2022 21:43:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=27
06/05/2022 21:43:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.14 on epoch=27
06/05/2022 21:43:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.16 on epoch=28
06/05/2022 21:43:57 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.8129270212256399 on epoch=28
06/05/2022 21:44:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.25 on epoch=29
06/05/2022 21:44:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=29
06/05/2022 21:44:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.14 on epoch=30
06/05/2022 21:44:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=31
06/05/2022 21:44:11 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=32
06/05/2022 21:44:17 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.7555587988389141 on epoch=32
06/05/2022 21:44:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.16 on epoch=32
06/05/2022 21:44:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=33
06/05/2022 21:44:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.15 on epoch=34
06/05/2022 21:44:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=34
06/05/2022 21:44:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.16 on epoch=35
06/05/2022 21:44:37 - INFO - __main__ - Global step 500 Train loss 0.17 Classification-F1 0.7246634704038355 on epoch=35
06/05/2022 21:44:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=36
06/05/2022 21:44:43 - INFO - __main__ - Step 520 Global step 520 Train loss 0.16 on epoch=37
06/05/2022 21:44:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=37
06/05/2022 21:44:48 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=38
06/05/2022 21:44:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=39
06/05/2022 21:44:58 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.6762253049245752 on epoch=39
06/05/2022 21:45:00 - INFO - __main__ - Step 560 Global step 560 Train loss 0.12 on epoch=39
06/05/2022 21:45:03 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=40
06/05/2022 21:45:06 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=41
06/05/2022 21:45:08 - INFO - __main__ - Step 590 Global step 590 Train loss 0.09 on epoch=42
06/05/2022 21:45:11 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=42
06/05/2022 21:45:17 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.6990056003794394 on epoch=42
06/05/2022 21:45:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=43
06/05/2022 21:45:23 - INFO - __main__ - Step 620 Global step 620 Train loss 0.12 on epoch=44
06/05/2022 21:45:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=44
06/05/2022 21:45:28 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=45
06/05/2022 21:45:31 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=46
06/05/2022 21:45:37 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.679215626874974 on epoch=46
06/05/2022 21:45:40 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=47
06/05/2022 21:45:43 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=47
06/05/2022 21:45:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=48
06/05/2022 21:45:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=49
06/05/2022 21:45:51 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=49
06/05/2022 21:45:58 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.7898217738685905 on epoch=49
06/05/2022 21:46:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=50
06/05/2022 21:46:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=51
06/05/2022 21:46:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=52
06/05/2022 21:46:09 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=52
06/05/2022 21:46:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=53
06/05/2022 21:46:17 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.8131511689475399 on epoch=53
06/05/2022 21:46:20 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=54
06/05/2022 21:46:23 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=54
06/05/2022 21:46:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=55
06/05/2022 21:46:28 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=56
06/05/2022 21:46:31 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=57
06/05/2022 21:46:37 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7777365561270014 on epoch=57
06/05/2022 21:46:40 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=57
06/05/2022 21:46:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=58
06/05/2022 21:46:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=59
06/05/2022 21:46:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=59
06/05/2022 21:46:51 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=60
06/05/2022 21:46:57 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.7055426504167208 on epoch=60
06/05/2022 21:47:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=61
06/05/2022 21:47:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=62
06/05/2022 21:47:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
06/05/2022 21:47:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=63
06/05/2022 21:47:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=64
06/05/2022 21:47:16 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.7312350564657049 on epoch=64
06/05/2022 21:47:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=64
06/05/2022 21:47:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=65
06/05/2022 21:47:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=66
06/05/2022 21:47:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=67
06/05/2022 21:47:30 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=67
06/05/2022 21:47:36 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.7324609962916414 on epoch=67
06/05/2022 21:47:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
06/05/2022 21:47:41 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=69
06/05/2022 21:47:44 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=69
06/05/2022 21:47:47 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/05/2022 21:47:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/05/2022 21:47:56 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.6948351797545346 on epoch=71
06/05/2022 21:47:58 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=72
06/05/2022 21:48:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=72
06/05/2022 21:48:04 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=73
06/05/2022 21:48:07 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=74
06/05/2022 21:48:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=74
06/05/2022 21:48:16 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.84640271522832 on epoch=74
06/05/2022 21:48:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=75
06/05/2022 21:48:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=76
06/05/2022 21:48:24 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=77
06/05/2022 21:48:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=77
06/05/2022 21:48:29 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/05/2022 21:48:36 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.8469604152567862 on epoch=78
06/05/2022 21:48:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
06/05/2022 21:48:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
06/05/2022 21:48:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
06/05/2022 21:48:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
06/05/2022 21:48:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=82
06/05/2022 21:48:55 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.8469634294839383 on epoch=82
06/05/2022 21:48:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
06/05/2022 21:49:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
06/05/2022 21:49:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
06/05/2022 21:49:06 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=84
06/05/2022 21:49:09 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
06/05/2022 21:49:15 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.7805521063530376 on epoch=85
06/05/2022 21:49:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
06/05/2022 21:49:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
06/05/2022 21:49:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
06/05/2022 21:49:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/05/2022 21:49:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
06/05/2022 21:49:36 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.8441206369114932 on epoch=89
06/05/2022 21:49:38 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
06/05/2022 21:49:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=90
06/05/2022 21:49:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/05/2022 21:49:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
06/05/2022 21:49:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
06/05/2022 21:49:55 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.708928414105434 on epoch=92
06/05/2022 21:49:58 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=93
06/05/2022 21:50:01 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
06/05/2022 21:50:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
06/05/2022 21:50:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
06/05/2022 21:50:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/05/2022 21:50:15 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.801354468147637 on epoch=96
06/05/2022 21:50:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
06/05/2022 21:50:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/05/2022 21:50:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=98
06/05/2022 21:50:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/05/2022 21:50:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/05/2022 21:50:35 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6671264059911166 on epoch=99
06/05/2022 21:50:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
06/05/2022 21:50:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/05/2022 21:50:43 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/05/2022 21:50:46 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
06/05/2022 21:50:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
06/05/2022 21:50:55 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.8427631113352176 on epoch=103
06/05/2022 21:50:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/05/2022 21:51:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/05/2022 21:51:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
06/05/2022 21:51:06 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/05/2022 21:51:09 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
06/05/2022 21:51:15 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.9056426653312083 on epoch=107
06/05/2022 21:51:16 - INFO - __main__ - Saving model with best Classification-F1: 0.8616087611392995 -> 0.9056426653312083 on epoch=107, global_step=1500
06/05/2022 21:51:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/05/2022 21:51:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
06/05/2022 21:51:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
06/05/2022 21:51:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/05/2022 21:51:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/05/2022 21:51:35 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7863755628654535 on epoch=110
06/05/2022 21:51:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/05/2022 21:51:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
06/05/2022 21:51:44 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/05/2022 21:51:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/05/2022 21:51:49 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
06/05/2022 21:51:55 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7400345358534195 on epoch=114
06/05/2022 21:51:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/05/2022 21:52:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/05/2022 21:52:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/05/2022 21:52:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/05/2022 21:52:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/05/2022 21:52:15 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8607143459062259 on epoch=117
06/05/2022 21:52:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
06/05/2022 21:52:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=119
06/05/2022 21:52:24 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/05/2022 21:52:26 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/05/2022 21:52:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/05/2022 21:52:35 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.8551808406647117 on epoch=121
06/05/2022 21:52:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/05/2022 21:52:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/05/2022 21:52:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/05/2022 21:52:46 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/05/2022 21:52:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=124
06/05/2022 21:52:55 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.9822570890526298 on epoch=124
06/05/2022 21:52:55 - INFO - __main__ - Saving model with best Classification-F1: 0.9056426653312083 -> 0.9822570890526298 on epoch=124, global_step=1750
06/05/2022 21:52:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/05/2022 21:53:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
06/05/2022 21:53:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/05/2022 21:53:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
06/05/2022 21:53:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/05/2022 21:53:15 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.9776348295916607 on epoch=128
06/05/2022 21:53:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=129
06/05/2022 21:53:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
06/05/2022 21:53:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/05/2022 21:53:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/05/2022 21:53:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=132
06/05/2022 21:53:35 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.8514128176930597 on epoch=132
06/05/2022 21:53:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/05/2022 21:53:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/05/2022 21:53:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/05/2022 21:53:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/05/2022 21:53:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/05/2022 21:53:55 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9062309733277476 on epoch=135
06/05/2022 21:53:58 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/05/2022 21:54:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/05/2022 21:54:04 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/05/2022 21:54:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
06/05/2022 21:54:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/05/2022 21:54:16 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.8409612033351952 on epoch=139
06/05/2022 21:54:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=139
06/05/2022 21:54:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/05/2022 21:54:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/05/2022 21:54:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
06/05/2022 21:54:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/05/2022 21:54:36 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9104017129823582 on epoch=142
06/05/2022 21:54:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/05/2022 21:54:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/05/2022 21:54:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/05/2022 21:54:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/05/2022 21:54:50 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/05/2022 21:54:56 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9775075059349252 on epoch=146
06/05/2022 21:54:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/05/2022 21:55:02 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/05/2022 21:55:04 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/05/2022 21:55:07 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/05/2022 21:55:10 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/05/2022 21:55:16 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8409149821952242 on epoch=149
06/05/2022 21:55:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/05/2022 21:55:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/05/2022 21:55:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
06/05/2022 21:55:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/05/2022 21:55:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/05/2022 21:55:36 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.8284376873147005 on epoch=153
06/05/2022 21:55:39 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/05/2022 21:55:42 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/05/2022 21:55:44 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/05/2022 21:55:47 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
06/05/2022 21:55:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/05/2022 21:55:56 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.8153364173534692 on epoch=157
06/05/2022 21:55:59 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/05/2022 21:56:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/05/2022 21:56:04 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/05/2022 21:56:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/05/2022 21:56:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/05/2022 21:56:16 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8862039752362333 on epoch=160
06/05/2022 21:56:19 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/05/2022 21:56:22 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/05/2022 21:56:25 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/05/2022 21:56:28 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/05/2022 21:56:30 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/05/2022 21:56:36 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7461457569973204 on epoch=164
06/05/2022 21:56:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
06/05/2022 21:56:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=165
06/05/2022 21:56:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/05/2022 21:56:47 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/05/2022 21:56:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/05/2022 21:56:56 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7971666379161636 on epoch=167
06/05/2022 21:56:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/05/2022 21:57:02 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=169
06/05/2022 21:57:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/05/2022 21:57:07 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/05/2022 21:57:10 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/05/2022 21:57:16 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8248708473492037 on epoch=171
06/05/2022 21:57:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/05/2022 21:57:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/05/2022 21:57:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/05/2022 21:57:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/05/2022 21:57:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
06/05/2022 21:57:36 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8028671439250187 on epoch=174
06/05/2022 21:57:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/05/2022 21:57:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/05/2022 21:57:45 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
06/05/2022 21:57:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/05/2022 21:57:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
06/05/2022 21:57:56 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9035948191593351 on epoch=178
06/05/2022 21:57:59 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
06/05/2022 21:58:02 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/05/2022 21:58:05 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/05/2022 21:58:07 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
06/05/2022 21:58:10 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/05/2022 21:58:16 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8514020362543845 on epoch=182
06/05/2022 21:58:19 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/05/2022 21:58:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/05/2022 21:58:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/05/2022 21:58:27 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/05/2022 21:58:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
06/05/2022 21:58:36 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8506214817811035 on epoch=185
06/05/2022 21:58:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/05/2022 21:58:42 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/05/2022 21:58:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/05/2022 21:58:47 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/05/2022 21:58:50 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/05/2022 21:58:56 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8467030128172718 on epoch=189
06/05/2022 21:58:59 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/05/2022 21:59:02 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/05/2022 21:59:05 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/05/2022 21:59:07 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/05/2022 21:59:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/05/2022 21:59:17 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.8239895949615901 on epoch=192
06/05/2022 21:59:19 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/05/2022 21:59:22 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/05/2022 21:59:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/05/2022 21:59:28 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/05/2022 21:59:31 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/05/2022 21:59:37 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7284023025958509 on epoch=196
06/05/2022 21:59:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/05/2022 21:59:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/05/2022 21:59:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/05/2022 21:59:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/05/2022 21:59:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/05/2022 21:59:56 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7438415731413307 on epoch=199
06/05/2022 21:59:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/05/2022 22:00:02 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/05/2022 22:00:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/05/2022 22:00:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/05/2022 22:00:10 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/05/2022 22:00:16 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8527598004516803 on epoch=203
06/05/2022 22:00:19 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/05/2022 22:00:22 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/05/2022 22:00:24 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/05/2022 22:00:27 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/05/2022 22:00:30 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/05/2022 22:00:36 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8400555090071219 on epoch=207
06/05/2022 22:00:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/05/2022 22:00:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.06 on epoch=208
06/05/2022 22:00:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/05/2022 22:00:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/05/2022 22:00:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/05/2022 22:00:57 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8345917524301493 on epoch=210
06/05/2022 22:00:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=211
06/05/2022 22:01:02 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/05/2022 22:01:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/05/2022 22:01:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/05/2022 22:01:10 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/05/2022 22:01:12 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 22:01:12 - INFO - __main__ - Printing 3 examples
06/05/2022 22:01:12 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/05/2022 22:01:12 - INFO - __main__ - ['Plant']
06/05/2022 22:01:12 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/05/2022 22:01:12 - INFO - __main__ - ['Plant']
06/05/2022 22:01:12 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/05/2022 22:01:12 - INFO - __main__ - ['Plant']
06/05/2022 22:01:12 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:01:12 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:01:12 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 22:01:12 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 22:01:12 - INFO - __main__ - Printing 3 examples
06/05/2022 22:01:12 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/05/2022 22:01:12 - INFO - __main__ - ['Plant']
06/05/2022 22:01:12 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/05/2022 22:01:12 - INFO - __main__ - ['Plant']
06/05/2022 22:01:12 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/05/2022 22:01:12 - INFO - __main__ - ['Plant']
06/05/2022 22:01:12 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:01:12 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:01:12 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 22:01:17 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.851699539073531 on epoch=214
06/05/2022 22:01:17 - INFO - __main__ - save last model!
06/05/2022 22:01:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 22:01:17 - INFO - __main__ - Start tokenizing ... 3500 instances
06/05/2022 22:01:17 - INFO - __main__ - Printing 3 examples
06/05/2022 22:01:17 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/05/2022 22:01:17 - INFO - __main__ - ['Animal']
06/05/2022 22:01:17 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/05/2022 22:01:17 - INFO - __main__ - ['Animal']
06/05/2022 22:01:17 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/05/2022 22:01:17 - INFO - __main__ - ['Village']
06/05/2022 22:01:17 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:01:19 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:01:23 - INFO - __main__ - Loaded 3500 examples from test data
06/05/2022 22:01:28 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 22:01:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 22:01:29 - INFO - __main__ - Starting training!
06/05/2022 22:03:38 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
06/05/2022 22:03:38 - INFO - __main__ - Classification-F1 on test data: 0.5906
06/05/2022 22:03:39 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.9822570890526298, test_performance=0.5906142508496366
06/05/2022 22:03:39 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
06/05/2022 22:03:40 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 22:03:40 - INFO - __main__ - Printing 3 examples
06/05/2022 22:03:40 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/05/2022 22:03:40 - INFO - __main__ - ['Plant']
06/05/2022 22:03:40 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/05/2022 22:03:40 - INFO - __main__ - ['Plant']
06/05/2022 22:03:40 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/05/2022 22:03:40 - INFO - __main__ - ['Plant']
06/05/2022 22:03:40 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:03:40 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:03:40 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 22:03:40 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 22:03:40 - INFO - __main__ - Printing 3 examples
06/05/2022 22:03:40 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/05/2022 22:03:40 - INFO - __main__ - ['Plant']
06/05/2022 22:03:40 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/05/2022 22:03:40 - INFO - __main__ - ['Plant']
06/05/2022 22:03:40 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/05/2022 22:03:40 - INFO - __main__ - ['Plant']
06/05/2022 22:03:40 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:03:40 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:03:41 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 22:03:59 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 22:04:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 22:04:00 - INFO - __main__ - Starting training!
06/05/2022 22:04:04 - INFO - __main__ - Step 10 Global step 10 Train loss 5.40 on epoch=0
06/05/2022 22:04:06 - INFO - __main__ - Step 20 Global step 20 Train loss 3.73 on epoch=1
06/05/2022 22:04:09 - INFO - __main__ - Step 30 Global step 30 Train loss 3.01 on epoch=2
06/05/2022 22:04:12 - INFO - __main__ - Step 40 Global step 40 Train loss 2.51 on epoch=2
06/05/2022 22:04:15 - INFO - __main__ - Step 50 Global step 50 Train loss 2.17 on epoch=3
06/05/2022 22:04:20 - INFO - __main__ - Global step 50 Train loss 3.36 Classification-F1 0.07621321535841356 on epoch=3
06/05/2022 22:04:20 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07621321535841356 on epoch=3, global_step=50
06/05/2022 22:04:23 - INFO - __main__ - Step 60 Global step 60 Train loss 1.66 on epoch=4
06/05/2022 22:04:26 - INFO - __main__ - Step 70 Global step 70 Train loss 1.57 on epoch=4
06/05/2022 22:04:28 - INFO - __main__ - Step 80 Global step 80 Train loss 1.31 on epoch=5
06/05/2022 22:04:31 - INFO - __main__ - Step 90 Global step 90 Train loss 1.07 on epoch=6
06/05/2022 22:04:34 - INFO - __main__ - Step 100 Global step 100 Train loss 1.00 on epoch=7
06/05/2022 22:04:41 - INFO - __main__ - Global step 100 Train loss 1.32 Classification-F1 0.383704496800012 on epoch=7
06/05/2022 22:04:41 - INFO - __main__ - Saving model with best Classification-F1: 0.07621321535841356 -> 0.383704496800012 on epoch=7, global_step=100
06/05/2022 22:04:44 - INFO - __main__ - Step 110 Global step 110 Train loss 0.98 on epoch=7
06/05/2022 22:04:46 - INFO - __main__ - Step 120 Global step 120 Train loss 0.75 on epoch=8
06/05/2022 22:04:49 - INFO - __main__ - Step 130 Global step 130 Train loss 0.77 on epoch=9
06/05/2022 22:04:52 - INFO - __main__ - Step 140 Global step 140 Train loss 0.71 on epoch=9
06/05/2022 22:04:54 - INFO - __main__ - Step 150 Global step 150 Train loss 0.70 on epoch=10
06/05/2022 22:05:01 - INFO - __main__ - Global step 150 Train loss 0.78 Classification-F1 0.49165628661488586 on epoch=10
06/05/2022 22:05:01 - INFO - __main__ - Saving model with best Classification-F1: 0.383704496800012 -> 0.49165628661488586 on epoch=10, global_step=150
06/05/2022 22:05:04 - INFO - __main__ - Step 160 Global step 160 Train loss 0.61 on epoch=11
06/05/2022 22:05:07 - INFO - __main__ - Step 170 Global step 170 Train loss 0.61 on epoch=12
06/05/2022 22:05:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.60 on epoch=12
06/05/2022 22:05:12 - INFO - __main__ - Step 190 Global step 190 Train loss 0.55 on epoch=13
06/05/2022 22:05:15 - INFO - __main__ - Step 200 Global step 200 Train loss 0.56 on epoch=14
06/05/2022 22:05:22 - INFO - __main__ - Global step 200 Train loss 0.59 Classification-F1 0.7442785091824213 on epoch=14
06/05/2022 22:05:22 - INFO - __main__ - Saving model with best Classification-F1: 0.49165628661488586 -> 0.7442785091824213 on epoch=14, global_step=200
06/05/2022 22:05:25 - INFO - __main__ - Step 210 Global step 210 Train loss 0.47 on epoch=14
06/05/2022 22:05:27 - INFO - __main__ - Step 220 Global step 220 Train loss 0.54 on epoch=15
06/05/2022 22:05:30 - INFO - __main__ - Step 230 Global step 230 Train loss 0.38 on epoch=16
06/05/2022 22:05:33 - INFO - __main__ - Step 240 Global step 240 Train loss 0.48 on epoch=17
06/05/2022 22:05:35 - INFO - __main__ - Step 250 Global step 250 Train loss 0.38 on epoch=17
06/05/2022 22:05:43 - INFO - __main__ - Global step 250 Train loss 0.45 Classification-F1 0.7827086956768083 on epoch=17
06/05/2022 22:05:43 - INFO - __main__ - Saving model with best Classification-F1: 0.7442785091824213 -> 0.7827086956768083 on epoch=17, global_step=250
06/05/2022 22:05:45 - INFO - __main__ - Step 260 Global step 260 Train loss 0.41 on epoch=18
06/05/2022 22:05:48 - INFO - __main__ - Step 270 Global step 270 Train loss 0.44 on epoch=19
06/05/2022 22:05:51 - INFO - __main__ - Step 280 Global step 280 Train loss 0.37 on epoch=19
06/05/2022 22:05:54 - INFO - __main__ - Step 290 Global step 290 Train loss 0.47 on epoch=20
06/05/2022 22:05:56 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=21
06/05/2022 22:06:03 - INFO - __main__ - Global step 300 Train loss 0.43 Classification-F1 0.7803295555019693 on epoch=21
06/05/2022 22:06:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.33 on epoch=22
06/05/2022 22:06:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.41 on epoch=22
06/05/2022 22:06:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=23
06/05/2022 22:06:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=24
06/05/2022 22:06:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=24
06/05/2022 22:06:24 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.7713119911864468 on epoch=24
06/05/2022 22:06:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=25
06/05/2022 22:06:30 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=26
06/05/2022 22:06:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.29 on epoch=27
06/05/2022 22:06:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=27
06/05/2022 22:06:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=28
06/05/2022 22:06:45 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.7624247165185151 on epoch=28
06/05/2022 22:06:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=29
06/05/2022 22:06:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=29
06/05/2022 22:06:53 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=30
06/05/2022 22:06:56 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=31
06/05/2022 22:06:58 - INFO - __main__ - Step 450 Global step 450 Train loss 0.17 on epoch=32
06/05/2022 22:07:05 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.655210423419252 on epoch=32
06/05/2022 22:07:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=32
06/05/2022 22:07:11 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=33
06/05/2022 22:07:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=34
06/05/2022 22:07:16 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=34
06/05/2022 22:07:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=35
06/05/2022 22:07:25 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.6085061108870157 on epoch=35
06/05/2022 22:07:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=36
06/05/2022 22:07:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=37
06/05/2022 22:07:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=37
06/05/2022 22:07:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=38
06/05/2022 22:07:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=39
06/05/2022 22:07:45 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.7952679027884118 on epoch=39
06/05/2022 22:07:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7827086956768083 -> 0.7952679027884118 on epoch=39, global_step=550
06/05/2022 22:07:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=39
06/05/2022 22:07:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=40
06/05/2022 22:07:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=41
06/05/2022 22:07:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.12 on epoch=42
06/05/2022 22:07:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=42
06/05/2022 22:08:05 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.8007692858351577 on epoch=42
06/05/2022 22:08:05 - INFO - __main__ - Saving model with best Classification-F1: 0.7952679027884118 -> 0.8007692858351577 on epoch=42, global_step=600
06/05/2022 22:08:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=43
06/05/2022 22:08:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.12 on epoch=44
06/05/2022 22:08:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=44
06/05/2022 22:08:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=45
06/05/2022 22:08:18 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=46
06/05/2022 22:08:25 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.8797377195144976 on epoch=46
06/05/2022 22:08:25 - INFO - __main__ - Saving model with best Classification-F1: 0.8007692858351577 -> 0.8797377195144976 on epoch=46, global_step=650
06/05/2022 22:08:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=47
06/05/2022 22:08:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=47
06/05/2022 22:08:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=48
06/05/2022 22:08:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=49
06/05/2022 22:08:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=49
06/05/2022 22:08:45 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.8306550980501919 on epoch=49
06/05/2022 22:08:47 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=50
06/05/2022 22:08:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=51
06/05/2022 22:08:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=52
06/05/2022 22:08:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
06/05/2022 22:08:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=53
06/05/2022 22:09:05 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.9059945278209035 on epoch=53
06/05/2022 22:09:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8797377195144976 -> 0.9059945278209035 on epoch=53, global_step=750
06/05/2022 22:09:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=54
06/05/2022 22:09:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.09 on epoch=54
06/05/2022 22:09:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=55
06/05/2022 22:09:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=56
06/05/2022 22:09:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=57
06/05/2022 22:09:25 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.9730528208350788 on epoch=57
06/05/2022 22:09:25 - INFO - __main__ - Saving model with best Classification-F1: 0.9059945278209035 -> 0.9730528208350788 on epoch=57, global_step=800
06/05/2022 22:09:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=57
06/05/2022 22:09:31 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=58
06/05/2022 22:09:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=59
06/05/2022 22:09:36 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=59
06/05/2022 22:09:39 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=60
06/05/2022 22:09:45 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.8983207781863698 on epoch=60
06/05/2022 22:09:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=61
06/05/2022 22:09:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=62
06/05/2022 22:09:53 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=62
06/05/2022 22:09:56 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=63
06/05/2022 22:09:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=64
06/05/2022 22:10:05 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.9003369072186277 on epoch=64
06/05/2022 22:10:08 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=64
06/05/2022 22:10:11 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=65
06/05/2022 22:10:13 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=66
06/05/2022 22:10:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=67
06/05/2022 22:10:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
06/05/2022 22:10:25 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.9105320485965649 on epoch=67
06/05/2022 22:10:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/05/2022 22:10:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=69
06/05/2022 22:10:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=69
06/05/2022 22:10:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/05/2022 22:10:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
06/05/2022 22:10:45 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.9078565293714481 on epoch=71
06/05/2022 22:10:48 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=72
06/05/2022 22:10:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=72
06/05/2022 22:10:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=73
06/05/2022 22:10:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
06/05/2022 22:10:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
06/05/2022 22:11:05 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.8150625105247378 on epoch=74
06/05/2022 22:11:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=75
06/05/2022 22:11:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
06/05/2022 22:11:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
06/05/2022 22:11:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
06/05/2022 22:11:19 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/05/2022 22:11:25 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.8422657833800422 on epoch=78
06/05/2022 22:11:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=79
06/05/2022 22:11:30 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
06/05/2022 22:11:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=80
06/05/2022 22:11:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
06/05/2022 22:11:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=82
06/05/2022 22:11:45 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.8974745263170313 on epoch=82
06/05/2022 22:11:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/05/2022 22:11:50 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
06/05/2022 22:11:53 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=84
06/05/2022 22:11:55 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/05/2022 22:11:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
06/05/2022 22:12:04 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.8963430126693884 on epoch=85
06/05/2022 22:12:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
06/05/2022 22:12:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=87
06/05/2022 22:12:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
06/05/2022 22:12:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=88
06/05/2022 22:12:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
06/05/2022 22:12:24 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.8982328790753837 on epoch=89
06/05/2022 22:12:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
06/05/2022 22:12:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
06/05/2022 22:12:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
06/05/2022 22:12:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/05/2022 22:12:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
06/05/2022 22:12:44 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.8433029962857325 on epoch=92
06/05/2022 22:12:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=93
06/05/2022 22:12:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=94
06/05/2022 22:12:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
06/05/2022 22:12:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=95
06/05/2022 22:12:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/05/2022 22:13:03 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.7984447647525302 on epoch=96
06/05/2022 22:13:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
06/05/2022 22:13:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
06/05/2022 22:13:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/05/2022 22:13:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/05/2022 22:13:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/05/2022 22:13:23 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7779191104129713 on epoch=99
06/05/2022 22:13:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
06/05/2022 22:13:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/05/2022 22:13:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
06/05/2022 22:13:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/05/2022 22:13:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/05/2022 22:13:43 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.8249264971128623 on epoch=103
06/05/2022 22:13:46 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/05/2022 22:13:48 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/05/2022 22:13:51 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/05/2022 22:13:54 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
06/05/2022 22:13:57 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/05/2022 22:14:03 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.7985108235487871 on epoch=107
06/05/2022 22:14:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/05/2022 22:14:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
06/05/2022 22:14:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=109
06/05/2022 22:14:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/05/2022 22:14:16 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/05/2022 22:14:23 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.830242784023026 on epoch=110
06/05/2022 22:14:26 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/05/2022 22:14:28 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/05/2022 22:14:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/05/2022 22:14:34 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/05/2022 22:14:37 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/05/2022 22:14:43 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7913893954453726 on epoch=114
06/05/2022 22:14:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/05/2022 22:14:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/05/2022 22:14:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/05/2022 22:14:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/05/2022 22:14:57 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/05/2022 22:15:03 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8284574710660885 on epoch=117
06/05/2022 22:15:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/05/2022 22:15:08 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/05/2022 22:15:11 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/05/2022 22:15:14 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
06/05/2022 22:15:16 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/05/2022 22:15:22 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7921649320057682 on epoch=121
06/05/2022 22:15:25 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/05/2022 22:15:28 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
06/05/2022 22:15:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/05/2022 22:15:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
06/05/2022 22:15:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/05/2022 22:15:43 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.9019556571406667 on epoch=124
06/05/2022 22:15:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=125
06/05/2022 22:15:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/05/2022 22:15:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/05/2022 22:15:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/05/2022 22:15:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/05/2022 22:16:03 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8411608591889583 on epoch=128
06/05/2022 22:16:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
06/05/2022 22:16:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/05/2022 22:16:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/05/2022 22:16:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/05/2022 22:16:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/05/2022 22:16:23 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9686808447719264 on epoch=132
06/05/2022 22:16:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
06/05/2022 22:16:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/05/2022 22:16:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/05/2022 22:16:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/05/2022 22:16:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/05/2022 22:16:43 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9097578959786969 on epoch=135
06/05/2022 22:16:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/05/2022 22:16:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/05/2022 22:16:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
06/05/2022 22:16:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/05/2022 22:16:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/05/2022 22:17:03 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9058404003391897 on epoch=139
06/05/2022 22:17:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/05/2022 22:17:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/05/2022 22:17:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/05/2022 22:17:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/05/2022 22:17:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/05/2022 22:17:23 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.901826870859129 on epoch=142
06/05/2022 22:17:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/05/2022 22:17:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/05/2022 22:17:31 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/05/2022 22:17:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/05/2022 22:17:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/05/2022 22:17:43 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.851536444856535 on epoch=146
06/05/2022 22:17:46 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/05/2022 22:17:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
06/05/2022 22:17:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/05/2022 22:17:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/05/2022 22:17:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=149
06/05/2022 22:18:04 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9146227454813792 on epoch=149
06/05/2022 22:18:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/05/2022 22:18:09 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/05/2022 22:18:12 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/05/2022 22:18:15 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/05/2022 22:18:17 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=153
06/05/2022 22:18:24 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9821297653958945 on epoch=153
06/05/2022 22:18:24 - INFO - __main__ - Saving model with best Classification-F1: 0.9730528208350788 -> 0.9821297653958945 on epoch=153, global_step=2150
06/05/2022 22:18:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/05/2022 22:18:29 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
06/05/2022 22:18:32 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/05/2022 22:18:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/05/2022 22:18:37 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/05/2022 22:18:44 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9014197477622526 on epoch=157
06/05/2022 22:18:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/05/2022 22:18:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=158
06/05/2022 22:18:52 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/05/2022 22:18:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/05/2022 22:18:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
06/05/2022 22:19:04 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9821254014802402 on epoch=160
06/05/2022 22:19:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/05/2022 22:19:10 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/05/2022 22:19:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/05/2022 22:19:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/05/2022 22:19:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/05/2022 22:19:25 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9773415744596959 on epoch=164
06/05/2022 22:19:27 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/05/2022 22:19:30 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/05/2022 22:19:33 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/05/2022 22:19:36 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/05/2022 22:19:38 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
06/05/2022 22:19:45 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9820991153059465 on epoch=167
06/05/2022 22:19:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
06/05/2022 22:19:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/05/2022 22:19:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/05/2022 22:19:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=170
06/05/2022 22:19:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/05/2022 22:20:05 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9732659046023101 on epoch=171
06/05/2022 22:20:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/05/2022 22:20:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/05/2022 22:20:13 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/05/2022 22:20:15 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/05/2022 22:20:18 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
06/05/2022 22:20:24 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9732659046023101 on epoch=174
06/05/2022 22:20:27 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/05/2022 22:20:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/05/2022 22:20:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/05/2022 22:20:35 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/05/2022 22:20:38 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
06/05/2022 22:20:44 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9822570890526298 on epoch=178
06/05/2022 22:20:44 - INFO - __main__ - Saving model with best Classification-F1: 0.9821297653958945 -> 0.9822570890526298 on epoch=178, global_step=2500
06/05/2022 22:20:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/05/2022 22:20:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/05/2022 22:20:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/05/2022 22:20:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
06/05/2022 22:20:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
06/05/2022 22:21:04 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9103175972246181 on epoch=182
06/05/2022 22:21:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/05/2022 22:21:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
06/05/2022 22:21:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/05/2022 22:21:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
06/05/2022 22:21:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/05/2022 22:21:24 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9822570890526298 on epoch=185
06/05/2022 22:21:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/05/2022 22:21:30 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/05/2022 22:21:32 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/05/2022 22:21:35 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/05/2022 22:21:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/05/2022 22:21:44 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9819857561793045 on epoch=189
06/05/2022 22:21:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/05/2022 22:21:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/05/2022 22:21:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/05/2022 22:21:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/05/2022 22:21:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/05/2022 22:22:04 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9822570890526298 on epoch=192
06/05/2022 22:22:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/05/2022 22:22:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/05/2022 22:22:12 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/05/2022 22:22:15 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/05/2022 22:22:18 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/05/2022 22:22:24 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9732659046023101 on epoch=196
06/05/2022 22:22:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/05/2022 22:22:29 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/05/2022 22:22:32 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/05/2022 22:22:35 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/05/2022 22:22:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/05/2022 22:22:44 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9728685609141016 on epoch=199
06/05/2022 22:22:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/05/2022 22:22:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/05/2022 22:22:53 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/05/2022 22:22:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/05/2022 22:22:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/05/2022 22:23:04 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9728729248297557 on epoch=203
06/05/2022 22:23:07 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/05/2022 22:23:10 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/05/2022 22:23:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/05/2022 22:23:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/05/2022 22:23:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/05/2022 22:23:25 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9680399209941838 on epoch=207
06/05/2022 22:23:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/05/2022 22:23:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/05/2022 22:23:33 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/05/2022 22:23:36 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/05/2022 22:23:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/05/2022 22:23:45 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9736163478098963 on epoch=210
06/05/2022 22:23:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/05/2022 22:23:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/05/2022 22:23:54 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/05/2022 22:23:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/05/2022 22:23:59 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/05/2022 22:24:01 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 22:24:01 - INFO - __main__ - Printing 3 examples
06/05/2022 22:24:01 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/05/2022 22:24:01 - INFO - __main__ - ['Plant']
06/05/2022 22:24:01 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/05/2022 22:24:01 - INFO - __main__ - ['Plant']
06/05/2022 22:24:01 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/05/2022 22:24:01 - INFO - __main__ - ['Plant']
06/05/2022 22:24:01 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:24:01 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:24:01 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 22:24:01 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 22:24:01 - INFO - __main__ - Printing 3 examples
06/05/2022 22:24:01 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/05/2022 22:24:01 - INFO - __main__ - ['Plant']
06/05/2022 22:24:01 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/05/2022 22:24:01 - INFO - __main__ - ['Plant']
06/05/2022 22:24:01 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/05/2022 22:24:01 - INFO - __main__ - ['Plant']
06/05/2022 22:24:01 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:24:01 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:24:01 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 22:24:06 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9775171065493645 on epoch=214
06/05/2022 22:24:06 - INFO - __main__ - save last model!
06/05/2022 22:24:06 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 22:24:06 - INFO - __main__ - Start tokenizing ... 3500 instances
06/05/2022 22:24:06 - INFO - __main__ - Printing 3 examples
06/05/2022 22:24:06 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/05/2022 22:24:06 - INFO - __main__ - ['Animal']
06/05/2022 22:24:06 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/05/2022 22:24:06 - INFO - __main__ - ['Animal']
06/05/2022 22:24:06 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/05/2022 22:24:06 - INFO - __main__ - ['Village']
06/05/2022 22:24:06 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:24:08 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:24:11 - INFO - __main__ - Loaded 3500 examples from test data
06/05/2022 22:24:21 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 22:24:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 22:24:22 - INFO - __main__ - Starting training!
06/05/2022 22:26:22 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
06/05/2022 22:26:22 - INFO - __main__ - Classification-F1 on test data: 0.7616
06/05/2022 22:26:23 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.9822570890526298, test_performance=0.7615878013231847
06/05/2022 22:26:23 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
06/05/2022 22:26:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 22:26:24 - INFO - __main__ - Printing 3 examples
06/05/2022 22:26:24 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/05/2022 22:26:24 - INFO - __main__ - ['Plant']
06/05/2022 22:26:24 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/05/2022 22:26:24 - INFO - __main__ - ['Plant']
06/05/2022 22:26:24 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/05/2022 22:26:24 - INFO - __main__ - ['Plant']
06/05/2022 22:26:24 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:26:24 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:26:24 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 22:26:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 22:26:24 - INFO - __main__ - Printing 3 examples
06/05/2022 22:26:24 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/05/2022 22:26:24 - INFO - __main__ - ['Plant']
06/05/2022 22:26:24 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/05/2022 22:26:24 - INFO - __main__ - ['Plant']
06/05/2022 22:26:24 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/05/2022 22:26:24 - INFO - __main__ - ['Plant']
06/05/2022 22:26:24 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:26:24 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:26:24 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 22:26:43 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 22:26:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 22:26:44 - INFO - __main__ - Starting training!
06/05/2022 22:26:48 - INFO - __main__ - Step 10 Global step 10 Train loss 5.61 on epoch=0
06/05/2022 22:26:50 - INFO - __main__ - Step 20 Global step 20 Train loss 4.37 on epoch=1
06/05/2022 22:26:53 - INFO - __main__ - Step 30 Global step 30 Train loss 3.64 on epoch=2
06/05/2022 22:26:56 - INFO - __main__ - Step 40 Global step 40 Train loss 3.04 on epoch=2
06/05/2022 22:26:59 - INFO - __main__ - Step 50 Global step 50 Train loss 2.70 on epoch=3
06/05/2022 22:27:04 - INFO - __main__ - Global step 50 Train loss 3.87 Classification-F1 0.04668876854249398 on epoch=3
06/05/2022 22:27:04 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04668876854249398 on epoch=3, global_step=50
06/05/2022 22:27:07 - INFO - __main__ - Step 60 Global step 60 Train loss 2.25 on epoch=4
06/05/2022 22:27:10 - INFO - __main__ - Step 70 Global step 70 Train loss 1.96 on epoch=4
06/05/2022 22:27:13 - INFO - __main__ - Step 80 Global step 80 Train loss 1.64 on epoch=5
06/05/2022 22:27:15 - INFO - __main__ - Step 90 Global step 90 Train loss 1.59 on epoch=6
06/05/2022 22:27:18 - INFO - __main__ - Step 100 Global step 100 Train loss 1.38 on epoch=7
06/05/2022 22:27:24 - INFO - __main__ - Global step 100 Train loss 1.76 Classification-F1 0.16309692557757574 on epoch=7
06/05/2022 22:27:24 - INFO - __main__ - Saving model with best Classification-F1: 0.04668876854249398 -> 0.16309692557757574 on epoch=7, global_step=100
06/05/2022 22:27:27 - INFO - __main__ - Step 110 Global step 110 Train loss 1.29 on epoch=7
06/05/2022 22:27:29 - INFO - __main__ - Step 120 Global step 120 Train loss 1.16 on epoch=8
06/05/2022 22:27:32 - INFO - __main__ - Step 130 Global step 130 Train loss 0.96 on epoch=9
06/05/2022 22:27:35 - INFO - __main__ - Step 140 Global step 140 Train loss 0.90 on epoch=9
06/05/2022 22:27:38 - INFO - __main__ - Step 150 Global step 150 Train loss 0.78 on epoch=10
06/05/2022 22:27:44 - INFO - __main__ - Global step 150 Train loss 1.02 Classification-F1 0.4149823509823509 on epoch=10
06/05/2022 22:27:44 - INFO - __main__ - Saving model with best Classification-F1: 0.16309692557757574 -> 0.4149823509823509 on epoch=10, global_step=150
06/05/2022 22:27:47 - INFO - __main__ - Step 160 Global step 160 Train loss 0.79 on epoch=11
06/05/2022 22:27:50 - INFO - __main__ - Step 170 Global step 170 Train loss 0.75 on epoch=12
06/05/2022 22:27:53 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=12
06/05/2022 22:27:56 - INFO - __main__ - Step 190 Global step 190 Train loss 0.63 on epoch=13
06/05/2022 22:27:58 - INFO - __main__ - Step 200 Global step 200 Train loss 0.59 on epoch=14
06/05/2022 22:28:05 - INFO - __main__ - Global step 200 Train loss 0.68 Classification-F1 0.48976929043463713 on epoch=14
06/05/2022 22:28:05 - INFO - __main__ - Saving model with best Classification-F1: 0.4149823509823509 -> 0.48976929043463713 on epoch=14, global_step=200
06/05/2022 22:28:08 - INFO - __main__ - Step 210 Global step 210 Train loss 0.65 on epoch=14
06/05/2022 22:28:11 - INFO - __main__ - Step 220 Global step 220 Train loss 0.59 on epoch=15
06/05/2022 22:28:13 - INFO - __main__ - Step 230 Global step 230 Train loss 0.55 on epoch=16
06/05/2022 22:28:16 - INFO - __main__ - Step 240 Global step 240 Train loss 0.54 on epoch=17
06/05/2022 22:28:19 - INFO - __main__ - Step 250 Global step 250 Train loss 0.59 on epoch=17
06/05/2022 22:28:25 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.5469301155877511 on epoch=17
06/05/2022 22:28:25 - INFO - __main__ - Saving model with best Classification-F1: 0.48976929043463713 -> 0.5469301155877511 on epoch=17, global_step=250
06/05/2022 22:28:28 - INFO - __main__ - Step 260 Global step 260 Train loss 0.49 on epoch=18
06/05/2022 22:28:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.50 on epoch=19
06/05/2022 22:28:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=19
06/05/2022 22:28:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=20
06/05/2022 22:28:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=21
06/05/2022 22:28:45 - INFO - __main__ - Global step 300 Train loss 0.47 Classification-F1 0.7843342574889495 on epoch=21
06/05/2022 22:28:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5469301155877511 -> 0.7843342574889495 on epoch=21, global_step=300
06/05/2022 22:28:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.41 on epoch=22
06/05/2022 22:28:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.47 on epoch=22
06/05/2022 22:28:53 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=23
06/05/2022 22:28:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.37 on epoch=24
06/05/2022 22:28:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=24
06/05/2022 22:29:06 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.7584705128891479 on epoch=24
06/05/2022 22:29:09 - INFO - __main__ - Step 360 Global step 360 Train loss 0.38 on epoch=25
06/05/2022 22:29:11 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=26
06/05/2022 22:29:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.37 on epoch=27
06/05/2022 22:29:17 - INFO - __main__ - Step 390 Global step 390 Train loss 0.40 on epoch=27
06/05/2022 22:29:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=28
06/05/2022 22:29:26 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.7437915173906553 on epoch=28
06/05/2022 22:29:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=29
06/05/2022 22:29:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=29
06/05/2022 22:29:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=30
06/05/2022 22:29:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=31
06/05/2022 22:29:40 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=32
06/05/2022 22:29:47 - INFO - __main__ - Global step 450 Train loss 0.27 Classification-F1 0.6321542492595124 on epoch=32
06/05/2022 22:29:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=32
06/05/2022 22:29:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=33
06/05/2022 22:29:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=34
06/05/2022 22:29:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=34
06/05/2022 22:30:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=35
06/05/2022 22:30:07 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.8089162109323399 on epoch=35
06/05/2022 22:30:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7843342574889495 -> 0.8089162109323399 on epoch=35, global_step=500
06/05/2022 22:30:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=36
06/05/2022 22:30:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=37
06/05/2022 22:30:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=37
06/05/2022 22:30:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=38
06/05/2022 22:30:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=39
06/05/2022 22:30:27 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.5676772491066883 on epoch=39
06/05/2022 22:30:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=39
06/05/2022 22:30:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=40
06/05/2022 22:30:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=41
06/05/2022 22:30:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=42
06/05/2022 22:30:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=42
06/05/2022 22:30:48 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.5776645873489903 on epoch=42
06/05/2022 22:30:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=43
06/05/2022 22:30:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=44
06/05/2022 22:30:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=44
06/05/2022 22:30:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=45
06/05/2022 22:31:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
06/05/2022 22:31:09 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.5572416138423186 on epoch=46
06/05/2022 22:31:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=47
06/05/2022 22:31:14 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=47
06/05/2022 22:31:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=48
06/05/2022 22:31:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=49
06/05/2022 22:31:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=49
06/05/2022 22:31:29 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.6379670443574867 on epoch=49
06/05/2022 22:31:32 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=50
06/05/2022 22:31:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=51
06/05/2022 22:31:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=52
06/05/2022 22:31:40 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=52
06/05/2022 22:31:43 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=53
06/05/2022 22:31:49 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.7746532869012708 on epoch=53
06/05/2022 22:31:52 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=54
06/05/2022 22:31:54 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=54
06/05/2022 22:31:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=55
06/05/2022 22:32:00 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=56
06/05/2022 22:32:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=57
06/05/2022 22:32:09 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.6671861953396994 on epoch=57
06/05/2022 22:32:12 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=57
06/05/2022 22:32:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=58
06/05/2022 22:32:17 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=59
06/05/2022 22:32:20 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=59
06/05/2022 22:32:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=60
06/05/2022 22:32:29 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.6674039955421441 on epoch=60
06/05/2022 22:32:32 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=61
06/05/2022 22:32:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=62
06/05/2022 22:32:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=62
06/05/2022 22:32:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=63
06/05/2022 22:32:43 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=64
06/05/2022 22:32:49 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.7024119061470505 on epoch=64
06/05/2022 22:32:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=64
06/05/2022 22:32:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=65
06/05/2022 22:32:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=66
06/05/2022 22:33:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=67
06/05/2022 22:33:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=67
06/05/2022 22:33:10 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.6942858287722465 on epoch=67
06/05/2022 22:33:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/05/2022 22:33:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=69
06/05/2022 22:33:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=69
06/05/2022 22:33:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=70
06/05/2022 22:33:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=71
06/05/2022 22:33:30 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.7796344373526537 on epoch=71
06/05/2022 22:33:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=72
06/05/2022 22:33:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
06/05/2022 22:33:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=73
06/05/2022 22:33:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=74
06/05/2022 22:33:44 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=74
06/05/2022 22:33:51 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.8192450706961417 on epoch=74
06/05/2022 22:33:51 - INFO - __main__ - Saving model with best Classification-F1: 0.8089162109323399 -> 0.8192450706961417 on epoch=74, global_step=1050
06/05/2022 22:33:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
06/05/2022 22:33:56 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=76
06/05/2022 22:33:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
06/05/2022 22:34:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=77
06/05/2022 22:34:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/05/2022 22:34:11 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.831231505158264 on epoch=78
06/05/2022 22:34:11 - INFO - __main__ - Saving model with best Classification-F1: 0.8192450706961417 -> 0.831231505158264 on epoch=78, global_step=1100
06/05/2022 22:34:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=79
06/05/2022 22:34:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
06/05/2022 22:34:19 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=80
06/05/2022 22:34:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
06/05/2022 22:34:25 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
06/05/2022 22:34:32 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.8367331425295135 on epoch=82
06/05/2022 22:34:32 - INFO - __main__ - Saving model with best Classification-F1: 0.831231505158264 -> 0.8367331425295135 on epoch=82, global_step=1150
06/05/2022 22:34:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=82
06/05/2022 22:34:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=83
06/05/2022 22:34:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=84
06/05/2022 22:34:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=84
06/05/2022 22:34:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
06/05/2022 22:34:52 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.827623780043135 on epoch=85
06/05/2022 22:34:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=86
06/05/2022 22:34:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
06/05/2022 22:35:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
06/05/2022 22:35:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=88
06/05/2022 22:35:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
06/05/2022 22:35:12 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7976744037465099 on epoch=89
06/05/2022 22:35:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
06/05/2022 22:35:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=90
06/05/2022 22:35:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
06/05/2022 22:35:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=92
06/05/2022 22:35:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=92
06/05/2022 22:35:32 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7854019320338106 on epoch=92
06/05/2022 22:35:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
06/05/2022 22:35:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=94
06/05/2022 22:35:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
06/05/2022 22:35:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=95
06/05/2022 22:35:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/05/2022 22:35:52 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.8505425630662822 on epoch=96
06/05/2022 22:35:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8367331425295135 -> 0.8505425630662822 on epoch=96, global_step=1350
06/05/2022 22:35:55 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
06/05/2022 22:35:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
06/05/2022 22:36:01 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/05/2022 22:36:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=99
06/05/2022 22:36:06 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/05/2022 22:36:13 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.8390142703398752 on epoch=99
06/05/2022 22:36:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
06/05/2022 22:36:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/05/2022 22:36:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=102
06/05/2022 22:36:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
06/05/2022 22:36:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
06/05/2022 22:36:33 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.9057256379141807 on epoch=103
06/05/2022 22:36:33 - INFO - __main__ - Saving model with best Classification-F1: 0.8505425630662822 -> 0.9057256379141807 on epoch=103, global_step=1450
06/05/2022 22:36:36 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
06/05/2022 22:36:39 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/05/2022 22:36:41 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/05/2022 22:36:44 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=106
06/05/2022 22:36:47 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/05/2022 22:36:54 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.9732659046023101 on epoch=107
06/05/2022 22:36:54 - INFO - __main__ - Saving model with best Classification-F1: 0.9057256379141807 -> 0.9732659046023101 on epoch=107, global_step=1500
06/05/2022 22:36:56 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/05/2022 22:36:59 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=108
06/05/2022 22:37:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/05/2022 22:37:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/05/2022 22:37:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/05/2022 22:37:14 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.8349508307925646 on epoch=110
06/05/2022 22:37:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
06/05/2022 22:37:19 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.12 on epoch=112
06/05/2022 22:37:22 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=112
06/05/2022 22:37:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/05/2022 22:37:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
06/05/2022 22:37:34 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.7476548689451915 on epoch=114
06/05/2022 22:37:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=114
06/05/2022 22:37:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/05/2022 22:37:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/05/2022 22:37:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/05/2022 22:37:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/05/2022 22:37:54 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7992955281129186 on epoch=117
06/05/2022 22:37:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/05/2022 22:38:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=119
06/05/2022 22:38:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=119
06/05/2022 22:38:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/05/2022 22:38:08 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=121
06/05/2022 22:38:14 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.7413041722695878 on epoch=121
06/05/2022 22:38:17 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
06/05/2022 22:38:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
06/05/2022 22:38:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=123
06/05/2022 22:38:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
06/05/2022 22:38:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/05/2022 22:38:34 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.8511646199902249 on epoch=124
06/05/2022 22:38:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=125
06/05/2022 22:38:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
06/05/2022 22:38:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/05/2022 22:38:45 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=127
06/05/2022 22:38:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/05/2022 22:38:54 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.8547919668739676 on epoch=128
06/05/2022 22:38:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
06/05/2022 22:38:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/05/2022 22:39:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=130
06/05/2022 22:39:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
06/05/2022 22:39:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/05/2022 22:39:14 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.9865984150258343 on epoch=132
06/05/2022 22:39:14 - INFO - __main__ - Saving model with best Classification-F1: 0.9732659046023101 -> 0.9865984150258343 on epoch=132, global_step=1850
06/05/2022 22:39:17 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/05/2022 22:39:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
06/05/2022 22:39:22 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/05/2022 22:39:25 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/05/2022 22:39:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
06/05/2022 22:39:34 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9141852338737768 on epoch=135
06/05/2022 22:39:37 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/05/2022 22:39:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/05/2022 22:39:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=137
06/05/2022 22:39:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/05/2022 22:39:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/05/2022 22:39:55 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.910202834799609 on epoch=139
06/05/2022 22:39:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/05/2022 22:40:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
06/05/2022 22:40:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/05/2022 22:40:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/05/2022 22:40:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=142
06/05/2022 22:40:15 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.9061509305579515 on epoch=142
06/05/2022 22:40:17 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/05/2022 22:40:20 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/05/2022 22:40:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/05/2022 22:40:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/05/2022 22:40:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/05/2022 22:40:35 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8510117249384839 on epoch=146
06/05/2022 22:40:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/05/2022 22:40:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/05/2022 22:40:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/05/2022 22:40:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=149
06/05/2022 22:40:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=149
06/05/2022 22:40:55 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.8488695878417096 on epoch=149
06/05/2022 22:40:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/05/2022 22:41:00 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/05/2022 22:41:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/05/2022 22:41:06 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/05/2022 22:41:08 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/05/2022 22:41:15 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.844818278160012 on epoch=153
06/05/2022 22:41:17 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=154
06/05/2022 22:41:20 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/05/2022 22:41:23 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=155
06/05/2022 22:41:25 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=156
06/05/2022 22:41:28 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/05/2022 22:41:34 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.9015264305586886 on epoch=157
06/05/2022 22:41:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/05/2022 22:41:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/05/2022 22:41:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.10 on epoch=159
06/05/2022 22:41:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/05/2022 22:41:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/05/2022 22:41:54 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9819857561793045 on epoch=160
06/05/2022 22:41:57 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=161
06/05/2022 22:42:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/05/2022 22:42:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/05/2022 22:42:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/05/2022 22:42:08 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.08 on epoch=164
06/05/2022 22:42:14 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.8419708629623242 on epoch=164
06/05/2022 22:42:17 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/05/2022 22:42:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/05/2022 22:42:22 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/05/2022 22:42:25 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/05/2022 22:42:28 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/05/2022 22:42:34 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.8523250942605782 on epoch=167
06/05/2022 22:42:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/05/2022 22:42:39 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/05/2022 22:42:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/05/2022 22:42:45 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/05/2022 22:42:48 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/05/2022 22:42:54 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9062309733277476 on epoch=171
06/05/2022 22:42:57 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/05/2022 22:42:59 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
06/05/2022 22:43:02 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/05/2022 22:43:05 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.11 on epoch=174
06/05/2022 22:43:07 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/05/2022 22:43:14 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.9117740250109548 on epoch=174
06/05/2022 22:43:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
06/05/2022 22:43:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/05/2022 22:43:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/05/2022 22:43:24 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.11 on epoch=177
06/05/2022 22:43:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/05/2022 22:43:34 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.8450740722014359 on epoch=178
06/05/2022 22:43:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=179
06/05/2022 22:43:39 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/05/2022 22:43:42 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/05/2022 22:43:45 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/05/2022 22:43:47 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/05/2022 22:43:54 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9076032853563443 on epoch=182
06/05/2022 22:43:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/05/2022 22:43:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/05/2022 22:44:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/05/2022 22:44:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/05/2022 22:44:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/05/2022 22:44:14 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8489733591889583 on epoch=185
06/05/2022 22:44:17 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/05/2022 22:44:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
06/05/2022 22:44:22 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/05/2022 22:44:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
06/05/2022 22:44:28 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/05/2022 22:44:34 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8064112134893395 on epoch=189
06/05/2022 22:44:37 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/05/2022 22:44:40 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/05/2022 22:44:43 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/05/2022 22:44:45 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/05/2022 22:44:48 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/05/2022 22:44:55 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9061583577712611 on epoch=192
06/05/2022 22:44:57 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/05/2022 22:45:00 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/05/2022 22:45:03 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/05/2022 22:45:06 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/05/2022 22:45:08 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/05/2022 22:45:15 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7506710732517186 on epoch=196
06/05/2022 22:45:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/05/2022 22:45:21 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/05/2022 22:45:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/05/2022 22:45:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/05/2022 22:45:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/05/2022 22:45:35 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9143735744542195 on epoch=199
06/05/2022 22:45:38 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=200
06/05/2022 22:45:41 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/05/2022 22:45:44 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/05/2022 22:45:46 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/05/2022 22:45:49 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/05/2022 22:45:56 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9060034883943803 on epoch=203
06/05/2022 22:45:59 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/05/2022 22:46:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/05/2022 22:46:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/05/2022 22:46:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/05/2022 22:46:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/05/2022 22:46:16 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7993099879247888 on epoch=207
06/05/2022 22:46:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/05/2022 22:46:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/05/2022 22:46:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/05/2022 22:46:27 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/05/2022 22:46:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/05/2022 22:46:36 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9143735744542195 on epoch=210
06/05/2022 22:46:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/05/2022 22:46:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/05/2022 22:46:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/05/2022 22:46:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/05/2022 22:46:50 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
06/05/2022 22:46:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 22:46:51 - INFO - __main__ - Printing 3 examples
06/05/2022 22:46:51 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/05/2022 22:46:51 - INFO - __main__ - ['Plant']
06/05/2022 22:46:51 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/05/2022 22:46:51 - INFO - __main__ - ['Plant']
06/05/2022 22:46:51 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/05/2022 22:46:51 - INFO - __main__ - ['Plant']
06/05/2022 22:46:51 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:46:51 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:46:51 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 22:46:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 22:46:51 - INFO - __main__ - Printing 3 examples
06/05/2022 22:46:51 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/05/2022 22:46:51 - INFO - __main__ - ['Plant']
06/05/2022 22:46:51 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/05/2022 22:46:51 - INFO - __main__ - ['Plant']
06/05/2022 22:46:51 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/05/2022 22:46:51 - INFO - __main__ - ['Plant']
06/05/2022 22:46:51 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:46:52 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:46:52 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 22:46:57 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.859241355083089 on epoch=214
06/05/2022 22:46:57 - INFO - __main__ - save last model!
06/05/2022 22:46:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 22:46:57 - INFO - __main__ - Start tokenizing ... 3500 instances
06/05/2022 22:46:57 - INFO - __main__ - Printing 3 examples
06/05/2022 22:46:57 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/05/2022 22:46:57 - INFO - __main__ - ['Animal']
06/05/2022 22:46:57 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/05/2022 22:46:57 - INFO - __main__ - ['Animal']
06/05/2022 22:46:57 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/05/2022 22:46:57 - INFO - __main__ - ['Village']
06/05/2022 22:46:57 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:46:59 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:47:02 - INFO - __main__ - Loaded 3500 examples from test data
06/05/2022 22:47:11 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 22:47:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 22:47:12 - INFO - __main__ - Starting training!
06/05/2022 22:49:26 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
06/05/2022 22:49:26 - INFO - __main__ - Classification-F1 on test data: 0.6525
06/05/2022 22:49:26 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.9865984150258343, test_performance=0.6524653196548227
06/05/2022 22:49:26 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
06/05/2022 22:49:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 22:49:27 - INFO - __main__ - Printing 3 examples
06/05/2022 22:49:27 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/05/2022 22:49:27 - INFO - __main__ - ['Plant']
06/05/2022 22:49:27 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/05/2022 22:49:27 - INFO - __main__ - ['Plant']
06/05/2022 22:49:27 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/05/2022 22:49:27 - INFO - __main__ - ['Plant']
06/05/2022 22:49:27 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:49:27 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:49:27 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 22:49:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 22:49:27 - INFO - __main__ - Printing 3 examples
06/05/2022 22:49:27 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/05/2022 22:49:27 - INFO - __main__ - ['Plant']
06/05/2022 22:49:27 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/05/2022 22:49:27 - INFO - __main__ - ['Plant']
06/05/2022 22:49:27 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/05/2022 22:49:27 - INFO - __main__ - ['Plant']
06/05/2022 22:49:27 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:49:28 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:49:28 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 22:49:44 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 22:49:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 22:49:45 - INFO - __main__ - Starting training!
06/05/2022 22:49:48 - INFO - __main__ - Step 10 Global step 10 Train loss 6.07 on epoch=0
06/05/2022 22:49:51 - INFO - __main__ - Step 20 Global step 20 Train loss 4.72 on epoch=1
06/05/2022 22:49:54 - INFO - __main__ - Step 30 Global step 30 Train loss 4.08 on epoch=2
06/05/2022 22:49:56 - INFO - __main__ - Step 40 Global step 40 Train loss 3.59 on epoch=2
06/05/2022 22:49:59 - INFO - __main__ - Step 50 Global step 50 Train loss 3.22 on epoch=3
06/05/2022 22:50:06 - INFO - __main__ - Global step 50 Train loss 4.34 Classification-F1 0.020658735829014462 on epoch=3
06/05/2022 22:50:06 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.020658735829014462 on epoch=3, global_step=50
06/05/2022 22:50:08 - INFO - __main__ - Step 60 Global step 60 Train loss 2.85 on epoch=4
06/05/2022 22:50:11 - INFO - __main__ - Step 70 Global step 70 Train loss 2.61 on epoch=4
06/05/2022 22:50:14 - INFO - __main__ - Step 80 Global step 80 Train loss 2.36 on epoch=5
06/05/2022 22:50:17 - INFO - __main__ - Step 90 Global step 90 Train loss 1.99 on epoch=6
06/05/2022 22:50:19 - INFO - __main__ - Step 100 Global step 100 Train loss 2.03 on epoch=7
06/05/2022 22:50:25 - INFO - __main__ - Global step 100 Train loss 2.36 Classification-F1 0.08613565258186265 on epoch=7
06/05/2022 22:50:25 - INFO - __main__ - Saving model with best Classification-F1: 0.020658735829014462 -> 0.08613565258186265 on epoch=7, global_step=100
06/05/2022 22:50:27 - INFO - __main__ - Step 110 Global step 110 Train loss 1.69 on epoch=7
06/05/2022 22:50:30 - INFO - __main__ - Step 120 Global step 120 Train loss 1.64 on epoch=8
06/05/2022 22:50:33 - INFO - __main__ - Step 130 Global step 130 Train loss 1.50 on epoch=9
06/05/2022 22:50:35 - INFO - __main__ - Step 140 Global step 140 Train loss 1.43 on epoch=9
06/05/2022 22:50:38 - INFO - __main__ - Step 150 Global step 150 Train loss 1.39 on epoch=10
06/05/2022 22:50:44 - INFO - __main__ - Global step 150 Train loss 1.53 Classification-F1 0.17443049906472455 on epoch=10
06/05/2022 22:50:44 - INFO - __main__ - Saving model with best Classification-F1: 0.08613565258186265 -> 0.17443049906472455 on epoch=10, global_step=150
06/05/2022 22:50:46 - INFO - __main__ - Step 160 Global step 160 Train loss 1.16 on epoch=11
06/05/2022 22:50:49 - INFO - __main__ - Step 170 Global step 170 Train loss 1.07 on epoch=12
06/05/2022 22:50:52 - INFO - __main__ - Step 180 Global step 180 Train loss 1.14 on epoch=12
06/05/2022 22:50:55 - INFO - __main__ - Step 190 Global step 190 Train loss 0.98 on epoch=13
06/05/2022 22:50:58 - INFO - __main__ - Step 200 Global step 200 Train loss 0.88 on epoch=14
06/05/2022 22:51:05 - INFO - __main__ - Global step 200 Train loss 1.05 Classification-F1 0.37677466587808145 on epoch=14
06/05/2022 22:51:05 - INFO - __main__ - Saving model with best Classification-F1: 0.17443049906472455 -> 0.37677466587808145 on epoch=14, global_step=200
06/05/2022 22:51:08 - INFO - __main__ - Step 210 Global step 210 Train loss 0.94 on epoch=14
06/05/2022 22:51:11 - INFO - __main__ - Step 220 Global step 220 Train loss 0.92 on epoch=15
06/05/2022 22:51:14 - INFO - __main__ - Step 230 Global step 230 Train loss 0.72 on epoch=16
06/05/2022 22:51:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.87 on epoch=17
06/05/2022 22:51:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.76 on epoch=17
06/05/2022 22:51:28 - INFO - __main__ - Global step 250 Train loss 0.84 Classification-F1 0.52766026615833 on epoch=17
06/05/2022 22:51:28 - INFO - __main__ - Saving model with best Classification-F1: 0.37677466587808145 -> 0.52766026615833 on epoch=17, global_step=250
06/05/2022 22:51:31 - INFO - __main__ - Step 260 Global step 260 Train loss 0.73 on epoch=18
06/05/2022 22:51:33 - INFO - __main__ - Step 270 Global step 270 Train loss 0.66 on epoch=19
06/05/2022 22:51:36 - INFO - __main__ - Step 280 Global step 280 Train loss 0.61 on epoch=19
06/05/2022 22:51:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.72 on epoch=20
06/05/2022 22:51:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.60 on epoch=21
06/05/2022 22:51:49 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.6492013200368612 on epoch=21
06/05/2022 22:51:50 - INFO - __main__ - Saving model with best Classification-F1: 0.52766026615833 -> 0.6492013200368612 on epoch=21, global_step=300
06/05/2022 22:51:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.65 on epoch=22
06/05/2022 22:51:55 - INFO - __main__ - Step 320 Global step 320 Train loss 0.49 on epoch=22
06/05/2022 22:51:58 - INFO - __main__ - Step 330 Global step 330 Train loss 0.56 on epoch=23
06/05/2022 22:52:01 - INFO - __main__ - Step 340 Global step 340 Train loss 0.54 on epoch=24
06/05/2022 22:52:03 - INFO - __main__ - Step 350 Global step 350 Train loss 0.52 on epoch=24
06/05/2022 22:52:11 - INFO - __main__ - Global step 350 Train loss 0.55 Classification-F1 0.7083802381976825 on epoch=24
06/05/2022 22:52:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6492013200368612 -> 0.7083802381976825 on epoch=24, global_step=350
06/05/2022 22:52:14 - INFO - __main__ - Step 360 Global step 360 Train loss 0.47 on epoch=25
06/05/2022 22:52:16 - INFO - __main__ - Step 370 Global step 370 Train loss 0.53 on epoch=26
06/05/2022 22:52:19 - INFO - __main__ - Step 380 Global step 380 Train loss 0.46 on epoch=27
06/05/2022 22:52:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.42 on epoch=27
06/05/2022 22:52:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.48 on epoch=28
06/05/2022 22:52:31 - INFO - __main__ - Global step 400 Train loss 0.47 Classification-F1 0.7474044157007866 on epoch=28
06/05/2022 22:52:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7083802381976825 -> 0.7474044157007866 on epoch=28, global_step=400
06/05/2022 22:52:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=29
06/05/2022 22:52:36 - INFO - __main__ - Step 420 Global step 420 Train loss 0.41 on epoch=29
06/05/2022 22:52:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.44 on epoch=30
06/05/2022 22:52:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.42 on epoch=31
06/05/2022 22:52:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.38 on epoch=32
06/05/2022 22:52:51 - INFO - __main__ - Global step 450 Train loss 0.41 Classification-F1 0.710062539394932 on epoch=32
06/05/2022 22:52:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.40 on epoch=32
06/05/2022 22:52:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=33
06/05/2022 22:52:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.40 on epoch=34
06/05/2022 22:53:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.37 on epoch=34
06/05/2022 22:53:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.52 on epoch=35
06/05/2022 22:53:12 - INFO - __main__ - Global step 500 Train loss 0.41 Classification-F1 0.7493151151696879 on epoch=35
06/05/2022 22:53:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7474044157007866 -> 0.7493151151696879 on epoch=35, global_step=500
06/05/2022 22:53:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.34 on epoch=36
06/05/2022 22:53:17 - INFO - __main__ - Step 520 Global step 520 Train loss 0.35 on epoch=37
06/05/2022 22:53:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.37 on epoch=37
06/05/2022 22:53:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.39 on epoch=38
06/05/2022 22:53:26 - INFO - __main__ - Step 550 Global step 550 Train loss 0.33 on epoch=39
06/05/2022 22:53:33 - INFO - __main__ - Global step 550 Train loss 0.36 Classification-F1 0.7175394840243038 on epoch=39
06/05/2022 22:53:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.36 on epoch=39
06/05/2022 22:53:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.37 on epoch=40
06/05/2022 22:53:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.32 on epoch=41
06/05/2022 22:53:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.29 on epoch=42
06/05/2022 22:53:47 - INFO - __main__ - Step 600 Global step 600 Train loss 0.35 on epoch=42
06/05/2022 22:53:54 - INFO - __main__ - Global step 600 Train loss 0.34 Classification-F1 0.6445640998612867 on epoch=42
06/05/2022 22:53:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.30 on epoch=43
06/05/2022 22:54:00 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=44
06/05/2022 22:54:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=44
06/05/2022 22:54:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=45
06/05/2022 22:54:08 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
06/05/2022 22:54:14 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.6184058557507125 on epoch=46
06/05/2022 22:54:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=47
06/05/2022 22:54:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=47
06/05/2022 22:54:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.30 on epoch=48
06/05/2022 22:54:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=49
06/05/2022 22:54:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=49
06/05/2022 22:54:35 - INFO - __main__ - Global step 700 Train loss 0.24 Classification-F1 0.6471356805740038 on epoch=49
06/05/2022 22:54:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=50
06/05/2022 22:54:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=51
06/05/2022 22:54:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=52
06/05/2022 22:54:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=52
06/05/2022 22:54:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=53
06/05/2022 22:54:55 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.5700778522552716 on epoch=53
06/05/2022 22:54:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=54
06/05/2022 22:55:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=54
06/05/2022 22:55:03 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=55
06/05/2022 22:55:06 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=56
06/05/2022 22:55:09 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=57
06/05/2022 22:55:15 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.6178983892634788 on epoch=57
06/05/2022 22:55:18 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=57
06/05/2022 22:55:20 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=58
06/05/2022 22:55:23 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=59
06/05/2022 22:55:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=59
06/05/2022 22:55:28 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=60
06/05/2022 22:55:35 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.6640105363497997 on epoch=60
06/05/2022 22:55:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=61
06/05/2022 22:55:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=62
06/05/2022 22:55:43 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=62
06/05/2022 22:55:46 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=63
06/05/2022 22:55:48 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=64
06/05/2022 22:55:55 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.6095772238514174 on epoch=64
06/05/2022 22:55:57 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=64
06/05/2022 22:56:00 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=65
06/05/2022 22:56:02 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=66
06/05/2022 22:56:05 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=67
06/05/2022 22:56:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=67
06/05/2022 22:56:14 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.6258766639407567 on epoch=67
06/05/2022 22:56:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/05/2022 22:56:19 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
06/05/2022 22:56:22 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
06/05/2022 22:56:25 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=70
06/05/2022 22:56:27 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=71
06/05/2022 22:56:34 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.619117597271101 on epoch=71
06/05/2022 22:56:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=72
06/05/2022 22:56:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=72
06/05/2022 22:56:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=73
06/05/2022 22:56:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
06/05/2022 22:56:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=74
06/05/2022 22:56:54 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.6712076251413045 on epoch=74
06/05/2022 22:56:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=75
06/05/2022 22:56:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=76
06/05/2022 22:57:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
06/05/2022 22:57:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=77
06/05/2022 22:57:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
06/05/2022 22:57:14 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.6792620483573106 on epoch=78
06/05/2022 22:57:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
06/05/2022 22:57:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=79
06/05/2022 22:57:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=80
06/05/2022 22:57:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=81
06/05/2022 22:57:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=82
06/05/2022 22:57:33 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.7233033095936321 on epoch=82
06/05/2022 22:57:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=82
06/05/2022 22:57:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/05/2022 22:57:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=84
06/05/2022 22:57:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=84
06/05/2022 22:57:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=85
06/05/2022 22:57:54 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.7993217585734833 on epoch=85
06/05/2022 22:57:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7493151151696879 -> 0.7993217585734833 on epoch=85, global_step=1200
06/05/2022 22:57:56 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/05/2022 22:57:59 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/05/2022 22:58:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=87
06/05/2022 22:58:04 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=88
06/05/2022 22:58:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
06/05/2022 22:58:14 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.7188850075709659 on epoch=89
06/05/2022 22:58:16 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=89
06/05/2022 22:58:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=90
06/05/2022 22:58:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=91
06/05/2022 22:58:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
06/05/2022 22:58:27 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=92
06/05/2022 22:58:34 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.7573251281897434 on epoch=92
06/05/2022 22:58:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
06/05/2022 22:58:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=94
06/05/2022 22:58:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=94
06/05/2022 22:58:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/05/2022 22:58:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=96
06/05/2022 22:58:54 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.7784869842365097 on epoch=96
06/05/2022 22:58:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=97
06/05/2022 22:58:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
06/05/2022 22:59:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
06/05/2022 22:59:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
06/05/2022 22:59:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
06/05/2022 22:59:13 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7546951566373377 on epoch=99
06/05/2022 22:59:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=100
06/05/2022 22:59:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
06/05/2022 22:59:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
06/05/2022 22:59:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=102
06/05/2022 22:59:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
06/05/2022 22:59:33 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.7429393396328879 on epoch=103
06/05/2022 22:59:36 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/05/2022 22:59:39 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=104
06/05/2022 22:59:41 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
06/05/2022 22:59:44 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
06/05/2022 22:59:47 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=107
06/05/2022 22:59:53 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.7914853437582942 on epoch=107
06/05/2022 22:59:56 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=107
06/05/2022 22:59:59 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
06/05/2022 23:00:01 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=109
06/05/2022 23:00:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=109
06/05/2022 23:00:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.19 on epoch=110
06/05/2022 23:00:13 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.7663148837247509 on epoch=110
06/05/2022 23:00:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=111
06/05/2022 23:00:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/05/2022 23:00:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=112
06/05/2022 23:00:24 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
06/05/2022 23:00:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.20 on epoch=114
06/05/2022 23:00:33 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.8355007636095078 on epoch=114
06/05/2022 23:00:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7993217585734833 -> 0.8355007636095078 on epoch=114, global_step=1600
06/05/2022 23:00:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
06/05/2022 23:00:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.16 on epoch=115
06/05/2022 23:00:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/05/2022 23:00:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
06/05/2022 23:00:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
06/05/2022 23:00:52 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.7794642343741016 on epoch=117
06/05/2022 23:00:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=118
06/05/2022 23:00:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/05/2022 23:01:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=119
06/05/2022 23:01:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=120
06/05/2022 23:01:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
06/05/2022 23:01:12 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.7678882089796177 on epoch=121
06/05/2022 23:01:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
06/05/2022 23:01:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
06/05/2022 23:01:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
06/05/2022 23:01:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/05/2022 23:01:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/05/2022 23:01:31 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7782797136449888 on epoch=124
06/05/2022 23:01:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/05/2022 23:01:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
06/05/2022 23:01:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
06/05/2022 23:01:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
06/05/2022 23:01:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/05/2022 23:01:50 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7200347367686076 on epoch=128
06/05/2022 23:01:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=129
06/05/2022 23:01:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/05/2022 23:01:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=130
06/05/2022 23:02:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=131
06/05/2022 23:02:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=132
06/05/2022 23:02:09 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.8238834921798632 on epoch=132
06/05/2022 23:02:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
06/05/2022 23:02:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=133
06/05/2022 23:02:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=134
06/05/2022 23:02:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/05/2022 23:02:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=135
06/05/2022 23:02:28 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.8128201448911869 on epoch=135
06/05/2022 23:02:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=136
06/05/2022 23:02:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/05/2022 23:02:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=137
06/05/2022 23:02:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
06/05/2022 23:02:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=139
06/05/2022 23:02:47 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.8184943262206101 on epoch=139
06/05/2022 23:02:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/05/2022 23:02:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
06/05/2022 23:02:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/05/2022 23:02:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/05/2022 23:03:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=142
06/05/2022 23:03:07 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8927221018034482 on epoch=142
06/05/2022 23:03:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8355007636095078 -> 0.8927221018034482 on epoch=142, global_step=2000
06/05/2022 23:03:09 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/05/2022 23:03:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/05/2022 23:03:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
06/05/2022 23:03:17 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/05/2022 23:03:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/05/2022 23:03:26 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.8386788643801266 on epoch=146
06/05/2022 23:03:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/05/2022 23:03:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/05/2022 23:03:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=148
06/05/2022 23:03:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=149
06/05/2022 23:03:39 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/05/2022 23:03:45 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9117577762739053 on epoch=149
06/05/2022 23:03:45 - INFO - __main__ - Saving model with best Classification-F1: 0.8927221018034482 -> 0.9117577762739053 on epoch=149, global_step=2100
06/05/2022 23:03:47 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=150
06/05/2022 23:03:50 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.12 on epoch=151
06/05/2022 23:03:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/05/2022 23:03:55 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/05/2022 23:03:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=153
06/05/2022 23:04:04 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.8563649891774892 on epoch=153
06/05/2022 23:04:06 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/05/2022 23:04:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/05/2022 23:04:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=155
06/05/2022 23:04:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=156
06/05/2022 23:04:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/05/2022 23:04:23 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8523289126867757 on epoch=157
06/05/2022 23:04:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/05/2022 23:04:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=158
06/05/2022 23:04:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
06/05/2022 23:04:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
06/05/2022 23:04:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
06/05/2022 23:04:42 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.844818278160012 on epoch=160
06/05/2022 23:04:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.10 on epoch=161
06/05/2022 23:04:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/05/2022 23:04:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/05/2022 23:04:52 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=163
06/05/2022 23:04:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.08 on epoch=164
06/05/2022 23:05:01 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.8444602272727273 on epoch=164
06/05/2022 23:05:04 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/05/2022 23:05:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
06/05/2022 23:05:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=166
06/05/2022 23:05:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/05/2022 23:05:14 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
06/05/2022 23:05:20 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.8366170900178254 on epoch=167
06/05/2022 23:05:23 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/05/2022 23:05:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/05/2022 23:05:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/05/2022 23:05:31 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=170
06/05/2022 23:05:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
06/05/2022 23:05:40 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8508704836829837 on epoch=171
06/05/2022 23:05:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/05/2022 23:05:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=172
06/05/2022 23:05:47 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=173
06/05/2022 23:05:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/05/2022 23:05:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/05/2022 23:05:59 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9117577762739053 on epoch=174
06/05/2022 23:06:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/05/2022 23:06:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=176
06/05/2022 23:06:06 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/05/2022 23:06:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/05/2022 23:06:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/05/2022 23:06:18 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7952297324925408 on epoch=178
06/05/2022 23:06:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=179
06/05/2022 23:06:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/05/2022 23:06:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/05/2022 23:06:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
06/05/2022 23:06:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/05/2022 23:06:37 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.843757484115347 on epoch=182
06/05/2022 23:06:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/05/2022 23:06:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/05/2022 23:06:45 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/05/2022 23:06:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/05/2022 23:06:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
06/05/2022 23:06:56 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8427688341750842 on epoch=185
06/05/2022 23:06:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/05/2022 23:07:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/05/2022 23:07:04 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/05/2022 23:07:07 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/05/2022 23:07:09 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/05/2022 23:07:15 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8387707722385143 on epoch=189
06/05/2022 23:07:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/05/2022 23:07:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=190
06/05/2022 23:07:23 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/05/2022 23:07:26 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/05/2022 23:07:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/05/2022 23:07:35 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8477748707824609 on epoch=192
06/05/2022 23:07:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=193
06/05/2022 23:07:40 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/05/2022 23:07:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/05/2022 23:07:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/05/2022 23:07:48 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=196
06/05/2022 23:07:54 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8516959921798631 on epoch=196
06/05/2022 23:07:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/05/2022 23:07:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.08 on epoch=197
06/05/2022 23:08:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/05/2022 23:08:04 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/05/2022 23:08:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/05/2022 23:08:13 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8466334098346722 on epoch=199
06/05/2022 23:08:15 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/05/2022 23:08:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=201
06/05/2022 23:08:21 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/05/2022 23:08:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/05/2022 23:08:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=203
06/05/2022 23:08:32 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.8595158574997285 on epoch=203
06/05/2022 23:08:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
06/05/2022 23:08:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/05/2022 23:08:40 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.07 on epoch=205
06/05/2022 23:08:43 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/05/2022 23:08:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
06/05/2022 23:08:51 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.8527567862245282 on epoch=207
06/05/2022 23:08:54 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/05/2022 23:08:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/05/2022 23:08:59 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/05/2022 23:09:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/05/2022 23:09:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/05/2022 23:09:11 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9163807429130008 on epoch=210
06/05/2022 23:09:11 - INFO - __main__ - Saving model with best Classification-F1: 0.9117577762739053 -> 0.9163807429130008 on epoch=210, global_step=2950
06/05/2022 23:09:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=211
06/05/2022 23:09:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/05/2022 23:09:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/05/2022 23:09:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/05/2022 23:09:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/05/2022 23:09:25 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 23:09:25 - INFO - __main__ - Printing 3 examples
06/05/2022 23:09:25 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/05/2022 23:09:25 - INFO - __main__ - ['Company']
06/05/2022 23:09:25 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/05/2022 23:09:25 - INFO - __main__ - ['Company']
06/05/2022 23:09:25 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/05/2022 23:09:25 - INFO - __main__ - ['Company']
06/05/2022 23:09:25 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:09:25 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:09:25 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 23:09:25 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 23:09:25 - INFO - __main__ - Printing 3 examples
06/05/2022 23:09:25 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/05/2022 23:09:25 - INFO - __main__ - ['Company']
06/05/2022 23:09:25 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/05/2022 23:09:25 - INFO - __main__ - ['Company']
06/05/2022 23:09:25 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/05/2022 23:09:25 - INFO - __main__ - ['Company']
06/05/2022 23:09:25 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:09:26 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:09:26 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 23:09:30 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9819901200949587 on epoch=214
06/05/2022 23:09:30 - INFO - __main__ - Saving model with best Classification-F1: 0.9163807429130008 -> 0.9819901200949587 on epoch=214, global_step=3000
06/05/2022 23:09:30 - INFO - __main__ - save last model!
06/05/2022 23:09:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 23:09:30 - INFO - __main__ - Start tokenizing ... 3500 instances
06/05/2022 23:09:30 - INFO - __main__ - Printing 3 examples
06/05/2022 23:09:30 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/05/2022 23:09:30 - INFO - __main__ - ['Animal']
06/05/2022 23:09:30 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/05/2022 23:09:30 - INFO - __main__ - ['Animal']
06/05/2022 23:09:30 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/05/2022 23:09:30 - INFO - __main__ - ['Village']
06/05/2022 23:09:30 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:09:32 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:09:36 - INFO - __main__ - Loaded 3500 examples from test data
06/05/2022 23:09:45 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 23:09:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 23:09:46 - INFO - __main__ - Starting training!
06/05/2022 23:11:50 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
06/05/2022 23:11:50 - INFO - __main__ - Classification-F1 on test data: 0.6185
06/05/2022 23:11:51 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.9819901200949587, test_performance=0.6184593951476836
06/05/2022 23:11:51 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
06/05/2022 23:11:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 23:11:52 - INFO - __main__ - Printing 3 examples
06/05/2022 23:11:52 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/05/2022 23:11:52 - INFO - __main__ - ['Company']
06/05/2022 23:11:52 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/05/2022 23:11:52 - INFO - __main__ - ['Company']
06/05/2022 23:11:52 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/05/2022 23:11:52 - INFO - __main__ - ['Company']
06/05/2022 23:11:52 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:11:52 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:11:52 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 23:11:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 23:11:52 - INFO - __main__ - Printing 3 examples
06/05/2022 23:11:52 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/05/2022 23:11:52 - INFO - __main__ - ['Company']
06/05/2022 23:11:52 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/05/2022 23:11:52 - INFO - __main__ - ['Company']
06/05/2022 23:11:52 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/05/2022 23:11:52 - INFO - __main__ - ['Company']
06/05/2022 23:11:52 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:11:52 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:11:52 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 23:12:11 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 23:12:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 23:12:12 - INFO - __main__ - Starting training!
06/05/2022 23:12:16 - INFO - __main__ - Step 10 Global step 10 Train loss 5.34 on epoch=0
06/05/2022 23:12:18 - INFO - __main__ - Step 20 Global step 20 Train loss 3.77 on epoch=1
06/05/2022 23:12:21 - INFO - __main__ - Step 30 Global step 30 Train loss 3.04 on epoch=2
06/05/2022 23:12:24 - INFO - __main__ - Step 40 Global step 40 Train loss 2.36 on epoch=2
06/05/2022 23:12:26 - INFO - __main__ - Step 50 Global step 50 Train loss 1.91 on epoch=3
06/05/2022 23:12:32 - INFO - __main__ - Global step 50 Train loss 3.28 Classification-F1 0.11304288369582924 on epoch=3
06/05/2022 23:12:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11304288369582924 on epoch=3, global_step=50
06/05/2022 23:12:35 - INFO - __main__ - Step 60 Global step 60 Train loss 1.59 on epoch=4
06/05/2022 23:12:37 - INFO - __main__ - Step 70 Global step 70 Train loss 1.26 on epoch=4
06/05/2022 23:12:40 - INFO - __main__ - Step 80 Global step 80 Train loss 1.15 on epoch=5
06/05/2022 23:12:43 - INFO - __main__ - Step 90 Global step 90 Train loss 0.85 on epoch=6
06/05/2022 23:12:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.95 on epoch=7
06/05/2022 23:12:52 - INFO - __main__ - Global step 100 Train loss 1.16 Classification-F1 0.3620171844961761 on epoch=7
06/05/2022 23:12:52 - INFO - __main__ - Saving model with best Classification-F1: 0.11304288369582924 -> 0.3620171844961761 on epoch=7, global_step=100
06/05/2022 23:12:55 - INFO - __main__ - Step 110 Global step 110 Train loss 0.86 on epoch=7
06/05/2022 23:12:58 - INFO - __main__ - Step 120 Global step 120 Train loss 0.72 on epoch=8
06/05/2022 23:13:00 - INFO - __main__ - Step 130 Global step 130 Train loss 0.66 on epoch=9
06/05/2022 23:13:03 - INFO - __main__ - Step 140 Global step 140 Train loss 0.61 on epoch=9
06/05/2022 23:13:06 - INFO - __main__ - Step 150 Global step 150 Train loss 0.61 on epoch=10
06/05/2022 23:13:13 - INFO - __main__ - Global step 150 Train loss 0.69 Classification-F1 0.5901334334265879 on epoch=10
06/05/2022 23:13:13 - INFO - __main__ - Saving model with best Classification-F1: 0.3620171844961761 -> 0.5901334334265879 on epoch=10, global_step=150
06/05/2022 23:13:16 - INFO - __main__ - Step 160 Global step 160 Train loss 0.56 on epoch=11
06/05/2022 23:13:19 - INFO - __main__ - Step 170 Global step 170 Train loss 0.54 on epoch=12
06/05/2022 23:13:21 - INFO - __main__ - Step 180 Global step 180 Train loss 0.59 on epoch=12
06/05/2022 23:13:24 - INFO - __main__ - Step 190 Global step 190 Train loss 0.46 on epoch=13
06/05/2022 23:13:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.51 on epoch=14
06/05/2022 23:13:34 - INFO - __main__ - Global step 200 Train loss 0.53 Classification-F1 0.6236763713205781 on epoch=14
06/05/2022 23:13:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5901334334265879 -> 0.6236763713205781 on epoch=14, global_step=200
06/05/2022 23:13:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.49 on epoch=14
06/05/2022 23:13:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.44 on epoch=15
06/05/2022 23:13:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.36 on epoch=16
06/05/2022 23:13:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.44 on epoch=17
06/05/2022 23:13:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=17
06/05/2022 23:13:55 - INFO - __main__ - Global step 250 Train loss 0.42 Classification-F1 0.6301927892489948 on epoch=17
06/05/2022 23:13:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6236763713205781 -> 0.6301927892489948 on epoch=17, global_step=250
06/05/2022 23:13:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=18
06/05/2022 23:14:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.31 on epoch=19
06/05/2022 23:14:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.41 on epoch=19
06/05/2022 23:14:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.32 on epoch=20
06/05/2022 23:14:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.27 on epoch=21
06/05/2022 23:14:15 - INFO - __main__ - Global step 300 Train loss 0.32 Classification-F1 0.5274357948991379 on epoch=21
06/05/2022 23:14:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.34 on epoch=22
06/05/2022 23:14:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=22
06/05/2022 23:14:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=23
06/05/2022 23:14:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.33 on epoch=24
06/05/2022 23:14:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.27 on epoch=24
06/05/2022 23:14:36 - INFO - __main__ - Global step 350 Train loss 0.30 Classification-F1 0.5225024410703957 on epoch=24
06/05/2022 23:14:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.14 on epoch=25
06/05/2022 23:14:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.33 on epoch=26
06/05/2022 23:14:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.27 on epoch=27
06/05/2022 23:14:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=27
06/05/2022 23:14:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=28
06/05/2022 23:14:55 - INFO - __main__ - Global step 400 Train loss 0.22 Classification-F1 0.5976843835947002 on epoch=28
06/05/2022 23:14:58 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=29
06/05/2022 23:15:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=29
06/05/2022 23:15:03 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=30
06/05/2022 23:15:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=31
06/05/2022 23:15:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=32
06/05/2022 23:15:16 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.6189975508128575 on epoch=32
06/05/2022 23:15:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=32
06/05/2022 23:15:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=33
06/05/2022 23:15:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=34
06/05/2022 23:15:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=34
06/05/2022 23:15:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=35
06/05/2022 23:15:36 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.7493767529820661 on epoch=35
06/05/2022 23:15:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6301927892489948 -> 0.7493767529820661 on epoch=35, global_step=500
06/05/2022 23:15:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=36
06/05/2022 23:15:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=37
06/05/2022 23:15:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=37
06/05/2022 23:15:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=38
06/05/2022 23:15:50 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=39
06/05/2022 23:15:56 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.789512936151839 on epoch=39
06/05/2022 23:15:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7493767529820661 -> 0.789512936151839 on epoch=39, global_step=550
06/05/2022 23:15:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=39
06/05/2022 23:16:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.08 on epoch=40
06/05/2022 23:16:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=41
06/05/2022 23:16:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=42
06/05/2022 23:16:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=42
06/05/2022 23:16:16 - INFO - __main__ - Global step 600 Train loss 0.12 Classification-F1 0.738006094225423 on epoch=42
06/05/2022 23:16:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=43
06/05/2022 23:16:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=44
06/05/2022 23:16:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=44
06/05/2022 23:16:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=45
06/05/2022 23:16:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=46
06/05/2022 23:16:36 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.752755235896226 on epoch=46
06/05/2022 23:16:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=47
06/05/2022 23:16:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.05 on epoch=47
06/05/2022 23:16:44 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=48
06/05/2022 23:16:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.11 on epoch=49
06/05/2022 23:16:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=49
06/05/2022 23:16:56 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.7389167317482729 on epoch=49
06/05/2022 23:16:59 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=50
06/05/2022 23:17:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=51
06/05/2022 23:17:04 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=52
06/05/2022 23:17:07 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
06/05/2022 23:17:10 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=53
06/05/2022 23:17:16 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.7043064129851306 on epoch=53
06/05/2022 23:17:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=54
06/05/2022 23:17:22 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=54
06/05/2022 23:17:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=55
06/05/2022 23:17:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=56
06/05/2022 23:17:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=57
06/05/2022 23:17:37 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.8081865570578519 on epoch=57
06/05/2022 23:17:37 - INFO - __main__ - Saving model with best Classification-F1: 0.789512936151839 -> 0.8081865570578519 on epoch=57, global_step=800
06/05/2022 23:17:40 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=57
06/05/2022 23:17:43 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=58
06/05/2022 23:17:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=59
06/05/2022 23:17:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=59
06/05/2022 23:17:51 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=60
06/05/2022 23:17:57 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.6747907163028131 on epoch=60
06/05/2022 23:18:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=61
06/05/2022 23:18:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=62
06/05/2022 23:18:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
06/05/2022 23:18:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=63
06/05/2022 23:18:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=64
06/05/2022 23:18:17 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.7898459950265879 on epoch=64
06/05/2022 23:18:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=64
06/05/2022 23:18:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=65
06/05/2022 23:18:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=66
06/05/2022 23:18:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=67
06/05/2022 23:18:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=67
06/05/2022 23:18:37 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.7973944010931956 on epoch=67
06/05/2022 23:18:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=68
06/05/2022 23:18:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=69
06/05/2022 23:18:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/05/2022 23:18:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
06/05/2022 23:18:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=71
06/05/2022 23:18:57 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.8009443694676422 on epoch=71
06/05/2022 23:19:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=72
06/05/2022 23:19:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
06/05/2022 23:19:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=73
06/05/2022 23:19:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=74
06/05/2022 23:19:11 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
06/05/2022 23:19:18 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.859103128054741 on epoch=74
06/05/2022 23:19:18 - INFO - __main__ - Saving model with best Classification-F1: 0.8081865570578519 -> 0.859103128054741 on epoch=74, global_step=1050
06/05/2022 23:19:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
06/05/2022 23:19:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
06/05/2022 23:19:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=77
06/05/2022 23:19:29 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=77
06/05/2022 23:19:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
06/05/2022 23:19:38 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.7007484494626641 on epoch=78
06/05/2022 23:19:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=79
06/05/2022 23:19:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
06/05/2022 23:19:46 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=80
06/05/2022 23:19:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
06/05/2022 23:19:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
06/05/2022 23:19:58 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.6818223758876342 on epoch=82
06/05/2022 23:20:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
06/05/2022 23:20:03 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=83
06/05/2022 23:20:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
06/05/2022 23:20:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=84
06/05/2022 23:20:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=85
06/05/2022 23:20:18 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.6943942309904491 on epoch=85
06/05/2022 23:20:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
06/05/2022 23:20:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/05/2022 23:20:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=87
06/05/2022 23:20:29 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=88
06/05/2022 23:20:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
06/05/2022 23:20:38 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.6771638520915496 on epoch=89
06/05/2022 23:20:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
06/05/2022 23:20:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
06/05/2022 23:20:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
06/05/2022 23:20:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=92
06/05/2022 23:20:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
06/05/2022 23:20:58 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7446052647191167 on epoch=92
06/05/2022 23:21:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=93
06/05/2022 23:21:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=94
06/05/2022 23:21:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=94
06/05/2022 23:21:09 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
06/05/2022 23:21:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=96
06/05/2022 23:21:18 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7762876232278508 on epoch=96
06/05/2022 23:21:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=97
06/05/2022 23:21:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
06/05/2022 23:21:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/05/2022 23:21:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
06/05/2022 23:21:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
06/05/2022 23:21:39 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.9185272075594656 on epoch=99
06/05/2022 23:21:39 - INFO - __main__ - Saving model with best Classification-F1: 0.859103128054741 -> 0.9185272075594656 on epoch=99, global_step=1400
06/05/2022 23:21:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
06/05/2022 23:21:44 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
06/05/2022 23:21:47 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/05/2022 23:21:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/05/2022 23:21:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/05/2022 23:21:59 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7993135817376805 on epoch=103
06/05/2022 23:22:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/05/2022 23:22:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
06/05/2022 23:22:07 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
06/05/2022 23:22:09 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/05/2022 23:22:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/05/2022 23:22:18 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7969048596281469 on epoch=107
06/05/2022 23:22:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/05/2022 23:22:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/05/2022 23:22:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/05/2022 23:22:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/05/2022 23:22:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/05/2022 23:22:38 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9228413163897036 on epoch=110
06/05/2022 23:22:38 - INFO - __main__ - Saving model with best Classification-F1: 0.9185272075594656 -> 0.9228413163897036 on epoch=110, global_step=1550
06/05/2022 23:22:41 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
06/05/2022 23:22:44 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=112
06/05/2022 23:22:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
06/05/2022 23:22:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
06/05/2022 23:22:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/05/2022 23:22:58 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9144998370804821 on epoch=114
06/05/2022 23:23:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
06/05/2022 23:23:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
06/05/2022 23:23:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
06/05/2022 23:23:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/05/2022 23:23:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/05/2022 23:23:18 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.9122100032583904 on epoch=117
06/05/2022 23:23:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
06/05/2022 23:23:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
06/05/2022 23:23:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/05/2022 23:23:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/05/2022 23:23:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/05/2022 23:23:38 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7989245824732967 on epoch=121
06/05/2022 23:23:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
06/05/2022 23:23:43 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/05/2022 23:23:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/05/2022 23:23:49 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
06/05/2022 23:23:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/05/2022 23:23:58 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8670576735092864 on epoch=124
06/05/2022 23:24:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
06/05/2022 23:24:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/05/2022 23:24:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=127
06/05/2022 23:24:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/05/2022 23:24:12 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/05/2022 23:24:18 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.8066701167270428 on epoch=128
06/05/2022 23:24:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/05/2022 23:24:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/05/2022 23:24:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/05/2022 23:24:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/05/2022 23:24:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/05/2022 23:24:39 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9228413163897036 on epoch=132
06/05/2022 23:24:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/05/2022 23:24:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/05/2022 23:24:47 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/05/2022 23:24:50 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/05/2022 23:24:52 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=135
06/05/2022 23:24:59 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8630131964809384 on epoch=135
06/05/2022 23:25:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/05/2022 23:25:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/05/2022 23:25:07 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/05/2022 23:25:10 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/05/2022 23:25:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/05/2022 23:25:19 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9143564679048549 on epoch=139
06/05/2022 23:25:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
06/05/2022 23:25:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/05/2022 23:25:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/05/2022 23:25:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/05/2022 23:25:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/05/2022 23:25:38 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9186460429724188 on epoch=142
06/05/2022 23:25:41 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/05/2022 23:25:43 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=144
06/05/2022 23:25:46 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/05/2022 23:25:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/05/2022 23:25:51 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/05/2022 23:25:58 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7901120858900746 on epoch=146
06/05/2022 23:26:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/05/2022 23:26:03 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/05/2022 23:26:06 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/05/2022 23:26:09 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/05/2022 23:26:11 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/05/2022 23:26:18 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.859103128054741 on epoch=149
06/05/2022 23:26:20 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/05/2022 23:26:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/05/2022 23:26:26 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/05/2022 23:26:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/05/2022 23:26:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/05/2022 23:26:38 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8630131964809384 on epoch=153
06/05/2022 23:26:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/05/2022 23:26:43 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/05/2022 23:26:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/05/2022 23:26:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/05/2022 23:26:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=157
06/05/2022 23:26:58 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8589687194525905 on epoch=157
06/05/2022 23:27:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/05/2022 23:27:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/05/2022 23:27:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/05/2022 23:27:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/05/2022 23:27:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
06/05/2022 23:27:18 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.791122170793451 on epoch=160
06/05/2022 23:27:20 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/05/2022 23:27:23 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/05/2022 23:27:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/05/2022 23:27:29 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/05/2022 23:27:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
06/05/2022 23:27:38 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8609970674486804 on epoch=164
06/05/2022 23:27:41 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
06/05/2022 23:27:43 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/05/2022 23:27:46 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/05/2022 23:27:49 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/05/2022 23:27:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
06/05/2022 23:27:58 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9165796210957501 on epoch=167
06/05/2022 23:28:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/05/2022 23:28:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/05/2022 23:28:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/05/2022 23:28:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
06/05/2022 23:28:12 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/05/2022 23:28:18 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7631786908761325 on epoch=171
06/05/2022 23:28:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
06/05/2022 23:28:24 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/05/2022 23:28:26 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/05/2022 23:28:29 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
06/05/2022 23:28:32 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/05/2022 23:28:39 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8031020947278342 on epoch=174
06/05/2022 23:28:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/05/2022 23:28:44 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/05/2022 23:28:47 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
06/05/2022 23:28:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
06/05/2022 23:28:52 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/05/2022 23:28:59 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.8474773679633144 on epoch=178
06/05/2022 23:29:02 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/05/2022 23:29:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
06/05/2022 23:29:08 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/05/2022 23:29:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/05/2022 23:29:13 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
06/05/2022 23:29:20 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9185272075594656 on epoch=182
06/05/2022 23:29:23 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/05/2022 23:29:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
06/05/2022 23:29:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/05/2022 23:29:31 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
06/05/2022 23:29:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/05/2022 23:29:41 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9185272075594656 on epoch=185
06/05/2022 23:29:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
06/05/2022 23:29:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/05/2022 23:29:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/05/2022 23:29:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/05/2022 23:29:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/05/2022 23:30:01 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9179519331243469 on epoch=189
06/05/2022 23:30:03 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/05/2022 23:30:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/05/2022 23:30:09 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/05/2022 23:30:12 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/05/2022 23:30:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/05/2022 23:30:21 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8443304007820136 on epoch=192
06/05/2022 23:30:23 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/05/2022 23:30:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/05/2022 23:30:29 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/05/2022 23:30:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/05/2022 23:30:34 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
06/05/2022 23:30:40 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8670576735092864 on epoch=196
06/05/2022 23:30:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/05/2022 23:30:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/05/2022 23:30:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/05/2022 23:30:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/05/2022 23:30:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
06/05/2022 23:31:00 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9864404412791509 on epoch=199
06/05/2022 23:31:00 - INFO - __main__ - Saving model with best Classification-F1: 0.9228413163897036 -> 0.9864404412791509 on epoch=199, global_step=2800
06/05/2022 23:31:02 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/05/2022 23:31:05 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
06/05/2022 23:31:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/05/2022 23:31:10 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/05/2022 23:31:13 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/05/2022 23:31:19 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9864404412791509 on epoch=203
06/05/2022 23:31:22 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/05/2022 23:31:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/05/2022 23:31:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/05/2022 23:31:30 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/05/2022 23:31:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/05/2022 23:31:39 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9270120560443141 on epoch=207
06/05/2022 23:31:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/05/2022 23:31:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/05/2022 23:31:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/05/2022 23:31:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/05/2022 23:31:52 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/05/2022 23:31:58 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.9864404412791509 on epoch=210
06/05/2022 23:32:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/05/2022 23:32:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/05/2022 23:32:06 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/05/2022 23:32:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/05/2022 23:32:11 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/05/2022 23:32:13 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 23:32:13 - INFO - __main__ - Printing 3 examples
06/05/2022 23:32:13 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/05/2022 23:32:13 - INFO - __main__ - ['Company']
06/05/2022 23:32:13 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/05/2022 23:32:13 - INFO - __main__ - ['Company']
06/05/2022 23:32:13 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/05/2022 23:32:13 - INFO - __main__ - ['Company']
06/05/2022 23:32:13 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:32:13 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:32:13 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 23:32:13 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 23:32:13 - INFO - __main__ - Printing 3 examples
06/05/2022 23:32:13 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/05/2022 23:32:13 - INFO - __main__ - ['Company']
06/05/2022 23:32:13 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/05/2022 23:32:13 - INFO - __main__ - ['Company']
06/05/2022 23:32:13 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/05/2022 23:32:13 - INFO - __main__ - ['Company']
06/05/2022 23:32:13 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:32:13 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:32:13 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 23:32:17 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9864404412791509 on epoch=214
06/05/2022 23:32:17 - INFO - __main__ - save last model!
06/05/2022 23:32:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 23:32:18 - INFO - __main__ - Start tokenizing ... 3500 instances
06/05/2022 23:32:18 - INFO - __main__ - Printing 3 examples
06/05/2022 23:32:18 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/05/2022 23:32:18 - INFO - __main__ - ['Animal']
06/05/2022 23:32:18 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/05/2022 23:32:18 - INFO - __main__ - ['Animal']
06/05/2022 23:32:18 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/05/2022 23:32:18 - INFO - __main__ - ['Village']
06/05/2022 23:32:18 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:32:19 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:32:23 - INFO - __main__ - Loaded 3500 examples from test data
06/05/2022 23:32:32 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 23:32:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 23:32:33 - INFO - __main__ - Starting training!
06/05/2022 23:34:31 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
06/05/2022 23:34:31 - INFO - __main__ - Classification-F1 on test data: 0.6852
06/05/2022 23:34:31 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.9864404412791509, test_performance=0.6851555654242979
06/05/2022 23:34:31 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
06/05/2022 23:34:32 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 23:34:32 - INFO - __main__ - Printing 3 examples
06/05/2022 23:34:32 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/05/2022 23:34:32 - INFO - __main__ - ['Company']
06/05/2022 23:34:32 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/05/2022 23:34:32 - INFO - __main__ - ['Company']
06/05/2022 23:34:32 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/05/2022 23:34:32 - INFO - __main__ - ['Company']
06/05/2022 23:34:32 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:34:32 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:34:32 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 23:34:32 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 23:34:32 - INFO - __main__ - Printing 3 examples
06/05/2022 23:34:32 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/05/2022 23:34:32 - INFO - __main__ - ['Company']
06/05/2022 23:34:32 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/05/2022 23:34:32 - INFO - __main__ - ['Company']
06/05/2022 23:34:32 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/05/2022 23:34:32 - INFO - __main__ - ['Company']
06/05/2022 23:34:32 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:34:33 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:34:33 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 23:34:52 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 23:34:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 23:34:53 - INFO - __main__ - Starting training!
06/05/2022 23:34:56 - INFO - __main__ - Step 10 Global step 10 Train loss 5.51 on epoch=0
06/05/2022 23:34:59 - INFO - __main__ - Step 20 Global step 20 Train loss 4.06 on epoch=1
06/05/2022 23:35:01 - INFO - __main__ - Step 30 Global step 30 Train loss 3.32 on epoch=2
06/05/2022 23:35:04 - INFO - __main__ - Step 40 Global step 40 Train loss 2.68 on epoch=2
06/05/2022 23:35:07 - INFO - __main__ - Step 50 Global step 50 Train loss 2.34 on epoch=3
06/05/2022 23:35:13 - INFO - __main__ - Global step 50 Train loss 3.58 Classification-F1 0.08187001806233823 on epoch=3
06/05/2022 23:35:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08187001806233823 on epoch=3, global_step=50
06/05/2022 23:35:15 - INFO - __main__ - Step 60 Global step 60 Train loss 1.96 on epoch=4
06/05/2022 23:35:18 - INFO - __main__ - Step 70 Global step 70 Train loss 1.71 on epoch=4
06/05/2022 23:35:21 - INFO - __main__ - Step 80 Global step 80 Train loss 1.40 on epoch=5
06/05/2022 23:35:23 - INFO - __main__ - Step 90 Global step 90 Train loss 1.36 on epoch=6
06/05/2022 23:35:26 - INFO - __main__ - Step 100 Global step 100 Train loss 1.10 on epoch=7
06/05/2022 23:35:33 - INFO - __main__ - Global step 100 Train loss 1.50 Classification-F1 0.25402204059139705 on epoch=7
06/05/2022 23:35:33 - INFO - __main__ - Saving model with best Classification-F1: 0.08187001806233823 -> 0.25402204059139705 on epoch=7, global_step=100
06/05/2022 23:35:36 - INFO - __main__ - Step 110 Global step 110 Train loss 0.94 on epoch=7
06/05/2022 23:35:38 - INFO - __main__ - Step 120 Global step 120 Train loss 0.88 on epoch=8
06/05/2022 23:35:41 - INFO - __main__ - Step 130 Global step 130 Train loss 0.79 on epoch=9
06/05/2022 23:35:44 - INFO - __main__ - Step 140 Global step 140 Train loss 0.74 on epoch=9
06/05/2022 23:35:47 - INFO - __main__ - Step 150 Global step 150 Train loss 0.67 on epoch=10
06/05/2022 23:35:53 - INFO - __main__ - Global step 150 Train loss 0.80 Classification-F1 0.42160685762188804 on epoch=10
06/05/2022 23:35:53 - INFO - __main__ - Saving model with best Classification-F1: 0.25402204059139705 -> 0.42160685762188804 on epoch=10, global_step=150
06/05/2022 23:35:56 - INFO - __main__ - Step 160 Global step 160 Train loss 0.77 on epoch=11
06/05/2022 23:35:59 - INFO - __main__ - Step 170 Global step 170 Train loss 0.72 on epoch=12
06/05/2022 23:36:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.66 on epoch=12
06/05/2022 23:36:04 - INFO - __main__ - Step 190 Global step 190 Train loss 0.68 on epoch=13
06/05/2022 23:36:07 - INFO - __main__ - Step 200 Global step 200 Train loss 0.59 on epoch=14
06/05/2022 23:36:15 - INFO - __main__ - Global step 200 Train loss 0.69 Classification-F1 0.6115841255507073 on epoch=14
06/05/2022 23:36:15 - INFO - __main__ - Saving model with best Classification-F1: 0.42160685762188804 -> 0.6115841255507073 on epoch=14, global_step=200
06/05/2022 23:36:17 - INFO - __main__ - Step 210 Global step 210 Train loss 0.57 on epoch=14
06/05/2022 23:36:20 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=15
06/05/2022 23:36:23 - INFO - __main__ - Step 230 Global step 230 Train loss 0.49 on epoch=16
06/05/2022 23:36:25 - INFO - __main__ - Step 240 Global step 240 Train loss 0.69 on epoch=17
06/05/2022 23:36:28 - INFO - __main__ - Step 250 Global step 250 Train loss 0.45 on epoch=17
06/05/2022 23:36:36 - INFO - __main__ - Global step 250 Train loss 0.54 Classification-F1 0.6625333473870116 on epoch=17
06/05/2022 23:36:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6115841255507073 -> 0.6625333473870116 on epoch=17, global_step=250
06/05/2022 23:36:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.44 on epoch=18
06/05/2022 23:36:41 - INFO - __main__ - Step 270 Global step 270 Train loss 0.43 on epoch=19
06/05/2022 23:36:44 - INFO - __main__ - Step 280 Global step 280 Train loss 0.45 on epoch=19
06/05/2022 23:36:46 - INFO - __main__ - Step 290 Global step 290 Train loss 0.38 on epoch=20
06/05/2022 23:36:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.37 on epoch=21
06/05/2022 23:36:57 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.6701958122512551 on epoch=21
06/05/2022 23:36:57 - INFO - __main__ - Saving model with best Classification-F1: 0.6625333473870116 -> 0.6701958122512551 on epoch=21, global_step=300
06/05/2022 23:36:59 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=22
06/05/2022 23:37:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=22
06/05/2022 23:37:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=23
06/05/2022 23:37:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=24
06/05/2022 23:37:10 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=24
06/05/2022 23:37:17 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.694344775362467 on epoch=24
06/05/2022 23:37:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6701958122512551 -> 0.694344775362467 on epoch=24, global_step=350
06/05/2022 23:37:20 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=25
06/05/2022 23:37:23 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=26
06/05/2022 23:37:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.39 on epoch=27
06/05/2022 23:37:28 - INFO - __main__ - Step 390 Global step 390 Train loss 0.37 on epoch=27
06/05/2022 23:37:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.24 on epoch=28
06/05/2022 23:37:38 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.7107766635992443 on epoch=28
06/05/2022 23:37:38 - INFO - __main__ - Saving model with best Classification-F1: 0.694344775362467 -> 0.7107766635992443 on epoch=28, global_step=400
06/05/2022 23:37:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=29
06/05/2022 23:37:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=29
06/05/2022 23:37:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=30
06/05/2022 23:37:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.36 on epoch=31
06/05/2022 23:37:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=32
06/05/2022 23:37:59 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.61011614300755 on epoch=32
06/05/2022 23:38:02 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=32
06/05/2022 23:38:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=33
06/05/2022 23:38:07 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=34
06/05/2022 23:38:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=34
06/05/2022 23:38:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=35
06/05/2022 23:38:19 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.5938501487268091 on epoch=35
06/05/2022 23:38:22 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=36
06/05/2022 23:38:24 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=37
06/05/2022 23:38:27 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=37
06/05/2022 23:38:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=38
06/05/2022 23:38:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.16 on epoch=39
06/05/2022 23:38:39 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.6216261675735788 on epoch=39
06/05/2022 23:38:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=39
06/05/2022 23:38:45 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=40
06/05/2022 23:38:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=41
06/05/2022 23:38:50 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=42
06/05/2022 23:38:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=42
06/05/2022 23:38:59 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.6124688715066912 on epoch=42
06/05/2022 23:39:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=43
06/05/2022 23:39:05 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=44
06/05/2022 23:39:08 - INFO - __main__ - Step 630 Global step 630 Train loss 0.14 on epoch=44
06/05/2022 23:39:10 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=45
06/05/2022 23:39:13 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=46
06/05/2022 23:39:20 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.7618389788733068 on epoch=46
06/05/2022 23:39:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7107766635992443 -> 0.7618389788733068 on epoch=46, global_step=650
06/05/2022 23:39:22 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=47
06/05/2022 23:39:25 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=47
06/05/2022 23:39:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=48
06/05/2022 23:39:30 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
06/05/2022 23:39:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=49
06/05/2022 23:39:39 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.8103343594227185 on epoch=49
06/05/2022 23:39:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7618389788733068 -> 0.8103343594227185 on epoch=49, global_step=700
06/05/2022 23:39:42 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=50
06/05/2022 23:39:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=51
06/05/2022 23:39:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=52
06/05/2022 23:39:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.12 on epoch=52
06/05/2022 23:39:53 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=53
06/05/2022 23:39:59 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.779873034912275 on epoch=53
06/05/2022 23:40:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=54
06/05/2022 23:40:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=54
06/05/2022 23:40:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
06/05/2022 23:40:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=56
06/05/2022 23:40:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=57
06/05/2022 23:40:19 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.7027195510517622 on epoch=57
06/05/2022 23:40:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=57
06/05/2022 23:40:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=58
06/05/2022 23:40:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=59
06/05/2022 23:40:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=59
06/05/2022 23:40:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=60
06/05/2022 23:40:39 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.7834859265822542 on epoch=60
06/05/2022 23:40:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=61
06/05/2022 23:40:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=62
06/05/2022 23:40:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=62
06/05/2022 23:40:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
06/05/2022 23:40:53 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=64
06/05/2022 23:40:59 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.588409186121796 on epoch=64
06/05/2022 23:41:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=64
06/05/2022 23:41:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=65
06/05/2022 23:41:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=66
06/05/2022 23:41:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=67
06/05/2022 23:41:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=67
06/05/2022 23:41:19 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.6930430535840054 on epoch=67
06/05/2022 23:41:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=68
06/05/2022 23:41:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
06/05/2022 23:41:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=69
06/05/2022 23:41:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/05/2022 23:41:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
06/05/2022 23:41:39 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.7506230267075651 on epoch=71
06/05/2022 23:41:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=72
06/05/2022 23:41:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=72
06/05/2022 23:41:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=73
06/05/2022 23:41:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
06/05/2022 23:41:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=74
06/05/2022 23:42:00 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.8465846416051506 on epoch=74
06/05/2022 23:42:00 - INFO - __main__ - Saving model with best Classification-F1: 0.8103343594227185 -> 0.8465846416051506 on epoch=74, global_step=1050
06/05/2022 23:42:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
06/05/2022 23:42:05 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
06/05/2022 23:42:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
06/05/2022 23:42:11 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=77
06/05/2022 23:42:13 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=78
06/05/2022 23:42:20 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.8489841406276334 on epoch=78
06/05/2022 23:42:20 - INFO - __main__ - Saving model with best Classification-F1: 0.8465846416051506 -> 0.8489841406276334 on epoch=78, global_step=1100
06/05/2022 23:42:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
06/05/2022 23:42:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=79
06/05/2022 23:42:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
06/05/2022 23:42:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
06/05/2022 23:42:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=82
06/05/2022 23:42:41 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.8126864999742759 on epoch=82
06/05/2022 23:42:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=82
06/05/2022 23:42:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=83
06/05/2022 23:42:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/05/2022 23:42:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/05/2022 23:42:54 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
06/05/2022 23:43:01 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.6703421554864679 on epoch=85
06/05/2022 23:43:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
06/05/2022 23:43:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=87
06/05/2022 23:43:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
06/05/2022 23:43:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=88
06/05/2022 23:43:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=89
06/05/2022 23:43:21 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.7952715025979342 on epoch=89
06/05/2022 23:43:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
06/05/2022 23:43:26 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
06/05/2022 23:43:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/05/2022 23:43:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/05/2022 23:43:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
06/05/2022 23:43:41 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.6986511904951985 on epoch=92
06/05/2022 23:43:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
06/05/2022 23:43:47 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
06/05/2022 23:43:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=94
06/05/2022 23:43:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
06/05/2022 23:43:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
06/05/2022 23:44:02 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7435742503101297 on epoch=96
06/05/2022 23:44:05 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
06/05/2022 23:44:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
06/05/2022 23:44:10 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
06/05/2022 23:44:13 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
06/05/2022 23:44:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/05/2022 23:44:24 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7487668677880025 on epoch=99
06/05/2022 23:44:27 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/05/2022 23:44:30 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
06/05/2022 23:44:32 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/05/2022 23:44:35 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
06/05/2022 23:44:38 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=103
06/05/2022 23:44:45 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.8400325086046149 on epoch=103
06/05/2022 23:44:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/05/2022 23:44:51 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
06/05/2022 23:44:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/05/2022 23:44:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/05/2022 23:44:59 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
06/05/2022 23:45:05 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.8390833874883759 on epoch=107
06/05/2022 23:45:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/05/2022 23:45:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/05/2022 23:45:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
06/05/2022 23:45:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=109
06/05/2022 23:45:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/05/2022 23:45:26 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7875614209803293 on epoch=110
06/05/2022 23:45:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/05/2022 23:45:31 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
06/05/2022 23:45:34 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
06/05/2022 23:45:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
06/05/2022 23:45:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
06/05/2022 23:45:46 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.8477052349532188 on epoch=114
06/05/2022 23:45:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/05/2022 23:45:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/05/2022 23:45:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.19 on epoch=116
06/05/2022 23:45:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/05/2022 23:45:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/05/2022 23:46:06 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.8496795916150754 on epoch=117
06/05/2022 23:46:06 - INFO - __main__ - Saving model with best Classification-F1: 0.8489841406276334 -> 0.8496795916150754 on epoch=117, global_step=1650
06/05/2022 23:46:09 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/05/2022 23:46:11 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/05/2022 23:46:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/05/2022 23:46:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/05/2022 23:46:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/05/2022 23:46:26 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.905955162764199 on epoch=121
06/05/2022 23:46:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8496795916150754 -> 0.905955162764199 on epoch=121, global_step=1700
06/05/2022 23:46:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/05/2022 23:46:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
06/05/2022 23:46:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/05/2022 23:46:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
06/05/2022 23:46:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=124
06/05/2022 23:46:46 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.804803235749334 on epoch=124
06/05/2022 23:46:48 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/05/2022 23:46:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/05/2022 23:46:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/05/2022 23:46:56 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/05/2022 23:46:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/05/2022 23:47:05 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.859348944856535 on epoch=128
06/05/2022 23:47:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
06/05/2022 23:47:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/05/2022 23:47:14 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/05/2022 23:47:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/05/2022 23:47:19 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/05/2022 23:47:26 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.8956805510300133 on epoch=132
06/05/2022 23:47:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/05/2022 23:47:31 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/05/2022 23:47:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=134
06/05/2022 23:47:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/05/2022 23:47:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
06/05/2022 23:47:46 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.8378810806556811 on epoch=135
06/05/2022 23:47:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
06/05/2022 23:47:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/05/2022 23:47:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
06/05/2022 23:47:57 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/05/2022 23:47:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/05/2022 23:48:07 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.8021764455126085 on epoch=139
06/05/2022 23:48:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/05/2022 23:48:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/05/2022 23:48:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/05/2022 23:48:18 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/05/2022 23:48:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/05/2022 23:48:27 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7520109701826412 on epoch=142
06/05/2022 23:48:30 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/05/2022 23:48:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/05/2022 23:48:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/05/2022 23:48:38 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/05/2022 23:48:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/05/2022 23:48:48 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8426011517701559 on epoch=146
06/05/2022 23:48:51 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/05/2022 23:48:53 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/05/2022 23:48:56 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/05/2022 23:48:59 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/05/2022 23:49:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/05/2022 23:49:08 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8562351626867757 on epoch=149
06/05/2022 23:49:11 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/05/2022 23:49:14 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/05/2022 23:49:16 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=152
06/05/2022 23:49:19 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/05/2022 23:49:22 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/05/2022 23:49:29 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.9054844648615504 on epoch=153
06/05/2022 23:49:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/05/2022 23:49:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/05/2022 23:49:37 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/05/2022 23:49:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
06/05/2022 23:49:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/05/2022 23:49:50 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9910627007401202 on epoch=157
06/05/2022 23:49:50 - INFO - __main__ - Saving model with best Classification-F1: 0.905955162764199 -> 0.9910627007401202 on epoch=157, global_step=2200
06/05/2022 23:49:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/05/2022 23:49:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/05/2022 23:49:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/05/2022 23:50:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/05/2022 23:50:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
06/05/2022 23:50:11 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9777884394226898 on epoch=160
06/05/2022 23:50:14 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/05/2022 23:50:17 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/05/2022 23:50:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/05/2022 23:50:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/05/2022 23:50:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/05/2022 23:50:32 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9822570890526298 on epoch=164
06/05/2022 23:50:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/05/2022 23:50:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/05/2022 23:50:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/05/2022 23:50:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/05/2022 23:50:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/05/2022 23:50:53 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9865677649358864 on epoch=167
06/05/2022 23:50:55 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/05/2022 23:50:58 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/05/2022 23:51:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/05/2022 23:51:04 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/05/2022 23:51:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
06/05/2022 23:51:13 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9822527251369755 on epoch=171
06/05/2022 23:51:16 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/05/2022 23:51:18 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/05/2022 23:51:21 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/05/2022 23:51:24 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/05/2022 23:51:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=174
06/05/2022 23:51:33 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9819805194805193 on epoch=174
06/05/2022 23:51:36 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/05/2022 23:51:38 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/05/2022 23:51:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/05/2022 23:51:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/05/2022 23:51:46 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/05/2022 23:51:53 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9775510891989517 on epoch=178
06/05/2022 23:51:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/05/2022 23:51:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/05/2022 23:52:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/05/2022 23:52:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
06/05/2022 23:52:07 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/05/2022 23:52:14 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9144793763057522 on epoch=182
06/05/2022 23:52:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/05/2022 23:52:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/05/2022 23:52:22 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/05/2022 23:52:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/05/2022 23:52:27 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/05/2022 23:52:34 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9864404412791509 on epoch=185
06/05/2022 23:52:37 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.19 on epoch=186
06/05/2022 23:52:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/05/2022 23:52:42 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/05/2022 23:52:45 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/05/2022 23:52:48 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/05/2022 23:52:55 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.972571667963373 on epoch=189
06/05/2022 23:52:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=189
06/05/2022 23:53:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/05/2022 23:53:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/05/2022 23:53:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/05/2022 23:53:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/05/2022 23:53:15 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9729660293685681 on epoch=192
06/05/2022 23:53:18 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/05/2022 23:53:21 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/05/2022 23:53:23 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/05/2022 23:53:26 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/05/2022 23:53:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
06/05/2022 23:53:36 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9776654796816084 on epoch=196
06/05/2022 23:53:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
06/05/2022 23:53:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/05/2022 23:53:44 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/05/2022 23:53:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/05/2022 23:53:49 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=199
06/05/2022 23:53:56 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9821341293115486 on epoch=199
06/05/2022 23:53:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/05/2022 23:54:02 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/05/2022 23:54:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/05/2022 23:54:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/05/2022 23:54:10 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/05/2022 23:54:17 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9820991153059465 on epoch=203
06/05/2022 23:54:20 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/05/2022 23:54:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/05/2022 23:54:25 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/05/2022 23:54:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/05/2022 23:54:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/05/2022 23:54:38 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9143564679048549 on epoch=207
06/05/2022 23:54:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/05/2022 23:54:43 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/05/2022 23:54:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/05/2022 23:54:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/05/2022 23:54:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
06/05/2022 23:54:59 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9819455054749172 on epoch=210
06/05/2022 23:55:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=211
06/05/2022 23:55:04 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
06/05/2022 23:55:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/05/2022 23:55:09 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/05/2022 23:55:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/05/2022 23:55:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 23:55:14 - INFO - __main__ - Printing 3 examples
06/05/2022 23:55:14 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/05/2022 23:55:14 - INFO - __main__ - ['Company']
06/05/2022 23:55:14 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/05/2022 23:55:14 - INFO - __main__ - ['Company']
06/05/2022 23:55:14 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/05/2022 23:55:14 - INFO - __main__ - ['Company']
06/05/2022 23:55:14 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:55:14 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:55:14 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 23:55:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 23:55:14 - INFO - __main__ - Printing 3 examples
06/05/2022 23:55:14 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/05/2022 23:55:14 - INFO - __main__ - ['Company']
06/05/2022 23:55:14 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/05/2022 23:55:14 - INFO - __main__ - ['Company']
06/05/2022 23:55:14 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/05/2022 23:55:14 - INFO - __main__ - ['Company']
06/05/2022 23:55:14 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:55:14 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:55:14 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 23:55:19 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9865677649358864 on epoch=214
06/05/2022 23:55:19 - INFO - __main__ - save last model!
06/05/2022 23:55:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 23:55:19 - INFO - __main__ - Start tokenizing ... 3500 instances
06/05/2022 23:55:19 - INFO - __main__ - Printing 3 examples
06/05/2022 23:55:19 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/05/2022 23:55:19 - INFO - __main__ - ['Animal']
06/05/2022 23:55:19 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/05/2022 23:55:19 - INFO - __main__ - ['Animal']
06/05/2022 23:55:19 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/05/2022 23:55:19 - INFO - __main__ - ['Village']
06/05/2022 23:55:19 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:55:21 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:55:25 - INFO - __main__ - Loaded 3500 examples from test data
06/05/2022 23:55:34 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 23:55:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 23:55:35 - INFO - __main__ - Starting training!
06/05/2022 23:57:39 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
06/05/2022 23:57:39 - INFO - __main__ - Classification-F1 on test data: 0.6833
06/05/2022 23:57:40 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.9910627007401202, test_performance=0.6833272827283042
06/05/2022 23:57:40 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
06/05/2022 23:57:41 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 23:57:41 - INFO - __main__ - Printing 3 examples
06/05/2022 23:57:41 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/05/2022 23:57:41 - INFO - __main__ - ['Company']
06/05/2022 23:57:41 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/05/2022 23:57:41 - INFO - __main__ - ['Company']
06/05/2022 23:57:41 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/05/2022 23:57:41 - INFO - __main__ - ['Company']
06/05/2022 23:57:41 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:57:41 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:57:41 - INFO - __main__ - Loaded 224 examples from train data
06/05/2022 23:57:41 - INFO - __main__ - Start tokenizing ... 224 instances
06/05/2022 23:57:41 - INFO - __main__ - Printing 3 examples
06/05/2022 23:57:41 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/05/2022 23:57:41 - INFO - __main__ - ['Company']
06/05/2022 23:57:41 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/05/2022 23:57:41 - INFO - __main__ - ['Company']
06/05/2022 23:57:41 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/05/2022 23:57:41 - INFO - __main__ - ['Company']
06/05/2022 23:57:41 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:57:41 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:57:41 - INFO - __main__ - Loaded 224 examples from dev data
06/05/2022 23:57:57 - INFO - __main__ - load prompt embedding from ckpt
06/05/2022 23:57:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 23:57:57 - INFO - __main__ - Starting training!
06/05/2022 23:58:01 - INFO - __main__ - Step 10 Global step 10 Train loss 5.59 on epoch=0
06/05/2022 23:58:04 - INFO - __main__ - Step 20 Global step 20 Train loss 4.42 on epoch=1
06/05/2022 23:58:07 - INFO - __main__ - Step 30 Global step 30 Train loss 3.68 on epoch=2
06/05/2022 23:58:09 - INFO - __main__ - Step 40 Global step 40 Train loss 3.17 on epoch=2
06/05/2022 23:58:12 - INFO - __main__ - Step 50 Global step 50 Train loss 2.67 on epoch=3
06/05/2022 23:58:18 - INFO - __main__ - Global step 50 Train loss 3.91 Classification-F1 0.06393508253264352 on epoch=3
06/05/2022 23:58:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06393508253264352 on epoch=3, global_step=50
06/05/2022 23:58:20 - INFO - __main__ - Step 60 Global step 60 Train loss 2.45 on epoch=4
06/05/2022 23:58:23 - INFO - __main__ - Step 70 Global step 70 Train loss 2.08 on epoch=4
06/05/2022 23:58:26 - INFO - __main__ - Step 80 Global step 80 Train loss 1.96 on epoch=5
06/05/2022 23:58:29 - INFO - __main__ - Step 90 Global step 90 Train loss 1.74 on epoch=6
06/05/2022 23:58:31 - INFO - __main__ - Step 100 Global step 100 Train loss 1.48 on epoch=7
06/05/2022 23:58:37 - INFO - __main__ - Global step 100 Train loss 1.94 Classification-F1 0.15995543759290562 on epoch=7
06/05/2022 23:58:37 - INFO - __main__ - Saving model with best Classification-F1: 0.06393508253264352 -> 0.15995543759290562 on epoch=7, global_step=100
06/05/2022 23:58:40 - INFO - __main__ - Step 110 Global step 110 Train loss 1.37 on epoch=7
06/05/2022 23:58:43 - INFO - __main__ - Step 120 Global step 120 Train loss 1.18 on epoch=8
06/05/2022 23:58:45 - INFO - __main__ - Step 130 Global step 130 Train loss 1.14 on epoch=9
06/05/2022 23:58:48 - INFO - __main__ - Step 140 Global step 140 Train loss 1.08 on epoch=9
06/05/2022 23:58:51 - INFO - __main__ - Step 150 Global step 150 Train loss 0.97 on epoch=10
06/05/2022 23:58:57 - INFO - __main__ - Global step 150 Train loss 1.15 Classification-F1 0.3710802820234886 on epoch=10
06/05/2022 23:58:58 - INFO - __main__ - Saving model with best Classification-F1: 0.15995543759290562 -> 0.3710802820234886 on epoch=10, global_step=150
06/05/2022 23:59:00 - INFO - __main__ - Step 160 Global step 160 Train loss 0.95 on epoch=11
06/05/2022 23:59:03 - INFO - __main__ - Step 170 Global step 170 Train loss 0.86 on epoch=12
06/05/2022 23:59:06 - INFO - __main__ - Step 180 Global step 180 Train loss 0.82 on epoch=12
06/05/2022 23:59:08 - INFO - __main__ - Step 190 Global step 190 Train loss 0.85 on epoch=13
06/05/2022 23:59:11 - INFO - __main__ - Step 200 Global step 200 Train loss 0.74 on epoch=14
06/05/2022 23:59:18 - INFO - __main__ - Global step 200 Train loss 0.84 Classification-F1 0.5250754791261084 on epoch=14
06/05/2022 23:59:18 - INFO - __main__ - Saving model with best Classification-F1: 0.3710802820234886 -> 0.5250754791261084 on epoch=14, global_step=200
06/05/2022 23:59:21 - INFO - __main__ - Step 210 Global step 210 Train loss 0.71 on epoch=14
06/05/2022 23:59:23 - INFO - __main__ - Step 220 Global step 220 Train loss 0.68 on epoch=15
06/05/2022 23:59:26 - INFO - __main__ - Step 230 Global step 230 Train loss 0.62 on epoch=16
06/05/2022 23:59:29 - INFO - __main__ - Step 240 Global step 240 Train loss 0.69 on epoch=17
06/05/2022 23:59:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.60 on epoch=17
06/05/2022 23:59:39 - INFO - __main__ - Global step 250 Train loss 0.66 Classification-F1 0.5280307237565302 on epoch=17
06/05/2022 23:59:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5250754791261084 -> 0.5280307237565302 on epoch=17, global_step=250
06/05/2022 23:59:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.57 on epoch=18
06/05/2022 23:59:44 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=19
06/05/2022 23:59:47 - INFO - __main__ - Step 280 Global step 280 Train loss 0.54 on epoch=19
06/05/2022 23:59:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=20
06/05/2022 23:59:52 - INFO - __main__ - Step 300 Global step 300 Train loss 0.49 on epoch=21
06/06/2022 00:00:00 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.5928287317863153 on epoch=21
06/06/2022 00:00:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5280307237565302 -> 0.5928287317863153 on epoch=21, global_step=300
06/06/2022 00:00:02 - INFO - __main__ - Step 310 Global step 310 Train loss 0.51 on epoch=22
06/06/2022 00:00:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.51 on epoch=22
06/06/2022 00:00:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=23
06/06/2022 00:00:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=24
06/06/2022 00:00:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.46 on epoch=24
06/06/2022 00:00:21 - INFO - __main__ - Global step 350 Train loss 0.50 Classification-F1 0.5548871522458183 on epoch=24
06/06/2022 00:00:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.46 on epoch=25
06/06/2022 00:00:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=26
06/06/2022 00:00:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.53 on epoch=27
06/06/2022 00:00:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.40 on epoch=27
06/06/2022 00:00:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.37 on epoch=28
06/06/2022 00:00:42 - INFO - __main__ - Global step 400 Train loss 0.43 Classification-F1 0.6282344839820123 on epoch=28
06/06/2022 00:00:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5928287317863153 -> 0.6282344839820123 on epoch=28, global_step=400
06/06/2022 00:00:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.42 on epoch=29
06/06/2022 00:00:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.42 on epoch=29
06/06/2022 00:00:50 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=30
06/06/2022 00:00:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.36 on epoch=31
06/06/2022 00:00:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=32
06/06/2022 00:01:03 - INFO - __main__ - Global step 450 Train loss 0.38 Classification-F1 0.6686457036591444 on epoch=32
06/06/2022 00:01:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6282344839820123 -> 0.6686457036591444 on epoch=32, global_step=450
06/06/2022 00:01:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=32
06/06/2022 00:01:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=33
06/06/2022 00:01:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=34
06/06/2022 00:01:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.35 on epoch=34
06/06/2022 00:01:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=35
06/06/2022 00:01:24 - INFO - __main__ - Global step 500 Train loss 0.31 Classification-F1 0.7156606317317097 on epoch=35
06/06/2022 00:01:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6686457036591444 -> 0.7156606317317097 on epoch=35, global_step=500
06/06/2022 00:01:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.34 on epoch=36
06/06/2022 00:01:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=37
06/06/2022 00:01:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.30 on epoch=37
06/06/2022 00:01:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=38
06/06/2022 00:01:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.35 on epoch=39
06/06/2022 00:01:45 - INFO - __main__ - Global step 550 Train loss 0.32 Classification-F1 0.6641480419469035 on epoch=39
06/06/2022 00:01:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.29 on epoch=39
06/06/2022 00:01:51 - INFO - __main__ - Step 570 Global step 570 Train loss 0.28 on epoch=40
06/06/2022 00:01:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=41
06/06/2022 00:01:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=42
06/06/2022 00:01:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.28 on epoch=42
06/06/2022 00:02:07 - INFO - __main__ - Global step 600 Train loss 0.27 Classification-F1 0.6536687074778714 on epoch=42
06/06/2022 00:02:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=43
06/06/2022 00:02:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=44
06/06/2022 00:02:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=44
06/06/2022 00:02:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=45
06/06/2022 00:02:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=46
06/06/2022 00:02:28 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.684630328378124 on epoch=46
06/06/2022 00:02:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=47
06/06/2022 00:02:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=47
06/06/2022 00:02:36 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=48
06/06/2022 00:02:39 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=49
06/06/2022 00:02:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.30 on epoch=49
06/06/2022 00:02:49 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.6164942792258883 on epoch=49
06/06/2022 00:02:52 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=50
06/06/2022 00:02:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.25 on epoch=51
06/06/2022 00:02:57 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=52
06/06/2022 00:03:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=52
06/06/2022 00:03:03 - INFO - __main__ - Step 750 Global step 750 Train loss 0.24 on epoch=53
06/06/2022 00:03:11 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.6924338411371935 on epoch=53
06/06/2022 00:03:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=54
06/06/2022 00:03:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=54
06/06/2022 00:03:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=55
06/06/2022 00:03:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=56
06/06/2022 00:03:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=57
06/06/2022 00:03:33 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.7408075736766482 on epoch=57
06/06/2022 00:03:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7156606317317097 -> 0.7408075736766482 on epoch=57, global_step=800
06/06/2022 00:03:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=57
06/06/2022 00:03:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=58
06/06/2022 00:03:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=59
06/06/2022 00:03:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=59
06/06/2022 00:03:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=60
06/06/2022 00:03:54 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.6894470864572725 on epoch=60
06/06/2022 00:03:56 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=61
06/06/2022 00:03:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.28 on epoch=62
06/06/2022 00:04:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=62
06/06/2022 00:04:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=63
06/06/2022 00:04:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=64
06/06/2022 00:04:15 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.7501118900749539 on epoch=64
06/06/2022 00:04:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7408075736766482 -> 0.7501118900749539 on epoch=64, global_step=900
06/06/2022 00:04:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.21 on epoch=64
06/06/2022 00:04:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=65
06/06/2022 00:04:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=66
06/06/2022 00:04:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=67
06/06/2022 00:04:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=67
06/06/2022 00:04:36 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.6409426830922081 on epoch=67
06/06/2022 00:04:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=68
06/06/2022 00:04:41 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=69
06/06/2022 00:04:44 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=69
06/06/2022 00:04:47 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=70
06/06/2022 00:04:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=71
06/06/2022 00:04:57 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.713718053975719 on epoch=71
06/06/2022 00:05:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=72
06/06/2022 00:05:02 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=72
06/06/2022 00:05:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=73
06/06/2022 00:05:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=74
06/06/2022 00:05:11 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=74
06/06/2022 00:05:18 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.7452340130049842 on epoch=74
06/06/2022 00:05:20 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=75
06/06/2022 00:05:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=76
06/06/2022 00:05:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
06/06/2022 00:05:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/06/2022 00:05:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=78
06/06/2022 00:05:39 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.7982205213076885 on epoch=78
06/06/2022 00:05:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7501118900749539 -> 0.7982205213076885 on epoch=78, global_step=1100
06/06/2022 00:05:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=79
06/06/2022 00:05:44 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=79
06/06/2022 00:05:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/06/2022 00:05:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
06/06/2022 00:05:52 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
06/06/2022 00:06:00 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7926212762620767 on epoch=82
06/06/2022 00:06:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
06/06/2022 00:06:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=83
06/06/2022 00:06:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/06/2022 00:06:11 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=84
06/06/2022 00:06:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
06/06/2022 00:06:20 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.7539450867593247 on epoch=85
06/06/2022 00:06:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/06/2022 00:06:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=87
06/06/2022 00:06:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/06/2022 00:06:31 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=88
06/06/2022 00:06:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
06/06/2022 00:06:41 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.7483887018925951 on epoch=89
06/06/2022 00:06:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
06/06/2022 00:06:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=90
06/06/2022 00:06:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
06/06/2022 00:06:52 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=92
06/06/2022 00:06:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
06/06/2022 00:07:02 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.8462153644954797 on epoch=92
06/06/2022 00:07:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7982205213076885 -> 0.8462153644954797 on epoch=92, global_step=1300
06/06/2022 00:07:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
06/06/2022 00:07:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=94
06/06/2022 00:07:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=94
06/06/2022 00:07:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=95
06/06/2022 00:07:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=96
06/06/2022 00:07:22 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.7893937442547779 on epoch=96
06/06/2022 00:07:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=97
06/06/2022 00:07:28 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
06/06/2022 00:07:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
06/06/2022 00:07:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
06/06/2022 00:07:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/06/2022 00:07:43 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7963229881008573 on epoch=99
06/06/2022 00:07:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/06/2022 00:07:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
06/06/2022 00:07:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
06/06/2022 00:07:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
06/06/2022 00:07:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/06/2022 00:08:03 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.8505723580766111 on epoch=103
06/06/2022 00:08:03 - INFO - __main__ - Saving model with best Classification-F1: 0.8462153644954797 -> 0.8505723580766111 on epoch=103, global_step=1450
06/06/2022 00:08:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=104
06/06/2022 00:08:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/06/2022 00:08:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/06/2022 00:08:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
06/06/2022 00:08:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
06/06/2022 00:08:24 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.8996201100185921 on epoch=107
06/06/2022 00:08:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8505723580766111 -> 0.8996201100185921 on epoch=107, global_step=1500
06/06/2022 00:08:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/06/2022 00:08:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
06/06/2022 00:08:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/06/2022 00:08:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=109
06/06/2022 00:08:37 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/06/2022 00:08:45 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.9062434504481222 on epoch=110
06/06/2022 00:08:45 - INFO - __main__ - Saving model with best Classification-F1: 0.8996201100185921 -> 0.9062434504481222 on epoch=110, global_step=1550
06/06/2022 00:08:47 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=111
06/06/2022 00:08:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
06/06/2022 00:08:53 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/06/2022 00:08:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
06/06/2022 00:08:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/06/2022 00:09:05 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7938114558203777 on epoch=114
06/06/2022 00:09:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
06/06/2022 00:09:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/06/2022 00:09:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/06/2022 00:09:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=117
06/06/2022 00:09:19 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/06/2022 00:09:26 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.841553732817719 on epoch=117
06/06/2022 00:09:29 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
06/06/2022 00:09:31 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/06/2022 00:09:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/06/2022 00:09:37 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/06/2022 00:09:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/06/2022 00:09:47 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.8249473249710442 on epoch=121
06/06/2022 00:09:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
06/06/2022 00:09:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/06/2022 00:09:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/06/2022 00:09:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
06/06/2022 00:10:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/06/2022 00:10:07 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8335884059244983 on epoch=124
06/06/2022 00:10:09 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/06/2022 00:10:12 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/06/2022 00:10:15 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
06/06/2022 00:10:17 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=127
06/06/2022 00:10:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=128
06/06/2022 00:10:26 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.8342535008969937 on epoch=128
06/06/2022 00:10:29 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/06/2022 00:10:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/06/2022 00:10:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/06/2022 00:10:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
06/06/2022 00:10:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/06/2022 00:10:46 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.8389874515111707 on epoch=132
06/06/2022 00:10:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
06/06/2022 00:10:51 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
06/06/2022 00:10:54 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/06/2022 00:10:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/06/2022 00:10:59 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/06/2022 00:11:05 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.7949753977837469 on epoch=135
06/06/2022 00:11:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/06/2022 00:11:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/06/2022 00:11:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/06/2022 00:11:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/06/2022 00:11:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/06/2022 00:11:25 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7877800381066218 on epoch=139
06/06/2022 00:11:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/06/2022 00:11:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/06/2022 00:11:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/06/2022 00:11:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/06/2022 00:11:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/06/2022 00:11:45 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7955735422124451 on epoch=142
06/06/2022 00:11:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/06/2022 00:11:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/06/2022 00:11:52 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
06/06/2022 00:11:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/06/2022 00:11:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=146
06/06/2022 00:12:04 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8550217462857325 on epoch=146
06/06/2022 00:12:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/06/2022 00:12:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/06/2022 00:12:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
06/06/2022 00:12:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/06/2022 00:12:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/06/2022 00:12:24 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.8528712086513239 on epoch=149
06/06/2022 00:12:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/06/2022 00:12:29 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/06/2022 00:12:32 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
06/06/2022 00:12:34 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/06/2022 00:12:37 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/06/2022 00:12:43 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7945404569065616 on epoch=153
06/06/2022 00:12:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/06/2022 00:12:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/06/2022 00:12:51 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/06/2022 00:12:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
06/06/2022 00:12:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/06/2022 00:13:03 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9038570237479157 on epoch=157
06/06/2022 00:13:06 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/06/2022 00:13:08 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/06/2022 00:13:11 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/06/2022 00:13:13 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/06/2022 00:13:16 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/06/2022 00:13:23 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8551700592260365 on epoch=160
06/06/2022 00:13:26 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/06/2022 00:13:28 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/06/2022 00:13:31 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=162
06/06/2022 00:13:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/06/2022 00:13:36 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/06/2022 00:13:42 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.844511752016005 on epoch=164
06/06/2022 00:13:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/06/2022 00:13:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/06/2022 00:13:50 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/06/2022 00:13:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/06/2022 00:13:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/06/2022 00:14:01 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7920505720637355 on epoch=167
06/06/2022 00:14:04 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/06/2022 00:14:07 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/06/2022 00:14:09 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
06/06/2022 00:14:12 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/06/2022 00:14:14 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=171
06/06/2022 00:14:21 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8424364613880744 on epoch=171
06/06/2022 00:14:23 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/06/2022 00:14:26 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/06/2022 00:14:29 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/06/2022 00:14:31 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/06/2022 00:14:34 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/06/2022 00:14:40 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8424364613880744 on epoch=174
06/06/2022 00:14:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
06/06/2022 00:14:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/06/2022 00:14:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/06/2022 00:14:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/06/2022 00:14:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=178
06/06/2022 00:15:00 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7986730537015168 on epoch=178
06/06/2022 00:15:02 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
06/06/2022 00:15:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/06/2022 00:15:07 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=180
06/06/2022 00:15:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/06/2022 00:15:13 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/06/2022 00:15:19 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7406610412617086 on epoch=182
06/06/2022 00:15:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/06/2022 00:15:25 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=183
06/06/2022 00:15:27 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/06/2022 00:15:30 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/06/2022 00:15:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/06/2022 00:15:39 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7568347754727683 on epoch=185
06/06/2022 00:15:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/06/2022 00:15:45 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/06/2022 00:15:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/06/2022 00:15:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/06/2022 00:15:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/06/2022 00:16:00 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7955559936584604 on epoch=189
06/06/2022 00:16:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/06/2022 00:16:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/06/2022 00:16:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/06/2022 00:16:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/06/2022 00:16:13 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/06/2022 00:16:20 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7227954786143624 on epoch=192
06/06/2022 00:16:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/06/2022 00:16:25 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/06/2022 00:16:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/06/2022 00:16:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/06/2022 00:16:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
06/06/2022 00:16:40 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7020107799254908 on epoch=196
06/06/2022 00:16:42 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/06/2022 00:16:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/06/2022 00:16:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/06/2022 00:16:50 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
06/06/2022 00:16:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/06/2022 00:16:59 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.85264073371284 on epoch=199
06/06/2022 00:17:02 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/06/2022 00:17:05 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/06/2022 00:17:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/06/2022 00:17:10 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/06/2022 00:17:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/06/2022 00:17:20 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7987922455985779 on epoch=203
06/06/2022 00:17:22 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/06/2022 00:17:25 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/06/2022 00:17:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/06/2022 00:17:30 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/06/2022 00:17:33 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=207
06/06/2022 00:17:40 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8464318147119299 on epoch=207
06/06/2022 00:17:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/06/2022 00:17:45 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/06/2022 00:17:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/06/2022 00:17:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/06/2022 00:17:53 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/06/2022 00:18:00 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7985305168803943 on epoch=210
06/06/2022 00:18:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/06/2022 00:18:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/06/2022 00:18:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/06/2022 00:18:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/06/2022 00:18:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/06/2022 00:18:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 00:18:14 - INFO - __main__ - Printing 3 examples
06/06/2022 00:18:14 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/06/2022 00:18:14 - INFO - __main__ - ['Company']
06/06/2022 00:18:14 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/06/2022 00:18:14 - INFO - __main__ - ['Company']
06/06/2022 00:18:14 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/06/2022 00:18:14 - INFO - __main__ - ['Company']
06/06/2022 00:18:14 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:18:14 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:18:15 - INFO - __main__ - Loaded 224 examples from train data
06/06/2022 00:18:15 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 00:18:15 - INFO - __main__ - Printing 3 examples
06/06/2022 00:18:15 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/06/2022 00:18:15 - INFO - __main__ - ['Company']
06/06/2022 00:18:15 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/06/2022 00:18:15 - INFO - __main__ - ['Company']
06/06/2022 00:18:15 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/06/2022 00:18:15 - INFO - __main__ - ['Company']
06/06/2022 00:18:15 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:18:15 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:18:15 - INFO - __main__ - Loaded 224 examples from dev data
06/06/2022 00:18:20 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8039988975669143 on epoch=214
06/06/2022 00:18:20 - INFO - __main__ - save last model!
06/06/2022 00:18:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 00:18:20 - INFO - __main__ - Start tokenizing ... 3500 instances
06/06/2022 00:18:20 - INFO - __main__ - Printing 3 examples
06/06/2022 00:18:20 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/06/2022 00:18:20 - INFO - __main__ - ['Animal']
06/06/2022 00:18:20 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/06/2022 00:18:20 - INFO - __main__ - ['Animal']
06/06/2022 00:18:20 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/06/2022 00:18:20 - INFO - __main__ - ['Village']
06/06/2022 00:18:20 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:18:22 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:18:25 - INFO - __main__ - Loaded 3500 examples from test data
06/06/2022 00:18:31 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 00:18:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 00:18:32 - INFO - __main__ - Starting training!
06/06/2022 00:20:43 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
06/06/2022 00:20:43 - INFO - __main__ - Classification-F1 on test data: 0.6404
06/06/2022 00:20:43 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.9062434504481222, test_performance=0.6404329737094935
06/06/2022 00:20:43 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
06/06/2022 00:20:44 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 00:20:44 - INFO - __main__ - Printing 3 examples
06/06/2022 00:20:44 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/06/2022 00:20:44 - INFO - __main__ - ['Company']
06/06/2022 00:20:44 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/06/2022 00:20:44 - INFO - __main__ - ['Company']
06/06/2022 00:20:44 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/06/2022 00:20:44 - INFO - __main__ - ['Company']
06/06/2022 00:20:44 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:20:44 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:20:44 - INFO - __main__ - Loaded 224 examples from train data
06/06/2022 00:20:44 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 00:20:44 - INFO - __main__ - Printing 3 examples
06/06/2022 00:20:44 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/06/2022 00:20:44 - INFO - __main__ - ['Company']
06/06/2022 00:20:44 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/06/2022 00:20:44 - INFO - __main__ - ['Company']
06/06/2022 00:20:44 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/06/2022 00:20:44 - INFO - __main__ - ['Company']
06/06/2022 00:20:44 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:20:45 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:20:45 - INFO - __main__ - Loaded 224 examples from dev data
06/06/2022 00:21:00 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 00:21:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 00:21:01 - INFO - __main__ - Starting training!
06/06/2022 00:21:05 - INFO - __main__ - Step 10 Global step 10 Train loss 6.04 on epoch=0
06/06/2022 00:21:07 - INFO - __main__ - Step 20 Global step 20 Train loss 5.04 on epoch=1
06/06/2022 00:21:10 - INFO - __main__ - Step 30 Global step 30 Train loss 4.32 on epoch=2
06/06/2022 00:21:13 - INFO - __main__ - Step 40 Global step 40 Train loss 3.73 on epoch=2
06/06/2022 00:21:16 - INFO - __main__ - Step 50 Global step 50 Train loss 3.31 on epoch=3
06/06/2022 00:21:22 - INFO - __main__ - Global step 50 Train loss 4.49 Classification-F1 0.026339758418076887 on epoch=3
06/06/2022 00:21:22 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.026339758418076887 on epoch=3, global_step=50
06/06/2022 00:21:25 - INFO - __main__ - Step 60 Global step 60 Train loss 3.16 on epoch=4
06/06/2022 00:21:27 - INFO - __main__ - Step 70 Global step 70 Train loss 2.80 on epoch=4
06/06/2022 00:21:30 - INFO - __main__ - Step 80 Global step 80 Train loss 2.39 on epoch=5
06/06/2022 00:21:33 - INFO - __main__ - Step 90 Global step 90 Train loss 2.21 on epoch=6
06/06/2022 00:21:35 - INFO - __main__ - Step 100 Global step 100 Train loss 2.07 on epoch=7
06/06/2022 00:21:41 - INFO - __main__ - Global step 100 Train loss 2.53 Classification-F1 0.07235657998506845 on epoch=7
06/06/2022 00:21:41 - INFO - __main__ - Saving model with best Classification-F1: 0.026339758418076887 -> 0.07235657998506845 on epoch=7, global_step=100
06/06/2022 00:21:44 - INFO - __main__ - Step 110 Global step 110 Train loss 1.94 on epoch=7
06/06/2022 00:21:47 - INFO - __main__ - Step 120 Global step 120 Train loss 1.79 on epoch=8
06/06/2022 00:21:49 - INFO - __main__ - Step 130 Global step 130 Train loss 1.65 on epoch=9
06/06/2022 00:21:52 - INFO - __main__ - Step 140 Global step 140 Train loss 1.66 on epoch=9
06/06/2022 00:21:55 - INFO - __main__ - Step 150 Global step 150 Train loss 1.43 on epoch=10
06/06/2022 00:22:01 - INFO - __main__ - Global step 150 Train loss 1.69 Classification-F1 0.14030841652909018 on epoch=10
06/06/2022 00:22:01 - INFO - __main__ - Saving model with best Classification-F1: 0.07235657998506845 -> 0.14030841652909018 on epoch=10, global_step=150
06/06/2022 00:22:04 - INFO - __main__ - Step 160 Global step 160 Train loss 1.26 on epoch=11
06/06/2022 00:22:07 - INFO - __main__ - Step 170 Global step 170 Train loss 1.22 on epoch=12
06/06/2022 00:22:09 - INFO - __main__ - Step 180 Global step 180 Train loss 1.12 on epoch=12
06/06/2022 00:22:12 - INFO - __main__ - Step 190 Global step 190 Train loss 1.02 on epoch=13
06/06/2022 00:22:14 - INFO - __main__ - Step 200 Global step 200 Train loss 1.00 on epoch=14
06/06/2022 00:22:21 - INFO - __main__ - Global step 200 Train loss 1.12 Classification-F1 0.30168966430814115 on epoch=14
06/06/2022 00:22:21 - INFO - __main__ - Saving model with best Classification-F1: 0.14030841652909018 -> 0.30168966430814115 on epoch=14, global_step=200
06/06/2022 00:22:24 - INFO - __main__ - Step 210 Global step 210 Train loss 1.00 on epoch=14
06/06/2022 00:22:26 - INFO - __main__ - Step 220 Global step 220 Train loss 0.85 on epoch=15
06/06/2022 00:22:29 - INFO - __main__ - Step 230 Global step 230 Train loss 0.96 on epoch=16
06/06/2022 00:22:31 - INFO - __main__ - Step 240 Global step 240 Train loss 0.82 on epoch=17
06/06/2022 00:22:34 - INFO - __main__ - Step 250 Global step 250 Train loss 0.78 on epoch=17
06/06/2022 00:22:41 - INFO - __main__ - Global step 250 Train loss 0.88 Classification-F1 0.36862490913352347 on epoch=17
06/06/2022 00:22:41 - INFO - __main__ - Saving model with best Classification-F1: 0.30168966430814115 -> 0.36862490913352347 on epoch=17, global_step=250
06/06/2022 00:22:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.74 on epoch=18
06/06/2022 00:22:47 - INFO - __main__ - Step 270 Global step 270 Train loss 0.73 on epoch=19
06/06/2022 00:22:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.72 on epoch=19
06/06/2022 00:22:52 - INFO - __main__ - Step 290 Global step 290 Train loss 0.75 on epoch=20
06/06/2022 00:22:54 - INFO - __main__ - Step 300 Global step 300 Train loss 0.67 on epoch=21
06/06/2022 00:23:02 - INFO - __main__ - Global step 300 Train loss 0.72 Classification-F1 0.500701972374642 on epoch=21
06/06/2022 00:23:02 - INFO - __main__ - Saving model with best Classification-F1: 0.36862490913352347 -> 0.500701972374642 on epoch=21, global_step=300
06/06/2022 00:23:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.62 on epoch=22
06/06/2022 00:23:07 - INFO - __main__ - Step 320 Global step 320 Train loss 0.63 on epoch=22
06/06/2022 00:23:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.60 on epoch=23
06/06/2022 00:23:13 - INFO - __main__ - Step 340 Global step 340 Train loss 0.75 on epoch=24
06/06/2022 00:23:16 - INFO - __main__ - Step 350 Global step 350 Train loss 0.56 on epoch=24
06/06/2022 00:23:23 - INFO - __main__ - Global step 350 Train loss 0.63 Classification-F1 0.5817857720227674 on epoch=24
06/06/2022 00:23:23 - INFO - __main__ - Saving model with best Classification-F1: 0.500701972374642 -> 0.5817857720227674 on epoch=24, global_step=350
06/06/2022 00:23:26 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=25
06/06/2022 00:23:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.52 on epoch=26
06/06/2022 00:23:31 - INFO - __main__ - Step 380 Global step 380 Train loss 0.60 on epoch=27
06/06/2022 00:23:34 - INFO - __main__ - Step 390 Global step 390 Train loss 0.56 on epoch=27
06/06/2022 00:23:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.54 on epoch=28
06/06/2022 00:23:44 - INFO - __main__ - Global step 400 Train loss 0.55 Classification-F1 0.6645252886476796 on epoch=28
06/06/2022 00:23:44 - INFO - __main__ - Saving model with best Classification-F1: 0.5817857720227674 -> 0.6645252886476796 on epoch=28, global_step=400
06/06/2022 00:23:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.48 on epoch=29
06/06/2022 00:23:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.61 on epoch=29
06/06/2022 00:23:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.53 on epoch=30
06/06/2022 00:23:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.52 on epoch=31
06/06/2022 00:23:58 - INFO - __main__ - Step 450 Global step 450 Train loss 0.52 on epoch=32
06/06/2022 00:24:05 - INFO - __main__ - Global step 450 Train loss 0.53 Classification-F1 0.637324167375101 on epoch=32
06/06/2022 00:24:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.48 on epoch=32
06/06/2022 00:24:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.40 on epoch=33
06/06/2022 00:24:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.49 on epoch=34
06/06/2022 00:24:16 - INFO - __main__ - Step 490 Global step 490 Train loss 0.49 on epoch=34
06/06/2022 00:24:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.33 on epoch=35
06/06/2022 00:24:26 - INFO - __main__ - Global step 500 Train loss 0.44 Classification-F1 0.6719839189942949 on epoch=35
06/06/2022 00:24:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6645252886476796 -> 0.6719839189942949 on epoch=35, global_step=500
06/06/2022 00:24:29 - INFO - __main__ - Step 510 Global step 510 Train loss 0.41 on epoch=36
06/06/2022 00:24:32 - INFO - __main__ - Step 520 Global step 520 Train loss 0.42 on epoch=37
06/06/2022 00:24:34 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=37
06/06/2022 00:24:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=38
06/06/2022 00:24:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.40 on epoch=39
06/06/2022 00:24:47 - INFO - __main__ - Global step 550 Train loss 0.39 Classification-F1 0.6697359000078797 on epoch=39
06/06/2022 00:24:50 - INFO - __main__ - Step 560 Global step 560 Train loss 0.42 on epoch=39
06/06/2022 00:24:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.38 on epoch=40
06/06/2022 00:24:55 - INFO - __main__ - Step 580 Global step 580 Train loss 0.44 on epoch=41
06/06/2022 00:24:58 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=42
06/06/2022 00:25:01 - INFO - __main__ - Step 600 Global step 600 Train loss 0.28 on epoch=42
06/06/2022 00:25:09 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.6820406322476185 on epoch=42
06/06/2022 00:25:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6719839189942949 -> 0.6820406322476185 on epoch=42, global_step=600
06/06/2022 00:25:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.38 on epoch=43
06/06/2022 00:25:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.34 on epoch=44
06/06/2022 00:25:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=44
06/06/2022 00:25:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.34 on epoch=45
06/06/2022 00:25:22 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=46
06/06/2022 00:25:30 - INFO - __main__ - Global step 650 Train loss 0.33 Classification-F1 0.7150498979274512 on epoch=46
06/06/2022 00:25:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6820406322476185 -> 0.7150498979274512 on epoch=46, global_step=650
06/06/2022 00:25:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.36 on epoch=47
06/06/2022 00:25:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.34 on epoch=47
06/06/2022 00:25:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=48
06/06/2022 00:25:40 - INFO - __main__ - Step 690 Global step 690 Train loss 0.33 on epoch=49
06/06/2022 00:25:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=49
06/06/2022 00:25:50 - INFO - __main__ - Global step 700 Train loss 0.30 Classification-F1 0.6010607821559 on epoch=49
06/06/2022 00:25:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=50
06/06/2022 00:25:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=51
06/06/2022 00:25:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.36 on epoch=52
06/06/2022 00:26:01 - INFO - __main__ - Step 740 Global step 740 Train loss 0.33 on epoch=52
06/06/2022 00:26:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.25 on epoch=53
06/06/2022 00:26:11 - INFO - __main__ - Global step 750 Train loss 0.29 Classification-F1 0.7508998158191706 on epoch=53
06/06/2022 00:26:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7150498979274512 -> 0.7508998158191706 on epoch=53, global_step=750
06/06/2022 00:26:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.29 on epoch=54
06/06/2022 00:26:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.29 on epoch=54
06/06/2022 00:26:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=55
06/06/2022 00:26:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=56
06/06/2022 00:26:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=57
06/06/2022 00:26:32 - INFO - __main__ - Global step 800 Train loss 0.28 Classification-F1 0.5707824168653662 on epoch=57
06/06/2022 00:26:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.24 on epoch=57
06/06/2022 00:26:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.24 on epoch=58
06/06/2022 00:26:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.27 on epoch=59
06/06/2022 00:26:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.24 on epoch=59
06/06/2022 00:26:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=60
06/06/2022 00:26:52 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.5502915138453347 on epoch=60
06/06/2022 00:26:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.31 on epoch=61
06/06/2022 00:26:58 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=62
06/06/2022 00:27:01 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=62
06/06/2022 00:27:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
06/06/2022 00:27:06 - INFO - __main__ - Step 900 Global step 900 Train loss 0.25 on epoch=64
06/06/2022 00:27:13 - INFO - __main__ - Global step 900 Train loss 0.23 Classification-F1 0.5327356950832964 on epoch=64
06/06/2022 00:27:16 - INFO - __main__ - Step 910 Global step 910 Train loss 0.21 on epoch=64
06/06/2022 00:27:18 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
06/06/2022 00:27:21 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=66
06/06/2022 00:27:24 - INFO - __main__ - Step 940 Global step 940 Train loss 0.22 on epoch=67
06/06/2022 00:27:26 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=67
06/06/2022 00:27:34 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.6548122567591361 on epoch=67
06/06/2022 00:27:36 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=68
06/06/2022 00:27:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=69
06/06/2022 00:27:42 - INFO - __main__ - Step 980 Global step 980 Train loss 0.20 on epoch=69
06/06/2022 00:27:45 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=70
06/06/2022 00:27:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.19 on epoch=71
06/06/2022 00:27:54 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.6315175256492578 on epoch=71
06/06/2022 00:27:57 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=72
06/06/2022 00:28:00 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=72
06/06/2022 00:28:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=73
06/06/2022 00:28:05 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.20 on epoch=74
06/06/2022 00:28:08 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=74
06/06/2022 00:28:14 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.5773815108750049 on epoch=74
06/06/2022 00:28:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
06/06/2022 00:28:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.27 on epoch=76
06/06/2022 00:28:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=77
06/06/2022 00:28:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=77
06/06/2022 00:28:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=78
06/06/2022 00:28:35 - INFO - __main__ - Global step 1100 Train loss 0.16 Classification-F1 0.7076815528304025 on epoch=78
06/06/2022 00:28:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=79
06/06/2022 00:28:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=79
06/06/2022 00:28:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=80
06/06/2022 00:28:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.22 on epoch=81
06/06/2022 00:28:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.24 on epoch=82
06/06/2022 00:28:56 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.6887661660711434 on epoch=82
06/06/2022 00:28:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=82
06/06/2022 00:29:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.17 on epoch=83
06/06/2022 00:29:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=84
06/06/2022 00:29:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=84
06/06/2022 00:29:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=85
06/06/2022 00:29:16 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.7951222717826134 on epoch=85
06/06/2022 00:29:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7508998158191706 -> 0.7951222717826134 on epoch=85, global_step=1200
06/06/2022 00:29:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=86
06/06/2022 00:29:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=87
06/06/2022 00:29:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
06/06/2022 00:29:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=88
06/06/2022 00:29:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/06/2022 00:29:37 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.7508061707171829 on epoch=89
06/06/2022 00:29:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=89
06/06/2022 00:29:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=90
06/06/2022 00:29:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=91
06/06/2022 00:29:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=92
06/06/2022 00:29:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=92
06/06/2022 00:29:57 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.9820991153059465 on epoch=92
06/06/2022 00:29:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7951222717826134 -> 0.9820991153059465 on epoch=92, global_step=1300
06/06/2022 00:30:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.14 on epoch=93
06/06/2022 00:30:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=94
06/06/2022 00:30:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=94
06/06/2022 00:30:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=95
06/06/2022 00:30:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/06/2022 00:30:17 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.9163766699250568 on epoch=96
06/06/2022 00:30:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=97
06/06/2022 00:30:23 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/06/2022 00:30:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=98
06/06/2022 00:30:28 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
06/06/2022 00:30:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
06/06/2022 00:30:38 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.9102304789512797 on epoch=99
06/06/2022 00:30:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
06/06/2022 00:30:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=101
06/06/2022 00:30:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=102
06/06/2022 00:30:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=102
06/06/2022 00:30:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=103
06/06/2022 00:30:58 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.9774768558449772 on epoch=103
06/06/2022 00:31:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=104
06/06/2022 00:31:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.17 on epoch=104
06/06/2022 00:31:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
06/06/2022 00:31:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=106
06/06/2022 00:31:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.18 on epoch=107
06/06/2022 00:31:18 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.9684834152085345 on epoch=107
06/06/2022 00:31:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
06/06/2022 00:31:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
06/06/2022 00:31:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
06/06/2022 00:31:28 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.15 on epoch=109
06/06/2022 00:31:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/06/2022 00:31:38 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.9729288297379828 on epoch=110
06/06/2022 00:31:41 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
06/06/2022 00:31:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=112
06/06/2022 00:31:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
06/06/2022 00:31:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
06/06/2022 00:31:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/06/2022 00:31:58 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.9059163701210419 on epoch=114
06/06/2022 00:32:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=114
06/06/2022 00:32:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/06/2022 00:32:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
06/06/2022 00:32:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/06/2022 00:32:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/06/2022 00:32:18 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.8325570241130014 on epoch=117
06/06/2022 00:32:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=118
06/06/2022 00:32:24 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=119
06/06/2022 00:32:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
06/06/2022 00:32:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
06/06/2022 00:32:32 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
06/06/2022 00:32:39 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.9683437699075991 on epoch=121
06/06/2022 00:32:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=122
06/06/2022 00:32:44 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/06/2022 00:32:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=123
06/06/2022 00:32:49 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=124
06/06/2022 00:32:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/06/2022 00:32:59 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.8428553972908812 on epoch=124
06/06/2022 00:33:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
06/06/2022 00:33:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=126
06/06/2022 00:33:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.13 on epoch=127
06/06/2022 00:33:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
06/06/2022 00:33:12 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/06/2022 00:33:19 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.843085850542563 on epoch=128
06/06/2022 00:33:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
06/06/2022 00:33:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=129
06/06/2022 00:33:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
06/06/2022 00:33:30 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=131
06/06/2022 00:33:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/06/2022 00:33:39 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.8472123908720127 on epoch=132
06/06/2022 00:33:42 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
06/06/2022 00:33:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=133
06/06/2022 00:33:47 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=134
06/06/2022 00:33:50 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
06/06/2022 00:33:52 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/06/2022 00:33:59 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.9016369809460171 on epoch=135
06/06/2022 00:34:02 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=136
06/06/2022 00:34:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/06/2022 00:34:07 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
06/06/2022 00:34:10 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
06/06/2022 00:34:13 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=139
06/06/2022 00:34:19 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.7970385494677191 on epoch=139
06/06/2022 00:34:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/06/2022 00:34:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/06/2022 00:34:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=141
06/06/2022 00:34:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
06/06/2022 00:34:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/06/2022 00:34:39 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.8392348450149603 on epoch=142
06/06/2022 00:34:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/06/2022 00:34:45 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/06/2022 00:34:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
06/06/2022 00:34:50 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/06/2022 00:34:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=146
06/06/2022 00:34:59 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.844837744481957 on epoch=146
06/06/2022 00:35:02 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
06/06/2022 00:35:05 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
06/06/2022 00:35:07 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/06/2022 00:35:10 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=149
06/06/2022 00:35:13 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=149
06/06/2022 00:35:19 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.8592253176930597 on epoch=149
06/06/2022 00:35:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=150
06/06/2022 00:35:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
06/06/2022 00:35:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/06/2022 00:35:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/06/2022 00:35:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=153
06/06/2022 00:35:39 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.8591069464809384 on epoch=153
06/06/2022 00:35:42 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/06/2022 00:35:45 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=154
06/06/2022 00:35:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/06/2022 00:35:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=156
06/06/2022 00:35:53 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=157
06/06/2022 00:35:59 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.9097537587860169 on epoch=157
06/06/2022 00:36:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=157
06/06/2022 00:36:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/06/2022 00:36:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
06/06/2022 00:36:10 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
06/06/2022 00:36:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/06/2022 00:36:20 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.9682586230973327 on epoch=160
06/06/2022 00:36:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
06/06/2022 00:36:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/06/2022 00:36:28 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/06/2022 00:36:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=163
06/06/2022 00:36:33 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/06/2022 00:36:40 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.9186705767350927 on epoch=164
06/06/2022 00:36:43 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/06/2022 00:36:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/06/2022 00:36:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=166
06/06/2022 00:36:51 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/06/2022 00:36:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=167
06/06/2022 00:37:01 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.8473130176329811 on epoch=167
06/06/2022 00:37:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/06/2022 00:37:06 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/06/2022 00:37:09 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
06/06/2022 00:37:11 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/06/2022 00:37:14 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=171
06/06/2022 00:37:21 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.9144753033178079 on epoch=171
06/06/2022 00:37:24 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.11 on epoch=172
06/06/2022 00:37:26 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/06/2022 00:37:29 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=173
06/06/2022 00:37:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
06/06/2022 00:37:34 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=174
06/06/2022 00:37:42 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.7919534529354264 on epoch=174
06/06/2022 00:37:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
06/06/2022 00:37:47 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=176
06/06/2022 00:37:50 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/06/2022 00:37:52 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/06/2022 00:37:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/06/2022 00:38:02 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.8451299303218102 on epoch=178
06/06/2022 00:38:05 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/06/2022 00:38:07 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/06/2022 00:38:10 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=180
06/06/2022 00:38:13 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/06/2022 00:38:15 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=182
06/06/2022 00:38:23 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7956957318507638 on epoch=182
06/06/2022 00:38:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/06/2022 00:38:28 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=183
06/06/2022 00:38:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/06/2022 00:38:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/06/2022 00:38:36 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/06/2022 00:38:43 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.844989254233901 on epoch=185
06/06/2022 00:38:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/06/2022 00:38:49 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.09 on epoch=187
06/06/2022 00:38:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/06/2022 00:38:54 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/06/2022 00:38:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
06/06/2022 00:39:04 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.8473767412023461 on epoch=189
06/06/2022 00:39:06 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/06/2022 00:39:09 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/06/2022 00:39:12 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
06/06/2022 00:39:14 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/06/2022 00:39:17 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/06/2022 00:39:24 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8972341126088755 on epoch=192
06/06/2022 00:39:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/06/2022 00:39:30 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/06/2022 00:39:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/06/2022 00:39:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.07 on epoch=195
06/06/2022 00:39:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.09 on epoch=196
06/06/2022 00:39:44 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.78790122655928 on epoch=196
06/06/2022 00:39:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/06/2022 00:39:50 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/06/2022 00:39:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
06/06/2022 00:39:55 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/06/2022 00:39:58 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
06/06/2022 00:40:05 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7894405102520329 on epoch=199
06/06/2022 00:40:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/06/2022 00:40:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
06/06/2022 00:40:13 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=202
06/06/2022 00:40:16 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
06/06/2022 00:40:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
06/06/2022 00:40:24 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7890054110429691 on epoch=203
06/06/2022 00:40:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/06/2022 00:40:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/06/2022 00:40:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=205
06/06/2022 00:40:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/06/2022 00:40:38 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/06/2022 00:40:44 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.8481462086300796 on epoch=207
06/06/2022 00:40:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/06/2022 00:40:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.10 on epoch=208
06/06/2022 00:40:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/06/2022 00:40:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/06/2022 00:40:58 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=210
06/06/2022 00:41:04 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.7824500882138453 on epoch=210
06/06/2022 00:41:07 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
06/06/2022 00:41:10 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/06/2022 00:41:12 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/06/2022 00:41:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/06/2022 00:41:18 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/06/2022 00:41:19 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 00:41:19 - INFO - __main__ - Printing 3 examples
06/06/2022 00:41:19 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/06/2022 00:41:19 - INFO - __main__ - ['Film']
06/06/2022 00:41:19 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/06/2022 00:41:19 - INFO - __main__ - ['Film']
06/06/2022 00:41:19 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/06/2022 00:41:19 - INFO - __main__ - ['Film']
06/06/2022 00:41:19 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:41:19 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:41:19 - INFO - __main__ - Loaded 224 examples from train data
06/06/2022 00:41:19 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 00:41:19 - INFO - __main__ - Printing 3 examples
06/06/2022 00:41:19 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/06/2022 00:41:19 - INFO - __main__ - ['Film']
06/06/2022 00:41:19 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/06/2022 00:41:19 - INFO - __main__ - ['Film']
06/06/2022 00:41:19 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/06/2022 00:41:19 - INFO - __main__ - ['Film']
06/06/2022 00:41:19 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:41:20 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:41:20 - INFO - __main__ - Loaded 224 examples from dev data
06/06/2022 00:41:24 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6915470276114369 on epoch=214
06/06/2022 00:41:24 - INFO - __main__ - save last model!
06/06/2022 00:41:24 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 00:41:24 - INFO - __main__ - Start tokenizing ... 3500 instances
06/06/2022 00:41:24 - INFO - __main__ - Printing 3 examples
06/06/2022 00:41:24 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/06/2022 00:41:24 - INFO - __main__ - ['Animal']
06/06/2022 00:41:24 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/06/2022 00:41:24 - INFO - __main__ - ['Animal']
06/06/2022 00:41:24 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/06/2022 00:41:24 - INFO - __main__ - ['Village']
06/06/2022 00:41:24 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:41:26 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:41:29 - INFO - __main__ - Loaded 3500 examples from test data
06/06/2022 00:41:40 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 00:41:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 00:41:40 - INFO - __main__ - Starting training!
06/06/2022 00:43:36 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
06/06/2022 00:43:36 - INFO - __main__ - Classification-F1 on test data: 0.6039
06/06/2022 00:43:36 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.9820991153059465, test_performance=0.6039376286259899
06/06/2022 00:43:36 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
06/06/2022 00:43:37 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 00:43:37 - INFO - __main__ - Printing 3 examples
06/06/2022 00:43:37 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/06/2022 00:43:37 - INFO - __main__ - ['Film']
06/06/2022 00:43:37 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/06/2022 00:43:37 - INFO - __main__ - ['Film']
06/06/2022 00:43:37 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/06/2022 00:43:37 - INFO - __main__ - ['Film']
06/06/2022 00:43:37 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:43:37 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:43:38 - INFO - __main__ - Loaded 224 examples from train data
06/06/2022 00:43:38 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 00:43:38 - INFO - __main__ - Printing 3 examples
06/06/2022 00:43:38 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/06/2022 00:43:38 - INFO - __main__ - ['Film']
06/06/2022 00:43:38 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/06/2022 00:43:38 - INFO - __main__ - ['Film']
06/06/2022 00:43:38 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/06/2022 00:43:38 - INFO - __main__ - ['Film']
06/06/2022 00:43:38 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:43:38 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:43:38 - INFO - __main__ - Loaded 224 examples from dev data
06/06/2022 00:43:54 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 00:43:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 00:43:55 - INFO - __main__ - Starting training!
06/06/2022 00:43:59 - INFO - __main__ - Step 10 Global step 10 Train loss 5.47 on epoch=0
06/06/2022 00:44:02 - INFO - __main__ - Step 20 Global step 20 Train loss 3.63 on epoch=1
06/06/2022 00:44:04 - INFO - __main__ - Step 30 Global step 30 Train loss 2.78 on epoch=2
06/06/2022 00:44:07 - INFO - __main__ - Step 40 Global step 40 Train loss 2.05 on epoch=2
06/06/2022 00:44:10 - INFO - __main__ - Step 50 Global step 50 Train loss 1.86 on epoch=3
06/06/2022 00:44:16 - INFO - __main__ - Global step 50 Train loss 3.16 Classification-F1 0.13504548032394786 on epoch=3
06/06/2022 00:44:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13504548032394786 on epoch=3, global_step=50
06/06/2022 00:44:19 - INFO - __main__ - Step 60 Global step 60 Train loss 1.44 on epoch=4
06/06/2022 00:44:21 - INFO - __main__ - Step 70 Global step 70 Train loss 1.09 on epoch=4
06/06/2022 00:44:24 - INFO - __main__ - Step 80 Global step 80 Train loss 0.94 on epoch=5
06/06/2022 00:44:27 - INFO - __main__ - Step 90 Global step 90 Train loss 0.93 on epoch=6
06/06/2022 00:44:30 - INFO - __main__ - Step 100 Global step 100 Train loss 0.70 on epoch=7
06/06/2022 00:44:36 - INFO - __main__ - Global step 100 Train loss 1.02 Classification-F1 0.40267246287170394 on epoch=7
06/06/2022 00:44:36 - INFO - __main__ - Saving model with best Classification-F1: 0.13504548032394786 -> 0.40267246287170394 on epoch=7, global_step=100
06/06/2022 00:44:39 - INFO - __main__ - Step 110 Global step 110 Train loss 0.75 on epoch=7
06/06/2022 00:44:42 - INFO - __main__ - Step 120 Global step 120 Train loss 0.74 on epoch=8
06/06/2022 00:44:45 - INFO - __main__ - Step 130 Global step 130 Train loss 0.59 on epoch=9
06/06/2022 00:44:48 - INFO - __main__ - Step 140 Global step 140 Train loss 0.53 on epoch=9
06/06/2022 00:44:50 - INFO - __main__ - Step 150 Global step 150 Train loss 0.54 on epoch=10
06/06/2022 00:44:58 - INFO - __main__ - Global step 150 Train loss 0.63 Classification-F1 0.7370378354408302 on epoch=10
06/06/2022 00:44:58 - INFO - __main__ - Saving model with best Classification-F1: 0.40267246287170394 -> 0.7370378354408302 on epoch=10, global_step=150
06/06/2022 00:45:01 - INFO - __main__ - Step 160 Global step 160 Train loss 0.53 on epoch=11
06/06/2022 00:45:04 - INFO - __main__ - Step 170 Global step 170 Train loss 0.64 on epoch=12
06/06/2022 00:45:06 - INFO - __main__ - Step 180 Global step 180 Train loss 0.45 on epoch=12
06/06/2022 00:45:09 - INFO - __main__ - Step 190 Global step 190 Train loss 0.51 on epoch=13
06/06/2022 00:45:12 - INFO - __main__ - Step 200 Global step 200 Train loss 0.43 on epoch=14
06/06/2022 00:45:19 - INFO - __main__ - Global step 200 Train loss 0.51 Classification-F1 0.6933512787803503 on epoch=14
06/06/2022 00:45:22 - INFO - __main__ - Step 210 Global step 210 Train loss 0.40 on epoch=14
06/06/2022 00:45:24 - INFO - __main__ - Step 220 Global step 220 Train loss 0.37 on epoch=15
06/06/2022 00:45:27 - INFO - __main__ - Step 230 Global step 230 Train loss 0.39 on epoch=16
06/06/2022 00:45:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.34 on epoch=17
06/06/2022 00:45:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.31 on epoch=17
06/06/2022 00:45:40 - INFO - __main__ - Global step 250 Train loss 0.36 Classification-F1 0.5918237859924294 on epoch=17
06/06/2022 00:45:42 - INFO - __main__ - Step 260 Global step 260 Train loss 0.30 on epoch=18
06/06/2022 00:45:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=19
06/06/2022 00:45:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.32 on epoch=19
06/06/2022 00:45:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.29 on epoch=20
06/06/2022 00:45:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=21
06/06/2022 00:46:00 - INFO - __main__ - Global step 300 Train loss 0.29 Classification-F1 0.678117044285099 on epoch=21
06/06/2022 00:46:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=22
06/06/2022 00:46:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=22
06/06/2022 00:46:09 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=23
06/06/2022 00:46:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=24
06/06/2022 00:46:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=24
06/06/2022 00:46:22 - INFO - __main__ - Global step 350 Train loss 0.27 Classification-F1 0.6740691625297888 on epoch=24
06/06/2022 00:46:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=25
06/06/2022 00:46:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=26
06/06/2022 00:46:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.16 on epoch=27
06/06/2022 00:46:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.16 on epoch=27
06/06/2022 00:46:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=28
06/06/2022 00:46:42 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.9016484811472707 on epoch=28
06/06/2022 00:46:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7370378354408302 -> 0.9016484811472707 on epoch=28, global_step=400
06/06/2022 00:46:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.25 on epoch=29
06/06/2022 00:46:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.13 on epoch=29
06/06/2022 00:46:50 - INFO - __main__ - Step 430 Global step 430 Train loss 0.13 on epoch=30
06/06/2022 00:46:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.16 on epoch=31
06/06/2022 00:46:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=32
06/06/2022 00:47:03 - INFO - __main__ - Global step 450 Train loss 0.16 Classification-F1 0.8362182728283952 on epoch=32
06/06/2022 00:47:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.10 on epoch=32
06/06/2022 00:47:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=33
06/06/2022 00:47:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.12 on epoch=34
06/06/2022 00:47:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.12 on epoch=34
06/06/2022 00:47:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=35
06/06/2022 00:47:23 - INFO - __main__ - Global step 500 Train loss 0.11 Classification-F1 0.851267627652234 on epoch=35
06/06/2022 00:47:26 - INFO - __main__ - Step 510 Global step 510 Train loss 0.15 on epoch=36
06/06/2022 00:47:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.13 on epoch=37
06/06/2022 00:47:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=37
06/06/2022 00:47:34 - INFO - __main__ - Step 540 Global step 540 Train loss 0.12 on epoch=38
06/06/2022 00:47:37 - INFO - __main__ - Step 550 Global step 550 Train loss 0.08 on epoch=39
06/06/2022 00:47:44 - INFO - __main__ - Global step 550 Train loss 0.11 Classification-F1 0.9683867416417471 on epoch=39
06/06/2022 00:47:44 - INFO - __main__ - Saving model with best Classification-F1: 0.9016484811472707 -> 0.9683867416417471 on epoch=39, global_step=550
06/06/2022 00:47:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.09 on epoch=39
06/06/2022 00:47:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=40
06/06/2022 00:47:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=41
06/06/2022 00:47:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.08 on epoch=42
06/06/2022 00:47:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=42
06/06/2022 00:48:04 - INFO - __main__ - Global step 600 Train loss 0.10 Classification-F1 0.9103086366511415 on epoch=42
06/06/2022 00:48:07 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=43
06/06/2022 00:48:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=44
06/06/2022 00:48:12 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=44
06/06/2022 00:48:15 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=45
06/06/2022 00:48:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=46
06/06/2022 00:48:24 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.8432761774570279 on epoch=46
06/06/2022 00:48:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=47
06/06/2022 00:48:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=47
06/06/2022 00:48:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=48
06/06/2022 00:48:35 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=49
06/06/2022 00:48:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=49
06/06/2022 00:48:43 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.7317654594629012 on epoch=49
06/06/2022 00:48:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=50
06/06/2022 00:48:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=51
06/06/2022 00:48:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=52
06/06/2022 00:48:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=52
06/06/2022 00:48:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.04 on epoch=53
06/06/2022 00:49:03 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.9097578959786969 on epoch=53
06/06/2022 00:49:06 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=54
06/06/2022 00:49:09 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=54
06/06/2022 00:49:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=55
06/06/2022 00:49:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=56
06/06/2022 00:49:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=57
06/06/2022 00:49:23 - INFO - __main__ - Global step 800 Train loss 0.07 Classification-F1 0.8936092902459127 on epoch=57
06/06/2022 00:49:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=57
06/06/2022 00:49:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=58
06/06/2022 00:49:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=59
06/06/2022 00:49:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=59
06/06/2022 00:49:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=60
06/06/2022 00:49:43 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.9777928033383443 on epoch=60
06/06/2022 00:49:43 - INFO - __main__ - Saving model with best Classification-F1: 0.9683867416417471 -> 0.9777928033383443 on epoch=60, global_step=850
06/06/2022 00:49:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=61
06/06/2022 00:49:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=62
06/06/2022 00:49:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=62
06/06/2022 00:49:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=63
06/06/2022 00:49:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=64
06/06/2022 00:50:03 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.9865984150258343 on epoch=64
06/06/2022 00:50:03 - INFO - __main__ - Saving model with best Classification-F1: 0.9777928033383443 -> 0.9865984150258343 on epoch=64, global_step=900
06/06/2022 00:50:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/06/2022 00:50:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=65
06/06/2022 00:50:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=66
06/06/2022 00:50:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=67
06/06/2022 00:50:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=67
06/06/2022 00:50:23 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.855196878054741 on epoch=67
06/06/2022 00:50:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=68
06/06/2022 00:50:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=69
06/06/2022 00:50:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=69
06/06/2022 00:50:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=70
06/06/2022 00:50:37 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=71
06/06/2022 00:50:43 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.9060190615835779 on epoch=71
06/06/2022 00:50:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=72
06/06/2022 00:50:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=72
06/06/2022 00:50:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=73
06/06/2022 00:50:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=74
06/06/2022 00:50:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
06/06/2022 00:51:03 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.7718236775874348 on epoch=74
06/06/2022 00:51:05 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=75
06/06/2022 00:51:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=76
06/06/2022 00:51:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
06/06/2022 00:51:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
06/06/2022 00:51:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=78
06/06/2022 00:51:23 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.9038194564238208 on epoch=78
06/06/2022 00:51:26 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
06/06/2022 00:51:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=79
06/06/2022 00:51:31 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
06/06/2022 00:51:34 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=81
06/06/2022 00:51:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=82
06/06/2022 00:51:43 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.9061493971977844 on epoch=82
06/06/2022 00:51:46 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=82
06/06/2022 00:51:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=83
06/06/2022 00:51:51 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=84
06/06/2022 00:51:54 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=84
06/06/2022 00:51:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=85
06/06/2022 00:52:03 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.9164955053380103 on epoch=85
06/06/2022 00:52:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=86
06/06/2022 00:52:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=87
06/06/2022 00:52:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
06/06/2022 00:52:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/06/2022 00:52:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
06/06/2022 00:52:24 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.8493820887959289 on epoch=89
06/06/2022 00:52:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
06/06/2022 00:52:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=90
06/06/2022 00:52:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
06/06/2022 00:52:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
06/06/2022 00:52:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
06/06/2022 00:52:43 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.9078958944281527 on epoch=92
06/06/2022 00:52:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
06/06/2022 00:52:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
06/06/2022 00:52:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
06/06/2022 00:52:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
06/06/2022 00:52:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/06/2022 00:53:03 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.8304572947214077 on epoch=96
06/06/2022 00:53:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=97
06/06/2022 00:53:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=97
06/06/2022 00:53:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
06/06/2022 00:53:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
06/06/2022 00:53:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/06/2022 00:53:23 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7801571816613039 on epoch=99
06/06/2022 00:53:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
06/06/2022 00:53:29 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/06/2022 00:53:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=102
06/06/2022 00:53:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=102
06/06/2022 00:53:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
06/06/2022 00:53:43 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.9100464320625612 on epoch=103
06/06/2022 00:53:46 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
06/06/2022 00:53:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/06/2022 00:53:51 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/06/2022 00:53:54 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
06/06/2022 00:53:57 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
06/06/2022 00:54:04 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.9145039100684262 on epoch=107
06/06/2022 00:54:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=107
06/06/2022 00:54:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
06/06/2022 00:54:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
06/06/2022 00:54:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
06/06/2022 00:54:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
06/06/2022 00:54:24 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.9101898012381885 on epoch=110
06/06/2022 00:54:27 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
06/06/2022 00:54:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/06/2022 00:54:32 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
06/06/2022 00:54:35 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/06/2022 00:54:38 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
06/06/2022 00:54:45 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.9730432202206397 on epoch=114
06/06/2022 00:54:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/06/2022 00:54:50 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=115
06/06/2022 00:54:53 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/06/2022 00:54:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/06/2022 00:54:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
06/06/2022 00:55:05 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.9775075059349254 on epoch=117
06/06/2022 00:55:08 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/06/2022 00:55:11 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
06/06/2022 00:55:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=119
06/06/2022 00:55:16 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/06/2022 00:55:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/06/2022 00:55:26 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.9821297653958945 on epoch=121
06/06/2022 00:55:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/06/2022 00:55:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/06/2022 00:55:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
06/06/2022 00:55:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
06/06/2022 00:55:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
06/06/2022 00:55:46 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.9775075059349254 on epoch=124
06/06/2022 00:55:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/06/2022 00:55:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=126
06/06/2022 00:55:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/06/2022 00:55:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/06/2022 00:56:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/06/2022 00:56:07 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.9639958943937571 on epoch=128
06/06/2022 00:56:09 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/06/2022 00:56:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/06/2022 00:56:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/06/2022 00:56:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/06/2022 00:56:20 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/06/2022 00:56:27 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9078999674160966 on epoch=132
06/06/2022 00:56:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/06/2022 00:56:32 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/06/2022 00:56:35 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/06/2022 00:56:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/06/2022 00:56:40 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/06/2022 00:56:47 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9775118698505797 on epoch=135
06/06/2022 00:56:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/06/2022 00:56:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/06/2022 00:56:55 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=137
06/06/2022 00:56:58 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/06/2022 00:57:01 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=139
06/06/2022 00:57:08 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.9122100032583906 on epoch=139
06/06/2022 00:57:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/06/2022 00:57:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/06/2022 00:57:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/06/2022 00:57:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/06/2022 00:57:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/06/2022 00:57:28 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9821297653958947 on epoch=142
06/06/2022 00:57:31 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=143
06/06/2022 00:57:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/06/2022 00:57:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/06/2022 00:57:39 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=145
06/06/2022 00:57:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/06/2022 00:57:48 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9119084336131055 on epoch=146
06/06/2022 00:57:51 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/06/2022 00:57:53 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/06/2022 00:57:56 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/06/2022 00:57:59 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/06/2022 00:58:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/06/2022 00:58:08 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9775075059349254 on epoch=149
06/06/2022 00:58:11 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=150
06/06/2022 00:58:14 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/06/2022 00:58:16 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/06/2022 00:58:19 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
06/06/2022 00:58:22 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/06/2022 00:58:29 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9101898012381885 on epoch=153
06/06/2022 00:58:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=154
06/06/2022 00:58:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=154
06/06/2022 00:58:37 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/06/2022 00:58:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=156
06/06/2022 00:58:42 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/06/2022 00:58:49 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9775075059349254 on epoch=157
06/06/2022 00:58:52 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/06/2022 00:58:55 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
06/06/2022 00:58:57 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
06/06/2022 00:59:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
06/06/2022 00:59:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/06/2022 00:59:09 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9775075059349254 on epoch=160
06/06/2022 00:59:12 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
06/06/2022 00:59:15 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
06/06/2022 00:59:17 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=162
06/06/2022 00:59:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/06/2022 00:59:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/06/2022 00:59:29 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.9775075059349254 on epoch=164
06/06/2022 00:59:32 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
06/06/2022 00:59:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/06/2022 00:59:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=166
06/06/2022 00:59:40 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/06/2022 00:59:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/06/2022 00:59:49 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9101898012381885 on epoch=167
06/06/2022 00:59:52 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/06/2022 00:59:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/06/2022 00:59:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/06/2022 01:00:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
06/06/2022 01:00:03 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/06/2022 01:00:10 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9821297653958945 on epoch=171
06/06/2022 01:00:12 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/06/2022 01:00:15 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
06/06/2022 01:00:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
06/06/2022 01:00:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
06/06/2022 01:00:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/06/2022 01:00:30 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9100070670058567 on epoch=174
06/06/2022 01:00:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/06/2022 01:00:35 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/06/2022 01:00:38 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/06/2022 01:00:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/06/2022 01:00:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
06/06/2022 01:00:50 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9730432202206397 on epoch=178
06/06/2022 01:00:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/06/2022 01:00:56 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/06/2022 01:00:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
06/06/2022 01:01:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
06/06/2022 01:01:04 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
06/06/2022 01:01:11 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.911301377833636 on epoch=182
06/06/2022 01:01:13 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
06/06/2022 01:01:16 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/06/2022 01:01:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
06/06/2022 01:01:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
06/06/2022 01:01:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
06/06/2022 01:01:31 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.9043087686904893 on epoch=185
06/06/2022 01:01:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/06/2022 01:01:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/06/2022 01:01:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/06/2022 01:01:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/06/2022 01:01:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/06/2022 01:01:51 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9122100032583904 on epoch=189
06/06/2022 01:01:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/06/2022 01:01:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
06/06/2022 01:01:59 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
06/06/2022 01:02:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/06/2022 01:02:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/06/2022 01:02:11 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9775075059349254 on epoch=192
06/06/2022 01:02:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/06/2022 01:02:16 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/06/2022 01:02:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/06/2022 01:02:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/06/2022 01:02:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/06/2022 01:02:30 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.9821297653958947 on epoch=196
06/06/2022 01:02:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/06/2022 01:02:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/06/2022 01:02:38 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/06/2022 01:02:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/06/2022 01:02:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/06/2022 01:02:50 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9037251547735418 on epoch=199
06/06/2022 01:02:53 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/06/2022 01:02:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/06/2022 01:02:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/06/2022 01:03:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/06/2022 01:03:04 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/06/2022 01:03:10 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.9186746497230369 on epoch=203
06/06/2022 01:03:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/06/2022 01:03:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/06/2022 01:03:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/06/2022 01:03:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/06/2022 01:03:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/06/2022 01:03:29 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9101898012381885 on epoch=207
06/06/2022 01:03:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/06/2022 01:03:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/06/2022 01:03:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/06/2022 01:03:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/06/2022 01:03:43 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/06/2022 01:03:50 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9730432202206397 on epoch=210
06/06/2022 01:03:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/06/2022 01:03:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/06/2022 01:03:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/06/2022 01:04:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/06/2022 01:04:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/06/2022 01:04:05 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 01:04:05 - INFO - __main__ - Printing 3 examples
06/06/2022 01:04:05 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/06/2022 01:04:05 - INFO - __main__ - ['Film']
06/06/2022 01:04:05 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/06/2022 01:04:05 - INFO - __main__ - ['Film']
06/06/2022 01:04:05 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/06/2022 01:04:05 - INFO - __main__ - ['Film']
06/06/2022 01:04:05 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:04:05 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:04:06 - INFO - __main__ - Loaded 224 examples from train data
06/06/2022 01:04:06 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 01:04:06 - INFO - __main__ - Printing 3 examples
06/06/2022 01:04:06 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/06/2022 01:04:06 - INFO - __main__ - ['Film']
06/06/2022 01:04:06 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/06/2022 01:04:06 - INFO - __main__ - ['Film']
06/06/2022 01:04:06 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/06/2022 01:04:06 - INFO - __main__ - ['Film']
06/06/2022 01:04:06 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:04:06 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:04:06 - INFO - __main__ - Loaded 224 examples from dev data
06/06/2022 01:04:10 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.9819761555648654 on epoch=214
06/06/2022 01:04:10 - INFO - __main__ - save last model!
06/06/2022 01:04:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 01:04:11 - INFO - __main__ - Start tokenizing ... 3500 instances
06/06/2022 01:04:11 - INFO - __main__ - Printing 3 examples
06/06/2022 01:04:11 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/06/2022 01:04:11 - INFO - __main__ - ['Animal']
06/06/2022 01:04:11 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/06/2022 01:04:11 - INFO - __main__ - ['Animal']
06/06/2022 01:04:11 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/06/2022 01:04:11 - INFO - __main__ - ['Village']
06/06/2022 01:04:11 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:04:12 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:04:16 - INFO - __main__ - Loaded 3500 examples from test data
06/06/2022 01:04:25 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 01:04:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 01:04:26 - INFO - __main__ - Starting training!
06/06/2022 01:06:27 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
06/06/2022 01:06:27 - INFO - __main__ - Classification-F1 on test data: 0.5683
06/06/2022 01:06:28 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.9865984150258343, test_performance=0.5682518619432598
06/06/2022 01:06:28 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
06/06/2022 01:06:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 01:06:29 - INFO - __main__ - Printing 3 examples
06/06/2022 01:06:29 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/06/2022 01:06:29 - INFO - __main__ - ['Film']
06/06/2022 01:06:29 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/06/2022 01:06:29 - INFO - __main__ - ['Film']
06/06/2022 01:06:29 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/06/2022 01:06:29 - INFO - __main__ - ['Film']
06/06/2022 01:06:29 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:06:29 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:06:29 - INFO - __main__ - Loaded 224 examples from train data
06/06/2022 01:06:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 01:06:29 - INFO - __main__ - Printing 3 examples
06/06/2022 01:06:29 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/06/2022 01:06:29 - INFO - __main__ - ['Film']
06/06/2022 01:06:29 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/06/2022 01:06:29 - INFO - __main__ - ['Film']
06/06/2022 01:06:29 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/06/2022 01:06:29 - INFO - __main__ - ['Film']
06/06/2022 01:06:29 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:06:29 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:06:30 - INFO - __main__ - Loaded 224 examples from dev data
06/06/2022 01:06:45 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 01:06:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 01:06:46 - INFO - __main__ - Starting training!
06/06/2022 01:06:50 - INFO - __main__ - Step 10 Global step 10 Train loss 5.71 on epoch=0
06/06/2022 01:06:53 - INFO - __main__ - Step 20 Global step 20 Train loss 4.04 on epoch=1
06/06/2022 01:06:55 - INFO - __main__ - Step 30 Global step 30 Train loss 3.35 on epoch=2
06/06/2022 01:06:58 - INFO - __main__ - Step 40 Global step 40 Train loss 2.56 on epoch=2
06/06/2022 01:07:01 - INFO - __main__ - Step 50 Global step 50 Train loss 2.37 on epoch=3
06/06/2022 01:07:06 - INFO - __main__ - Global step 50 Train loss 3.61 Classification-F1 0.07222840466124197 on epoch=3
06/06/2022 01:07:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07222840466124197 on epoch=3, global_step=50
06/06/2022 01:07:09 - INFO - __main__ - Step 60 Global step 60 Train loss 1.99 on epoch=4
06/06/2022 01:07:12 - INFO - __main__ - Step 70 Global step 70 Train loss 1.61 on epoch=4
06/06/2022 01:07:15 - INFO - __main__ - Step 80 Global step 80 Train loss 1.43 on epoch=5
06/06/2022 01:07:17 - INFO - __main__ - Step 90 Global step 90 Train loss 1.23 on epoch=6
06/06/2022 01:07:20 - INFO - __main__ - Step 100 Global step 100 Train loss 1.14 on epoch=7
06/06/2022 01:07:26 - INFO - __main__ - Global step 100 Train loss 1.48 Classification-F1 0.2477729312935515 on epoch=7
06/06/2022 01:07:26 - INFO - __main__ - Saving model with best Classification-F1: 0.07222840466124197 -> 0.2477729312935515 on epoch=7, global_step=100
06/06/2022 01:07:29 - INFO - __main__ - Step 110 Global step 110 Train loss 0.92 on epoch=7
06/06/2022 01:07:32 - INFO - __main__ - Step 120 Global step 120 Train loss 0.84 on epoch=8
06/06/2022 01:07:34 - INFO - __main__ - Step 130 Global step 130 Train loss 0.81 on epoch=9
06/06/2022 01:07:37 - INFO - __main__ - Step 140 Global step 140 Train loss 0.70 on epoch=9
06/06/2022 01:07:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.67 on epoch=10
06/06/2022 01:07:47 - INFO - __main__ - Global step 150 Train loss 0.79 Classification-F1 0.5574681133075694 on epoch=10
06/06/2022 01:07:47 - INFO - __main__ - Saving model with best Classification-F1: 0.2477729312935515 -> 0.5574681133075694 on epoch=10, global_step=150
06/06/2022 01:07:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.63 on epoch=11
06/06/2022 01:07:52 - INFO - __main__ - Step 170 Global step 170 Train loss 0.66 on epoch=12
06/06/2022 01:07:55 - INFO - __main__ - Step 180 Global step 180 Train loss 0.57 on epoch=12
06/06/2022 01:07:57 - INFO - __main__ - Step 190 Global step 190 Train loss 0.65 on epoch=13
06/06/2022 01:08:00 - INFO - __main__ - Step 200 Global step 200 Train loss 0.57 on epoch=14
06/06/2022 01:08:08 - INFO - __main__ - Global step 200 Train loss 0.62 Classification-F1 0.5576073208159802 on epoch=14
06/06/2022 01:08:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5574681133075694 -> 0.5576073208159802 on epoch=14, global_step=200
06/06/2022 01:08:10 - INFO - __main__ - Step 210 Global step 210 Train loss 0.57 on epoch=14
06/06/2022 01:08:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.49 on epoch=15
06/06/2022 01:08:16 - INFO - __main__ - Step 230 Global step 230 Train loss 0.45 on epoch=16
06/06/2022 01:08:19 - INFO - __main__ - Step 240 Global step 240 Train loss 0.55 on epoch=17
06/06/2022 01:08:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=17
06/06/2022 01:08:29 - INFO - __main__ - Global step 250 Train loss 0.49 Classification-F1 0.6231416256567612 on epoch=17
06/06/2022 01:08:29 - INFO - __main__ - Saving model with best Classification-F1: 0.5576073208159802 -> 0.6231416256567612 on epoch=17, global_step=250
06/06/2022 01:08:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.35 on epoch=18
06/06/2022 01:08:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.47 on epoch=19
06/06/2022 01:08:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.45 on epoch=19
06/06/2022 01:08:40 - INFO - __main__ - Step 290 Global step 290 Train loss 0.39 on epoch=20
06/06/2022 01:08:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=21
06/06/2022 01:08:50 - INFO - __main__ - Global step 300 Train loss 0.40 Classification-F1 0.7029376703116695 on epoch=21
06/06/2022 01:08:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6231416256567612 -> 0.7029376703116695 on epoch=21, global_step=300
06/06/2022 01:08:53 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=22
06/06/2022 01:08:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.32 on epoch=22
06/06/2022 01:08:58 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=23
06/06/2022 01:09:01 - INFO - __main__ - Step 340 Global step 340 Train loss 0.29 on epoch=24
06/06/2022 01:09:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=24
06/06/2022 01:09:11 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.6460342674052352 on epoch=24
06/06/2022 01:09:14 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=25
06/06/2022 01:09:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=26
06/06/2022 01:09:19 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=27
06/06/2022 01:09:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=27
06/06/2022 01:09:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=28
06/06/2022 01:09:32 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.6687242899766619 on epoch=28
06/06/2022 01:09:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.15 on epoch=29
06/06/2022 01:09:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=29
06/06/2022 01:09:40 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=30
06/06/2022 01:09:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=31
06/06/2022 01:09:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=32
06/06/2022 01:09:52 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.7236464009443695 on epoch=32
06/06/2022 01:09:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7029376703116695 -> 0.7236464009443695 on epoch=32, global_step=450
06/06/2022 01:09:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.19 on epoch=32
06/06/2022 01:09:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.15 on epoch=33
06/06/2022 01:10:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=34
06/06/2022 01:10:03 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=34
06/06/2022 01:10:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.12 on epoch=35
06/06/2022 01:10:12 - INFO - __main__ - Global step 500 Train loss 0.17 Classification-F1 0.7629858569793879 on epoch=35
06/06/2022 01:10:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7236464009443695 -> 0.7629858569793879 on epoch=35, global_step=500
06/06/2022 01:10:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=36
06/06/2022 01:10:17 - INFO - __main__ - Step 520 Global step 520 Train loss 0.13 on epoch=37
06/06/2022 01:10:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=37
06/06/2022 01:10:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=38
06/06/2022 01:10:25 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=39
06/06/2022 01:10:32 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.782386453481686 on epoch=39
06/06/2022 01:10:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7629858569793879 -> 0.782386453481686 on epoch=39, global_step=550
06/06/2022 01:10:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=39
06/06/2022 01:10:37 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=40
06/06/2022 01:10:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=41
06/06/2022 01:10:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.12 on epoch=42
06/06/2022 01:10:45 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=42
06/06/2022 01:10:52 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.7324675202280676 on epoch=42
06/06/2022 01:10:55 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=43
06/06/2022 01:10:58 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=44
06/06/2022 01:11:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=44
06/06/2022 01:11:03 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=45
06/06/2022 01:11:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=46
06/06/2022 01:11:13 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.7736097233918342 on epoch=46
06/06/2022 01:11:15 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=47
06/06/2022 01:11:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=47
06/06/2022 01:11:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=48
06/06/2022 01:11:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=49
06/06/2022 01:11:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=49
06/06/2022 01:11:33 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.7709966091183784 on epoch=49
06/06/2022 01:11:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=50
06/06/2022 01:11:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=51
06/06/2022 01:11:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=52
06/06/2022 01:11:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=52
06/06/2022 01:11:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=53
06/06/2022 01:11:53 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.977639193507315 on epoch=53
06/06/2022 01:11:53 - INFO - __main__ - Saving model with best Classification-F1: 0.782386453481686 -> 0.977639193507315 on epoch=53, global_step=750
06/06/2022 01:11:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=54
06/06/2022 01:11:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=54
06/06/2022 01:12:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=55
06/06/2022 01:12:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=56
06/06/2022 01:12:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=57
06/06/2022 01:12:13 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.8934019534825987 on epoch=57
06/06/2022 01:12:16 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=57
06/06/2022 01:12:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=58
06/06/2022 01:12:21 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=59
06/06/2022 01:12:24 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=59
06/06/2022 01:12:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=60
06/06/2022 01:12:34 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.847384378054741 on epoch=60
06/06/2022 01:12:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=61
06/06/2022 01:12:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=62
06/06/2022 01:12:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=62
06/06/2022 01:12:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=63
06/06/2022 01:12:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
06/06/2022 01:12:54 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.9060876041521202 on epoch=64
06/06/2022 01:12:57 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=64
06/06/2022 01:13:00 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=65
06/06/2022 01:13:02 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
06/06/2022 01:13:05 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=67
06/06/2022 01:13:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=67
06/06/2022 01:13:14 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.9731845084074686 on epoch=67
06/06/2022 01:13:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
06/06/2022 01:13:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=69
06/06/2022 01:13:22 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/06/2022 01:13:25 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=70
06/06/2022 01:13:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=71
06/06/2022 01:13:34 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.9867213747669157 on epoch=71
06/06/2022 01:13:34 - INFO - __main__ - Saving model with best Classification-F1: 0.977639193507315 -> 0.9867213747669157 on epoch=71, global_step=1000
06/06/2022 01:13:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=72
06/06/2022 01:13:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
06/06/2022 01:13:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
06/06/2022 01:13:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=74
06/06/2022 01:13:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
06/06/2022 01:13:54 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.8390152525390508 on epoch=74
06/06/2022 01:13:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
06/06/2022 01:14:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=76
06/06/2022 01:14:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
06/06/2022 01:14:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=77
06/06/2022 01:14:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=78
06/06/2022 01:14:15 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.8683398423559716 on epoch=78
06/06/2022 01:14:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
06/06/2022 01:14:20 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
06/06/2022 01:14:23 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
06/06/2022 01:14:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=81
06/06/2022 01:14:28 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
06/06/2022 01:14:35 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.9776304656760065 on epoch=82
06/06/2022 01:14:38 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
06/06/2022 01:14:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
06/06/2022 01:14:43 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
06/06/2022 01:14:46 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/06/2022 01:14:48 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
06/06/2022 01:14:56 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.8976571214996263 on epoch=85
06/06/2022 01:14:59 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
06/06/2022 01:15:01 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
06/06/2022 01:15:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
06/06/2022 01:15:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/06/2022 01:15:09 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
06/06/2022 01:15:17 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.8488535504516803 on epoch=89
06/06/2022 01:15:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
06/06/2022 01:15:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
06/06/2022 01:15:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/06/2022 01:15:27 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/06/2022 01:15:30 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
06/06/2022 01:15:37 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.9776444302061 on epoch=92
06/06/2022 01:15:39 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=93
06/06/2022 01:15:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
06/06/2022 01:15:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
06/06/2022 01:15:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
06/06/2022 01:15:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
06/06/2022 01:15:57 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.9061583577712612 on epoch=96
06/06/2022 01:16:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
06/06/2022 01:16:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=97
06/06/2022 01:16:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
06/06/2022 01:16:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
06/06/2022 01:16:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/06/2022 01:16:18 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.8419022733538863 on epoch=99
06/06/2022 01:16:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
06/06/2022 01:16:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/06/2022 01:16:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
06/06/2022 01:16:28 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
06/06/2022 01:16:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
06/06/2022 01:16:38 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.9821297653958947 on epoch=103
06/06/2022 01:16:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
06/06/2022 01:16:44 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
06/06/2022 01:16:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/06/2022 01:16:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=106
06/06/2022 01:16:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/06/2022 01:16:58 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.894959851975981 on epoch=107
06/06/2022 01:17:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=107
06/06/2022 01:17:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
06/06/2022 01:17:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
06/06/2022 01:17:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/06/2022 01:17:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/06/2022 01:17:19 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8445685125728924 on epoch=110
06/06/2022 01:17:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
06/06/2022 01:17:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/06/2022 01:17:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
06/06/2022 01:17:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
06/06/2022 01:17:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/06/2022 01:17:39 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.8438564018186291 on epoch=114
06/06/2022 01:17:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/06/2022 01:17:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/06/2022 01:17:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/06/2022 01:17:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
06/06/2022 01:17:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/06/2022 01:18:00 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.9028165293487876 on epoch=117
06/06/2022 01:18:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/06/2022 01:18:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/06/2022 01:18:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/06/2022 01:18:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/06/2022 01:18:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
06/06/2022 01:18:21 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.9012729832891123 on epoch=121
06/06/2022 01:18:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/06/2022 01:18:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
06/06/2022 01:18:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/06/2022 01:18:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
06/06/2022 01:18:34 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/06/2022 01:18:42 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7927372417159224 on epoch=124
06/06/2022 01:18:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/06/2022 01:18:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/06/2022 01:18:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/06/2022 01:18:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/06/2022 01:18:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/06/2022 01:19:02 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7942141961340533 on epoch=128
06/06/2022 01:19:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/06/2022 01:19:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/06/2022 01:19:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/06/2022 01:19:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/06/2022 01:19:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/06/2022 01:19:23 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7844488823839197 on epoch=132
06/06/2022 01:19:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/06/2022 01:19:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
06/06/2022 01:19:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
06/06/2022 01:19:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/06/2022 01:19:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/06/2022 01:19:43 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7927372417159224 on epoch=135
06/06/2022 01:19:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
06/06/2022 01:19:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/06/2022 01:19:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/06/2022 01:19:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/06/2022 01:19:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/06/2022 01:20:03 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8037637681538892 on epoch=139
06/06/2022 01:20:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/06/2022 01:20:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/06/2022 01:20:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/06/2022 01:20:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/06/2022 01:20:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/06/2022 01:20:24 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7797507994851448 on epoch=142
06/06/2022 01:20:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/06/2022 01:20:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/06/2022 01:20:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/06/2022 01:20:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/06/2022 01:20:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/06/2022 01:20:44 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.8415944559845769 on epoch=146
06/06/2022 01:20:46 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/06/2022 01:20:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/06/2022 01:20:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/06/2022 01:20:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/06/2022 01:20:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/06/2022 01:21:04 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.872340338872597 on epoch=149
06/06/2022 01:21:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/06/2022 01:21:09 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/06/2022 01:21:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/06/2022 01:21:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/06/2022 01:21:16 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=153
06/06/2022 01:21:23 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7987807453973245 on epoch=153
06/06/2022 01:21:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/06/2022 01:21:28 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/06/2022 01:21:31 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/06/2022 01:21:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/06/2022 01:21:36 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/06/2022 01:21:43 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9775075059349254 on epoch=157
06/06/2022 01:21:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/06/2022 01:21:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/06/2022 01:21:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/06/2022 01:21:54 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/06/2022 01:21:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/06/2022 01:22:03 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8512944464809384 on epoch=160
06/06/2022 01:22:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/06/2022 01:22:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/06/2022 01:22:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/06/2022 01:22:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/06/2022 01:22:16 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/06/2022 01:22:23 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.851428855083089 on epoch=164
06/06/2022 01:22:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/06/2022 01:22:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/06/2022 01:22:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/06/2022 01:22:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/06/2022 01:22:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/06/2022 01:22:43 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9186705767350929 on epoch=167
06/06/2022 01:22:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/06/2022 01:22:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/06/2022 01:22:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/06/2022 01:22:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/06/2022 01:22:56 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
06/06/2022 01:23:02 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9054437871484592 on epoch=171
06/06/2022 01:23:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/06/2022 01:23:08 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/06/2022 01:23:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/06/2022 01:23:13 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/06/2022 01:23:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/06/2022 01:23:22 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.908389656938044 on epoch=174
06/06/2022 01:23:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/06/2022 01:23:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/06/2022 01:23:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/06/2022 01:23:33 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/06/2022 01:23:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/06/2022 01:23:42 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9011223901546482 on epoch=178
06/06/2022 01:23:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/06/2022 01:23:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
06/06/2022 01:23:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/06/2022 01:23:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/06/2022 01:23:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/06/2022 01:24:02 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8901140436624307 on epoch=182
06/06/2022 01:24:04 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=182
06/06/2022 01:24:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
06/06/2022 01:24:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
06/06/2022 01:24:12 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/06/2022 01:24:15 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
06/06/2022 01:24:22 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8999946598602513 on epoch=185
06/06/2022 01:24:24 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
06/06/2022 01:24:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/06/2022 01:24:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/06/2022 01:24:32 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/06/2022 01:24:35 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/06/2022 01:24:41 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9101898012381885 on epoch=189
06/06/2022 01:24:44 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/06/2022 01:24:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/06/2022 01:24:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/06/2022 01:24:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/06/2022 01:24:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/06/2022 01:25:01 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9078958944281527 on epoch=192
06/06/2022 01:25:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/06/2022 01:25:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/06/2022 01:25:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/06/2022 01:25:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/06/2022 01:25:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/06/2022 01:25:21 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9101898012381885 on epoch=196
06/06/2022 01:25:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/06/2022 01:25:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/06/2022 01:25:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/06/2022 01:25:31 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/06/2022 01:25:34 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/06/2022 01:25:40 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8415944559845769 on epoch=199
06/06/2022 01:25:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/06/2022 01:25:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/06/2022 01:25:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/06/2022 01:25:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/06/2022 01:25:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/06/2022 01:26:00 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8958279931935846 on epoch=203
06/06/2022 01:26:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/06/2022 01:26:06 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/06/2022 01:26:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/06/2022 01:26:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/06/2022 01:26:14 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/06/2022 01:26:21 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8324696053274683 on epoch=207
06/06/2022 01:26:24 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/06/2022 01:26:26 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/06/2022 01:26:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/06/2022 01:26:31 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/06/2022 01:26:34 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/06/2022 01:26:42 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9028165293487873 on epoch=210
06/06/2022 01:26:45 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/06/2022 01:26:47 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/06/2022 01:26:50 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/06/2022 01:26:53 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/06/2022 01:26:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/06/2022 01:26:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 01:26:57 - INFO - __main__ - Printing 3 examples
06/06/2022 01:26:57 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/06/2022 01:26:57 - INFO - __main__ - ['Film']
06/06/2022 01:26:57 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/06/2022 01:26:57 - INFO - __main__ - ['Film']
06/06/2022 01:26:57 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/06/2022 01:26:57 - INFO - __main__ - ['Film']
06/06/2022 01:26:57 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:26:57 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:26:57 - INFO - __main__ - Loaded 224 examples from train data
06/06/2022 01:26:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 01:26:57 - INFO - __main__ - Printing 3 examples
06/06/2022 01:26:57 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/06/2022 01:26:57 - INFO - __main__ - ['Film']
06/06/2022 01:26:57 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/06/2022 01:26:57 - INFO - __main__ - ['Film']
06/06/2022 01:26:57 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/06/2022 01:26:57 - INFO - __main__ - ['Film']
06/06/2022 01:26:57 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:26:58 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:26:58 - INFO - __main__ - Loaded 224 examples from dev data
06/06/2022 01:27:03 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.9145039100684262 on epoch=214
06/06/2022 01:27:03 - INFO - __main__ - save last model!
06/06/2022 01:27:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 01:27:03 - INFO - __main__ - Start tokenizing ... 3500 instances
06/06/2022 01:27:03 - INFO - __main__ - Printing 3 examples
06/06/2022 01:27:03 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/06/2022 01:27:03 - INFO - __main__ - ['Animal']
06/06/2022 01:27:03 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/06/2022 01:27:03 - INFO - __main__ - ['Animal']
06/06/2022 01:27:03 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/06/2022 01:27:03 - INFO - __main__ - ['Village']
06/06/2022 01:27:03 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:27:04 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:27:08 - INFO - __main__ - Loaded 3500 examples from test data
06/06/2022 01:27:17 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 01:27:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 01:27:18 - INFO - __main__ - Starting training!
06/06/2022 01:29:26 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
06/06/2022 01:29:26 - INFO - __main__ - Classification-F1 on test data: 0.6233
06/06/2022 01:29:26 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.9867213747669157, test_performance=0.6233154168685704
06/06/2022 01:29:26 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
06/06/2022 01:29:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 01:29:27 - INFO - __main__ - Printing 3 examples
06/06/2022 01:29:27 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/06/2022 01:29:27 - INFO - __main__ - ['Film']
06/06/2022 01:29:27 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/06/2022 01:29:27 - INFO - __main__ - ['Film']
06/06/2022 01:29:27 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/06/2022 01:29:27 - INFO - __main__ - ['Film']
06/06/2022 01:29:27 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:29:27 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:29:28 - INFO - __main__ - Loaded 224 examples from train data
06/06/2022 01:29:28 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 01:29:28 - INFO - __main__ - Printing 3 examples
06/06/2022 01:29:28 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/06/2022 01:29:28 - INFO - __main__ - ['Film']
06/06/2022 01:29:28 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/06/2022 01:29:28 - INFO - __main__ - ['Film']
06/06/2022 01:29:28 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/06/2022 01:29:28 - INFO - __main__ - ['Film']
06/06/2022 01:29:28 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:29:28 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:29:28 - INFO - __main__ - Loaded 224 examples from dev data
06/06/2022 01:29:47 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 01:29:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 01:29:48 - INFO - __main__ - Starting training!
06/06/2022 01:29:52 - INFO - __main__ - Step 10 Global step 10 Train loss 6.14 on epoch=0
06/06/2022 01:29:54 - INFO - __main__ - Step 20 Global step 20 Train loss 4.66 on epoch=1
06/06/2022 01:29:57 - INFO - __main__ - Step 30 Global step 30 Train loss 3.74 on epoch=2
06/06/2022 01:30:00 - INFO - __main__ - Step 40 Global step 40 Train loss 3.14 on epoch=2
06/06/2022 01:30:03 - INFO - __main__ - Step 50 Global step 50 Train loss 2.88 on epoch=3
06/06/2022 01:30:09 - INFO - __main__ - Global step 50 Train loss 4.11 Classification-F1 0.05100346167573058 on epoch=3
06/06/2022 01:30:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05100346167573058 on epoch=3, global_step=50
06/06/2022 01:30:11 - INFO - __main__ - Step 60 Global step 60 Train loss 2.46 on epoch=4
06/06/2022 01:30:14 - INFO - __main__ - Step 70 Global step 70 Train loss 1.87 on epoch=4
06/06/2022 01:30:17 - INFO - __main__ - Step 80 Global step 80 Train loss 1.80 on epoch=5
06/06/2022 01:30:20 - INFO - __main__ - Step 90 Global step 90 Train loss 1.55 on epoch=6
06/06/2022 01:30:22 - INFO - __main__ - Step 100 Global step 100 Train loss 1.44 on epoch=7
06/06/2022 01:30:28 - INFO - __main__ - Global step 100 Train loss 1.82 Classification-F1 0.17420597963717227 on epoch=7
06/06/2022 01:30:28 - INFO - __main__ - Saving model with best Classification-F1: 0.05100346167573058 -> 0.17420597963717227 on epoch=7, global_step=100
06/06/2022 01:30:31 - INFO - __main__ - Step 110 Global step 110 Train loss 1.19 on epoch=7
06/06/2022 01:30:34 - INFO - __main__ - Step 120 Global step 120 Train loss 1.18 on epoch=8
06/06/2022 01:30:36 - INFO - __main__ - Step 130 Global step 130 Train loss 1.00 on epoch=9
06/06/2022 01:30:39 - INFO - __main__ - Step 140 Global step 140 Train loss 0.87 on epoch=9
06/06/2022 01:30:42 - INFO - __main__ - Step 150 Global step 150 Train loss 0.75 on epoch=10
06/06/2022 01:30:49 - INFO - __main__ - Global step 150 Train loss 1.00 Classification-F1 0.35054250891292044 on epoch=10
06/06/2022 01:30:49 - INFO - __main__ - Saving model with best Classification-F1: 0.17420597963717227 -> 0.35054250891292044 on epoch=10, global_step=150
06/06/2022 01:30:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.80 on epoch=11
06/06/2022 01:30:54 - INFO - __main__ - Step 170 Global step 170 Train loss 0.77 on epoch=12
06/06/2022 01:30:57 - INFO - __main__ - Step 180 Global step 180 Train loss 0.60 on epoch=12
06/06/2022 01:30:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.65 on epoch=13
06/06/2022 01:31:02 - INFO - __main__ - Step 200 Global step 200 Train loss 0.61 on epoch=14
06/06/2022 01:31:09 - INFO - __main__ - Global step 200 Train loss 0.69 Classification-F1 0.5874273614286212 on epoch=14
06/06/2022 01:31:09 - INFO - __main__ - Saving model with best Classification-F1: 0.35054250891292044 -> 0.5874273614286212 on epoch=14, global_step=200
06/06/2022 01:31:12 - INFO - __main__ - Step 210 Global step 210 Train loss 0.62 on epoch=14
06/06/2022 01:31:15 - INFO - __main__ - Step 220 Global step 220 Train loss 0.59 on epoch=15
06/06/2022 01:31:18 - INFO - __main__ - Step 230 Global step 230 Train loss 0.55 on epoch=16
06/06/2022 01:31:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.51 on epoch=17
06/06/2022 01:31:23 - INFO - __main__ - Step 250 Global step 250 Train loss 0.49 on epoch=17
06/06/2022 01:31:30 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.6375996561619476 on epoch=17
06/06/2022 01:31:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5874273614286212 -> 0.6375996561619476 on epoch=17, global_step=250
06/06/2022 01:31:33 - INFO - __main__ - Step 260 Global step 260 Train loss 0.50 on epoch=18
06/06/2022 01:31:35 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=19
06/06/2022 01:31:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=19
06/06/2022 01:31:41 - INFO - __main__ - Step 290 Global step 290 Train loss 0.48 on epoch=20
06/06/2022 01:31:43 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=21
06/06/2022 01:31:51 - INFO - __main__ - Global step 300 Train loss 0.48 Classification-F1 0.7819945321265345 on epoch=21
06/06/2022 01:31:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6375996561619476 -> 0.7819945321265345 on epoch=21, global_step=300
06/06/2022 01:31:53 - INFO - __main__ - Step 310 Global step 310 Train loss 0.45 on epoch=22
06/06/2022 01:31:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=22
06/06/2022 01:31:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.43 on epoch=23
06/06/2022 01:32:01 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=24
06/06/2022 01:32:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.34 on epoch=24
06/06/2022 01:32:11 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.7673216211076969 on epoch=24
06/06/2022 01:32:14 - INFO - __main__ - Step 360 Global step 360 Train loss 0.37 on epoch=25
06/06/2022 01:32:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.40 on epoch=26
06/06/2022 01:32:19 - INFO - __main__ - Step 380 Global step 380 Train loss 0.37 on epoch=27
06/06/2022 01:32:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.34 on epoch=27
06/06/2022 01:32:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.40 on epoch=28
06/06/2022 01:32:32 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.846590630025756 on epoch=28
06/06/2022 01:32:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7819945321265345 -> 0.846590630025756 on epoch=28, global_step=400
06/06/2022 01:32:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.36 on epoch=29
06/06/2022 01:32:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=29
06/06/2022 01:32:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=30
06/06/2022 01:32:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.35 on epoch=31
06/06/2022 01:32:46 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=32
06/06/2022 01:32:53 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.8531559409586466 on epoch=32
06/06/2022 01:32:53 - INFO - __main__ - Saving model with best Classification-F1: 0.846590630025756 -> 0.8531559409586466 on epoch=32, global_step=450
06/06/2022 01:32:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=32
06/06/2022 01:32:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=33
06/06/2022 01:33:01 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=34
06/06/2022 01:33:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
06/06/2022 01:33:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=35
06/06/2022 01:33:14 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.794379103221608 on epoch=35
06/06/2022 01:33:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=36
06/06/2022 01:33:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=37
06/06/2022 01:33:22 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=37
06/06/2022 01:33:25 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=38
06/06/2022 01:33:27 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=39
06/06/2022 01:33:34 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.7418554910579853 on epoch=39
06/06/2022 01:33:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=39
06/06/2022 01:33:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=40
06/06/2022 01:33:42 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=41
06/06/2022 01:33:45 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=42
06/06/2022 01:33:47 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=42
06/06/2022 01:33:54 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.652027914456757 on epoch=42
06/06/2022 01:33:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=43
06/06/2022 01:33:59 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=44
06/06/2022 01:34:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=44
06/06/2022 01:34:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=45
06/06/2022 01:34:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=46
06/06/2022 01:34:15 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.6719532402016978 on epoch=46
06/06/2022 01:34:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=47
06/06/2022 01:34:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
06/06/2022 01:34:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=48
06/06/2022 01:34:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=49
06/06/2022 01:34:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=49
06/06/2022 01:34:35 - INFO - __main__ - Global step 700 Train loss 0.14 Classification-F1 0.6556203720877146 on epoch=49
06/06/2022 01:34:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=50
06/06/2022 01:34:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=51
06/06/2022 01:34:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=52
06/06/2022 01:34:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=52
06/06/2022 01:34:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=53
06/06/2022 01:34:56 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.763997816652968 on epoch=53
06/06/2022 01:34:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=54
06/06/2022 01:35:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=54
06/06/2022 01:35:04 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=55
06/06/2022 01:35:07 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=56
06/06/2022 01:35:09 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=57
06/06/2022 01:35:16 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.6904664760726881 on epoch=57
06/06/2022 01:35:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=57
06/06/2022 01:35:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=58
06/06/2022 01:35:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=59
06/06/2022 01:35:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=59
06/06/2022 01:35:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=60
06/06/2022 01:35:36 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.7884169972974526 on epoch=60
06/06/2022 01:35:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=61
06/06/2022 01:35:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=62
06/06/2022 01:35:44 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=62
06/06/2022 01:35:47 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=63
06/06/2022 01:35:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=64
06/06/2022 01:35:56 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.7956184233224083 on epoch=64
06/06/2022 01:35:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=64
06/06/2022 01:36:01 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=65
06/06/2022 01:36:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=66
06/06/2022 01:36:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
06/06/2022 01:36:10 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=67
06/06/2022 01:36:16 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.7915788930718053 on epoch=67
06/06/2022 01:36:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=68
06/06/2022 01:36:21 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=69
06/06/2022 01:36:24 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=69
06/06/2022 01:36:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/06/2022 01:36:29 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/06/2022 01:36:36 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.9642025945275472 on epoch=71
06/06/2022 01:36:36 - INFO - __main__ - Saving model with best Classification-F1: 0.8531559409586466 -> 0.9642025945275472 on epoch=71, global_step=1000
06/06/2022 01:36:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=72
06/06/2022 01:36:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
06/06/2022 01:36:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=73
06/06/2022 01:36:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=74
06/06/2022 01:36:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=74
06/06/2022 01:36:56 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.9101938742261323 on epoch=74
06/06/2022 01:36:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
06/06/2022 01:37:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=76
06/06/2022 01:37:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=77
06/06/2022 01:37:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=77
06/06/2022 01:37:10 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=78
06/06/2022 01:37:16 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.9080433365917238 on epoch=78
06/06/2022 01:37:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=79
06/06/2022 01:37:22 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
06/06/2022 01:37:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
06/06/2022 01:37:27 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
06/06/2022 01:37:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
06/06/2022 01:37:36 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.9103045636631976 on epoch=82
06/06/2022 01:37:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/06/2022 01:37:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
06/06/2022 01:37:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
06/06/2022 01:37:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=84
06/06/2022 01:37:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
06/06/2022 01:37:56 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.9689940883489273 on epoch=85
06/06/2022 01:37:56 - INFO - __main__ - Saving model with best Classification-F1: 0.9642025945275472 -> 0.9689940883489273 on epoch=85, global_step=1200
06/06/2022 01:37:59 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/06/2022 01:38:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=87
06/06/2022 01:38:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/06/2022 01:38:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
06/06/2022 01:38:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
06/06/2022 01:38:17 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.9186460429724188 on epoch=89
06/06/2022 01:38:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=89
06/06/2022 01:38:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
06/06/2022 01:38:25 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=91
06/06/2022 01:38:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=92
06/06/2022 01:38:30 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
06/06/2022 01:38:36 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.9103045636631973 on epoch=92
06/06/2022 01:38:39 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
06/06/2022 01:38:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/06/2022 01:38:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=94
06/06/2022 01:38:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
06/06/2022 01:38:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=96
06/06/2022 01:38:56 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.817335813177547 on epoch=96
06/06/2022 01:38:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/06/2022 01:39:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
06/06/2022 01:39:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/06/2022 01:39:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
06/06/2022 01:39:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
06/06/2022 01:39:16 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.8970704859129905 on epoch=99
06/06/2022 01:39:19 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/06/2022 01:39:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/06/2022 01:39:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
06/06/2022 01:39:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
06/06/2022 01:39:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=103
06/06/2022 01:39:36 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.8257831404695055 on epoch=103
06/06/2022 01:39:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
06/06/2022 01:39:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/06/2022 01:39:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/06/2022 01:39:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/06/2022 01:39:50 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
06/06/2022 01:39:56 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8427668210890888 on epoch=107
06/06/2022 01:39:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/06/2022 01:40:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/06/2022 01:40:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
06/06/2022 01:40:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/06/2022 01:40:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/06/2022 01:40:16 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.892875212495706 on epoch=110
06/06/2022 01:40:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/06/2022 01:40:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/06/2022 01:40:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/06/2022 01:40:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/06/2022 01:40:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=114
06/06/2022 01:40:35 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.8824330360305116 on epoch=114
06/06/2022 01:40:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/06/2022 01:40:41 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/06/2022 01:40:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/06/2022 01:40:46 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
06/06/2022 01:40:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/06/2022 01:40:55 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.804337286433191 on epoch=117
06/06/2022 01:40:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
06/06/2022 01:41:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/06/2022 01:41:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/06/2022 01:41:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
06/06/2022 01:41:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/06/2022 01:41:14 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.8065341200018619 on epoch=121
06/06/2022 01:41:17 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/06/2022 01:41:20 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/06/2022 01:41:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/06/2022 01:41:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/06/2022 01:41:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/06/2022 01:41:34 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.8348886930644439 on epoch=124
06/06/2022 01:41:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
06/06/2022 01:41:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/06/2022 01:41:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/06/2022 01:41:45 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
06/06/2022 01:41:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/06/2022 01:41:53 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.830002185782301 on epoch=128
06/06/2022 01:41:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/06/2022 01:41:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/06/2022 01:42:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/06/2022 01:42:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
06/06/2022 01:42:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/06/2022 01:42:13 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.8285976722572941 on epoch=132
06/06/2022 01:42:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/06/2022 01:42:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
06/06/2022 01:42:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/06/2022 01:42:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=134
06/06/2022 01:42:27 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/06/2022 01:42:33 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7937005956427768 on epoch=135
06/06/2022 01:42:36 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
06/06/2022 01:42:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/06/2022 01:42:41 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/06/2022 01:42:44 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/06/2022 01:42:47 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/06/2022 01:42:53 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9103045636631976 on epoch=139
06/06/2022 01:42:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/06/2022 01:42:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/06/2022 01:43:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/06/2022 01:43:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/06/2022 01:43:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/06/2022 01:43:12 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8528712086513238 on epoch=142
06/06/2022 01:43:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
06/06/2022 01:43:18 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=144
06/06/2022 01:43:21 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
06/06/2022 01:43:23 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/06/2022 01:43:26 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/06/2022 01:43:32 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8521906856584276 on epoch=146
06/06/2022 01:43:35 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/06/2022 01:43:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/06/2022 01:43:40 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
06/06/2022 01:43:43 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/06/2022 01:43:46 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/06/2022 01:43:52 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.863147605083089 on epoch=149
06/06/2022 01:43:55 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/06/2022 01:43:58 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/06/2022 01:44:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/06/2022 01:44:03 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/06/2022 01:44:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/06/2022 01:44:12 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=153
06/06/2022 01:44:12 - INFO - __main__ - Saving model with best Classification-F1: 0.9689940883489273 -> 0.9865940511101802 on epoch=153, global_step=2150
06/06/2022 01:44:15 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/06/2022 01:44:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/06/2022 01:44:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/06/2022 01:44:23 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/06/2022 01:44:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
06/06/2022 01:44:32 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.853180749022483 on epoch=157
06/06/2022 01:44:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/06/2022 01:44:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/06/2022 01:44:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=159
06/06/2022 01:44:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/06/2022 01:44:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/06/2022 01:44:51 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9186705767350929 on epoch=160
06/06/2022 01:44:54 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/06/2022 01:44:56 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/06/2022 01:44:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/06/2022 01:45:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/06/2022 01:45:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
06/06/2022 01:45:11 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9821254014802402 on epoch=164
06/06/2022 01:45:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/06/2022 01:45:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/06/2022 01:45:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/06/2022 01:45:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/06/2022 01:45:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/06/2022 01:45:31 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9864404412791509 on epoch=167
06/06/2022 01:45:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/06/2022 01:45:37 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/06/2022 01:45:39 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/06/2022 01:45:42 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/06/2022 01:45:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/06/2022 01:45:51 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9821254014802402 on epoch=171
06/06/2022 01:45:54 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/06/2022 01:45:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/06/2022 01:45:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/06/2022 01:46:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=174
06/06/2022 01:46:05 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/06/2022 01:46:11 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7949394449088458 on epoch=174
06/06/2022 01:46:13 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/06/2022 01:46:16 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/06/2022 01:46:19 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/06/2022 01:46:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/06/2022 01:46:24 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/06/2022 01:46:30 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9103372434017596 on epoch=178
06/06/2022 01:46:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/06/2022 01:46:36 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/06/2022 01:46:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/06/2022 01:46:41 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/06/2022 01:46:44 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/06/2022 01:46:50 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8569525904203323 on epoch=182
06/06/2022 01:46:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/06/2022 01:46:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/06/2022 01:46:58 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/06/2022 01:47:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/06/2022 01:47:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/06/2022 01:47:09 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8103501811281698 on epoch=185
06/06/2022 01:47:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/06/2022 01:47:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/06/2022 01:47:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/06/2022 01:47:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/06/2022 01:47:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/06/2022 01:47:29 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.860145231112973 on epoch=189
06/06/2022 01:47:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/06/2022 01:47:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/06/2022 01:47:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/06/2022 01:47:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/06/2022 01:47:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/06/2022 01:47:48 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8969935941140875 on epoch=192
06/06/2022 01:47:51 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/06/2022 01:47:54 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/06/2022 01:47:56 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/06/2022 01:47:59 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/06/2022 01:48:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/06/2022 01:48:08 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9776611157659545 on epoch=196
06/06/2022 01:48:11 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/06/2022 01:48:13 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/06/2022 01:48:16 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/06/2022 01:48:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/06/2022 01:48:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/06/2022 01:48:27 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9270120560443141 on epoch=199
06/06/2022 01:48:30 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/06/2022 01:48:33 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
06/06/2022 01:48:35 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/06/2022 01:48:38 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/06/2022 01:48:41 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/06/2022 01:48:47 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9270120560443141 on epoch=203
06/06/2022 01:48:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/06/2022 01:48:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=204
06/06/2022 01:48:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/06/2022 01:48:57 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/06/2022 01:49:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/06/2022 01:49:06 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=207
06/06/2022 01:49:06 - INFO - __main__ - Saving model with best Classification-F1: 0.9865940511101802 -> 0.9910627007401202 on epoch=207, global_step=2900
06/06/2022 01:49:09 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/06/2022 01:49:12 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/06/2022 01:49:14 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/06/2022 01:49:17 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/06/2022 01:49:20 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/06/2022 01:49:26 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=210
06/06/2022 01:49:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/06/2022 01:49:31 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/06/2022 01:49:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/06/2022 01:49:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/06/2022 01:49:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/06/2022 01:49:41 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 01:49:41 - INFO - __main__ - Printing 3 examples
06/06/2022 01:49:41 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/06/2022 01:49:41 - INFO - __main__ - ['Film']
06/06/2022 01:49:41 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/06/2022 01:49:41 - INFO - __main__ - ['Film']
06/06/2022 01:49:41 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/06/2022 01:49:41 - INFO - __main__ - ['Film']
06/06/2022 01:49:41 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:49:41 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:49:42 - INFO - __main__ - Loaded 224 examples from train data
06/06/2022 01:49:42 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 01:49:42 - INFO - __main__ - Printing 3 examples
06/06/2022 01:49:42 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/06/2022 01:49:42 - INFO - __main__ - ['Film']
06/06/2022 01:49:42 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/06/2022 01:49:42 - INFO - __main__ - ['Film']
06/06/2022 01:49:42 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/06/2022 01:49:42 - INFO - __main__ - ['Film']
06/06/2022 01:49:42 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:49:42 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:49:42 - INFO - __main__ - Loaded 224 examples from dev data
06/06/2022 01:49:46 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9186705767350929 on epoch=214
06/06/2022 01:49:46 - INFO - __main__ - save last model!
06/06/2022 01:49:46 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 01:49:46 - INFO - __main__ - Start tokenizing ... 3500 instances
06/06/2022 01:49:46 - INFO - __main__ - Printing 3 examples
06/06/2022 01:49:46 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/06/2022 01:49:46 - INFO - __main__ - ['Animal']
06/06/2022 01:49:46 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/06/2022 01:49:46 - INFO - __main__ - ['Animal']
06/06/2022 01:49:46 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/06/2022 01:49:46 - INFO - __main__ - ['Village']
06/06/2022 01:49:46 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:49:48 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:49:52 - INFO - __main__ - Loaded 3500 examples from test data
06/06/2022 01:49:57 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 01:49:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 01:49:58 - INFO - __main__ - Starting training!
06/06/2022 01:52:04 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
06/06/2022 01:52:04 - INFO - __main__ - Classification-F1 on test data: 0.6826
06/06/2022 01:52:04 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.9910627007401202, test_performance=0.6825654782087233
06/06/2022 01:52:04 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
06/06/2022 01:52:05 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 01:52:05 - INFO - __main__ - Printing 3 examples
06/06/2022 01:52:05 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/06/2022 01:52:05 - INFO - __main__ - ['Film']
06/06/2022 01:52:05 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/06/2022 01:52:05 - INFO - __main__ - ['Film']
06/06/2022 01:52:05 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/06/2022 01:52:05 - INFO - __main__ - ['Film']
06/06/2022 01:52:05 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:52:05 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:52:06 - INFO - __main__ - Loaded 224 examples from train data
06/06/2022 01:52:06 - INFO - __main__ - Start tokenizing ... 224 instances
06/06/2022 01:52:06 - INFO - __main__ - Printing 3 examples
06/06/2022 01:52:06 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/06/2022 01:52:06 - INFO - __main__ - ['Film']
06/06/2022 01:52:06 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/06/2022 01:52:06 - INFO - __main__ - ['Film']
06/06/2022 01:52:06 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/06/2022 01:52:06 - INFO - __main__ - ['Film']
06/06/2022 01:52:06 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:52:06 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:52:06 - INFO - __main__ - Loaded 224 examples from dev data
06/06/2022 01:52:25 - INFO - __main__ - load prompt embedding from ckpt
06/06/2022 01:52:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 01:52:26 - INFO - __main__ - Starting training!
06/06/2022 01:52:29 - INFO - __main__ - Step 10 Global step 10 Train loss 6.15 on epoch=0
06/06/2022 01:52:32 - INFO - __main__ - Step 20 Global step 20 Train loss 5.07 on epoch=1
06/06/2022 01:52:35 - INFO - __main__ - Step 30 Global step 30 Train loss 4.36 on epoch=2
06/06/2022 01:52:38 - INFO - __main__ - Step 40 Global step 40 Train loss 3.67 on epoch=2
06/06/2022 01:52:40 - INFO - __main__ - Step 50 Global step 50 Train loss 3.48 on epoch=3
06/06/2022 01:52:46 - INFO - __main__ - Global step 50 Train loss 4.55 Classification-F1 0.018366437484084543 on epoch=3
06/06/2022 01:52:46 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.018366437484084543 on epoch=3, global_step=50
06/06/2022 01:52:49 - INFO - __main__ - Step 60 Global step 60 Train loss 3.07 on epoch=4
06/06/2022 01:52:52 - INFO - __main__ - Step 70 Global step 70 Train loss 2.52 on epoch=4
06/06/2022 01:52:55 - INFO - __main__ - Step 80 Global step 80 Train loss 2.64 on epoch=5
06/06/2022 01:52:57 - INFO - __main__ - Step 90 Global step 90 Train loss 2.22 on epoch=6
06/06/2022 01:53:00 - INFO - __main__ - Step 100 Global step 100 Train loss 2.07 on epoch=7
06/06/2022 01:53:05 - INFO - __main__ - Global step 100 Train loss 2.50 Classification-F1 0.07668426950280688 on epoch=7
06/06/2022 01:53:05 - INFO - __main__ - Saving model with best Classification-F1: 0.018366437484084543 -> 0.07668426950280688 on epoch=7, global_step=100
06/06/2022 01:53:08 - INFO - __main__ - Step 110 Global step 110 Train loss 1.71 on epoch=7
06/06/2022 01:53:11 - INFO - __main__ - Step 120 Global step 120 Train loss 1.72 on epoch=8
06/06/2022 01:53:13 - INFO - __main__ - Step 130 Global step 130 Train loss 1.59 on epoch=9
06/06/2022 01:53:16 - INFO - __main__ - Step 140 Global step 140 Train loss 1.39 on epoch=9
06/06/2022 01:53:19 - INFO - __main__ - Step 150 Global step 150 Train loss 1.39 on epoch=10
06/06/2022 01:53:25 - INFO - __main__ - Global step 150 Train loss 1.56 Classification-F1 0.20759790064415956 on epoch=10
06/06/2022 01:53:25 - INFO - __main__ - Saving model with best Classification-F1: 0.07668426950280688 -> 0.20759790064415956 on epoch=10, global_step=150
06/06/2022 01:53:28 - INFO - __main__ - Step 160 Global step 160 Train loss 1.28 on epoch=11
06/06/2022 01:53:30 - INFO - __main__ - Step 170 Global step 170 Train loss 1.05 on epoch=12
06/06/2022 01:53:33 - INFO - __main__ - Step 180 Global step 180 Train loss 0.92 on epoch=12
06/06/2022 01:53:36 - INFO - __main__ - Step 190 Global step 190 Train loss 0.92 on epoch=13
06/06/2022 01:53:38 - INFO - __main__ - Step 200 Global step 200 Train loss 0.86 on epoch=14
06/06/2022 01:53:45 - INFO - __main__ - Global step 200 Train loss 1.01 Classification-F1 0.3936205843422982 on epoch=14
06/06/2022 01:53:45 - INFO - __main__ - Saving model with best Classification-F1: 0.20759790064415956 -> 0.3936205843422982 on epoch=14, global_step=200
06/06/2022 01:53:48 - INFO - __main__ - Step 210 Global step 210 Train loss 0.88 on epoch=14
06/06/2022 01:53:50 - INFO - __main__ - Step 220 Global step 220 Train loss 0.89 on epoch=15
06/06/2022 01:53:53 - INFO - __main__ - Step 230 Global step 230 Train loss 0.92 on epoch=16
06/06/2022 01:53:56 - INFO - __main__ - Step 240 Global step 240 Train loss 0.83 on epoch=17
06/06/2022 01:53:58 - INFO - __main__ - Step 250 Global step 250 Train loss 0.71 on epoch=17
06/06/2022 01:54:05 - INFO - __main__ - Global step 250 Train loss 0.85 Classification-F1 0.47013264039577013 on epoch=17
06/06/2022 01:54:05 - INFO - __main__ - Saving model with best Classification-F1: 0.3936205843422982 -> 0.47013264039577013 on epoch=17, global_step=250
06/06/2022 01:54:08 - INFO - __main__ - Step 260 Global step 260 Train loss 0.77 on epoch=18
06/06/2022 01:54:11 - INFO - __main__ - Step 270 Global step 270 Train loss 0.74 on epoch=19
06/06/2022 01:54:13 - INFO - __main__ - Step 280 Global step 280 Train loss 0.61 on epoch=19
06/06/2022 01:54:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.64 on epoch=20
06/06/2022 01:54:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.69 on epoch=21
06/06/2022 01:54:25 - INFO - __main__ - Global step 300 Train loss 0.69 Classification-F1 0.5462175714177091 on epoch=21
06/06/2022 01:54:25 - INFO - __main__ - Saving model with best Classification-F1: 0.47013264039577013 -> 0.5462175714177091 on epoch=21, global_step=300
06/06/2022 01:54:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.59 on epoch=22
06/06/2022 01:54:31 - INFO - __main__ - Step 320 Global step 320 Train loss 0.57 on epoch=22
06/06/2022 01:54:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.60 on epoch=23
06/06/2022 01:54:36 - INFO - __main__ - Step 340 Global step 340 Train loss 0.57 on epoch=24
06/06/2022 01:54:39 - INFO - __main__ - Step 350 Global step 350 Train loss 0.48 on epoch=24
06/06/2022 01:54:46 - INFO - __main__ - Global step 350 Train loss 0.56 Classification-F1 0.6605311473014341 on epoch=24
06/06/2022 01:54:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5462175714177091 -> 0.6605311473014341 on epoch=24, global_step=350
06/06/2022 01:54:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.48 on epoch=25
06/06/2022 01:54:51 - INFO - __main__ - Step 370 Global step 370 Train loss 0.51 on epoch=26
06/06/2022 01:54:54 - INFO - __main__ - Step 380 Global step 380 Train loss 0.52 on epoch=27
06/06/2022 01:54:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.45 on epoch=27
06/06/2022 01:54:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.58 on epoch=28
06/06/2022 01:55:06 - INFO - __main__ - Global step 400 Train loss 0.51 Classification-F1 0.6009142427379697 on epoch=28
06/06/2022 01:55:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.52 on epoch=29
06/06/2022 01:55:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.40 on epoch=29
06/06/2022 01:55:14 - INFO - __main__ - Step 430 Global step 430 Train loss 0.47 on epoch=30
06/06/2022 01:55:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.44 on epoch=31
06/06/2022 01:55:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.46 on epoch=32
06/06/2022 01:55:27 - INFO - __main__ - Global step 450 Train loss 0.46 Classification-F1 0.5968999812712336 on epoch=32
06/06/2022 01:55:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.39 on epoch=32
06/06/2022 01:55:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.45 on epoch=33
06/06/2022 01:55:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.39 on epoch=34
06/06/2022 01:55:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.34 on epoch=34
06/06/2022 01:55:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.48 on epoch=35
06/06/2022 01:55:47 - INFO - __main__ - Global step 500 Train loss 0.41 Classification-F1 0.767154039480792 on epoch=35
06/06/2022 01:55:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6605311473014341 -> 0.767154039480792 on epoch=35, global_step=500
06/06/2022 01:55:50 - INFO - __main__ - Step 510 Global step 510 Train loss 0.32 on epoch=36
06/06/2022 01:55:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.33 on epoch=37
06/06/2022 01:55:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.25 on epoch=37
06/06/2022 01:55:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.42 on epoch=38
06/06/2022 01:56:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.35 on epoch=39
06/06/2022 01:56:08 - INFO - __main__ - Global step 550 Train loss 0.33 Classification-F1 0.5240813899303491 on epoch=39
06/06/2022 01:56:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.50 on epoch=39
06/06/2022 01:56:14 - INFO - __main__ - Step 570 Global step 570 Train loss 0.41 on epoch=40
06/06/2022 01:56:16 - INFO - __main__ - Step 580 Global step 580 Train loss 0.30 on epoch=41
06/06/2022 01:56:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.33 on epoch=42
06/06/2022 01:56:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.29 on epoch=42
06/06/2022 01:56:29 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.7914316467617362 on epoch=42
06/06/2022 01:56:29 - INFO - __main__ - Saving model with best Classification-F1: 0.767154039480792 -> 0.7914316467617362 on epoch=42, global_step=600
06/06/2022 01:56:32 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=43
06/06/2022 01:56:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=44
06/06/2022 01:56:37 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=44
06/06/2022 01:56:40 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=45
06/06/2022 01:56:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=46
06/06/2022 01:56:50 - INFO - __main__ - Global step 650 Train loss 0.27 Classification-F1 0.7582954293373809 on epoch=46
06/06/2022 01:56:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.30 on epoch=47
06/06/2022 01:56:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=47
06/06/2022 01:56:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.29 on epoch=48
06/06/2022 01:57:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.30 on epoch=49
06/06/2022 01:57:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.27 on epoch=49
06/06/2022 01:57:11 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.6741499756707928 on epoch=49
06/06/2022 01:57:13 - INFO - __main__ - Step 710 Global step 710 Train loss 0.23 on epoch=50
06/06/2022 01:57:16 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=51
06/06/2022 01:57:19 - INFO - __main__ - Step 730 Global step 730 Train loss 0.32 on epoch=52
06/06/2022 01:57:21 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=52
06/06/2022 01:57:24 - INFO - __main__ - Step 750 Global step 750 Train loss 0.26 on epoch=53
06/06/2022 01:57:31 - INFO - __main__ - Global step 750 Train loss 0.27 Classification-F1 0.796471998379019 on epoch=53
06/06/2022 01:57:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7914316467617362 -> 0.796471998379019 on epoch=53, global_step=750
06/06/2022 01:57:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.25 on epoch=54
06/06/2022 01:57:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=54
06/06/2022 01:57:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.26 on epoch=55
06/06/2022 01:57:42 - INFO - __main__ - Step 790 Global step 790 Train loss 0.30 on epoch=56
06/06/2022 01:57:45 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=57
06/06/2022 01:57:52 - INFO - __main__ - Global step 800 Train loss 0.26 Classification-F1 0.6767426216469944 on epoch=57
06/06/2022 01:57:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.24 on epoch=57
06/06/2022 01:57:57 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=58
06/06/2022 01:58:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=59
06/06/2022 01:58:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=59
06/06/2022 01:58:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.28 on epoch=60
06/06/2022 01:58:13 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.7067374817232093 on epoch=60
06/06/2022 01:58:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.31 on epoch=61
06/06/2022 01:58:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=62
06/06/2022 01:58:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=62
06/06/2022 01:58:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=63
06/06/2022 01:58:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.26 on epoch=64
06/06/2022 01:58:33 - INFO - __main__ - Global step 900 Train loss 0.24 Classification-F1 0.6193534011845209 on epoch=64
06/06/2022 01:58:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.23 on epoch=64
06/06/2022 01:58:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.21 on epoch=65
06/06/2022 01:58:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=66
06/06/2022 01:58:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.25 on epoch=67
06/06/2022 01:58:47 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=67
06/06/2022 01:58:54 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.646918807892875 on epoch=67
06/06/2022 01:58:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=68
06/06/2022 01:59:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=69
06/06/2022 01:59:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.23 on epoch=69
06/06/2022 01:59:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=70
06/06/2022 01:59:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
06/06/2022 01:59:15 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.6138409948019955 on epoch=71
06/06/2022 01:59:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=72
06/06/2022 01:59:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=72
06/06/2022 01:59:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=73
06/06/2022 01:59:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=74
06/06/2022 01:59:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=74
06/06/2022 01:59:35 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.664924640776034 on epoch=74
06/06/2022 01:59:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=75
06/06/2022 01:59:41 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=76
06/06/2022 01:59:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.21 on epoch=77
06/06/2022 01:59:46 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=77
06/06/2022 01:59:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=78
06/06/2022 01:59:55 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.5938381372395171 on epoch=78
06/06/2022 01:59:58 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.24 on epoch=79
06/06/2022 02:00:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
06/06/2022 02:00:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.16 on epoch=80
06/06/2022 02:00:06 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=81
06/06/2022 02:00:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=82
06/06/2022 02:00:16 - INFO - __main__ - Global step 1150 Train loss 0.16 Classification-F1 0.6286489684622113 on epoch=82
06/06/2022 02:00:19 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=82
06/06/2022 02:00:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=83
06/06/2022 02:00:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=84
06/06/2022 02:00:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/06/2022 02:00:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=85
06/06/2022 02:00:37 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.6874176447863989 on epoch=85
06/06/2022 02:00:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.15 on epoch=86
06/06/2022 02:00:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
06/06/2022 02:00:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
06/06/2022 02:00:48 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=88
06/06/2022 02:00:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=89
06/06/2022 02:00:57 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.6761789445729257 on epoch=89
06/06/2022 02:01:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=89
06/06/2022 02:01:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=90
06/06/2022 02:01:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=91
06/06/2022 02:01:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=92
06/06/2022 02:01:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=92
06/06/2022 02:01:18 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.654758098353781 on epoch=92
06/06/2022 02:01:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=93
06/06/2022 02:01:23 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=94
06/06/2022 02:01:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=94
06/06/2022 02:01:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/06/2022 02:01:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=96
06/06/2022 02:01:39 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.6657910874342557 on epoch=96
06/06/2022 02:01:41 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
06/06/2022 02:01:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
06/06/2022 02:01:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=98
06/06/2022 02:01:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=99
06/06/2022 02:01:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=99
06/06/2022 02:01:59 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.758931578688248 on epoch=99
06/06/2022 02:02:02 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=100
06/06/2022 02:02:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
06/06/2022 02:02:07 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=102
06/06/2022 02:02:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=102
06/06/2022 02:02:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=103
06/06/2022 02:02:20 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.7782673841022988 on epoch=103
06/06/2022 02:02:23 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=104
06/06/2022 02:02:25 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=104
06/06/2022 02:02:28 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
06/06/2022 02:02:31 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=106
06/06/2022 02:02:33 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
06/06/2022 02:02:40 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.7683172717077171 on epoch=107
06/06/2022 02:02:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=107
06/06/2022 02:02:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
06/06/2022 02:02:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=109
06/06/2022 02:02:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/06/2022 02:02:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
06/06/2022 02:03:01 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.8452000802659521 on epoch=110
06/06/2022 02:03:01 - INFO - __main__ - Saving model with best Classification-F1: 0.796471998379019 -> 0.8452000802659521 on epoch=110, global_step=1550
06/06/2022 02:03:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=111
06/06/2022 02:03:07 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=112
06/06/2022 02:03:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
06/06/2022 02:03:12 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=113
06/06/2022 02:03:15 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=114
06/06/2022 02:03:22 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.8348840225797702 on epoch=114
06/06/2022 02:03:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=114
06/06/2022 02:03:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=115
06/06/2022 02:03:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=116
06/06/2022 02:03:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=117
06/06/2022 02:03:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=117
06/06/2022 02:03:43 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.7146803184135088 on epoch=117
06/06/2022 02:03:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
06/06/2022 02:03:48 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=119
06/06/2022 02:03:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
06/06/2022 02:03:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
06/06/2022 02:03:56 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/06/2022 02:04:03 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.8449366493721333 on epoch=121
06/06/2022 02:04:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=122
06/06/2022 02:04:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.15 on epoch=122
06/06/2022 02:04:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/06/2022 02:04:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=124
06/06/2022 02:04:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
06/06/2022 02:04:23 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.8379072039576665 on epoch=124
06/06/2022 02:04:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
06/06/2022 02:04:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/06/2022 02:04:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
06/06/2022 02:04:34 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/06/2022 02:04:37 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=128
06/06/2022 02:04:44 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.712014099683879 on epoch=128
06/06/2022 02:04:47 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
06/06/2022 02:04:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
06/06/2022 02:04:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=130
06/06/2022 02:04:55 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
06/06/2022 02:04:57 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=132
06/06/2022 02:05:04 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.7587463644811314 on epoch=132
06/06/2022 02:05:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
06/06/2022 02:05:10 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=133
06/06/2022 02:05:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=134
06/06/2022 02:05:15 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=134
06/06/2022 02:05:18 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/06/2022 02:05:25 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.8424402798142717 on epoch=135
06/06/2022 02:05:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/06/2022 02:05:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/06/2022 02:05:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
06/06/2022 02:05:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=138
06/06/2022 02:05:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/06/2022 02:05:45 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.6614430596285436 on epoch=139
06/06/2022 02:05:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=139
06/06/2022 02:05:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/06/2022 02:05:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=141
06/06/2022 02:05:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/06/2022 02:05:59 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/06/2022 02:06:06 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6980565416473735 on epoch=142
06/06/2022 02:06:09 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=143
06/06/2022 02:06:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=144
06/06/2022 02:06:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=144
06/06/2022 02:06:17 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/06/2022 02:06:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/06/2022 02:06:27 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.8544526314924796 on epoch=146
06/06/2022 02:06:27 - INFO - __main__ - Saving model with best Classification-F1: 0.8452000802659521 -> 0.8544526314924796 on epoch=146, global_step=2050
06/06/2022 02:06:29 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
06/06/2022 02:06:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
06/06/2022 02:06:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=148
06/06/2022 02:06:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.10 on epoch=149
06/06/2022 02:06:40 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.11 on epoch=149
06/06/2022 02:06:47 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.7464115618551104 on epoch=149
06/06/2022 02:06:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/06/2022 02:06:52 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/06/2022 02:06:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
06/06/2022 02:06:58 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/06/2022 02:07:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/06/2022 02:07:07 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.855304467828187 on epoch=153
06/06/2022 02:07:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8544526314924796 -> 0.855304467828187 on epoch=153, global_step=2150
06/06/2022 02:07:10 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/06/2022 02:07:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/06/2022 02:07:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/06/2022 02:07:18 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
06/06/2022 02:07:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/06/2022 02:07:27 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9145039100684262 on epoch=157
06/06/2022 02:07:27 - INFO - __main__ - Saving model with best Classification-F1: 0.855304467828187 -> 0.9145039100684262 on epoch=157, global_step=2200
06/06/2022 02:07:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=157
06/06/2022 02:07:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/06/2022 02:07:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.13 on epoch=159
06/06/2022 02:07:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
06/06/2022 02:07:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=160
06/06/2022 02:07:47 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.9104560788147128 on epoch=160
06/06/2022 02:07:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
06/06/2022 02:07:52 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/06/2022 02:07:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/06/2022 02:07:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/06/2022 02:08:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
06/06/2022 02:08:07 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8457697947214076 on epoch=164
06/06/2022 02:08:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
06/06/2022 02:08:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
06/06/2022 02:08:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/06/2022 02:08:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/06/2022 02:08:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/06/2022 02:08:27 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9821297653958947 on epoch=167
06/06/2022 02:08:27 - INFO - __main__ - Saving model with best Classification-F1: 0.9145039100684262 -> 0.9821297653958947 on epoch=167, global_step=2350
06/06/2022 02:08:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/06/2022 02:08:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/06/2022 02:08:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
06/06/2022 02:08:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/06/2022 02:08:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=171
06/06/2022 02:08:46 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.7984866121711753 on epoch=171
06/06/2022 02:08:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
06/06/2022 02:08:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/06/2022 02:08:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/06/2022 02:08:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=174
06/06/2022 02:09:00 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/06/2022 02:09:07 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.8504349732928362 on epoch=174
06/06/2022 02:09:10 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/06/2022 02:09:12 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/06/2022 02:09:15 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=177
06/06/2022 02:09:18 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/06/2022 02:09:21 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=178
06/06/2022 02:09:27 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.855196878054741 on epoch=178
06/06/2022 02:09:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/06/2022 02:09:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/06/2022 02:09:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/06/2022 02:09:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
06/06/2022 02:09:41 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=182
06/06/2022 02:09:48 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9122100032583906 on epoch=182
06/06/2022 02:09:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/06/2022 02:09:53 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/06/2022 02:09:56 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
06/06/2022 02:09:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/06/2022 02:10:01 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/06/2022 02:10:08 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9776698435972629 on epoch=185
06/06/2022 02:10:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/06/2022 02:10:14 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
06/06/2022 02:10:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/06/2022 02:10:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/06/2022 02:10:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/06/2022 02:10:29 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8434513092260365 on epoch=189
06/06/2022 02:10:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/06/2022 02:10:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/06/2022 02:10:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=191
06/06/2022 02:10:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/06/2022 02:10:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/06/2022 02:10:49 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.8513028470185728 on epoch=192
06/06/2022 02:10:51 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=193
06/06/2022 02:10:54 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=194
06/06/2022 02:10:57 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/06/2022 02:10:59 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/06/2022 02:11:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/06/2022 02:11:09 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.9123247656833996 on epoch=196
06/06/2022 02:11:11 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/06/2022 02:11:14 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/06/2022 02:11:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/06/2022 02:11:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/06/2022 02:11:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/06/2022 02:11:29 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9100029940179124 on epoch=199
06/06/2022 02:11:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/06/2022 02:11:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/06/2022 02:11:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/06/2022 02:11:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/06/2022 02:11:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/06/2022 02:11:48 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9733241537084043 on epoch=203
06/06/2022 02:11:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/06/2022 02:11:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/06/2022 02:11:57 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/06/2022 02:11:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/06/2022 02:12:02 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
06/06/2022 02:12:08 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9035702853966612 on epoch=207
06/06/2022 02:12:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/06/2022 02:12:14 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/06/2022 02:12:17 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=209
06/06/2022 02:12:19 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=209
06/06/2022 02:12:22 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/06/2022 02:12:29 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.9077090872078768 on epoch=210
06/06/2022 02:12:31 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/06/2022 02:12:34 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/06/2022 02:12:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/06/2022 02:12:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/06/2022 02:12:42 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/06/2022 02:12:48 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9733321114369503 on epoch=214
06/06/2022 02:12:48 - INFO - __main__ - save last model!
06/06/2022 02:12:48 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 02:12:48 - INFO - __main__ - Start tokenizing ... 3500 instances
06/06/2022 02:12:48 - INFO - __main__ - Printing 3 examples
06/06/2022 02:12:48 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/06/2022 02:12:48 - INFO - __main__ - ['Animal']
06/06/2022 02:12:48 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/06/2022 02:12:48 - INFO - __main__ - ['Animal']
06/06/2022 02:12:48 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/06/2022 02:12:48 - INFO - __main__ - ['Village']
06/06/2022 02:12:49 - INFO - __main__ - Tokenizing Input ...
06/06/2022 02:12:50 - INFO - __main__ - Tokenizing Output ...
06/06/2022 02:12:54 - INFO - __main__ - Loaded 3500 examples from test data
06/06/2022 02:15:05 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up128shot/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
06/06/2022 02:15:05 - INFO - __main__ - Classification-F1 on test data: 0.6486
06/06/2022 02:15:05 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.9821297653958947, test_performance=0.6486229124717091
