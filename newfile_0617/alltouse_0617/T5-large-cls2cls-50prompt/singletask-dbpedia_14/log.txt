05/30/2022 07:41:16 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-cls2cls-50prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-50prompt/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=50, cuda='6,7')
05/30/2022 07:41:16 - INFO - __main__ - models/T5-large-cls2cls-50prompt/singletask-dbpedia_14
05/30/2022 07:41:16 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-cls2cls-50prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-50prompt/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=50, cuda='6,7')
05/30/2022 07:41:16 - INFO - __main__ - models/T5-large-cls2cls-50prompt/singletask-dbpedia_14
05/30/2022 07:41:18 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/30/2022 07:41:18 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/30/2022 07:41:18 - INFO - __main__ - args.device: cuda:0
05/30/2022 07:41:18 - INFO - __main__ - Using 2 gpus
05/30/2022 07:41:18 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/30/2022 07:41:18 - INFO - __main__ - args.device: cuda:1
05/30/2022 07:41:18 - INFO - __main__ - Using 2 gpus
05/30/2022 07:41:18 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/30/2022 07:41:22 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
05/30/2022 07:41:23 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 07:41:23 - INFO - __main__ - Printing 3 examples
05/30/2022 07:41:23 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/30/2022 07:41:23 - INFO - __main__ - ['Animal']
05/30/2022 07:41:23 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/30/2022 07:41:23 - INFO - __main__ - ['Animal']
05/30/2022 07:41:23 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/30/2022 07:41:23 - INFO - __main__ - ['Animal']
05/30/2022 07:41:23 - INFO - __main__ - Tokenizing Input ...
05/30/2022 07:41:23 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 07:41:23 - INFO - __main__ - Printing 3 examples
05/30/2022 07:41:23 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/30/2022 07:41:23 - INFO - __main__ - ['Animal']
05/30/2022 07:41:23 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/30/2022 07:41:23 - INFO - __main__ - ['Animal']
05/30/2022 07:41:23 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/30/2022 07:41:23 - INFO - __main__ - ['Animal']
05/30/2022 07:41:23 - INFO - __main__ - Tokenizing Input ...
05/30/2022 07:41:23 - INFO - __main__ - Tokenizing Output ...
05/30/2022 07:41:24 - INFO - __main__ - Tokenizing Output ...
05/30/2022 07:41:24 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 07:41:24 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 07:41:24 - INFO - __main__ - Printing 3 examples
05/30/2022 07:41:24 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/30/2022 07:41:24 - INFO - __main__ - ['Animal']
05/30/2022 07:41:24 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/30/2022 07:41:24 - INFO - __main__ - ['Animal']
05/30/2022 07:41:24 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/30/2022 07:41:24 - INFO - __main__ - ['Animal']
05/30/2022 07:41:24 - INFO - __main__ - Tokenizing Input ...
05/30/2022 07:41:24 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 07:41:24 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 07:41:24 - INFO - __main__ - Printing 3 examples
05/30/2022 07:41:24 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/30/2022 07:41:24 - INFO - __main__ - ['Animal']
05/30/2022 07:41:24 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/30/2022 07:41:24 - INFO - __main__ - ['Animal']
05/30/2022 07:41:24 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/30/2022 07:41:24 - INFO - __main__ - ['Animal']
05/30/2022 07:41:24 - INFO - __main__ - Tokenizing Input ...
05/30/2022 07:41:24 - INFO - __main__ - Tokenizing Output ...
05/30/2022 07:41:24 - INFO - __main__ - Tokenizing Output ...
05/30/2022 07:41:24 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 07:41:24 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 07:41:42 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 07:41:42 - INFO - __main__ - task name: dbpedia_14
05/30/2022 07:41:42 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 07:41:42 - INFO - __main__ - task name: dbpedia_14
05/30/2022 07:41:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 07:41:43 - INFO - __main__ - Starting training!
05/30/2022 07:41:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 07:41:43 - INFO - __main__ - Starting training!
05/30/2022 07:41:46 - INFO - __main__ - Step 10 Global step 10 Train loss 6.96 on epoch=0
05/30/2022 07:41:49 - INFO - __main__ - Step 20 Global step 20 Train loss 5.97 on epoch=1
05/30/2022 07:41:51 - INFO - __main__ - Step 30 Global step 30 Train loss 4.49 on epoch=2
05/30/2022 07:41:54 - INFO - __main__ - Step 40 Global step 40 Train loss 3.33 on epoch=2
05/30/2022 07:41:56 - INFO - __main__ - Step 50 Global step 50 Train loss 2.90 on epoch=3
05/30/2022 07:42:29 - INFO - __main__ - Global step 50 Train loss 4.73 Classification-F1 0.08305559010731971 on epoch=3
05/30/2022 07:42:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08305559010731971 on epoch=3, global_step=50
05/30/2022 07:42:31 - INFO - __main__ - Step 60 Global step 60 Train loss 2.63 on epoch=4
05/30/2022 07:42:33 - INFO - __main__ - Step 70 Global step 70 Train loss 2.22 on epoch=4
05/30/2022 07:42:36 - INFO - __main__ - Step 80 Global step 80 Train loss 2.18 on epoch=5
05/30/2022 07:42:38 - INFO - __main__ - Step 90 Global step 90 Train loss 1.83 on epoch=6
05/30/2022 07:42:41 - INFO - __main__ - Step 100 Global step 100 Train loss 1.68 on epoch=7
05/30/2022 07:42:48 - INFO - __main__ - Global step 100 Train loss 2.11 Classification-F1 0.30863088336436023 on epoch=7
05/30/2022 07:42:48 - INFO - __main__ - Saving model with best Classification-F1: 0.08305559010731971 -> 0.30863088336436023 on epoch=7, global_step=100
05/30/2022 07:42:51 - INFO - __main__ - Step 110 Global step 110 Train loss 1.55 on epoch=7
05/30/2022 07:42:53 - INFO - __main__ - Step 120 Global step 120 Train loss 1.46 on epoch=8
05/30/2022 07:42:55 - INFO - __main__ - Step 130 Global step 130 Train loss 1.28 on epoch=9
05/30/2022 07:42:58 - INFO - __main__ - Step 140 Global step 140 Train loss 1.13 on epoch=9
05/30/2022 07:43:00 - INFO - __main__ - Step 150 Global step 150 Train loss 1.13 on epoch=10
05/30/2022 07:43:07 - INFO - __main__ - Global step 150 Train loss 1.31 Classification-F1 0.3540031080947972 on epoch=10
05/30/2022 07:43:07 - INFO - __main__ - Saving model with best Classification-F1: 0.30863088336436023 -> 0.3540031080947972 on epoch=10, global_step=150
05/30/2022 07:43:10 - INFO - __main__ - Step 160 Global step 160 Train loss 1.05 on epoch=11
05/30/2022 07:43:12 - INFO - __main__ - Step 170 Global step 170 Train loss 1.08 on epoch=12
05/30/2022 07:43:14 - INFO - __main__ - Step 180 Global step 180 Train loss 0.90 on epoch=12
05/30/2022 07:43:17 - INFO - __main__ - Step 190 Global step 190 Train loss 0.86 on epoch=13
05/30/2022 07:43:19 - INFO - __main__ - Step 200 Global step 200 Train loss 0.88 on epoch=14
05/30/2022 07:43:27 - INFO - __main__ - Global step 200 Train loss 0.96 Classification-F1 0.3248550727434332 on epoch=14
05/30/2022 07:43:30 - INFO - __main__ - Step 210 Global step 210 Train loss 0.88 on epoch=14
05/30/2022 07:43:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.94 on epoch=15
05/30/2022 07:43:35 - INFO - __main__ - Step 230 Global step 230 Train loss 0.80 on epoch=16
05/30/2022 07:43:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.84 on epoch=17
05/30/2022 07:43:40 - INFO - __main__ - Step 250 Global step 250 Train loss 0.78 on epoch=17
05/30/2022 07:43:46 - INFO - __main__ - Global step 250 Train loss 0.85 Classification-F1 0.3215185152685152 on epoch=17
05/30/2022 07:43:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.75 on epoch=18
05/30/2022 07:43:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.68 on epoch=19
05/30/2022 07:43:53 - INFO - __main__ - Step 280 Global step 280 Train loss 0.63 on epoch=19
05/30/2022 07:43:55 - INFO - __main__ - Step 290 Global step 290 Train loss 0.63 on epoch=20
05/30/2022 07:43:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.68 on epoch=21
05/30/2022 07:44:04 - INFO - __main__ - Global step 300 Train loss 0.67 Classification-F1 0.4145777233201986 on epoch=21
05/30/2022 07:44:04 - INFO - __main__ - Saving model with best Classification-F1: 0.3540031080947972 -> 0.4145777233201986 on epoch=21, global_step=300
05/30/2022 07:44:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.77 on epoch=22
05/30/2022 07:44:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.54 on epoch=22
05/30/2022 07:44:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.63 on epoch=23
05/30/2022 07:44:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.65 on epoch=24
05/30/2022 07:44:16 - INFO - __main__ - Step 350 Global step 350 Train loss 0.55 on epoch=24
05/30/2022 07:44:22 - INFO - __main__ - Global step 350 Train loss 0.63 Classification-F1 0.46135799682420897 on epoch=24
05/30/2022 07:44:22 - INFO - __main__ - Saving model with best Classification-F1: 0.4145777233201986 -> 0.46135799682420897 on epoch=24, global_step=350
05/30/2022 07:44:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.54 on epoch=25
05/30/2022 07:44:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.52 on epoch=26
05/30/2022 07:44:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.53 on epoch=27
05/30/2022 07:44:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.50 on epoch=27
05/30/2022 07:44:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.53 on epoch=28
05/30/2022 07:44:41 - INFO - __main__ - Global step 400 Train loss 0.53 Classification-F1 0.48456035906764733 on epoch=28
05/30/2022 07:44:41 - INFO - __main__ - Saving model with best Classification-F1: 0.46135799682420897 -> 0.48456035906764733 on epoch=28, global_step=400
05/30/2022 07:44:43 - INFO - __main__ - Step 410 Global step 410 Train loss 0.50 on epoch=29
05/30/2022 07:44:46 - INFO - __main__ - Step 420 Global step 420 Train loss 0.45 on epoch=29
05/30/2022 07:44:48 - INFO - __main__ - Step 430 Global step 430 Train loss 0.52 on epoch=30
05/30/2022 07:44:51 - INFO - __main__ - Step 440 Global step 440 Train loss 0.40 on epoch=31
05/30/2022 07:44:53 - INFO - __main__ - Step 450 Global step 450 Train loss 0.58 on epoch=32
05/30/2022 07:44:59 - INFO - __main__ - Global step 450 Train loss 0.49 Classification-F1 0.5140430166727116 on epoch=32
05/30/2022 07:44:59 - INFO - __main__ - Saving model with best Classification-F1: 0.48456035906764733 -> 0.5140430166727116 on epoch=32, global_step=450
05/30/2022 07:45:02 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=32
05/30/2022 07:45:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.40 on epoch=33
05/30/2022 07:45:06 - INFO - __main__ - Step 480 Global step 480 Train loss 0.45 on epoch=34
05/30/2022 07:45:09 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=34
05/30/2022 07:45:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.38 on epoch=35
05/30/2022 07:45:18 - INFO - __main__ - Global step 500 Train loss 0.38 Classification-F1 0.5648332313679861 on epoch=35
05/30/2022 07:45:18 - INFO - __main__ - Saving model with best Classification-F1: 0.5140430166727116 -> 0.5648332313679861 on epoch=35, global_step=500
05/30/2022 07:45:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.35 on epoch=36
05/30/2022 07:45:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.40 on epoch=37
05/30/2022 07:45:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=37
05/30/2022 07:45:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=38
05/30/2022 07:45:30 - INFO - __main__ - Step 550 Global step 550 Train loss 0.35 on epoch=39
05/30/2022 07:45:36 - INFO - __main__ - Global step 550 Train loss 0.37 Classification-F1 0.657502369896997 on epoch=39
05/30/2022 07:45:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5648332313679861 -> 0.657502369896997 on epoch=39, global_step=550
05/30/2022 07:45:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.37 on epoch=39
05/30/2022 07:45:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.29 on epoch=40
05/30/2022 07:45:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.33 on epoch=41
05/30/2022 07:45:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=42
05/30/2022 07:45:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.38 on epoch=42
05/30/2022 07:45:55 - INFO - __main__ - Global step 600 Train loss 0.34 Classification-F1 0.6952920479329677 on epoch=42
05/30/2022 07:45:55 - INFO - __main__ - Saving model with best Classification-F1: 0.657502369896997 -> 0.6952920479329677 on epoch=42, global_step=600
05/30/2022 07:45:58 - INFO - __main__ - Step 610 Global step 610 Train loss 0.32 on epoch=43
05/30/2022 07:46:00 - INFO - __main__ - Step 620 Global step 620 Train loss 0.37 on epoch=44
05/30/2022 07:46:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.42 on epoch=44
05/30/2022 07:46:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=45
05/30/2022 07:46:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.28 on epoch=46
05/30/2022 07:46:14 - INFO - __main__ - Global step 650 Train loss 0.33 Classification-F1 0.6897296911502511 on epoch=46
05/30/2022 07:46:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.39 on epoch=47
05/30/2022 07:46:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=47
05/30/2022 07:46:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=48
05/30/2022 07:46:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.39 on epoch=49
05/30/2022 07:46:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.33 on epoch=49
05/30/2022 07:46:32 - INFO - __main__ - Global step 700 Train loss 0.33 Classification-F1 0.7520796133489541 on epoch=49
05/30/2022 07:46:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6952920479329677 -> 0.7520796133489541 on epoch=49, global_step=700
05/30/2022 07:46:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.31 on epoch=50
05/30/2022 07:46:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=51
05/30/2022 07:46:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.29 on epoch=52
05/30/2022 07:46:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.26 on epoch=52
05/30/2022 07:46:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=53
05/30/2022 07:46:50 - INFO - __main__ - Global step 750 Train loss 0.26 Classification-F1 0.6386808909501392 on epoch=53
05/30/2022 07:46:53 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=54
05/30/2022 07:46:55 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=54
05/30/2022 07:46:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.26 on epoch=55
05/30/2022 07:47:00 - INFO - __main__ - Step 790 Global step 790 Train loss 0.26 on epoch=56
05/30/2022 07:47:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.27 on epoch=57
05/30/2022 07:47:08 - INFO - __main__ - Global step 800 Train loss 0.24 Classification-F1 0.7118995992313586 on epoch=57
05/30/2022 07:47:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=57
05/30/2022 07:47:14 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=58
05/30/2022 07:47:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=59
05/30/2022 07:47:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=59
05/30/2022 07:47:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.28 on epoch=60
05/30/2022 07:47:27 - INFO - __main__ - Global step 850 Train loss 0.22 Classification-F1 0.7090663447755655 on epoch=60
05/30/2022 07:47:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=61
05/30/2022 07:47:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=62
05/30/2022 07:47:35 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=62
05/30/2022 07:47:37 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=63
05/30/2022 07:47:40 - INFO - __main__ - Step 900 Global step 900 Train loss 0.24 on epoch=64
05/30/2022 07:47:46 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.6050842913642874 on epoch=64
05/30/2022 07:47:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=64
05/30/2022 07:47:51 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=65
05/30/2022 07:47:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.30 on epoch=66
05/30/2022 07:47:56 - INFO - __main__ - Step 940 Global step 940 Train loss 0.24 on epoch=67
05/30/2022 07:47:58 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=67
05/30/2022 07:48:04 - INFO - __main__ - Global step 950 Train loss 0.21 Classification-F1 0.6651631781201675 on epoch=67
05/30/2022 07:48:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=68
05/30/2022 07:48:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=69
05/30/2022 07:48:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=69
05/30/2022 07:48:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.21 on epoch=70
05/30/2022 07:48:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.18 on epoch=71
05/30/2022 07:48:22 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.7448712507074138 on epoch=71
05/30/2022 07:48:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=72
05/30/2022 07:48:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
05/30/2022 07:48:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=73
05/30/2022 07:48:32 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=74
05/30/2022 07:48:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
05/30/2022 07:48:40 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.6472999107198464 on epoch=74
05/30/2022 07:48:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=75
05/30/2022 07:48:45 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=76
05/30/2022 07:48:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=77
05/30/2022 07:48:50 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=77
05/30/2022 07:48:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=78
05/30/2022 07:48:58 - INFO - __main__ - Global step 1100 Train loss 0.16 Classification-F1 0.716042131007529 on epoch=78
05/30/2022 07:49:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=79
05/30/2022 07:49:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=79
05/30/2022 07:49:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=80
05/30/2022 07:49:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=81
05/30/2022 07:49:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=82
05/30/2022 07:49:16 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.6543411871131668 on epoch=82
05/30/2022 07:49:19 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=82
05/30/2022 07:49:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=83
05/30/2022 07:49:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=84
05/30/2022 07:49:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.17 on epoch=84
05/30/2022 07:49:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
05/30/2022 07:49:34 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.6234981418354693 on epoch=85
05/30/2022 07:49:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=86
05/30/2022 07:49:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.21 on epoch=87
05/30/2022 07:49:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
05/30/2022 07:49:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=88
05/30/2022 07:49:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=89
05/30/2022 07:49:53 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.6710236162685479 on epoch=89
05/30/2022 07:49:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=89
05/30/2022 07:49:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=90
05/30/2022 07:50:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
05/30/2022 07:50:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=92
05/30/2022 07:50:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=92
05/30/2022 07:50:11 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.7130102992294644 on epoch=92
05/30/2022 07:50:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
05/30/2022 07:50:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=94
05/30/2022 07:50:18 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
05/30/2022 07:50:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=95
05/30/2022 07:50:23 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=96
05/30/2022 07:50:29 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.7102109009129882 on epoch=96
05/30/2022 07:50:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=97
05/30/2022 07:50:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
05/30/2022 07:50:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=98
05/30/2022 07:50:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=99
05/30/2022 07:50:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
05/30/2022 07:50:47 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.7201541026967971 on epoch=99
05/30/2022 07:50:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
05/30/2022 07:50:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=101
05/30/2022 07:50:54 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.14 on epoch=102
05/30/2022 07:50:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=102
05/30/2022 07:50:59 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=103
05/30/2022 07:51:04 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.6847952998899703 on epoch=103
05/30/2022 07:51:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=104
05/30/2022 07:51:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=104
05/30/2022 07:51:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=105
05/30/2022 07:51:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=106
05/30/2022 07:51:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=107
05/30/2022 07:51:22 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.6481197442547688 on epoch=107
05/30/2022 07:51:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=107
05/30/2022 07:51:27 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=108
05/30/2022 07:51:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
05/30/2022 07:51:32 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=109
05/30/2022 07:51:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
05/30/2022 07:51:41 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.6729923027673452 on epoch=110
05/30/2022 07:51:43 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
05/30/2022 07:51:46 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=112
05/30/2022 07:51:48 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
05/30/2022 07:51:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
05/30/2022 07:51:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
05/30/2022 07:51:59 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.6725347704549742 on epoch=114
05/30/2022 07:52:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=114
05/30/2022 07:52:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=115
05/30/2022 07:52:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=116
05/30/2022 07:52:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=117
05/30/2022 07:52:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
05/30/2022 07:52:17 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.7453307266210492 on epoch=117
05/30/2022 07:52:20 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
05/30/2022 07:52:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
05/30/2022 07:52:25 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
05/30/2022 07:52:27 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=120
05/30/2022 07:52:30 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
05/30/2022 07:52:36 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.6648686662799566 on epoch=121
05/30/2022 07:52:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
05/30/2022 07:52:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
05/30/2022 07:52:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=123
05/30/2022 07:52:46 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
05/30/2022 07:52:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
05/30/2022 07:52:54 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.6841144895474267 on epoch=124
05/30/2022 07:52:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=125
05/30/2022 07:52:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
05/30/2022 07:53:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
05/30/2022 07:53:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
05/30/2022 07:53:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
05/30/2022 07:53:12 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.6554407699009733 on epoch=128
05/30/2022 07:53:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=129
05/30/2022 07:53:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
05/30/2022 07:53:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
05/30/2022 07:53:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
05/30/2022 07:53:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
05/30/2022 07:53:30 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.6527548404246198 on epoch=132
05/30/2022 07:53:32 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
05/30/2022 07:53:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
05/30/2022 07:53:37 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
05/30/2022 07:53:39 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
05/30/2022 07:53:42 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
05/30/2022 07:53:47 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.7876786373173296 on epoch=135
05/30/2022 07:53:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7520796133489541 -> 0.7876786373173296 on epoch=135, global_step=1900
05/30/2022 07:53:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
05/30/2022 07:53:52 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=137
05/30/2022 07:53:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=137
05/30/2022 07:53:57 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
05/30/2022 07:53:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
05/30/2022 07:54:05 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.714750485564053 on epoch=139
05/30/2022 07:54:07 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
05/30/2022 07:54:10 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
05/30/2022 07:54:12 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
05/30/2022 07:54:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
05/30/2022 07:54:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
05/30/2022 07:54:22 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.6593604245217148 on epoch=142
05/30/2022 07:54:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
05/30/2022 07:54:27 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=144
05/30/2022 07:54:29 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
05/30/2022 07:54:32 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
05/30/2022 07:54:34 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
05/30/2022 07:54:40 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.6757160523412423 on epoch=146
05/30/2022 07:54:43 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
05/30/2022 07:54:45 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=147
05/30/2022 07:54:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
05/30/2022 07:54:50 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
05/30/2022 07:54:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=149
05/30/2022 07:54:58 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.6974915294100353 on epoch=149
05/30/2022 07:55:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=150
05/30/2022 07:55:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
05/30/2022 07:55:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
05/30/2022 07:55:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
05/30/2022 07:55:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=153
05/30/2022 07:55:16 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7236377720248688 on epoch=153
05/30/2022 07:55:18 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=154
05/30/2022 07:55:21 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=154
05/30/2022 07:55:23 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
05/30/2022 07:55:26 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
05/30/2022 07:55:28 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
05/30/2022 07:55:33 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7046712791158056 on epoch=157
05/30/2022 07:55:36 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
05/30/2022 07:55:38 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
05/30/2022 07:55:41 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
05/30/2022 07:55:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
05/30/2022 07:55:46 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
05/30/2022 07:55:52 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.8568304007820137 on epoch=160
05/30/2022 07:55:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7876786373173296 -> 0.8568304007820137 on epoch=160, global_step=2250
05/30/2022 07:55:54 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
05/30/2022 07:55:56 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
05/30/2022 07:55:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
05/30/2022 07:56:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
05/30/2022 07:56:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
05/30/2022 07:56:10 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7193423441301201 on epoch=164
05/30/2022 07:56:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
05/30/2022 07:56:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
05/30/2022 07:56:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
05/30/2022 07:56:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
05/30/2022 07:56:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
05/30/2022 07:56:27 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8562351626867756 on epoch=167
05/30/2022 07:56:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=168
05/30/2022 07:56:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
05/30/2022 07:56:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.09 on epoch=169
05/30/2022 07:56:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
05/30/2022 07:56:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
05/30/2022 07:56:45 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.7777668252051554 on epoch=171
05/30/2022 07:56:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
05/30/2022 07:56:50 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
05/30/2022 07:56:52 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=173
05/30/2022 07:56:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
05/30/2022 07:56:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.09 on epoch=174
05/30/2022 07:57:03 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6480647779639714 on epoch=174
05/30/2022 07:57:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
05/30/2022 07:57:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
05/30/2022 07:57:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/30/2022 07:57:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
05/30/2022 07:57:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/30/2022 07:57:21 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7287532583903551 on epoch=178
05/30/2022 07:57:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
05/30/2022 07:57:26 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
05/30/2022 07:57:28 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/30/2022 07:57:31 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
05/30/2022 07:57:33 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
05/30/2022 07:57:39 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.618015333645134 on epoch=182
05/30/2022 07:57:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/30/2022 07:57:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/30/2022 07:57:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
05/30/2022 07:57:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/30/2022 07:57:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
05/30/2022 07:57:57 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7989455752975677 on epoch=185
05/30/2022 07:57:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
05/30/2022 07:58:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/30/2022 07:58:04 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
05/30/2022 07:58:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
05/30/2022 07:58:09 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/30/2022 07:58:14 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7508375734182187 on epoch=189
05/30/2022 07:58:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=189
05/30/2022 07:58:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/30/2022 07:58:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
05/30/2022 07:58:24 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/30/2022 07:58:26 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
05/30/2022 07:58:32 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9163897034864777 on epoch=192
05/30/2022 07:58:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8568304007820137 -> 0.9163897034864777 on epoch=192, global_step=2700
05/30/2022 07:58:35 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/30/2022 07:58:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
05/30/2022 07:58:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
05/30/2022 07:58:42 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/30/2022 07:58:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
05/30/2022 07:58:50 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7922235639123685 on epoch=196
05/30/2022 07:58:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
05/30/2022 07:58:55 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
05/30/2022 07:58:57 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/30/2022 07:59:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=199
05/30/2022 07:59:02 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
05/30/2022 07:59:08 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7894713157480256 on epoch=199
05/30/2022 07:59:10 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
05/30/2022 07:59:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
05/30/2022 07:59:15 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
05/30/2022 07:59:18 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
05/30/2022 07:59:20 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
05/30/2022 07:59:26 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.744718476670564 on epoch=203
05/30/2022 07:59:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
05/30/2022 07:59:31 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
05/30/2022 07:59:33 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/30/2022 07:59:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
05/30/2022 07:59:38 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
05/30/2022 07:59:44 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.778921071022589 on epoch=207
05/30/2022 07:59:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
05/30/2022 07:59:49 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/30/2022 07:59:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/30/2022 07:59:54 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
05/30/2022 07:59:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/30/2022 08:00:02 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7955815150410452 on epoch=210
05/30/2022 08:00:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
05/30/2022 08:00:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
05/30/2022 08:00:09 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
05/30/2022 08:00:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/30/2022 08:00:14 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/30/2022 08:00:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 08:00:15 - INFO - __main__ - Printing 3 examples
05/30/2022 08:00:15 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/30/2022 08:00:15 - INFO - __main__ - ['Animal']
05/30/2022 08:00:15 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/30/2022 08:00:15 - INFO - __main__ - ['Animal']
05/30/2022 08:00:15 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/30/2022 08:00:15 - INFO - __main__ - ['Animal']
05/30/2022 08:00:15 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:00:16 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:00:16 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 08:00:16 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 08:00:16 - INFO - __main__ - Printing 3 examples
05/30/2022 08:00:16 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/30/2022 08:00:16 - INFO - __main__ - ['Animal']
05/30/2022 08:00:16 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/30/2022 08:00:16 - INFO - __main__ - ['Animal']
05/30/2022 08:00:16 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/30/2022 08:00:16 - INFO - __main__ - ['Animal']
05/30/2022 08:00:16 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:00:16 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:00:16 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 08:00:20 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9776611157659545 on epoch=214
05/30/2022 08:00:20 - INFO - __main__ - Saving model with best Classification-F1: 0.9163897034864777 -> 0.9776611157659545 on epoch=214, global_step=3000
05/30/2022 08:00:20 - INFO - __main__ - save last model!
05/30/2022 08:00:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 08:00:20 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 08:00:20 - INFO - __main__ - Printing 3 examples
05/30/2022 08:00:20 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 08:00:20 - INFO - __main__ - ['Animal']
05/30/2022 08:00:20 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 08:00:20 - INFO - __main__ - ['Animal']
05/30/2022 08:00:20 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 08:00:20 - INFO - __main__ - ['Village']
05/30/2022 08:00:20 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:00:22 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:00:26 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 08:00:34 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 08:00:34 - INFO - __main__ - task name: dbpedia_14
05/30/2022 08:00:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 08:00:35 - INFO - __main__ - Starting training!
05/30/2022 08:02:28 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
05/30/2022 08:02:28 - INFO - __main__ - Classification-F1 on test data: 0.6180
05/30/2022 08:02:28 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.9776611157659545, test_performance=0.6179748347940893
05/30/2022 08:02:28 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
05/30/2022 08:02:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 08:02:29 - INFO - __main__ - Printing 3 examples
05/30/2022 08:02:29 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/30/2022 08:02:29 - INFO - __main__ - ['Animal']
05/30/2022 08:02:29 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/30/2022 08:02:29 - INFO - __main__ - ['Animal']
05/30/2022 08:02:29 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/30/2022 08:02:29 - INFO - __main__ - ['Animal']
05/30/2022 08:02:29 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:02:30 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:02:30 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 08:02:30 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 08:02:30 - INFO - __main__ - Printing 3 examples
05/30/2022 08:02:30 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/30/2022 08:02:30 - INFO - __main__ - ['Animal']
05/30/2022 08:02:30 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/30/2022 08:02:30 - INFO - __main__ - ['Animal']
05/30/2022 08:02:30 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/30/2022 08:02:30 - INFO - __main__ - ['Animal']
05/30/2022 08:02:30 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:02:30 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:02:30 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 08:02:49 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 08:02:49 - INFO - __main__ - task name: dbpedia_14
05/30/2022 08:02:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 08:02:49 - INFO - __main__ - Starting training!
05/30/2022 08:02:52 - INFO - __main__ - Step 10 Global step 10 Train loss 6.78 on epoch=0
05/30/2022 08:02:55 - INFO - __main__ - Step 20 Global step 20 Train loss 5.94 on epoch=1
05/30/2022 08:02:57 - INFO - __main__ - Step 30 Global step 30 Train loss 4.50 on epoch=2
05/30/2022 08:03:00 - INFO - __main__ - Step 40 Global step 40 Train loss 3.49 on epoch=2
05/30/2022 08:03:02 - INFO - __main__ - Step 50 Global step 50 Train loss 2.91 on epoch=3
05/30/2022 08:03:34 - INFO - __main__ - Global step 50 Train loss 4.72 Classification-F1 0.054424354744103 on epoch=3
05/30/2022 08:03:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.054424354744103 on epoch=3, global_step=50
05/30/2022 08:03:36 - INFO - __main__ - Step 60 Global step 60 Train loss 2.51 on epoch=4
05/30/2022 08:03:39 - INFO - __main__ - Step 70 Global step 70 Train loss 2.06 on epoch=4
05/30/2022 08:03:41 - INFO - __main__ - Step 80 Global step 80 Train loss 1.98 on epoch=5
05/30/2022 08:03:44 - INFO - __main__ - Step 90 Global step 90 Train loss 1.83 on epoch=6
05/30/2022 08:03:46 - INFO - __main__ - Step 100 Global step 100 Train loss 1.69 on epoch=7
05/30/2022 08:03:53 - INFO - __main__ - Global step 100 Train loss 2.01 Classification-F1 0.3096617631917414 on epoch=7
05/30/2022 08:03:53 - INFO - __main__ - Saving model with best Classification-F1: 0.054424354744103 -> 0.3096617631917414 on epoch=7, global_step=100
05/30/2022 08:03:56 - INFO - __main__ - Step 110 Global step 110 Train loss 1.58 on epoch=7
05/30/2022 08:03:58 - INFO - __main__ - Step 120 Global step 120 Train loss 1.41 on epoch=8
05/30/2022 08:04:01 - INFO - __main__ - Step 130 Global step 130 Train loss 1.38 on epoch=9
05/30/2022 08:04:03 - INFO - __main__ - Step 140 Global step 140 Train loss 1.17 on epoch=9
05/30/2022 08:04:06 - INFO - __main__ - Step 150 Global step 150 Train loss 1.20 on epoch=10
05/30/2022 08:04:14 - INFO - __main__ - Global step 150 Train loss 1.35 Classification-F1 0.4270099623040799 on epoch=10
05/30/2022 08:04:14 - INFO - __main__ - Saving model with best Classification-F1: 0.3096617631917414 -> 0.4270099623040799 on epoch=10, global_step=150
05/30/2022 08:04:16 - INFO - __main__ - Step 160 Global step 160 Train loss 1.24 on epoch=11
05/30/2022 08:04:19 - INFO - __main__ - Step 170 Global step 170 Train loss 1.13 on epoch=12
05/30/2022 08:04:21 - INFO - __main__ - Step 180 Global step 180 Train loss 0.94 on epoch=12
05/30/2022 08:04:24 - INFO - __main__ - Step 190 Global step 190 Train loss 1.00 on epoch=13
05/30/2022 08:04:26 - INFO - __main__ - Step 200 Global step 200 Train loss 1.09 on epoch=14
05/30/2022 08:04:34 - INFO - __main__ - Global step 200 Train loss 1.08 Classification-F1 0.5005146346719248 on epoch=14
05/30/2022 08:04:34 - INFO - __main__ - Saving model with best Classification-F1: 0.4270099623040799 -> 0.5005146346719248 on epoch=14, global_step=200
05/30/2022 08:04:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.83 on epoch=14
05/30/2022 08:04:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.89 on epoch=15
05/30/2022 08:04:41 - INFO - __main__ - Step 230 Global step 230 Train loss 0.91 on epoch=16
05/30/2022 08:04:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.85 on epoch=17
05/30/2022 08:04:46 - INFO - __main__ - Step 250 Global step 250 Train loss 0.80 on epoch=17
05/30/2022 08:04:54 - INFO - __main__ - Global step 250 Train loss 0.86 Classification-F1 0.5006684967461081 on epoch=17
05/30/2022 08:04:54 - INFO - __main__ - Saving model with best Classification-F1: 0.5005146346719248 -> 0.5006684967461081 on epoch=17, global_step=250
05/30/2022 08:04:56 - INFO - __main__ - Step 260 Global step 260 Train loss 0.88 on epoch=18
05/30/2022 08:04:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.88 on epoch=19
05/30/2022 08:05:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.69 on epoch=19
05/30/2022 08:05:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.77 on epoch=20
05/30/2022 08:05:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.87 on epoch=21
05/30/2022 08:05:14 - INFO - __main__ - Global step 300 Train loss 0.82 Classification-F1 0.5759178710046741 on epoch=21
05/30/2022 08:05:14 - INFO - __main__ - Saving model with best Classification-F1: 0.5006684967461081 -> 0.5759178710046741 on epoch=21, global_step=300
05/30/2022 08:05:16 - INFO - __main__ - Step 310 Global step 310 Train loss 0.73 on epoch=22
05/30/2022 08:05:19 - INFO - __main__ - Step 320 Global step 320 Train loss 0.69 on epoch=22
05/30/2022 08:05:21 - INFO - __main__ - Step 330 Global step 330 Train loss 0.64 on epoch=23
05/30/2022 08:05:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.69 on epoch=24
05/30/2022 08:05:26 - INFO - __main__ - Step 350 Global step 350 Train loss 0.60 on epoch=24
05/30/2022 08:05:33 - INFO - __main__ - Global step 350 Train loss 0.67 Classification-F1 0.5360253104736307 on epoch=24
05/30/2022 08:05:35 - INFO - __main__ - Step 360 Global step 360 Train loss 0.65 on epoch=25
05/30/2022 08:05:38 - INFO - __main__ - Step 370 Global step 370 Train loss 0.65 on epoch=26
05/30/2022 08:05:40 - INFO - __main__ - Step 380 Global step 380 Train loss 0.67 on epoch=27
05/30/2022 08:05:43 - INFO - __main__ - Step 390 Global step 390 Train loss 0.64 on epoch=27
05/30/2022 08:05:45 - INFO - __main__ - Step 400 Global step 400 Train loss 0.51 on epoch=28
05/30/2022 08:05:53 - INFO - __main__ - Global step 400 Train loss 0.62 Classification-F1 0.6202551037023182 on epoch=28
05/30/2022 08:05:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5759178710046741 -> 0.6202551037023182 on epoch=28, global_step=400
05/30/2022 08:05:56 - INFO - __main__ - Step 410 Global step 410 Train loss 0.53 on epoch=29
05/30/2022 08:05:58 - INFO - __main__ - Step 420 Global step 420 Train loss 0.52 on epoch=29
05/30/2022 08:06:01 - INFO - __main__ - Step 430 Global step 430 Train loss 0.61 on epoch=30
05/30/2022 08:06:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.64 on epoch=31
05/30/2022 08:06:06 - INFO - __main__ - Step 450 Global step 450 Train loss 0.60 on epoch=32
05/30/2022 08:06:13 - INFO - __main__ - Global step 450 Train loss 0.58 Classification-F1 0.6562580564596694 on epoch=32
05/30/2022 08:06:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6202551037023182 -> 0.6562580564596694 on epoch=32, global_step=450
05/30/2022 08:06:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.53 on epoch=32
05/30/2022 08:06:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.57 on epoch=33
05/30/2022 08:06:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.55 on epoch=34
05/30/2022 08:06:22 - INFO - __main__ - Step 490 Global step 490 Train loss 0.40 on epoch=34
05/30/2022 08:06:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.48 on epoch=35
05/30/2022 08:06:32 - INFO - __main__ - Global step 500 Train loss 0.51 Classification-F1 0.6931882015705545 on epoch=35
05/30/2022 08:06:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6562580564596694 -> 0.6931882015705545 on epoch=35, global_step=500
05/30/2022 08:06:34 - INFO - __main__ - Step 510 Global step 510 Train loss 0.57 on epoch=36
05/30/2022 08:06:37 - INFO - __main__ - Step 520 Global step 520 Train loss 0.49 on epoch=37
05/30/2022 08:06:39 - INFO - __main__ - Step 530 Global step 530 Train loss 0.43 on epoch=37
05/30/2022 08:06:42 - INFO - __main__ - Step 540 Global step 540 Train loss 0.40 on epoch=38
05/30/2022 08:06:44 - INFO - __main__ - Step 550 Global step 550 Train loss 0.45 on epoch=39
05/30/2022 08:06:50 - INFO - __main__ - Global step 550 Train loss 0.47 Classification-F1 0.668283294855931 on epoch=39
05/30/2022 08:06:53 - INFO - __main__ - Step 560 Global step 560 Train loss 0.35 on epoch=39
05/30/2022 08:06:55 - INFO - __main__ - Step 570 Global step 570 Train loss 0.47 on epoch=40
05/30/2022 08:06:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.50 on epoch=41
05/30/2022 08:07:00 - INFO - __main__ - Step 590 Global step 590 Train loss 0.44 on epoch=42
05/30/2022 08:07:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.41 on epoch=42
05/30/2022 08:07:09 - INFO - __main__ - Global step 600 Train loss 0.43 Classification-F1 0.7261707520117338 on epoch=42
05/30/2022 08:07:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6931882015705545 -> 0.7261707520117338 on epoch=42, global_step=600
05/30/2022 08:07:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.40 on epoch=43
05/30/2022 08:07:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.46 on epoch=44
05/30/2022 08:07:16 - INFO - __main__ - Step 630 Global step 630 Train loss 0.41 on epoch=44
05/30/2022 08:07:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.43 on epoch=45
05/30/2022 08:07:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.44 on epoch=46
05/30/2022 08:07:28 - INFO - __main__ - Global step 650 Train loss 0.43 Classification-F1 0.7546744658110882 on epoch=46
05/30/2022 08:07:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7261707520117338 -> 0.7546744658110882 on epoch=46, global_step=650
05/30/2022 08:07:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.35 on epoch=47
05/30/2022 08:07:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.34 on epoch=47
05/30/2022 08:07:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.39 on epoch=48
05/30/2022 08:07:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.31 on epoch=49
05/30/2022 08:07:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.38 on epoch=49
05/30/2022 08:07:46 - INFO - __main__ - Global step 700 Train loss 0.35 Classification-F1 0.6553596499656206 on epoch=49
05/30/2022 08:07:49 - INFO - __main__ - Step 710 Global step 710 Train loss 0.35 on epoch=50
05/30/2022 08:07:51 - INFO - __main__ - Step 720 Global step 720 Train loss 0.31 on epoch=51
05/30/2022 08:07:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.41 on epoch=52
05/30/2022 08:07:56 - INFO - __main__ - Step 740 Global step 740 Train loss 0.32 on epoch=52
05/30/2022 08:07:59 - INFO - __main__ - Step 750 Global step 750 Train loss 0.31 on epoch=53
05/30/2022 08:08:05 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.734336434600878 on epoch=53
05/30/2022 08:08:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.30 on epoch=54
05/30/2022 08:08:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.26 on epoch=54
05/30/2022 08:08:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.30 on epoch=55
05/30/2022 08:08:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=56
05/30/2022 08:08:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.28 on epoch=57
05/30/2022 08:08:23 - INFO - __main__ - Global step 800 Train loss 0.28 Classification-F1 0.7494018504306692 on epoch=57
05/30/2022 08:08:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.24 on epoch=57
05/30/2022 08:08:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.26 on epoch=58
05/30/2022 08:08:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.29 on epoch=59
05/30/2022 08:08:33 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=59
05/30/2022 08:08:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.29 on epoch=60
05/30/2022 08:08:42 - INFO - __main__ - Global step 850 Train loss 0.26 Classification-F1 0.8030061324416163 on epoch=60
05/30/2022 08:08:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7546744658110882 -> 0.8030061324416163 on epoch=60, global_step=850
05/30/2022 08:08:45 - INFO - __main__ - Step 860 Global step 860 Train loss 0.29 on epoch=61
05/30/2022 08:08:47 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=62
05/30/2022 08:08:50 - INFO - __main__ - Step 880 Global step 880 Train loss 0.25 on epoch=62
05/30/2022 08:08:52 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=63
05/30/2022 08:08:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.23 on epoch=64
05/30/2022 08:09:00 - INFO - __main__ - Global step 900 Train loss 0.24 Classification-F1 0.7769015336601005 on epoch=64
05/30/2022 08:09:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.33 on epoch=64
05/30/2022 08:09:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.25 on epoch=65
05/30/2022 08:09:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=66
05/30/2022 08:09:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.27 on epoch=67
05/30/2022 08:09:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=67
05/30/2022 08:09:19 - INFO - __main__ - Global step 950 Train loss 0.25 Classification-F1 0.7894674947777972 on epoch=67
05/30/2022 08:09:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.23 on epoch=68
05/30/2022 08:09:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.25 on epoch=69
05/30/2022 08:09:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.27 on epoch=69
05/30/2022 08:09:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=70
05/30/2022 08:09:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=71
05/30/2022 08:09:38 - INFO - __main__ - Global step 1000 Train loss 0.21 Classification-F1 0.7881299909219724 on epoch=71
05/30/2022 08:09:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.25 on epoch=72
05/30/2022 08:09:43 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.19 on epoch=72
05/30/2022 08:09:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=73
05/30/2022 08:09:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=74
05/30/2022 08:09:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=74
05/30/2022 08:09:56 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.760760192957793 on epoch=74
05/30/2022 08:09:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=75
05/30/2022 08:10:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=76
05/30/2022 08:10:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=77
05/30/2022 08:10:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=77
05/30/2022 08:10:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=78
05/30/2022 08:10:14 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.8397583140483238 on epoch=78
05/30/2022 08:10:14 - INFO - __main__ - Saving model with best Classification-F1: 0.8030061324416163 -> 0.8397583140483238 on epoch=78, global_step=1100
05/30/2022 08:10:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=79
05/30/2022 08:10:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.16 on epoch=79
05/30/2022 08:10:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.18 on epoch=80
05/30/2022 08:10:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.20 on epoch=81
05/30/2022 08:10:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.19 on epoch=82
05/30/2022 08:10:32 - INFO - __main__ - Global step 1150 Train loss 0.18 Classification-F1 0.8227848008297487 on epoch=82
05/30/2022 08:10:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=82
05/30/2022 08:10:38 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=83
05/30/2022 08:10:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=84
05/30/2022 08:10:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.18 on epoch=84
05/30/2022 08:10:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.17 on epoch=85
05/30/2022 08:10:51 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.8830998541482412 on epoch=85
05/30/2022 08:10:51 - INFO - __main__ - Saving model with best Classification-F1: 0.8397583140483238 -> 0.8830998541482412 on epoch=85, global_step=1200
05/30/2022 08:10:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.15 on epoch=86
05/30/2022 08:10:56 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
05/30/2022 08:10:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
05/30/2022 08:11:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.22 on epoch=88
05/30/2022 08:11:03 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=89
05/30/2022 08:11:09 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.832792267984148 on epoch=89
05/30/2022 08:11:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=89
05/30/2022 08:11:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=90
05/30/2022 08:11:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
05/30/2022 08:11:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=92
05/30/2022 08:11:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=92
05/30/2022 08:11:28 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.8470564193925119 on epoch=92
05/30/2022 08:11:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.14 on epoch=93
05/30/2022 08:11:33 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
05/30/2022 08:11:35 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=94
05/30/2022 08:11:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=95
05/30/2022 08:11:40 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
05/30/2022 08:11:46 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.9104635060280221 on epoch=96
05/30/2022 08:11:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8830998541482412 -> 0.9104635060280221 on epoch=96, global_step=1350
05/30/2022 08:11:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=97
05/30/2022 08:11:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=97
05/30/2022 08:11:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=98
05/30/2022 08:11:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.21 on epoch=99
05/30/2022 08:11:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=99
05/30/2022 08:12:05 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.8395793761558623 on epoch=99
05/30/2022 08:12:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
05/30/2022 08:12:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=101
05/30/2022 08:12:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.14 on epoch=102
05/30/2022 08:12:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
05/30/2022 08:12:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=103
05/30/2022 08:12:23 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.9063743425033747 on epoch=103
05/30/2022 08:12:25 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=104
05/30/2022 08:12:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=104
05/30/2022 08:12:30 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
05/30/2022 08:12:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
05/30/2022 08:12:35 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=107
05/30/2022 08:12:41 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.9733241537084041 on epoch=107
05/30/2022 08:12:41 - INFO - __main__ - Saving model with best Classification-F1: 0.9104635060280221 -> 0.9733241537084041 on epoch=107, global_step=1500
05/30/2022 08:12:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=107
05/30/2022 08:12:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=108
05/30/2022 08:12:49 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
05/30/2022 08:12:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
05/30/2022 08:12:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=110
05/30/2022 08:13:03 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.9690809094898956 on epoch=110
05/30/2022 08:13:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
05/30/2022 08:13:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.13 on epoch=112
05/30/2022 08:13:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
05/30/2022 08:13:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
05/30/2022 08:13:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.14 on epoch=114
05/30/2022 08:13:22 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.7877303483063054 on epoch=114
05/30/2022 08:13:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.14 on epoch=114
05/30/2022 08:13:27 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=115
05/30/2022 08:13:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
05/30/2022 08:13:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
05/30/2022 08:13:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=117
05/30/2022 08:13:40 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.9063743425033747 on epoch=117
05/30/2022 08:13:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.11 on epoch=118
05/30/2022 08:13:45 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.15 on epoch=119
05/30/2022 08:13:47 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=119
05/30/2022 08:13:50 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
05/30/2022 08:13:52 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=121
05/30/2022 08:13:58 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.9146227454813792 on epoch=121
05/30/2022 08:14:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=122
05/30/2022 08:14:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=122
05/30/2022 08:14:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=123
05/30/2022 08:14:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
05/30/2022 08:14:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=124
05/30/2022 08:14:16 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.9081540260287888 on epoch=124
05/30/2022 08:14:19 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
05/30/2022 08:14:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
05/30/2022 08:14:24 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
05/30/2022 08:14:27 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
05/30/2022 08:14:29 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
05/30/2022 08:14:35 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.9081294922661148 on epoch=128
05/30/2022 08:14:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
05/30/2022 08:14:40 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
05/30/2022 08:14:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
05/30/2022 08:14:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=131
05/30/2022 08:14:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=132
05/30/2022 08:14:53 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.9104520058267686 on epoch=132
05/30/2022 08:14:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
05/30/2022 08:14:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
05/30/2022 08:15:01 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=134
05/30/2022 08:15:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
05/30/2022 08:15:06 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=135
05/30/2022 08:15:11 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.8437683476983169 on epoch=135
05/30/2022 08:15:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
05/30/2022 08:15:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
05/30/2022 08:15:18 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
05/30/2022 08:15:21 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
05/30/2022 08:15:23 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=139
05/30/2022 08:15:29 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.906281266172158 on epoch=139
05/30/2022 08:15:32 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
05/30/2022 08:15:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
05/30/2022 08:15:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
05/30/2022 08:15:39 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
05/30/2022 08:15:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=142
05/30/2022 08:15:47 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.9055585495734683 on epoch=142
05/30/2022 08:15:50 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
05/30/2022 08:15:52 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
05/30/2022 08:15:55 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=144
05/30/2022 08:15:57 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
05/30/2022 08:16:00 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
05/30/2022 08:16:05 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.9062641596227933 on epoch=146
05/30/2022 08:16:08 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
05/30/2022 08:16:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
05/30/2022 08:16:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
05/30/2022 08:16:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
05/30/2022 08:16:18 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
05/30/2022 08:16:23 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.9018644658793844 on epoch=149
05/30/2022 08:16:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
05/30/2022 08:16:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
05/30/2022 08:16:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
05/30/2022 08:16:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
05/30/2022 08:16:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
05/30/2022 08:16:42 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9123247656833996 on epoch=153
05/30/2022 08:16:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=154
05/30/2022 08:16:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=154
05/30/2022 08:16:49 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=155
05/30/2022 08:16:52 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
05/30/2022 08:16:54 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
05/30/2022 08:17:00 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.9777884394226898 on epoch=157
05/30/2022 08:17:00 - INFO - __main__ - Saving model with best Classification-F1: 0.9733241537084041 -> 0.9777884394226898 on epoch=157, global_step=2200
05/30/2022 08:17:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
05/30/2022 08:17:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
05/30/2022 08:17:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=159
05/30/2022 08:17:10 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
05/30/2022 08:17:12 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
05/30/2022 08:17:22 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.9103045636631976 on epoch=160
05/30/2022 08:17:24 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
05/30/2022 08:17:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.11 on epoch=162
05/30/2022 08:17:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
05/30/2022 08:17:32 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
05/30/2022 08:17:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=164
05/30/2022 08:17:40 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.9146186724934353 on epoch=164
05/30/2022 08:17:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=164
05/30/2022 08:17:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
05/30/2022 08:17:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
05/30/2022 08:17:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=167
05/30/2022 08:17:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
05/30/2022 08:17:58 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.9103086366511415 on epoch=167
05/30/2022 08:18:00 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=168
05/30/2022 08:18:03 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
05/30/2022 08:18:05 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
05/30/2022 08:18:08 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
05/30/2022 08:18:11 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.09 on epoch=171
05/30/2022 08:18:16 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.9778741995331856 on epoch=171
05/30/2022 08:18:16 - INFO - __main__ - Saving model with best Classification-F1: 0.9777884394226898 -> 0.9778741995331856 on epoch=171, global_step=2400
05/30/2022 08:18:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
05/30/2022 08:18:21 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
05/30/2022 08:18:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/30/2022 08:18:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
05/30/2022 08:18:29 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/30/2022 08:18:34 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9777884394226898 on epoch=174
05/30/2022 08:18:37 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
05/30/2022 08:18:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.09 on epoch=176
05/30/2022 08:18:42 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
05/30/2022 08:18:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/30/2022 08:18:47 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
05/30/2022 08:18:53 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9016410539339612 on epoch=178
05/30/2022 08:18:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
05/30/2022 08:18:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
05/30/2022 08:19:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
05/30/2022 08:19:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
05/30/2022 08:19:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
05/30/2022 08:19:11 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9061378969965309 on epoch=182
05/30/2022 08:19:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/30/2022 08:19:16 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
05/30/2022 08:19:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
05/30/2022 08:19:21 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
05/30/2022 08:19:24 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
05/30/2022 08:19:29 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9730082062150373 on epoch=185
05/30/2022 08:19:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
05/30/2022 08:19:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
05/30/2022 08:19:37 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
05/30/2022 08:19:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
05/30/2022 08:19:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
05/30/2022 08:19:47 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9146186724934353 on epoch=189
05/30/2022 08:19:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/30/2022 08:19:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
05/30/2022 08:19:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
05/30/2022 08:19:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
05/30/2022 08:20:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
05/30/2022 08:20:05 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9080106568531616 on epoch=192
05/30/2022 08:20:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
05/30/2022 08:20:10 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.16 on epoch=194
05/30/2022 08:20:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
05/30/2022 08:20:15 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/30/2022 08:20:18 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
05/30/2022 08:20:23 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.9103045636631976 on epoch=196
05/30/2022 08:20:26 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
05/30/2022 08:20:28 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/30/2022 08:20:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/30/2022 08:20:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
05/30/2022 08:20:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
05/30/2022 08:20:41 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9103045636631976 on epoch=199
05/30/2022 08:20:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/30/2022 08:20:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
05/30/2022 08:20:49 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=202
05/30/2022 08:20:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
05/30/2022 08:20:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
05/30/2022 08:21:00 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9019671573419202 on epoch=203
05/30/2022 08:21:02 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
05/30/2022 08:21:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/30/2022 08:21:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
05/30/2022 08:21:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
05/30/2022 08:21:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/30/2022 08:21:18 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9776304656760065 on epoch=207
05/30/2022 08:21:20 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/30/2022 08:21:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/30/2022 08:21:25 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/30/2022 08:21:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/30/2022 08:21:30 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
05/30/2022 08:21:36 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.906365381929898 on epoch=210
05/30/2022 08:21:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.14 on epoch=211
05/30/2022 08:21:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
05/30/2022 08:21:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=212
05/30/2022 08:21:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
05/30/2022 08:21:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
05/30/2022 08:21:50 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 08:21:50 - INFO - __main__ - Printing 3 examples
05/30/2022 08:21:50 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/30/2022 08:21:50 - INFO - __main__ - ['Animal']
05/30/2022 08:21:50 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/30/2022 08:21:50 - INFO - __main__ - ['Animal']
05/30/2022 08:21:50 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/30/2022 08:21:50 - INFO - __main__ - ['Animal']
05/30/2022 08:21:50 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:21:50 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:21:51 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 08:21:51 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 08:21:51 - INFO - __main__ - Printing 3 examples
05/30/2022 08:21:51 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/30/2022 08:21:51 - INFO - __main__ - ['Animal']
05/30/2022 08:21:51 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/30/2022 08:21:51 - INFO - __main__ - ['Animal']
05/30/2022 08:21:51 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/30/2022 08:21:51 - INFO - __main__ - ['Animal']
05/30/2022 08:21:51 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:21:51 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:21:51 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 08:21:55 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.9776304656760065 on epoch=214
05/30/2022 08:21:55 - INFO - __main__ - save last model!
05/30/2022 08:21:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 08:21:55 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 08:21:55 - INFO - __main__ - Printing 3 examples
05/30/2022 08:21:55 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 08:21:55 - INFO - __main__ - ['Animal']
05/30/2022 08:21:55 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 08:21:55 - INFO - __main__ - ['Animal']
05/30/2022 08:21:55 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 08:21:55 - INFO - __main__ - ['Village']
05/30/2022 08:21:55 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:21:57 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:22:00 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 08:22:07 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 08:22:07 - INFO - __main__ - task name: dbpedia_14
05/30/2022 08:22:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 08:22:08 - INFO - __main__ - Starting training!
05/30/2022 08:24:07 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
05/30/2022 08:24:07 - INFO - __main__ - Classification-F1 on test data: 0.8022
05/30/2022 08:24:07 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.9778741995331856, test_performance=0.8022315978258794
05/30/2022 08:24:07 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
05/30/2022 08:24:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 08:24:08 - INFO - __main__ - Printing 3 examples
05/30/2022 08:24:08 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/30/2022 08:24:08 - INFO - __main__ - ['Animal']
05/30/2022 08:24:08 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/30/2022 08:24:08 - INFO - __main__ - ['Animal']
05/30/2022 08:24:08 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/30/2022 08:24:08 - INFO - __main__ - ['Animal']
05/30/2022 08:24:08 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:24:08 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:24:08 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 08:24:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 08:24:08 - INFO - __main__ - Printing 3 examples
05/30/2022 08:24:08 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/30/2022 08:24:08 - INFO - __main__ - ['Animal']
05/30/2022 08:24:08 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/30/2022 08:24:08 - INFO - __main__ - ['Animal']
05/30/2022 08:24:08 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/30/2022 08:24:08 - INFO - __main__ - ['Animal']
05/30/2022 08:24:08 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:24:09 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:24:09 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 08:24:27 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 08:24:27 - INFO - __main__ - task name: dbpedia_14
05/30/2022 08:24:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 08:24:28 - INFO - __main__ - Starting training!
05/30/2022 08:24:31 - INFO - __main__ - Step 10 Global step 10 Train loss 7.08 on epoch=0
05/30/2022 08:24:34 - INFO - __main__ - Step 20 Global step 20 Train loss 6.67 on epoch=1
05/30/2022 08:24:36 - INFO - __main__ - Step 30 Global step 30 Train loss 5.94 on epoch=2
05/30/2022 08:24:39 - INFO - __main__ - Step 40 Global step 40 Train loss 5.20 on epoch=2
05/30/2022 08:24:41 - INFO - __main__ - Step 50 Global step 50 Train loss 4.56 on epoch=3
05/30/2022 08:26:18 - INFO - __main__ - Global step 50 Train loss 5.89 Classification-F1 0.0 on epoch=3
05/30/2022 08:26:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/30/2022 08:26:21 - INFO - __main__ - Step 60 Global step 60 Train loss 3.77 on epoch=4
05/30/2022 08:26:23 - INFO - __main__ - Step 70 Global step 70 Train loss 3.25 on epoch=4
05/30/2022 08:26:26 - INFO - __main__ - Step 80 Global step 80 Train loss 2.71 on epoch=5
05/30/2022 08:26:28 - INFO - __main__ - Step 90 Global step 90 Train loss 2.45 on epoch=6
05/30/2022 08:26:31 - INFO - __main__ - Step 100 Global step 100 Train loss 2.38 on epoch=7
05/30/2022 08:26:37 - INFO - __main__ - Global step 100 Train loss 2.91 Classification-F1 0.15633290113166276 on epoch=7
05/30/2022 08:26:37 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.15633290113166276 on epoch=7, global_step=100
05/30/2022 08:26:40 - INFO - __main__ - Step 110 Global step 110 Train loss 2.04 on epoch=7
05/30/2022 08:26:42 - INFO - __main__ - Step 120 Global step 120 Train loss 1.88 on epoch=8
05/30/2022 08:26:45 - INFO - __main__ - Step 130 Global step 130 Train loss 1.73 on epoch=9
05/30/2022 08:26:47 - INFO - __main__ - Step 140 Global step 140 Train loss 1.60 on epoch=9
05/30/2022 08:26:50 - INFO - __main__ - Step 150 Global step 150 Train loss 1.56 on epoch=10
05/30/2022 08:26:57 - INFO - __main__ - Global step 150 Train loss 1.76 Classification-F1 0.34986370116451015 on epoch=10
05/30/2022 08:26:57 - INFO - __main__ - Saving model with best Classification-F1: 0.15633290113166276 -> 0.34986370116451015 on epoch=10, global_step=150
05/30/2022 08:26:59 - INFO - __main__ - Step 160 Global step 160 Train loss 1.30 on epoch=11
05/30/2022 08:27:02 - INFO - __main__ - Step 170 Global step 170 Train loss 1.41 on epoch=12
05/30/2022 08:27:04 - INFO - __main__ - Step 180 Global step 180 Train loss 1.24 on epoch=12
05/30/2022 08:27:07 - INFO - __main__ - Step 190 Global step 190 Train loss 1.22 on epoch=13
05/30/2022 08:27:09 - INFO - __main__ - Step 200 Global step 200 Train loss 1.15 on epoch=14
05/30/2022 08:27:16 - INFO - __main__ - Global step 200 Train loss 1.26 Classification-F1 0.34711492057649673 on epoch=14
05/30/2022 08:27:19 - INFO - __main__ - Step 210 Global step 210 Train loss 1.06 on epoch=14
05/30/2022 08:27:21 - INFO - __main__ - Step 220 Global step 220 Train loss 1.05 on epoch=15
05/30/2022 08:27:23 - INFO - __main__ - Step 230 Global step 230 Train loss 1.03 on epoch=16
05/30/2022 08:27:26 - INFO - __main__ - Step 240 Global step 240 Train loss 0.92 on epoch=17
05/30/2022 08:27:28 - INFO - __main__ - Step 250 Global step 250 Train loss 0.87 on epoch=17
05/30/2022 08:27:36 - INFO - __main__ - Global step 250 Train loss 0.99 Classification-F1 0.48080543809528387 on epoch=17
05/30/2022 08:27:36 - INFO - __main__ - Saving model with best Classification-F1: 0.34986370116451015 -> 0.48080543809528387 on epoch=17, global_step=250
05/30/2022 08:27:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.92 on epoch=18
05/30/2022 08:27:40 - INFO - __main__ - Step 270 Global step 270 Train loss 0.80 on epoch=19
05/30/2022 08:27:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.76 on epoch=19
05/30/2022 08:27:45 - INFO - __main__ - Step 290 Global step 290 Train loss 0.71 on epoch=20
05/30/2022 08:27:48 - INFO - __main__ - Step 300 Global step 300 Train loss 0.80 on epoch=21
05/30/2022 08:27:55 - INFO - __main__ - Global step 300 Train loss 0.80 Classification-F1 0.4927647386561218 on epoch=21
05/30/2022 08:27:55 - INFO - __main__ - Saving model with best Classification-F1: 0.48080543809528387 -> 0.4927647386561218 on epoch=21, global_step=300
05/30/2022 08:27:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.79 on epoch=22
05/30/2022 08:28:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.75 on epoch=22
05/30/2022 08:28:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.81 on epoch=23
05/30/2022 08:28:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.78 on epoch=24
05/30/2022 08:28:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.70 on epoch=24
05/30/2022 08:28:14 - INFO - __main__ - Global step 350 Train loss 0.76 Classification-F1 0.5017491107592269 on epoch=24
05/30/2022 08:28:14 - INFO - __main__ - Saving model with best Classification-F1: 0.4927647386561218 -> 0.5017491107592269 on epoch=24, global_step=350
05/30/2022 08:28:17 - INFO - __main__ - Step 360 Global step 360 Train loss 0.73 on epoch=25
05/30/2022 08:28:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.67 on epoch=26
05/30/2022 08:28:22 - INFO - __main__ - Step 380 Global step 380 Train loss 0.65 on epoch=27
05/30/2022 08:28:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.69 on epoch=27
05/30/2022 08:28:26 - INFO - __main__ - Step 400 Global step 400 Train loss 0.56 on epoch=28
05/30/2022 08:28:34 - INFO - __main__ - Global step 400 Train loss 0.66 Classification-F1 0.5981267670090132 on epoch=28
05/30/2022 08:28:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5017491107592269 -> 0.5981267670090132 on epoch=28, global_step=400
05/30/2022 08:28:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.69 on epoch=29
05/30/2022 08:28:39 - INFO - __main__ - Step 420 Global step 420 Train loss 0.48 on epoch=29
05/30/2022 08:28:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.59 on epoch=30
05/30/2022 08:28:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.60 on epoch=31
05/30/2022 08:28:46 - INFO - __main__ - Step 450 Global step 450 Train loss 0.56 on epoch=32
05/30/2022 08:28:52 - INFO - __main__ - Global step 450 Train loss 0.58 Classification-F1 0.7336865347272643 on epoch=32
05/30/2022 08:28:52 - INFO - __main__ - Saving model with best Classification-F1: 0.5981267670090132 -> 0.7336865347272643 on epoch=32, global_step=450
05/30/2022 08:28:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.49 on epoch=32
05/30/2022 08:28:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.53 on epoch=33
05/30/2022 08:29:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.47 on epoch=34
05/30/2022 08:29:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.47 on epoch=34
05/30/2022 08:29:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.53 on epoch=35
05/30/2022 08:29:11 - INFO - __main__ - Global step 500 Train loss 0.50 Classification-F1 0.6233842110539903 on epoch=35
05/30/2022 08:29:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.58 on epoch=36
05/30/2022 08:29:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.52 on epoch=37
05/30/2022 08:29:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.40 on epoch=37
05/30/2022 08:29:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.47 on epoch=38
05/30/2022 08:29:23 - INFO - __main__ - Step 550 Global step 550 Train loss 0.51 on epoch=39
05/30/2022 08:29:29 - INFO - __main__ - Global step 550 Train loss 0.50 Classification-F1 0.7122842876687878 on epoch=39
05/30/2022 08:29:32 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=39
05/30/2022 08:29:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.39 on epoch=40
05/30/2022 08:29:37 - INFO - __main__ - Step 580 Global step 580 Train loss 0.46 on epoch=41
05/30/2022 08:29:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.43 on epoch=42
05/30/2022 08:29:42 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=42
05/30/2022 08:29:48 - INFO - __main__ - Global step 600 Train loss 0.39 Classification-F1 0.6923077906390334 on epoch=42
05/30/2022 08:29:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.43 on epoch=43
05/30/2022 08:29:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.46 on epoch=44
05/30/2022 08:29:55 - INFO - __main__ - Step 630 Global step 630 Train loss 0.37 on epoch=44
05/30/2022 08:29:58 - INFO - __main__ - Step 640 Global step 640 Train loss 0.42 on epoch=45
05/30/2022 08:30:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.34 on epoch=46
05/30/2022 08:30:07 - INFO - __main__ - Global step 650 Train loss 0.40 Classification-F1 0.7672346578770384 on epoch=46
05/30/2022 08:30:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7336865347272643 -> 0.7672346578770384 on epoch=46, global_step=650
05/30/2022 08:30:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.38 on epoch=47
05/30/2022 08:30:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=47
05/30/2022 08:30:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.39 on epoch=48
05/30/2022 08:30:17 - INFO - __main__ - Step 690 Global step 690 Train loss 0.38 on epoch=49
05/30/2022 08:30:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.31 on epoch=49
05/30/2022 08:30:25 - INFO - __main__ - Global step 700 Train loss 0.35 Classification-F1 0.7838452886919467 on epoch=49
05/30/2022 08:30:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7672346578770384 -> 0.7838452886919467 on epoch=49, global_step=700
05/30/2022 08:30:28 - INFO - __main__ - Step 710 Global step 710 Train loss 0.33 on epoch=50
05/30/2022 08:30:30 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=51
05/30/2022 08:30:33 - INFO - __main__ - Step 730 Global step 730 Train loss 0.32 on epoch=52
05/30/2022 08:30:35 - INFO - __main__ - Step 740 Global step 740 Train loss 0.31 on epoch=52
05/30/2022 08:30:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.31 on epoch=53
05/30/2022 08:30:44 - INFO - __main__ - Global step 750 Train loss 0.30 Classification-F1 0.8435219555631901 on epoch=53
05/30/2022 08:30:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7838452886919467 -> 0.8435219555631901 on epoch=53, global_step=750
05/30/2022 08:30:47 - INFO - __main__ - Step 760 Global step 760 Train loss 0.36 on epoch=54
05/30/2022 08:30:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.34 on epoch=54
05/30/2022 08:30:52 - INFO - __main__ - Step 780 Global step 780 Train loss 0.41 on epoch=55
05/30/2022 08:30:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.24 on epoch=56
05/30/2022 08:30:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.31 on epoch=57
05/30/2022 08:31:06 - INFO - __main__ - Global step 800 Train loss 0.33 Classification-F1 0.7516633779512372 on epoch=57
05/30/2022 08:31:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.30 on epoch=57
05/30/2022 08:31:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.33 on epoch=58
05/30/2022 08:31:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.25 on epoch=59
05/30/2022 08:31:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.24 on epoch=59
05/30/2022 08:31:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=60
05/30/2022 08:31:24 - INFO - __main__ - Global step 850 Train loss 0.26 Classification-F1 0.8035724546788457 on epoch=60
05/30/2022 08:31:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=61
05/30/2022 08:31:29 - INFO - __main__ - Step 870 Global step 870 Train loss 0.26 on epoch=62
05/30/2022 08:31:31 - INFO - __main__ - Step 880 Global step 880 Train loss 0.29 on epoch=62
05/30/2022 08:31:34 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=63
05/30/2022 08:31:36 - INFO - __main__ - Step 900 Global step 900 Train loss 0.33 on epoch=64
05/30/2022 08:31:43 - INFO - __main__ - Global step 900 Train loss 0.27 Classification-F1 0.6771216989279037 on epoch=64
05/30/2022 08:31:45 - INFO - __main__ - Step 910 Global step 910 Train loss 0.23 on epoch=64
05/30/2022 08:31:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=65
05/30/2022 08:31:50 - INFO - __main__ - Step 930 Global step 930 Train loss 0.24 on epoch=66
05/30/2022 08:31:53 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=67
05/30/2022 08:31:55 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=67
05/30/2022 08:32:02 - INFO - __main__ - Global step 950 Train loss 0.21 Classification-F1 0.8133823960526322 on epoch=67
05/30/2022 08:32:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=68
05/30/2022 08:32:07 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=69
05/30/2022 08:32:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.29 on epoch=69
05/30/2022 08:32:11 - INFO - __main__ - Step 990 Global step 990 Train loss 0.32 on epoch=70
05/30/2022 08:32:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=71
05/30/2022 08:32:20 - INFO - __main__ - Global step 1000 Train loss 0.24 Classification-F1 0.8815697943756897 on epoch=71
05/30/2022 08:32:20 - INFO - __main__ - Saving model with best Classification-F1: 0.8435219555631901 -> 0.8815697943756897 on epoch=71, global_step=1000
05/30/2022 08:32:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=72
05/30/2022 08:32:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=72
05/30/2022 08:32:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.29 on epoch=73
05/30/2022 08:32:30 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.23 on epoch=74
05/30/2022 08:32:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=74
05/30/2022 08:32:39 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.7652496139320241 on epoch=74
05/30/2022 08:32:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.21 on epoch=75
05/30/2022 08:32:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=76
05/30/2022 08:32:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.23 on epoch=77
05/30/2022 08:32:48 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.21 on epoch=77
05/30/2022 08:32:51 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.22 on epoch=78
05/30/2022 08:32:57 - INFO - __main__ - Global step 1100 Train loss 0.22 Classification-F1 0.6324067990112133 on epoch=78
05/30/2022 08:33:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.19 on epoch=79
05/30/2022 08:33:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=79
05/30/2022 08:33:04 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=80
05/30/2022 08:33:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=81
05/30/2022 08:33:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.16 on epoch=82
05/30/2022 08:33:15 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.6641095692540431 on epoch=82
05/30/2022 08:33:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=82
05/30/2022 08:33:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=83
05/30/2022 08:33:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=84
05/30/2022 08:33:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=84
05/30/2022 08:33:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.16 on epoch=85
05/30/2022 08:33:34 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.8164750884316742 on epoch=85
05/30/2022 08:33:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=86
05/30/2022 08:33:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.23 on epoch=87
05/30/2022 08:33:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
05/30/2022 08:33:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=88
05/30/2022 08:33:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.19 on epoch=89
05/30/2022 08:33:52 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.7612558178957889 on epoch=89
05/30/2022 08:33:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=89
05/30/2022 08:33:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=90
05/30/2022 08:34:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
05/30/2022 08:34:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.14 on epoch=92
05/30/2022 08:34:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=92
05/30/2022 08:34:12 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.8754638796558467 on epoch=92
05/30/2022 08:34:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=93
05/30/2022 08:34:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=94
05/30/2022 08:34:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=94
05/30/2022 08:34:22 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=95
05/30/2022 08:34:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=96
05/30/2022 08:34:35 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.7917705694104211 on epoch=96
05/30/2022 08:34:38 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=97
05/30/2022 08:34:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.16 on epoch=97
05/30/2022 08:34:43 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=98
05/30/2022 08:34:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=99
05/30/2022 08:34:47 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.14 on epoch=99
05/30/2022 08:34:56 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.7957268719114349 on epoch=99
05/30/2022 08:34:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.20 on epoch=100
05/30/2022 08:35:01 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=101
05/30/2022 08:35:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.16 on epoch=102
05/30/2022 08:35:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.18 on epoch=102
05/30/2022 08:35:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=103
05/30/2022 08:35:15 - INFO - __main__ - Global step 1450 Train loss 0.16 Classification-F1 0.8302675630875265 on epoch=103
05/30/2022 08:35:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=104
05/30/2022 08:35:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.13 on epoch=104
05/30/2022 08:35:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=105
05/30/2022 08:35:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.13 on epoch=106
05/30/2022 08:35:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.14 on epoch=107
05/30/2022 08:35:36 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.8315584252220343 on epoch=107
05/30/2022 08:35:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=107
05/30/2022 08:35:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=108
05/30/2022 08:35:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=109
05/30/2022 08:35:46 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=109
05/30/2022 08:35:48 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=110
05/30/2022 08:35:55 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.7477041125997483 on epoch=110
05/30/2022 08:35:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
05/30/2022 08:36:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=112
05/30/2022 08:36:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
05/30/2022 08:36:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=113
05/30/2022 08:36:07 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
05/30/2022 08:36:15 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.7474902807326906 on epoch=114
05/30/2022 08:36:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
05/30/2022 08:36:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
05/30/2022 08:36:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=116
05/30/2022 08:36:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=117
05/30/2022 08:36:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=117
05/30/2022 08:36:33 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.8431731697950189 on epoch=117
05/30/2022 08:36:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=118
05/30/2022 08:36:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.14 on epoch=119
05/30/2022 08:36:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=119
05/30/2022 08:36:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=120
05/30/2022 08:36:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
05/30/2022 08:36:52 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.792443165141011 on epoch=121
05/30/2022 08:36:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=122
05/30/2022 08:36:57 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=122
05/30/2022 08:37:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=123
05/30/2022 08:37:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
05/30/2022 08:37:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.20 on epoch=124
05/30/2022 08:37:11 - INFO - __main__ - Global step 1750 Train loss 0.11 Classification-F1 0.6666058433800368 on epoch=124
05/30/2022 08:37:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=125
05/30/2022 08:37:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
05/30/2022 08:37:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=127
05/30/2022 08:37:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=127
05/30/2022 08:37:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=128
05/30/2022 08:37:29 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.8982251622273763 on epoch=128
05/30/2022 08:37:30 - INFO - __main__ - Saving model with best Classification-F1: 0.8815697943756897 -> 0.8982251622273763 on epoch=128, global_step=1800
05/30/2022 08:37:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=129
05/30/2022 08:37:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=129
05/30/2022 08:37:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
05/30/2022 08:37:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
05/30/2022 08:37:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
05/30/2022 08:37:48 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.7467479435679396 on epoch=132
05/30/2022 08:37:51 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
05/30/2022 08:37:53 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=133
05/30/2022 08:37:56 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=134
05/30/2022 08:37:58 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=134
05/30/2022 08:38:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
05/30/2022 08:38:07 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.7453191440787954 on epoch=135
05/30/2022 08:38:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=136
05/30/2022 08:38:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=137
05/30/2022 08:38:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
05/30/2022 08:38:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=138
05/30/2022 08:38:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.09 on epoch=139
05/30/2022 08:38:26 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.8469833534586855 on epoch=139
05/30/2022 08:38:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
05/30/2022 08:38:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=140
05/30/2022 08:38:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
05/30/2022 08:38:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=142
05/30/2022 08:38:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=142
05/30/2022 08:38:45 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7565703285224159 on epoch=142
05/30/2022 08:38:48 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
05/30/2022 08:38:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=144
05/30/2022 08:38:53 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
05/30/2022 08:38:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=145
05/30/2022 08:38:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
05/30/2022 08:39:04 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7971398104309624 on epoch=146
05/30/2022 08:39:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=147
05/30/2022 08:39:09 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
05/30/2022 08:39:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=148
05/30/2022 08:39:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.09 on epoch=149
05/30/2022 08:39:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=149
05/30/2022 08:39:24 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7023289240103933 on epoch=149
05/30/2022 08:39:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
05/30/2022 08:39:29 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
05/30/2022 08:39:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=152
05/30/2022 08:39:34 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=152
05/30/2022 08:39:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=153
05/30/2022 08:39:46 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7941027879344098 on epoch=153
05/30/2022 08:39:49 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.08 on epoch=154
05/30/2022 08:39:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=154
05/30/2022 08:39:54 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=155
05/30/2022 08:39:56 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=156
05/30/2022 08:39:59 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
05/30/2022 08:40:06 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.7994220303267072 on epoch=157
05/30/2022 08:40:08 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=157
05/30/2022 08:40:10 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=158
05/30/2022 08:40:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.12 on epoch=159
05/30/2022 08:40:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
05/30/2022 08:40:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
05/30/2022 08:40:30 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.9144753033178081 on epoch=160
05/30/2022 08:40:30 - INFO - __main__ - Saving model with best Classification-F1: 0.8982251622273763 -> 0.9144753033178081 on epoch=160, global_step=2250
05/30/2022 08:40:32 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=161
05/30/2022 08:40:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=162
05/30/2022 08:40:37 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=162
05/30/2022 08:40:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.08 on epoch=163
05/30/2022 08:40:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
05/30/2022 08:40:52 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7994220303267072 on epoch=164
05/30/2022 08:40:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
05/30/2022 08:40:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
05/30/2022 08:41:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.11 on epoch=166
05/30/2022 08:41:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=167
05/30/2022 08:41:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=167
05/30/2022 08:41:13 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.9144753033178081 on epoch=167
05/30/2022 08:41:16 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
05/30/2022 08:41:18 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=169
05/30/2022 08:41:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.09 on epoch=169
05/30/2022 08:41:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=170
05/30/2022 08:41:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=171
05/30/2022 08:41:32 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.7445585620682134 on epoch=171
05/30/2022 08:41:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
05/30/2022 08:41:37 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
05/30/2022 08:41:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
05/30/2022 08:41:42 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.11 on epoch=174
05/30/2022 08:41:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=174
05/30/2022 08:41:51 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.8438755837949387 on epoch=174
05/30/2022 08:41:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
05/30/2022 08:41:56 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=176
05/30/2022 08:41:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
05/30/2022 08:42:01 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=177
05/30/2022 08:42:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=178
05/30/2022 08:42:10 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.9055585495734683 on epoch=178
05/30/2022 08:42:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=179
05/30/2022 08:42:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
05/30/2022 08:42:17 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
05/30/2022 08:42:20 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
05/30/2022 08:42:22 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
05/30/2022 08:42:28 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7601620250576607 on epoch=182
05/30/2022 08:42:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=182
05/30/2022 08:42:33 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
05/30/2022 08:42:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
05/30/2022 08:42:38 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=184
05/30/2022 08:42:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
05/30/2022 08:42:49 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.7545467323455939 on epoch=185
05/30/2022 08:42:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
05/30/2022 08:42:54 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
05/30/2022 08:42:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
05/30/2022 08:42:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
05/30/2022 08:43:01 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=189
05/30/2022 08:43:08 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.851398217828187 on epoch=189
05/30/2022 08:43:11 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=189
05/30/2022 08:43:13 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
05/30/2022 08:43:16 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
05/30/2022 08:43:18 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
05/30/2022 08:43:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
05/30/2022 08:43:27 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7994046954645235 on epoch=192
05/30/2022 08:43:30 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
05/30/2022 08:43:33 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
05/30/2022 08:43:35 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
05/30/2022 08:43:38 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
05/30/2022 08:43:40 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
05/30/2022 08:43:47 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.977757789332742 on epoch=196
05/30/2022 08:43:47 - INFO - __main__ - Saving model with best Classification-F1: 0.9144753033178081 -> 0.977757789332742 on epoch=196, global_step=2750
05/30/2022 08:43:50 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
05/30/2022 08:43:52 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
05/30/2022 08:43:55 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
05/30/2022 08:43:58 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
05/30/2022 08:44:00 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
05/30/2022 08:44:06 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8511154962857325 on epoch=199
05/30/2022 08:44:09 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
05/30/2022 08:44:11 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
05/30/2022 08:44:14 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=202
05/30/2022 08:44:16 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
05/30/2022 08:44:19 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
05/30/2022 08:44:25 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.8514104367920189 on epoch=203
05/30/2022 08:44:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
05/30/2022 08:44:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=204
05/30/2022 08:44:33 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
05/30/2022 08:44:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
05/30/2022 08:44:38 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
05/30/2022 08:44:46 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7971398104309624 on epoch=207
05/30/2022 08:44:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/30/2022 08:44:51 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
05/30/2022 08:44:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
05/30/2022 08:44:57 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
05/30/2022 08:45:00 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
05/30/2022 08:45:08 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7973944010931957 on epoch=210
05/30/2022 08:45:10 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
05/30/2022 08:45:13 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
05/30/2022 08:45:15 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
05/30/2022 08:45:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
05/30/2022 08:45:21 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
05/30/2022 08:45:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 08:45:22 - INFO - __main__ - Printing 3 examples
05/30/2022 08:45:22 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/30/2022 08:45:22 - INFO - __main__ - ['Animal']
05/30/2022 08:45:22 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/30/2022 08:45:22 - INFO - __main__ - ['Animal']
05/30/2022 08:45:22 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/30/2022 08:45:22 - INFO - __main__ - ['Animal']
05/30/2022 08:45:22 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:45:22 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:45:22 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 08:45:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 08:45:22 - INFO - __main__ - Printing 3 examples
05/30/2022 08:45:22 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/30/2022 08:45:22 - INFO - __main__ - ['Animal']
05/30/2022 08:45:22 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/30/2022 08:45:22 - INFO - __main__ - ['Animal']
05/30/2022 08:45:22 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/30/2022 08:45:22 - INFO - __main__ - ['Animal']
05/30/2022 08:45:22 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:45:22 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:45:22 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 08:45:28 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8531539301937784 on epoch=214
05/30/2022 08:45:28 - INFO - __main__ - save last model!
05/30/2022 08:45:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 08:45:28 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 08:45:28 - INFO - __main__ - Printing 3 examples
05/30/2022 08:45:28 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 08:45:28 - INFO - __main__ - ['Animal']
05/30/2022 08:45:28 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 08:45:28 - INFO - __main__ - ['Animal']
05/30/2022 08:45:28 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 08:45:28 - INFO - __main__ - ['Village']
05/30/2022 08:45:28 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:45:30 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:45:33 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 08:45:41 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 08:45:41 - INFO - __main__ - task name: dbpedia_14
05/30/2022 08:45:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 08:45:42 - INFO - __main__ - Starting training!
05/30/2022 08:47:46 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
05/30/2022 08:47:46 - INFO - __main__ - Classification-F1 on test data: 0.6453
05/30/2022 08:47:46 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.977757789332742, test_performance=0.6453257271512685
05/30/2022 08:47:46 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
05/30/2022 08:47:47 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 08:47:47 - INFO - __main__ - Printing 3 examples
05/30/2022 08:47:47 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/30/2022 08:47:47 - INFO - __main__ - ['Animal']
05/30/2022 08:47:47 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/30/2022 08:47:47 - INFO - __main__ - ['Animal']
05/30/2022 08:47:47 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/30/2022 08:47:47 - INFO - __main__ - ['Animal']
05/30/2022 08:47:47 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:47:47 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:47:48 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 08:47:48 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 08:47:48 - INFO - __main__ - Printing 3 examples
05/30/2022 08:47:48 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/30/2022 08:47:48 - INFO - __main__ - ['Animal']
05/30/2022 08:47:48 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/30/2022 08:47:48 - INFO - __main__ - ['Animal']
05/30/2022 08:47:48 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/30/2022 08:47:48 - INFO - __main__ - ['Animal']
05/30/2022 08:47:48 - INFO - __main__ - Tokenizing Input ...
05/30/2022 08:47:48 - INFO - __main__ - Tokenizing Output ...
05/30/2022 08:47:48 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 08:48:03 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 08:48:03 - INFO - __main__ - task name: dbpedia_14
05/30/2022 08:48:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 08:48:04 - INFO - __main__ - Starting training!
05/30/2022 08:48:07 - INFO - __main__ - Step 10 Global step 10 Train loss 7.16 on epoch=0
05/30/2022 08:48:09 - INFO - __main__ - Step 20 Global step 20 Train loss 6.85 on epoch=1
05/30/2022 08:48:12 - INFO - __main__ - Step 30 Global step 30 Train loss 6.18 on epoch=2
05/30/2022 08:48:14 - INFO - __main__ - Step 40 Global step 40 Train loss 5.57 on epoch=2
05/30/2022 08:48:17 - INFO - __main__ - Step 50 Global step 50 Train loss 5.00 on epoch=3
05/30/2022 08:49:46 - INFO - __main__ - Global step 50 Train loss 6.15 Classification-F1 0.0018272541991707079 on epoch=3
05/30/2022 08:49:46 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0018272541991707079 on epoch=3, global_step=50
05/30/2022 08:49:49 - INFO - __main__ - Step 60 Global step 60 Train loss 4.26 on epoch=4
05/30/2022 08:49:51 - INFO - __main__ - Step 70 Global step 70 Train loss 3.74 on epoch=4
05/30/2022 08:49:53 - INFO - __main__ - Step 80 Global step 80 Train loss 3.47 on epoch=5
05/30/2022 08:49:56 - INFO - __main__ - Step 90 Global step 90 Train loss 2.99 on epoch=6
05/30/2022 08:49:58 - INFO - __main__ - Step 100 Global step 100 Train loss 2.78 on epoch=7
05/30/2022 08:50:18 - INFO - __main__ - Global step 100 Train loss 3.45 Classification-F1 0.10620339902299256 on epoch=7
05/30/2022 08:50:18 - INFO - __main__ - Saving model with best Classification-F1: 0.0018272541991707079 -> 0.10620339902299256 on epoch=7, global_step=100
05/30/2022 08:50:20 - INFO - __main__ - Step 110 Global step 110 Train loss 2.61 on epoch=7
05/30/2022 08:50:23 - INFO - __main__ - Step 120 Global step 120 Train loss 2.31 on epoch=8
05/30/2022 08:50:25 - INFO - __main__ - Step 130 Global step 130 Train loss 2.18 on epoch=9
05/30/2022 08:50:27 - INFO - __main__ - Step 140 Global step 140 Train loss 2.03 on epoch=9
05/30/2022 08:50:30 - INFO - __main__ - Step 150 Global step 150 Train loss 1.87 on epoch=10
05/30/2022 08:50:37 - INFO - __main__ - Global step 150 Train loss 2.20 Classification-F1 0.2339795498999946 on epoch=10
05/30/2022 08:50:37 - INFO - __main__ - Saving model with best Classification-F1: 0.10620339902299256 -> 0.2339795498999946 on epoch=10, global_step=150
05/30/2022 08:50:40 - INFO - __main__ - Step 160 Global step 160 Train loss 1.70 on epoch=11
05/30/2022 08:50:42 - INFO - __main__ - Step 170 Global step 170 Train loss 1.70 on epoch=12
05/30/2022 08:50:44 - INFO - __main__ - Step 180 Global step 180 Train loss 1.48 on epoch=12
05/30/2022 08:50:47 - INFO - __main__ - Step 190 Global step 190 Train loss 1.49 on epoch=13
05/30/2022 08:50:49 - INFO - __main__ - Step 200 Global step 200 Train loss 1.45 on epoch=14
05/30/2022 08:50:56 - INFO - __main__ - Global step 200 Train loss 1.56 Classification-F1 0.3085245074287034 on epoch=14
05/30/2022 08:50:56 - INFO - __main__ - Saving model with best Classification-F1: 0.2339795498999946 -> 0.3085245074287034 on epoch=14, global_step=200
05/30/2022 08:50:58 - INFO - __main__ - Step 210 Global step 210 Train loss 1.25 on epoch=14
05/30/2022 08:51:01 - INFO - __main__ - Step 220 Global step 220 Train loss 1.29 on epoch=15
05/30/2022 08:51:03 - INFO - __main__ - Step 230 Global step 230 Train loss 1.29 on epoch=16
05/30/2022 08:51:06 - INFO - __main__ - Step 240 Global step 240 Train loss 1.23 on epoch=17
05/30/2022 08:51:08 - INFO - __main__ - Step 250 Global step 250 Train loss 1.05 on epoch=17
05/30/2022 08:51:15 - INFO - __main__ - Global step 250 Train loss 1.22 Classification-F1 0.34330532648587486 on epoch=17
05/30/2022 08:51:15 - INFO - __main__ - Saving model with best Classification-F1: 0.3085245074287034 -> 0.34330532648587486 on epoch=17, global_step=250
05/30/2022 08:51:18 - INFO - __main__ - Step 260 Global step 260 Train loss 1.09 on epoch=18
05/30/2022 08:51:20 - INFO - __main__ - Step 270 Global step 270 Train loss 1.12 on epoch=19
05/30/2022 08:51:22 - INFO - __main__ - Step 280 Global step 280 Train loss 1.06 on epoch=19
05/30/2022 08:51:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.98 on epoch=20
05/30/2022 08:51:27 - INFO - __main__ - Step 300 Global step 300 Train loss 1.01 on epoch=21
05/30/2022 08:51:33 - INFO - __main__ - Global step 300 Train loss 1.05 Classification-F1 0.4071184548346591 on epoch=21
05/30/2022 08:51:33 - INFO - __main__ - Saving model with best Classification-F1: 0.34330532648587486 -> 0.4071184548346591 on epoch=21, global_step=300
05/30/2022 08:51:35 - INFO - __main__ - Step 310 Global step 310 Train loss 1.09 on epoch=22
05/30/2022 08:51:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.85 on epoch=22
05/30/2022 08:51:40 - INFO - __main__ - Step 330 Global step 330 Train loss 0.83 on epoch=23
05/30/2022 08:51:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.89 on epoch=24
05/30/2022 08:51:45 - INFO - __main__ - Step 350 Global step 350 Train loss 0.89 on epoch=24
05/30/2022 08:51:50 - INFO - __main__ - Global step 350 Train loss 0.91 Classification-F1 0.5410912354676897 on epoch=24
05/30/2022 08:51:50 - INFO - __main__ - Saving model with best Classification-F1: 0.4071184548346591 -> 0.5410912354676897 on epoch=24, global_step=350
05/30/2022 08:51:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.91 on epoch=25
05/30/2022 08:51:55 - INFO - __main__ - Step 370 Global step 370 Train loss 0.86 on epoch=26
05/30/2022 08:51:57 - INFO - __main__ - Step 380 Global step 380 Train loss 0.78 on epoch=27
05/30/2022 08:52:00 - INFO - __main__ - Step 390 Global step 390 Train loss 0.79 on epoch=27
05/30/2022 08:52:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.83 on epoch=28
05/30/2022 08:52:08 - INFO - __main__ - Global step 400 Train loss 0.83 Classification-F1 0.5985164039119248 on epoch=28
05/30/2022 08:52:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5410912354676897 -> 0.5985164039119248 on epoch=28, global_step=400
05/30/2022 08:52:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.72 on epoch=29
05/30/2022 08:52:13 - INFO - __main__ - Step 420 Global step 420 Train loss 0.72 on epoch=29
05/30/2022 08:52:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.83 on epoch=30
05/30/2022 08:52:18 - INFO - __main__ - Step 440 Global step 440 Train loss 0.76 on epoch=31
05/30/2022 08:52:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.81 on epoch=32
05/30/2022 08:52:26 - INFO - __main__ - Global step 450 Train loss 0.77 Classification-F1 0.7446116340101161 on epoch=32
05/30/2022 08:52:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5985164039119248 -> 0.7446116340101161 on epoch=32, global_step=450
05/30/2022 08:52:28 - INFO - __main__ - Step 460 Global step 460 Train loss 0.68 on epoch=32
05/30/2022 08:52:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.79 on epoch=33
05/30/2022 08:52:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.64 on epoch=34
05/30/2022 08:52:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.68 on epoch=34
05/30/2022 08:52:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.72 on epoch=35
05/30/2022 08:52:45 - INFO - __main__ - Global step 500 Train loss 0.70 Classification-F1 0.7306668883153657 on epoch=35
05/30/2022 08:52:47 - INFO - __main__ - Step 510 Global step 510 Train loss 0.70 on epoch=36
05/30/2022 08:52:50 - INFO - __main__ - Step 520 Global step 520 Train loss 0.69 on epoch=37
05/30/2022 08:52:52 - INFO - __main__ - Step 530 Global step 530 Train loss 0.66 on epoch=37
05/30/2022 08:52:55 - INFO - __main__ - Step 540 Global step 540 Train loss 0.58 on epoch=38
05/30/2022 08:52:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.60 on epoch=39
05/30/2022 08:53:04 - INFO - __main__ - Global step 550 Train loss 0.65 Classification-F1 0.6661190292244059 on epoch=39
05/30/2022 08:53:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.72 on epoch=39
05/30/2022 08:53:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.58 on epoch=40
05/30/2022 08:53:11 - INFO - __main__ - Step 580 Global step 580 Train loss 0.60 on epoch=41
05/30/2022 08:53:14 - INFO - __main__ - Step 590 Global step 590 Train loss 0.68 on epoch=42
05/30/2022 08:53:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.49 on epoch=42
05/30/2022 08:53:24 - INFO - __main__ - Global step 600 Train loss 0.61 Classification-F1 0.6926952384005438 on epoch=42
05/30/2022 08:53:26 - INFO - __main__ - Step 610 Global step 610 Train loss 0.63 on epoch=43
05/30/2022 08:53:29 - INFO - __main__ - Step 620 Global step 620 Train loss 0.62 on epoch=44
05/30/2022 08:53:31 - INFO - __main__ - Step 630 Global step 630 Train loss 0.50 on epoch=44
05/30/2022 08:53:33 - INFO - __main__ - Step 640 Global step 640 Train loss 0.50 on epoch=45
05/30/2022 08:53:36 - INFO - __main__ - Step 650 Global step 650 Train loss 0.52 on epoch=46
05/30/2022 08:53:42 - INFO - __main__ - Global step 650 Train loss 0.56 Classification-F1 0.6689930265064674 on epoch=46
05/30/2022 08:53:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.57 on epoch=47
05/30/2022 08:53:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.57 on epoch=47
05/30/2022 08:53:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.54 on epoch=48
05/30/2022 08:53:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.44 on epoch=49
05/30/2022 08:53:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.41 on epoch=49
05/30/2022 08:53:59 - INFO - __main__ - Global step 700 Train loss 0.50 Classification-F1 0.7591605030373694 on epoch=49
05/30/2022 08:53:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7446116340101161 -> 0.7591605030373694 on epoch=49, global_step=700
05/30/2022 08:54:02 - INFO - __main__ - Step 710 Global step 710 Train loss 0.44 on epoch=50
05/30/2022 08:54:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.52 on epoch=51
05/30/2022 08:54:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.47 on epoch=52
05/30/2022 08:54:09 - INFO - __main__ - Step 740 Global step 740 Train loss 0.47 on epoch=52
05/30/2022 08:54:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.35 on epoch=53
05/30/2022 08:54:17 - INFO - __main__ - Global step 750 Train loss 0.45 Classification-F1 0.6896755745308876 on epoch=53
05/30/2022 08:54:20 - INFO - __main__ - Step 760 Global step 760 Train loss 0.41 on epoch=54
05/30/2022 08:54:22 - INFO - __main__ - Step 770 Global step 770 Train loss 0.43 on epoch=54
05/30/2022 08:54:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.48 on epoch=55
05/30/2022 08:54:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.34 on epoch=56
05/30/2022 08:54:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.44 on epoch=57
05/30/2022 08:54:36 - INFO - __main__ - Global step 800 Train loss 0.42 Classification-F1 0.7203231852732837 on epoch=57
05/30/2022 08:54:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.38 on epoch=57
05/30/2022 08:54:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.43 on epoch=58
05/30/2022 08:54:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.48 on epoch=59
05/30/2022 08:54:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.35 on epoch=59
05/30/2022 08:54:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.41 on epoch=60
05/30/2022 08:54:54 - INFO - __main__ - Global step 850 Train loss 0.41 Classification-F1 0.771588908962901 on epoch=60
05/30/2022 08:54:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7591605030373694 -> 0.771588908962901 on epoch=60, global_step=850
05/30/2022 08:54:56 - INFO - __main__ - Step 860 Global step 860 Train loss 0.34 on epoch=61
05/30/2022 08:54:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.40 on epoch=62
05/30/2022 08:55:01 - INFO - __main__ - Step 880 Global step 880 Train loss 0.42 on epoch=62
05/30/2022 08:55:04 - INFO - __main__ - Step 890 Global step 890 Train loss 0.37 on epoch=63
05/30/2022 08:55:06 - INFO - __main__ - Step 900 Global step 900 Train loss 0.37 on epoch=64
05/30/2022 08:55:12 - INFO - __main__ - Global step 900 Train loss 0.38 Classification-F1 0.7243878630475239 on epoch=64
05/30/2022 08:55:15 - INFO - __main__ - Step 910 Global step 910 Train loss 0.42 on epoch=64
05/30/2022 08:55:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.41 on epoch=65
05/30/2022 08:55:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.37 on epoch=66
05/30/2022 08:55:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.40 on epoch=67
05/30/2022 08:55:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.39 on epoch=67
05/30/2022 08:55:30 - INFO - __main__ - Global step 950 Train loss 0.40 Classification-F1 0.7790168512032163 on epoch=67
05/30/2022 08:55:30 - INFO - __main__ - Saving model with best Classification-F1: 0.771588908962901 -> 0.7790168512032163 on epoch=67, global_step=950
05/30/2022 08:55:33 - INFO - __main__ - Step 960 Global step 960 Train loss 0.40 on epoch=68
05/30/2022 08:55:35 - INFO - __main__ - Step 970 Global step 970 Train loss 0.26 on epoch=69
05/30/2022 08:55:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.31 on epoch=69
05/30/2022 08:55:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.32 on epoch=70
05/30/2022 08:55:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.32 on epoch=71
05/30/2022 08:55:49 - INFO - __main__ - Global step 1000 Train loss 0.32 Classification-F1 0.7828606381352387 on epoch=71
05/30/2022 08:55:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7790168512032163 -> 0.7828606381352387 on epoch=71, global_step=1000
05/30/2022 08:55:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.35 on epoch=72
05/30/2022 08:55:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.27 on epoch=72
05/30/2022 08:55:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.32 on epoch=73
05/30/2022 08:55:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.29 on epoch=74
05/30/2022 08:56:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.34 on epoch=74
05/30/2022 08:56:07 - INFO - __main__ - Global step 1050 Train loss 0.31 Classification-F1 0.7544055896091252 on epoch=74
05/30/2022 08:56:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.27 on epoch=75
05/30/2022 08:56:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.36 on epoch=76
05/30/2022 08:56:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.32 on epoch=77
05/30/2022 08:56:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=77
05/30/2022 08:56:19 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.33 on epoch=78
05/30/2022 08:56:25 - INFO - __main__ - Global step 1100 Train loss 0.29 Classification-F1 0.6649194235407588 on epoch=78
05/30/2022 08:56:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.32 on epoch=79
05/30/2022 08:56:30 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.28 on epoch=79
05/30/2022 08:56:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.26 on epoch=80
05/30/2022 08:56:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.23 on epoch=81
05/30/2022 08:56:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.39 on epoch=82
05/30/2022 08:56:43 - INFO - __main__ - Global step 1150 Train loss 0.30 Classification-F1 0.7374272682843599 on epoch=82
05/30/2022 08:56:46 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.27 on epoch=82
05/30/2022 08:56:48 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.28 on epoch=83
05/30/2022 08:56:51 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.27 on epoch=84
05/30/2022 08:56:53 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.18 on epoch=84
05/30/2022 08:56:56 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.26 on epoch=85
05/30/2022 08:57:02 - INFO - __main__ - Global step 1200 Train loss 0.25 Classification-F1 0.6665486784493034 on epoch=85
05/30/2022 08:57:04 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.32 on epoch=86
05/30/2022 08:57:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.30 on epoch=87
05/30/2022 08:57:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.25 on epoch=87
05/30/2022 08:57:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.28 on epoch=88
05/30/2022 08:57:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.29 on epoch=89
05/30/2022 08:57:20 - INFO - __main__ - Global step 1250 Train loss 0.29 Classification-F1 0.8869388403781192 on epoch=89
05/30/2022 08:57:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7828606381352387 -> 0.8869388403781192 on epoch=89, global_step=1250
05/30/2022 08:57:23 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.25 on epoch=89
05/30/2022 08:57:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.22 on epoch=90
05/30/2022 08:57:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.34 on epoch=91
05/30/2022 08:57:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.21 on epoch=92
05/30/2022 08:57:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.22 on epoch=92
05/30/2022 08:57:38 - INFO - __main__ - Global step 1300 Train loss 0.25 Classification-F1 0.689723555818925 on epoch=92
05/30/2022 08:57:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.22 on epoch=93
05/30/2022 08:57:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.25 on epoch=94
05/30/2022 08:57:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.23 on epoch=94
05/30/2022 08:57:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.28 on epoch=95
05/30/2022 08:57:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.25 on epoch=96
05/30/2022 08:57:57 - INFO - __main__ - Global step 1350 Train loss 0.24 Classification-F1 0.9402847315205002 on epoch=96
05/30/2022 08:57:57 - INFO - __main__ - Saving model with best Classification-F1: 0.8869388403781192 -> 0.9402847315205002 on epoch=96, global_step=1350
05/30/2022 08:57:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.20 on epoch=97
05/30/2022 08:58:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.14 on epoch=97
05/30/2022 08:58:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
05/30/2022 08:58:06 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.20 on epoch=99
05/30/2022 08:58:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.17 on epoch=99
05/30/2022 08:58:15 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.9499454279133032 on epoch=99
05/30/2022 08:58:15 - INFO - __main__ - Saving model with best Classification-F1: 0.9402847315205002 -> 0.9499454279133032 on epoch=99, global_step=1400
05/30/2022 08:58:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.20 on epoch=100
05/30/2022 08:58:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.15 on epoch=101
05/30/2022 08:58:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.16 on epoch=102
05/30/2022 08:58:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.29 on epoch=102
05/30/2022 08:58:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.23 on epoch=103
05/30/2022 08:58:33 - INFO - __main__ - Global step 1450 Train loss 0.21 Classification-F1 0.945806118483393 on epoch=103
05/30/2022 08:58:36 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.28 on epoch=104
05/30/2022 08:58:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.23 on epoch=104
05/30/2022 08:58:41 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.19 on epoch=105
05/30/2022 08:58:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=106
05/30/2022 08:58:46 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.20 on epoch=107
05/30/2022 08:58:52 - INFO - __main__ - Global step 1500 Train loss 0.21 Classification-F1 0.7810847080380993 on epoch=107
05/30/2022 08:58:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.13 on epoch=107
05/30/2022 08:58:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.24 on epoch=108
05/30/2022 08:58:59 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.18 on epoch=109
05/30/2022 08:59:02 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.15 on epoch=109
05/30/2022 08:59:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.15 on epoch=110
05/30/2022 08:59:10 - INFO - __main__ - Global step 1550 Train loss 0.17 Classification-F1 0.8649877325920968 on epoch=110
05/30/2022 08:59:12 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.17 on epoch=111
05/30/2022 08:59:15 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.16 on epoch=112
05/30/2022 08:59:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.16 on epoch=112
05/30/2022 08:59:20 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.18 on epoch=113
05/30/2022 08:59:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.15 on epoch=114
05/30/2022 08:59:28 - INFO - __main__ - Global step 1600 Train loss 0.16 Classification-F1 0.8384456948228275 on epoch=114
05/30/2022 08:59:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.24 on epoch=114
05/30/2022 08:59:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.18 on epoch=115
05/30/2022 08:59:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.18 on epoch=116
05/30/2022 08:59:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.25 on epoch=117
05/30/2022 08:59:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.17 on epoch=117
05/30/2022 08:59:46 - INFO - __main__ - Global step 1650 Train loss 0.20 Classification-F1 0.9456120596686445 on epoch=117
05/30/2022 08:59:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.15 on epoch=118
05/30/2022 08:59:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=119
05/30/2022 08:59:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=119
05/30/2022 08:59:56 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=120
05/30/2022 08:59:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.15 on epoch=121
05/30/2022 09:00:04 - INFO - __main__ - Global step 1700 Train loss 0.14 Classification-F1 0.8911490369903312 on epoch=121
05/30/2022 09:00:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.22 on epoch=122
05/30/2022 09:00:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=122
05/30/2022 09:00:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.18 on epoch=123
05/30/2022 09:00:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.20 on epoch=124
05/30/2022 09:00:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.17 on epoch=124
05/30/2022 09:00:23 - INFO - __main__ - Global step 1750 Train loss 0.18 Classification-F1 0.8888665661768129 on epoch=124
05/30/2022 09:00:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.15 on epoch=125
05/30/2022 09:00:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.17 on epoch=126
05/30/2022 09:00:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.17 on epoch=127
05/30/2022 09:00:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=127
05/30/2022 09:00:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.15 on epoch=128
05/30/2022 09:00:42 - INFO - __main__ - Global step 1800 Train loss 0.15 Classification-F1 0.9641582320560946 on epoch=128
05/30/2022 09:00:42 - INFO - __main__ - Saving model with best Classification-F1: 0.9499454279133032 -> 0.9641582320560946 on epoch=128, global_step=1800
05/30/2022 09:00:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.18 on epoch=129
05/30/2022 09:00:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=129
05/30/2022 09:00:49 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.15 on epoch=130
05/30/2022 09:00:51 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=131
05/30/2022 09:00:54 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.16 on epoch=132
05/30/2022 09:01:00 - INFO - __main__ - Global step 1850 Train loss 0.14 Classification-F1 0.839254700831187 on epoch=132
05/30/2022 09:01:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=132
05/30/2022 09:01:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.20 on epoch=133
05/30/2022 09:01:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=134
05/30/2022 09:01:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.17 on epoch=134
05/30/2022 09:01:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.13 on epoch=135
05/30/2022 09:01:18 - INFO - __main__ - Global step 1900 Train loss 0.14 Classification-F1 0.7957419659255801 on epoch=135
05/30/2022 09:01:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.15 on epoch=136
05/30/2022 09:01:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.16 on epoch=137
05/30/2022 09:01:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.11 on epoch=137
05/30/2022 09:01:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.14 on epoch=138
05/30/2022 09:01:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.16 on epoch=139
05/30/2022 09:01:36 - INFO - __main__ - Global step 1950 Train loss 0.15 Classification-F1 0.8376085524018992 on epoch=139
05/30/2022 09:01:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.13 on epoch=139
05/30/2022 09:01:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.12 on epoch=140
05/30/2022 09:01:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=141
05/30/2022 09:01:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.15 on epoch=142
05/30/2022 09:01:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=142
05/30/2022 09:01:55 - INFO - __main__ - Global step 2000 Train loss 0.12 Classification-F1 0.9686975303317809 on epoch=142
05/30/2022 09:01:55 - INFO - __main__ - Saving model with best Classification-F1: 0.9641582320560946 -> 0.9686975303317809 on epoch=142, global_step=2000
05/30/2022 09:01:58 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=143
05/30/2022 09:02:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.14 on epoch=144
05/30/2022 09:02:03 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.15 on epoch=144
05/30/2022 09:02:05 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=145
05/30/2022 09:02:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.13 on epoch=146
05/30/2022 09:02:14 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.8453460123052154 on epoch=146
05/30/2022 09:02:16 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.14 on epoch=147
05/30/2022 09:02:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.14 on epoch=147
05/30/2022 09:02:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.10 on epoch=148
05/30/2022 09:02:24 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.14 on epoch=149
05/30/2022 09:02:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=149
05/30/2022 09:02:32 - INFO - __main__ - Global step 2100 Train loss 0.12 Classification-F1 0.8987605521191859 on epoch=149
05/30/2022 09:02:35 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.12 on epoch=150
05/30/2022 09:02:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=151
05/30/2022 09:02:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.14 on epoch=152
05/30/2022 09:02:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.13 on epoch=152
05/30/2022 09:02:45 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.15 on epoch=153
05/30/2022 09:02:51 - INFO - __main__ - Global step 2150 Train loss 0.12 Classification-F1 0.8395005176329811 on epoch=153
05/30/2022 09:02:53 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.08 on epoch=154
05/30/2022 09:02:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.12 on epoch=154
05/30/2022 09:02:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.10 on epoch=155
05/30/2022 09:03:00 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.12 on epoch=156
05/30/2022 09:03:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=157
05/30/2022 09:03:09 - INFO - __main__ - Global step 2200 Train loss 0.10 Classification-F1 0.9103413163897035 on epoch=157
05/30/2022 09:03:12 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.11 on epoch=157
05/30/2022 09:03:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.12 on epoch=158
05/30/2022 09:03:17 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
05/30/2022 09:03:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.10 on epoch=159
05/30/2022 09:03:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
05/30/2022 09:03:27 - INFO - __main__ - Global step 2250 Train loss 0.09 Classification-F1 0.8972557987026678 on epoch=160
05/30/2022 09:03:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.14 on epoch=161
05/30/2022 09:03:32 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=162
05/30/2022 09:03:35 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.09 on epoch=162
05/30/2022 09:03:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=163
05/30/2022 09:03:40 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.11 on epoch=164
05/30/2022 09:03:46 - INFO - __main__ - Global step 2300 Train loss 0.10 Classification-F1 0.8953197766449418 on epoch=164
05/30/2022 09:03:48 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=164
05/30/2022 09:03:51 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.14 on epoch=165
05/30/2022 09:03:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.18 on epoch=166
05/30/2022 09:03:56 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.18 on epoch=167
05/30/2022 09:03:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=167
05/30/2022 09:04:04 - INFO - __main__ - Global step 2350 Train loss 0.13 Classification-F1 0.8395496413374735 on epoch=167
05/30/2022 09:04:06 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.17 on epoch=168
05/30/2022 09:04:09 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.10 on epoch=169
05/30/2022 09:04:11 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.14 on epoch=169
05/30/2022 09:04:14 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=170
05/30/2022 09:04:16 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=171
05/30/2022 09:04:23 - INFO - __main__ - Global step 2400 Train loss 0.11 Classification-F1 0.9061378969965307 on epoch=171
05/30/2022 09:04:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.11 on epoch=172
05/30/2022 09:04:27 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
05/30/2022 09:04:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.11 on epoch=173
05/30/2022 09:04:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.12 on epoch=174
05/30/2022 09:04:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.09 on epoch=174
05/30/2022 09:04:41 - INFO - __main__ - Global step 2450 Train loss 0.10 Classification-F1 0.9689951493793999 on epoch=174
05/30/2022 09:04:41 - INFO - __main__ - Saving model with best Classification-F1: 0.9686975303317809 -> 0.9689951493793999 on epoch=174, global_step=2450
05/30/2022 09:04:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.10 on epoch=175
05/30/2022 09:04:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.11 on epoch=176
05/30/2022 09:04:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.12 on epoch=177
05/30/2022 09:04:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=177
05/30/2022 09:04:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.10 on epoch=178
05/30/2022 09:04:59 - INFO - __main__ - Global step 2500 Train loss 0.11 Classification-F1 0.9019842638912848 on epoch=178
05/30/2022 09:05:01 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=179
05/30/2022 09:05:03 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.14 on epoch=179
05/30/2022 09:05:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.13 on epoch=180
05/30/2022 09:05:08 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.13 on epoch=181
05/30/2022 09:05:11 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.14 on epoch=182
05/30/2022 09:05:17 - INFO - __main__ - Global step 2550 Train loss 0.12 Classification-F1 0.9733197897927498 on epoch=182
05/30/2022 09:05:17 - INFO - __main__ - Saving model with best Classification-F1: 0.9689951493793999 -> 0.9733197897927498 on epoch=182, global_step=2550
05/30/2022 09:05:19 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=182
05/30/2022 09:05:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.10 on epoch=183
05/30/2022 09:05:24 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=184
05/30/2022 09:05:26 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=184
05/30/2022 09:05:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=185
05/30/2022 09:05:35 - INFO - __main__ - Global step 2600 Train loss 0.08 Classification-F1 0.8976136834549777 on epoch=185
05/30/2022 09:05:37 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.09 on epoch=186
05/30/2022 09:05:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.14 on epoch=187
05/30/2022 09:05:42 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=187
05/30/2022 09:05:44 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=188
05/30/2022 09:05:47 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.07 on epoch=189
05/30/2022 09:05:53 - INFO - __main__ - Global step 2650 Train loss 0.09 Classification-F1 0.9062894121480459 on epoch=189
05/30/2022 09:05:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.14 on epoch=189
05/30/2022 09:05:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.10 on epoch=190
05/30/2022 09:06:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.11 on epoch=191
05/30/2022 09:06:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.08 on epoch=192
05/30/2022 09:06:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=192
05/30/2022 09:06:11 - INFO - __main__ - Global step 2700 Train loss 0.10 Classification-F1 0.9018237881662929 on epoch=192
05/30/2022 09:06:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.11 on epoch=193
05/30/2022 09:06:16 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.08 on epoch=194
05/30/2022 09:06:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.10 on epoch=194
05/30/2022 09:06:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.11 on epoch=195
05/30/2022 09:06:23 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=196
05/30/2022 09:06:29 - INFO - __main__ - Global step 2750 Train loss 0.10 Classification-F1 0.8972382498015553 on epoch=196
05/30/2022 09:06:31 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
05/30/2022 09:06:34 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=197
05/30/2022 09:06:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
05/30/2022 09:06:38 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.12 on epoch=199
05/30/2022 09:06:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=199
05/30/2022 09:06:47 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.8466401314924797 on epoch=199
05/30/2022 09:06:49 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=200
05/30/2022 09:06:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.15 on epoch=201
05/30/2022 09:06:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.14 on epoch=202
05/30/2022 09:06:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.09 on epoch=202
05/30/2022 09:06:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.15 on epoch=203
05/30/2022 09:07:05 - INFO - __main__ - Global step 2850 Train loss 0.12 Classification-F1 0.9062894121480459 on epoch=203
05/30/2022 09:07:07 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=204
05/30/2022 09:07:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.13 on epoch=204
05/30/2022 09:07:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.11 on epoch=205
05/30/2022 09:07:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=206
05/30/2022 09:07:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.13 on epoch=207
05/30/2022 09:07:23 - INFO - __main__ - Global step 2900 Train loss 0.10 Classification-F1 0.897090807637984 on epoch=207
05/30/2022 09:07:25 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.13 on epoch=207
05/30/2022 09:07:28 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.12 on epoch=208
05/30/2022 09:07:30 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.08 on epoch=209
05/30/2022 09:07:33 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=209
05/30/2022 09:07:35 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.10 on epoch=210
05/30/2022 09:07:41 - INFO - __main__ - Global step 2950 Train loss 0.10 Classification-F1 0.8355012777244075 on epoch=210
05/30/2022 09:07:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.08 on epoch=211
05/30/2022 09:07:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=212
05/30/2022 09:07:48 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=212
05/30/2022 09:07:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.07 on epoch=213
05/30/2022 09:07:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
05/30/2022 09:07:54 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 09:07:54 - INFO - __main__ - Printing 3 examples
05/30/2022 09:07:54 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/30/2022 09:07:54 - INFO - __main__ - ['Animal']
05/30/2022 09:07:54 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/30/2022 09:07:54 - INFO - __main__ - ['Animal']
05/30/2022 09:07:54 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/30/2022 09:07:54 - INFO - __main__ - ['Animal']
05/30/2022 09:07:54 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:07:54 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:07:55 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 09:07:55 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 09:07:55 - INFO - __main__ - Printing 3 examples
05/30/2022 09:07:55 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/30/2022 09:07:55 - INFO - __main__ - ['Animal']
05/30/2022 09:07:55 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/30/2022 09:07:55 - INFO - __main__ - ['Animal']
05/30/2022 09:07:55 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/30/2022 09:07:55 - INFO - __main__ - ['Animal']
05/30/2022 09:07:55 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:07:55 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:07:55 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 09:07:59 - INFO - __main__ - Global step 3000 Train loss 0.07 Classification-F1 0.9019793763057521 on epoch=214
05/30/2022 09:07:59 - INFO - __main__ - save last model!
05/30/2022 09:07:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 09:07:59 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 09:07:59 - INFO - __main__ - Printing 3 examples
05/30/2022 09:07:59 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 09:07:59 - INFO - __main__ - ['Animal']
05/30/2022 09:07:59 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 09:07:59 - INFO - __main__ - ['Animal']
05/30/2022 09:07:59 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 09:07:59 - INFO - __main__ - ['Village']
05/30/2022 09:07:59 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:08:01 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:08:05 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 09:08:10 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 09:08:10 - INFO - __main__ - task name: dbpedia_14
05/30/2022 09:08:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 09:08:10 - INFO - __main__ - Starting training!
05/30/2022 09:10:13 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
05/30/2022 09:10:13 - INFO - __main__ - Classification-F1 on test data: 0.4636
05/30/2022 09:10:13 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.9733197897927498, test_performance=0.46358778376677495
05/30/2022 09:10:13 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
05/30/2022 09:10:14 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 09:10:14 - INFO - __main__ - Printing 3 examples
05/30/2022 09:10:14 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/30/2022 09:10:14 - INFO - __main__ - ['Animal']
05/30/2022 09:10:14 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/30/2022 09:10:14 - INFO - __main__ - ['Animal']
05/30/2022 09:10:14 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/30/2022 09:10:14 - INFO - __main__ - ['Animal']
05/30/2022 09:10:14 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:10:14 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:10:14 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 09:10:14 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 09:10:14 - INFO - __main__ - Printing 3 examples
05/30/2022 09:10:14 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/30/2022 09:10:14 - INFO - __main__ - ['Animal']
05/30/2022 09:10:14 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/30/2022 09:10:14 - INFO - __main__ - ['Animal']
05/30/2022 09:10:14 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/30/2022 09:10:14 - INFO - __main__ - ['Animal']
05/30/2022 09:10:14 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:10:14 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:10:15 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 09:10:29 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 09:10:29 - INFO - __main__ - task name: dbpedia_14
05/30/2022 09:10:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 09:10:30 - INFO - __main__ - Starting training!
05/30/2022 09:10:33 - INFO - __main__ - Step 10 Global step 10 Train loss 6.88 on epoch=0
05/30/2022 09:10:36 - INFO - __main__ - Step 20 Global step 20 Train loss 6.49 on epoch=1
05/30/2022 09:10:38 - INFO - __main__ - Step 30 Global step 30 Train loss 5.42 on epoch=2
05/30/2022 09:10:40 - INFO - __main__ - Step 40 Global step 40 Train loss 3.93 on epoch=2
05/30/2022 09:10:43 - INFO - __main__ - Step 50 Global step 50 Train loss 3.24 on epoch=3
05/30/2022 09:11:23 - INFO - __main__ - Global step 50 Train loss 5.19 Classification-F1 0.018715541011183542 on epoch=3
05/30/2022 09:11:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.018715541011183542 on epoch=3, global_step=50
05/30/2022 09:11:25 - INFO - __main__ - Step 60 Global step 60 Train loss 2.86 on epoch=4
05/30/2022 09:11:28 - INFO - __main__ - Step 70 Global step 70 Train loss 2.27 on epoch=4
05/30/2022 09:11:30 - INFO - __main__ - Step 80 Global step 80 Train loss 2.13 on epoch=5
05/30/2022 09:11:33 - INFO - __main__ - Step 90 Global step 90 Train loss 1.91 on epoch=6
05/30/2022 09:11:35 - INFO - __main__ - Step 100 Global step 100 Train loss 1.79 on epoch=7
05/30/2022 09:11:43 - INFO - __main__ - Global step 100 Train loss 2.19 Classification-F1 0.2572691700397168 on epoch=7
05/30/2022 09:11:43 - INFO - __main__ - Saving model with best Classification-F1: 0.018715541011183542 -> 0.2572691700397168 on epoch=7, global_step=100
05/30/2022 09:11:46 - INFO - __main__ - Step 110 Global step 110 Train loss 1.66 on epoch=7
05/30/2022 09:11:48 - INFO - __main__ - Step 120 Global step 120 Train loss 1.68 on epoch=8
05/30/2022 09:11:51 - INFO - __main__ - Step 130 Global step 130 Train loss 1.51 on epoch=9
05/30/2022 09:11:53 - INFO - __main__ - Step 140 Global step 140 Train loss 1.31 on epoch=9
05/30/2022 09:11:55 - INFO - __main__ - Step 150 Global step 150 Train loss 1.30 on epoch=10
05/30/2022 09:12:04 - INFO - __main__ - Global step 150 Train loss 1.49 Classification-F1 0.34422770711478545 on epoch=10
05/30/2022 09:12:04 - INFO - __main__ - Saving model with best Classification-F1: 0.2572691700397168 -> 0.34422770711478545 on epoch=10, global_step=150
05/30/2022 09:12:06 - INFO - __main__ - Step 160 Global step 160 Train loss 1.30 on epoch=11
05/30/2022 09:12:08 - INFO - __main__ - Step 170 Global step 170 Train loss 1.20 on epoch=12
05/30/2022 09:12:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.99 on epoch=12
05/30/2022 09:12:13 - INFO - __main__ - Step 190 Global step 190 Train loss 0.91 on epoch=13
05/30/2022 09:12:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.99 on epoch=14
05/30/2022 09:12:21 - INFO - __main__ - Global step 200 Train loss 1.08 Classification-F1 0.28044243999546886 on epoch=14
05/30/2022 09:12:24 - INFO - __main__ - Step 210 Global step 210 Train loss 0.77 on epoch=14
05/30/2022 09:12:26 - INFO - __main__ - Step 220 Global step 220 Train loss 0.85 on epoch=15
05/30/2022 09:12:29 - INFO - __main__ - Step 230 Global step 230 Train loss 0.80 on epoch=16
05/30/2022 09:12:31 - INFO - __main__ - Step 240 Global step 240 Train loss 0.75 on epoch=17
05/30/2022 09:12:34 - INFO - __main__ - Step 250 Global step 250 Train loss 0.79 on epoch=17
05/30/2022 09:12:41 - INFO - __main__ - Global step 250 Train loss 0.79 Classification-F1 0.38237512071886265 on epoch=17
05/30/2022 09:12:41 - INFO - __main__ - Saving model with best Classification-F1: 0.34422770711478545 -> 0.38237512071886265 on epoch=17, global_step=250
05/30/2022 09:12:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.72 on epoch=18
05/30/2022 09:12:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.67 on epoch=19
05/30/2022 09:12:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.61 on epoch=19
05/30/2022 09:12:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.67 on epoch=20
05/30/2022 09:12:54 - INFO - __main__ - Step 300 Global step 300 Train loss 0.57 on epoch=21
05/30/2022 09:13:00 - INFO - __main__ - Global step 300 Train loss 0.65 Classification-F1 0.5294495222519416 on epoch=21
05/30/2022 09:13:00 - INFO - __main__ - Saving model with best Classification-F1: 0.38237512071886265 -> 0.5294495222519416 on epoch=21, global_step=300
05/30/2022 09:13:02 - INFO - __main__ - Step 310 Global step 310 Train loss 0.57 on epoch=22
05/30/2022 09:13:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.65 on epoch=22
05/30/2022 09:13:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.56 on epoch=23
05/30/2022 09:13:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.61 on epoch=24
05/30/2022 09:13:12 - INFO - __main__ - Step 350 Global step 350 Train loss 0.54 on epoch=24
05/30/2022 09:13:18 - INFO - __main__ - Global step 350 Train loss 0.59 Classification-F1 0.6623495214814001 on epoch=24
05/30/2022 09:13:18 - INFO - __main__ - Saving model with best Classification-F1: 0.5294495222519416 -> 0.6623495214814001 on epoch=24, global_step=350
05/30/2022 09:13:20 - INFO - __main__ - Step 360 Global step 360 Train loss 0.59 on epoch=25
05/30/2022 09:13:23 - INFO - __main__ - Step 370 Global step 370 Train loss 0.52 on epoch=26
05/30/2022 09:13:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.53 on epoch=27
05/30/2022 09:13:28 - INFO - __main__ - Step 390 Global step 390 Train loss 0.42 on epoch=27
05/30/2022 09:13:30 - INFO - __main__ - Step 400 Global step 400 Train loss 0.44 on epoch=28
05/30/2022 09:13:37 - INFO - __main__ - Global step 400 Train loss 0.50 Classification-F1 0.7629594640723673 on epoch=28
05/30/2022 09:13:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6623495214814001 -> 0.7629594640723673 on epoch=28, global_step=400
05/30/2022 09:13:39 - INFO - __main__ - Step 410 Global step 410 Train loss 0.48 on epoch=29
05/30/2022 09:13:42 - INFO - __main__ - Step 420 Global step 420 Train loss 0.49 on epoch=29
05/30/2022 09:13:44 - INFO - __main__ - Step 430 Global step 430 Train loss 0.53 on epoch=30
05/30/2022 09:13:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.43 on epoch=31
05/30/2022 09:13:49 - INFO - __main__ - Step 450 Global step 450 Train loss 0.53 on epoch=32
05/30/2022 09:13:56 - INFO - __main__ - Global step 450 Train loss 0.49 Classification-F1 0.5996572360763694 on epoch=32
05/30/2022 09:13:58 - INFO - __main__ - Step 460 Global step 460 Train loss 0.47 on epoch=32
05/30/2022 09:14:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.40 on epoch=33
05/30/2022 09:14:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.45 on epoch=34
05/30/2022 09:14:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.48 on epoch=34
05/30/2022 09:14:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.41 on epoch=35
05/30/2022 09:14:15 - INFO - __main__ - Global step 500 Train loss 0.44 Classification-F1 0.7454345593882159 on epoch=35
05/30/2022 09:14:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.34 on epoch=36
05/30/2022 09:14:20 - INFO - __main__ - Step 520 Global step 520 Train loss 0.38 on epoch=37
05/30/2022 09:14:22 - INFO - __main__ - Step 530 Global step 530 Train loss 0.34 on epoch=37
05/30/2022 09:14:25 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=38
05/30/2022 09:14:27 - INFO - __main__ - Step 550 Global step 550 Train loss 0.42 on epoch=39
05/30/2022 09:14:33 - INFO - __main__ - Global step 550 Train loss 0.38 Classification-F1 0.6196987793680676 on epoch=39
05/30/2022 09:14:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.42 on epoch=39
05/30/2022 09:14:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=40
05/30/2022 09:14:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.36 on epoch=41
05/30/2022 09:14:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.36 on epoch=42
05/30/2022 09:14:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.33 on epoch=42
05/30/2022 09:14:52 - INFO - __main__ - Global step 600 Train loss 0.36 Classification-F1 0.7497388231036832 on epoch=42
05/30/2022 09:14:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.35 on epoch=43
05/30/2022 09:14:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.35 on epoch=44
05/30/2022 09:14:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.34 on epoch=44
05/30/2022 09:15:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.35 on epoch=45
05/30/2022 09:15:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.26 on epoch=46
05/30/2022 09:15:10 - INFO - __main__ - Global step 650 Train loss 0.33 Classification-F1 0.6728619893705283 on epoch=46
05/30/2022 09:15:13 - INFO - __main__ - Step 660 Global step 660 Train loss 0.30 on epoch=47
05/30/2022 09:15:15 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=47
05/30/2022 09:15:18 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=48
05/30/2022 09:15:20 - INFO - __main__ - Step 690 Global step 690 Train loss 0.29 on epoch=49
05/30/2022 09:15:23 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=49
05/30/2022 09:15:29 - INFO - __main__ - Global step 700 Train loss 0.26 Classification-F1 0.6384113098858929 on epoch=49
05/30/2022 09:15:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.31 on epoch=50
05/30/2022 09:15:34 - INFO - __main__ - Step 720 Global step 720 Train loss 0.31 on epoch=51
05/30/2022 09:15:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.30 on epoch=52
05/30/2022 09:15:39 - INFO - __main__ - Step 740 Global step 740 Train loss 0.25 on epoch=52
05/30/2022 09:15:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=53
05/30/2022 09:15:47 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.8499129544290833 on epoch=53
05/30/2022 09:15:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7629594640723673 -> 0.8499129544290833 on epoch=53, global_step=750
05/30/2022 09:15:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=54
05/30/2022 09:15:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=54
05/30/2022 09:15:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=55
05/30/2022 09:15:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=56
05/30/2022 09:16:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=57
05/30/2022 09:16:05 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.6460773488068017 on epoch=57
05/30/2022 09:16:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=57
05/30/2022 09:16:10 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=58
05/30/2022 09:16:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.26 on epoch=59
05/30/2022 09:16:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=59
05/30/2022 09:16:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=60
05/30/2022 09:16:23 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.6819497952325276 on epoch=60
05/30/2022 09:16:26 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=61
05/30/2022 09:16:28 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=62
05/30/2022 09:16:31 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=62
05/30/2022 09:16:33 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=63
05/30/2022 09:16:36 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=64
05/30/2022 09:16:41 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.7657995034795864 on epoch=64
05/30/2022 09:16:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=64
05/30/2022 09:16:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
05/30/2022 09:16:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=66
05/30/2022 09:16:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=67
05/30/2022 09:16:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=67
05/30/2022 09:16:59 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.8094088273631868 on epoch=67
05/30/2022 09:17:02 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=68
05/30/2022 09:17:04 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=69
05/30/2022 09:17:07 - INFO - __main__ - Step 980 Global step 980 Train loss 0.19 on epoch=69
05/30/2022 09:17:09 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=70
05/30/2022 09:17:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=71
05/30/2022 09:17:18 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.7274359740319847 on epoch=71
05/30/2022 09:17:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=72
05/30/2022 09:17:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=72
05/30/2022 09:17:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=73
05/30/2022 09:17:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=74
05/30/2022 09:17:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
05/30/2022 09:17:36 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7129228877503104 on epoch=74
05/30/2022 09:17:39 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=75
05/30/2022 09:17:41 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
05/30/2022 09:17:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
05/30/2022 09:17:46 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
05/30/2022 09:17:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=78
05/30/2022 09:17:54 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.7321141801639377 on epoch=78
05/30/2022 09:17:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=79
05/30/2022 09:17:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
05/30/2022 09:18:02 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=80
05/30/2022 09:18:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=81
05/30/2022 09:18:07 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
05/30/2022 09:18:12 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.8935549244135582 on epoch=82
05/30/2022 09:18:12 - INFO - __main__ - Saving model with best Classification-F1: 0.8499129544290833 -> 0.8935549244135582 on epoch=82, global_step=1150
05/30/2022 09:18:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=82
05/30/2022 09:18:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=83
05/30/2022 09:18:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=84
05/30/2022 09:18:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=84
05/30/2022 09:18:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=85
05/30/2022 09:18:30 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.7615090354989261 on epoch=85
05/30/2022 09:18:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
05/30/2022 09:18:35 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=87
05/30/2022 09:18:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
05/30/2022 09:18:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=88
05/30/2022 09:18:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
05/30/2022 09:18:48 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.7898424012136961 on epoch=89
05/30/2022 09:18:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=89
05/30/2022 09:18:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
05/30/2022 09:18:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
05/30/2022 09:18:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=92
05/30/2022 09:19:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=92
05/30/2022 09:19:06 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.7311253692592435 on epoch=92
05/30/2022 09:19:09 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
05/30/2022 09:19:11 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=94
05/30/2022 09:19:14 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=94
05/30/2022 09:19:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
05/30/2022 09:19:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=96
05/30/2022 09:19:25 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.9556450806128903 on epoch=96
05/30/2022 09:19:25 - INFO - __main__ - Saving model with best Classification-F1: 0.8935549244135582 -> 0.9556450806128903 on epoch=96, global_step=1350
05/30/2022 09:19:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=97
05/30/2022 09:19:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
05/30/2022 09:19:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
05/30/2022 09:19:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
05/30/2022 09:19:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
05/30/2022 09:19:43 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.8330775757883798 on epoch=99
05/30/2022 09:19:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
05/30/2022 09:19:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
05/30/2022 09:19:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
05/30/2022 09:19:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
05/30/2022 09:19:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
05/30/2022 09:20:01 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7383317627554193 on epoch=103
05/30/2022 09:20:03 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
05/30/2022 09:20:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
05/30/2022 09:20:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
05/30/2022 09:20:11 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
05/30/2022 09:20:13 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=107
05/30/2022 09:20:19 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.9373074152164014 on epoch=107
05/30/2022 09:20:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
05/30/2022 09:20:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
05/30/2022 09:20:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
05/30/2022 09:20:30 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.13 on epoch=109
05/30/2022 09:20:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
05/30/2022 09:20:38 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.7606912755227782 on epoch=110
05/30/2022 09:20:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
05/30/2022 09:20:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
05/30/2022 09:20:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
05/30/2022 09:20:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
05/30/2022 09:20:50 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=114
05/30/2022 09:20:56 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7661157780870409 on epoch=114
05/30/2022 09:20:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
05/30/2022 09:21:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
05/30/2022 09:21:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
05/30/2022 09:21:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=117
05/30/2022 09:21:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
05/30/2022 09:21:14 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7060427409441746 on epoch=117
05/30/2022 09:21:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
05/30/2022 09:21:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
05/30/2022 09:21:22 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
05/30/2022 09:21:24 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
05/30/2022 09:21:27 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
05/30/2022 09:21:32 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.8375670655498018 on epoch=121
05/30/2022 09:21:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
05/30/2022 09:21:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
05/30/2022 09:21:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
05/30/2022 09:21:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
05/30/2022 09:21:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
05/30/2022 09:21:50 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6332418462660397 on epoch=124
05/30/2022 09:21:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
05/30/2022 09:21:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
05/30/2022 09:21:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=127
05/30/2022 09:22:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
05/30/2022 09:22:03 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
05/30/2022 09:22:09 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.6526336001293557 on epoch=128
05/30/2022 09:22:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
05/30/2022 09:22:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
05/30/2022 09:22:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
05/30/2022 09:22:19 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
05/30/2022 09:22:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
05/30/2022 09:22:27 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7381843850660607 on epoch=132
05/30/2022 09:22:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
05/30/2022 09:22:32 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
05/30/2022 09:22:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
05/30/2022 09:22:37 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
05/30/2022 09:22:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
05/30/2022 09:22:45 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.6976963064919455 on epoch=135
05/30/2022 09:22:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
05/30/2022 09:22:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
05/30/2022 09:22:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
05/30/2022 09:22:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
05/30/2022 09:22:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
05/30/2022 09:23:03 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6989180202100904 on epoch=139
05/30/2022 09:23:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
05/30/2022 09:23:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=140
05/30/2022 09:23:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
05/30/2022 09:23:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
05/30/2022 09:23:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
05/30/2022 09:23:22 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6217345046146889 on epoch=142
05/30/2022 09:23:24 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
05/30/2022 09:23:27 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
05/30/2022 09:23:29 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
05/30/2022 09:23:31 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=145
05/30/2022 09:23:34 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
05/30/2022 09:23:40 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.8125290909696183 on epoch=146
05/30/2022 09:23:43 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
05/30/2022 09:23:45 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=147
05/30/2022 09:23:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=148
05/30/2022 09:23:50 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
05/30/2022 09:23:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
05/30/2022 09:23:58 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.8122148758697028 on epoch=149
05/30/2022 09:24:01 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/30/2022 09:24:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
05/30/2022 09:24:06 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
05/30/2022 09:24:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
05/30/2022 09:24:11 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
05/30/2022 09:24:17 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6534241741147764 on epoch=153
05/30/2022 09:24:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.08 on epoch=154
05/30/2022 09:24:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
05/30/2022 09:24:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
05/30/2022 09:24:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
05/30/2022 09:24:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/30/2022 09:24:35 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6553884641108749 on epoch=157
05/30/2022 09:24:38 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/30/2022 09:24:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
05/30/2022 09:24:43 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
05/30/2022 09:24:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
05/30/2022 09:24:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
05/30/2022 09:24:53 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7404684048882622 on epoch=160
05/30/2022 09:24:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
05/30/2022 09:24:58 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=162
05/30/2022 09:25:01 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=162
05/30/2022 09:25:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=163
05/30/2022 09:25:06 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
05/30/2022 09:25:11 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.5953856593142307 on epoch=164
05/30/2022 09:25:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
05/30/2022 09:25:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=165
05/30/2022 09:25:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
05/30/2022 09:25:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
05/30/2022 09:25:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/30/2022 09:25:30 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7038206091060297 on epoch=167
05/30/2022 09:25:32 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.10 on epoch=168
05/30/2022 09:25:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=169
05/30/2022 09:25:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
05/30/2022 09:25:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
05/30/2022 09:25:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
05/30/2022 09:25:49 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.6811768909255108 on epoch=171
05/30/2022 09:25:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
05/30/2022 09:25:53 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/30/2022 09:25:56 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
05/30/2022 09:25:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
05/30/2022 09:26:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
05/30/2022 09:26:07 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7974348714636341 on epoch=174
05/30/2022 09:26:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
05/30/2022 09:26:12 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
05/30/2022 09:26:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=177
05/30/2022 09:26:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
05/30/2022 09:26:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/30/2022 09:26:27 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7728981908969121 on epoch=178
05/30/2022 09:26:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
05/30/2022 09:26:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
05/30/2022 09:26:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
05/30/2022 09:26:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/30/2022 09:26:39 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
05/30/2022 09:26:46 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7850267379679144 on epoch=182
05/30/2022 09:26:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/30/2022 09:26:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
05/30/2022 09:26:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
05/30/2022 09:26:56 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
05/30/2022 09:26:58 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
05/30/2022 09:27:04 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7334174466750648 on epoch=185
05/30/2022 09:27:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
05/30/2022 09:27:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
05/30/2022 09:27:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
05/30/2022 09:27:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
05/30/2022 09:27:17 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/30/2022 09:27:24 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7434311646473083 on epoch=189
05/30/2022 09:27:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/30/2022 09:27:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
05/30/2022 09:27:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/30/2022 09:27:34 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
05/30/2022 09:27:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
05/30/2022 09:27:43 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7721507791103094 on epoch=192
05/30/2022 09:27:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/30/2022 09:27:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/30/2022 09:27:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/30/2022 09:27:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/30/2022 09:27:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
05/30/2022 09:28:03 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7855841157494091 on epoch=196
05/30/2022 09:28:05 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
05/30/2022 09:28:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
05/30/2022 09:28:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/30/2022 09:28:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
05/30/2022 09:28:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
05/30/2022 09:28:21 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6845273177697275 on epoch=199
05/30/2022 09:28:23 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/30/2022 09:28:26 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
05/30/2022 09:28:28 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
05/30/2022 09:28:31 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/30/2022 09:28:33 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
05/30/2022 09:28:40 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7160746869617838 on epoch=203
05/30/2022 09:28:43 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
05/30/2022 09:28:45 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
05/30/2022 09:28:48 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/30/2022 09:28:50 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
05/30/2022 09:28:53 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/30/2022 09:29:00 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7258021583145905 on epoch=207
05/30/2022 09:29:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/30/2022 09:29:05 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
05/30/2022 09:29:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
05/30/2022 09:29:10 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
05/30/2022 09:29:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.09 on epoch=210
05/30/2022 09:29:20 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7827050683996213 on epoch=210
05/30/2022 09:29:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
05/30/2022 09:29:25 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
05/30/2022 09:29:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
05/30/2022 09:29:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/30/2022 09:29:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
05/30/2022 09:29:34 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 09:29:34 - INFO - __main__ - Printing 3 examples
05/30/2022 09:29:34 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/30/2022 09:29:34 - INFO - __main__ - ['Animal']
05/30/2022 09:29:34 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/30/2022 09:29:34 - INFO - __main__ - ['Animal']
05/30/2022 09:29:34 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/30/2022 09:29:34 - INFO - __main__ - ['Animal']
05/30/2022 09:29:34 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:29:34 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:29:34 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 09:29:34 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 09:29:34 - INFO - __main__ - Printing 3 examples
05/30/2022 09:29:34 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/30/2022 09:29:34 - INFO - __main__ - ['Animal']
05/30/2022 09:29:34 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/30/2022 09:29:34 - INFO - __main__ - ['Animal']
05/30/2022 09:29:34 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/30/2022 09:29:34 - INFO - __main__ - ['Animal']
05/30/2022 09:29:34 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:29:34 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:29:34 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 09:29:39 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.795590222461246 on epoch=214
05/30/2022 09:29:39 - INFO - __main__ - save last model!
05/30/2022 09:29:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 09:29:39 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 09:29:39 - INFO - __main__ - Printing 3 examples
05/30/2022 09:29:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 09:29:39 - INFO - __main__ - ['Animal']
05/30/2022 09:29:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 09:29:39 - INFO - __main__ - ['Animal']
05/30/2022 09:29:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 09:29:39 - INFO - __main__ - ['Village']
05/30/2022 09:29:39 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:29:41 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:29:44 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 09:29:53 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 09:29:53 - INFO - __main__ - task name: dbpedia_14
05/30/2022 09:29:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 09:29:54 - INFO - __main__ - Starting training!
05/30/2022 09:31:47 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
05/30/2022 09:31:47 - INFO - __main__ - Classification-F1 on test data: 0.5205
05/30/2022 09:31:47 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.9556450806128903, test_performance=0.5204697133545744
05/30/2022 09:31:47 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
05/30/2022 09:31:48 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 09:31:48 - INFO - __main__ - Printing 3 examples
05/30/2022 09:31:48 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/30/2022 09:31:48 - INFO - __main__ - ['Animal']
05/30/2022 09:31:48 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/30/2022 09:31:48 - INFO - __main__ - ['Animal']
05/30/2022 09:31:48 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/30/2022 09:31:48 - INFO - __main__ - ['Animal']
05/30/2022 09:31:48 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:31:48 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:31:49 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 09:31:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 09:31:49 - INFO - __main__ - Printing 3 examples
05/30/2022 09:31:49 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/30/2022 09:31:49 - INFO - __main__ - ['Animal']
05/30/2022 09:31:49 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/30/2022 09:31:49 - INFO - __main__ - ['Animal']
05/30/2022 09:31:49 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/30/2022 09:31:49 - INFO - __main__ - ['Animal']
05/30/2022 09:31:49 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:31:49 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:31:49 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 09:32:04 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 09:32:04 - INFO - __main__ - task name: dbpedia_14
05/30/2022 09:32:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 09:32:05 - INFO - __main__ - Starting training!
05/30/2022 09:32:07 - INFO - __main__ - Step 10 Global step 10 Train loss 6.80 on epoch=0
05/30/2022 09:32:10 - INFO - __main__ - Step 20 Global step 20 Train loss 6.51 on epoch=1
05/30/2022 09:32:12 - INFO - __main__ - Step 30 Global step 30 Train loss 5.25 on epoch=2
05/30/2022 09:32:14 - INFO - __main__ - Step 40 Global step 40 Train loss 4.07 on epoch=2
05/30/2022 09:32:17 - INFO - __main__ - Step 50 Global step 50 Train loss 3.39 on epoch=3
05/30/2022 09:32:34 - INFO - __main__ - Global step 50 Train loss 5.21 Classification-F1 0.06216786463844599 on epoch=3
05/30/2022 09:32:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06216786463844599 on epoch=3, global_step=50
05/30/2022 09:32:36 - INFO - __main__ - Step 60 Global step 60 Train loss 2.87 on epoch=4
05/30/2022 09:32:39 - INFO - __main__ - Step 70 Global step 70 Train loss 2.45 on epoch=4
05/30/2022 09:32:41 - INFO - __main__ - Step 80 Global step 80 Train loss 2.11 on epoch=5
05/30/2022 09:32:43 - INFO - __main__ - Step 90 Global step 90 Train loss 2.02 on epoch=6
05/30/2022 09:32:46 - INFO - __main__ - Step 100 Global step 100 Train loss 1.75 on epoch=7
05/30/2022 09:32:52 - INFO - __main__ - Global step 100 Train loss 2.24 Classification-F1 0.21418314270703864 on epoch=7
05/30/2022 09:32:52 - INFO - __main__ - Saving model with best Classification-F1: 0.06216786463844599 -> 0.21418314270703864 on epoch=7, global_step=100
05/30/2022 09:32:55 - INFO - __main__ - Step 110 Global step 110 Train loss 1.80 on epoch=7
05/30/2022 09:32:57 - INFO - __main__ - Step 120 Global step 120 Train loss 1.64 on epoch=8
05/30/2022 09:32:59 - INFO - __main__ - Step 130 Global step 130 Train loss 1.45 on epoch=9
05/30/2022 09:33:02 - INFO - __main__ - Step 140 Global step 140 Train loss 1.35 on epoch=9
05/30/2022 09:33:04 - INFO - __main__ - Step 150 Global step 150 Train loss 1.27 on epoch=10
05/30/2022 09:33:10 - INFO - __main__ - Global step 150 Train loss 1.50 Classification-F1 0.2733116408505403 on epoch=10
05/30/2022 09:33:10 - INFO - __main__ - Saving model with best Classification-F1: 0.21418314270703864 -> 0.2733116408505403 on epoch=10, global_step=150
05/30/2022 09:33:12 - INFO - __main__ - Step 160 Global step 160 Train loss 1.15 on epoch=11
05/30/2022 09:33:15 - INFO - __main__ - Step 170 Global step 170 Train loss 1.22 on epoch=12
05/30/2022 09:33:17 - INFO - __main__ - Step 180 Global step 180 Train loss 1.08 on epoch=12
05/30/2022 09:33:19 - INFO - __main__ - Step 190 Global step 190 Train loss 1.02 on epoch=13
05/30/2022 09:33:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.97 on epoch=14
05/30/2022 09:33:28 - INFO - __main__ - Global step 200 Train loss 1.09 Classification-F1 0.3784986954222248 on epoch=14
05/30/2022 09:33:28 - INFO - __main__ - Saving model with best Classification-F1: 0.2733116408505403 -> 0.3784986954222248 on epoch=14, global_step=200
05/30/2022 09:33:31 - INFO - __main__ - Step 210 Global step 210 Train loss 1.10 on epoch=14
05/30/2022 09:33:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.84 on epoch=15
05/30/2022 09:33:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.78 on epoch=16
05/30/2022 09:33:38 - INFO - __main__ - Step 240 Global step 240 Train loss 0.90 on epoch=17
05/30/2022 09:33:40 - INFO - __main__ - Step 250 Global step 250 Train loss 0.75 on epoch=17
05/30/2022 09:33:46 - INFO - __main__ - Global step 250 Train loss 0.87 Classification-F1 0.361098934949572 on epoch=17
05/30/2022 09:33:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.84 on epoch=18
05/30/2022 09:33:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.93 on epoch=19
05/30/2022 09:33:53 - INFO - __main__ - Step 280 Global step 280 Train loss 0.85 on epoch=19
05/30/2022 09:33:56 - INFO - __main__ - Step 290 Global step 290 Train loss 0.79 on epoch=20
05/30/2022 09:33:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.68 on epoch=21
05/30/2022 09:34:04 - INFO - __main__ - Global step 300 Train loss 0.82 Classification-F1 0.4717156756053585 on epoch=21
05/30/2022 09:34:04 - INFO - __main__ - Saving model with best Classification-F1: 0.3784986954222248 -> 0.4717156756053585 on epoch=21, global_step=300
05/30/2022 09:34:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.69 on epoch=22
05/30/2022 09:34:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.57 on epoch=22
05/30/2022 09:34:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.71 on epoch=23
05/30/2022 09:34:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.74 on epoch=24
05/30/2022 09:34:16 - INFO - __main__ - Step 350 Global step 350 Train loss 0.64 on epoch=24
05/30/2022 09:34:23 - INFO - __main__ - Global step 350 Train loss 0.67 Classification-F1 0.531975944867352 on epoch=24
05/30/2022 09:34:23 - INFO - __main__ - Saving model with best Classification-F1: 0.4717156756053585 -> 0.531975944867352 on epoch=24, global_step=350
05/30/2022 09:34:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.61 on epoch=25
05/30/2022 09:34:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.65 on epoch=26
05/30/2022 09:34:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.60 on epoch=27
05/30/2022 09:34:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=27
05/30/2022 09:34:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.56 on epoch=28
05/30/2022 09:34:41 - INFO - __main__ - Global step 400 Train loss 0.59 Classification-F1 0.5184625338965839 on epoch=28
05/30/2022 09:34:44 - INFO - __main__ - Step 410 Global step 410 Train loss 0.71 on epoch=29
05/30/2022 09:34:46 - INFO - __main__ - Step 420 Global step 420 Train loss 0.59 on epoch=29
05/30/2022 09:34:48 - INFO - __main__ - Step 430 Global step 430 Train loss 0.63 on epoch=30
05/30/2022 09:34:51 - INFO - __main__ - Step 440 Global step 440 Train loss 0.61 on epoch=31
05/30/2022 09:34:53 - INFO - __main__ - Step 450 Global step 450 Train loss 0.57 on epoch=32
05/30/2022 09:35:00 - INFO - __main__ - Global step 450 Train loss 0.62 Classification-F1 0.6773151723999218 on epoch=32
05/30/2022 09:35:00 - INFO - __main__ - Saving model with best Classification-F1: 0.531975944867352 -> 0.6773151723999218 on epoch=32, global_step=450
05/30/2022 09:35:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.55 on epoch=32
05/30/2022 09:35:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.53 on epoch=33
05/30/2022 09:35:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.50 on epoch=34
05/30/2022 09:35:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.45 on epoch=34
05/30/2022 09:35:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.52 on epoch=35
05/30/2022 09:35:19 - INFO - __main__ - Global step 500 Train loss 0.51 Classification-F1 0.6292949036382572 on epoch=35
05/30/2022 09:35:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.51 on epoch=36
05/30/2022 09:35:24 - INFO - __main__ - Step 520 Global step 520 Train loss 0.49 on epoch=37
05/30/2022 09:35:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.50 on epoch=37
05/30/2022 09:35:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.51 on epoch=38
05/30/2022 09:35:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.51 on epoch=39
05/30/2022 09:35:37 - INFO - __main__ - Global step 550 Train loss 0.50 Classification-F1 0.6970897927853885 on epoch=39
05/30/2022 09:35:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6773151723999218 -> 0.6970897927853885 on epoch=39, global_step=550
05/30/2022 09:35:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=39
05/30/2022 09:35:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.37 on epoch=40
05/30/2022 09:35:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.41 on epoch=41
05/30/2022 09:35:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.53 on epoch=42
05/30/2022 09:35:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.44 on epoch=42
05/30/2022 09:35:56 - INFO - __main__ - Global step 600 Train loss 0.43 Classification-F1 0.7386248922149637 on epoch=42
05/30/2022 09:35:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6970897927853885 -> 0.7386248922149637 on epoch=42, global_step=600
05/30/2022 09:35:59 - INFO - __main__ - Step 610 Global step 610 Train loss 0.40 on epoch=43
05/30/2022 09:36:01 - INFO - __main__ - Step 620 Global step 620 Train loss 0.47 on epoch=44
05/30/2022 09:36:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.38 on epoch=44
05/30/2022 09:36:06 - INFO - __main__ - Step 640 Global step 640 Train loss 0.43 on epoch=45
05/30/2022 09:36:08 - INFO - __main__ - Step 650 Global step 650 Train loss 0.39 on epoch=46
05/30/2022 09:36:15 - INFO - __main__ - Global step 650 Train loss 0.41 Classification-F1 0.650567099357422 on epoch=46
05/30/2022 09:36:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.46 on epoch=47
05/30/2022 09:36:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.41 on epoch=47
05/30/2022 09:36:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.33 on epoch=48
05/30/2022 09:36:24 - INFO - __main__ - Step 690 Global step 690 Train loss 0.37 on epoch=49
05/30/2022 09:36:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.37 on epoch=49
05/30/2022 09:36:33 - INFO - __main__ - Global step 700 Train loss 0.39 Classification-F1 0.5459981744331781 on epoch=49
05/30/2022 09:36:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.37 on epoch=50
05/30/2022 09:36:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.35 on epoch=51
05/30/2022 09:36:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.35 on epoch=52
05/30/2022 09:36:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.29 on epoch=52
05/30/2022 09:36:45 - INFO - __main__ - Step 750 Global step 750 Train loss 0.31 on epoch=53
05/30/2022 09:36:52 - INFO - __main__ - Global step 750 Train loss 0.33 Classification-F1 0.7570722463604651 on epoch=53
05/30/2022 09:36:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7386248922149637 -> 0.7570722463604651 on epoch=53, global_step=750
05/30/2022 09:36:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.31 on epoch=54
05/30/2022 09:36:56 - INFO - __main__ - Step 770 Global step 770 Train loss 0.33 on epoch=54
05/30/2022 09:36:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.37 on epoch=55
05/30/2022 09:37:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.33 on epoch=56
05/30/2022 09:37:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.30 on epoch=57
05/30/2022 09:37:10 - INFO - __main__ - Global step 800 Train loss 0.32 Classification-F1 0.8055305745628326 on epoch=57
05/30/2022 09:37:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7570722463604651 -> 0.8055305745628326 on epoch=57, global_step=800
05/30/2022 09:37:12 - INFO - __main__ - Step 810 Global step 810 Train loss 0.35 on epoch=57
05/30/2022 09:37:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=58
05/30/2022 09:37:17 - INFO - __main__ - Step 830 Global step 830 Train loss 0.28 on epoch=59
05/30/2022 09:37:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.37 on epoch=59
05/30/2022 09:37:22 - INFO - __main__ - Step 850 Global step 850 Train loss 0.29 on epoch=60
05/30/2022 09:37:28 - INFO - __main__ - Global step 850 Train loss 0.30 Classification-F1 0.7545310288544085 on epoch=60
05/30/2022 09:37:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.30 on epoch=61
05/30/2022 09:37:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.29 on epoch=62
05/30/2022 09:37:35 - INFO - __main__ - Step 880 Global step 880 Train loss 0.24 on epoch=62
05/30/2022 09:37:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.28 on epoch=63
05/30/2022 09:37:40 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=64
05/30/2022 09:37:47 - INFO - __main__ - Global step 900 Train loss 0.26 Classification-F1 0.8406165108710419 on epoch=64
05/30/2022 09:37:47 - INFO - __main__ - Saving model with best Classification-F1: 0.8055305745628326 -> 0.8406165108710419 on epoch=64, global_step=900
05/30/2022 09:37:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.30 on epoch=64
05/30/2022 09:37:52 - INFO - __main__ - Step 920 Global step 920 Train loss 0.29 on epoch=65
05/30/2022 09:37:54 - INFO - __main__ - Step 930 Global step 930 Train loss 0.27 on epoch=66
05/30/2022 09:37:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.28 on epoch=67
05/30/2022 09:37:59 - INFO - __main__ - Step 950 Global step 950 Train loss 0.23 on epoch=67
05/30/2022 09:38:06 - INFO - __main__ - Global step 950 Train loss 0.28 Classification-F1 0.7329138575358334 on epoch=67
05/30/2022 09:38:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.24 on epoch=68
05/30/2022 09:38:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.31 on epoch=69
05/30/2022 09:38:13 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=69
05/30/2022 09:38:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.29 on epoch=70
05/30/2022 09:38:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.19 on epoch=71
05/30/2022 09:38:24 - INFO - __main__ - Global step 1000 Train loss 0.25 Classification-F1 0.7986453242098404 on epoch=71
05/30/2022 09:38:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.26 on epoch=72
05/30/2022 09:38:29 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.23 on epoch=72
05/30/2022 09:38:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=73
05/30/2022 09:38:34 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.26 on epoch=74
05/30/2022 09:38:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.23 on epoch=74
05/30/2022 09:38:44 - INFO - __main__ - Global step 1050 Train loss 0.23 Classification-F1 0.9026170830013337 on epoch=74
05/30/2022 09:38:44 - INFO - __main__ - Saving model with best Classification-F1: 0.8406165108710419 -> 0.9026170830013337 on epoch=74, global_step=1050
05/30/2022 09:38:47 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.25 on epoch=75
05/30/2022 09:38:49 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.26 on epoch=76
05/30/2022 09:38:52 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.23 on epoch=77
05/30/2022 09:38:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=77
05/30/2022 09:38:57 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.19 on epoch=78
05/30/2022 09:39:03 - INFO - __main__ - Global step 1100 Train loss 0.22 Classification-F1 0.7573648389263871 on epoch=78
05/30/2022 09:39:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.27 on epoch=79
05/30/2022 09:39:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.16 on epoch=79
05/30/2022 09:39:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.18 on epoch=80
05/30/2022 09:39:13 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.23 on epoch=81
05/30/2022 09:39:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.23 on epoch=82
05/30/2022 09:39:22 - INFO - __main__ - Global step 1150 Train loss 0.22 Classification-F1 0.7728427539148602 on epoch=82
05/30/2022 09:39:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.19 on epoch=82
05/30/2022 09:39:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.20 on epoch=83
05/30/2022 09:39:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=84
05/30/2022 09:39:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.18 on epoch=84
05/30/2022 09:39:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=85
05/30/2022 09:39:41 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.5304622950326393 on epoch=85
05/30/2022 09:39:43 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=86
05/30/2022 09:39:46 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=87
05/30/2022 09:39:48 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=87
05/30/2022 09:39:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=88
05/30/2022 09:39:53 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=89
05/30/2022 09:40:00 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.6479751655118415 on epoch=89
05/30/2022 09:40:02 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=89
05/30/2022 09:40:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.22 on epoch=90
05/30/2022 09:40:07 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.19 on epoch=91
05/30/2022 09:40:10 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=92
05/30/2022 09:40:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
05/30/2022 09:40:19 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.6064309038662486 on epoch=92
05/30/2022 09:40:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=93
05/30/2022 09:40:23 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.25 on epoch=94
05/30/2022 09:40:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=94
05/30/2022 09:40:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.17 on epoch=95
05/30/2022 09:40:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=96
05/30/2022 09:40:37 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.5392239602288278 on epoch=96
05/30/2022 09:40:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.23 on epoch=97
05/30/2022 09:40:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.20 on epoch=97
05/30/2022 09:40:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=98
05/30/2022 09:40:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=99
05/30/2022 09:40:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=99
05/30/2022 09:40:56 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.7454531783963082 on epoch=99
05/30/2022 09:40:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.18 on epoch=100
05/30/2022 09:41:01 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=101
05/30/2022 09:41:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.20 on epoch=102
05/30/2022 09:41:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.17 on epoch=102
05/30/2022 09:41:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=103
05/30/2022 09:41:15 - INFO - __main__ - Global step 1450 Train loss 0.16 Classification-F1 0.6912008328566802 on epoch=103
05/30/2022 09:41:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=104
05/30/2022 09:41:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.20 on epoch=104
05/30/2022 09:41:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=105
05/30/2022 09:41:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=106
05/30/2022 09:41:28 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=107
05/30/2022 09:41:34 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.625433211450248 on epoch=107
05/30/2022 09:41:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=107
05/30/2022 09:41:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=108
05/30/2022 09:41:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=109
05/30/2022 09:41:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=109
05/30/2022 09:41:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=110
05/30/2022 09:41:53 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.7451178451178451 on epoch=110
05/30/2022 09:41:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=111
05/30/2022 09:41:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=112
05/30/2022 09:42:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=112
05/30/2022 09:42:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
05/30/2022 09:42:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=114
05/30/2022 09:42:13 - INFO - __main__ - Global step 1600 Train loss 0.11 Classification-F1 0.8356647116324536 on epoch=114
05/30/2022 09:42:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
05/30/2022 09:42:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=115
05/30/2022 09:42:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=116
05/30/2022 09:42:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.16 on epoch=117
05/30/2022 09:42:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=117
05/30/2022 09:42:32 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.905443787148459 on epoch=117
05/30/2022 09:42:32 - INFO - __main__ - Saving model with best Classification-F1: 0.9026170830013337 -> 0.905443787148459 on epoch=117, global_step=1650
05/30/2022 09:42:34 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
05/30/2022 09:42:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=119
05/30/2022 09:42:39 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=119
05/30/2022 09:42:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=120
05/30/2022 09:42:44 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
05/30/2022 09:42:51 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.7005728720375112 on epoch=121
05/30/2022 09:42:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
05/30/2022 09:42:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=122
05/30/2022 09:42:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=123
05/30/2022 09:43:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
05/30/2022 09:43:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.15 on epoch=124
05/30/2022 09:43:10 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.9776348295916607 on epoch=124
05/30/2022 09:43:10 - INFO - __main__ - Saving model with best Classification-F1: 0.905443787148459 -> 0.9776348295916607 on epoch=124, global_step=1750
05/30/2022 09:43:12 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
05/30/2022 09:43:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
05/30/2022 09:43:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
05/30/2022 09:43:20 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
05/30/2022 09:43:22 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=128
05/30/2022 09:43:29 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.7864486901586948 on epoch=128
05/30/2022 09:43:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=129
05/30/2022 09:43:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=129
05/30/2022 09:43:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
05/30/2022 09:43:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=131
05/30/2022 09:43:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
05/30/2022 09:43:48 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.7988957474098596 on epoch=132
05/30/2022 09:43:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
05/30/2022 09:43:53 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
05/30/2022 09:43:55 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=134
05/30/2022 09:43:58 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.13 on epoch=134
05/30/2022 09:44:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=135
05/30/2022 09:44:06 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.6319517033563686 on epoch=135
05/30/2022 09:44:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=136
05/30/2022 09:44:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=137
05/30/2022 09:44:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=137
05/30/2022 09:44:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
05/30/2022 09:44:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
05/30/2022 09:44:25 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.8949345994507285 on epoch=139
05/30/2022 09:44:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=139
05/30/2022 09:44:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
05/30/2022 09:44:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=141
05/30/2022 09:44:35 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
05/30/2022 09:44:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=142
05/30/2022 09:44:44 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7951115851258166 on epoch=142
05/30/2022 09:44:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
05/30/2022 09:44:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
05/30/2022 09:44:52 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
05/30/2022 09:44:54 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
05/30/2022 09:44:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=146
05/30/2022 09:45:03 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7784326523624995 on epoch=146
05/30/2022 09:45:05 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=147
05/30/2022 09:45:08 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
05/30/2022 09:45:11 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
05/30/2022 09:45:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=149
05/30/2022 09:45:16 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=149
05/30/2022 09:45:22 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.902183142074034 on epoch=149
05/30/2022 09:45:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=150
05/30/2022 09:45:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
05/30/2022 09:45:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
05/30/2022 09:45:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
05/30/2022 09:45:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
05/30/2022 09:45:40 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.9026861937345809 on epoch=153
05/30/2022 09:45:43 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=154
05/30/2022 09:45:45 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.12 on epoch=154
05/30/2022 09:45:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
05/30/2022 09:45:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
05/30/2022 09:45:53 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
05/30/2022 09:45:59 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.881888045540797 on epoch=157
05/30/2022 09:46:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=157
05/30/2022 09:46:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
05/30/2022 09:46:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
05/30/2022 09:46:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
05/30/2022 09:46:12 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
05/30/2022 09:46:18 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.9054151803978409 on epoch=160
05/30/2022 09:46:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
05/30/2022 09:46:23 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
05/30/2022 09:46:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
05/30/2022 09:46:28 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
05/30/2022 09:46:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
05/30/2022 09:46:37 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.9019597301286105 on epoch=164
05/30/2022 09:46:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
05/30/2022 09:46:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
05/30/2022 09:46:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
05/30/2022 09:46:47 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.08 on epoch=167
05/30/2022 09:46:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=167
05/30/2022 09:46:57 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.9037006210108677 on epoch=167
05/30/2022 09:46:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
05/30/2022 09:47:02 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=169
05/30/2022 09:47:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
05/30/2022 09:47:07 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
05/30/2022 09:47:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
05/30/2022 09:47:16 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.9012525867191182 on epoch=171
05/30/2022 09:47:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
05/30/2022 09:47:21 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
05/30/2022 09:47:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/30/2022 09:47:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
05/30/2022 09:47:29 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/30/2022 09:47:36 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8958164929923311 on epoch=174
05/30/2022 09:47:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
05/30/2022 09:47:41 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
05/30/2022 09:47:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
05/30/2022 09:47:46 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
05/30/2022 09:47:49 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/30/2022 09:47:56 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8917575273220435 on epoch=178
05/30/2022 09:47:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
05/30/2022 09:48:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
05/30/2022 09:48:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=180
05/30/2022 09:48:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
05/30/2022 09:48:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=182
05/30/2022 09:48:15 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.8820984239247996 on epoch=182
05/30/2022 09:48:17 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/30/2022 09:48:20 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/30/2022 09:48:22 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
05/30/2022 09:48:25 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
05/30/2022 09:48:27 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
05/30/2022 09:48:34 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8415944559845769 on epoch=185
05/30/2022 09:48:37 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
05/30/2022 09:48:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/30/2022 09:48:42 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=187
05/30/2022 09:48:44 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
05/30/2022 09:48:47 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
05/30/2022 09:48:53 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.8861100131752304 on epoch=189
05/30/2022 09:48:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/30/2022 09:48:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
05/30/2022 09:49:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
05/30/2022 09:49:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
05/30/2022 09:49:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
05/30/2022 09:49:12 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8932704613176379 on epoch=192
05/30/2022 09:49:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
05/30/2022 09:49:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
05/30/2022 09:49:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
05/30/2022 09:49:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/30/2022 09:49:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
05/30/2022 09:49:30 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.973139893787427 on epoch=196
05/30/2022 09:49:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/30/2022 09:49:35 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/30/2022 09:49:38 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
05/30/2022 09:49:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
05/30/2022 09:49:43 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/30/2022 09:49:49 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8449365190130051 on epoch=199
05/30/2022 09:49:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/30/2022 09:49:54 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
05/30/2022 09:49:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.17 on epoch=202
05/30/2022 09:50:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
05/30/2022 09:50:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
05/30/2022 09:50:08 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7907703889840394 on epoch=203
05/30/2022 09:50:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
05/30/2022 09:50:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
05/30/2022 09:50:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
05/30/2022 09:50:18 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
05/30/2022 09:50:21 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/30/2022 09:50:28 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7989922649167194 on epoch=207
05/30/2022 09:50:30 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
05/30/2022 09:50:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/30/2022 09:50:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/30/2022 09:50:38 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/30/2022 09:50:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=210
05/30/2022 09:50:46 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8269332955514221 on epoch=210
05/30/2022 09:50:49 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
05/30/2022 09:50:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
05/30/2022 09:50:54 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
05/30/2022 09:50:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/30/2022 09:50:59 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
05/30/2022 09:51:00 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 09:51:00 - INFO - __main__ - Printing 3 examples
05/30/2022 09:51:00 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/30/2022 09:51:00 - INFO - __main__ - ['Animal']
05/30/2022 09:51:00 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/30/2022 09:51:00 - INFO - __main__ - ['Animal']
05/30/2022 09:51:00 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/30/2022 09:51:00 - INFO - __main__ - ['Animal']
05/30/2022 09:51:00 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:51:00 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:51:01 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 09:51:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 09:51:01 - INFO - __main__ - Printing 3 examples
05/30/2022 09:51:01 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/30/2022 09:51:01 - INFO - __main__ - ['Animal']
05/30/2022 09:51:01 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/30/2022 09:51:01 - INFO - __main__ - ['Animal']
05/30/2022 09:51:01 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/30/2022 09:51:01 - INFO - __main__ - ['Animal']
05/30/2022 09:51:01 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:51:01 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:51:01 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 09:51:05 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8976571214996263 on epoch=214
05/30/2022 09:51:05 - INFO - __main__ - save last model!
05/30/2022 09:51:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 09:51:05 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 09:51:05 - INFO - __main__ - Printing 3 examples
05/30/2022 09:51:05 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 09:51:05 - INFO - __main__ - ['Animal']
05/30/2022 09:51:05 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 09:51:05 - INFO - __main__ - ['Animal']
05/30/2022 09:51:05 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 09:51:05 - INFO - __main__ - ['Village']
05/30/2022 09:51:05 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:51:07 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:51:10 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 09:51:16 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 09:51:16 - INFO - __main__ - task name: dbpedia_14
05/30/2022 09:51:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 09:51:16 - INFO - __main__ - Starting training!
05/30/2022 09:53:29 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
05/30/2022 09:53:29 - INFO - __main__ - Classification-F1 on test data: 0.6788
05/30/2022 09:53:30 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.9776348295916607, test_performance=0.678846778018517
05/30/2022 09:53:30 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
05/30/2022 09:53:31 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 09:53:31 - INFO - __main__ - Printing 3 examples
05/30/2022 09:53:31 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/30/2022 09:53:31 - INFO - __main__ - ['Animal']
05/30/2022 09:53:31 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/30/2022 09:53:31 - INFO - __main__ - ['Animal']
05/30/2022 09:53:31 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/30/2022 09:53:31 - INFO - __main__ - ['Animal']
05/30/2022 09:53:31 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:53:31 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:53:31 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 09:53:31 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 09:53:31 - INFO - __main__ - Printing 3 examples
05/30/2022 09:53:31 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/30/2022 09:53:31 - INFO - __main__ - ['Animal']
05/30/2022 09:53:31 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/30/2022 09:53:31 - INFO - __main__ - ['Animal']
05/30/2022 09:53:31 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/30/2022 09:53:31 - INFO - __main__ - ['Animal']
05/30/2022 09:53:31 - INFO - __main__ - Tokenizing Input ...
05/30/2022 09:53:31 - INFO - __main__ - Tokenizing Output ...
05/30/2022 09:53:31 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 09:53:50 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 09:53:50 - INFO - __main__ - task name: dbpedia_14
05/30/2022 09:53:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 09:53:51 - INFO - __main__ - Starting training!
05/30/2022 09:53:53 - INFO - __main__ - Step 10 Global step 10 Train loss 7.08 on epoch=0
05/30/2022 09:53:56 - INFO - __main__ - Step 20 Global step 20 Train loss 6.85 on epoch=1
05/30/2022 09:53:58 - INFO - __main__ - Step 30 Global step 30 Train loss 6.06 on epoch=2
05/30/2022 09:54:01 - INFO - __main__ - Step 40 Global step 40 Train loss 5.10 on epoch=2
05/30/2022 09:54:03 - INFO - __main__ - Step 50 Global step 50 Train loss 4.22 on epoch=3
05/30/2022 09:55:37 - INFO - __main__ - Global step 50 Train loss 5.86 Classification-F1 0.0014160962945480291 on epoch=3
05/30/2022 09:55:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0014160962945480291 on epoch=3, global_step=50
05/30/2022 09:55:39 - INFO - __main__ - Step 60 Global step 60 Train loss 3.59 on epoch=4
05/30/2022 09:55:42 - INFO - __main__ - Step 70 Global step 70 Train loss 3.20 on epoch=4
05/30/2022 09:55:44 - INFO - __main__ - Step 80 Global step 80 Train loss 2.86 on epoch=5
05/30/2022 09:55:47 - INFO - __main__ - Step 90 Global step 90 Train loss 2.61 on epoch=6
05/30/2022 09:55:49 - INFO - __main__ - Step 100 Global step 100 Train loss 2.57 on epoch=7
05/30/2022 09:56:01 - INFO - __main__ - Global step 100 Train loss 2.97 Classification-F1 0.1657254238241007 on epoch=7
05/30/2022 09:56:01 - INFO - __main__ - Saving model with best Classification-F1: 0.0014160962945480291 -> 0.1657254238241007 on epoch=7, global_step=100
05/30/2022 09:56:04 - INFO - __main__ - Step 110 Global step 110 Train loss 2.11 on epoch=7
05/30/2022 09:56:06 - INFO - __main__ - Step 120 Global step 120 Train loss 2.14 on epoch=8
05/30/2022 09:56:09 - INFO - __main__ - Step 130 Global step 130 Train loss 1.96 on epoch=9
05/30/2022 09:56:11 - INFO - __main__ - Step 140 Global step 140 Train loss 1.82 on epoch=9
05/30/2022 09:56:14 - INFO - __main__ - Step 150 Global step 150 Train loss 1.62 on epoch=10
05/30/2022 09:56:23 - INFO - __main__ - Global step 150 Train loss 1.93 Classification-F1 0.23663724978041367 on epoch=10
05/30/2022 09:56:23 - INFO - __main__ - Saving model with best Classification-F1: 0.1657254238241007 -> 0.23663724978041367 on epoch=10, global_step=150
05/30/2022 09:56:26 - INFO - __main__ - Step 160 Global step 160 Train loss 1.66 on epoch=11
05/30/2022 09:56:28 - INFO - __main__ - Step 170 Global step 170 Train loss 1.74 on epoch=12
05/30/2022 09:56:31 - INFO - __main__ - Step 180 Global step 180 Train loss 1.56 on epoch=12
05/30/2022 09:56:33 - INFO - __main__ - Step 190 Global step 190 Train loss 1.53 on epoch=13
05/30/2022 09:56:36 - INFO - __main__ - Step 200 Global step 200 Train loss 1.39 on epoch=14
05/30/2022 09:56:44 - INFO - __main__ - Global step 200 Train loss 1.58 Classification-F1 0.3043236560291588 on epoch=14
05/30/2022 09:56:44 - INFO - __main__ - Saving model with best Classification-F1: 0.23663724978041367 -> 0.3043236560291588 on epoch=14, global_step=200
05/30/2022 09:56:47 - INFO - __main__ - Step 210 Global step 210 Train loss 1.42 on epoch=14
05/30/2022 09:56:49 - INFO - __main__ - Step 220 Global step 220 Train loss 1.33 on epoch=15
05/30/2022 09:56:52 - INFO - __main__ - Step 230 Global step 230 Train loss 1.31 on epoch=16
05/30/2022 09:56:54 - INFO - __main__ - Step 240 Global step 240 Train loss 1.23 on epoch=17
05/30/2022 09:56:57 - INFO - __main__ - Step 250 Global step 250 Train loss 1.15 on epoch=17
05/30/2022 09:57:07 - INFO - __main__ - Global step 250 Train loss 1.29 Classification-F1 0.4265764400562572 on epoch=17
05/30/2022 09:57:07 - INFO - __main__ - Saving model with best Classification-F1: 0.3043236560291588 -> 0.4265764400562572 on epoch=17, global_step=250
05/30/2022 09:57:09 - INFO - __main__ - Step 260 Global step 260 Train loss 1.16 on epoch=18
05/30/2022 09:57:12 - INFO - __main__ - Step 270 Global step 270 Train loss 1.12 on epoch=19
05/30/2022 09:57:14 - INFO - __main__ - Step 280 Global step 280 Train loss 1.12 on epoch=19
05/30/2022 09:57:17 - INFO - __main__ - Step 290 Global step 290 Train loss 1.07 on epoch=20
05/30/2022 09:57:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.97 on epoch=21
05/30/2022 09:57:29 - INFO - __main__ - Global step 300 Train loss 1.09 Classification-F1 0.48850311422899684 on epoch=21
05/30/2022 09:57:29 - INFO - __main__ - Saving model with best Classification-F1: 0.4265764400562572 -> 0.48850311422899684 on epoch=21, global_step=300
05/30/2022 09:57:31 - INFO - __main__ - Step 310 Global step 310 Train loss 0.86 on epoch=22
05/30/2022 09:57:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.98 on epoch=22
05/30/2022 09:57:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.93 on epoch=23
05/30/2022 09:57:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.99 on epoch=24
05/30/2022 09:57:41 - INFO - __main__ - Step 350 Global step 350 Train loss 0.82 on epoch=24
05/30/2022 09:57:52 - INFO - __main__ - Global step 350 Train loss 0.92 Classification-F1 0.5661410959904217 on epoch=24
05/30/2022 09:57:52 - INFO - __main__ - Saving model with best Classification-F1: 0.48850311422899684 -> 0.5661410959904217 on epoch=24, global_step=350
05/30/2022 09:57:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.84 on epoch=25
05/30/2022 09:57:57 - INFO - __main__ - Step 370 Global step 370 Train loss 0.85 on epoch=26
05/30/2022 09:57:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.79 on epoch=27
05/30/2022 09:58:02 - INFO - __main__ - Step 390 Global step 390 Train loss 0.85 on epoch=27
05/30/2022 09:58:04 - INFO - __main__ - Step 400 Global step 400 Train loss 0.75 on epoch=28
05/30/2022 09:58:16 - INFO - __main__ - Global step 400 Train loss 0.81 Classification-F1 0.498811329779494 on epoch=28
05/30/2022 09:58:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.79 on epoch=29
05/30/2022 09:58:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.74 on epoch=29
05/30/2022 09:58:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.76 on epoch=30
05/30/2022 09:58:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.76 on epoch=31
05/30/2022 09:58:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.69 on epoch=32
05/30/2022 09:58:37 - INFO - __main__ - Global step 450 Train loss 0.75 Classification-F1 0.5348517148966564 on epoch=32
05/30/2022 09:58:40 - INFO - __main__ - Step 460 Global step 460 Train loss 0.77 on epoch=32
05/30/2022 09:58:42 - INFO - __main__ - Step 470 Global step 470 Train loss 0.65 on epoch=33
05/30/2022 09:58:45 - INFO - __main__ - Step 480 Global step 480 Train loss 0.68 on epoch=34
05/30/2022 09:58:47 - INFO - __main__ - Step 490 Global step 490 Train loss 0.63 on epoch=34
05/30/2022 09:58:50 - INFO - __main__ - Step 500 Global step 500 Train loss 0.67 on epoch=35
05/30/2022 09:58:57 - INFO - __main__ - Global step 500 Train loss 0.68 Classification-F1 0.5954232932760848 on epoch=35
05/30/2022 09:58:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5661410959904217 -> 0.5954232932760848 on epoch=35, global_step=500
05/30/2022 09:59:00 - INFO - __main__ - Step 510 Global step 510 Train loss 0.64 on epoch=36
05/30/2022 09:59:02 - INFO - __main__ - Step 520 Global step 520 Train loss 0.62 on epoch=37
05/30/2022 09:59:04 - INFO - __main__ - Step 530 Global step 530 Train loss 0.67 on epoch=37
05/30/2022 09:59:07 - INFO - __main__ - Step 540 Global step 540 Train loss 0.70 on epoch=38
05/30/2022 09:59:09 - INFO - __main__ - Step 550 Global step 550 Train loss 0.63 on epoch=39
05/30/2022 09:59:17 - INFO - __main__ - Global step 550 Train loss 0.65 Classification-F1 0.5808628046278033 on epoch=39
05/30/2022 09:59:19 - INFO - __main__ - Step 560 Global step 560 Train loss 0.61 on epoch=39
05/30/2022 09:59:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.62 on epoch=40
05/30/2022 09:59:24 - INFO - __main__ - Step 580 Global step 580 Train loss 0.50 on epoch=41
05/30/2022 09:59:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.61 on epoch=42
05/30/2022 09:59:29 - INFO - __main__ - Step 600 Global step 600 Train loss 0.53 on epoch=42
05/30/2022 09:59:36 - INFO - __main__ - Global step 600 Train loss 0.57 Classification-F1 0.6322675822787667 on epoch=42
05/30/2022 09:59:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5954232932760848 -> 0.6322675822787667 on epoch=42, global_step=600
05/30/2022 09:59:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.49 on epoch=43
05/30/2022 09:59:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.61 on epoch=44
05/30/2022 09:59:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.44 on epoch=44
05/30/2022 09:59:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.50 on epoch=45
05/30/2022 09:59:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.50 on epoch=46
05/30/2022 09:59:56 - INFO - __main__ - Global step 650 Train loss 0.51 Classification-F1 0.6521973437185867 on epoch=46
05/30/2022 09:59:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6322675822787667 -> 0.6521973437185867 on epoch=46, global_step=650
05/30/2022 09:59:58 - INFO - __main__ - Step 660 Global step 660 Train loss 0.50 on epoch=47
05/30/2022 10:00:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.55 on epoch=47
05/30/2022 10:00:03 - INFO - __main__ - Step 680 Global step 680 Train loss 0.43 on epoch=48
05/30/2022 10:00:06 - INFO - __main__ - Step 690 Global step 690 Train loss 0.49 on epoch=49
05/30/2022 10:00:08 - INFO - __main__ - Step 700 Global step 700 Train loss 0.45 on epoch=49
05/30/2022 10:00:16 - INFO - __main__ - Global step 700 Train loss 0.48 Classification-F1 0.6616804601783793 on epoch=49
05/30/2022 10:00:16 - INFO - __main__ - Saving model with best Classification-F1: 0.6521973437185867 -> 0.6616804601783793 on epoch=49, global_step=700
05/30/2022 10:00:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.49 on epoch=50
05/30/2022 10:00:21 - INFO - __main__ - Step 720 Global step 720 Train loss 0.49 on epoch=51
05/30/2022 10:00:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.45 on epoch=52
05/30/2022 10:00:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.45 on epoch=52
05/30/2022 10:00:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.50 on epoch=53
05/30/2022 10:00:35 - INFO - __main__ - Global step 750 Train loss 0.48 Classification-F1 0.6574651988723179 on epoch=53
05/30/2022 10:00:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.45 on epoch=54
05/30/2022 10:00:40 - INFO - __main__ - Step 770 Global step 770 Train loss 0.33 on epoch=54
05/30/2022 10:00:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.35 on epoch=55
05/30/2022 10:00:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.42 on epoch=56
05/30/2022 10:00:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.47 on epoch=57
05/30/2022 10:00:55 - INFO - __main__ - Global step 800 Train loss 0.41 Classification-F1 0.6752248700066538 on epoch=57
05/30/2022 10:00:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6616804601783793 -> 0.6752248700066538 on epoch=57, global_step=800
05/30/2022 10:00:57 - INFO - __main__ - Step 810 Global step 810 Train loss 0.33 on epoch=57
05/30/2022 10:01:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.32 on epoch=58
05/30/2022 10:01:02 - INFO - __main__ - Step 830 Global step 830 Train loss 0.40 on epoch=59
05/30/2022 10:01:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.43 on epoch=59
05/30/2022 10:01:08 - INFO - __main__ - Step 850 Global step 850 Train loss 0.37 on epoch=60
05/30/2022 10:01:15 - INFO - __main__ - Global step 850 Train loss 0.37 Classification-F1 0.6695469657044609 on epoch=60
05/30/2022 10:01:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.28 on epoch=61
05/30/2022 10:01:20 - INFO - __main__ - Step 870 Global step 870 Train loss 0.40 on epoch=62
05/30/2022 10:01:22 - INFO - __main__ - Step 880 Global step 880 Train loss 0.29 on epoch=62
05/30/2022 10:01:25 - INFO - __main__ - Step 890 Global step 890 Train loss 0.30 on epoch=63
05/30/2022 10:01:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.36 on epoch=64
05/30/2022 10:01:34 - INFO - __main__ - Global step 900 Train loss 0.33 Classification-F1 0.6194077733414527 on epoch=64
05/30/2022 10:01:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.29 on epoch=64
05/30/2022 10:01:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.35 on epoch=65
05/30/2022 10:01:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.32 on epoch=66
05/30/2022 10:01:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.33 on epoch=67
05/30/2022 10:01:47 - INFO - __main__ - Step 950 Global step 950 Train loss 0.28 on epoch=67
05/30/2022 10:01:54 - INFO - __main__ - Global step 950 Train loss 0.32 Classification-F1 0.7043267111341116 on epoch=67
05/30/2022 10:01:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6752248700066538 -> 0.7043267111341116 on epoch=67, global_step=950
05/30/2022 10:01:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.35 on epoch=68
05/30/2022 10:01:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.27 on epoch=69
05/30/2022 10:02:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.30 on epoch=69
05/30/2022 10:02:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.28 on epoch=70
05/30/2022 10:02:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.27 on epoch=71
05/30/2022 10:02:14 - INFO - __main__ - Global step 1000 Train loss 0.29 Classification-F1 0.6075471836325421 on epoch=71
05/30/2022 10:02:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.30 on epoch=72
05/30/2022 10:02:19 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.27 on epoch=72
05/30/2022 10:02:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.30 on epoch=73
05/30/2022 10:02:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.35 on epoch=74
05/30/2022 10:02:27 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.26 on epoch=74
05/30/2022 10:02:33 - INFO - __main__ - Global step 1050 Train loss 0.30 Classification-F1 0.6674291749340864 on epoch=74
05/30/2022 10:02:36 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.25 on epoch=75
05/30/2022 10:02:38 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=76
05/30/2022 10:02:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=77
05/30/2022 10:02:43 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=77
05/30/2022 10:02:45 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=78
05/30/2022 10:02:52 - INFO - __main__ - Global step 1100 Train loss 0.24 Classification-F1 0.6810812285159427 on epoch=78
05/30/2022 10:02:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=79
05/30/2022 10:02:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.19 on epoch=79
05/30/2022 10:02:59 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.17 on epoch=80
05/30/2022 10:03:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=81
05/30/2022 10:03:04 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.20 on epoch=82
05/30/2022 10:03:10 - INFO - __main__ - Global step 1150 Train loss 0.19 Classification-F1 0.666562142233255 on epoch=82
05/30/2022 10:03:13 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.20 on epoch=82
05/30/2022 10:03:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.19 on epoch=83
05/30/2022 10:03:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.21 on epoch=84
05/30/2022 10:03:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=84
05/30/2022 10:03:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.24 on epoch=85
05/30/2022 10:03:29 - INFO - __main__ - Global step 1200 Train loss 0.20 Classification-F1 0.5463582282300093 on epoch=85
05/30/2022 10:03:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.15 on epoch=86
05/30/2022 10:03:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.18 on epoch=87
05/30/2022 10:03:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=87
05/30/2022 10:03:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.20 on epoch=88
05/30/2022 10:03:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=89
05/30/2022 10:03:47 - INFO - __main__ - Global step 1250 Train loss 0.16 Classification-F1 0.5362805103824165 on epoch=89
05/30/2022 10:03:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.18 on epoch=89
05/30/2022 10:03:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=90
05/30/2022 10:03:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=91
05/30/2022 10:03:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.19 on epoch=92
05/30/2022 10:04:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.16 on epoch=92
05/30/2022 10:04:05 - INFO - __main__ - Global step 1300 Train loss 0.18 Classification-F1 0.5620869090378655 on epoch=92
05/30/2022 10:04:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.17 on epoch=93
05/30/2022 10:04:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=94
05/30/2022 10:04:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=94
05/30/2022 10:04:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=95
05/30/2022 10:04:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.17 on epoch=96
05/30/2022 10:04:24 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.5470049202339416 on epoch=96
05/30/2022 10:04:26 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.19 on epoch=97
05/30/2022 10:04:29 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=97
05/30/2022 10:04:31 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.17 on epoch=98
05/30/2022 10:04:34 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=99
05/30/2022 10:04:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.18 on epoch=99
05/30/2022 10:04:42 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.609832121185798 on epoch=99
05/30/2022 10:04:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=100
05/30/2022 10:04:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=101
05/30/2022 10:04:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=102
05/30/2022 10:04:52 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=102
05/30/2022 10:04:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.14 on epoch=103
05/30/2022 10:05:00 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.49067224512895147 on epoch=103
05/30/2022 10:05:03 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.20 on epoch=104
05/30/2022 10:05:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.14 on epoch=104
05/30/2022 10:05:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.16 on epoch=105
05/30/2022 10:05:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=106
05/30/2022 10:05:13 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=107
05/30/2022 10:05:19 - INFO - __main__ - Global step 1500 Train loss 0.15 Classification-F1 0.5278557128968752 on epoch=107
05/30/2022 10:05:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=107
05/30/2022 10:05:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=108
05/30/2022 10:05:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=109
05/30/2022 10:05:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=109
05/30/2022 10:05:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=110
05/30/2022 10:05:37 - INFO - __main__ - Global step 1550 Train loss 0.11 Classification-F1 0.5414378589493796 on epoch=110
05/30/2022 10:05:39 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=111
05/30/2022 10:05:42 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.12 on epoch=112
05/30/2022 10:05:44 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=112
05/30/2022 10:05:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=113
05/30/2022 10:05:49 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.20 on epoch=114
05/30/2022 10:05:55 - INFO - __main__ - Global step 1600 Train loss 0.13 Classification-F1 0.5549092603390597 on epoch=114
05/30/2022 10:05:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=114
05/30/2022 10:06:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=115
05/30/2022 10:06:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=116
05/30/2022 10:06:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=117
05/30/2022 10:06:07 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.13 on epoch=117
05/30/2022 10:06:13 - INFO - __main__ - Global step 1650 Train loss 0.11 Classification-F1 0.5331484698979683 on epoch=117
05/30/2022 10:06:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=118
05/30/2022 10:06:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=119
05/30/2022 10:06:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=119
05/30/2022 10:06:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
05/30/2022 10:06:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
05/30/2022 10:06:31 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.5960636881829956 on epoch=121
05/30/2022 10:06:33 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
05/30/2022 10:06:36 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=122
05/30/2022 10:06:38 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=123
05/30/2022 10:06:41 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
05/30/2022 10:06:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=124
05/30/2022 10:06:49 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.5140172348856175 on epoch=124
05/30/2022 10:06:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=125
05/30/2022 10:06:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.16 on epoch=126
05/30/2022 10:06:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.19 on epoch=127
05/30/2022 10:06:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
05/30/2022 10:07:01 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=128
05/30/2022 10:07:07 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.6555126819982506 on epoch=128
05/30/2022 10:07:09 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
05/30/2022 10:07:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.12 on epoch=129
05/30/2022 10:07:14 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
05/30/2022 10:07:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
05/30/2022 10:07:19 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=132
05/30/2022 10:07:25 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.8150733646953405 on epoch=132
05/30/2022 10:07:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7043267111341116 -> 0.8150733646953405 on epoch=132, global_step=1850
05/30/2022 10:07:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=132
05/30/2022 10:07:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=133
05/30/2022 10:07:33 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=134
05/30/2022 10:07:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
05/30/2022 10:07:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=135
05/30/2022 10:07:43 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.7856050519224423 on epoch=135
05/30/2022 10:07:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
05/30/2022 10:07:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.13 on epoch=137
05/30/2022 10:07:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
05/30/2022 10:07:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=138
05/30/2022 10:07:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=139
05/30/2022 10:08:02 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.7282315862154571 on epoch=139
05/30/2022 10:08:04 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
05/30/2022 10:08:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
05/30/2022 10:08:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=141
05/30/2022 10:08:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
05/30/2022 10:08:14 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
05/30/2022 10:08:20 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6805751678929479 on epoch=142
05/30/2022 10:08:22 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
05/30/2022 10:08:25 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=144
05/30/2022 10:08:27 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=144
05/30/2022 10:08:30 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
05/30/2022 10:08:32 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=146
05/30/2022 10:08:38 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.8234079896719757 on epoch=146
05/30/2022 10:08:38 - INFO - __main__ - Saving model with best Classification-F1: 0.8150733646953405 -> 0.8234079896719757 on epoch=146, global_step=2050
05/30/2022 10:08:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=147
05/30/2022 10:08:43 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
05/30/2022 10:08:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=148
05/30/2022 10:08:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
05/30/2022 10:08:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=149
05/30/2022 10:08:56 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.6840542451323436 on epoch=149
05/30/2022 10:08:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=150
05/30/2022 10:09:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=151
05/30/2022 10:09:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=152
05/30/2022 10:09:05 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.11 on epoch=152
05/30/2022 10:09:08 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
05/30/2022 10:09:14 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.6822851667291396 on epoch=153
05/30/2022 10:09:16 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=154
05/30/2022 10:09:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=154
05/30/2022 10:09:21 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
05/30/2022 10:09:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=156
05/30/2022 10:09:26 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=157
05/30/2022 10:09:32 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.8400305084766067 on epoch=157
05/30/2022 10:09:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8234079896719757 -> 0.8400305084766067 on epoch=157, global_step=2200
05/30/2022 10:09:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
05/30/2022 10:09:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
05/30/2022 10:09:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
05/30/2022 10:09:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=159
05/30/2022 10:09:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
05/30/2022 10:09:50 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.8255042935323926 on epoch=160
05/30/2022 10:09:53 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=161
05/30/2022 10:09:56 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
05/30/2022 10:09:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=162
05/30/2022 10:10:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=163
05/30/2022 10:10:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=164
05/30/2022 10:10:09 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.69163318410801 on epoch=164
05/30/2022 10:10:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=164
05/30/2022 10:10:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
05/30/2022 10:10:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
05/30/2022 10:10:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
05/30/2022 10:10:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.10 on epoch=167
05/30/2022 10:10:27 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.7821106721584377 on epoch=167
05/30/2022 10:10:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=168
05/30/2022 10:10:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
05/30/2022 10:10:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
05/30/2022 10:10:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=170
05/30/2022 10:10:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.09 on epoch=171
05/30/2022 10:10:45 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.782634714227247 on epoch=171
05/30/2022 10:10:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.12 on epoch=172
05/30/2022 10:10:50 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
05/30/2022 10:10:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=173
05/30/2022 10:10:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=174
05/30/2022 10:10:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=174
05/30/2022 10:11:03 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.7695510432060751 on epoch=174
05/30/2022 10:11:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
05/30/2022 10:11:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=176
05/30/2022 10:11:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=177
05/30/2022 10:11:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
05/30/2022 10:11:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=178
05/30/2022 10:11:21 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.8399633212889261 on epoch=178
05/30/2022 10:11:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=179
05/30/2022 10:11:26 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.08 on epoch=179
05/30/2022 10:11:28 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=180
05/30/2022 10:11:31 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
05/30/2022 10:11:33 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=182
05/30/2022 10:11:39 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.7778146695590048 on epoch=182
05/30/2022 10:11:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=182
05/30/2022 10:11:44 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
05/30/2022 10:11:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
05/30/2022 10:11:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
05/30/2022 10:11:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
05/30/2022 10:11:57 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.7680149341465741 on epoch=185
05/30/2022 10:11:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
05/30/2022 10:12:02 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
05/30/2022 10:12:04 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
05/30/2022 10:12:07 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=188
05/30/2022 10:12:09 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=189
05/30/2022 10:12:15 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7858616501629114 on epoch=189
05/30/2022 10:12:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
05/30/2022 10:12:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
05/30/2022 10:12:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=191
05/30/2022 10:12:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=192
05/30/2022 10:12:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=192
05/30/2022 10:12:33 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7868135406655331 on epoch=192
05/30/2022 10:12:35 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
05/30/2022 10:12:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.10 on epoch=194
05/30/2022 10:12:40 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.11 on epoch=194
05/30/2022 10:12:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
05/30/2022 10:12:45 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=196
05/30/2022 10:12:51 - INFO - __main__ - Global step 2750 Train loss 0.07 Classification-F1 0.8973182925713513 on epoch=196
05/30/2022 10:12:51 - INFO - __main__ - Saving model with best Classification-F1: 0.8400305084766067 -> 0.8973182925713513 on epoch=196, global_step=2750
05/30/2022 10:12:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
05/30/2022 10:12:56 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=197
05/30/2022 10:12:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=198
05/30/2022 10:13:01 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
05/30/2022 10:13:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
05/30/2022 10:13:09 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.819338644787891 on epoch=199
05/30/2022 10:13:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
05/30/2022 10:13:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
05/30/2022 10:13:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=202
05/30/2022 10:13:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
05/30/2022 10:13:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
05/30/2022 10:13:27 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7817738986703637 on epoch=203
05/30/2022 10:13:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
05/30/2022 10:13:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=204
05/30/2022 10:13:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
05/30/2022 10:13:37 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
05/30/2022 10:13:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
05/30/2022 10:13:45 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7824577880541158 on epoch=207
05/30/2022 10:13:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
05/30/2022 10:13:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/30/2022 10:13:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/30/2022 10:13:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
05/30/2022 10:13:57 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
05/30/2022 10:14:03 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7680900032848276 on epoch=210
05/30/2022 10:14:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
05/30/2022 10:14:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
05/30/2022 10:14:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
05/30/2022 10:14:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.09 on epoch=213
05/30/2022 10:14:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=214
05/30/2022 10:14:17 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 10:14:17 - INFO - __main__ - Printing 3 examples
05/30/2022 10:14:17 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/30/2022 10:14:17 - INFO - __main__ - ['Animal']
05/30/2022 10:14:17 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/30/2022 10:14:17 - INFO - __main__ - ['Animal']
05/30/2022 10:14:17 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/30/2022 10:14:17 - INFO - __main__ - ['Animal']
05/30/2022 10:14:17 - INFO - __main__ - Tokenizing Input ...
05/30/2022 10:14:17 - INFO - __main__ - Tokenizing Output ...
05/30/2022 10:14:17 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 10:14:17 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 10:14:17 - INFO - __main__ - Printing 3 examples
05/30/2022 10:14:17 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/30/2022 10:14:17 - INFO - __main__ - ['Animal']
05/30/2022 10:14:17 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/30/2022 10:14:17 - INFO - __main__ - ['Animal']
05/30/2022 10:14:17 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/30/2022 10:14:17 - INFO - __main__ - ['Animal']
05/30/2022 10:14:17 - INFO - __main__ - Tokenizing Input ...
05/30/2022 10:14:17 - INFO - __main__ - Tokenizing Output ...
05/30/2022 10:14:17 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 10:14:21 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7714468768757752 on epoch=214
05/30/2022 10:14:21 - INFO - __main__ - save last model!
05/30/2022 10:14:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 10:14:21 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 10:14:21 - INFO - __main__ - Printing 3 examples
05/30/2022 10:14:21 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 10:14:21 - INFO - __main__ - ['Animal']
05/30/2022 10:14:21 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 10:14:21 - INFO - __main__ - ['Animal']
05/30/2022 10:14:21 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 10:14:21 - INFO - __main__ - ['Village']
05/30/2022 10:14:21 - INFO - __main__ - Tokenizing Input ...
05/30/2022 10:14:23 - INFO - __main__ - Tokenizing Output ...
05/30/2022 10:14:26 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 10:14:32 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 10:14:32 - INFO - __main__ - task name: dbpedia_14
05/30/2022 10:14:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 10:14:32 - INFO - __main__ - Starting training!
05/30/2022 10:16:26 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
05/30/2022 10:16:26 - INFO - __main__ - Classification-F1 on test data: 0.6724
05/30/2022 10:16:26 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.8973182925713513, test_performance=0.6723717480291225
05/30/2022 10:16:26 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
05/30/2022 10:16:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 10:16:27 - INFO - __main__ - Printing 3 examples
05/30/2022 10:16:27 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/30/2022 10:16:27 - INFO - __main__ - ['Animal']
05/30/2022 10:16:27 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/30/2022 10:16:27 - INFO - __main__ - ['Animal']
05/30/2022 10:16:27 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/30/2022 10:16:27 - INFO - __main__ - ['Animal']
05/30/2022 10:16:27 - INFO - __main__ - Tokenizing Input ...
05/30/2022 10:16:27 - INFO - __main__ - Tokenizing Output ...
05/30/2022 10:16:27 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 10:16:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 10:16:27 - INFO - __main__ - Printing 3 examples
05/30/2022 10:16:27 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/30/2022 10:16:27 - INFO - __main__ - ['Animal']
05/30/2022 10:16:27 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/30/2022 10:16:27 - INFO - __main__ - ['Animal']
05/30/2022 10:16:27 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/30/2022 10:16:27 - INFO - __main__ - ['Animal']
05/30/2022 10:16:27 - INFO - __main__ - Tokenizing Input ...
05/30/2022 10:16:27 - INFO - __main__ - Tokenizing Output ...
05/30/2022 10:16:27 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 10:16:43 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 10:16:43 - INFO - __main__ - task name: dbpedia_14
05/30/2022 10:16:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 10:16:44 - INFO - __main__ - Starting training!
05/30/2022 10:16:47 - INFO - __main__ - Step 10 Global step 10 Train loss 7.16 on epoch=0
05/30/2022 10:16:50 - INFO - __main__ - Step 20 Global step 20 Train loss 7.04 on epoch=1
05/30/2022 10:16:52 - INFO - __main__ - Step 30 Global step 30 Train loss 6.44 on epoch=2
05/30/2022 10:16:55 - INFO - __main__ - Step 40 Global step 40 Train loss 6.08 on epoch=2
05/30/2022 10:16:58 - INFO - __main__ - Step 50 Global step 50 Train loss 5.58 on epoch=3
05/30/2022 10:18:41 - INFO - __main__ - Global step 50 Train loss 6.46 Classification-F1 0.0 on epoch=3
05/30/2022 10:18:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/30/2022 10:18:44 - INFO - __main__ - Step 60 Global step 60 Train loss 5.26 on epoch=4
05/30/2022 10:18:46 - INFO - __main__ - Step 70 Global step 70 Train loss 4.75 on epoch=4
05/30/2022 10:18:49 - INFO - __main__ - Step 80 Global step 80 Train loss 3.96 on epoch=5
05/30/2022 10:18:51 - INFO - __main__ - Step 90 Global step 90 Train loss 3.61 on epoch=6
05/30/2022 10:18:54 - INFO - __main__ - Step 100 Global step 100 Train loss 3.15 on epoch=7
05/30/2022 10:20:11 - INFO - __main__ - Global step 100 Train loss 4.15 Classification-F1 0.008734218325011164 on epoch=7
05/30/2022 10:20:11 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.008734218325011164 on epoch=7, global_step=100
05/30/2022 10:20:14 - INFO - __main__ - Step 110 Global step 110 Train loss 2.84 on epoch=7
05/30/2022 10:20:16 - INFO - __main__ - Step 120 Global step 120 Train loss 2.54 on epoch=8
05/30/2022 10:20:19 - INFO - __main__ - Step 130 Global step 130 Train loss 2.48 on epoch=9
05/30/2022 10:20:21 - INFO - __main__ - Step 140 Global step 140 Train loss 2.22 on epoch=9
05/30/2022 10:20:24 - INFO - __main__ - Step 150 Global step 150 Train loss 2.00 on epoch=10
05/30/2022 10:20:57 - INFO - __main__ - Global step 150 Train loss 2.42 Classification-F1 0.07097671664859888 on epoch=10
05/30/2022 10:20:57 - INFO - __main__ - Saving model with best Classification-F1: 0.008734218325011164 -> 0.07097671664859888 on epoch=10, global_step=150
05/30/2022 10:21:00 - INFO - __main__ - Step 160 Global step 160 Train loss 1.98 on epoch=11
05/30/2022 10:21:02 - INFO - __main__ - Step 170 Global step 170 Train loss 1.84 on epoch=12
05/30/2022 10:21:05 - INFO - __main__ - Step 180 Global step 180 Train loss 1.81 on epoch=12
05/30/2022 10:21:07 - INFO - __main__ - Step 190 Global step 190 Train loss 1.67 on epoch=13
05/30/2022 10:21:10 - INFO - __main__ - Step 200 Global step 200 Train loss 1.73 on epoch=14
05/30/2022 10:21:22 - INFO - __main__ - Global step 200 Train loss 1.81 Classification-F1 0.21165396236327627 on epoch=14
05/30/2022 10:21:22 - INFO - __main__ - Saving model with best Classification-F1: 0.07097671664859888 -> 0.21165396236327627 on epoch=14, global_step=200
05/30/2022 10:21:24 - INFO - __main__ - Step 210 Global step 210 Train loss 1.53 on epoch=14
05/30/2022 10:21:27 - INFO - __main__ - Step 220 Global step 220 Train loss 1.51 on epoch=15
05/30/2022 10:21:29 - INFO - __main__ - Step 230 Global step 230 Train loss 1.39 on epoch=16
05/30/2022 10:21:32 - INFO - __main__ - Step 240 Global step 240 Train loss 1.41 on epoch=17
05/30/2022 10:21:34 - INFO - __main__ - Step 250 Global step 250 Train loss 1.36 on epoch=17
05/30/2022 10:21:50 - INFO - __main__ - Global step 250 Train loss 1.44 Classification-F1 0.30878338650771814 on epoch=17
05/30/2022 10:21:50 - INFO - __main__ - Saving model with best Classification-F1: 0.21165396236327627 -> 0.30878338650771814 on epoch=17, global_step=250
05/30/2022 10:21:53 - INFO - __main__ - Step 260 Global step 260 Train loss 1.20 on epoch=18
05/30/2022 10:21:55 - INFO - __main__ - Step 270 Global step 270 Train loss 1.25 on epoch=19
05/30/2022 10:21:58 - INFO - __main__ - Step 280 Global step 280 Train loss 1.21 on epoch=19
05/30/2022 10:22:00 - INFO - __main__ - Step 290 Global step 290 Train loss 1.13 on epoch=20
05/30/2022 10:22:03 - INFO - __main__ - Step 300 Global step 300 Train loss 1.12 on epoch=21
05/30/2022 10:22:13 - INFO - __main__ - Global step 300 Train loss 1.18 Classification-F1 0.30743713774921 on epoch=21
05/30/2022 10:22:15 - INFO - __main__ - Step 310 Global step 310 Train loss 1.11 on epoch=22
05/30/2022 10:22:18 - INFO - __main__ - Step 320 Global step 320 Train loss 1.05 on epoch=22
05/30/2022 10:22:20 - INFO - __main__ - Step 330 Global step 330 Train loss 1.02 on epoch=23
05/30/2022 10:22:23 - INFO - __main__ - Step 340 Global step 340 Train loss 1.15 on epoch=24
05/30/2022 10:22:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.93 on epoch=24
05/30/2022 10:22:36 - INFO - __main__ - Global step 350 Train loss 1.05 Classification-F1 0.335392412773817 on epoch=24
05/30/2022 10:22:36 - INFO - __main__ - Saving model with best Classification-F1: 0.30878338650771814 -> 0.335392412773817 on epoch=24, global_step=350
05/30/2022 10:22:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.96 on epoch=25
05/30/2022 10:22:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.91 on epoch=26
05/30/2022 10:22:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.86 on epoch=27
05/30/2022 10:22:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.99 on epoch=27
05/30/2022 10:22:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.85 on epoch=28
05/30/2022 10:22:58 - INFO - __main__ - Global step 400 Train loss 0.91 Classification-F1 0.4371019062828285 on epoch=28
05/30/2022 10:22:58 - INFO - __main__ - Saving model with best Classification-F1: 0.335392412773817 -> 0.4371019062828285 on epoch=28, global_step=400
05/30/2022 10:23:01 - INFO - __main__ - Step 410 Global step 410 Train loss 1.01 on epoch=29
05/30/2022 10:23:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.84 on epoch=29
05/30/2022 10:23:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.83 on epoch=30
05/30/2022 10:23:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.80 on epoch=31
05/30/2022 10:23:11 - INFO - __main__ - Step 450 Global step 450 Train loss 0.75 on epoch=32
05/30/2022 10:23:20 - INFO - __main__ - Global step 450 Train loss 0.85 Classification-F1 0.4312771299520087 on epoch=32
05/30/2022 10:23:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.77 on epoch=32
05/30/2022 10:23:25 - INFO - __main__ - Step 470 Global step 470 Train loss 0.79 on epoch=33
05/30/2022 10:23:27 - INFO - __main__ - Step 480 Global step 480 Train loss 0.81 on epoch=34
05/30/2022 10:23:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.70 on epoch=34
05/30/2022 10:23:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.68 on epoch=35
05/30/2022 10:23:40 - INFO - __main__ - Global step 500 Train loss 0.75 Classification-F1 0.5271463620914691 on epoch=35
05/30/2022 10:23:40 - INFO - __main__ - Saving model with best Classification-F1: 0.4371019062828285 -> 0.5271463620914691 on epoch=35, global_step=500
05/30/2022 10:23:43 - INFO - __main__ - Step 510 Global step 510 Train loss 0.71 on epoch=36
05/30/2022 10:23:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.69 on epoch=37
05/30/2022 10:23:48 - INFO - __main__ - Step 530 Global step 530 Train loss 0.74 on epoch=37
05/30/2022 10:23:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.60 on epoch=38
05/30/2022 10:23:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.66 on epoch=39
05/30/2022 10:24:00 - INFO - __main__ - Global step 550 Train loss 0.68 Classification-F1 0.5662553552493763 on epoch=39
05/30/2022 10:24:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5271463620914691 -> 0.5662553552493763 on epoch=39, global_step=550
05/30/2022 10:24:02 - INFO - __main__ - Step 560 Global step 560 Train loss 0.60 on epoch=39
05/30/2022 10:24:05 - INFO - __main__ - Step 570 Global step 570 Train loss 0.56 on epoch=40
05/30/2022 10:24:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.66 on epoch=41
05/30/2022 10:24:10 - INFO - __main__ - Step 590 Global step 590 Train loss 0.72 on epoch=42
05/30/2022 10:24:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.58 on epoch=42
05/30/2022 10:24:21 - INFO - __main__ - Global step 600 Train loss 0.62 Classification-F1 0.6123511054812995 on epoch=42
05/30/2022 10:24:21 - INFO - __main__ - Saving model with best Classification-F1: 0.5662553552493763 -> 0.6123511054812995 on epoch=42, global_step=600
05/30/2022 10:24:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.61 on epoch=43
05/30/2022 10:24:26 - INFO - __main__ - Step 620 Global step 620 Train loss 0.64 on epoch=44
05/30/2022 10:24:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.60 on epoch=44
05/30/2022 10:24:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.66 on epoch=45
05/30/2022 10:24:33 - INFO - __main__ - Step 650 Global step 650 Train loss 0.48 on epoch=46
05/30/2022 10:24:41 - INFO - __main__ - Global step 650 Train loss 0.60 Classification-F1 0.6085411659150711 on epoch=46
05/30/2022 10:24:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.59 on epoch=47
05/30/2022 10:24:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.50 on epoch=47
05/30/2022 10:24:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.51 on epoch=48
05/30/2022 10:24:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.52 on epoch=49
05/30/2022 10:24:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.54 on epoch=49
05/30/2022 10:25:01 - INFO - __main__ - Global step 700 Train loss 0.53 Classification-F1 0.6962043438324274 on epoch=49
05/30/2022 10:25:01 - INFO - __main__ - Saving model with best Classification-F1: 0.6123511054812995 -> 0.6962043438324274 on epoch=49, global_step=700
05/30/2022 10:25:04 - INFO - __main__ - Step 710 Global step 710 Train loss 0.51 on epoch=50
05/30/2022 10:25:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.46 on epoch=51
05/30/2022 10:25:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.57 on epoch=52
05/30/2022 10:25:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.44 on epoch=52
05/30/2022 10:25:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.41 on epoch=53
05/30/2022 10:25:22 - INFO - __main__ - Global step 750 Train loss 0.48 Classification-F1 0.6593463554468669 on epoch=53
05/30/2022 10:25:25 - INFO - __main__ - Step 760 Global step 760 Train loss 0.49 on epoch=54
05/30/2022 10:25:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.41 on epoch=54
05/30/2022 10:25:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.56 on epoch=55
05/30/2022 10:25:32 - INFO - __main__ - Step 790 Global step 790 Train loss 0.45 on epoch=56
05/30/2022 10:25:34 - INFO - __main__ - Step 800 Global step 800 Train loss 0.48 on epoch=57
05/30/2022 10:25:42 - INFO - __main__ - Global step 800 Train loss 0.48 Classification-F1 0.6861701522255302 on epoch=57
05/30/2022 10:25:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.44 on epoch=57
05/30/2022 10:25:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.41 on epoch=58
05/30/2022 10:25:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.54 on epoch=59
05/30/2022 10:25:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.37 on epoch=59
05/30/2022 10:25:55 - INFO - __main__ - Step 850 Global step 850 Train loss 0.47 on epoch=60
05/30/2022 10:26:03 - INFO - __main__ - Global step 850 Train loss 0.45 Classification-F1 0.7431403554464164 on epoch=60
05/30/2022 10:26:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6962043438324274 -> 0.7431403554464164 on epoch=60, global_step=850
05/30/2022 10:26:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.37 on epoch=61
05/30/2022 10:26:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.47 on epoch=62
05/30/2022 10:26:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.34 on epoch=62
05/30/2022 10:26:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.42 on epoch=63
05/30/2022 10:26:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.35 on epoch=64
05/30/2022 10:26:21 - INFO - __main__ - Global step 900 Train loss 0.39 Classification-F1 0.611863793005522 on epoch=64
05/30/2022 10:26:24 - INFO - __main__ - Step 910 Global step 910 Train loss 0.31 on epoch=64
05/30/2022 10:26:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.46 on epoch=65
05/30/2022 10:26:29 - INFO - __main__ - Step 930 Global step 930 Train loss 0.37 on epoch=66
05/30/2022 10:26:31 - INFO - __main__ - Step 940 Global step 940 Train loss 0.41 on epoch=67
05/30/2022 10:26:34 - INFO - __main__ - Step 950 Global step 950 Train loss 0.38 on epoch=67
05/30/2022 10:26:41 - INFO - __main__ - Global step 950 Train loss 0.39 Classification-F1 0.6923503620637788 on epoch=67
05/30/2022 10:26:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.32 on epoch=68
05/30/2022 10:26:46 - INFO - __main__ - Step 970 Global step 970 Train loss 0.33 on epoch=69
05/30/2022 10:26:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.40 on epoch=69
05/30/2022 10:26:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.30 on epoch=70
05/30/2022 10:26:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.34 on epoch=71
05/30/2022 10:27:01 - INFO - __main__ - Global step 1000 Train loss 0.34 Classification-F1 0.8015366861334603 on epoch=71
05/30/2022 10:27:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7431403554464164 -> 0.8015366861334603 on epoch=71, global_step=1000
05/30/2022 10:27:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.35 on epoch=72
05/30/2022 10:27:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.24 on epoch=72
05/30/2022 10:27:09 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.25 on epoch=73
05/30/2022 10:27:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.35 on epoch=74
05/30/2022 10:27:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.37 on epoch=74
05/30/2022 10:27:21 - INFO - __main__ - Global step 1050 Train loss 0.31 Classification-F1 0.7957408242892114 on epoch=74
05/30/2022 10:27:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.30 on epoch=75
05/30/2022 10:27:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.28 on epoch=76
05/30/2022 10:27:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.34 on epoch=77
05/30/2022 10:27:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=77
05/30/2022 10:27:33 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.31 on epoch=78
05/30/2022 10:27:40 - INFO - __main__ - Global step 1100 Train loss 0.30 Classification-F1 0.8163004057928158 on epoch=78
05/30/2022 10:27:40 - INFO - __main__ - Saving model with best Classification-F1: 0.8015366861334603 -> 0.8163004057928158 on epoch=78, global_step=1100
05/30/2022 10:27:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.33 on epoch=79
05/30/2022 10:27:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.29 on epoch=79
05/30/2022 10:27:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.25 on epoch=80
05/30/2022 10:27:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.28 on epoch=81
05/30/2022 10:27:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.30 on epoch=82
05/30/2022 10:28:01 - INFO - __main__ - Global step 1150 Train loss 0.29 Classification-F1 0.7568493067470179 on epoch=82
05/30/2022 10:28:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.35 on epoch=82
05/30/2022 10:28:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.27 on epoch=83
05/30/2022 10:28:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.28 on epoch=84
05/30/2022 10:28:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.22 on epoch=84
05/30/2022 10:28:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.28 on epoch=85
05/30/2022 10:28:19 - INFO - __main__ - Global step 1200 Train loss 0.28 Classification-F1 0.7000110942997689 on epoch=85
05/30/2022 10:28:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.27 on epoch=86
05/30/2022 10:28:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.20 on epoch=87
05/30/2022 10:28:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.22 on epoch=87
05/30/2022 10:28:29 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.24 on epoch=88
05/30/2022 10:28:32 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.19 on epoch=89
05/30/2022 10:28:38 - INFO - __main__ - Global step 1250 Train loss 0.22 Classification-F1 0.7107222513372459 on epoch=89
05/30/2022 10:28:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.22 on epoch=89
05/30/2022 10:28:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.26 on epoch=90
05/30/2022 10:28:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=91
05/30/2022 10:28:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.28 on epoch=92
05/30/2022 10:28:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.22 on epoch=92
05/30/2022 10:28:57 - INFO - __main__ - Global step 1300 Train loss 0.24 Classification-F1 0.7506400207748015 on epoch=92
05/30/2022 10:28:59 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.23 on epoch=93
05/30/2022 10:29:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.27 on epoch=94
05/30/2022 10:29:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.29 on epoch=94
05/30/2022 10:29:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.25 on epoch=95
05/30/2022 10:29:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.20 on epoch=96
05/30/2022 10:29:15 - INFO - __main__ - Global step 1350 Train loss 0.25 Classification-F1 0.7989128449422696 on epoch=96
05/30/2022 10:29:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.26 on epoch=97
05/30/2022 10:29:20 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.22 on epoch=97
05/30/2022 10:29:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.24 on epoch=98
05/30/2022 10:29:25 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.23 on epoch=99
05/30/2022 10:29:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.21 on epoch=99
05/30/2022 10:29:35 - INFO - __main__ - Global step 1400 Train loss 0.23 Classification-F1 0.6999062666568185 on epoch=99
05/30/2022 10:29:37 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.24 on epoch=100
05/30/2022 10:29:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=101
05/30/2022 10:29:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.29 on epoch=102
05/30/2022 10:29:45 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.20 on epoch=102
05/30/2022 10:29:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.21 on epoch=103
05/30/2022 10:29:53 - INFO - __main__ - Global step 1450 Train loss 0.21 Classification-F1 0.7531307160270262 on epoch=103
05/30/2022 10:29:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.16 on epoch=104
05/30/2022 10:29:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.25 on epoch=104
05/30/2022 10:30:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.23 on epoch=105
05/30/2022 10:30:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.18 on epoch=106
05/30/2022 10:30:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.21 on epoch=107
05/30/2022 10:30:12 - INFO - __main__ - Global step 1500 Train loss 0.20 Classification-F1 0.8207793194762989 on epoch=107
05/30/2022 10:30:12 - INFO - __main__ - Saving model with best Classification-F1: 0.8163004057928158 -> 0.8207793194762989 on epoch=107, global_step=1500
05/30/2022 10:30:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.17 on epoch=107
05/30/2022 10:30:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.18 on epoch=108
05/30/2022 10:30:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=109
05/30/2022 10:30:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.18 on epoch=109
05/30/2022 10:30:24 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.19 on epoch=110
05/30/2022 10:30:31 - INFO - __main__ - Global step 1550 Train loss 0.18 Classification-F1 0.7035899463899429 on epoch=110
05/30/2022 10:30:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.14 on epoch=111
05/30/2022 10:30:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.19 on epoch=112
05/30/2022 10:30:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.15 on epoch=112
05/30/2022 10:30:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.16 on epoch=113
05/30/2022 10:30:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.21 on epoch=114
05/30/2022 10:30:50 - INFO - __main__ - Global step 1600 Train loss 0.17 Classification-F1 0.7900242794381707 on epoch=114
05/30/2022 10:30:52 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.23 on epoch=114
05/30/2022 10:30:55 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.16 on epoch=115
05/30/2022 10:30:57 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.19 on epoch=116
05/30/2022 10:30:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.15 on epoch=117
05/30/2022 10:31:02 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.16 on epoch=117
05/30/2022 10:31:08 - INFO - __main__ - Global step 1650 Train loss 0.18 Classification-F1 0.78905549414622 on epoch=117
05/30/2022 10:31:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.15 on epoch=118
05/30/2022 10:31:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=119
05/30/2022 10:31:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=119
05/30/2022 10:31:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=120
05/30/2022 10:31:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.20 on epoch=121
05/30/2022 10:31:26 - INFO - __main__ - Global step 1700 Train loss 0.15 Classification-F1 0.8224804689104381 on epoch=121
05/30/2022 10:31:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8207793194762989 -> 0.8224804689104381 on epoch=121, global_step=1700
05/30/2022 10:31:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.16 on epoch=122
05/30/2022 10:31:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.14 on epoch=122
05/30/2022 10:31:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.14 on epoch=123
05/30/2022 10:31:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=124
05/30/2022 10:31:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=124
05/30/2022 10:31:45 - INFO - __main__ - Global step 1750 Train loss 0.13 Classification-F1 0.8131255673090351 on epoch=124
05/30/2022 10:31:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.12 on epoch=125
05/30/2022 10:31:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.12 on epoch=126
05/30/2022 10:31:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=127
05/30/2022 10:31:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.18 on epoch=127
05/30/2022 10:31:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=128
05/30/2022 10:32:03 - INFO - __main__ - Global step 1800 Train loss 0.12 Classification-F1 0.820276514248636 on epoch=128
05/30/2022 10:32:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.18 on epoch=129
05/30/2022 10:32:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=129
05/30/2022 10:32:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.14 on epoch=130
05/30/2022 10:32:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=131
05/30/2022 10:32:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.11 on epoch=132
05/30/2022 10:32:21 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.8836868633627015 on epoch=132
05/30/2022 10:32:21 - INFO - __main__ - Saving model with best Classification-F1: 0.8224804689104381 -> 0.8836868633627015 on epoch=132, global_step=1850
05/30/2022 10:32:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.14 on epoch=132
05/30/2022 10:32:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.13 on epoch=133
05/30/2022 10:32:28 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=134
05/30/2022 10:32:30 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.13 on epoch=134
05/30/2022 10:32:33 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=135
05/30/2022 10:32:38 - INFO - __main__ - Global step 1900 Train loss 0.13 Classification-F1 0.8802497644670323 on epoch=135
05/30/2022 10:32:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.13 on epoch=136
05/30/2022 10:32:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.13 on epoch=137
05/30/2022 10:32:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=137
05/30/2022 10:32:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.12 on epoch=138
05/30/2022 10:32:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.12 on epoch=139
05/30/2022 10:32:56 - INFO - __main__ - Global step 1950 Train loss 0.12 Classification-F1 0.8279490199672244 on epoch=139
05/30/2022 10:32:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.12 on epoch=139
05/30/2022 10:33:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=140
05/30/2022 10:33:04 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=141
05/30/2022 10:33:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=142
05/30/2022 10:33:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=142
05/30/2022 10:33:15 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.8675876890345582 on epoch=142
05/30/2022 10:33:17 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=143
05/30/2022 10:33:20 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=144
05/30/2022 10:33:22 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.10 on epoch=144
05/30/2022 10:33:25 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=145
05/30/2022 10:33:27 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=146
05/30/2022 10:33:33 - INFO - __main__ - Global step 2050 Train loss 0.10 Classification-F1 0.8859818117424609 on epoch=146
05/30/2022 10:33:33 - INFO - __main__ - Saving model with best Classification-F1: 0.8836868633627015 -> 0.8859818117424609 on epoch=146, global_step=2050
05/30/2022 10:33:36 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.14 on epoch=147
05/30/2022 10:33:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=147
05/30/2022 10:33:40 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.10 on epoch=148
05/30/2022 10:33:43 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.10 on epoch=149
05/30/2022 10:33:45 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=149
05/30/2022 10:33:53 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.8847622356208693 on epoch=149
05/30/2022 10:33:55 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.12 on epoch=150
05/30/2022 10:33:57 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.16 on epoch=151
05/30/2022 10:34:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=152
05/30/2022 10:34:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=152
05/30/2022 10:34:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=153
05/30/2022 10:34:12 - INFO - __main__ - Global step 2150 Train loss 0.11 Classification-F1 0.8807758554596546 on epoch=153
05/30/2022 10:34:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.13 on epoch=154
05/30/2022 10:34:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=154
05/30/2022 10:34:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.12 on epoch=155
05/30/2022 10:34:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=156
05/30/2022 10:34:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=157
05/30/2022 10:34:30 - INFO - __main__ - Global step 2200 Train loss 0.10 Classification-F1 0.8736306819893158 on epoch=157
05/30/2022 10:34:33 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=157
05/30/2022 10:34:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.11 on epoch=158
05/30/2022 10:34:38 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.09 on epoch=159
05/30/2022 10:34:40 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=159
05/30/2022 10:34:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.10 on epoch=160
05/30/2022 10:34:49 - INFO - __main__ - Global step 2250 Train loss 0.09 Classification-F1 0.8697971028315747 on epoch=160
05/30/2022 10:34:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=161
05/30/2022 10:34:54 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.13 on epoch=162
05/30/2022 10:34:56 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=162
05/30/2022 10:34:59 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.13 on epoch=163
05/30/2022 10:35:01 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=164
05/30/2022 10:35:07 - INFO - __main__ - Global step 2300 Train loss 0.10 Classification-F1 0.8397399080599982 on epoch=164
05/30/2022 10:35:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.14 on epoch=164
05/30/2022 10:35:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.10 on epoch=165
05/30/2022 10:35:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=166
05/30/2022 10:35:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.10 on epoch=167
05/30/2022 10:35:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.10 on epoch=167
05/30/2022 10:35:26 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.8938820047406385 on epoch=167
05/30/2022 10:35:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8859818117424609 -> 0.8938820047406385 on epoch=167, global_step=2350
05/30/2022 10:35:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
05/30/2022 10:35:31 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=169
05/30/2022 10:35:33 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=169
05/30/2022 10:35:35 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=170
05/30/2022 10:35:38 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
05/30/2022 10:35:45 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.8200784196831066 on epoch=171
05/30/2022 10:35:47 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
05/30/2022 10:35:50 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=172
05/30/2022 10:35:52 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.11 on epoch=173
05/30/2022 10:35:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=174
05/30/2022 10:35:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=174
05/30/2022 10:36:04 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.8350772527258452 on epoch=174
05/30/2022 10:36:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.11 on epoch=175
05/30/2022 10:36:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=176
05/30/2022 10:36:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=177
05/30/2022 10:36:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=177
05/30/2022 10:36:16 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=178
05/30/2022 10:36:23 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.8876608583044382 on epoch=178
05/30/2022 10:36:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=179
05/30/2022 10:36:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=179
05/30/2022 10:36:30 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=180
05/30/2022 10:36:32 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
05/30/2022 10:36:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=182
05/30/2022 10:36:41 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.9512607706156094 on epoch=182
05/30/2022 10:36:42 - INFO - __main__ - Saving model with best Classification-F1: 0.8938820047406385 -> 0.9512607706156094 on epoch=182, global_step=2550
05/30/2022 10:36:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.11 on epoch=182
05/30/2022 10:36:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=183
05/30/2022 10:36:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=184
05/30/2022 10:36:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
05/30/2022 10:36:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
05/30/2022 10:37:00 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.891475468975469 on epoch=185
05/30/2022 10:37:03 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
05/30/2022 10:37:05 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.12 on epoch=187
05/30/2022 10:37:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
05/30/2022 10:37:10 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.10 on epoch=188
05/30/2022 10:37:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.07 on epoch=189
05/30/2022 10:37:19 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.8937693757855049 on epoch=189
05/30/2022 10:37:21 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=189
05/30/2022 10:37:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
05/30/2022 10:37:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
05/30/2022 10:37:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=192
05/30/2022 10:37:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
05/30/2022 10:37:37 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.8978731062317401 on epoch=192
05/30/2022 10:37:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=193
05/30/2022 10:37:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.08 on epoch=194
05/30/2022 10:37:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.10 on epoch=194
05/30/2022 10:37:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=195
05/30/2022 10:37:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=196
05/30/2022 10:37:55 - INFO - __main__ - Global step 2750 Train loss 0.08 Classification-F1 0.8978731062317401 on epoch=196
05/30/2022 10:37:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
05/30/2022 10:38:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=197
05/30/2022 10:38:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=198
05/30/2022 10:38:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=199
05/30/2022 10:38:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
05/30/2022 10:38:13 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.8805352980352981 on epoch=199
05/30/2022 10:38:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
05/30/2022 10:38:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
05/30/2022 10:38:21 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=202
05/30/2022 10:38:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.12 on epoch=202
05/30/2022 10:38:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=203
05/30/2022 10:38:32 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.8808338763983924 on epoch=203
05/30/2022 10:38:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=204
05/30/2022 10:38:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.11 on epoch=204
05/30/2022 10:38:39 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=205
05/30/2022 10:38:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=206
05/30/2022 10:38:44 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=207
05/30/2022 10:38:50 - INFO - __main__ - Global step 2900 Train loss 0.07 Classification-F1 0.8297570146093628 on epoch=207
05/30/2022 10:38:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=207
05/30/2022 10:38:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=208
05/30/2022 10:38:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.11 on epoch=209
05/30/2022 10:39:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
05/30/2022 10:39:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
05/30/2022 10:39:09 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.8301819630181821 on epoch=210
05/30/2022 10:39:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=211
05/30/2022 10:39:14 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=212
05/30/2022 10:39:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=212
05/30/2022 10:39:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
05/30/2022 10:39:21 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
05/30/2022 10:39:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 10:39:22 - INFO - __main__ - Printing 3 examples
05/30/2022 10:39:22 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/30/2022 10:39:22 - INFO - __main__ - ['Plant']
05/30/2022 10:39:22 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/30/2022 10:39:22 - INFO - __main__ - ['Plant']
05/30/2022 10:39:22 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/30/2022 10:39:22 - INFO - __main__ - ['Plant']
05/30/2022 10:39:22 - INFO - __main__ - Tokenizing Input ...
05/30/2022 10:39:22 - INFO - __main__ - Tokenizing Output ...
05/30/2022 10:39:23 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 10:39:23 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 10:39:23 - INFO - __main__ - Printing 3 examples
05/30/2022 10:39:23 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/30/2022 10:39:23 - INFO - __main__ - ['Plant']
05/30/2022 10:39:23 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/30/2022 10:39:23 - INFO - __main__ - ['Plant']
05/30/2022 10:39:23 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/30/2022 10:39:23 - INFO - __main__ - ['Plant']
05/30/2022 10:39:23 - INFO - __main__ - Tokenizing Input ...
05/30/2022 10:39:23 - INFO - __main__ - Tokenizing Output ...
05/30/2022 10:39:23 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 10:39:27 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.878989202599314 on epoch=214
05/30/2022 10:39:27 - INFO - __main__ - save last model!
05/30/2022 10:39:27 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 10:39:27 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 10:39:27 - INFO - __main__ - Printing 3 examples
05/30/2022 10:39:27 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 10:39:27 - INFO - __main__ - ['Animal']
05/30/2022 10:39:27 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 10:39:27 - INFO - __main__ - ['Animal']
05/30/2022 10:39:27 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 10:39:27 - INFO - __main__ - ['Village']
05/30/2022 10:39:27 - INFO - __main__ - Tokenizing Input ...
05/30/2022 10:39:29 - INFO - __main__ - Tokenizing Output ...
05/30/2022 10:39:32 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 10:39:37 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 10:39:37 - INFO - __main__ - task name: dbpedia_14
05/30/2022 10:39:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 10:39:38 - INFO - __main__ - Starting training!
05/30/2022 10:41:42 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
05/30/2022 10:41:42 - INFO - __main__ - Classification-F1 on test data: 0.6715
05/30/2022 10:41:42 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.9512607706156094, test_performance=0.6715016949769232
05/30/2022 10:41:42 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
05/30/2022 10:41:43 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 10:41:43 - INFO - __main__ - Printing 3 examples
05/30/2022 10:41:43 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/30/2022 10:41:43 - INFO - __main__ - ['Plant']
05/30/2022 10:41:43 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/30/2022 10:41:43 - INFO - __main__ - ['Plant']
05/30/2022 10:41:43 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/30/2022 10:41:43 - INFO - __main__ - ['Plant']
05/30/2022 10:41:43 - INFO - __main__ - Tokenizing Input ...
05/30/2022 10:41:43 - INFO - __main__ - Tokenizing Output ...
05/30/2022 10:41:43 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 10:41:43 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 10:41:43 - INFO - __main__ - Printing 3 examples
05/30/2022 10:41:43 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/30/2022 10:41:43 - INFO - __main__ - ['Plant']
05/30/2022 10:41:43 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/30/2022 10:41:43 - INFO - __main__ - ['Plant']
05/30/2022 10:41:43 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/30/2022 10:41:43 - INFO - __main__ - ['Plant']
05/30/2022 10:41:43 - INFO - __main__ - Tokenizing Input ...
05/30/2022 10:41:43 - INFO - __main__ - Tokenizing Output ...
05/30/2022 10:41:44 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 10:42:02 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 10:42:02 - INFO - __main__ - task name: dbpedia_14
05/30/2022 10:42:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 10:42:03 - INFO - __main__ - Starting training!
05/30/2022 10:42:06 - INFO - __main__ - Step 10 Global step 10 Train loss 7.14 on epoch=0
05/30/2022 10:42:08 - INFO - __main__ - Step 20 Global step 20 Train loss 5.39 on epoch=1
05/30/2022 10:42:11 - INFO - __main__ - Step 30 Global step 30 Train loss 3.89 on epoch=2
05/30/2022 10:42:13 - INFO - __main__ - Step 40 Global step 40 Train loss 3.04 on epoch=2
05/30/2022 10:42:16 - INFO - __main__ - Step 50 Global step 50 Train loss 2.49 on epoch=3
05/30/2022 10:42:24 - INFO - __main__ - Global step 50 Train loss 4.39 Classification-F1 0.142246320886558 on epoch=3
05/30/2022 10:42:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.142246320886558 on epoch=3, global_step=50
05/30/2022 10:42:27 - INFO - __main__ - Step 60 Global step 60 Train loss 2.16 on epoch=4
05/30/2022 10:42:29 - INFO - __main__ - Step 70 Global step 70 Train loss 1.91 on epoch=4
05/30/2022 10:42:32 - INFO - __main__ - Step 80 Global step 80 Train loss 1.74 on epoch=5
05/30/2022 10:42:34 - INFO - __main__ - Step 90 Global step 90 Train loss 1.61 on epoch=6
05/30/2022 10:42:37 - INFO - __main__ - Step 100 Global step 100 Train loss 1.42 on epoch=7
05/30/2022 10:42:42 - INFO - __main__ - Global step 100 Train loss 1.77 Classification-F1 0.31870927545388633 on epoch=7
05/30/2022 10:42:42 - INFO - __main__ - Saving model with best Classification-F1: 0.142246320886558 -> 0.31870927545388633 on epoch=7, global_step=100
05/30/2022 10:42:45 - INFO - __main__ - Step 110 Global step 110 Train loss 1.34 on epoch=7
05/30/2022 10:42:47 - INFO - __main__ - Step 120 Global step 120 Train loss 1.26 on epoch=8
05/30/2022 10:42:50 - INFO - __main__ - Step 130 Global step 130 Train loss 1.14 on epoch=9
05/30/2022 10:42:52 - INFO - __main__ - Step 140 Global step 140 Train loss 1.05 on epoch=9
05/30/2022 10:42:55 - INFO - __main__ - Step 150 Global step 150 Train loss 0.92 on epoch=10
05/30/2022 10:43:09 - INFO - __main__ - Global step 150 Train loss 1.14 Classification-F1 0.44372610452066114 on epoch=10
05/30/2022 10:43:09 - INFO - __main__ - Saving model with best Classification-F1: 0.31870927545388633 -> 0.44372610452066114 on epoch=10, global_step=150
05/30/2022 10:43:12 - INFO - __main__ - Step 160 Global step 160 Train loss 1.02 on epoch=11
05/30/2022 10:43:14 - INFO - __main__ - Step 170 Global step 170 Train loss 0.93 on epoch=12
05/30/2022 10:43:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.86 on epoch=12
05/30/2022 10:43:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.92 on epoch=13
05/30/2022 10:43:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.86 on epoch=14
05/30/2022 10:43:28 - INFO - __main__ - Global step 200 Train loss 0.92 Classification-F1 0.37747947082102257 on epoch=14
05/30/2022 10:43:30 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=14
05/30/2022 10:43:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.76 on epoch=15
05/30/2022 10:43:35 - INFO - __main__ - Step 230 Global step 230 Train loss 0.55 on epoch=16
05/30/2022 10:43:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.68 on epoch=17
05/30/2022 10:43:40 - INFO - __main__ - Step 250 Global step 250 Train loss 0.74 on epoch=17
05/30/2022 10:43:54 - INFO - __main__ - Global step 250 Train loss 0.68 Classification-F1 0.4171781633585617 on epoch=17
05/30/2022 10:43:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.58 on epoch=18
05/30/2022 10:43:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.61 on epoch=19
05/30/2022 10:44:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.57 on epoch=19
05/30/2022 10:44:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.51 on epoch=20
05/30/2022 10:44:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.52 on epoch=21
05/30/2022 10:44:12 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.5638951364099484 on epoch=21
05/30/2022 10:44:12 - INFO - __main__ - Saving model with best Classification-F1: 0.44372610452066114 -> 0.5638951364099484 on epoch=21, global_step=300
05/30/2022 10:44:15 - INFO - __main__ - Step 310 Global step 310 Train loss 0.53 on epoch=22
05/30/2022 10:44:17 - INFO - __main__ - Step 320 Global step 320 Train loss 0.49 on epoch=22
05/30/2022 10:44:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.56 on epoch=23
05/30/2022 10:44:22 - INFO - __main__ - Step 340 Global step 340 Train loss 0.50 on epoch=24
05/30/2022 10:44:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.48 on epoch=24
05/30/2022 10:44:31 - INFO - __main__ - Global step 350 Train loss 0.51 Classification-F1 0.7381791296343254 on epoch=24
05/30/2022 10:44:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5638951364099484 -> 0.7381791296343254 on epoch=24, global_step=350
05/30/2022 10:44:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.42 on epoch=25
05/30/2022 10:44:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=26
05/30/2022 10:44:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=27
05/30/2022 10:44:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.46 on epoch=27
05/30/2022 10:44:43 - INFO - __main__ - Step 400 Global step 400 Train loss 0.43 on epoch=28
05/30/2022 10:44:49 - INFO - __main__ - Global step 400 Train loss 0.41 Classification-F1 0.6939466886967144 on epoch=28
05/30/2022 10:44:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.35 on epoch=29
05/30/2022 10:44:54 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=29
05/30/2022 10:44:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.37 on epoch=30
05/30/2022 10:44:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=31
05/30/2022 10:45:02 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=32
05/30/2022 10:45:08 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.7102101562639415 on epoch=32
05/30/2022 10:45:11 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=32
05/30/2022 10:45:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.34 on epoch=33
05/30/2022 10:45:16 - INFO - __main__ - Step 480 Global step 480 Train loss 0.41 on epoch=34
05/30/2022 10:45:18 - INFO - __main__ - Step 490 Global step 490 Train loss 0.34 on epoch=34
05/30/2022 10:45:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.30 on epoch=35
05/30/2022 10:45:26 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.7491228124737375 on epoch=35
05/30/2022 10:45:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7381791296343254 -> 0.7491228124737375 on epoch=35, global_step=500
05/30/2022 10:45:29 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=36
05/30/2022 10:45:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=37
05/30/2022 10:45:34 - INFO - __main__ - Step 530 Global step 530 Train loss 0.34 on epoch=37
05/30/2022 10:45:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=38
05/30/2022 10:45:39 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=39
05/30/2022 10:45:45 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.781972892478835 on epoch=39
05/30/2022 10:45:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7491228124737375 -> 0.781972892478835 on epoch=39, global_step=550
05/30/2022 10:45:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.31 on epoch=39
05/30/2022 10:45:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.27 on epoch=40
05/30/2022 10:45:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=41
05/30/2022 10:45:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=42
05/30/2022 10:45:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.32 on epoch=42
05/30/2022 10:46:03 - INFO - __main__ - Global step 600 Train loss 0.28 Classification-F1 0.5799622049088777 on epoch=42
05/30/2022 10:46:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.32 on epoch=43
05/30/2022 10:46:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=44
05/30/2022 10:46:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=44
05/30/2022 10:46:13 - INFO - __main__ - Step 640 Global step 640 Train loss 0.26 on epoch=45
05/30/2022 10:46:15 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=46
05/30/2022 10:46:21 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.7753385056769024 on epoch=46
05/30/2022 10:46:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=47
05/30/2022 10:46:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
05/30/2022 10:46:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=48
05/30/2022 10:46:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=49
05/30/2022 10:46:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=49
05/30/2022 10:46:40 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.80405618710593 on epoch=49
05/30/2022 10:46:40 - INFO - __main__ - Saving model with best Classification-F1: 0.781972892478835 -> 0.80405618710593 on epoch=49, global_step=700
05/30/2022 10:46:42 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=50
05/30/2022 10:46:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=51
05/30/2022 10:46:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=52
05/30/2022 10:46:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=52
05/30/2022 10:46:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=53
05/30/2022 10:46:58 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.6792707691414588 on epoch=53
05/30/2022 10:47:00 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=54
05/30/2022 10:47:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=54
05/30/2022 10:47:05 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=55
05/30/2022 10:47:08 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=56
05/30/2022 10:47:10 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
05/30/2022 10:47:16 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.7762639698411471 on epoch=57
05/30/2022 10:47:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=57
05/30/2022 10:47:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=58
05/30/2022 10:47:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=59
05/30/2022 10:47:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=59
05/30/2022 10:47:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=60
05/30/2022 10:47:35 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.6397788477675782 on epoch=60
05/30/2022 10:47:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=61
05/30/2022 10:47:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=62
05/30/2022 10:47:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=62
05/30/2022 10:47:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=63
05/30/2022 10:47:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=64
05/30/2022 10:47:53 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.695661511609852 on epoch=64
05/30/2022 10:47:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=64
05/30/2022 10:47:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
05/30/2022 10:48:01 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=66
05/30/2022 10:48:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=67
05/30/2022 10:48:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=67
05/30/2022 10:48:12 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.8463149553797149 on epoch=67
05/30/2022 10:48:12 - INFO - __main__ - Saving model with best Classification-F1: 0.80405618710593 -> 0.8463149553797149 on epoch=67, global_step=950
05/30/2022 10:48:14 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=68
05/30/2022 10:48:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=69
05/30/2022 10:48:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=69
05/30/2022 10:48:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=70
05/30/2022 10:48:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.19 on epoch=71
05/30/2022 10:48:30 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.7131520159346391 on epoch=71
05/30/2022 10:48:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=72
05/30/2022 10:48:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
05/30/2022 10:48:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=73
05/30/2022 10:48:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
05/30/2022 10:48:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
05/30/2022 10:48:48 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.7337184785213459 on epoch=74
05/30/2022 10:48:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=75
05/30/2022 10:48:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
05/30/2022 10:48:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
05/30/2022 10:48:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=77
05/30/2022 10:49:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=78
05/30/2022 10:49:06 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.756752689863249 on epoch=78
05/30/2022 10:49:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=79
05/30/2022 10:49:11 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=79
05/30/2022 10:49:14 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=80
05/30/2022 10:49:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
05/30/2022 10:49:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.18 on epoch=82
05/30/2022 10:49:25 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.819566986674499 on epoch=82
05/30/2022 10:49:27 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=82
05/30/2022 10:49:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=83
05/30/2022 10:49:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=84
05/30/2022 10:49:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=84
05/30/2022 10:49:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=85
05/30/2022 10:49:43 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.7307441274376758 on epoch=85
05/30/2022 10:49:45 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=86
05/30/2022 10:49:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
05/30/2022 10:49:50 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=87
05/30/2022 10:49:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=88
05/30/2022 10:49:55 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.20 on epoch=89
05/30/2022 10:50:01 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.7832245669142008 on epoch=89
05/30/2022 10:50:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=89
05/30/2022 10:50:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=90
05/30/2022 10:50:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
05/30/2022 10:50:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
05/30/2022 10:50:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=92
05/30/2022 10:50:19 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.7810935861988357 on epoch=92
05/30/2022 10:50:22 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
05/30/2022 10:50:24 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=94
05/30/2022 10:50:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
05/30/2022 10:50:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=95
05/30/2022 10:50:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=96
05/30/2022 10:50:37 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.6624873164109658 on epoch=96
05/30/2022 10:50:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=97
05/30/2022 10:50:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.19 on epoch=97
05/30/2022 10:50:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=98
05/30/2022 10:50:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=99
05/30/2022 10:50:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
05/30/2022 10:50:56 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.7449483617280352 on epoch=99
05/30/2022 10:50:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=100
05/30/2022 10:51:01 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=101
05/30/2022 10:51:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
05/30/2022 10:51:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=102
05/30/2022 10:51:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
05/30/2022 10:51:14 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.7723464151343937 on epoch=103
05/30/2022 10:51:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.15 on epoch=104
05/30/2022 10:51:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
05/30/2022 10:51:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=105
05/30/2022 10:51:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
05/30/2022 10:51:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
05/30/2022 10:51:32 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.8685840739509688 on epoch=107
05/30/2022 10:51:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8463149553797149 -> 0.8685840739509688 on epoch=107, global_step=1500
05/30/2022 10:51:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.14 on epoch=107
05/30/2022 10:51:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=108
05/30/2022 10:51:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
05/30/2022 10:51:42 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
05/30/2022 10:51:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=110
05/30/2022 10:51:50 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.8148553760405093 on epoch=110
05/30/2022 10:51:52 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=111
05/30/2022 10:51:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
05/30/2022 10:51:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=112
05/30/2022 10:52:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
05/30/2022 10:52:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
05/30/2022 10:52:08 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8937735129781846 on epoch=114
05/30/2022 10:52:08 - INFO - __main__ - Saving model with best Classification-F1: 0.8685840739509688 -> 0.8937735129781846 on epoch=114, global_step=1600
05/30/2022 10:52:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
05/30/2022 10:52:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=115
05/30/2022 10:52:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=116
05/30/2022 10:52:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
05/30/2022 10:52:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=117
05/30/2022 10:52:26 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.8421045078792351 on epoch=117
05/30/2022 10:52:29 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=118
05/30/2022 10:52:31 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
05/30/2022 10:52:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
05/30/2022 10:52:36 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=120
05/30/2022 10:52:39 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
05/30/2022 10:52:44 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.7371254573839963 on epoch=121
05/30/2022 10:52:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
05/30/2022 10:52:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=122
05/30/2022 10:52:52 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
05/30/2022 10:52:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
05/30/2022 10:52:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=124
05/30/2022 10:53:03 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.6830789562313582 on epoch=124
05/30/2022 10:53:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
05/30/2022 10:53:08 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
05/30/2022 10:53:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=127
05/30/2022 10:53:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.14 on epoch=127
05/30/2022 10:53:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
05/30/2022 10:53:21 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.6630661416565715 on epoch=128
05/30/2022 10:53:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
05/30/2022 10:53:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
05/30/2022 10:53:29 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
05/30/2022 10:53:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=131
05/30/2022 10:53:34 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
05/30/2022 10:53:40 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.837509255789371 on epoch=132
05/30/2022 10:53:42 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=132
05/30/2022 10:53:45 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
05/30/2022 10:53:47 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=134
05/30/2022 10:53:50 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
05/30/2022 10:53:52 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
05/30/2022 10:53:58 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.7813802270951506 on epoch=135
05/30/2022 10:54:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=136
05/30/2022 10:54:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
05/30/2022 10:54:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.14 on epoch=137
05/30/2022 10:54:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
05/30/2022 10:54:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=139
05/30/2022 10:54:16 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.7202374623427255 on epoch=139
05/30/2022 10:54:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
05/30/2022 10:54:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
05/30/2022 10:54:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.12 on epoch=141
05/30/2022 10:54:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
05/30/2022 10:54:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
05/30/2022 10:54:34 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.9036939356927254 on epoch=142
05/30/2022 10:54:34 - INFO - __main__ - Saving model with best Classification-F1: 0.8937735129781846 -> 0.9036939356927254 on epoch=142, global_step=2000
05/30/2022 10:54:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=143
05/30/2022 10:54:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=144
05/30/2022 10:54:41 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
05/30/2022 10:54:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
05/30/2022 10:54:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=146
05/30/2022 10:54:52 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.8025873120122401 on epoch=146
05/30/2022 10:54:54 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
05/30/2022 10:54:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
05/30/2022 10:54:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
05/30/2022 10:55:02 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=149
05/30/2022 10:55:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
05/30/2022 10:55:10 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.77097966486581 on epoch=149
05/30/2022 10:55:12 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
05/30/2022 10:55:15 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
05/30/2022 10:55:17 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=152
05/30/2022 10:55:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=152
05/30/2022 10:55:22 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
05/30/2022 10:55:28 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7013280263135767 on epoch=153
05/30/2022 10:55:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
05/30/2022 10:55:33 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=154
05/30/2022 10:55:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
05/30/2022 10:55:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
05/30/2022 10:55:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
05/30/2022 10:55:46 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7583317266875701 on epoch=157
05/30/2022 10:55:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=157
05/30/2022 10:55:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=158
05/30/2022 10:55:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=159
05/30/2022 10:55:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
05/30/2022 10:55:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
05/30/2022 10:56:04 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.7782580662073351 on epoch=160
05/30/2022 10:56:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
05/30/2022 10:56:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
05/30/2022 10:56:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/30/2022 10:56:14 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=163
05/30/2022 10:56:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
05/30/2022 10:56:22 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7568165030100544 on epoch=164
05/30/2022 10:56:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
05/30/2022 10:56:27 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
05/30/2022 10:56:30 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.10 on epoch=166
05/30/2022 10:56:32 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=167
05/30/2022 10:56:35 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=167
05/30/2022 10:56:41 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7706568439002306 on epoch=167
05/30/2022 10:56:43 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
05/30/2022 10:56:46 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
05/30/2022 10:56:48 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
05/30/2022 10:56:51 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
05/30/2022 10:56:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
05/30/2022 10:56:59 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6854002675309976 on epoch=171
05/30/2022 10:57:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
05/30/2022 10:57:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=172
05/30/2022 10:57:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=173
05/30/2022 10:57:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=174
05/30/2022 10:57:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/30/2022 10:57:17 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.7793059168252193 on epoch=174
05/30/2022 10:57:20 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=175
05/30/2022 10:57:22 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=176
05/30/2022 10:57:25 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
05/30/2022 10:57:27 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
05/30/2022 10:57:30 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.09 on epoch=178
05/30/2022 10:57:35 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.8386396069197221 on epoch=178
05/30/2022 10:57:38 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
05/30/2022 10:57:40 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
05/30/2022 10:57:43 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/30/2022 10:57:45 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/30/2022 10:57:47 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
05/30/2022 10:57:53 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7909999811551325 on epoch=182
05/30/2022 10:57:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
05/30/2022 10:57:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
05/30/2022 10:58:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
05/30/2022 10:58:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
05/30/2022 10:58:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
05/30/2022 10:58:11 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7797943619798737 on epoch=185
05/30/2022 10:58:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
05/30/2022 10:58:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/30/2022 10:58:19 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
05/30/2022 10:58:21 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=188
05/30/2022 10:58:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
05/30/2022 10:58:29 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7274548058559278 on epoch=189
05/30/2022 10:58:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/30/2022 10:58:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.10 on epoch=190
05/30/2022 10:58:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
05/30/2022 10:58:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/30/2022 10:58:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
05/30/2022 10:58:47 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7868749960068747 on epoch=192
05/30/2022 10:58:50 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/30/2022 10:58:53 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
05/30/2022 10:58:55 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
05/30/2022 10:58:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
05/30/2022 10:59:00 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
05/30/2022 10:59:05 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7465233276613206 on epoch=196
05/30/2022 10:59:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/30/2022 10:59:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
05/30/2022 10:59:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
05/30/2022 10:59:15 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
05/30/2022 10:59:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/30/2022 10:59:24 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9040029325513196 on epoch=199
05/30/2022 10:59:24 - INFO - __main__ - Saving model with best Classification-F1: 0.9036939356927254 -> 0.9040029325513196 on epoch=199, global_step=2800
05/30/2022 10:59:26 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
05/30/2022 10:59:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
05/30/2022 10:59:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/30/2022 10:59:33 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
05/30/2022 10:59:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
05/30/2022 10:59:41 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7838236223031325 on epoch=203
05/30/2022 10:59:44 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
05/30/2022 10:59:46 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/30/2022 10:59:49 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/30/2022 10:59:52 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/30/2022 10:59:54 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=207
05/30/2022 11:00:00 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7991559394632205 on epoch=207
05/30/2022 11:00:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/30/2022 11:00:05 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/30/2022 11:00:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/30/2022 11:00:10 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
05/30/2022 11:00:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
05/30/2022 11:00:18 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8514020362543845 on epoch=210
05/30/2022 11:00:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
05/30/2022 11:00:23 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.07 on epoch=212
05/30/2022 11:00:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/30/2022 11:00:28 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=213
05/30/2022 11:00:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
05/30/2022 11:00:32 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 11:00:32 - INFO - __main__ - Printing 3 examples
05/30/2022 11:00:32 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/30/2022 11:00:32 - INFO - __main__ - ['Plant']
05/30/2022 11:00:32 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/30/2022 11:00:32 - INFO - __main__ - ['Plant']
05/30/2022 11:00:32 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/30/2022 11:00:32 - INFO - __main__ - ['Plant']
05/30/2022 11:00:32 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:00:32 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:00:32 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 11:00:32 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 11:00:32 - INFO - __main__ - Printing 3 examples
05/30/2022 11:00:32 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/30/2022 11:00:32 - INFO - __main__ - ['Plant']
05/30/2022 11:00:32 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/30/2022 11:00:32 - INFO - __main__ - ['Plant']
05/30/2022 11:00:32 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/30/2022 11:00:32 - INFO - __main__ - ['Plant']
05/30/2022 11:00:32 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:00:32 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:00:32 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 11:00:36 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8419770622895624 on epoch=214
05/30/2022 11:00:36 - INFO - __main__ - save last model!
05/30/2022 11:00:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 11:00:36 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 11:00:36 - INFO - __main__ - Printing 3 examples
05/30/2022 11:00:36 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 11:00:36 - INFO - __main__ - ['Animal']
05/30/2022 11:00:36 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 11:00:36 - INFO - __main__ - ['Animal']
05/30/2022 11:00:36 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 11:00:36 - INFO - __main__ - ['Village']
05/30/2022 11:00:36 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:00:38 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:00:42 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 11:00:47 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 11:00:47 - INFO - __main__ - task name: dbpedia_14
05/30/2022 11:00:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 11:00:47 - INFO - __main__ - Starting training!
05/30/2022 11:02:47 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
05/30/2022 11:02:47 - INFO - __main__ - Classification-F1 on test data: 0.6395
05/30/2022 11:02:48 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.9040029325513196, test_performance=0.6395087610497067
05/30/2022 11:02:48 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
05/30/2022 11:02:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 11:02:49 - INFO - __main__ - Printing 3 examples
05/30/2022 11:02:49 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/30/2022 11:02:49 - INFO - __main__ - ['Plant']
05/30/2022 11:02:49 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/30/2022 11:02:49 - INFO - __main__ - ['Plant']
05/30/2022 11:02:49 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/30/2022 11:02:49 - INFO - __main__ - ['Plant']
05/30/2022 11:02:49 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:02:49 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:02:49 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 11:02:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 11:02:49 - INFO - __main__ - Printing 3 examples
05/30/2022 11:02:49 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/30/2022 11:02:49 - INFO - __main__ - ['Plant']
05/30/2022 11:02:49 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/30/2022 11:02:49 - INFO - __main__ - ['Plant']
05/30/2022 11:02:49 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/30/2022 11:02:49 - INFO - __main__ - ['Plant']
05/30/2022 11:02:49 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:02:49 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:02:50 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 11:03:04 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 11:03:04 - INFO - __main__ - task name: dbpedia_14
05/30/2022 11:03:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 11:03:05 - INFO - __main__ - Starting training!
05/30/2022 11:03:08 - INFO - __main__ - Step 10 Global step 10 Train loss 7.24 on epoch=0
05/30/2022 11:03:11 - INFO - __main__ - Step 20 Global step 20 Train loss 6.39 on epoch=1
05/30/2022 11:03:13 - INFO - __main__ - Step 30 Global step 30 Train loss 5.23 on epoch=2
05/30/2022 11:03:16 - INFO - __main__ - Step 40 Global step 40 Train loss 3.97 on epoch=2
05/30/2022 11:03:18 - INFO - __main__ - Step 50 Global step 50 Train loss 3.32 on epoch=3
05/30/2022 11:03:43 - INFO - __main__ - Global step 50 Train loss 5.23 Classification-F1 0.051451321868177066 on epoch=3
05/30/2022 11:03:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.051451321868177066 on epoch=3, global_step=50
05/30/2022 11:03:46 - INFO - __main__ - Step 60 Global step 60 Train loss 2.81 on epoch=4
05/30/2022 11:03:48 - INFO - __main__ - Step 70 Global step 70 Train loss 2.58 on epoch=4
05/30/2022 11:03:51 - INFO - __main__ - Step 80 Global step 80 Train loss 2.35 on epoch=5
05/30/2022 11:03:53 - INFO - __main__ - Step 90 Global step 90 Train loss 1.99 on epoch=6
05/30/2022 11:03:56 - INFO - __main__ - Step 100 Global step 100 Train loss 1.65 on epoch=7
05/30/2022 11:04:03 - INFO - __main__ - Global step 100 Train loss 2.28 Classification-F1 0.1039336780530689 on epoch=7
05/30/2022 11:04:03 - INFO - __main__ - Saving model with best Classification-F1: 0.051451321868177066 -> 0.1039336780530689 on epoch=7, global_step=100
05/30/2022 11:04:06 - INFO - __main__ - Step 110 Global step 110 Train loss 1.50 on epoch=7
05/30/2022 11:04:08 - INFO - __main__ - Step 120 Global step 120 Train loss 1.42 on epoch=8
05/30/2022 11:04:10 - INFO - __main__ - Step 130 Global step 130 Train loss 1.27 on epoch=9
05/30/2022 11:04:13 - INFO - __main__ - Step 140 Global step 140 Train loss 1.17 on epoch=9
05/30/2022 11:04:15 - INFO - __main__ - Step 150 Global step 150 Train loss 1.12 on epoch=10
05/30/2022 11:04:28 - INFO - __main__ - Global step 150 Train loss 1.30 Classification-F1 0.24837894985602965 on epoch=10
05/30/2022 11:04:28 - INFO - __main__ - Saving model with best Classification-F1: 0.1039336780530689 -> 0.24837894985602965 on epoch=10, global_step=150
05/30/2022 11:04:30 - INFO - __main__ - Step 160 Global step 160 Train loss 1.00 on epoch=11
05/30/2022 11:04:33 - INFO - __main__ - Step 170 Global step 170 Train loss 0.94 on epoch=12
05/30/2022 11:04:35 - INFO - __main__ - Step 180 Global step 180 Train loss 0.94 on epoch=12
05/30/2022 11:04:38 - INFO - __main__ - Step 190 Global step 190 Train loss 0.97 on epoch=13
05/30/2022 11:04:40 - INFO - __main__ - Step 200 Global step 200 Train loss 0.82 on epoch=14
05/30/2022 11:04:46 - INFO - __main__ - Global step 200 Train loss 0.93 Classification-F1 0.3869113322210011 on epoch=14
05/30/2022 11:04:46 - INFO - __main__ - Saving model with best Classification-F1: 0.24837894985602965 -> 0.3869113322210011 on epoch=14, global_step=200
05/30/2022 11:04:49 - INFO - __main__ - Step 210 Global step 210 Train loss 0.77 on epoch=14
05/30/2022 11:04:51 - INFO - __main__ - Step 220 Global step 220 Train loss 0.64 on epoch=15
05/30/2022 11:04:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.67 on epoch=16
05/30/2022 11:04:56 - INFO - __main__ - Step 240 Global step 240 Train loss 0.73 on epoch=17
05/30/2022 11:04:59 - INFO - __main__ - Step 250 Global step 250 Train loss 0.56 on epoch=17
05/30/2022 11:05:05 - INFO - __main__ - Global step 250 Train loss 0.67 Classification-F1 0.6192530107242759 on epoch=17
05/30/2022 11:05:05 - INFO - __main__ - Saving model with best Classification-F1: 0.3869113322210011 -> 0.6192530107242759 on epoch=17, global_step=250
05/30/2022 11:05:07 - INFO - __main__ - Step 260 Global step 260 Train loss 0.67 on epoch=18
05/30/2022 11:05:10 - INFO - __main__ - Step 270 Global step 270 Train loss 0.60 on epoch=19
05/30/2022 11:05:12 - INFO - __main__ - Step 280 Global step 280 Train loss 0.55 on epoch=19
05/30/2022 11:05:15 - INFO - __main__ - Step 290 Global step 290 Train loss 0.55 on epoch=20
05/30/2022 11:05:17 - INFO - __main__ - Step 300 Global step 300 Train loss 0.49 on epoch=21
05/30/2022 11:05:23 - INFO - __main__ - Global step 300 Train loss 0.57 Classification-F1 0.6903546682602659 on epoch=21
05/30/2022 11:05:23 - INFO - __main__ - Saving model with best Classification-F1: 0.6192530107242759 -> 0.6903546682602659 on epoch=21, global_step=300
05/30/2022 11:05:26 - INFO - __main__ - Step 310 Global step 310 Train loss 0.52 on epoch=22
05/30/2022 11:05:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.49 on epoch=22
05/30/2022 11:05:31 - INFO - __main__ - Step 330 Global step 330 Train loss 0.46 on epoch=23
05/30/2022 11:05:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.53 on epoch=24
05/30/2022 11:05:36 - INFO - __main__ - Step 350 Global step 350 Train loss 0.54 on epoch=24
05/30/2022 11:05:42 - INFO - __main__ - Global step 350 Train loss 0.51 Classification-F1 0.5839554783418794 on epoch=24
05/30/2022 11:05:45 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=25
05/30/2022 11:05:47 - INFO - __main__ - Step 370 Global step 370 Train loss 0.34 on epoch=26
05/30/2022 11:05:50 - INFO - __main__ - Step 380 Global step 380 Train loss 0.43 on epoch=27
05/30/2022 11:05:52 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=27
05/30/2022 11:05:55 - INFO - __main__ - Step 400 Global step 400 Train loss 0.31 on epoch=28
05/30/2022 11:06:00 - INFO - __main__ - Global step 400 Train loss 0.35 Classification-F1 0.42746227333533066 on epoch=28
05/30/2022 11:06:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.36 on epoch=29
05/30/2022 11:06:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.32 on epoch=29
05/30/2022 11:06:08 - INFO - __main__ - Step 430 Global step 430 Train loss 0.39 on epoch=30
05/30/2022 11:06:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=31
05/30/2022 11:06:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=32
05/30/2022 11:06:19 - INFO - __main__ - Global step 450 Train loss 0.35 Classification-F1 0.560366934652649 on epoch=32
05/30/2022 11:06:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=32
05/30/2022 11:06:24 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=33
05/30/2022 11:06:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=34
05/30/2022 11:06:29 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=34
05/30/2022 11:06:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=35
05/30/2022 11:06:37 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.49589317508111336 on epoch=35
05/30/2022 11:06:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=36
05/30/2022 11:06:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=37
05/30/2022 11:06:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.35 on epoch=37
05/30/2022 11:06:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=38
05/30/2022 11:06:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=39
05/30/2022 11:06:55 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.4950844838538886 on epoch=39
05/30/2022 11:06:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=39
05/30/2022 11:07:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=40
05/30/2022 11:07:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=41
05/30/2022 11:07:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=42
05/30/2022 11:07:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=42
05/30/2022 11:07:13 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.5625333076327133 on epoch=42
05/30/2022 11:07:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=43
05/30/2022 11:07:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=44
05/30/2022 11:07:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=44
05/30/2022 11:07:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=45
05/30/2022 11:07:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=46
05/30/2022 11:07:32 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.5753469231031356 on epoch=46
05/30/2022 11:07:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=47
05/30/2022 11:07:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.26 on epoch=47
05/30/2022 11:07:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=48
05/30/2022 11:07:42 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=49
05/30/2022 11:07:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=49
05/30/2022 11:07:51 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.6858139596679497 on epoch=49
05/30/2022 11:07:54 - INFO - __main__ - Step 710 Global step 710 Train loss 0.26 on epoch=50
05/30/2022 11:07:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=51
05/30/2022 11:07:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
05/30/2022 11:08:01 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=52
05/30/2022 11:08:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=53
05/30/2022 11:08:10 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.8177350720825114 on epoch=53
05/30/2022 11:08:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6903546682602659 -> 0.8177350720825114 on epoch=53, global_step=750
05/30/2022 11:08:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=54
05/30/2022 11:08:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=54
05/30/2022 11:08:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=55
05/30/2022 11:08:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=56
05/30/2022 11:08:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
05/30/2022 11:08:30 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.7299968860566172 on epoch=57
05/30/2022 11:08:32 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=57
05/30/2022 11:08:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=58
05/30/2022 11:08:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=59
05/30/2022 11:08:40 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=59
05/30/2022 11:08:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=60
05/30/2022 11:08:48 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.6964902276871715 on epoch=60
05/30/2022 11:08:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=61
05/30/2022 11:08:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=62
05/30/2022 11:08:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=62
05/30/2022 11:08:58 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
05/30/2022 11:09:01 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=64
05/30/2022 11:09:07 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.8457140893380812 on epoch=64
05/30/2022 11:09:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8177350720825114 -> 0.8457140893380812 on epoch=64, global_step=900
05/30/2022 11:09:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=64
05/30/2022 11:09:12 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
05/30/2022 11:09:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=66
05/30/2022 11:09:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=67
05/30/2022 11:09:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=67
05/30/2022 11:09:26 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.7372155608016351 on epoch=67
05/30/2022 11:09:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=68
05/30/2022 11:09:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=69
05/30/2022 11:09:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=69
05/30/2022 11:09:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=70
05/30/2022 11:09:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=71
05/30/2022 11:09:45 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.8511485826001955 on epoch=71
05/30/2022 11:09:45 - INFO - __main__ - Saving model with best Classification-F1: 0.8457140893380812 -> 0.8511485826001955 on epoch=71, global_step=1000
05/30/2022 11:09:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=72
05/30/2022 11:09:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
05/30/2022 11:09:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=73
05/30/2022 11:09:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=74
05/30/2022 11:09:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
05/30/2022 11:10:03 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.8926422260008597 on epoch=74
05/30/2022 11:10:03 - INFO - __main__ - Saving model with best Classification-F1: 0.8511485826001955 -> 0.8926422260008597 on epoch=74, global_step=1050
05/30/2022 11:10:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=75
05/30/2022 11:10:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
05/30/2022 11:10:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=77
05/30/2022 11:10:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=77
05/30/2022 11:10:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=78
05/30/2022 11:10:23 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.9236213959320043 on epoch=78
05/30/2022 11:10:23 - INFO - __main__ - Saving model with best Classification-F1: 0.8926422260008597 -> 0.9236213959320043 on epoch=78, global_step=1100
05/30/2022 11:10:25 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
05/30/2022 11:10:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=79
05/30/2022 11:10:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=80
05/30/2022 11:10:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
05/30/2022 11:10:36 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=82
05/30/2022 11:10:42 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.9731618160460666 on epoch=82
05/30/2022 11:10:42 - INFO - __main__ - Saving model with best Classification-F1: 0.9236213959320043 -> 0.9731618160460666 on epoch=82, global_step=1150
05/30/2022 11:10:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=82
05/30/2022 11:10:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
05/30/2022 11:10:50 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
05/30/2022 11:10:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=84
05/30/2022 11:10:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=85
05/30/2022 11:11:01 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.8979111801123186 on epoch=85
05/30/2022 11:11:04 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
05/30/2022 11:11:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
05/30/2022 11:11:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
05/30/2022 11:11:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=88
05/30/2022 11:11:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
05/30/2022 11:11:21 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.859103128054741 on epoch=89
05/30/2022 11:11:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
05/30/2022 11:11:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
05/30/2022 11:11:30 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
05/30/2022 11:11:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
05/30/2022 11:11:35 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=92
05/30/2022 11:11:41 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.9103372434017596 on epoch=92
05/30/2022 11:11:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
05/30/2022 11:11:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=94
05/30/2022 11:11:48 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
05/30/2022 11:11:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
05/30/2022 11:11:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
05/30/2022 11:11:59 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.9163766699250571 on epoch=96
05/30/2022 11:12:02 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
05/30/2022 11:12:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
05/30/2022 11:12:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
05/30/2022 11:12:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
05/30/2022 11:12:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
05/30/2022 11:12:18 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.97778843942269 on epoch=99
05/30/2022 11:12:18 - INFO - __main__ - Saving model with best Classification-F1: 0.9731618160460666 -> 0.97778843942269 on epoch=99, global_step=1400
05/30/2022 11:12:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
05/30/2022 11:12:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
05/30/2022 11:12:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
05/30/2022 11:12:28 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=102
05/30/2022 11:12:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
05/30/2022 11:12:36 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.9165241120886282 on epoch=103
05/30/2022 11:12:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=104
05/30/2022 11:12:42 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
05/30/2022 11:12:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
05/30/2022 11:12:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=106
05/30/2022 11:12:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
05/30/2022 11:12:55 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.9049514937939986 on epoch=107
05/30/2022 11:12:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
05/30/2022 11:13:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
05/30/2022 11:13:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
05/30/2022 11:13:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
05/30/2022 11:13:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
05/30/2022 11:13:14 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.97787856344884 on epoch=110
05/30/2022 11:13:14 - INFO - __main__ - Saving model with best Classification-F1: 0.97778843942269 -> 0.97787856344884 on epoch=110, global_step=1550
05/30/2022 11:13:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=111
05/30/2022 11:13:19 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
05/30/2022 11:13:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
05/30/2022 11:13:24 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=113
05/30/2022 11:13:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
05/30/2022 11:13:32 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.97778843942269 on epoch=114
05/30/2022 11:13:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
05/30/2022 11:13:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
05/30/2022 11:13:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
05/30/2022 11:13:43 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
05/30/2022 11:13:45 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
05/30/2022 11:13:51 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.9777840755070358 on epoch=117
05/30/2022 11:13:54 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
05/30/2022 11:13:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
05/30/2022 11:13:59 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
05/30/2022 11:14:02 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
05/30/2022 11:14:04 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
05/30/2022 11:14:10 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.9776304656760065 on epoch=121
05/30/2022 11:14:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
05/30/2022 11:14:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
05/30/2022 11:14:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
05/30/2022 11:14:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=124
05/30/2022 11:14:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
05/30/2022 11:14:29 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.9822527251369758 on epoch=124
05/30/2022 11:14:29 - INFO - __main__ - Saving model with best Classification-F1: 0.97787856344884 -> 0.9822527251369758 on epoch=124, global_step=1750
05/30/2022 11:14:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.14 on epoch=125
05/30/2022 11:14:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
05/30/2022 11:14:37 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=127
05/30/2022 11:14:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
05/30/2022 11:14:42 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
05/30/2022 11:14:48 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.9146186724934353 on epoch=128
05/30/2022 11:14:51 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
05/30/2022 11:14:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=129
05/30/2022 11:14:56 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
05/30/2022 11:14:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
05/30/2022 11:15:01 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
05/30/2022 11:15:07 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.8516957206473336 on epoch=132
05/30/2022 11:15:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
05/30/2022 11:15:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
05/30/2022 11:15:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
05/30/2022 11:15:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
05/30/2022 11:15:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
05/30/2022 11:15:26 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9103160638644511 on epoch=135
05/30/2022 11:15:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
05/30/2022 11:15:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
05/30/2022 11:15:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
05/30/2022 11:15:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
05/30/2022 11:15:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
05/30/2022 11:15:45 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9166388745136373 on epoch=139
05/30/2022 11:15:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
05/30/2022 11:15:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=140
05/30/2022 11:15:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=141
05/30/2022 11:15:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
05/30/2022 11:15:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=142
05/30/2022 11:16:04 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.8350688521882108 on epoch=142
05/30/2022 11:16:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
05/30/2022 11:16:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
05/30/2022 11:16:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
05/30/2022 11:16:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
05/30/2022 11:16:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
05/30/2022 11:16:23 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9733014613470024 on epoch=146
05/30/2022 11:16:25 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
05/30/2022 11:16:28 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
05/30/2022 11:16:30 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
05/30/2022 11:16:33 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
05/30/2022 11:16:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
05/30/2022 11:16:42 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9777840755070358 on epoch=149
05/30/2022 11:16:45 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
05/30/2022 11:16:47 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
05/30/2022 11:16:50 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
05/30/2022 11:16:52 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
05/30/2022 11:16:55 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.15 on epoch=153
05/30/2022 11:17:01 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.803005146340061 on epoch=153
05/30/2022 11:17:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
05/30/2022 11:17:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
05/30/2022 11:17:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/30/2022 11:17:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
05/30/2022 11:17:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
05/30/2022 11:17:20 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9777840755070358 on epoch=157
05/30/2022 11:17:22 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/30/2022 11:17:25 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
05/30/2022 11:17:27 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.12 on epoch=159
05/30/2022 11:17:30 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
05/30/2022 11:17:32 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
05/30/2022 11:17:41 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.8496834100412729 on epoch=160
05/30/2022 11:17:43 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
05/30/2022 11:17:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
05/30/2022 11:17:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
05/30/2022 11:17:51 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
05/30/2022 11:17:53 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
05/30/2022 11:18:00 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9732891397028022 on epoch=164
05/30/2022 11:18:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
05/30/2022 11:18:05 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
05/30/2022 11:18:08 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
05/30/2022 11:18:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
05/30/2022 11:18:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
05/30/2022 11:18:20 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9776304656760065 on epoch=167
05/30/2022 11:18:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=168
05/30/2022 11:18:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/30/2022 11:18:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
05/30/2022 11:18:30 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
05/30/2022 11:18:32 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
05/30/2022 11:18:38 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9187894121480459 on epoch=171
05/30/2022 11:18:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
05/30/2022 11:18:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
05/30/2022 11:18:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
05/30/2022 11:18:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
05/30/2022 11:18:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/30/2022 11:18:57 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.910434899277404 on epoch=174
05/30/2022 11:19:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
05/30/2022 11:19:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/30/2022 11:19:05 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/30/2022 11:19:07 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
05/30/2022 11:19:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/30/2022 11:19:16 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9776444302061 on epoch=178
05/30/2022 11:19:18 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
05/30/2022 11:19:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
05/30/2022 11:19:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/30/2022 11:19:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
05/30/2022 11:19:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
05/30/2022 11:19:41 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9733241537084043 on epoch=182
05/30/2022 11:19:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
05/30/2022 11:19:47 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
05/30/2022 11:19:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
05/30/2022 11:19:52 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.18 on epoch=184
05/30/2022 11:19:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
05/30/2022 11:20:01 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.97778843942269 on epoch=185
05/30/2022 11:20:03 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/30/2022 11:20:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
05/30/2022 11:20:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
05/30/2022 11:20:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
05/30/2022 11:20:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
05/30/2022 11:20:20 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9686792018860331 on epoch=189
05/30/2022 11:20:22 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/30/2022 11:20:25 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=190
05/30/2022 11:20:27 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/30/2022 11:20:30 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
05/30/2022 11:20:32 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
05/30/2022 11:20:38 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9688371756327167 on epoch=192
05/30/2022 11:20:41 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/30/2022 11:20:44 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/30/2022 11:20:46 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/30/2022 11:20:49 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/30/2022 11:20:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
05/30/2022 11:20:57 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9733014613470024 on epoch=196
05/30/2022 11:21:00 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/30/2022 11:21:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/30/2022 11:21:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/30/2022 11:21:08 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/30/2022 11:21:10 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
05/30/2022 11:21:17 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.973201193967323 on epoch=199
05/30/2022 11:21:19 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
05/30/2022 11:21:22 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
05/30/2022 11:21:24 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/30/2022 11:21:27 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
05/30/2022 11:21:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
05/30/2022 11:21:36 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9733241537084043 on epoch=203
05/30/2022 11:21:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
05/30/2022 11:21:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=204
05/30/2022 11:21:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
05/30/2022 11:21:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
05/30/2022 11:21:48 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
05/30/2022 11:21:54 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9728430696274868 on epoch=207
05/30/2022 11:21:57 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=207
05/30/2022 11:21:59 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/30/2022 11:22:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
05/30/2022 11:22:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
05/30/2022 11:22:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/30/2022 11:22:14 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9733241537084043 on epoch=210
05/30/2022 11:22:16 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=211
05/30/2022 11:22:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/30/2022 11:22:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
05/30/2022 11:22:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
05/30/2022 11:22:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/30/2022 11:22:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 11:22:27 - INFO - __main__ - Printing 3 examples
05/30/2022 11:22:27 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/30/2022 11:22:27 - INFO - __main__ - ['Plant']
05/30/2022 11:22:27 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/30/2022 11:22:27 - INFO - __main__ - ['Plant']
05/30/2022 11:22:27 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/30/2022 11:22:27 - INFO - __main__ - ['Plant']
05/30/2022 11:22:27 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:22:28 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:22:28 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 11:22:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 11:22:28 - INFO - __main__ - Printing 3 examples
05/30/2022 11:22:28 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/30/2022 11:22:28 - INFO - __main__ - ['Plant']
05/30/2022 11:22:28 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/30/2022 11:22:28 - INFO - __main__ - ['Plant']
05/30/2022 11:22:28 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/30/2022 11:22:28 - INFO - __main__ - ['Plant']
05/30/2022 11:22:28 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:22:28 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:22:28 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 11:22:32 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.97778843942269 on epoch=214
05/30/2022 11:22:32 - INFO - __main__ - save last model!
05/30/2022 11:22:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 11:22:32 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 11:22:32 - INFO - __main__ - Printing 3 examples
05/30/2022 11:22:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 11:22:32 - INFO - __main__ - ['Animal']
05/30/2022 11:22:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 11:22:32 - INFO - __main__ - ['Animal']
05/30/2022 11:22:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 11:22:32 - INFO - __main__ - ['Village']
05/30/2022 11:22:32 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:22:34 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:22:38 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 11:22:43 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 11:22:43 - INFO - __main__ - task name: dbpedia_14
05/30/2022 11:22:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 11:22:43 - INFO - __main__ - Starting training!
05/30/2022 11:24:37 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
05/30/2022 11:24:37 - INFO - __main__ - Classification-F1 on test data: 0.7596
05/30/2022 11:24:37 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.9822527251369758, test_performance=0.7596202450701097
05/30/2022 11:24:37 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
05/30/2022 11:24:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 11:24:38 - INFO - __main__ - Printing 3 examples
05/30/2022 11:24:38 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/30/2022 11:24:38 - INFO - __main__ - ['Plant']
05/30/2022 11:24:38 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/30/2022 11:24:38 - INFO - __main__ - ['Plant']
05/30/2022 11:24:38 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/30/2022 11:24:38 - INFO - __main__ - ['Plant']
05/30/2022 11:24:38 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:24:39 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:24:39 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 11:24:39 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 11:24:39 - INFO - __main__ - Printing 3 examples
05/30/2022 11:24:39 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/30/2022 11:24:39 - INFO - __main__ - ['Plant']
05/30/2022 11:24:39 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/30/2022 11:24:39 - INFO - __main__ - ['Plant']
05/30/2022 11:24:39 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/30/2022 11:24:39 - INFO - __main__ - ['Plant']
05/30/2022 11:24:39 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:24:39 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:24:39 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 11:24:54 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 11:24:54 - INFO - __main__ - task name: dbpedia_14
05/30/2022 11:24:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 11:24:55 - INFO - __main__ - Starting training!
05/30/2022 11:24:58 - INFO - __main__ - Step 10 Global step 10 Train loss 7.26 on epoch=0
05/30/2022 11:25:00 - INFO - __main__ - Step 20 Global step 20 Train loss 6.62 on epoch=1
05/30/2022 11:25:03 - INFO - __main__ - Step 30 Global step 30 Train loss 6.20 on epoch=2
05/30/2022 11:25:05 - INFO - __main__ - Step 40 Global step 40 Train loss 5.51 on epoch=2
05/30/2022 11:25:08 - INFO - __main__ - Step 50 Global step 50 Train loss 4.65 on epoch=3
05/30/2022 11:26:49 - INFO - __main__ - Global step 50 Train loss 6.05 Classification-F1 0.0 on epoch=3
05/30/2022 11:26:49 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/30/2022 11:26:51 - INFO - __main__ - Step 60 Global step 60 Train loss 3.91 on epoch=4
05/30/2022 11:26:54 - INFO - __main__ - Step 70 Global step 70 Train loss 3.14 on epoch=4
05/30/2022 11:26:56 - INFO - __main__ - Step 80 Global step 80 Train loss 2.74 on epoch=5
05/30/2022 11:26:59 - INFO - __main__ - Step 90 Global step 90 Train loss 2.42 on epoch=6
05/30/2022 11:27:01 - INFO - __main__ - Step 100 Global step 100 Train loss 2.13 on epoch=7
05/30/2022 11:27:15 - INFO - __main__ - Global step 100 Train loss 2.87 Classification-F1 0.11790247118541568 on epoch=7
05/30/2022 11:27:15 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.11790247118541568 on epoch=7, global_step=100
05/30/2022 11:27:17 - INFO - __main__ - Step 110 Global step 110 Train loss 2.15 on epoch=7
05/30/2022 11:27:20 - INFO - __main__ - Step 120 Global step 120 Train loss 1.98 on epoch=8
05/30/2022 11:27:22 - INFO - __main__ - Step 130 Global step 130 Train loss 1.84 on epoch=9
05/30/2022 11:27:25 - INFO - __main__ - Step 140 Global step 140 Train loss 1.64 on epoch=9
05/30/2022 11:27:27 - INFO - __main__ - Step 150 Global step 150 Train loss 1.60 on epoch=10
05/30/2022 11:27:32 - INFO - __main__ - Global step 150 Train loss 1.84 Classification-F1 0.2962357897890388 on epoch=10
05/30/2022 11:27:32 - INFO - __main__ - Saving model with best Classification-F1: 0.11790247118541568 -> 0.2962357897890388 on epoch=10, global_step=150
05/30/2022 11:27:35 - INFO - __main__ - Step 160 Global step 160 Train loss 1.53 on epoch=11
05/30/2022 11:27:37 - INFO - __main__ - Step 170 Global step 170 Train loss 1.50 on epoch=12
05/30/2022 11:27:40 - INFO - __main__ - Step 180 Global step 180 Train loss 1.27 on epoch=12
05/30/2022 11:27:42 - INFO - __main__ - Step 190 Global step 190 Train loss 1.22 on epoch=13
05/30/2022 11:27:44 - INFO - __main__ - Step 200 Global step 200 Train loss 1.29 on epoch=14
05/30/2022 11:27:50 - INFO - __main__ - Global step 200 Train loss 1.36 Classification-F1 0.43540306603780216 on epoch=14
05/30/2022 11:27:50 - INFO - __main__ - Saving model with best Classification-F1: 0.2962357897890388 -> 0.43540306603780216 on epoch=14, global_step=200
05/30/2022 11:27:53 - INFO - __main__ - Step 210 Global step 210 Train loss 1.20 on epoch=14
05/30/2022 11:27:55 - INFO - __main__ - Step 220 Global step 220 Train loss 0.91 on epoch=15
05/30/2022 11:27:58 - INFO - __main__ - Step 230 Global step 230 Train loss 0.95 on epoch=16
05/30/2022 11:28:00 - INFO - __main__ - Step 240 Global step 240 Train loss 1.11 on epoch=17
05/30/2022 11:28:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.95 on epoch=17
05/30/2022 11:28:08 - INFO - __main__ - Global step 250 Train loss 1.02 Classification-F1 0.38090271150030525 on epoch=17
05/30/2022 11:28:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.92 on epoch=18
05/30/2022 11:28:13 - INFO - __main__ - Step 270 Global step 270 Train loss 0.93 on epoch=19
05/30/2022 11:28:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.85 on epoch=19
05/30/2022 11:28:18 - INFO - __main__ - Step 290 Global step 290 Train loss 0.87 on epoch=20
05/30/2022 11:28:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.85 on epoch=21
05/30/2022 11:28:27 - INFO - __main__ - Global step 300 Train loss 0.89 Classification-F1 0.43941471336044724 on epoch=21
05/30/2022 11:28:27 - INFO - __main__ - Saving model with best Classification-F1: 0.43540306603780216 -> 0.43941471336044724 on epoch=21, global_step=300
05/30/2022 11:28:29 - INFO - __main__ - Step 310 Global step 310 Train loss 0.84 on epoch=22
05/30/2022 11:28:32 - INFO - __main__ - Step 320 Global step 320 Train loss 0.77 on epoch=22
05/30/2022 11:28:34 - INFO - __main__ - Step 330 Global step 330 Train loss 0.69 on epoch=23
05/30/2022 11:28:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.76 on epoch=24
05/30/2022 11:28:39 - INFO - __main__ - Step 350 Global step 350 Train loss 0.70 on epoch=24
05/30/2022 11:28:45 - INFO - __main__ - Global step 350 Train loss 0.75 Classification-F1 0.5428023377809905 on epoch=24
05/30/2022 11:28:45 - INFO - __main__ - Saving model with best Classification-F1: 0.43941471336044724 -> 0.5428023377809905 on epoch=24, global_step=350
05/30/2022 11:28:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.76 on epoch=25
05/30/2022 11:28:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.66 on epoch=26
05/30/2022 11:28:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.73 on epoch=27
05/30/2022 11:28:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.60 on epoch=27
05/30/2022 11:28:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.57 on epoch=28
05/30/2022 11:29:03 - INFO - __main__ - Global step 400 Train loss 0.66 Classification-F1 0.5187231979711757 on epoch=28
05/30/2022 11:29:06 - INFO - __main__ - Step 410 Global step 410 Train loss 0.59 on epoch=29
05/30/2022 11:29:08 - INFO - __main__ - Step 420 Global step 420 Train loss 0.58 on epoch=29
05/30/2022 11:29:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.62 on epoch=30
05/30/2022 11:29:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.56 on epoch=31
05/30/2022 11:29:16 - INFO - __main__ - Step 450 Global step 450 Train loss 0.70 on epoch=32
05/30/2022 11:29:22 - INFO - __main__ - Global step 450 Train loss 0.61 Classification-F1 0.49817171908267016 on epoch=32
05/30/2022 11:29:24 - INFO - __main__ - Step 460 Global step 460 Train loss 0.57 on epoch=32
05/30/2022 11:29:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.59 on epoch=33
05/30/2022 11:29:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.53 on epoch=34
05/30/2022 11:29:32 - INFO - __main__ - Step 490 Global step 490 Train loss 0.55 on epoch=34
05/30/2022 11:29:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.54 on epoch=35
05/30/2022 11:29:40 - INFO - __main__ - Global step 500 Train loss 0.55 Classification-F1 0.5140448494780476 on epoch=35
05/30/2022 11:29:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.48 on epoch=36
05/30/2022 11:29:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.50 on epoch=37
05/30/2022 11:29:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.52 on epoch=37
05/30/2022 11:29:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.45 on epoch=38
05/30/2022 11:29:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.47 on epoch=39
05/30/2022 11:29:58 - INFO - __main__ - Global step 550 Train loss 0.48 Classification-F1 0.662199712492762 on epoch=39
05/30/2022 11:29:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5428023377809905 -> 0.662199712492762 on epoch=39, global_step=550
05/30/2022 11:30:01 - INFO - __main__ - Step 560 Global step 560 Train loss 0.47 on epoch=39
05/30/2022 11:30:03 - INFO - __main__ - Step 570 Global step 570 Train loss 0.44 on epoch=40
05/30/2022 11:30:05 - INFO - __main__ - Step 580 Global step 580 Train loss 0.42 on epoch=41
05/30/2022 11:30:08 - INFO - __main__ - Step 590 Global step 590 Train loss 0.39 on epoch=42
05/30/2022 11:30:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.45 on epoch=42
05/30/2022 11:30:16 - INFO - __main__ - Global step 600 Train loss 0.43 Classification-F1 0.6455489598565237 on epoch=42
05/30/2022 11:30:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.58 on epoch=43
05/30/2022 11:30:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.36 on epoch=44
05/30/2022 11:30:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.41 on epoch=44
05/30/2022 11:30:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.39 on epoch=45
05/30/2022 11:30:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.40 on epoch=46
05/30/2022 11:30:34 - INFO - __main__ - Global step 650 Train loss 0.43 Classification-F1 0.7943983458233344 on epoch=46
05/30/2022 11:30:34 - INFO - __main__ - Saving model with best Classification-F1: 0.662199712492762 -> 0.7943983458233344 on epoch=46, global_step=650
05/30/2022 11:30:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.35 on epoch=47
05/30/2022 11:30:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.32 on epoch=47
05/30/2022 11:30:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.34 on epoch=48
05/30/2022 11:30:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.31 on epoch=49
05/30/2022 11:30:46 - INFO - __main__ - Step 700 Global step 700 Train loss 0.40 on epoch=49
05/30/2022 11:30:52 - INFO - __main__ - Global step 700 Train loss 0.34 Classification-F1 0.763522506377159 on epoch=49
05/30/2022 11:30:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.34 on epoch=50
05/30/2022 11:30:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.38 on epoch=51
05/30/2022 11:30:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.36 on epoch=52
05/30/2022 11:31:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.42 on epoch=52
05/30/2022 11:31:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.35 on epoch=53
05/30/2022 11:31:10 - INFO - __main__ - Global step 750 Train loss 0.37 Classification-F1 0.8059218206531379 on epoch=53
05/30/2022 11:31:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7943983458233344 -> 0.8059218206531379 on epoch=53, global_step=750
05/30/2022 11:31:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.37 on epoch=54
05/30/2022 11:31:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.34 on epoch=54
05/30/2022 11:31:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.35 on epoch=55
05/30/2022 11:31:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.33 on epoch=56
05/30/2022 11:31:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=57
05/30/2022 11:31:28 - INFO - __main__ - Global step 800 Train loss 0.33 Classification-F1 0.8738261114722568 on epoch=57
05/30/2022 11:31:28 - INFO - __main__ - Saving model with best Classification-F1: 0.8059218206531379 -> 0.8738261114722568 on epoch=57, global_step=800
05/30/2022 11:31:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=57
05/30/2022 11:31:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.28 on epoch=58
05/30/2022 11:31:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.32 on epoch=59
05/30/2022 11:31:38 - INFO - __main__ - Step 840 Global step 840 Train loss 0.28 on epoch=59
05/30/2022 11:31:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.26 on epoch=60
05/30/2022 11:31:46 - INFO - __main__ - Global step 850 Train loss 0.29 Classification-F1 0.6371988239298235 on epoch=60
05/30/2022 11:31:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=61
05/30/2022 11:31:50 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=62
05/30/2022 11:31:53 - INFO - __main__ - Step 880 Global step 880 Train loss 0.29 on epoch=62
05/30/2022 11:31:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.30 on epoch=63
05/30/2022 11:31:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=64
05/30/2022 11:32:04 - INFO - __main__ - Global step 900 Train loss 0.23 Classification-F1 0.8178753974595759 on epoch=64
05/30/2022 11:32:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.33 on epoch=64
05/30/2022 11:32:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.27 on epoch=65
05/30/2022 11:32:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.24 on epoch=66
05/30/2022 11:32:13 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=67
05/30/2022 11:32:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.29 on epoch=67
05/30/2022 11:32:22 - INFO - __main__ - Global step 950 Train loss 0.27 Classification-F1 0.7405454469970599 on epoch=67
05/30/2022 11:32:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.27 on epoch=68
05/30/2022 11:32:26 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=69
05/30/2022 11:32:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=69
05/30/2022 11:32:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.28 on epoch=70
05/30/2022 11:32:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=71
05/30/2022 11:32:40 - INFO - __main__ - Global step 1000 Train loss 0.23 Classification-F1 0.6462551544944435 on epoch=71
05/30/2022 11:32:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.20 on epoch=72
05/30/2022 11:32:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.20 on epoch=72
05/30/2022 11:32:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=73
05/30/2022 11:32:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.26 on epoch=74
05/30/2022 11:32:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=74
05/30/2022 11:32:58 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.7537201202760975 on epoch=74
05/30/2022 11:33:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=75
05/30/2022 11:33:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.22 on epoch=76
05/30/2022 11:33:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=77
05/30/2022 11:33:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.22 on epoch=77
05/30/2022 11:33:10 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.24 on epoch=78
05/30/2022 11:33:16 - INFO - __main__ - Global step 1100 Train loss 0.20 Classification-F1 0.7814446498907481 on epoch=78
05/30/2022 11:33:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=79
05/30/2022 11:33:21 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=79
05/30/2022 11:33:23 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.23 on epoch=80
05/30/2022 11:33:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=81
05/30/2022 11:33:28 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=82
05/30/2022 11:33:34 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.7093419968182777 on epoch=82
05/30/2022 11:33:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=82
05/30/2022 11:33:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=83
05/30/2022 11:33:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.21 on epoch=84
05/30/2022 11:33:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.18 on epoch=84
05/30/2022 11:33:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.23 on epoch=85
05/30/2022 11:33:52 - INFO - __main__ - Global step 1200 Train loss 0.19 Classification-F1 0.8282012886614403 on epoch=85
05/30/2022 11:33:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=86
05/30/2022 11:33:56 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.17 on epoch=87
05/30/2022 11:33:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=87
05/30/2022 11:34:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=88
05/30/2022 11:34:04 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=89
05/30/2022 11:34:10 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.8497323670426137 on epoch=89
05/30/2022 11:34:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=89
05/30/2022 11:34:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.17 on epoch=90
05/30/2022 11:34:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=91
05/30/2022 11:34:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=92
05/30/2022 11:34:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=92
05/30/2022 11:34:28 - INFO - __main__ - Global step 1300 Train loss 0.16 Classification-F1 0.7394380919523236 on epoch=92
05/30/2022 11:34:31 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=93
05/30/2022 11:34:33 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=94
05/30/2022 11:34:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=94
05/30/2022 11:34:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.18 on epoch=95
05/30/2022 11:34:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=96
05/30/2022 11:34:47 - INFO - __main__ - Global step 1350 Train loss 0.14 Classification-F1 0.8669850158275205 on epoch=96
05/30/2022 11:34:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=97
05/30/2022 11:34:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=97
05/30/2022 11:34:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.16 on epoch=98
05/30/2022 11:34:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=99
05/30/2022 11:34:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=99
05/30/2022 11:35:05 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.6632982912257356 on epoch=99
05/30/2022 11:35:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=100
05/30/2022 11:35:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=101
05/30/2022 11:35:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
05/30/2022 11:35:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=102
05/30/2022 11:35:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.18 on epoch=103
05/30/2022 11:35:24 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.7830375325839036 on epoch=103
05/30/2022 11:35:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.16 on epoch=104
05/30/2022 11:35:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=104
05/30/2022 11:35:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=105
05/30/2022 11:35:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=106
05/30/2022 11:35:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=107
05/30/2022 11:35:42 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.8283082016435287 on epoch=107
05/30/2022 11:35:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
05/30/2022 11:35:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=108
05/30/2022 11:35:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=109
05/30/2022 11:35:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=109
05/30/2022 11:35:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=110
05/30/2022 11:36:01 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.6998705200555295 on epoch=110
05/30/2022 11:36:03 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=111
05/30/2022 11:36:06 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=112
05/30/2022 11:36:08 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=112
05/30/2022 11:36:11 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=113
05/30/2022 11:36:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=114
05/30/2022 11:36:19 - INFO - __main__ - Global step 1600 Train loss 0.11 Classification-F1 0.7319995039397317 on epoch=114
05/30/2022 11:36:22 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=114
05/30/2022 11:36:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.17 on epoch=115
05/30/2022 11:36:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
05/30/2022 11:36:29 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=117
05/30/2022 11:36:31 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.19 on epoch=117
05/30/2022 11:36:38 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.7752889823070648 on epoch=117
05/30/2022 11:36:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.14 on epoch=118
05/30/2022 11:36:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
05/30/2022 11:36:45 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=119
05/30/2022 11:36:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=120
05/30/2022 11:36:50 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=121
05/30/2022 11:36:56 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.7994963870201062 on epoch=121
05/30/2022 11:36:59 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
05/30/2022 11:37:01 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.12 on epoch=122
05/30/2022 11:37:04 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.15 on epoch=123
05/30/2022 11:37:06 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.11 on epoch=124
05/30/2022 11:37:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
05/30/2022 11:37:15 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.793346330251956 on epoch=124
05/30/2022 11:37:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=125
05/30/2022 11:37:19 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=126
05/30/2022 11:37:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=127
05/30/2022 11:37:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=127
05/30/2022 11:37:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=128
05/30/2022 11:37:33 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.6896789686875076 on epoch=128
05/30/2022 11:37:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=129
05/30/2022 11:37:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=129
05/30/2022 11:37:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
05/30/2022 11:37:43 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.16 on epoch=131
05/30/2022 11:37:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
05/30/2022 11:37:52 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.7032009520980109 on epoch=132
05/30/2022 11:37:55 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=132
05/30/2022 11:37:57 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=133
05/30/2022 11:38:00 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=134
05/30/2022 11:38:02 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.12 on epoch=134
05/30/2022 11:38:05 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=135
05/30/2022 11:38:11 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.6404319856769173 on epoch=135
05/30/2022 11:38:13 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=136
05/30/2022 11:38:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=137
05/30/2022 11:38:18 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=137
05/30/2022 11:38:21 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=138
05/30/2022 11:38:23 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
05/30/2022 11:38:29 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.7436736668626995 on epoch=139
05/30/2022 11:38:32 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.10 on epoch=139
05/30/2022 11:38:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=140
05/30/2022 11:38:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=141
05/30/2022 11:38:39 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
05/30/2022 11:38:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.20 on epoch=142
05/30/2022 11:38:48 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.673346196521402 on epoch=142
05/30/2022 11:38:50 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=143
05/30/2022 11:38:53 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=144
05/30/2022 11:38:55 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.09 on epoch=144
05/30/2022 11:38:58 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=145
05/30/2022 11:39:00 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=146
05/30/2022 11:39:08 - INFO - __main__ - Global step 2050 Train loss 0.09 Classification-F1 0.7107653920153919 on epoch=146
05/30/2022 11:39:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
05/30/2022 11:39:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
05/30/2022 11:39:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.11 on epoch=148
05/30/2022 11:39:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
05/30/2022 11:39:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=149
05/30/2022 11:39:27 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.6707781183163185 on epoch=149
05/30/2022 11:39:30 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
05/30/2022 11:39:32 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.14 on epoch=151
05/30/2022 11:39:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=152
05/30/2022 11:39:38 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.13 on epoch=152
05/30/2022 11:39:40 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=153
05/30/2022 11:39:46 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.7644013666072489 on epoch=153
05/30/2022 11:39:48 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.09 on epoch=154
05/30/2022 11:39:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
05/30/2022 11:39:54 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=155
05/30/2022 11:39:56 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.10 on epoch=156
05/30/2022 11:39:59 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=157
05/30/2022 11:40:06 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.8920171140031987 on epoch=157
05/30/2022 11:40:06 - INFO - __main__ - Saving model with best Classification-F1: 0.8738261114722568 -> 0.8920171140031987 on epoch=157, global_step=2200
05/30/2022 11:40:09 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.14 on epoch=157
05/30/2022 11:40:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=158
05/30/2022 11:40:14 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=159
05/30/2022 11:40:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
05/30/2022 11:40:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=160
05/30/2022 11:40:26 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.8155341625286479 on epoch=160
05/30/2022 11:40:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=161
05/30/2022 11:40:31 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=162
05/30/2022 11:40:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
05/30/2022 11:40:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.08 on epoch=163
05/30/2022 11:40:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.08 on epoch=164
05/30/2022 11:40:46 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.7962826647037173 on epoch=164
05/30/2022 11:40:49 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
05/30/2022 11:40:51 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
05/30/2022 11:40:54 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=166
05/30/2022 11:40:56 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
05/30/2022 11:40:59 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=167
05/30/2022 11:41:07 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7637758693456874 on epoch=167
05/30/2022 11:41:09 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=168
05/30/2022 11:41:12 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.13 on epoch=169
05/30/2022 11:41:14 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.08 on epoch=169
05/30/2022 11:41:17 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=170
05/30/2022 11:41:19 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.10 on epoch=171
05/30/2022 11:41:26 - INFO - __main__ - Global step 2400 Train loss 0.09 Classification-F1 0.8968747587011345 on epoch=171
05/30/2022 11:41:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8920171140031987 -> 0.8968747587011345 on epoch=171, global_step=2400
05/30/2022 11:41:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
05/30/2022 11:41:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
05/30/2022 11:41:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=173
05/30/2022 11:41:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.10 on epoch=174
05/30/2022 11:41:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=174
05/30/2022 11:41:45 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.896788054637517 on epoch=174
05/30/2022 11:41:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.07 on epoch=175
05/30/2022 11:41:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.12 on epoch=176
05/30/2022 11:41:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=177
05/30/2022 11:41:55 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=177
05/30/2022 11:41:58 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.08 on epoch=178
05/30/2022 11:42:05 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.9686835658016874 on epoch=178
05/30/2022 11:42:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8968747587011345 -> 0.9686835658016874 on epoch=178, global_step=2500
05/30/2022 11:42:07 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=179
05/30/2022 11:42:10 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
05/30/2022 11:42:12 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
05/30/2022 11:42:15 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
05/30/2022 11:42:17 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
05/30/2022 11:42:25 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.8976080771068666 on epoch=182
05/30/2022 11:42:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
05/30/2022 11:42:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.10 on epoch=183
05/30/2022 11:42:33 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=184
05/30/2022 11:42:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
05/30/2022 11:42:38 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
05/30/2022 11:42:44 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.8938894319539481 on epoch=185
05/30/2022 11:42:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
05/30/2022 11:42:49 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
05/30/2022 11:42:52 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=187
05/30/2022 11:42:54 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=188
05/30/2022 11:42:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
05/30/2022 11:43:03 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.897576116130883 on epoch=189
05/30/2022 11:43:05 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.09 on epoch=189
05/30/2022 11:43:08 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
05/30/2022 11:43:10 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=191
05/30/2022 11:43:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
05/30/2022 11:43:15 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=192
05/30/2022 11:43:22 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.9641464531509845 on epoch=192
05/30/2022 11:43:24 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.09 on epoch=193
05/30/2022 11:43:27 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.12 on epoch=194
05/30/2022 11:43:29 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
05/30/2022 11:43:32 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=195
05/30/2022 11:43:34 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=196
05/30/2022 11:43:41 - INFO - __main__ - Global step 2750 Train loss 0.08 Classification-F1 0.7822816399286987 on epoch=196
05/30/2022 11:43:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
05/30/2022 11:43:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=197
05/30/2022 11:43:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
05/30/2022 11:43:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.10 on epoch=199
05/30/2022 11:43:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=199
05/30/2022 11:44:01 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.8788684774007355 on epoch=199
05/30/2022 11:44:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
05/30/2022 11:44:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.08 on epoch=201
05/30/2022 11:44:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
05/30/2022 11:44:11 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
05/30/2022 11:44:14 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.09 on epoch=203
05/30/2022 11:44:21 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.8765156945802107 on epoch=203
05/30/2022 11:44:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.07 on epoch=204
05/30/2022 11:44:26 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
05/30/2022 11:44:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=205
05/30/2022 11:44:31 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=206
05/30/2022 11:44:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
05/30/2022 11:44:40 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.7238149715735105 on epoch=207
05/30/2022 11:44:42 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
05/30/2022 11:44:45 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
05/30/2022 11:44:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=209
05/30/2022 11:44:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
05/30/2022 11:44:52 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
05/30/2022 11:44:59 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7844894580621224 on epoch=210
05/30/2022 11:45:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
05/30/2022 11:45:04 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
05/30/2022 11:45:06 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=212
05/30/2022 11:45:09 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=213
05/30/2022 11:45:11 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=214
05/30/2022 11:45:13 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 11:45:13 - INFO - __main__ - Printing 3 examples
05/30/2022 11:45:13 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/30/2022 11:45:13 - INFO - __main__ - ['Plant']
05/30/2022 11:45:13 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/30/2022 11:45:13 - INFO - __main__ - ['Plant']
05/30/2022 11:45:13 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/30/2022 11:45:13 - INFO - __main__ - ['Plant']
05/30/2022 11:45:13 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:45:13 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:45:13 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 11:45:13 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 11:45:13 - INFO - __main__ - Printing 3 examples
05/30/2022 11:45:13 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/30/2022 11:45:13 - INFO - __main__ - ['Plant']
05/30/2022 11:45:13 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/30/2022 11:45:13 - INFO - __main__ - ['Plant']
05/30/2022 11:45:13 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/30/2022 11:45:13 - INFO - __main__ - ['Plant']
05/30/2022 11:45:13 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:45:13 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:45:13 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 11:45:18 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.897576116130883 on epoch=214
05/30/2022 11:45:18 - INFO - __main__ - save last model!
05/30/2022 11:45:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 11:45:18 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 11:45:18 - INFO - __main__ - Printing 3 examples
05/30/2022 11:45:18 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 11:45:18 - INFO - __main__ - ['Animal']
05/30/2022 11:45:18 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 11:45:18 - INFO - __main__ - ['Animal']
05/30/2022 11:45:18 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 11:45:18 - INFO - __main__ - ['Village']
05/30/2022 11:45:18 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:45:20 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:45:24 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 11:45:28 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 11:45:28 - INFO - __main__ - task name: dbpedia_14
05/30/2022 11:45:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 11:45:28 - INFO - __main__ - Starting training!
05/30/2022 11:47:38 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
05/30/2022 11:47:38 - INFO - __main__ - Classification-F1 on test data: 0.7134
05/30/2022 11:47:39 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.9686835658016874, test_performance=0.7133914296720016
05/30/2022 11:47:39 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
05/30/2022 11:47:40 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 11:47:40 - INFO - __main__ - Printing 3 examples
05/30/2022 11:47:40 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/30/2022 11:47:40 - INFO - __main__ - ['Plant']
05/30/2022 11:47:40 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/30/2022 11:47:40 - INFO - __main__ - ['Plant']
05/30/2022 11:47:40 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/30/2022 11:47:40 - INFO - __main__ - ['Plant']
05/30/2022 11:47:40 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:47:40 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:47:40 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 11:47:40 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 11:47:40 - INFO - __main__ - Printing 3 examples
05/30/2022 11:47:40 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/30/2022 11:47:40 - INFO - __main__ - ['Plant']
05/30/2022 11:47:40 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/30/2022 11:47:40 - INFO - __main__ - ['Plant']
05/30/2022 11:47:40 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/30/2022 11:47:40 - INFO - __main__ - ['Plant']
05/30/2022 11:47:40 - INFO - __main__ - Tokenizing Input ...
05/30/2022 11:47:40 - INFO - __main__ - Tokenizing Output ...
05/30/2022 11:47:41 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 11:47:55 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 11:47:55 - INFO - __main__ - task name: dbpedia_14
05/30/2022 11:47:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 11:47:56 - INFO - __main__ - Starting training!
05/30/2022 11:47:59 - INFO - __main__ - Step 10 Global step 10 Train loss 7.32 on epoch=0
05/30/2022 11:48:02 - INFO - __main__ - Step 20 Global step 20 Train loss 6.76 on epoch=1
05/30/2022 11:48:04 - INFO - __main__ - Step 30 Global step 30 Train loss 6.40 on epoch=2
05/30/2022 11:48:07 - INFO - __main__ - Step 40 Global step 40 Train loss 5.74 on epoch=2
05/30/2022 11:48:09 - INFO - __main__ - Step 50 Global step 50 Train loss 5.20 on epoch=3
05/30/2022 11:49:55 - INFO - __main__ - Global step 50 Train loss 6.29 Classification-F1 0.0 on epoch=3
05/30/2022 11:49:55 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/30/2022 11:49:58 - INFO - __main__ - Step 60 Global step 60 Train loss 4.52 on epoch=4
05/30/2022 11:50:00 - INFO - __main__ - Step 70 Global step 70 Train loss 3.81 on epoch=4
05/30/2022 11:50:03 - INFO - __main__ - Step 80 Global step 80 Train loss 3.30 on epoch=5
05/30/2022 11:50:05 - INFO - __main__ - Step 90 Global step 90 Train loss 2.98 on epoch=6
05/30/2022 11:50:08 - INFO - __main__ - Step 100 Global step 100 Train loss 2.79 on epoch=7
05/30/2022 11:50:50 - INFO - __main__ - Global step 100 Train loss 3.48 Classification-F1 0.050239065853209995 on epoch=7
05/30/2022 11:50:50 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.050239065853209995 on epoch=7, global_step=100
05/30/2022 11:50:52 - INFO - __main__ - Step 110 Global step 110 Train loss 2.51 on epoch=7
05/30/2022 11:50:55 - INFO - __main__ - Step 120 Global step 120 Train loss 2.33 on epoch=8
05/30/2022 11:50:57 - INFO - __main__ - Step 130 Global step 130 Train loss 2.27 on epoch=9
05/30/2022 11:51:00 - INFO - __main__ - Step 140 Global step 140 Train loss 2.15 on epoch=9
05/30/2022 11:51:02 - INFO - __main__ - Step 150 Global step 150 Train loss 1.91 on epoch=10
05/30/2022 11:51:15 - INFO - __main__ - Global step 150 Train loss 2.23 Classification-F1 0.18384797576034725 on epoch=10
05/30/2022 11:51:15 - INFO - __main__ - Saving model with best Classification-F1: 0.050239065853209995 -> 0.18384797576034725 on epoch=10, global_step=150
05/30/2022 11:51:17 - INFO - __main__ - Step 160 Global step 160 Train loss 1.86 on epoch=11
05/30/2022 11:51:20 - INFO - __main__ - Step 170 Global step 170 Train loss 1.65 on epoch=12
05/30/2022 11:51:22 - INFO - __main__ - Step 180 Global step 180 Train loss 1.66 on epoch=12
05/30/2022 11:51:25 - INFO - __main__ - Step 190 Global step 190 Train loss 1.66 on epoch=13
05/30/2022 11:51:27 - INFO - __main__ - Step 200 Global step 200 Train loss 1.54 on epoch=14
05/30/2022 11:51:35 - INFO - __main__ - Global step 200 Train loss 1.68 Classification-F1 0.23229125190339553 on epoch=14
05/30/2022 11:51:36 - INFO - __main__ - Saving model with best Classification-F1: 0.18384797576034725 -> 0.23229125190339553 on epoch=14, global_step=200
05/30/2022 11:51:38 - INFO - __main__ - Step 210 Global step 210 Train loss 1.61 on epoch=14
05/30/2022 11:51:41 - INFO - __main__ - Step 220 Global step 220 Train loss 1.44 on epoch=15
05/30/2022 11:51:43 - INFO - __main__ - Step 230 Global step 230 Train loss 1.44 on epoch=16
05/30/2022 11:51:46 - INFO - __main__ - Step 240 Global step 240 Train loss 1.34 on epoch=17
05/30/2022 11:51:48 - INFO - __main__ - Step 250 Global step 250 Train loss 1.28 on epoch=17
05/30/2022 11:51:53 - INFO - __main__ - Global step 250 Train loss 1.42 Classification-F1 0.2530932225023776 on epoch=17
05/30/2022 11:51:53 - INFO - __main__ - Saving model with best Classification-F1: 0.23229125190339553 -> 0.2530932225023776 on epoch=17, global_step=250
05/30/2022 11:51:55 - INFO - __main__ - Step 260 Global step 260 Train loss 1.10 on epoch=18
05/30/2022 11:51:58 - INFO - __main__ - Step 270 Global step 270 Train loss 1.29 on epoch=19
05/30/2022 11:52:01 - INFO - __main__ - Step 280 Global step 280 Train loss 1.25 on epoch=19
05/30/2022 11:52:03 - INFO - __main__ - Step 290 Global step 290 Train loss 1.20 on epoch=20
05/30/2022 11:52:06 - INFO - __main__ - Step 300 Global step 300 Train loss 1.07 on epoch=21
05/30/2022 11:52:20 - INFO - __main__ - Global step 300 Train loss 1.18 Classification-F1 0.33386230377913717 on epoch=21
05/30/2022 11:52:20 - INFO - __main__ - Saving model with best Classification-F1: 0.2530932225023776 -> 0.33386230377913717 on epoch=21, global_step=300
05/30/2022 11:52:23 - INFO - __main__ - Step 310 Global step 310 Train loss 1.01 on epoch=22
05/30/2022 11:52:25 - INFO - __main__ - Step 320 Global step 320 Train loss 0.99 on epoch=22
05/30/2022 11:52:28 - INFO - __main__ - Step 330 Global step 330 Train loss 1.01 on epoch=23
05/30/2022 11:52:30 - INFO - __main__ - Step 340 Global step 340 Train loss 1.09 on epoch=24
05/30/2022 11:52:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.93 on epoch=24
05/30/2022 11:52:38 - INFO - __main__ - Global step 350 Train loss 1.01 Classification-F1 0.3754362678221896 on epoch=24
05/30/2022 11:52:38 - INFO - __main__ - Saving model with best Classification-F1: 0.33386230377913717 -> 0.3754362678221896 on epoch=24, global_step=350
05/30/2022 11:52:41 - INFO - __main__ - Step 360 Global step 360 Train loss 1.03 on epoch=25
05/30/2022 11:52:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.82 on epoch=26
05/30/2022 11:52:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.88 on epoch=27
05/30/2022 11:52:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.84 on epoch=27
05/30/2022 11:52:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.88 on epoch=28
05/30/2022 11:52:57 - INFO - __main__ - Global step 400 Train loss 0.89 Classification-F1 0.3874357908329346 on epoch=28
05/30/2022 11:52:57 - INFO - __main__ - Saving model with best Classification-F1: 0.3754362678221896 -> 0.3874357908329346 on epoch=28, global_step=400
05/30/2022 11:52:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.81 on epoch=29
05/30/2022 11:53:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.85 on epoch=29
05/30/2022 11:53:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.87 on epoch=30
05/30/2022 11:53:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.81 on epoch=31
05/30/2022 11:53:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.75 on epoch=32
05/30/2022 11:53:16 - INFO - __main__ - Global step 450 Train loss 0.82 Classification-F1 0.4808876381401043 on epoch=32
05/30/2022 11:53:16 - INFO - __main__ - Saving model with best Classification-F1: 0.3874357908329346 -> 0.4808876381401043 on epoch=32, global_step=450
05/30/2022 11:53:19 - INFO - __main__ - Step 460 Global step 460 Train loss 0.80 on epoch=32
05/30/2022 11:53:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.73 on epoch=33
05/30/2022 11:53:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.74 on epoch=34
05/30/2022 11:53:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.73 on epoch=34
05/30/2022 11:53:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.72 on epoch=35
05/30/2022 11:53:35 - INFO - __main__ - Global step 500 Train loss 0.75 Classification-F1 0.5580525765869818 on epoch=35
05/30/2022 11:53:35 - INFO - __main__ - Saving model with best Classification-F1: 0.4808876381401043 -> 0.5580525765869818 on epoch=35, global_step=500
05/30/2022 11:53:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.74 on epoch=36
05/30/2022 11:53:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.74 on epoch=37
05/30/2022 11:53:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.74 on epoch=37
05/30/2022 11:53:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.60 on epoch=38
05/30/2022 11:53:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.73 on epoch=39
05/30/2022 11:53:54 - INFO - __main__ - Global step 550 Train loss 0.71 Classification-F1 0.4668718615704453 on epoch=39
05/30/2022 11:53:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.69 on epoch=39
05/30/2022 11:53:59 - INFO - __main__ - Step 570 Global step 570 Train loss 0.70 on epoch=40
05/30/2022 11:54:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.62 on epoch=41
05/30/2022 11:54:04 - INFO - __main__ - Step 590 Global step 590 Train loss 0.63 on epoch=42
05/30/2022 11:54:07 - INFO - __main__ - Step 600 Global step 600 Train loss 0.65 on epoch=42
05/30/2022 11:54:13 - INFO - __main__ - Global step 600 Train loss 0.66 Classification-F1 0.5525423594680285 on epoch=42
05/30/2022 11:54:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.60 on epoch=43
05/30/2022 11:54:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.55 on epoch=44
05/30/2022 11:54:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.52 on epoch=44
05/30/2022 11:54:23 - INFO - __main__ - Step 640 Global step 640 Train loss 0.61 on epoch=45
05/30/2022 11:54:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.54 on epoch=46
05/30/2022 11:54:32 - INFO - __main__ - Global step 650 Train loss 0.56 Classification-F1 0.5346111788722677 on epoch=46
05/30/2022 11:54:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.58 on epoch=47
05/30/2022 11:54:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.58 on epoch=47
05/30/2022 11:54:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.48 on epoch=48
05/30/2022 11:54:42 - INFO - __main__ - Step 690 Global step 690 Train loss 0.53 on epoch=49
05/30/2022 11:54:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.47 on epoch=49
05/30/2022 11:54:52 - INFO - __main__ - Global step 700 Train loss 0.53 Classification-F1 0.6101138313362422 on epoch=49
05/30/2022 11:54:52 - INFO - __main__ - Saving model with best Classification-F1: 0.5580525765869818 -> 0.6101138313362422 on epoch=49, global_step=700
05/30/2022 11:54:54 - INFO - __main__ - Step 710 Global step 710 Train loss 0.47 on epoch=50
05/30/2022 11:54:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.52 on epoch=51
05/30/2022 11:54:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.54 on epoch=52
05/30/2022 11:55:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.57 on epoch=52
05/30/2022 11:55:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.51 on epoch=53
05/30/2022 11:55:11 - INFO - __main__ - Global step 750 Train loss 0.52 Classification-F1 0.544719462372347 on epoch=53
05/30/2022 11:55:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.50 on epoch=54
05/30/2022 11:55:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.43 on epoch=54
05/30/2022 11:55:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.50 on epoch=55
05/30/2022 11:55:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.41 on epoch=56
05/30/2022 11:55:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.51 on epoch=57
05/30/2022 11:55:30 - INFO - __main__ - Global step 800 Train loss 0.47 Classification-F1 0.6482522717242485 on epoch=57
05/30/2022 11:55:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6101138313362422 -> 0.6482522717242485 on epoch=57, global_step=800
05/30/2022 11:55:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.50 on epoch=57
05/30/2022 11:55:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.44 on epoch=58
05/30/2022 11:55:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.44 on epoch=59
05/30/2022 11:55:40 - INFO - __main__ - Step 840 Global step 840 Train loss 0.44 on epoch=59
05/30/2022 11:55:43 - INFO - __main__ - Step 850 Global step 850 Train loss 0.42 on epoch=60
05/30/2022 11:55:49 - INFO - __main__ - Global step 850 Train loss 0.45 Classification-F1 0.6980061023969866 on epoch=60
05/30/2022 11:55:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6482522717242485 -> 0.6980061023969866 on epoch=60, global_step=850
05/30/2022 11:55:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.51 on epoch=61
05/30/2022 11:55:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.48 on epoch=62
05/30/2022 11:55:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.42 on epoch=62
05/30/2022 11:55:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.41 on epoch=63
05/30/2022 11:56:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.49 on epoch=64
05/30/2022 11:56:08 - INFO - __main__ - Global step 900 Train loss 0.46 Classification-F1 0.6981295601537817 on epoch=64
05/30/2022 11:56:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6980061023969866 -> 0.6981295601537817 on epoch=64, global_step=900
05/30/2022 11:56:11 - INFO - __main__ - Step 910 Global step 910 Train loss 0.43 on epoch=64
05/30/2022 11:56:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.40 on epoch=65
05/30/2022 11:56:16 - INFO - __main__ - Step 930 Global step 930 Train loss 0.35 on epoch=66
05/30/2022 11:56:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.37 on epoch=67
05/30/2022 11:56:21 - INFO - __main__ - Step 950 Global step 950 Train loss 0.38 on epoch=67
05/30/2022 11:56:27 - INFO - __main__ - Global step 950 Train loss 0.39 Classification-F1 0.754821654040404 on epoch=67
05/30/2022 11:56:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6981295601537817 -> 0.754821654040404 on epoch=67, global_step=950
05/30/2022 11:56:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.32 on epoch=68
05/30/2022 11:56:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.40 on epoch=69
05/30/2022 11:56:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.50 on epoch=69
05/30/2022 11:56:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.35 on epoch=70
05/30/2022 11:56:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.39 on epoch=71
05/30/2022 11:56:46 - INFO - __main__ - Global step 1000 Train loss 0.39 Classification-F1 0.7966262982701615 on epoch=71
05/30/2022 11:56:46 - INFO - __main__ - Saving model with best Classification-F1: 0.754821654040404 -> 0.7966262982701615 on epoch=71, global_step=1000
05/30/2022 11:56:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.33 on epoch=72
05/30/2022 11:56:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.36 on epoch=72
05/30/2022 11:56:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.32 on epoch=73
05/30/2022 11:56:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.36 on epoch=74
05/30/2022 11:56:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.37 on epoch=74
05/30/2022 11:57:05 - INFO - __main__ - Global step 1050 Train loss 0.35 Classification-F1 0.7516598377057977 on epoch=74
05/30/2022 11:57:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.35 on epoch=75
05/30/2022 11:57:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.35 on epoch=76
05/30/2022 11:57:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.39 on epoch=77
05/30/2022 11:57:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.28 on epoch=77
05/30/2022 11:57:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=78
05/30/2022 11:57:24 - INFO - __main__ - Global step 1100 Train loss 0.33 Classification-F1 0.7803363940618053 on epoch=78
05/30/2022 11:57:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.28 on epoch=79
05/30/2022 11:57:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.28 on epoch=79
05/30/2022 11:57:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.36 on epoch=80
05/30/2022 11:57:34 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.32 on epoch=81
05/30/2022 11:57:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.27 on epoch=82
05/30/2022 11:57:43 - INFO - __main__ - Global step 1150 Train loss 0.30 Classification-F1 0.8600764052061388 on epoch=82
05/30/2022 11:57:43 - INFO - __main__ - Saving model with best Classification-F1: 0.7966262982701615 -> 0.8600764052061388 on epoch=82, global_step=1150
05/30/2022 11:57:46 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.31 on epoch=82
05/30/2022 11:57:48 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.33 on epoch=83
05/30/2022 11:57:51 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.30 on epoch=84
05/30/2022 11:57:53 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.31 on epoch=84
05/30/2022 11:57:56 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=85
05/30/2022 11:58:02 - INFO - __main__ - Global step 1200 Train loss 0.29 Classification-F1 0.8155032027593004 on epoch=85
05/30/2022 11:58:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.28 on epoch=86
05/30/2022 11:58:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.28 on epoch=87
05/30/2022 11:58:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.29 on epoch=87
05/30/2022 11:58:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.27 on epoch=88
05/30/2022 11:58:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.33 on epoch=89
05/30/2022 11:58:21 - INFO - __main__ - Global step 1250 Train loss 0.29 Classification-F1 0.8003298435698816 on epoch=89
05/30/2022 11:58:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.31 on epoch=89
05/30/2022 11:58:26 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.27 on epoch=90
05/30/2022 11:58:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.23 on epoch=91
05/30/2022 11:58:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.28 on epoch=92
05/30/2022 11:58:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.28 on epoch=92
05/30/2022 11:58:41 - INFO - __main__ - Global step 1300 Train loss 0.27 Classification-F1 0.716346272414289 on epoch=92
05/30/2022 11:58:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.22 on epoch=93
05/30/2022 11:58:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.29 on epoch=94
05/30/2022 11:58:48 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.18 on epoch=94
05/30/2022 11:58:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.25 on epoch=95
05/30/2022 11:58:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.36 on epoch=96
05/30/2022 11:59:00 - INFO - __main__ - Global step 1350 Train loss 0.26 Classification-F1 0.7101029583258937 on epoch=96
05/30/2022 11:59:02 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.18 on epoch=97
05/30/2022 11:59:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.25 on epoch=97
05/30/2022 11:59:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.19 on epoch=98
05/30/2022 11:59:10 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.27 on epoch=99
05/30/2022 11:59:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.20 on epoch=99
05/30/2022 11:59:19 - INFO - __main__ - Global step 1400 Train loss 0.22 Classification-F1 0.7444875978892532 on epoch=99
05/30/2022 11:59:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.19 on epoch=100
05/30/2022 11:59:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.22 on epoch=101
05/30/2022 11:59:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.21 on epoch=102
05/30/2022 11:59:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.30 on epoch=102
05/30/2022 11:59:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.22 on epoch=103
05/30/2022 11:59:38 - INFO - __main__ - Global step 1450 Train loss 0.22 Classification-F1 0.8047510429353097 on epoch=103
05/30/2022 11:59:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.18 on epoch=104
05/30/2022 11:59:44 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.18 on epoch=104
05/30/2022 11:59:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.19 on epoch=105
05/30/2022 11:59:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.17 on epoch=106
05/30/2022 11:59:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.15 on epoch=107
05/30/2022 11:59:59 - INFO - __main__ - Global step 1500 Train loss 0.17 Classification-F1 0.7820413991499415 on epoch=107
05/30/2022 12:00:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.23 on epoch=107
05/30/2022 12:00:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.32 on epoch=108
05/30/2022 12:00:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=109
05/30/2022 12:00:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.18 on epoch=109
05/30/2022 12:00:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.14 on epoch=110
05/30/2022 12:00:19 - INFO - __main__ - Global step 1550 Train loss 0.21 Classification-F1 0.613772520487584 on epoch=110
05/30/2022 12:00:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.17 on epoch=111
05/30/2022 12:00:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=112
05/30/2022 12:00:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.20 on epoch=112
05/30/2022 12:00:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.23 on epoch=113
05/30/2022 12:00:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.19 on epoch=114
05/30/2022 12:00:38 - INFO - __main__ - Global step 1600 Train loss 0.18 Classification-F1 0.7128400353105042 on epoch=114
05/30/2022 12:00:41 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.15 on epoch=114
05/30/2022 12:00:43 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.28 on epoch=115
05/30/2022 12:00:46 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.18 on epoch=116
05/30/2022 12:00:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.15 on epoch=117
05/30/2022 12:00:51 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.21 on epoch=117
05/30/2022 12:00:59 - INFO - __main__ - Global step 1650 Train loss 0.20 Classification-F1 0.8854827688651218 on epoch=117
05/30/2022 12:00:59 - INFO - __main__ - Saving model with best Classification-F1: 0.8600764052061388 -> 0.8854827688651218 on epoch=117, global_step=1650
05/30/2022 12:01:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.18 on epoch=118
05/30/2022 12:01:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.19 on epoch=119
05/30/2022 12:01:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=119
05/30/2022 12:01:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.16 on epoch=120
05/30/2022 12:01:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.17 on epoch=121
05/30/2022 12:01:18 - INFO - __main__ - Global step 1700 Train loss 0.17 Classification-F1 0.8097566639591581 on epoch=121
05/30/2022 12:01:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.12 on epoch=122
05/30/2022 12:01:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.14 on epoch=122
05/30/2022 12:01:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.19 on epoch=123
05/30/2022 12:01:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.15 on epoch=124
05/30/2022 12:01:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.18 on epoch=124
05/30/2022 12:01:37 - INFO - __main__ - Global step 1750 Train loss 0.16 Classification-F1 0.7954366490509079 on epoch=124
05/30/2022 12:01:40 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=125
05/30/2022 12:01:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=126
05/30/2022 12:01:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=127
05/30/2022 12:01:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=127
05/30/2022 12:01:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.15 on epoch=128
05/30/2022 12:01:57 - INFO - __main__ - Global step 1800 Train loss 0.12 Classification-F1 0.771567655007492 on epoch=128
05/30/2022 12:02:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.22 on epoch=129
05/30/2022 12:02:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.13 on epoch=129
05/30/2022 12:02:05 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.12 on epoch=130
05/30/2022 12:02:07 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=131
05/30/2022 12:02:10 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.11 on epoch=132
05/30/2022 12:02:17 - INFO - __main__ - Global step 1850 Train loss 0.14 Classification-F1 0.8488918927174975 on epoch=132
05/30/2022 12:02:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.13 on epoch=132
05/30/2022 12:02:22 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=133
05/30/2022 12:02:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.18 on epoch=134
05/30/2022 12:02:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.18 on epoch=134
05/30/2022 12:02:30 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=135
05/30/2022 12:02:37 - INFO - __main__ - Global step 1900 Train loss 0.14 Classification-F1 0.8239837634658607 on epoch=135
05/30/2022 12:02:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.13 on epoch=136
05/30/2022 12:02:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.13 on epoch=137
05/30/2022 12:02:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.11 on epoch=137
05/30/2022 12:02:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.12 on epoch=138
05/30/2022 12:02:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.11 on epoch=139
05/30/2022 12:02:57 - INFO - __main__ - Global step 1950 Train loss 0.12 Classification-F1 0.8889555229716518 on epoch=139
05/30/2022 12:02:57 - INFO - __main__ - Saving model with best Classification-F1: 0.8854827688651218 -> 0.8889555229716518 on epoch=139, global_step=1950
05/30/2022 12:03:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.14 on epoch=139
05/30/2022 12:03:02 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.14 on epoch=140
05/30/2022 12:03:05 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.18 on epoch=141
05/30/2022 12:03:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.13 on epoch=142
05/30/2022 12:03:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.13 on epoch=142
05/30/2022 12:03:17 - INFO - __main__ - Global step 2000 Train loss 0.14 Classification-F1 0.8375714892318309 on epoch=142
05/30/2022 12:03:20 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=143
05/30/2022 12:03:22 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.13 on epoch=144
05/30/2022 12:03:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.15 on epoch=144
05/30/2022 12:03:27 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=145
05/30/2022 12:03:30 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=146
05/30/2022 12:03:37 - INFO - __main__ - Global step 2050 Train loss 0.11 Classification-F1 0.8905869209854029 on epoch=146
05/30/2022 12:03:37 - INFO - __main__ - Saving model with best Classification-F1: 0.8889555229716518 -> 0.8905869209854029 on epoch=146, global_step=2050
05/30/2022 12:03:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.12 on epoch=147
05/30/2022 12:03:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=147
05/30/2022 12:03:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.13 on epoch=148
05/30/2022 12:03:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.19 on epoch=149
05/30/2022 12:03:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=149
05/30/2022 12:03:57 - INFO - __main__ - Global step 2100 Train loss 0.12 Classification-F1 0.8773324914138378 on epoch=149
05/30/2022 12:04:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=150
05/30/2022 12:04:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.10 on epoch=151
05/30/2022 12:04:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=152
05/30/2022 12:04:07 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=152
05/30/2022 12:04:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.11 on epoch=153
05/30/2022 12:04:17 - INFO - __main__ - Global step 2150 Train loss 0.09 Classification-F1 0.8300231830070539 on epoch=153
05/30/2022 12:04:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.29 on epoch=154
05/30/2022 12:04:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.18 on epoch=154
05/30/2022 12:04:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.15 on epoch=155
05/30/2022 12:04:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.18 on epoch=156
05/30/2022 12:04:30 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=157
05/30/2022 12:04:36 - INFO - __main__ - Global step 2200 Train loss 0.18 Classification-F1 0.7740782963701865 on epoch=157
05/30/2022 12:04:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.14 on epoch=157
05/30/2022 12:04:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.14 on epoch=158
05/30/2022 12:04:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.14 on epoch=159
05/30/2022 12:04:46 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.10 on epoch=159
05/30/2022 12:04:49 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.13 on epoch=160
05/30/2022 12:04:55 - INFO - __main__ - Global step 2250 Train loss 0.13 Classification-F1 0.747995675509907 on epoch=160
05/30/2022 12:04:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.11 on epoch=161
05/30/2022 12:05:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.11 on epoch=162
05/30/2022 12:05:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=162
05/30/2022 12:05:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.15 on epoch=163
05/30/2022 12:05:08 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.13 on epoch=164
05/30/2022 12:05:14 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.8283983505425631 on epoch=164
05/30/2022 12:05:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.12 on epoch=164
05/30/2022 12:05:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.15 on epoch=165
05/30/2022 12:05:22 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.12 on epoch=166
05/30/2022 12:05:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.08 on epoch=167
05/30/2022 12:05:27 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=167
05/30/2022 12:05:33 - INFO - __main__ - Global step 2350 Train loss 0.11 Classification-F1 0.7662838742535139 on epoch=167
05/30/2022 12:05:36 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.13 on epoch=168
05/30/2022 12:05:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.13 on epoch=169
05/30/2022 12:05:41 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.08 on epoch=169
05/30/2022 12:05:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.11 on epoch=170
05/30/2022 12:05:46 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=171
05/30/2022 12:05:53 - INFO - __main__ - Global step 2400 Train loss 0.11 Classification-F1 0.8917460227944097 on epoch=171
05/30/2022 12:05:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8905869209854029 -> 0.8917460227944097 on epoch=171, global_step=2400
05/30/2022 12:05:55 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=172
05/30/2022 12:05:58 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=172
05/30/2022 12:06:00 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.13 on epoch=173
05/30/2022 12:06:03 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.10 on epoch=174
05/30/2022 12:06:06 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.10 on epoch=174
05/30/2022 12:06:13 - INFO - __main__ - Global step 2450 Train loss 0.09 Classification-F1 0.873906292526786 on epoch=174
05/30/2022 12:06:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.11 on epoch=175
05/30/2022 12:06:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.14 on epoch=176
05/30/2022 12:06:21 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.10 on epoch=177
05/30/2022 12:06:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.10 on epoch=177
05/30/2022 12:06:26 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.08 on epoch=178
05/30/2022 12:06:32 - INFO - __main__ - Global step 2500 Train loss 0.11 Classification-F1 0.8033936185988518 on epoch=178
05/30/2022 12:06:35 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=179
05/30/2022 12:06:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=179
05/30/2022 12:06:40 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.11 on epoch=180
05/30/2022 12:06:42 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=181
05/30/2022 12:06:45 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=182
05/30/2022 12:06:52 - INFO - __main__ - Global step 2550 Train loss 0.09 Classification-F1 0.8868910205928603 on epoch=182
05/30/2022 12:06:54 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=182
05/30/2022 12:06:57 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=183
05/30/2022 12:07:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
05/30/2022 12:07:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
05/30/2022 12:07:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.11 on epoch=185
05/30/2022 12:07:11 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.8353531280547409 on epoch=185
05/30/2022 12:07:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=186
05/30/2022 12:07:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.11 on epoch=187
05/30/2022 12:07:19 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.14 on epoch=187
05/30/2022 12:07:21 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=188
05/30/2022 12:07:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.10 on epoch=189
05/30/2022 12:07:30 - INFO - __main__ - Global step 2650 Train loss 0.10 Classification-F1 0.897835562040234 on epoch=189
05/30/2022 12:07:30 - INFO - __main__ - Saving model with best Classification-F1: 0.8917460227944097 -> 0.897835562040234 on epoch=189, global_step=2650
05/30/2022 12:07:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=189
05/30/2022 12:07:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.11 on epoch=190
05/30/2022 12:07:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=191
05/30/2022 12:07:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.09 on epoch=192
05/30/2022 12:07:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=192
05/30/2022 12:07:49 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.8982443792766373 on epoch=192
05/30/2022 12:07:49 - INFO - __main__ - Saving model with best Classification-F1: 0.897835562040234 -> 0.8982443792766373 on epoch=192, global_step=2700
05/30/2022 12:07:52 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.07 on epoch=193
05/30/2022 12:07:54 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.11 on epoch=194
05/30/2022 12:07:57 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.11 on epoch=194
05/30/2022 12:08:00 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.08 on epoch=195
05/30/2022 12:08:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=196
05/30/2022 12:08:09 - INFO - __main__ - Global step 2750 Train loss 0.09 Classification-F1 0.8387745906647116 on epoch=196
05/30/2022 12:08:11 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=197
05/30/2022 12:08:14 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
05/30/2022 12:08:16 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=198
05/30/2022 12:08:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.09 on epoch=199
05/30/2022 12:08:21 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.08 on epoch=199
05/30/2022 12:08:27 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.8412479598200661 on epoch=199
05/30/2022 12:08:30 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.11 on epoch=200
05/30/2022 12:08:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.10 on epoch=201
05/30/2022 12:08:35 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.11 on epoch=202
05/30/2022 12:08:37 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.09 on epoch=202
05/30/2022 12:08:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.15 on epoch=203
05/30/2022 12:08:46 - INFO - __main__ - Global step 2850 Train loss 0.11 Classification-F1 0.9100144942191659 on epoch=203
05/30/2022 12:08:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8982443792766373 -> 0.9100144942191659 on epoch=203, global_step=2850
05/30/2022 12:08:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.11 on epoch=204
05/30/2022 12:08:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=204
05/30/2022 12:08:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.07 on epoch=205
05/30/2022 12:08:56 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=206
05/30/2022 12:08:59 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.07 on epoch=207
05/30/2022 12:09:05 - INFO - __main__ - Global step 2900 Train loss 0.08 Classification-F1 0.9686835658016874 on epoch=207
05/30/2022 12:09:05 - INFO - __main__ - Saving model with best Classification-F1: 0.9100144942191659 -> 0.9686835658016874 on epoch=207, global_step=2900
05/30/2022 12:09:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.09 on epoch=207
05/30/2022 12:09:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.09 on epoch=208
05/30/2022 12:09:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=209
05/30/2022 12:09:16 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.09 on epoch=209
05/30/2022 12:09:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=210
05/30/2022 12:09:25 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.8271397561957334 on epoch=210
05/30/2022 12:09:27 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.09 on epoch=211
05/30/2022 12:09:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.15 on epoch=212
05/30/2022 12:09:32 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
05/30/2022 12:09:35 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.12 on epoch=213
05/30/2022 12:09:38 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.07 on epoch=214
05/30/2022 12:09:39 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 12:09:39 - INFO - __main__ - Printing 3 examples
05/30/2022 12:09:39 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/30/2022 12:09:39 - INFO - __main__ - ['Company']
05/30/2022 12:09:39 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/30/2022 12:09:39 - INFO - __main__ - ['Company']
05/30/2022 12:09:39 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/30/2022 12:09:39 - INFO - __main__ - ['Company']
05/30/2022 12:09:39 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:09:39 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:09:39 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 12:09:39 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 12:09:39 - INFO - __main__ - Printing 3 examples
05/30/2022 12:09:39 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/30/2022 12:09:39 - INFO - __main__ - ['Company']
05/30/2022 12:09:39 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/30/2022 12:09:39 - INFO - __main__ - ['Company']
05/30/2022 12:09:39 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/30/2022 12:09:39 - INFO - __main__ - ['Company']
05/30/2022 12:09:39 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:09:39 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:09:39 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 12:09:44 - INFO - __main__ - Global step 3000 Train loss 0.09 Classification-F1 0.9103160638644511 on epoch=214
05/30/2022 12:09:44 - INFO - __main__ - save last model!
05/30/2022 12:09:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 12:09:44 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 12:09:44 - INFO - __main__ - Printing 3 examples
05/30/2022 12:09:44 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 12:09:44 - INFO - __main__ - ['Animal']
05/30/2022 12:09:44 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 12:09:44 - INFO - __main__ - ['Animal']
05/30/2022 12:09:44 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 12:09:44 - INFO - __main__ - ['Village']
05/30/2022 12:09:44 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:09:46 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:09:49 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 12:09:58 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 12:09:58 - INFO - __main__ - task name: dbpedia_14
05/30/2022 12:09:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 12:09:59 - INFO - __main__ - Starting training!
05/30/2022 12:11:56 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
05/30/2022 12:11:56 - INFO - __main__ - Classification-F1 on test data: 0.5660
05/30/2022 12:11:57 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.9686835658016874, test_performance=0.5660113372768006
05/30/2022 12:11:57 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
05/30/2022 12:11:58 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 12:11:58 - INFO - __main__ - Printing 3 examples
05/30/2022 12:11:58 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/30/2022 12:11:58 - INFO - __main__ - ['Company']
05/30/2022 12:11:58 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/30/2022 12:11:58 - INFO - __main__ - ['Company']
05/30/2022 12:11:58 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/30/2022 12:11:58 - INFO - __main__ - ['Company']
05/30/2022 12:11:58 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:11:58 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:11:58 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 12:11:58 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 12:11:58 - INFO - __main__ - Printing 3 examples
05/30/2022 12:11:58 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/30/2022 12:11:58 - INFO - __main__ - ['Company']
05/30/2022 12:11:58 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/30/2022 12:11:58 - INFO - __main__ - ['Company']
05/30/2022 12:11:58 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/30/2022 12:11:58 - INFO - __main__ - ['Company']
05/30/2022 12:11:58 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:11:58 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:11:58 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 12:12:13 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 12:12:13 - INFO - __main__ - task name: dbpedia_14
05/30/2022 12:12:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 12:12:14 - INFO - __main__ - Starting training!
05/30/2022 12:12:17 - INFO - __main__ - Step 10 Global step 10 Train loss 6.81 on epoch=0
05/30/2022 12:12:19 - INFO - __main__ - Step 20 Global step 20 Train loss 5.89 on epoch=1
05/30/2022 12:12:22 - INFO - __main__ - Step 30 Global step 30 Train loss 4.37 on epoch=2
05/30/2022 12:12:24 - INFO - __main__ - Step 40 Global step 40 Train loss 3.23 on epoch=2
05/30/2022 12:12:27 - INFO - __main__ - Step 50 Global step 50 Train loss 2.60 on epoch=3
05/30/2022 12:12:36 - INFO - __main__ - Global step 50 Train loss 4.58 Classification-F1 0.1313799485538616 on epoch=3
05/30/2022 12:12:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1313799485538616 on epoch=3, global_step=50
05/30/2022 12:12:39 - INFO - __main__ - Step 60 Global step 60 Train loss 2.40 on epoch=4
05/30/2022 12:12:41 - INFO - __main__ - Step 70 Global step 70 Train loss 2.01 on epoch=4
05/30/2022 12:12:44 - INFO - __main__ - Step 80 Global step 80 Train loss 1.90 on epoch=5
05/30/2022 12:12:46 - INFO - __main__ - Step 90 Global step 90 Train loss 1.76 on epoch=6
05/30/2022 12:12:49 - INFO - __main__ - Step 100 Global step 100 Train loss 1.57 on epoch=7
05/30/2022 12:12:56 - INFO - __main__ - Global step 100 Train loss 1.93 Classification-F1 0.33073337453593976 on epoch=7
05/30/2022 12:12:56 - INFO - __main__ - Saving model with best Classification-F1: 0.1313799485538616 -> 0.33073337453593976 on epoch=7, global_step=100
05/30/2022 12:12:58 - INFO - __main__ - Step 110 Global step 110 Train loss 1.46 on epoch=7
05/30/2022 12:13:01 - INFO - __main__ - Step 120 Global step 120 Train loss 1.38 on epoch=8
05/30/2022 12:13:03 - INFO - __main__ - Step 130 Global step 130 Train loss 1.35 on epoch=9
05/30/2022 12:13:06 - INFO - __main__ - Step 140 Global step 140 Train loss 1.07 on epoch=9
05/30/2022 12:13:08 - INFO - __main__ - Step 150 Global step 150 Train loss 1.07 on epoch=10
05/30/2022 12:13:15 - INFO - __main__ - Global step 150 Train loss 1.26 Classification-F1 0.3844482520902948 on epoch=10
05/30/2022 12:13:15 - INFO - __main__ - Saving model with best Classification-F1: 0.33073337453593976 -> 0.3844482520902948 on epoch=10, global_step=150
05/30/2022 12:13:18 - INFO - __main__ - Step 160 Global step 160 Train loss 1.10 on epoch=11
05/30/2022 12:13:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.97 on epoch=12
05/30/2022 12:13:23 - INFO - __main__ - Step 180 Global step 180 Train loss 0.89 on epoch=12
05/30/2022 12:13:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.87 on epoch=13
05/30/2022 12:13:28 - INFO - __main__ - Step 200 Global step 200 Train loss 0.92 on epoch=14
05/30/2022 12:13:34 - INFO - __main__ - Global step 200 Train loss 0.95 Classification-F1 0.3593503726116734 on epoch=14
05/30/2022 12:13:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.80 on epoch=14
05/30/2022 12:13:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.84 on epoch=15
05/30/2022 12:13:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.84 on epoch=16
05/30/2022 12:13:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.78 on epoch=17
05/30/2022 12:13:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.80 on epoch=17
05/30/2022 12:13:53 - INFO - __main__ - Global step 250 Train loss 0.81 Classification-F1 0.5350699085040697 on epoch=17
05/30/2022 12:13:53 - INFO - __main__ - Saving model with best Classification-F1: 0.3844482520902948 -> 0.5350699085040697 on epoch=17, global_step=250
05/30/2022 12:13:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.55 on epoch=18
05/30/2022 12:13:58 - INFO - __main__ - Step 270 Global step 270 Train loss 0.70 on epoch=19
05/30/2022 12:14:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.69 on epoch=19
05/30/2022 12:14:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.62 on epoch=20
05/30/2022 12:14:05 - INFO - __main__ - Step 300 Global step 300 Train loss 0.75 on epoch=21
05/30/2022 12:14:12 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.6139761687836994 on epoch=21
05/30/2022 12:14:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5350699085040697 -> 0.6139761687836994 on epoch=21, global_step=300
05/30/2022 12:14:14 - INFO - __main__ - Step 310 Global step 310 Train loss 0.58 on epoch=22
05/30/2022 12:14:17 - INFO - __main__ - Step 320 Global step 320 Train loss 0.65 on epoch=22
05/30/2022 12:14:19 - INFO - __main__ - Step 330 Global step 330 Train loss 0.54 on epoch=23
05/30/2022 12:14:22 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=24
05/30/2022 12:14:24 - INFO - __main__ - Step 350 Global step 350 Train loss 0.56 on epoch=24
05/30/2022 12:14:31 - INFO - __main__ - Global step 350 Train loss 0.58 Classification-F1 0.5323591929017192 on epoch=24
05/30/2022 12:14:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.55 on epoch=25
05/30/2022 12:14:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.56 on epoch=26
05/30/2022 12:14:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.60 on epoch=27
05/30/2022 12:14:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.43 on epoch=27
05/30/2022 12:14:43 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=28
05/30/2022 12:14:50 - INFO - __main__ - Global step 400 Train loss 0.52 Classification-F1 0.6238165463718331 on epoch=28
05/30/2022 12:14:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6139761687836994 -> 0.6238165463718331 on epoch=28, global_step=400
05/30/2022 12:14:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.48 on epoch=29
05/30/2022 12:14:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.51 on epoch=29
05/30/2022 12:14:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=30
05/30/2022 12:15:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.43 on epoch=31
05/30/2022 12:15:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.45 on epoch=32
05/30/2022 12:15:09 - INFO - __main__ - Global step 450 Train loss 0.46 Classification-F1 0.6901972754251585 on epoch=32
05/30/2022 12:15:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6238165463718331 -> 0.6901972754251585 on epoch=32, global_step=450
05/30/2022 12:15:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.43 on epoch=32
05/30/2022 12:15:14 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=33
05/30/2022 12:15:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.46 on epoch=34
05/30/2022 12:15:19 - INFO - __main__ - Step 490 Global step 490 Train loss 0.38 on epoch=34
05/30/2022 12:15:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.41 on epoch=35
05/30/2022 12:15:28 - INFO - __main__ - Global step 500 Train loss 0.41 Classification-F1 0.7255248519327022 on epoch=35
05/30/2022 12:15:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6901972754251585 -> 0.7255248519327022 on epoch=35, global_step=500
05/30/2022 12:15:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.43 on epoch=36
05/30/2022 12:15:33 - INFO - __main__ - Step 520 Global step 520 Train loss 0.39 on epoch=37
05/30/2022 12:15:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.51 on epoch=37
05/30/2022 12:15:38 - INFO - __main__ - Step 540 Global step 540 Train loss 0.37 on epoch=38
05/30/2022 12:15:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=39
05/30/2022 12:15:47 - INFO - __main__ - Global step 550 Train loss 0.42 Classification-F1 0.6916793897102012 on epoch=39
05/30/2022 12:15:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=39
05/30/2022 12:15:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.37 on epoch=40
05/30/2022 12:15:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.32 on epoch=41
05/30/2022 12:15:57 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=42
05/30/2022 12:15:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.32 on epoch=42
05/30/2022 12:16:05 - INFO - __main__ - Global step 600 Train loss 0.33 Classification-F1 0.5990712581182901 on epoch=42
05/30/2022 12:16:07 - INFO - __main__ - Step 610 Global step 610 Train loss 0.27 on epoch=43
05/30/2022 12:16:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.33 on epoch=44
05/30/2022 12:16:12 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=44
05/30/2022 12:16:15 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=45
05/30/2022 12:16:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=46
05/30/2022 12:16:23 - INFO - __main__ - Global step 650 Train loss 0.30 Classification-F1 0.6548330756255192 on epoch=46
05/30/2022 12:16:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.33 on epoch=47
05/30/2022 12:16:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.32 on epoch=47
05/30/2022 12:16:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.34 on epoch=48
05/30/2022 12:16:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.33 on epoch=49
05/30/2022 12:16:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.33 on epoch=49
05/30/2022 12:16:42 - INFO - __main__ - Global step 700 Train loss 0.33 Classification-F1 0.7657590525572924 on epoch=49
05/30/2022 12:16:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7255248519327022 -> 0.7657590525572924 on epoch=49, global_step=700
05/30/2022 12:16:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.29 on epoch=50
05/30/2022 12:16:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.30 on epoch=51
05/30/2022 12:16:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=52
05/30/2022 12:16:52 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=52
05/30/2022 12:16:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=53
05/30/2022 12:17:01 - INFO - __main__ - Global step 750 Train loss 0.27 Classification-F1 0.774660989968271 on epoch=53
05/30/2022 12:17:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7657590525572924 -> 0.774660989968271 on epoch=53, global_step=750
05/30/2022 12:17:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.30 on epoch=54
05/30/2022 12:17:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.30 on epoch=54
05/30/2022 12:17:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=55
05/30/2022 12:17:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=56
05/30/2022 12:17:14 - INFO - __main__ - Step 800 Global step 800 Train loss 0.29 on epoch=57
05/30/2022 12:17:20 - INFO - __main__ - Global step 800 Train loss 0.25 Classification-F1 0.635446454129709 on epoch=57
05/30/2022 12:17:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=57
05/30/2022 12:17:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=58
05/30/2022 12:17:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.26 on epoch=59
05/30/2022 12:17:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=59
05/30/2022 12:17:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.27 on epoch=60
05/30/2022 12:17:38 - INFO - __main__ - Global step 850 Train loss 0.24 Classification-F1 0.7395568215010208 on epoch=60
05/30/2022 12:17:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.28 on epoch=61
05/30/2022 12:17:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=62
05/30/2022 12:17:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.23 on epoch=62
05/30/2022 12:17:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=63
05/30/2022 12:17:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=64
05/30/2022 12:17:57 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.7836170911444862 on epoch=64
05/30/2022 12:17:57 - INFO - __main__ - Saving model with best Classification-F1: 0.774660989968271 -> 0.7836170911444862 on epoch=64, global_step=900
05/30/2022 12:18:00 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=64
05/30/2022 12:18:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=65
05/30/2022 12:18:05 - INFO - __main__ - Step 930 Global step 930 Train loss 0.28 on epoch=66
05/30/2022 12:18:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.24 on epoch=67
05/30/2022 12:18:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=67
05/30/2022 12:18:17 - INFO - __main__ - Global step 950 Train loss 0.22 Classification-F1 0.7398130117650991 on epoch=67
05/30/2022 12:18:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=68
05/30/2022 12:18:22 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=69
05/30/2022 12:18:24 - INFO - __main__ - Step 980 Global step 980 Train loss 0.21 on epoch=69
05/30/2022 12:18:26 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=70
05/30/2022 12:18:29 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=71
05/30/2022 12:18:35 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.8314497918076547 on epoch=71
05/30/2022 12:18:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7836170911444862 -> 0.8314497918076547 on epoch=71, global_step=1000
05/30/2022 12:18:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.23 on epoch=72
05/30/2022 12:18:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=72
05/30/2022 12:18:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=73
05/30/2022 12:18:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=74
05/30/2022 12:18:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=74
05/30/2022 12:18:55 - INFO - __main__ - Global step 1050 Train loss 0.19 Classification-F1 0.8058013723573496 on epoch=74
05/30/2022 12:18:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=75
05/30/2022 12:19:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=76
05/30/2022 12:19:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=77
05/30/2022 12:19:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=77
05/30/2022 12:19:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=78
05/30/2022 12:19:14 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.7412113128260608 on epoch=78
05/30/2022 12:19:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=79
05/30/2022 12:19:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.20 on epoch=79
05/30/2022 12:19:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=80
05/30/2022 12:19:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=81
05/30/2022 12:19:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.20 on epoch=82
05/30/2022 12:19:32 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.7487169700072926 on epoch=82
05/30/2022 12:19:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=82
05/30/2022 12:19:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=83
05/30/2022 12:19:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=84
05/30/2022 12:19:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=84
05/30/2022 12:19:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=85
05/30/2022 12:19:52 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.9018685388673283 on epoch=85
05/30/2022 12:19:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8314497918076547 -> 0.9018685388673283 on epoch=85, global_step=1200
05/30/2022 12:19:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=86
05/30/2022 12:19:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=87
05/30/2022 12:19:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
05/30/2022 12:20:02 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=88
05/30/2022 12:20:04 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
05/30/2022 12:20:10 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.8471401806079226 on epoch=89
05/30/2022 12:20:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=89
05/30/2022 12:20:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=90
05/30/2022 12:20:18 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=91
05/30/2022 12:20:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=92
05/30/2022 12:20:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=92
05/30/2022 12:20:29 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.8104766833419584 on epoch=92
05/30/2022 12:20:31 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=93
05/30/2022 12:20:33 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=94
05/30/2022 12:20:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=94
05/30/2022 12:20:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=95
05/30/2022 12:20:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=96
05/30/2022 12:20:47 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.9185272075594656 on epoch=96
05/30/2022 12:20:47 - INFO - __main__ - Saving model with best Classification-F1: 0.9018685388673283 -> 0.9185272075594656 on epoch=96, global_step=1350
05/30/2022 12:20:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=97
05/30/2022 12:20:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=97
05/30/2022 12:20:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
05/30/2022 12:20:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=99
05/30/2022 12:20:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=99
05/30/2022 12:21:06 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.855442694856535 on epoch=99
05/30/2022 12:21:09 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
05/30/2022 12:21:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
05/30/2022 12:21:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=102
05/30/2022 12:21:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=102
05/30/2022 12:21:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=103
05/30/2022 12:21:24 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.8002907908031248 on epoch=103
05/30/2022 12:21:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=104
05/30/2022 12:21:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=104
05/30/2022 12:21:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=105
05/30/2022 12:21:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=106
05/30/2022 12:21:37 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=107
05/30/2022 12:21:43 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.863147605083089 on epoch=107
05/30/2022 12:21:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=107
05/30/2022 12:21:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
05/30/2022 12:21:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
05/30/2022 12:21:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
05/30/2022 12:21:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
05/30/2022 12:22:01 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.8064286125007188 on epoch=110
05/30/2022 12:22:03 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
05/30/2022 12:22:06 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.15 on epoch=112
05/30/2022 12:22:08 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=112
05/30/2022 12:22:11 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
05/30/2022 12:22:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=114
05/30/2022 12:22:19 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.847353740799839 on epoch=114
05/30/2022 12:22:22 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
05/30/2022 12:22:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=115
05/30/2022 12:22:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.14 on epoch=116
05/30/2022 12:22:29 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=117
05/30/2022 12:22:32 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=117
05/30/2022 12:22:39 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.9139245626453634 on epoch=117
05/30/2022 12:22:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=118
05/30/2022 12:22:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
05/30/2022 12:22:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=119
05/30/2022 12:22:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
05/30/2022 12:22:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=121
05/30/2022 12:22:57 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.9097538229907528 on epoch=121
05/30/2022 12:22:59 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
05/30/2022 12:23:02 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
05/30/2022 12:23:04 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
05/30/2022 12:23:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
05/30/2022 12:23:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=124
05/30/2022 12:23:16 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.9186705767350929 on epoch=124
05/30/2022 12:23:16 - INFO - __main__ - Saving model with best Classification-F1: 0.9185272075594656 -> 0.9186705767350929 on epoch=124, global_step=1750
05/30/2022 12:23:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.13 on epoch=125
05/30/2022 12:23:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.12 on epoch=126
05/30/2022 12:23:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=127
05/30/2022 12:23:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
05/30/2022 12:23:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=128
05/30/2022 12:23:42 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.9071265651910811 on epoch=128
05/30/2022 12:23:45 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=129
05/30/2022 12:23:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=129
05/30/2022 12:23:50 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=130
05/30/2022 12:23:52 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
05/30/2022 12:23:55 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.11 on epoch=132
05/30/2022 12:24:01 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.804506492656725 on epoch=132
05/30/2022 12:24:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
05/30/2022 12:24:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
05/30/2022 12:24:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
05/30/2022 12:24:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=134
05/30/2022 12:24:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=135
05/30/2022 12:24:20 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.851398217828187 on epoch=135
05/30/2022 12:24:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
05/30/2022 12:24:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=137
05/30/2022 12:24:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=137
05/30/2022 12:24:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
05/30/2022 12:24:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
05/30/2022 12:24:40 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.9776304656760065 on epoch=139
05/30/2022 12:24:40 - INFO - __main__ - Saving model with best Classification-F1: 0.9186705767350929 -> 0.9776304656760065 on epoch=139, global_step=1950
05/30/2022 12:24:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=139
05/30/2022 12:24:44 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
05/30/2022 12:24:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
05/30/2022 12:24:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
05/30/2022 12:24:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
05/30/2022 12:24:58 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.9146227454813792 on epoch=142
05/30/2022 12:25:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
05/30/2022 12:25:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=144
05/30/2022 12:25:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.13 on epoch=144
05/30/2022 12:25:08 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=145
05/30/2022 12:25:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
05/30/2022 12:25:18 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.9228413163897036 on epoch=146
05/30/2022 12:25:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
05/30/2022 12:25:23 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
05/30/2022 12:25:26 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=148
05/30/2022 12:25:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
05/30/2022 12:25:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=149
05/30/2022 12:25:38 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.9821254014802402 on epoch=149
05/30/2022 12:25:38 - INFO - __main__ - Saving model with best Classification-F1: 0.9776304656760065 -> 0.9821254014802402 on epoch=149, global_step=2100
05/30/2022 12:25:40 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
05/30/2022 12:25:43 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
05/30/2022 12:25:45 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=152
05/30/2022 12:25:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
05/30/2022 12:25:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=153
05/30/2022 12:25:57 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.8478608085462924 on epoch=153
05/30/2022 12:25:59 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
05/30/2022 12:26:02 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.12 on epoch=154
05/30/2022 12:26:04 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
05/30/2022 12:26:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
05/30/2022 12:26:09 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
05/30/2022 12:26:16 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.9103045636631976 on epoch=157
05/30/2022 12:26:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
05/30/2022 12:26:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
05/30/2022 12:26:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
05/30/2022 12:26:26 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
05/30/2022 12:26:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
05/30/2022 12:26:36 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8975830367877087 on epoch=160
05/30/2022 12:26:38 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
05/30/2022 12:26:41 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=162
05/30/2022 12:26:43 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
05/30/2022 12:26:46 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=163
05/30/2022 12:26:48 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
05/30/2022 12:26:55 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8510002696598915 on epoch=164
05/30/2022 12:26:57 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
05/30/2022 12:27:00 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.10 on epoch=165
05/30/2022 12:27:02 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.10 on epoch=166
05/30/2022 12:27:05 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
05/30/2022 12:27:07 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
05/30/2022 12:27:13 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.9028124563608434 on epoch=167
05/30/2022 12:27:16 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
05/30/2022 12:27:18 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
05/30/2022 12:27:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
05/30/2022 12:27:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
05/30/2022 12:27:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
05/30/2022 12:27:32 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7546866514608451 on epoch=171
05/30/2022 12:27:34 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.11 on epoch=172
05/30/2022 12:27:37 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
05/30/2022 12:27:39 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=173
05/30/2022 12:27:42 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
05/30/2022 12:27:44 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/30/2022 12:27:50 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.9776654796816088 on epoch=174
05/30/2022 12:27:53 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
05/30/2022 12:27:55 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.09 on epoch=176
05/30/2022 12:27:58 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
05/30/2022 12:28:00 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=177
05/30/2022 12:28:02 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
05/30/2022 12:28:09 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.9776304656760065 on epoch=178
05/30/2022 12:28:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
05/30/2022 12:28:14 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=179
05/30/2022 12:28:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
05/30/2022 12:28:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
05/30/2022 12:28:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
05/30/2022 12:28:28 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.9145039100684262 on epoch=182
05/30/2022 12:28:30 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
05/30/2022 12:28:33 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
05/30/2022 12:28:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
05/30/2022 12:28:38 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
05/30/2022 12:28:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
05/30/2022 12:28:47 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.9910627007401202 on epoch=185
05/30/2022 12:28:47 - INFO - __main__ - Saving model with best Classification-F1: 0.9821254014802402 -> 0.9910627007401202 on epoch=185, global_step=2600
05/30/2022 12:28:49 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
05/30/2022 12:28:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
05/30/2022 12:28:54 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
05/30/2022 12:28:57 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
05/30/2022 12:28:59 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
05/30/2022 12:29:06 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9865940511101802 on epoch=189
05/30/2022 12:29:09 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/30/2022 12:29:11 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/30/2022 12:29:13 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
05/30/2022 12:29:16 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
05/30/2022 12:29:18 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
05/30/2022 12:29:25 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9771800316850372 on epoch=192
05/30/2022 12:29:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
05/30/2022 12:29:30 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/30/2022 12:29:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
05/30/2022 12:29:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.10 on epoch=195
05/30/2022 12:29:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=196
05/30/2022 12:29:43 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.9098841586049592 on epoch=196
05/30/2022 12:29:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=197
05/30/2022 12:29:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
05/30/2022 12:29:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/30/2022 12:29:53 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
05/30/2022 12:29:56 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.13 on epoch=199
05/30/2022 12:30:01 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.859103128054741 on epoch=199
05/30/2022 12:30:04 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
05/30/2022 12:30:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=201
05/30/2022 12:30:09 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
05/30/2022 12:30:11 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
05/30/2022 12:30:14 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
05/30/2022 12:30:20 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9185272075594656 on epoch=203
05/30/2022 12:30:22 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
05/30/2022 12:30:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/30/2022 12:30:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
05/30/2022 12:30:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=206
05/30/2022 12:30:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.07 on epoch=207
05/30/2022 12:30:38 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.9909090909090909 on epoch=207
05/30/2022 12:30:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
05/30/2022 12:30:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
05/30/2022 12:30:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
05/30/2022 12:30:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
05/30/2022 12:30:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
05/30/2022 12:30:56 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9101857282502444 on epoch=210
05/30/2022 12:30:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
05/30/2022 12:31:01 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.08 on epoch=212
05/30/2022 12:31:03 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
05/30/2022 12:31:06 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=213
05/30/2022 12:31:08 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
05/30/2022 12:31:10 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 12:31:10 - INFO - __main__ - Printing 3 examples
05/30/2022 12:31:10 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/30/2022 12:31:10 - INFO - __main__ - ['Company']
05/30/2022 12:31:10 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/30/2022 12:31:10 - INFO - __main__ - ['Company']
05/30/2022 12:31:10 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/30/2022 12:31:10 - INFO - __main__ - ['Company']
05/30/2022 12:31:10 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:31:10 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:31:10 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 12:31:10 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 12:31:10 - INFO - __main__ - Printing 3 examples
05/30/2022 12:31:10 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/30/2022 12:31:10 - INFO - __main__ - ['Company']
05/30/2022 12:31:10 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/30/2022 12:31:10 - INFO - __main__ - ['Company']
05/30/2022 12:31:10 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/30/2022 12:31:10 - INFO - __main__ - ['Company']
05/30/2022 12:31:10 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:31:10 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:31:10 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 12:31:15 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.9727113820550972 on epoch=214
05/30/2022 12:31:15 - INFO - __main__ - save last model!
05/30/2022 12:31:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 12:31:15 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 12:31:15 - INFO - __main__ - Printing 3 examples
05/30/2022 12:31:15 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 12:31:15 - INFO - __main__ - ['Animal']
05/30/2022 12:31:15 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 12:31:15 - INFO - __main__ - ['Animal']
05/30/2022 12:31:15 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 12:31:15 - INFO - __main__ - ['Village']
05/30/2022 12:31:15 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:31:17 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:31:20 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 12:31:29 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 12:31:29 - INFO - __main__ - task name: dbpedia_14
05/30/2022 12:31:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 12:31:30 - INFO - __main__ - Starting training!
05/30/2022 12:33:21 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
05/30/2022 12:33:21 - INFO - __main__ - Classification-F1 on test data: 0.7172
05/30/2022 12:33:22 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.9910627007401202, test_performance=0.7172285669332001
05/30/2022 12:33:22 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
05/30/2022 12:33:23 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 12:33:23 - INFO - __main__ - Printing 3 examples
05/30/2022 12:33:23 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/30/2022 12:33:23 - INFO - __main__ - ['Company']
05/30/2022 12:33:23 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/30/2022 12:33:23 - INFO - __main__ - ['Company']
05/30/2022 12:33:23 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/30/2022 12:33:23 - INFO - __main__ - ['Company']
05/30/2022 12:33:23 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:33:23 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:33:23 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 12:33:23 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 12:33:23 - INFO - __main__ - Printing 3 examples
05/30/2022 12:33:23 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/30/2022 12:33:23 - INFO - __main__ - ['Company']
05/30/2022 12:33:23 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/30/2022 12:33:23 - INFO - __main__ - ['Company']
05/30/2022 12:33:23 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/30/2022 12:33:23 - INFO - __main__ - ['Company']
05/30/2022 12:33:23 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:33:23 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:33:23 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 12:33:38 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 12:33:38 - INFO - __main__ - task name: dbpedia_14
05/30/2022 12:33:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 12:33:39 - INFO - __main__ - Starting training!
05/30/2022 12:33:42 - INFO - __main__ - Step 10 Global step 10 Train loss 6.81 on epoch=0
05/30/2022 12:33:44 - INFO - __main__ - Step 20 Global step 20 Train loss 6.04 on epoch=1
05/30/2022 12:33:47 - INFO - __main__ - Step 30 Global step 30 Train loss 4.54 on epoch=2
05/30/2022 12:33:49 - INFO - __main__ - Step 40 Global step 40 Train loss 3.31 on epoch=2
05/30/2022 12:33:52 - INFO - __main__ - Step 50 Global step 50 Train loss 2.99 on epoch=3
05/30/2022 12:34:28 - INFO - __main__ - Global step 50 Train loss 4.74 Classification-F1 0.02593636217605483 on epoch=3
05/30/2022 12:34:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.02593636217605483 on epoch=3, global_step=50
05/30/2022 12:34:31 - INFO - __main__ - Step 60 Global step 60 Train loss 2.45 on epoch=4
05/30/2022 12:34:33 - INFO - __main__ - Step 70 Global step 70 Train loss 2.28 on epoch=4
05/30/2022 12:34:36 - INFO - __main__ - Step 80 Global step 80 Train loss 1.98 on epoch=5
05/30/2022 12:34:38 - INFO - __main__ - Step 90 Global step 90 Train loss 1.78 on epoch=6
05/30/2022 12:34:41 - INFO - __main__ - Step 100 Global step 100 Train loss 1.64 on epoch=7
05/30/2022 12:34:48 - INFO - __main__ - Global step 100 Train loss 2.03 Classification-F1 0.30117557086247787 on epoch=7
05/30/2022 12:34:48 - INFO - __main__ - Saving model with best Classification-F1: 0.02593636217605483 -> 0.30117557086247787 on epoch=7, global_step=100
05/30/2022 12:34:51 - INFO - __main__ - Step 110 Global step 110 Train loss 1.41 on epoch=7
05/30/2022 12:34:53 - INFO - __main__ - Step 120 Global step 120 Train loss 1.27 on epoch=8
05/30/2022 12:34:56 - INFO - __main__ - Step 130 Global step 130 Train loss 1.18 on epoch=9
05/30/2022 12:34:58 - INFO - __main__ - Step 140 Global step 140 Train loss 0.98 on epoch=9
05/30/2022 12:35:00 - INFO - __main__ - Step 150 Global step 150 Train loss 1.03 on epoch=10
05/30/2022 12:35:08 - INFO - __main__ - Global step 150 Train loss 1.18 Classification-F1 0.3287450793807604 on epoch=10
05/30/2022 12:35:08 - INFO - __main__ - Saving model with best Classification-F1: 0.30117557086247787 -> 0.3287450793807604 on epoch=10, global_step=150
05/30/2022 12:35:11 - INFO - __main__ - Step 160 Global step 160 Train loss 1.06 on epoch=11
05/30/2022 12:35:13 - INFO - __main__ - Step 170 Global step 170 Train loss 0.99 on epoch=12
05/30/2022 12:35:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.93 on epoch=12
05/30/2022 12:35:18 - INFO - __main__ - Step 190 Global step 190 Train loss 0.81 on epoch=13
05/30/2022 12:35:21 - INFO - __main__ - Step 200 Global step 200 Train loss 0.85 on epoch=14
05/30/2022 12:35:28 - INFO - __main__ - Global step 200 Train loss 0.93 Classification-F1 0.6277479947661652 on epoch=14
05/30/2022 12:35:28 - INFO - __main__ - Saving model with best Classification-F1: 0.3287450793807604 -> 0.6277479947661652 on epoch=14, global_step=200
05/30/2022 12:35:30 - INFO - __main__ - Step 210 Global step 210 Train loss 0.84 on epoch=14
05/30/2022 12:35:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.80 on epoch=15
05/30/2022 12:35:35 - INFO - __main__ - Step 230 Global step 230 Train loss 0.75 on epoch=16
05/30/2022 12:35:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.80 on epoch=17
05/30/2022 12:35:40 - INFO - __main__ - Step 250 Global step 250 Train loss 0.73 on epoch=17
05/30/2022 12:35:47 - INFO - __main__ - Global step 250 Train loss 0.78 Classification-F1 0.44912334453260794 on epoch=17
05/30/2022 12:35:49 - INFO - __main__ - Step 260 Global step 260 Train loss 0.78 on epoch=18
05/30/2022 12:35:52 - INFO - __main__ - Step 270 Global step 270 Train loss 0.77 on epoch=19
05/30/2022 12:35:54 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=19
05/30/2022 12:35:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.63 on epoch=20
05/30/2022 12:35:59 - INFO - __main__ - Step 300 Global step 300 Train loss 0.64 on epoch=21
05/30/2022 12:36:06 - INFO - __main__ - Global step 300 Train loss 0.70 Classification-F1 0.5769761970047009 on epoch=21
05/30/2022 12:36:09 - INFO - __main__ - Step 310 Global step 310 Train loss 0.60 on epoch=22
05/30/2022 12:36:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.61 on epoch=22
05/30/2022 12:36:14 - INFO - __main__ - Step 330 Global step 330 Train loss 0.54 on epoch=23
05/30/2022 12:36:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.65 on epoch=24
05/30/2022 12:36:19 - INFO - __main__ - Step 350 Global step 350 Train loss 0.62 on epoch=24
05/30/2022 12:36:24 - INFO - __main__ - Global step 350 Train loss 0.60 Classification-F1 0.4339983692377146 on epoch=24
05/30/2022 12:36:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.58 on epoch=25
05/30/2022 12:36:29 - INFO - __main__ - Step 370 Global step 370 Train loss 0.54 on epoch=26
05/30/2022 12:36:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.58 on epoch=27
05/30/2022 12:36:34 - INFO - __main__ - Step 390 Global step 390 Train loss 0.56 on epoch=27
05/30/2022 12:36:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.42 on epoch=28
05/30/2022 12:36:44 - INFO - __main__ - Global step 400 Train loss 0.54 Classification-F1 0.5678498281404287 on epoch=28
05/30/2022 12:36:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.56 on epoch=29
05/30/2022 12:36:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.54 on epoch=29
05/30/2022 12:36:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.49 on epoch=30
05/30/2022 12:36:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.51 on epoch=31
05/30/2022 12:36:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.58 on epoch=32
05/30/2022 12:37:02 - INFO - __main__ - Global step 450 Train loss 0.54 Classification-F1 0.5271518934330947 on epoch=32
05/30/2022 12:37:04 - INFO - __main__ - Step 460 Global step 460 Train loss 0.51 on epoch=32
05/30/2022 12:37:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.45 on epoch=33
05/30/2022 12:37:09 - INFO - __main__ - Step 480 Global step 480 Train loss 0.49 on epoch=34
05/30/2022 12:37:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.58 on epoch=34
05/30/2022 12:37:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.42 on epoch=35
05/30/2022 12:37:21 - INFO - __main__ - Global step 500 Train loss 0.49 Classification-F1 0.5551022438890086 on epoch=35
05/30/2022 12:37:24 - INFO - __main__ - Step 510 Global step 510 Train loss 0.48 on epoch=36
05/30/2022 12:37:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.50 on epoch=37
05/30/2022 12:37:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.49 on epoch=37
05/30/2022 12:37:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.48 on epoch=38
05/30/2022 12:37:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.45 on epoch=39
05/30/2022 12:37:41 - INFO - __main__ - Global step 550 Train loss 0.48 Classification-F1 0.48233398305942826 on epoch=39
05/30/2022 12:37:44 - INFO - __main__ - Step 560 Global step 560 Train loss 0.46 on epoch=39
05/30/2022 12:37:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.46 on epoch=40
05/30/2022 12:37:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.47 on epoch=41
05/30/2022 12:37:51 - INFO - __main__ - Step 590 Global step 590 Train loss 0.46 on epoch=42
05/30/2022 12:37:54 - INFO - __main__ - Step 600 Global step 600 Train loss 0.46 on epoch=42
05/30/2022 12:38:00 - INFO - __main__ - Global step 600 Train loss 0.46 Classification-F1 0.6105206665678052 on epoch=42
05/30/2022 12:38:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.42 on epoch=43
05/30/2022 12:38:05 - INFO - __main__ - Step 620 Global step 620 Train loss 0.51 on epoch=44
05/30/2022 12:38:08 - INFO - __main__ - Step 630 Global step 630 Train loss 0.45 on epoch=44
05/30/2022 12:38:10 - INFO - __main__ - Step 640 Global step 640 Train loss 0.43 on epoch=45
05/30/2022 12:38:13 - INFO - __main__ - Step 650 Global step 650 Train loss 0.42 on epoch=46
05/30/2022 12:38:20 - INFO - __main__ - Global step 650 Train loss 0.45 Classification-F1 0.596807279110451 on epoch=46
05/30/2022 12:38:22 - INFO - __main__ - Step 660 Global step 660 Train loss 0.30 on epoch=47
05/30/2022 12:38:25 - INFO - __main__ - Step 670 Global step 670 Train loss 0.47 on epoch=47
05/30/2022 12:38:27 - INFO - __main__ - Step 680 Global step 680 Train loss 0.34 on epoch=48
05/30/2022 12:38:30 - INFO - __main__ - Step 690 Global step 690 Train loss 0.41 on epoch=49
05/30/2022 12:38:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.36 on epoch=49
05/30/2022 12:38:39 - INFO - __main__ - Global step 700 Train loss 0.38 Classification-F1 0.6326372334993795 on epoch=49
05/30/2022 12:38:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6277479947661652 -> 0.6326372334993795 on epoch=49, global_step=700
05/30/2022 12:38:42 - INFO - __main__ - Step 710 Global step 710 Train loss 0.31 on epoch=50
05/30/2022 12:38:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.35 on epoch=51
05/30/2022 12:38:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.40 on epoch=52
05/30/2022 12:38:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.36 on epoch=52
05/30/2022 12:38:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.41 on epoch=53
05/30/2022 12:38:58 - INFO - __main__ - Global step 750 Train loss 0.37 Classification-F1 0.529334204025401 on epoch=53
05/30/2022 12:39:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.37 on epoch=54
05/30/2022 12:39:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.46 on epoch=54
05/30/2022 12:39:06 - INFO - __main__ - Step 780 Global step 780 Train loss 0.38 on epoch=55
05/30/2022 12:39:08 - INFO - __main__ - Step 790 Global step 790 Train loss 0.34 on epoch=56
05/30/2022 12:39:11 - INFO - __main__ - Step 800 Global step 800 Train loss 0.38 on epoch=57
05/30/2022 12:39:17 - INFO - __main__ - Global step 800 Train loss 0.39 Classification-F1 0.6828995473775077 on epoch=57
05/30/2022 12:39:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6326372334993795 -> 0.6828995473775077 on epoch=57, global_step=800
05/30/2022 12:39:20 - INFO - __main__ - Step 810 Global step 810 Train loss 0.37 on epoch=57
05/30/2022 12:39:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.32 on epoch=58
05/30/2022 12:39:25 - INFO - __main__ - Step 830 Global step 830 Train loss 0.33 on epoch=59
05/30/2022 12:39:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.33 on epoch=59
05/30/2022 12:39:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.31 on epoch=60
05/30/2022 12:39:36 - INFO - __main__ - Global step 850 Train loss 0.33 Classification-F1 0.6218255801026097 on epoch=60
05/30/2022 12:39:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.33 on epoch=61
05/30/2022 12:39:42 - INFO - __main__ - Step 870 Global step 870 Train loss 0.31 on epoch=62
05/30/2022 12:39:44 - INFO - __main__ - Step 880 Global step 880 Train loss 0.34 on epoch=62
05/30/2022 12:39:47 - INFO - __main__ - Step 890 Global step 890 Train loss 0.32 on epoch=63
05/30/2022 12:39:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.31 on epoch=64
05/30/2022 12:39:56 - INFO - __main__ - Global step 900 Train loss 0.32 Classification-F1 0.5946504584096405 on epoch=64
05/30/2022 12:39:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.30 on epoch=64
05/30/2022 12:40:01 - INFO - __main__ - Step 920 Global step 920 Train loss 0.29 on epoch=65
05/30/2022 12:40:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.40 on epoch=66
05/30/2022 12:40:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.32 on epoch=67
05/30/2022 12:40:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.23 on epoch=67
05/30/2022 12:40:15 - INFO - __main__ - Global step 950 Train loss 0.31 Classification-F1 0.6818481295386032 on epoch=67
05/30/2022 12:40:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.27 on epoch=68
05/30/2022 12:40:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.36 on epoch=69
05/30/2022 12:40:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.29 on epoch=69
05/30/2022 12:40:26 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=70
05/30/2022 12:40:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.42 on epoch=71
05/30/2022 12:40:35 - INFO - __main__ - Global step 1000 Train loss 0.32 Classification-F1 0.6192739599614197 on epoch=71
05/30/2022 12:40:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.39 on epoch=72
05/30/2022 12:40:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.33 on epoch=72
05/30/2022 12:40:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.24 on epoch=73
05/30/2022 12:40:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.26 on epoch=74
05/30/2022 12:40:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.31 on epoch=74
05/30/2022 12:40:55 - INFO - __main__ - Global step 1050 Train loss 0.30 Classification-F1 0.5751062785605165 on epoch=74
05/30/2022 12:40:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.25 on epoch=75
05/30/2022 12:41:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.29 on epoch=76
05/30/2022 12:41:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.29 on epoch=77
05/30/2022 12:41:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.28 on epoch=77
05/30/2022 12:41:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.34 on epoch=78
05/30/2022 12:41:14 - INFO - __main__ - Global step 1100 Train loss 0.29 Classification-F1 0.6778447325187538 on epoch=78
05/30/2022 12:41:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.28 on epoch=79
05/30/2022 12:41:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.34 on epoch=79
05/30/2022 12:41:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.19 on epoch=80
05/30/2022 12:41:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.32 on epoch=81
05/30/2022 12:41:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.30 on epoch=82
05/30/2022 12:41:34 - INFO - __main__ - Global step 1150 Train loss 0.29 Classification-F1 0.767359759152928 on epoch=82
05/30/2022 12:41:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6828995473775077 -> 0.767359759152928 on epoch=82, global_step=1150
05/30/2022 12:41:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.30 on epoch=82
05/30/2022 12:41:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.28 on epoch=83
05/30/2022 12:41:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.31 on epoch=84
05/30/2022 12:41:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.26 on epoch=84
05/30/2022 12:41:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.17 on epoch=85
05/30/2022 12:41:53 - INFO - __main__ - Global step 1200 Train loss 0.26 Classification-F1 0.6283808762912587 on epoch=85
05/30/2022 12:41:56 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.19 on epoch=86
05/30/2022 12:41:58 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.20 on epoch=87
05/30/2022 12:42:01 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.20 on epoch=87
05/30/2022 12:42:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.23 on epoch=88
05/30/2022 12:42:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.22 on epoch=89
05/30/2022 12:42:12 - INFO - __main__ - Global step 1250 Train loss 0.21 Classification-F1 0.6454150105538183 on epoch=89
05/30/2022 12:42:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.26 on epoch=89
05/30/2022 12:42:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.21 on epoch=90
05/30/2022 12:42:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.22 on epoch=91
05/30/2022 12:42:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.22 on epoch=92
05/30/2022 12:42:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.21 on epoch=92
05/30/2022 12:42:31 - INFO - __main__ - Global step 1300 Train loss 0.23 Classification-F1 0.5801439302851548 on epoch=92
05/30/2022 12:42:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.18 on epoch=93
05/30/2022 12:42:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.25 on epoch=94
05/30/2022 12:42:39 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.22 on epoch=94
05/30/2022 12:42:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.17 on epoch=95
05/30/2022 12:42:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.24 on epoch=96
05/30/2022 12:42:50 - INFO - __main__ - Global step 1350 Train loss 0.21 Classification-F1 0.6157540256532192 on epoch=96
05/30/2022 12:42:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.22 on epoch=97
05/30/2022 12:42:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.23 on epoch=97
05/30/2022 12:42:57 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.16 on epoch=98
05/30/2022 12:43:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=99
05/30/2022 12:43:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.20 on epoch=99
05/30/2022 12:43:10 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.6655054669910359 on epoch=99
05/30/2022 12:43:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.19 on epoch=100
05/30/2022 12:43:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.18 on epoch=101
05/30/2022 12:43:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.21 on epoch=102
05/30/2022 12:43:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=102
05/30/2022 12:43:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.19 on epoch=103
05/30/2022 12:43:28 - INFO - __main__ - Global step 1450 Train loss 0.19 Classification-F1 0.626603350455252 on epoch=103
05/30/2022 12:43:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.17 on epoch=104
05/30/2022 12:43:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.19 on epoch=104
05/30/2022 12:43:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=105
05/30/2022 12:43:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.34 on epoch=106
05/30/2022 12:43:41 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.19 on epoch=107
05/30/2022 12:43:47 - INFO - __main__ - Global step 1500 Train loss 0.20 Classification-F1 0.566324990176804 on epoch=107
05/30/2022 12:43:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=107
05/30/2022 12:43:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.22 on epoch=108
05/30/2022 12:43:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.17 on epoch=109
05/30/2022 12:43:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.20 on epoch=109
05/30/2022 12:43:59 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=110
05/30/2022 12:44:05 - INFO - __main__ - Global step 1550 Train loss 0.17 Classification-F1 0.5786849501722616 on epoch=110
05/30/2022 12:44:08 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.17 on epoch=111
05/30/2022 12:44:10 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.18 on epoch=112
05/30/2022 12:44:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.15 on epoch=112
05/30/2022 12:44:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=113
05/30/2022 12:44:18 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.19 on epoch=114
05/30/2022 12:44:24 - INFO - __main__ - Global step 1600 Train loss 0.16 Classification-F1 0.7000232742168226 on epoch=114
05/30/2022 12:44:27 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.15 on epoch=114
05/30/2022 12:44:29 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=115
05/30/2022 12:44:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.21 on epoch=116
05/30/2022 12:44:34 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.20 on epoch=117
05/30/2022 12:44:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.19 on epoch=117
05/30/2022 12:44:43 - INFO - __main__ - Global step 1650 Train loss 0.17 Classification-F1 0.592031559780311 on epoch=117
05/30/2022 12:44:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=118
05/30/2022 12:44:48 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.21 on epoch=119
05/30/2022 12:44:50 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.20 on epoch=119
05/30/2022 12:44:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=120
05/30/2022 12:44:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.20 on epoch=121
05/30/2022 12:45:02 - INFO - __main__ - Global step 1700 Train loss 0.17 Classification-F1 0.6366289747824787 on epoch=121
05/30/2022 12:45:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.15 on epoch=122
05/30/2022 12:45:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.14 on epoch=122
05/30/2022 12:45:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.17 on epoch=123
05/30/2022 12:45:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.19 on epoch=124
05/30/2022 12:45:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.16 on epoch=124
05/30/2022 12:45:20 - INFO - __main__ - Global step 1750 Train loss 0.16 Classification-F1 0.6625670720981299 on epoch=124
05/30/2022 12:45:23 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=125
05/30/2022 12:45:25 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.15 on epoch=126
05/30/2022 12:45:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.17 on epoch=127
05/30/2022 12:45:30 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=127
05/30/2022 12:45:33 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=128
05/30/2022 12:45:39 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.7526249002820192 on epoch=128
05/30/2022 12:45:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.17 on epoch=129
05/30/2022 12:45:44 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=129
05/30/2022 12:45:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.15 on epoch=130
05/30/2022 12:45:49 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.18 on epoch=131
05/30/2022 12:45:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.15 on epoch=132
05/30/2022 12:45:58 - INFO - __main__ - Global step 1850 Train loss 0.16 Classification-F1 0.7538099892938602 on epoch=132
05/30/2022 12:46:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.18 on epoch=132
05/30/2022 12:46:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=133
05/30/2022 12:46:05 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.26 on epoch=134
05/30/2022 12:46:08 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.15 on epoch=134
05/30/2022 12:46:10 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.15 on epoch=135
05/30/2022 12:46:16 - INFO - __main__ - Global step 1900 Train loss 0.17 Classification-F1 0.7486848696456594 on epoch=135
05/30/2022 12:46:18 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.16 on epoch=136
05/30/2022 12:46:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.17 on epoch=137
05/30/2022 12:46:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.11 on epoch=137
05/30/2022 12:46:26 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.20 on epoch=138
05/30/2022 12:46:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.16 on epoch=139
05/30/2022 12:46:34 - INFO - __main__ - Global step 1950 Train loss 0.16 Classification-F1 0.704799036340255 on epoch=139
05/30/2022 12:46:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.14 on epoch=139
05/30/2022 12:46:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=140
05/30/2022 12:46:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.11 on epoch=141
05/30/2022 12:46:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.12 on epoch=142
05/30/2022 12:46:46 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.13 on epoch=142
05/30/2022 12:46:52 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.715690402787177 on epoch=142
05/30/2022 12:46:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.13 on epoch=143
05/30/2022 12:46:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=144
05/30/2022 12:46:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.09 on epoch=144
05/30/2022 12:47:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.14 on epoch=145
05/30/2022 12:47:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.13 on epoch=146
05/30/2022 12:47:10 - INFO - __main__ - Global step 2050 Train loss 0.11 Classification-F1 0.8024824572361051 on epoch=146
05/30/2022 12:47:10 - INFO - __main__ - Saving model with best Classification-F1: 0.767359759152928 -> 0.8024824572361051 on epoch=146, global_step=2050
05/30/2022 12:47:12 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.15 on epoch=147
05/30/2022 12:47:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.14 on epoch=147
05/30/2022 12:47:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.14 on epoch=148
05/30/2022 12:47:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.12 on epoch=149
05/30/2022 12:47:22 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.15 on epoch=149
05/30/2022 12:47:28 - INFO - __main__ - Global step 2100 Train loss 0.14 Classification-F1 0.713472047665596 on epoch=149
05/30/2022 12:47:30 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=150
05/30/2022 12:47:33 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=151
05/30/2022 12:47:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.14 on epoch=152
05/30/2022 12:47:38 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.12 on epoch=152
05/30/2022 12:47:40 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=153
05/30/2022 12:47:46 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.789056213873485 on epoch=153
05/30/2022 12:47:49 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.14 on epoch=154
05/30/2022 12:47:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.15 on epoch=154
05/30/2022 12:47:54 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.18 on epoch=155
05/30/2022 12:47:56 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.13 on epoch=156
05/30/2022 12:47:58 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=157
05/30/2022 12:48:04 - INFO - __main__ - Global step 2200 Train loss 0.14 Classification-F1 0.7321686105697326 on epoch=157
05/30/2022 12:48:07 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=157
05/30/2022 12:48:09 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=158
05/30/2022 12:48:12 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.12 on epoch=159
05/30/2022 12:48:14 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.13 on epoch=159
05/30/2022 12:48:17 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
05/30/2022 12:48:22 - INFO - __main__ - Global step 2250 Train loss 0.10 Classification-F1 0.7969982142030285 on epoch=160
05/30/2022 12:48:25 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.12 on epoch=161
05/30/2022 12:48:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=162
05/30/2022 12:48:30 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.09 on epoch=162
05/30/2022 12:48:32 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.14 on epoch=163
05/30/2022 12:48:35 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=164
05/30/2022 12:48:40 - INFO - __main__ - Global step 2300 Train loss 0.10 Classification-F1 0.7445741852206552 on epoch=164
05/30/2022 12:48:43 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=164
05/30/2022 12:48:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
05/30/2022 12:48:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.14 on epoch=166
05/30/2022 12:48:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.08 on epoch=167
05/30/2022 12:48:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.09 on epoch=167
05/30/2022 12:48:58 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.7829896161113854 on epoch=167
05/30/2022 12:49:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=168
05/30/2022 12:49:03 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=169
05/30/2022 12:49:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.14 on epoch=169
05/30/2022 12:49:08 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=170
05/30/2022 12:49:11 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
05/30/2022 12:49:17 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.8981219000036202 on epoch=171
05/30/2022 12:49:17 - INFO - __main__ - Saving model with best Classification-F1: 0.8024824572361051 -> 0.8981219000036202 on epoch=171, global_step=2400
05/30/2022 12:49:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.10 on epoch=172
05/30/2022 12:49:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
05/30/2022 12:49:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
05/30/2022 12:49:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.11 on epoch=174
05/30/2022 12:49:29 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.11 on epoch=174
05/30/2022 12:49:35 - INFO - __main__ - Global step 2450 Train loss 0.09 Classification-F1 0.6982182182036089 on epoch=174
05/30/2022 12:49:37 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
05/30/2022 12:49:40 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.11 on epoch=176
05/30/2022 12:49:42 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.11 on epoch=177
05/30/2022 12:49:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=177
05/30/2022 12:49:47 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.08 on epoch=178
05/30/2022 12:49:53 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.7547590136048671 on epoch=178
05/30/2022 12:49:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=179
05/30/2022 12:49:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=179
05/30/2022 12:50:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
05/30/2022 12:50:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.10 on epoch=181
05/30/2022 12:50:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=182
05/30/2022 12:50:11 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.7772312682138605 on epoch=182
05/30/2022 12:50:13 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.15 on epoch=182
05/30/2022 12:50:16 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.09 on epoch=183
05/30/2022 12:50:18 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=184
05/30/2022 12:50:21 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.10 on epoch=184
05/30/2022 12:50:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=185
05/30/2022 12:50:29 - INFO - __main__ - Global step 2600 Train loss 0.10 Classification-F1 0.7772112398521597 on epoch=185
05/30/2022 12:50:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.09 on epoch=186
05/30/2022 12:50:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
05/30/2022 12:50:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.09 on epoch=187
05/30/2022 12:50:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=188
05/30/2022 12:50:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
05/30/2022 12:50:47 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.896578690127077 on epoch=189
05/30/2022 12:50:49 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.13 on epoch=189
05/30/2022 12:50:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=190
05/30/2022 12:50:54 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=191
05/30/2022 12:50:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=192
05/30/2022 12:50:59 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=192
05/30/2022 12:51:05 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.7818732765323394 on epoch=192
05/30/2022 12:51:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.09 on epoch=193
05/30/2022 12:51:10 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=194
05/30/2022 12:51:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=194
05/30/2022 12:51:15 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=195
05/30/2022 12:51:17 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.09 on epoch=196
05/30/2022 12:51:23 - INFO - __main__ - Global step 2750 Train loss 0.07 Classification-F1 0.7817546807069123 on epoch=196
05/30/2022 12:51:26 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=197
05/30/2022 12:51:28 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=197
05/30/2022 12:51:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=198
05/30/2022 12:51:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
05/30/2022 12:51:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
05/30/2022 12:51:42 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.8457697947214076 on epoch=199
05/30/2022 12:51:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
05/30/2022 12:51:47 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=201
05/30/2022 12:51:49 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.10 on epoch=202
05/30/2022 12:51:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
05/30/2022 12:51:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
05/30/2022 12:52:00 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.9015296457343174 on epoch=203
05/30/2022 12:52:00 - INFO - __main__ - Saving model with best Classification-F1: 0.8981219000036202 -> 0.9015296457343174 on epoch=203, global_step=2850
05/30/2022 12:52:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=204
05/30/2022 12:52:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=204
05/30/2022 12:52:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=205
05/30/2022 12:52:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=206
05/30/2022 12:52:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=207
05/30/2022 12:52:18 - INFO - __main__ - Global step 2900 Train loss 0.07 Classification-F1 0.6825494156963247 on epoch=207
05/30/2022 12:52:21 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
05/30/2022 12:52:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.06 on epoch=208
05/30/2022 12:52:26 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=209
05/30/2022 12:52:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.16 on epoch=209
05/30/2022 12:52:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.10 on epoch=210
05/30/2022 12:52:37 - INFO - __main__ - Global step 2950 Train loss 0.09 Classification-F1 0.9186705767350927 on epoch=210
05/30/2022 12:52:37 - INFO - __main__ - Saving model with best Classification-F1: 0.9015296457343174 -> 0.9186705767350927 on epoch=210, global_step=2950
05/30/2022 12:52:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
05/30/2022 12:52:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.09 on epoch=212
05/30/2022 12:52:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
05/30/2022 12:52:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.18 on epoch=213
05/30/2022 12:52:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
05/30/2022 12:52:51 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 12:52:51 - INFO - __main__ - Printing 3 examples
05/30/2022 12:52:51 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/30/2022 12:52:51 - INFO - __main__ - ['Company']
05/30/2022 12:52:51 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/30/2022 12:52:51 - INFO - __main__ - ['Company']
05/30/2022 12:52:51 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/30/2022 12:52:51 - INFO - __main__ - ['Company']
05/30/2022 12:52:51 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:52:51 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:52:51 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 12:52:51 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 12:52:51 - INFO - __main__ - Printing 3 examples
05/30/2022 12:52:51 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/30/2022 12:52:51 - INFO - __main__ - ['Company']
05/30/2022 12:52:51 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/30/2022 12:52:51 - INFO - __main__ - ['Company']
05/30/2022 12:52:51 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/30/2022 12:52:51 - INFO - __main__ - ['Company']
05/30/2022 12:52:51 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:52:51 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:52:51 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 12:52:55 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.8488467177983308 on epoch=214
05/30/2022 12:52:55 - INFO - __main__ - save last model!
05/30/2022 12:52:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 12:52:55 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 12:52:55 - INFO - __main__ - Printing 3 examples
05/30/2022 12:52:55 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 12:52:55 - INFO - __main__ - ['Animal']
05/30/2022 12:52:55 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 12:52:55 - INFO - __main__ - ['Animal']
05/30/2022 12:52:55 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 12:52:55 - INFO - __main__ - ['Village']
05/30/2022 12:52:55 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:52:57 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:53:01 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 12:53:06 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 12:53:06 - INFO - __main__ - task name: dbpedia_14
05/30/2022 12:53:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 12:53:07 - INFO - __main__ - Starting training!
05/30/2022 12:55:06 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
05/30/2022 12:55:06 - INFO - __main__ - Classification-F1 on test data: 0.5388
05/30/2022 12:55:07 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.9186705767350927, test_performance=0.5387860375256505
05/30/2022 12:55:07 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
05/30/2022 12:55:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 12:55:08 - INFO - __main__ - Printing 3 examples
05/30/2022 12:55:08 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/30/2022 12:55:08 - INFO - __main__ - ['Company']
05/30/2022 12:55:08 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/30/2022 12:55:08 - INFO - __main__ - ['Company']
05/30/2022 12:55:08 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/30/2022 12:55:08 - INFO - __main__ - ['Company']
05/30/2022 12:55:08 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:55:08 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:55:08 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 12:55:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 12:55:08 - INFO - __main__ - Printing 3 examples
05/30/2022 12:55:08 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/30/2022 12:55:08 - INFO - __main__ - ['Company']
05/30/2022 12:55:08 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/30/2022 12:55:08 - INFO - __main__ - ['Company']
05/30/2022 12:55:08 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/30/2022 12:55:08 - INFO - __main__ - ['Company']
05/30/2022 12:55:08 - INFO - __main__ - Tokenizing Input ...
05/30/2022 12:55:08 - INFO - __main__ - Tokenizing Output ...
05/30/2022 12:55:08 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 12:55:27 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 12:55:27 - INFO - __main__ - task name: dbpedia_14
05/30/2022 12:55:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 12:55:28 - INFO - __main__ - Starting training!
05/30/2022 12:55:31 - INFO - __main__ - Step 10 Global step 10 Train loss 6.79 on epoch=0
05/30/2022 12:55:33 - INFO - __main__ - Step 20 Global step 20 Train loss 6.59 on epoch=1
05/30/2022 12:55:36 - INFO - __main__ - Step 30 Global step 30 Train loss 6.01 on epoch=2
05/30/2022 12:55:38 - INFO - __main__ - Step 40 Global step 40 Train loss 4.70 on epoch=2
05/30/2022 12:55:41 - INFO - __main__ - Step 50 Global step 50 Train loss 4.70 on epoch=3
05/30/2022 12:56:43 - INFO - __main__ - Global step 50 Train loss 5.76 Classification-F1 0.0011111111111111111 on epoch=3
05/30/2022 12:56:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0011111111111111111 on epoch=3, global_step=50
05/30/2022 12:56:46 - INFO - __main__ - Step 60 Global step 60 Train loss 3.84 on epoch=4
05/30/2022 12:56:48 - INFO - __main__ - Step 70 Global step 70 Train loss 3.31 on epoch=4
05/30/2022 12:56:51 - INFO - __main__ - Step 80 Global step 80 Train loss 2.76 on epoch=5
05/30/2022 12:56:53 - INFO - __main__ - Step 90 Global step 90 Train loss 2.62 on epoch=6
05/30/2022 12:56:56 - INFO - __main__ - Step 100 Global step 100 Train loss 2.29 on epoch=7
05/30/2022 12:57:20 - INFO - __main__ - Global step 100 Train loss 2.96 Classification-F1 0.11918769820616956 on epoch=7
05/30/2022 12:57:20 - INFO - __main__ - Saving model with best Classification-F1: 0.0011111111111111111 -> 0.11918769820616956 on epoch=7, global_step=100
05/30/2022 12:57:22 - INFO - __main__ - Step 110 Global step 110 Train loss 2.03 on epoch=7
05/30/2022 12:57:25 - INFO - __main__ - Step 120 Global step 120 Train loss 1.97 on epoch=8
05/30/2022 12:57:27 - INFO - __main__ - Step 130 Global step 130 Train loss 1.88 on epoch=9
05/30/2022 12:57:30 - INFO - __main__ - Step 140 Global step 140 Train loss 1.63 on epoch=9
05/30/2022 12:57:32 - INFO - __main__ - Step 150 Global step 150 Train loss 1.54 on epoch=10
05/30/2022 12:57:46 - INFO - __main__ - Global step 150 Train loss 1.81 Classification-F1 0.2057653351706796 on epoch=10
05/30/2022 12:57:46 - INFO - __main__ - Saving model with best Classification-F1: 0.11918769820616956 -> 0.2057653351706796 on epoch=10, global_step=150
05/30/2022 12:57:49 - INFO - __main__ - Step 160 Global step 160 Train loss 1.62 on epoch=11
05/30/2022 12:57:51 - INFO - __main__ - Step 170 Global step 170 Train loss 1.41 on epoch=12
05/30/2022 12:57:54 - INFO - __main__ - Step 180 Global step 180 Train loss 1.31 on epoch=12
05/30/2022 12:57:56 - INFO - __main__ - Step 190 Global step 190 Train loss 1.20 on epoch=13
05/30/2022 12:57:59 - INFO - __main__ - Step 200 Global step 200 Train loss 1.28 on epoch=14
05/30/2022 12:58:05 - INFO - __main__ - Global step 200 Train loss 1.37 Classification-F1 0.38770968898110375 on epoch=14
05/30/2022 12:58:05 - INFO - __main__ - Saving model with best Classification-F1: 0.2057653351706796 -> 0.38770968898110375 on epoch=14, global_step=200
05/30/2022 12:58:08 - INFO - __main__ - Step 210 Global step 210 Train loss 1.19 on epoch=14
05/30/2022 12:58:10 - INFO - __main__ - Step 220 Global step 220 Train loss 1.09 on epoch=15
05/30/2022 12:58:13 - INFO - __main__ - Step 230 Global step 230 Train loss 1.07 on epoch=16
05/30/2022 12:58:15 - INFO - __main__ - Step 240 Global step 240 Train loss 1.00 on epoch=17
05/30/2022 12:58:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.95 on epoch=17
05/30/2022 12:58:23 - INFO - __main__ - Global step 250 Train loss 1.06 Classification-F1 0.3831332207341123 on epoch=17
05/30/2022 12:58:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.89 on epoch=18
05/30/2022 12:58:28 - INFO - __main__ - Step 270 Global step 270 Train loss 1.08 on epoch=19
05/30/2022 12:58:31 - INFO - __main__ - Step 280 Global step 280 Train loss 1.00 on epoch=19
05/30/2022 12:58:33 - INFO - __main__ - Step 290 Global step 290 Train loss 0.89 on epoch=20
05/30/2022 12:58:36 - INFO - __main__ - Step 300 Global step 300 Train loss 0.93 on epoch=21
05/30/2022 12:58:41 - INFO - __main__ - Global step 300 Train loss 0.96 Classification-F1 0.39574987864388583 on epoch=21
05/30/2022 12:58:41 - INFO - __main__ - Saving model with best Classification-F1: 0.38770968898110375 -> 0.39574987864388583 on epoch=21, global_step=300
05/30/2022 12:58:44 - INFO - __main__ - Step 310 Global step 310 Train loss 0.87 on epoch=22
05/30/2022 12:58:46 - INFO - __main__ - Step 320 Global step 320 Train loss 0.81 on epoch=22
05/30/2022 12:58:49 - INFO - __main__ - Step 330 Global step 330 Train loss 0.81 on epoch=23
05/30/2022 12:58:51 - INFO - __main__ - Step 340 Global step 340 Train loss 0.77 on epoch=24
05/30/2022 12:58:54 - INFO - __main__ - Step 350 Global step 350 Train loss 0.78 on epoch=24
05/30/2022 12:59:00 - INFO - __main__ - Global step 350 Train loss 0.81 Classification-F1 0.33221311016092764 on epoch=24
05/30/2022 12:59:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.69 on epoch=25
05/30/2022 12:59:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.79 on epoch=26
05/30/2022 12:59:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.79 on epoch=27
05/30/2022 12:59:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.70 on epoch=27
05/30/2022 12:59:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.64 on epoch=28
05/30/2022 12:59:18 - INFO - __main__ - Global step 400 Train loss 0.72 Classification-F1 0.4563993607410135 on epoch=28
05/30/2022 12:59:18 - INFO - __main__ - Saving model with best Classification-F1: 0.39574987864388583 -> 0.4563993607410135 on epoch=28, global_step=400
05/30/2022 12:59:21 - INFO - __main__ - Step 410 Global step 410 Train loss 0.76 on epoch=29
05/30/2022 12:59:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.66 on epoch=29
05/30/2022 12:59:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.68 on epoch=30
05/30/2022 12:59:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.75 on epoch=31
05/30/2022 12:59:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.63 on epoch=32
05/30/2022 12:59:37 - INFO - __main__ - Global step 450 Train loss 0.70 Classification-F1 0.512784082599865 on epoch=32
05/30/2022 12:59:37 - INFO - __main__ - Saving model with best Classification-F1: 0.4563993607410135 -> 0.512784082599865 on epoch=32, global_step=450
05/30/2022 12:59:40 - INFO - __main__ - Step 460 Global step 460 Train loss 0.64 on epoch=32
05/30/2022 12:59:42 - INFO - __main__ - Step 470 Global step 470 Train loss 0.61 on epoch=33
05/30/2022 12:59:45 - INFO - __main__ - Step 480 Global step 480 Train loss 0.61 on epoch=34
05/30/2022 12:59:47 - INFO - __main__ - Step 490 Global step 490 Train loss 0.64 on epoch=34
05/30/2022 12:59:50 - INFO - __main__ - Step 500 Global step 500 Train loss 0.62 on epoch=35
05/30/2022 12:59:56 - INFO - __main__ - Global step 500 Train loss 0.63 Classification-F1 0.554682916778505 on epoch=35
05/30/2022 12:59:56 - INFO - __main__ - Saving model with best Classification-F1: 0.512784082599865 -> 0.554682916778505 on epoch=35, global_step=500
05/30/2022 12:59:59 - INFO - __main__ - Step 510 Global step 510 Train loss 0.53 on epoch=36
05/30/2022 13:00:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.52 on epoch=37
05/30/2022 13:00:04 - INFO - __main__ - Step 530 Global step 530 Train loss 0.60 on epoch=37
05/30/2022 13:00:06 - INFO - __main__ - Step 540 Global step 540 Train loss 0.49 on epoch=38
05/30/2022 13:00:09 - INFO - __main__ - Step 550 Global step 550 Train loss 0.64 on epoch=39
05/30/2022 13:00:15 - INFO - __main__ - Global step 550 Train loss 0.56 Classification-F1 0.5656625773688442 on epoch=39
05/30/2022 13:00:15 - INFO - __main__ - Saving model with best Classification-F1: 0.554682916778505 -> 0.5656625773688442 on epoch=39, global_step=550
05/30/2022 13:00:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.66 on epoch=39
05/30/2022 13:00:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.53 on epoch=40
05/30/2022 13:00:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.53 on epoch=41
05/30/2022 13:00:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.52 on epoch=42
05/30/2022 13:00:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.51 on epoch=42
05/30/2022 13:00:33 - INFO - __main__ - Global step 600 Train loss 0.55 Classification-F1 0.6206081289270127 on epoch=42
05/30/2022 13:00:33 - INFO - __main__ - Saving model with best Classification-F1: 0.5656625773688442 -> 0.6206081289270127 on epoch=42, global_step=600
05/30/2022 13:00:36 - INFO - __main__ - Step 610 Global step 610 Train loss 0.48 on epoch=43
05/30/2022 13:00:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.48 on epoch=44
05/30/2022 13:00:41 - INFO - __main__ - Step 630 Global step 630 Train loss 0.52 on epoch=44
05/30/2022 13:00:43 - INFO - __main__ - Step 640 Global step 640 Train loss 0.45 on epoch=45
05/30/2022 13:00:45 - INFO - __main__ - Step 650 Global step 650 Train loss 0.61 on epoch=46
05/30/2022 13:00:52 - INFO - __main__ - Global step 650 Train loss 0.51 Classification-F1 0.574624344968378 on epoch=46
05/30/2022 13:00:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.52 on epoch=47
05/30/2022 13:00:57 - INFO - __main__ - Step 670 Global step 670 Train loss 0.44 on epoch=47
05/30/2022 13:00:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.43 on epoch=48
05/30/2022 13:01:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.39 on epoch=49
05/30/2022 13:01:04 - INFO - __main__ - Step 700 Global step 700 Train loss 0.48 on epoch=49
05/30/2022 13:01:10 - INFO - __main__ - Global step 700 Train loss 0.45 Classification-F1 0.6397936521276181 on epoch=49
05/30/2022 13:01:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6206081289270127 -> 0.6397936521276181 on epoch=49, global_step=700
05/30/2022 13:01:13 - INFO - __main__ - Step 710 Global step 710 Train loss 0.38 on epoch=50
05/30/2022 13:01:15 - INFO - __main__ - Step 720 Global step 720 Train loss 0.42 on epoch=51
05/30/2022 13:01:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.40 on epoch=52
05/30/2022 13:01:20 - INFO - __main__ - Step 740 Global step 740 Train loss 0.43 on epoch=52
05/30/2022 13:01:23 - INFO - __main__ - Step 750 Global step 750 Train loss 0.43 on epoch=53
05/30/2022 13:01:28 - INFO - __main__ - Global step 750 Train loss 0.41 Classification-F1 0.525069357691872 on epoch=53
05/30/2022 13:01:31 - INFO - __main__ - Step 760 Global step 760 Train loss 0.43 on epoch=54
05/30/2022 13:01:33 - INFO - __main__ - Step 770 Global step 770 Train loss 0.49 on epoch=54
05/30/2022 13:01:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.35 on epoch=55
05/30/2022 13:01:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.40 on epoch=56
05/30/2022 13:01:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.38 on epoch=57
05/30/2022 13:01:48 - INFO - __main__ - Global step 800 Train loss 0.41 Classification-F1 0.5958105653595525 on epoch=57
05/30/2022 13:01:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.32 on epoch=57
05/30/2022 13:01:53 - INFO - __main__ - Step 820 Global step 820 Train loss 0.37 on epoch=58
05/30/2022 13:01:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.40 on epoch=59
05/30/2022 13:01:58 - INFO - __main__ - Step 840 Global step 840 Train loss 0.43 on epoch=59
05/30/2022 13:02:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.35 on epoch=60
05/30/2022 13:02:06 - INFO - __main__ - Global step 850 Train loss 0.38 Classification-F1 0.5865663762465145 on epoch=60
05/30/2022 13:02:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.36 on epoch=61
05/30/2022 13:02:11 - INFO - __main__ - Step 870 Global step 870 Train loss 0.35 on epoch=62
05/30/2022 13:02:14 - INFO - __main__ - Step 880 Global step 880 Train loss 0.46 on epoch=62
05/30/2022 13:02:16 - INFO - __main__ - Step 890 Global step 890 Train loss 0.38 on epoch=63
05/30/2022 13:02:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.32 on epoch=64
05/30/2022 13:02:25 - INFO - __main__ - Global step 900 Train loss 0.38 Classification-F1 0.6304868575812901 on epoch=64
05/30/2022 13:02:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.39 on epoch=64
05/30/2022 13:02:30 - INFO - __main__ - Step 920 Global step 920 Train loss 0.30 on epoch=65
05/30/2022 13:02:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.32 on epoch=66
05/30/2022 13:02:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.30 on epoch=67
05/30/2022 13:02:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.36 on epoch=67
05/30/2022 13:02:43 - INFO - __main__ - Global step 950 Train loss 0.33 Classification-F1 0.7079754658911238 on epoch=67
05/30/2022 13:02:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6397936521276181 -> 0.7079754658911238 on epoch=67, global_step=950
05/30/2022 13:02:46 - INFO - __main__ - Step 960 Global step 960 Train loss 0.28 on epoch=68
05/30/2022 13:02:48 - INFO - __main__ - Step 970 Global step 970 Train loss 0.37 on epoch=69
05/30/2022 13:02:51 - INFO - __main__ - Step 980 Global step 980 Train loss 0.35 on epoch=69
05/30/2022 13:02:53 - INFO - __main__ - Step 990 Global step 990 Train loss 0.31 on epoch=70
05/30/2022 13:02:56 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.30 on epoch=71
05/30/2022 13:03:02 - INFO - __main__ - Global step 1000 Train loss 0.32 Classification-F1 0.6029347523382562 on epoch=71
05/30/2022 13:03:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.36 on epoch=72
05/30/2022 13:03:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.36 on epoch=72
05/30/2022 13:03:09 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.28 on epoch=73
05/30/2022 13:03:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.26 on epoch=74
05/30/2022 13:03:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.25 on epoch=74
05/30/2022 13:03:20 - INFO - __main__ - Global step 1050 Train loss 0.30 Classification-F1 0.624900639866288 on epoch=74
05/30/2022 13:03:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.32 on epoch=75
05/30/2022 13:03:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.31 on epoch=76
05/30/2022 13:03:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.25 on epoch=77
05/30/2022 13:03:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=77
05/30/2022 13:03:33 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.26 on epoch=78
05/30/2022 13:03:39 - INFO - __main__ - Global step 1100 Train loss 0.28 Classification-F1 0.6405055176789853 on epoch=78
05/30/2022 13:03:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.32 on epoch=79
05/30/2022 13:03:44 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.33 on epoch=79
05/30/2022 13:03:46 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.29 on epoch=80
05/30/2022 13:03:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.27 on epoch=81
05/30/2022 13:03:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.32 on epoch=82
05/30/2022 13:03:57 - INFO - __main__ - Global step 1150 Train loss 0.31 Classification-F1 0.8249611320579061 on epoch=82
05/30/2022 13:03:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7079754658911238 -> 0.8249611320579061 on epoch=82, global_step=1150
05/30/2022 13:04:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.30 on epoch=82
05/30/2022 13:04:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.20 on epoch=83
05/30/2022 13:04:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.25 on epoch=84
05/30/2022 13:04:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.27 on epoch=84
05/30/2022 13:04:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.21 on epoch=85
05/30/2022 13:04:16 - INFO - __main__ - Global step 1200 Train loss 0.25 Classification-F1 0.7500614036118662 on epoch=85
05/30/2022 13:04:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.24 on epoch=86
05/30/2022 13:04:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.28 on epoch=87
05/30/2022 13:04:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.22 on epoch=87
05/30/2022 13:04:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.23 on epoch=88
05/30/2022 13:04:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.25 on epoch=89
05/30/2022 13:04:35 - INFO - __main__ - Global step 1250 Train loss 0.24 Classification-F1 0.8223527517882356 on epoch=89
05/30/2022 13:04:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.27 on epoch=89
05/30/2022 13:04:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=90
05/30/2022 13:04:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.24 on epoch=91
05/30/2022 13:04:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.28 on epoch=92
05/30/2022 13:04:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.22 on epoch=92
05/30/2022 13:04:53 - INFO - __main__ - Global step 1300 Train loss 0.23 Classification-F1 0.7535625932277346 on epoch=92
05/30/2022 13:04:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.14 on epoch=93
05/30/2022 13:04:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.21 on epoch=94
05/30/2022 13:05:01 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.24 on epoch=94
05/30/2022 13:05:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.17 on epoch=95
05/30/2022 13:05:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.20 on epoch=96
05/30/2022 13:05:11 - INFO - __main__ - Global step 1350 Train loss 0.19 Classification-F1 0.6052182984630802 on epoch=96
05/30/2022 13:05:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=97
05/30/2022 13:05:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.22 on epoch=97
05/30/2022 13:05:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=98
05/30/2022 13:05:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.20 on epoch=99
05/30/2022 13:05:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.20 on epoch=99
05/30/2022 13:05:29 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.5813380111682319 on epoch=99
05/30/2022 13:05:32 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=100
05/30/2022 13:05:34 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.16 on epoch=101
05/30/2022 13:05:37 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.21 on epoch=102
05/30/2022 13:05:39 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=102
05/30/2022 13:05:41 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.21 on epoch=103
05/30/2022 13:05:48 - INFO - __main__ - Global step 1450 Train loss 0.17 Classification-F1 0.6907085237730399 on epoch=103
05/30/2022 13:05:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=104
05/30/2022 13:05:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.17 on epoch=104
05/30/2022 13:05:55 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.13 on epoch=105
05/30/2022 13:05:57 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.18 on epoch=106
05/30/2022 13:06:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=107
05/30/2022 13:06:06 - INFO - __main__ - Global step 1500 Train loss 0.15 Classification-F1 0.7243099913970715 on epoch=107
05/30/2022 13:06:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=107
05/30/2022 13:06:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=108
05/30/2022 13:06:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=109
05/30/2022 13:06:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.15 on epoch=109
05/30/2022 13:06:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.14 on epoch=110
05/30/2022 13:06:24 - INFO - __main__ - Global step 1550 Train loss 0.15 Classification-F1 0.901848321928967 on epoch=110
05/30/2022 13:06:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8249611320579061 -> 0.901848321928967 on epoch=110, global_step=1550
05/30/2022 13:06:27 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.13 on epoch=111
05/30/2022 13:06:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.19 on epoch=112
05/30/2022 13:06:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=112
05/30/2022 13:06:34 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=113
05/30/2022 13:06:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.17 on epoch=114
05/30/2022 13:06:42 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.7909874360301306 on epoch=114
05/30/2022 13:06:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=114
05/30/2022 13:06:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=115
05/30/2022 13:06:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=116
05/30/2022 13:06:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=117
05/30/2022 13:06:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.13 on epoch=117
05/30/2022 13:07:00 - INFO - __main__ - Global step 1650 Train loss 0.11 Classification-F1 0.7856088250775158 on epoch=117
05/30/2022 13:07:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
05/30/2022 13:07:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=119
05/30/2022 13:07:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=119
05/30/2022 13:07:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=120
05/30/2022 13:07:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=121
05/30/2022 13:07:18 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.8762461673436427 on epoch=121
05/30/2022 13:07:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.18 on epoch=122
05/30/2022 13:07:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=122
05/30/2022 13:07:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
05/30/2022 13:07:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.13 on epoch=124
05/30/2022 13:07:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=124
05/30/2022 13:07:36 - INFO - __main__ - Global step 1750 Train loss 0.12 Classification-F1 0.8987735856806064 on epoch=124
05/30/2022 13:07:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
05/30/2022 13:07:41 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.16 on epoch=126
05/30/2022 13:07:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=127
05/30/2022 13:07:46 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=127
05/30/2022 13:07:49 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=128
05/30/2022 13:07:55 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.8998851622760543 on epoch=128
05/30/2022 13:07:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=129
05/30/2022 13:08:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.17 on epoch=129
05/30/2022 13:08:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=130
05/30/2022 13:08:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=131
05/30/2022 13:08:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=132
05/30/2022 13:08:13 - INFO - __main__ - Global step 1850 Train loss 0.11 Classification-F1 0.8418440912125684 on epoch=132
05/30/2022 13:08:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
05/30/2022 13:08:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=133
05/30/2022 13:08:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=134
05/30/2022 13:08:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.10 on epoch=134
05/30/2022 13:08:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=135
05/30/2022 13:08:31 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.9038529507599716 on epoch=135
05/30/2022 13:08:31 - INFO - __main__ - Saving model with best Classification-F1: 0.901848321928967 -> 0.9038529507599716 on epoch=135, global_step=1900
05/30/2022 13:08:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=136
05/30/2022 13:08:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=137
05/30/2022 13:08:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=137
05/30/2022 13:08:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
05/30/2022 13:08:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.12 on epoch=139
05/30/2022 13:08:49 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.9054364989848859 on epoch=139
05/30/2022 13:08:49 - INFO - __main__ - Saving model with best Classification-F1: 0.9038529507599716 -> 0.9054364989848859 on epoch=139, global_step=1950
05/30/2022 13:08:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=139
05/30/2022 13:08:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
05/30/2022 13:08:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
05/30/2022 13:08:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.14 on epoch=142
05/30/2022 13:09:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=142
05/30/2022 13:09:06 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.8592375366568915 on epoch=142
05/30/2022 13:09:09 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=143
05/30/2022 13:09:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=144
05/30/2022 13:09:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=144
05/30/2022 13:09:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=145
05/30/2022 13:09:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=146
05/30/2022 13:09:24 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.8978519266944315 on epoch=146
05/30/2022 13:09:27 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=147
05/30/2022 13:09:29 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=147
05/30/2022 13:09:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=148
05/30/2022 13:09:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.09 on epoch=149
05/30/2022 13:09:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=149
05/30/2022 13:09:42 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.851536444856535 on epoch=149
05/30/2022 13:09:45 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
05/30/2022 13:09:47 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.13 on epoch=151
05/30/2022 13:09:50 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.13 on epoch=152
05/30/2022 13:09:52 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=152
05/30/2022 13:09:55 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=153
05/30/2022 13:10:00 - INFO - __main__ - Global step 2150 Train loss 0.09 Classification-F1 0.9735678875655834 on epoch=153
05/30/2022 13:10:00 - INFO - __main__ - Saving model with best Classification-F1: 0.9054364989848859 -> 0.9735678875655834 on epoch=153, global_step=2150
05/30/2022 13:10:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.12 on epoch=154
05/30/2022 13:10:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=154
05/30/2022 13:10:07 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
05/30/2022 13:10:10 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.12 on epoch=156
05/30/2022 13:10:12 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=157
05/30/2022 13:10:18 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.906361308941954 on epoch=157
05/30/2022 13:10:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
05/30/2022 13:10:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=158
05/30/2022 13:10:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
05/30/2022 13:10:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=159
05/30/2022 13:10:30 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.09 on epoch=160
05/30/2022 13:10:35 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.9683999112841616 on epoch=160
05/30/2022 13:10:38 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=161
05/30/2022 13:10:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=162
05/30/2022 13:10:43 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=162
05/30/2022 13:10:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=163
05/30/2022 13:10:48 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=164
05/30/2022 13:10:54 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.9777884394226898 on epoch=164
05/30/2022 13:10:54 - INFO - __main__ - Saving model with best Classification-F1: 0.9735678875655834 -> 0.9777884394226898 on epoch=164, global_step=2300
05/30/2022 13:10:56 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=164
05/30/2022 13:10:59 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
05/30/2022 13:11:01 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
05/30/2022 13:11:03 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=167
05/30/2022 13:11:06 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=167
05/30/2022 13:11:13 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.9777884394226898 on epoch=167
05/30/2022 13:11:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=168
05/30/2022 13:11:18 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
05/30/2022 13:11:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.11 on epoch=169
05/30/2022 13:11:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
05/30/2022 13:11:25 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=171
05/30/2022 13:11:31 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.906361308941954 on epoch=171
05/30/2022 13:11:33 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
05/30/2022 13:11:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
05/30/2022 13:11:38 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/30/2022 13:11:40 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=174
05/30/2022 13:11:43 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=174
05/30/2022 13:11:48 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.9776304656760063 on epoch=174
05/30/2022 13:11:51 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
05/30/2022 13:11:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.11 on epoch=176
05/30/2022 13:11:56 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=177
05/30/2022 13:11:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
05/30/2022 13:12:01 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=178
05/30/2022 13:12:06 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.9688112195024637 on epoch=178
05/30/2022 13:12:09 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=179
05/30/2022 13:12:11 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
05/30/2022 13:12:14 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
05/30/2022 13:12:16 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
05/30/2022 13:12:19 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=182
05/30/2022 13:12:24 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.9776698435972629 on epoch=182
05/30/2022 13:12:27 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=182
05/30/2022 13:12:29 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
05/30/2022 13:12:32 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
05/30/2022 13:12:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=184
05/30/2022 13:12:37 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
05/30/2022 13:12:42 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.9776654796816088 on epoch=185
05/30/2022 13:12:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
05/30/2022 13:12:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
05/30/2022 13:12:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=187
05/30/2022 13:12:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
05/30/2022 13:12:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
05/30/2022 13:13:00 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.9101938742261323 on epoch=189
05/30/2022 13:13:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
05/30/2022 13:13:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
05/30/2022 13:13:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
05/30/2022 13:13:09 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
05/30/2022 13:13:12 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
05/30/2022 13:13:17 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9644463283847264 on epoch=192
05/30/2022 13:13:20 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
05/30/2022 13:13:22 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=194
05/30/2022 13:13:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=194
05/30/2022 13:13:27 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/30/2022 13:13:30 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=196
05/30/2022 13:13:35 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.9038529507599716 on epoch=196
05/30/2022 13:13:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=197
05/30/2022 13:13:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
05/30/2022 13:13:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
05/30/2022 13:13:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
05/30/2022 13:13:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
05/30/2022 13:13:53 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8450280713964219 on epoch=199
05/30/2022 13:13:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
05/30/2022 13:13:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=201
05/30/2022 13:14:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
05/30/2022 13:14:02 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=202
05/30/2022 13:14:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
05/30/2022 13:14:10 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.9228413163897036 on epoch=203
05/30/2022 13:14:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
05/30/2022 13:14:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=204
05/30/2022 13:14:17 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
05/30/2022 13:14:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
05/30/2022 13:14:22 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.07 on epoch=207
05/30/2022 13:14:28 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7971362166180707 on epoch=207
05/30/2022 13:14:30 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
05/30/2022 13:14:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
05/30/2022 13:14:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
05/30/2022 13:14:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
05/30/2022 13:14:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=210
05/30/2022 13:14:45 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.8489955959062258 on epoch=210
05/30/2022 13:14:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=211
05/30/2022 13:14:50 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
05/30/2022 13:14:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
05/30/2022 13:14:55 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.09 on epoch=213
05/30/2022 13:14:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
05/30/2022 13:14:58 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 13:14:58 - INFO - __main__ - Printing 3 examples
05/30/2022 13:14:58 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/30/2022 13:14:58 - INFO - __main__ - ['Company']
05/30/2022 13:14:58 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/30/2022 13:14:58 - INFO - __main__ - ['Company']
05/30/2022 13:14:58 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/30/2022 13:14:58 - INFO - __main__ - ['Company']
05/30/2022 13:14:58 - INFO - __main__ - Tokenizing Input ...
05/30/2022 13:14:58 - INFO - __main__ - Tokenizing Output ...
05/30/2022 13:14:59 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 13:14:59 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 13:14:59 - INFO - __main__ - Printing 3 examples
05/30/2022 13:14:59 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/30/2022 13:14:59 - INFO - __main__ - ['Company']
05/30/2022 13:14:59 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/30/2022 13:14:59 - INFO - __main__ - ['Company']
05/30/2022 13:14:59 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/30/2022 13:14:59 - INFO - __main__ - ['Company']
05/30/2022 13:14:59 - INFO - __main__ - Tokenizing Input ...
05/30/2022 13:14:59 - INFO - __main__ - Tokenizing Output ...
05/30/2022 13:14:59 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 13:15:02 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.859241355083089 on epoch=214
05/30/2022 13:15:02 - INFO - __main__ - save last model!
05/30/2022 13:15:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 13:15:02 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 13:15:02 - INFO - __main__ - Printing 3 examples
05/30/2022 13:15:02 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 13:15:02 - INFO - __main__ - ['Animal']
05/30/2022 13:15:02 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 13:15:02 - INFO - __main__ - ['Animal']
05/30/2022 13:15:02 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 13:15:02 - INFO - __main__ - ['Village']
05/30/2022 13:15:02 - INFO - __main__ - Tokenizing Input ...
05/30/2022 13:15:04 - INFO - __main__ - Tokenizing Output ...
05/30/2022 13:15:08 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 13:15:17 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 13:15:17 - INFO - __main__ - task name: dbpedia_14
05/30/2022 13:15:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 13:15:18 - INFO - __main__ - Starting training!
05/30/2022 13:17:05 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
05/30/2022 13:17:05 - INFO - __main__ - Classification-F1 on test data: 0.5644
05/30/2022 13:17:05 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.9777884394226898, test_performance=0.5644155971505227
05/30/2022 13:17:05 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
05/30/2022 13:17:06 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 13:17:06 - INFO - __main__ - Printing 3 examples
05/30/2022 13:17:06 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/30/2022 13:17:06 - INFO - __main__ - ['Company']
05/30/2022 13:17:06 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/30/2022 13:17:06 - INFO - __main__ - ['Company']
05/30/2022 13:17:06 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/30/2022 13:17:06 - INFO - __main__ - ['Company']
05/30/2022 13:17:06 - INFO - __main__ - Tokenizing Input ...
05/30/2022 13:17:06 - INFO - __main__ - Tokenizing Output ...
05/30/2022 13:17:07 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 13:17:07 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 13:17:07 - INFO - __main__ - Printing 3 examples
05/30/2022 13:17:07 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/30/2022 13:17:07 - INFO - __main__ - ['Company']
05/30/2022 13:17:07 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/30/2022 13:17:07 - INFO - __main__ - ['Company']
05/30/2022 13:17:07 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/30/2022 13:17:07 - INFO - __main__ - ['Company']
05/30/2022 13:17:07 - INFO - __main__ - Tokenizing Input ...
05/30/2022 13:17:07 - INFO - __main__ - Tokenizing Output ...
05/30/2022 13:17:07 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 13:17:22 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 13:17:22 - INFO - __main__ - task name: dbpedia_14
05/30/2022 13:17:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 13:17:23 - INFO - __main__ - Starting training!
05/30/2022 13:17:26 - INFO - __main__ - Step 10 Global step 10 Train loss 6.91 on epoch=0
05/30/2022 13:17:28 - INFO - __main__ - Step 20 Global step 20 Train loss 6.94 on epoch=1
05/30/2022 13:17:31 - INFO - __main__ - Step 30 Global step 30 Train loss 6.41 on epoch=2
05/30/2022 13:17:33 - INFO - __main__ - Step 40 Global step 40 Train loss 5.50 on epoch=2
05/30/2022 13:17:36 - INFO - __main__ - Step 50 Global step 50 Train loss 5.12 on epoch=3
05/30/2022 13:19:13 - INFO - __main__ - Global step 50 Train loss 6.18 Classification-F1 0.0 on epoch=3
05/30/2022 13:19:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/30/2022 13:19:15 - INFO - __main__ - Step 60 Global step 60 Train loss 4.38 on epoch=4
05/30/2022 13:19:17 - INFO - __main__ - Step 70 Global step 70 Train loss 3.69 on epoch=4
05/30/2022 13:19:20 - INFO - __main__ - Step 80 Global step 80 Train loss 3.20 on epoch=5
05/30/2022 13:19:23 - INFO - __main__ - Step 90 Global step 90 Train loss 3.05 on epoch=6
05/30/2022 13:19:25 - INFO - __main__ - Step 100 Global step 100 Train loss 2.69 on epoch=7
05/30/2022 13:19:49 - INFO - __main__ - Global step 100 Train loss 3.40 Classification-F1 0.0507034918041789 on epoch=7
05/30/2022 13:19:49 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0507034918041789 on epoch=7, global_step=100
05/30/2022 13:19:52 - INFO - __main__ - Step 110 Global step 110 Train loss 2.49 on epoch=7
05/30/2022 13:19:54 - INFO - __main__ - Step 120 Global step 120 Train loss 2.40 on epoch=8
05/30/2022 13:19:57 - INFO - __main__ - Step 130 Global step 130 Train loss 2.19 on epoch=9
05/30/2022 13:19:59 - INFO - __main__ - Step 140 Global step 140 Train loss 2.11 on epoch=9
05/30/2022 13:20:02 - INFO - __main__ - Step 150 Global step 150 Train loss 1.95 on epoch=10
05/30/2022 13:20:16 - INFO - __main__ - Global step 150 Train loss 2.23 Classification-F1 0.1733667798049069 on epoch=10
05/30/2022 13:20:16 - INFO - __main__ - Saving model with best Classification-F1: 0.0507034918041789 -> 0.1733667798049069 on epoch=10, global_step=150
05/30/2022 13:20:18 - INFO - __main__ - Step 160 Global step 160 Train loss 2.00 on epoch=11
05/30/2022 13:20:21 - INFO - __main__ - Step 170 Global step 170 Train loss 1.87 on epoch=12
05/30/2022 13:20:23 - INFO - __main__ - Step 180 Global step 180 Train loss 1.59 on epoch=12
05/30/2022 13:20:26 - INFO - __main__ - Step 190 Global step 190 Train loss 1.65 on epoch=13
05/30/2022 13:20:28 - INFO - __main__ - Step 200 Global step 200 Train loss 1.73 on epoch=14
05/30/2022 13:20:40 - INFO - __main__ - Global step 200 Train loss 1.77 Classification-F1 0.23315982263350685 on epoch=14
05/30/2022 13:20:40 - INFO - __main__ - Saving model with best Classification-F1: 0.1733667798049069 -> 0.23315982263350685 on epoch=14, global_step=200
05/30/2022 13:20:42 - INFO - __main__ - Step 210 Global step 210 Train loss 1.42 on epoch=14
05/30/2022 13:20:45 - INFO - __main__ - Step 220 Global step 220 Train loss 1.47 on epoch=15
05/30/2022 13:20:47 - INFO - __main__ - Step 230 Global step 230 Train loss 1.39 on epoch=16
05/30/2022 13:20:50 - INFO - __main__ - Step 240 Global step 240 Train loss 1.48 on epoch=17
05/30/2022 13:20:52 - INFO - __main__ - Step 250 Global step 250 Train loss 1.21 on epoch=17
05/30/2022 13:20:58 - INFO - __main__ - Global step 250 Train loss 1.39 Classification-F1 0.34482349474368007 on epoch=17
05/30/2022 13:20:59 - INFO - __main__ - Saving model with best Classification-F1: 0.23315982263350685 -> 0.34482349474368007 on epoch=17, global_step=250
05/30/2022 13:21:01 - INFO - __main__ - Step 260 Global step 260 Train loss 1.34 on epoch=18
05/30/2022 13:21:03 - INFO - __main__ - Step 270 Global step 270 Train loss 1.24 on epoch=19
05/30/2022 13:21:06 - INFO - __main__ - Step 280 Global step 280 Train loss 1.11 on epoch=19
05/30/2022 13:21:09 - INFO - __main__ - Step 290 Global step 290 Train loss 1.09 on epoch=20
05/30/2022 13:21:11 - INFO - __main__ - Step 300 Global step 300 Train loss 1.26 on epoch=21
05/30/2022 13:21:17 - INFO - __main__ - Global step 300 Train loss 1.21 Classification-F1 0.29092353348881034 on epoch=21
05/30/2022 13:21:20 - INFO - __main__ - Step 310 Global step 310 Train loss 1.04 on epoch=22
05/30/2022 13:21:22 - INFO - __main__ - Step 320 Global step 320 Train loss 1.00 on epoch=22
05/30/2022 13:21:25 - INFO - __main__ - Step 330 Global step 330 Train loss 1.01 on epoch=23
05/30/2022 13:21:27 - INFO - __main__ - Step 340 Global step 340 Train loss 1.08 on epoch=24
05/30/2022 13:21:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.97 on epoch=24
05/30/2022 13:21:36 - INFO - __main__ - Global step 350 Train loss 1.02 Classification-F1 0.27209014872354254 on epoch=24
05/30/2022 13:21:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.94 on epoch=25
05/30/2022 13:21:41 - INFO - __main__ - Step 370 Global step 370 Train loss 1.01 on epoch=26
05/30/2022 13:21:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.95 on epoch=27
05/30/2022 13:21:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.91 on epoch=27
05/30/2022 13:21:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.85 on epoch=28
05/30/2022 13:21:56 - INFO - __main__ - Global step 400 Train loss 0.93 Classification-F1 0.290266993534443 on epoch=28
05/30/2022 13:21:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.89 on epoch=29
05/30/2022 13:22:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.81 on epoch=29
05/30/2022 13:22:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.83 on epoch=30
05/30/2022 13:22:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.69 on epoch=31
05/30/2022 13:22:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.78 on epoch=32
05/30/2022 13:22:16 - INFO - __main__ - Global step 450 Train loss 0.80 Classification-F1 0.30196630783531875 on epoch=32
05/30/2022 13:22:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.75 on epoch=32
05/30/2022 13:22:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.77 on epoch=33
05/30/2022 13:22:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.81 on epoch=34
05/30/2022 13:22:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.75 on epoch=34
05/30/2022 13:22:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.66 on epoch=35
05/30/2022 13:22:34 - INFO - __main__ - Global step 500 Train loss 0.75 Classification-F1 0.36097807528505355 on epoch=35
05/30/2022 13:22:34 - INFO - __main__ - Saving model with best Classification-F1: 0.34482349474368007 -> 0.36097807528505355 on epoch=35, global_step=500
05/30/2022 13:22:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.72 on epoch=36
05/30/2022 13:22:39 - INFO - __main__ - Step 520 Global step 520 Train loss 0.84 on epoch=37
05/30/2022 13:22:42 - INFO - __main__ - Step 530 Global step 530 Train loss 0.64 on epoch=37
05/30/2022 13:22:44 - INFO - __main__ - Step 540 Global step 540 Train loss 0.60 on epoch=38
05/30/2022 13:22:47 - INFO - __main__ - Step 550 Global step 550 Train loss 0.67 on epoch=39
05/30/2022 13:22:53 - INFO - __main__ - Global step 550 Train loss 0.69 Classification-F1 0.3831466865099006 on epoch=39
05/30/2022 13:22:53 - INFO - __main__ - Saving model with best Classification-F1: 0.36097807528505355 -> 0.3831466865099006 on epoch=39, global_step=550
05/30/2022 13:22:56 - INFO - __main__ - Step 560 Global step 560 Train loss 0.63 on epoch=39
05/30/2022 13:22:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.57 on epoch=40
05/30/2022 13:23:01 - INFO - __main__ - Step 580 Global step 580 Train loss 0.64 on epoch=41
05/30/2022 13:23:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.63 on epoch=42
05/30/2022 13:23:06 - INFO - __main__ - Step 600 Global step 600 Train loss 0.59 on epoch=42
05/30/2022 13:23:14 - INFO - __main__ - Global step 600 Train loss 0.61 Classification-F1 0.4472975501463167 on epoch=42
05/30/2022 13:23:14 - INFO - __main__ - Saving model with best Classification-F1: 0.3831466865099006 -> 0.4472975501463167 on epoch=42, global_step=600
05/30/2022 13:23:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.53 on epoch=43
05/30/2022 13:23:19 - INFO - __main__ - Step 620 Global step 620 Train loss 0.81 on epoch=44
05/30/2022 13:23:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.64 on epoch=44
05/30/2022 13:23:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.57 on epoch=45
05/30/2022 13:23:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.57 on epoch=46
05/30/2022 13:23:33 - INFO - __main__ - Global step 650 Train loss 0.62 Classification-F1 0.46337316483219304 on epoch=46
05/30/2022 13:23:33 - INFO - __main__ - Saving model with best Classification-F1: 0.4472975501463167 -> 0.46337316483219304 on epoch=46, global_step=650
05/30/2022 13:23:36 - INFO - __main__ - Step 660 Global step 660 Train loss 0.63 on epoch=47
05/30/2022 13:23:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.52 on epoch=47
05/30/2022 13:23:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.48 on epoch=48
05/30/2022 13:23:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.52 on epoch=49
05/30/2022 13:23:46 - INFO - __main__ - Step 700 Global step 700 Train loss 0.58 on epoch=49
05/30/2022 13:23:52 - INFO - __main__ - Global step 700 Train loss 0.55 Classification-F1 0.4581252788562544 on epoch=49
05/30/2022 13:23:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.43 on epoch=50
05/30/2022 13:23:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.46 on epoch=51
05/30/2022 13:24:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.65 on epoch=52
05/30/2022 13:24:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.41 on epoch=52
05/30/2022 13:24:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.50 on epoch=53
05/30/2022 13:24:11 - INFO - __main__ - Global step 750 Train loss 0.49 Classification-F1 0.4667347377741672 on epoch=53
05/30/2022 13:24:11 - INFO - __main__ - Saving model with best Classification-F1: 0.46337316483219304 -> 0.4667347377741672 on epoch=53, global_step=750
05/30/2022 13:24:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.44 on epoch=54
05/30/2022 13:24:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.49 on epoch=54
05/30/2022 13:24:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.52 on epoch=55
05/30/2022 13:24:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.42 on epoch=56
05/30/2022 13:24:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.51 on epoch=57
05/30/2022 13:24:30 - INFO - __main__ - Global step 800 Train loss 0.48 Classification-F1 0.5478513165312742 on epoch=57
05/30/2022 13:24:30 - INFO - __main__ - Saving model with best Classification-F1: 0.4667347377741672 -> 0.5478513165312742 on epoch=57, global_step=800
05/30/2022 13:24:32 - INFO - __main__ - Step 810 Global step 810 Train loss 0.46 on epoch=57
05/30/2022 13:24:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.41 on epoch=58
05/30/2022 13:24:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.49 on epoch=59
05/30/2022 13:24:40 - INFO - __main__ - Step 840 Global step 840 Train loss 0.44 on epoch=59
05/30/2022 13:24:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.38 on epoch=60
05/30/2022 13:24:49 - INFO - __main__ - Global step 850 Train loss 0.44 Classification-F1 0.5319571262862383 on epoch=60
05/30/2022 13:24:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.48 on epoch=61
05/30/2022 13:24:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.43 on epoch=62
05/30/2022 13:24:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.39 on epoch=62
05/30/2022 13:24:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.38 on epoch=63
05/30/2022 13:25:01 - INFO - __main__ - Step 900 Global step 900 Train loss 0.41 on epoch=64
05/30/2022 13:25:07 - INFO - __main__ - Global step 900 Train loss 0.42 Classification-F1 0.5336046344173092 on epoch=64
05/30/2022 13:25:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.54 on epoch=64
05/30/2022 13:25:12 - INFO - __main__ - Step 920 Global step 920 Train loss 0.33 on epoch=65
05/30/2022 13:25:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.44 on epoch=66
05/30/2022 13:25:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.48 on epoch=67
05/30/2022 13:25:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.35 on epoch=67
05/30/2022 13:25:26 - INFO - __main__ - Global step 950 Train loss 0.42 Classification-F1 0.5094857183528011 on epoch=67
05/30/2022 13:25:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.36 on epoch=68
05/30/2022 13:25:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.37 on epoch=69
05/30/2022 13:25:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.40 on epoch=69
05/30/2022 13:25:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.23 on epoch=70
05/30/2022 13:25:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.42 on epoch=71
05/30/2022 13:25:45 - INFO - __main__ - Global step 1000 Train loss 0.36 Classification-F1 0.5275447588189937 on epoch=71
05/30/2022 13:25:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.28 on epoch=72
05/30/2022 13:25:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.34 on epoch=72
05/30/2022 13:25:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.33 on epoch=73
05/30/2022 13:25:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.38 on epoch=74
05/30/2022 13:25:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.43 on epoch=74
05/30/2022 13:26:03 - INFO - __main__ - Global step 1050 Train loss 0.35 Classification-F1 0.5344831096120537 on epoch=74
05/30/2022 13:26:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.37 on epoch=75
05/30/2022 13:26:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.37 on epoch=76
05/30/2022 13:26:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.38 on epoch=77
05/30/2022 13:26:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.28 on epoch=77
05/30/2022 13:26:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.36 on epoch=78
05/30/2022 13:26:22 - INFO - __main__ - Global step 1100 Train loss 0.35 Classification-F1 0.5817131446909164 on epoch=78
05/30/2022 13:26:22 - INFO - __main__ - Saving model with best Classification-F1: 0.5478513165312742 -> 0.5817131446909164 on epoch=78, global_step=1100
05/30/2022 13:26:25 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.24 on epoch=79
05/30/2022 13:26:27 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.30 on epoch=79
05/30/2022 13:26:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=80
05/30/2022 13:26:32 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.40 on epoch=81
05/30/2022 13:26:35 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.38 on epoch=82
05/30/2022 13:26:41 - INFO - __main__ - Global step 1150 Train loss 0.30 Classification-F1 0.5965461062235256 on epoch=82
05/30/2022 13:26:41 - INFO - __main__ - Saving model with best Classification-F1: 0.5817131446909164 -> 0.5965461062235256 on epoch=82, global_step=1150
05/30/2022 13:26:43 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.29 on epoch=82
05/30/2022 13:26:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.24 on epoch=83
05/30/2022 13:26:48 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.29 on epoch=84
05/30/2022 13:26:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.24 on epoch=84
05/30/2022 13:26:53 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.23 on epoch=85
05/30/2022 13:26:59 - INFO - __main__ - Global step 1200 Train loss 0.26 Classification-F1 0.721508144228167 on epoch=85
05/30/2022 13:26:59 - INFO - __main__ - Saving model with best Classification-F1: 0.5965461062235256 -> 0.721508144228167 on epoch=85, global_step=1200
05/30/2022 13:27:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.34 on epoch=86
05/30/2022 13:27:04 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.27 on epoch=87
05/30/2022 13:27:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.24 on epoch=87
05/30/2022 13:27:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.27 on epoch=88
05/30/2022 13:27:12 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.27 on epoch=89
05/30/2022 13:27:18 - INFO - __main__ - Global step 1250 Train loss 0.28 Classification-F1 0.6543505185682855 on epoch=89
05/30/2022 13:27:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.27 on epoch=89
05/30/2022 13:27:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.22 on epoch=90
05/30/2022 13:27:25 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.39 on epoch=91
05/30/2022 13:27:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.29 on epoch=92
05/30/2022 13:27:30 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=92
05/30/2022 13:27:36 - INFO - __main__ - Global step 1300 Train loss 0.27 Classification-F1 0.733097430498137 on epoch=92
05/30/2022 13:27:36 - INFO - __main__ - Saving model with best Classification-F1: 0.721508144228167 -> 0.733097430498137 on epoch=92, global_step=1300
05/30/2022 13:27:39 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.25 on epoch=93
05/30/2022 13:27:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.21 on epoch=94
05/30/2022 13:27:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.20 on epoch=94
05/30/2022 13:27:46 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.22 on epoch=95
05/30/2022 13:27:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.24 on epoch=96
05/30/2022 13:27:55 - INFO - __main__ - Global step 1350 Train loss 0.22 Classification-F1 0.6367276896095682 on epoch=96
05/30/2022 13:27:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.17 on epoch=97
05/30/2022 13:28:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.28 on epoch=97
05/30/2022 13:28:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.22 on epoch=98
05/30/2022 13:28:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.18 on epoch=99
05/30/2022 13:28:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.24 on epoch=99
05/30/2022 13:28:13 - INFO - __main__ - Global step 1400 Train loss 0.21 Classification-F1 0.6946631173040146 on epoch=99
05/30/2022 13:28:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.18 on epoch=100
05/30/2022 13:28:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.18 on epoch=101
05/30/2022 13:28:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.22 on epoch=102
05/30/2022 13:28:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.19 on epoch=102
05/30/2022 13:28:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.18 on epoch=103
05/30/2022 13:28:32 - INFO - __main__ - Global step 1450 Train loss 0.19 Classification-F1 0.6791601187898931 on epoch=103
05/30/2022 13:28:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.24 on epoch=104
05/30/2022 13:28:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.16 on epoch=104
05/30/2022 13:28:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.22 on epoch=105
05/30/2022 13:28:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.18 on epoch=106
05/30/2022 13:28:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.22 on epoch=107
05/30/2022 13:28:51 - INFO - __main__ - Global step 1500 Train loss 0.20 Classification-F1 0.5995465406755729 on epoch=107
05/30/2022 13:28:53 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.19 on epoch=107
05/30/2022 13:28:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.29 on epoch=108
05/30/2022 13:28:58 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.27 on epoch=109
05/30/2022 13:29:01 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.17 on epoch=109
05/30/2022 13:29:03 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.25 on epoch=110
05/30/2022 13:29:10 - INFO - __main__ - Global step 1550 Train loss 0.23 Classification-F1 0.6476685959245666 on epoch=110
05/30/2022 13:29:12 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.18 on epoch=111
05/30/2022 13:29:15 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.26 on epoch=112
05/30/2022 13:29:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.25 on epoch=112
05/30/2022 13:29:20 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.14 on epoch=113
05/30/2022 13:29:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.14 on epoch=114
05/30/2022 13:29:28 - INFO - __main__ - Global step 1600 Train loss 0.20 Classification-F1 0.7255918364789332 on epoch=114
05/30/2022 13:29:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.18 on epoch=114
05/30/2022 13:29:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=115
05/30/2022 13:29:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.16 on epoch=116
05/30/2022 13:29:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.16 on epoch=117
05/30/2022 13:29:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.17 on epoch=117
05/30/2022 13:29:47 - INFO - __main__ - Global step 1650 Train loss 0.15 Classification-F1 0.7266326117132569 on epoch=117
05/30/2022 13:29:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=118
05/30/2022 13:29:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=119
05/30/2022 13:29:55 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=119
05/30/2022 13:29:57 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.19 on epoch=120
05/30/2022 13:30:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.19 on epoch=121
05/30/2022 13:30:06 - INFO - __main__ - Global step 1700 Train loss 0.15 Classification-F1 0.7700872964331498 on epoch=121
05/30/2022 13:30:06 - INFO - __main__ - Saving model with best Classification-F1: 0.733097430498137 -> 0.7700872964331498 on epoch=121, global_step=1700
05/30/2022 13:30:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=122
05/30/2022 13:30:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
05/30/2022 13:30:13 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.15 on epoch=123
05/30/2022 13:30:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.14 on epoch=124
05/30/2022 13:30:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.15 on epoch=124
05/30/2022 13:30:25 - INFO - __main__ - Global step 1750 Train loss 0.13 Classification-F1 0.7675383565535927 on epoch=124
05/30/2022 13:30:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.12 on epoch=125
05/30/2022 13:30:30 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.18 on epoch=126
05/30/2022 13:30:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.14 on epoch=127
05/30/2022 13:30:35 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=127
05/30/2022 13:30:37 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.16 on epoch=128
05/30/2022 13:30:44 - INFO - __main__ - Global step 1800 Train loss 0.14 Classification-F1 0.8292656080533134 on epoch=128
05/30/2022 13:30:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7700872964331498 -> 0.8292656080533134 on epoch=128, global_step=1800
05/30/2022 13:30:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.14 on epoch=129
05/30/2022 13:30:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.13 on epoch=129
05/30/2022 13:30:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.14 on epoch=130
05/30/2022 13:30:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=131
05/30/2022 13:30:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=132
05/30/2022 13:31:03 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.7440904731517668 on epoch=132
05/30/2022 13:31:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.13 on epoch=132
05/30/2022 13:31:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.23 on epoch=133
05/30/2022 13:31:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=134
05/30/2022 13:31:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=134
05/30/2022 13:31:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=135
05/30/2022 13:31:22 - INFO - __main__ - Global step 1900 Train loss 0.13 Classification-F1 0.8930951542986157 on epoch=135
05/30/2022 13:31:22 - INFO - __main__ - Saving model with best Classification-F1: 0.8292656080533134 -> 0.8930951542986157 on epoch=135, global_step=1900
05/30/2022 13:31:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=136
05/30/2022 13:31:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.18 on epoch=137
05/30/2022 13:31:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
05/30/2022 13:31:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.15 on epoch=138
05/30/2022 13:31:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.14 on epoch=139
05/30/2022 13:31:40 - INFO - __main__ - Global step 1950 Train loss 0.13 Classification-F1 0.8322200687965549 on epoch=139
05/30/2022 13:31:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.10 on epoch=139
05/30/2022 13:31:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=140
05/30/2022 13:31:48 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.18 on epoch=141
05/30/2022 13:31:50 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.13 on epoch=142
05/30/2022 13:31:53 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=142
05/30/2022 13:31:59 - INFO - __main__ - Global step 2000 Train loss 0.12 Classification-F1 0.7363287710826643 on epoch=142
05/30/2022 13:32:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=143
05/30/2022 13:32:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=144
05/30/2022 13:32:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.17 on epoch=144
05/30/2022 13:32:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=145
05/30/2022 13:32:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.12 on epoch=146
05/30/2022 13:32:18 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.702136260739826 on epoch=146
05/30/2022 13:32:20 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.15 on epoch=147
05/30/2022 13:32:23 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=147
05/30/2022 13:32:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.10 on epoch=148
05/30/2022 13:32:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=149
05/30/2022 13:32:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.12 on epoch=149
05/30/2022 13:32:37 - INFO - __main__ - Global step 2100 Train loss 0.11 Classification-F1 0.735710503654052 on epoch=149
05/30/2022 13:32:39 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
05/30/2022 13:32:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=151
05/30/2022 13:32:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.16 on epoch=152
05/30/2022 13:32:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=152
05/30/2022 13:32:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=153
05/30/2022 13:32:55 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.6902997346918182 on epoch=153
05/30/2022 13:32:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.08 on epoch=154
05/30/2022 13:33:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.15 on epoch=154
05/30/2022 13:33:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=155
05/30/2022 13:33:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.11 on epoch=156
05/30/2022 13:33:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.11 on epoch=157
05/30/2022 13:33:14 - INFO - __main__ - Global step 2200 Train loss 0.11 Classification-F1 0.7360618398924851 on epoch=157
05/30/2022 13:33:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=157
05/30/2022 13:33:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=158
05/30/2022 13:33:21 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.18 on epoch=159
05/30/2022 13:33:24 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
05/30/2022 13:33:26 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=160
05/30/2022 13:33:32 - INFO - __main__ - Global step 2250 Train loss 0.09 Classification-F1 0.7300118042053527 on epoch=160
05/30/2022 13:33:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=161
05/30/2022 13:33:37 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
05/30/2022 13:33:40 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=162
05/30/2022 13:33:42 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.11 on epoch=163
05/30/2022 13:33:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.09 on epoch=164
05/30/2022 13:33:51 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.7890450916942771 on epoch=164
05/30/2022 13:33:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=164
05/30/2022 13:33:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=165
05/30/2022 13:33:58 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=166
05/30/2022 13:34:01 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.14 on epoch=167
05/30/2022 13:34:03 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=167
05/30/2022 13:34:10 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.89460691901394 on epoch=167
05/30/2022 13:34:10 - INFO - __main__ - Saving model with best Classification-F1: 0.8930951542986157 -> 0.89460691901394 on epoch=167, global_step=2350
05/30/2022 13:34:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
05/30/2022 13:34:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.12 on epoch=169
05/30/2022 13:34:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=169
05/30/2022 13:34:20 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=170
05/30/2022 13:34:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=171
05/30/2022 13:34:28 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.8972252162401346 on epoch=171
05/30/2022 13:34:28 - INFO - __main__ - Saving model with best Classification-F1: 0.89460691901394 -> 0.8972252162401346 on epoch=171, global_step=2400
05/30/2022 13:34:31 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.08 on epoch=172
05/30/2022 13:34:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.11 on epoch=172
05/30/2022 13:34:36 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
05/30/2022 13:34:38 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=174
05/30/2022 13:34:41 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=174
05/30/2022 13:34:48 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.8976701550610469 on epoch=174
05/30/2022 13:34:48 - INFO - __main__ - Saving model with best Classification-F1: 0.8972252162401346 -> 0.8976701550610469 on epoch=174, global_step=2450
05/30/2022 13:34:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
05/30/2022 13:34:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.09 on epoch=176
05/30/2022 13:34:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=177
05/30/2022 13:34:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
05/30/2022 13:35:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.11 on epoch=178
05/30/2022 13:35:07 - INFO - __main__ - Global step 2500 Train loss 0.08 Classification-F1 0.8975643532095143 on epoch=178
05/30/2022 13:35:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=179
05/30/2022 13:35:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=179
05/30/2022 13:35:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=180
05/30/2022 13:35:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
05/30/2022 13:35:20 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=182
05/30/2022 13:35:27 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.8348666552903901 on epoch=182
05/30/2022 13:35:29 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=182
05/30/2022 13:35:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=183
05/30/2022 13:35:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=184
05/30/2022 13:35:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
05/30/2022 13:35:39 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=185
05/30/2022 13:35:47 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.8929241409713176 on epoch=185
05/30/2022 13:35:49 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.09 on epoch=186
05/30/2022 13:35:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
05/30/2022 13:35:54 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=187
05/30/2022 13:35:57 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.10 on epoch=188
05/30/2022 13:35:59 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.12 on epoch=189
05/30/2022 13:36:06 - INFO - __main__ - Global step 2650 Train loss 0.08 Classification-F1 0.9028124563608434 on epoch=189
05/30/2022 13:36:06 - INFO - __main__ - Saving model with best Classification-F1: 0.8976701550610469 -> 0.9028124563608434 on epoch=189, global_step=2650
05/30/2022 13:36:09 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=189
05/30/2022 13:36:11 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=190
05/30/2022 13:36:14 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=191
05/30/2022 13:36:16 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=192
05/30/2022 13:36:19 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=192
05/30/2022 13:36:25 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.8491362719941349 on epoch=192
05/30/2022 13:36:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=193
05/30/2022 13:36:30 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=194
05/30/2022 13:36:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=194
05/30/2022 13:36:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=195
05/30/2022 13:36:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=196
05/30/2022 13:36:44 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.892818339119785 on epoch=196
05/30/2022 13:36:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=197
05/30/2022 13:36:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
05/30/2022 13:36:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.09 on epoch=198
05/30/2022 13:36:54 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.12 on epoch=199
05/30/2022 13:36:56 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
05/30/2022 13:37:03 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.828635578131546 on epoch=199
05/30/2022 13:37:05 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
05/30/2022 13:37:08 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=201
05/30/2022 13:37:10 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
05/30/2022 13:37:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
05/30/2022 13:37:15 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.08 on epoch=203
05/30/2022 13:37:22 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.8901910813201134 on epoch=203
05/30/2022 13:37:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.09 on epoch=204
05/30/2022 13:37:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=204
05/30/2022 13:37:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
05/30/2022 13:37:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=206
05/30/2022 13:37:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.09 on epoch=207
05/30/2022 13:37:41 - INFO - __main__ - Global step 2900 Train loss 0.07 Classification-F1 0.8952704463994787 on epoch=207
05/30/2022 13:37:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=207
05/30/2022 13:37:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=208
05/30/2022 13:37:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=209
05/30/2022 13:37:51 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=209
05/30/2022 13:37:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
05/30/2022 13:38:01 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.9685885351207931 on epoch=210
05/30/2022 13:38:01 - INFO - __main__ - Saving model with best Classification-F1: 0.9028124563608434 -> 0.9685885351207931 on epoch=210, global_step=2950
05/30/2022 13:38:03 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
05/30/2022 13:38:06 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
05/30/2022 13:38:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=212
05/30/2022 13:38:11 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
05/30/2022 13:38:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.08 on epoch=214
05/30/2022 13:38:14 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 13:38:14 - INFO - __main__ - Printing 3 examples
05/30/2022 13:38:14 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/30/2022 13:38:14 - INFO - __main__ - ['Film']
05/30/2022 13:38:14 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/30/2022 13:38:14 - INFO - __main__ - ['Film']
05/30/2022 13:38:14 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/30/2022 13:38:14 - INFO - __main__ - ['Film']
05/30/2022 13:38:14 - INFO - __main__ - Tokenizing Input ...
05/30/2022 13:38:15 - INFO - __main__ - Tokenizing Output ...
05/30/2022 13:38:15 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 13:38:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 13:38:15 - INFO - __main__ - Printing 3 examples
05/30/2022 13:38:15 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/30/2022 13:38:15 - INFO - __main__ - ['Film']
05/30/2022 13:38:15 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/30/2022 13:38:15 - INFO - __main__ - ['Film']
05/30/2022 13:38:15 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/30/2022 13:38:15 - INFO - __main__ - ['Film']
05/30/2022 13:38:15 - INFO - __main__ - Tokenizing Input ...
05/30/2022 13:38:15 - INFO - __main__ - Tokenizing Output ...
05/30/2022 13:38:15 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 13:38:20 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.6947421298439973 on epoch=214
05/30/2022 13:38:20 - INFO - __main__ - save last model!
05/30/2022 13:38:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 13:38:20 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 13:38:20 - INFO - __main__ - Printing 3 examples
05/30/2022 13:38:20 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 13:38:20 - INFO - __main__ - ['Animal']
05/30/2022 13:38:20 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 13:38:20 - INFO - __main__ - ['Animal']
05/30/2022 13:38:20 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 13:38:20 - INFO - __main__ - ['Village']
05/30/2022 13:38:20 - INFO - __main__ - Tokenizing Input ...
05/30/2022 13:38:22 - INFO - __main__ - Tokenizing Output ...
05/30/2022 13:38:25 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 13:38:34 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 13:38:34 - INFO - __main__ - task name: dbpedia_14
05/30/2022 13:38:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 13:38:35 - INFO - __main__ - Starting training!
05/30/2022 13:40:26 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
05/30/2022 13:40:26 - INFO - __main__ - Classification-F1 on test data: 0.4973
05/30/2022 13:40:27 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.9685885351207931, test_performance=0.49728121824187793
05/30/2022 13:40:27 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
05/30/2022 13:40:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 13:40:28 - INFO - __main__ - Printing 3 examples
05/30/2022 13:40:28 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/30/2022 13:40:28 - INFO - __main__ - ['Film']
05/30/2022 13:40:28 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/30/2022 13:40:28 - INFO - __main__ - ['Film']
05/30/2022 13:40:28 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/30/2022 13:40:28 - INFO - __main__ - ['Film']
05/30/2022 13:40:28 - INFO - __main__ - Tokenizing Input ...
05/30/2022 13:40:28 - INFO - __main__ - Tokenizing Output ...
05/30/2022 13:40:28 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 13:40:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 13:40:28 - INFO - __main__ - Printing 3 examples
05/30/2022 13:40:28 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/30/2022 13:40:28 - INFO - __main__ - ['Film']
05/30/2022 13:40:28 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/30/2022 13:40:28 - INFO - __main__ - ['Film']
05/30/2022 13:40:28 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/30/2022 13:40:28 - INFO - __main__ - ['Film']
05/30/2022 13:40:28 - INFO - __main__ - Tokenizing Input ...
05/30/2022 13:40:28 - INFO - __main__ - Tokenizing Output ...
05/30/2022 13:40:28 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 13:40:43 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 13:40:43 - INFO - __main__ - task name: dbpedia_14
05/30/2022 13:40:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 13:40:44 - INFO - __main__ - Starting training!
05/30/2022 13:40:47 - INFO - __main__ - Step 10 Global step 10 Train loss 6.90 on epoch=0
05/30/2022 13:40:49 - INFO - __main__ - Step 20 Global step 20 Train loss 5.64 on epoch=1
05/30/2022 13:40:52 - INFO - __main__ - Step 30 Global step 30 Train loss 4.28 on epoch=2
05/30/2022 13:40:54 - INFO - __main__ - Step 40 Global step 40 Train loss 3.36 on epoch=2
05/30/2022 13:40:56 - INFO - __main__ - Step 50 Global step 50 Train loss 2.73 on epoch=3
05/30/2022 13:41:18 - INFO - __main__ - Global step 50 Train loss 4.58 Classification-F1 0.07441204800915949 on epoch=3
05/30/2022 13:41:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07441204800915949 on epoch=3, global_step=50
05/30/2022 13:41:21 - INFO - __main__ - Step 60 Global step 60 Train loss 2.30 on epoch=4
05/30/2022 13:41:23 - INFO - __main__ - Step 70 Global step 70 Train loss 1.99 on epoch=4
05/30/2022 13:41:26 - INFO - __main__ - Step 80 Global step 80 Train loss 1.83 on epoch=5
05/30/2022 13:41:28 - INFO - __main__ - Step 90 Global step 90 Train loss 1.55 on epoch=6
05/30/2022 13:41:30 - INFO - __main__ - Step 100 Global step 100 Train loss 1.32 on epoch=7
05/30/2022 13:41:37 - INFO - __main__ - Global step 100 Train loss 1.80 Classification-F1 0.38151943253862525 on epoch=7
05/30/2022 13:41:37 - INFO - __main__ - Saving model with best Classification-F1: 0.07441204800915949 -> 0.38151943253862525 on epoch=7, global_step=100
05/30/2022 13:41:39 - INFO - __main__ - Step 110 Global step 110 Train loss 1.13 on epoch=7
05/30/2022 13:41:42 - INFO - __main__ - Step 120 Global step 120 Train loss 1.21 on epoch=8
05/30/2022 13:41:44 - INFO - __main__ - Step 130 Global step 130 Train loss 1.12 on epoch=9
05/30/2022 13:41:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.98 on epoch=9
05/30/2022 13:41:49 - INFO - __main__ - Step 150 Global step 150 Train loss 0.93 on epoch=10
05/30/2022 13:41:56 - INFO - __main__ - Global step 150 Train loss 1.07 Classification-F1 0.39831892523579693 on epoch=10
05/30/2022 13:41:56 - INFO - __main__ - Saving model with best Classification-F1: 0.38151943253862525 -> 0.39831892523579693 on epoch=10, global_step=150
05/30/2022 13:41:59 - INFO - __main__ - Step 160 Global step 160 Train loss 0.93 on epoch=11
05/30/2022 13:42:01 - INFO - __main__ - Step 170 Global step 170 Train loss 0.88 on epoch=12
05/30/2022 13:42:04 - INFO - __main__ - Step 180 Global step 180 Train loss 0.98 on epoch=12
05/30/2022 13:42:06 - INFO - __main__ - Step 190 Global step 190 Train loss 0.88 on epoch=13
05/30/2022 13:42:08 - INFO - __main__ - Step 200 Global step 200 Train loss 0.74 on epoch=14
05/30/2022 13:42:14 - INFO - __main__ - Global step 200 Train loss 0.88 Classification-F1 0.40624136380752635 on epoch=14
05/30/2022 13:42:14 - INFO - __main__ - Saving model with best Classification-F1: 0.39831892523579693 -> 0.40624136380752635 on epoch=14, global_step=200
05/30/2022 13:42:17 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=14
05/30/2022 13:42:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.72 on epoch=15
05/30/2022 13:42:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.72 on epoch=16
05/30/2022 13:42:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.65 on epoch=17
05/30/2022 13:42:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.54 on epoch=17
05/30/2022 13:42:33 - INFO - __main__ - Global step 250 Train loss 0.66 Classification-F1 0.742112263113622 on epoch=17
05/30/2022 13:42:33 - INFO - __main__ - Saving model with best Classification-F1: 0.40624136380752635 -> 0.742112263113622 on epoch=17, global_step=250
05/30/2022 13:42:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.61 on epoch=18
05/30/2022 13:42:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=19
05/30/2022 13:42:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.60 on epoch=19
05/30/2022 13:42:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.63 on epoch=20
05/30/2022 13:42:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.51 on epoch=21
05/30/2022 13:42:52 - INFO - __main__ - Global step 300 Train loss 0.58 Classification-F1 0.6754037392787869 on epoch=21
05/30/2022 13:42:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.53 on epoch=22
05/30/2022 13:42:57 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=22
05/30/2022 13:42:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.54 on epoch=23
05/30/2022 13:43:02 - INFO - __main__ - Step 340 Global step 340 Train loss 0.48 on epoch=24
05/30/2022 13:43:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.53 on epoch=24
05/30/2022 13:43:10 - INFO - __main__ - Global step 350 Train loss 0.50 Classification-F1 0.666639283475705 on epoch=24
05/30/2022 13:43:13 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=25
05/30/2022 13:43:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.48 on epoch=26
05/30/2022 13:43:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.47 on epoch=27
05/30/2022 13:43:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.44 on epoch=27
05/30/2022 13:43:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.56 on epoch=28
05/30/2022 13:43:30 - INFO - __main__ - Global step 400 Train loss 0.50 Classification-F1 0.7647394133311679 on epoch=28
05/30/2022 13:43:30 - INFO - __main__ - Saving model with best Classification-F1: 0.742112263113622 -> 0.7647394133311679 on epoch=28, global_step=400
05/30/2022 13:43:32 - INFO - __main__ - Step 410 Global step 410 Train loss 0.47 on epoch=29
05/30/2022 13:43:35 - INFO - __main__ - Step 420 Global step 420 Train loss 0.46 on epoch=29
05/30/2022 13:43:37 - INFO - __main__ - Step 430 Global step 430 Train loss 0.44 on epoch=30
05/30/2022 13:43:40 - INFO - __main__ - Step 440 Global step 440 Train loss 0.43 on epoch=31
05/30/2022 13:43:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.45 on epoch=32
05/30/2022 13:43:48 - INFO - __main__ - Global step 450 Train loss 0.45 Classification-F1 0.7770860378830018 on epoch=32
05/30/2022 13:43:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7647394133311679 -> 0.7770860378830018 on epoch=32, global_step=450
05/30/2022 13:43:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.36 on epoch=32
05/30/2022 13:43:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.41 on epoch=33
05/30/2022 13:43:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.43 on epoch=34
05/30/2022 13:43:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.41 on epoch=34
05/30/2022 13:44:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=35
05/30/2022 13:44:07 - INFO - __main__ - Global step 500 Train loss 0.39 Classification-F1 0.8377520524714885 on epoch=35
05/30/2022 13:44:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7770860378830018 -> 0.8377520524714885 on epoch=35, global_step=500
05/30/2022 13:44:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.39 on epoch=36
05/30/2022 13:44:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.35 on epoch=37
05/30/2022 13:44:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.30 on epoch=37
05/30/2022 13:44:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.42 on epoch=38
05/30/2022 13:44:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=39
05/30/2022 13:44:25 - INFO - __main__ - Global step 550 Train loss 0.37 Classification-F1 0.8567508320406112 on epoch=39
05/30/2022 13:44:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8377520524714885 -> 0.8567508320406112 on epoch=39, global_step=550
05/30/2022 13:44:28 - INFO - __main__ - Step 560 Global step 560 Train loss 0.35 on epoch=39
05/30/2022 13:44:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=40
05/30/2022 13:44:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.32 on epoch=41
05/30/2022 13:44:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.36 on epoch=42
05/30/2022 13:44:38 - INFO - __main__ - Step 600 Global step 600 Train loss 0.31 on epoch=42
05/30/2022 13:44:44 - INFO - __main__ - Global step 600 Train loss 0.33 Classification-F1 0.7535514322279029 on epoch=42
05/30/2022 13:44:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=43
05/30/2022 13:44:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.34 on epoch=44
05/30/2022 13:44:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=44
05/30/2022 13:44:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=45
05/30/2022 13:44:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=46
05/30/2022 13:45:03 - INFO - __main__ - Global step 650 Train loss 0.30 Classification-F1 0.5453741585391131 on epoch=46
05/30/2022 13:45:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=47
05/30/2022 13:45:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.29 on epoch=47
05/30/2022 13:45:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.28 on epoch=48
05/30/2022 13:45:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.31 on epoch=49
05/30/2022 13:45:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=49
05/30/2022 13:45:21 - INFO - __main__ - Global step 700 Train loss 0.27 Classification-F1 0.7784641819467135 on epoch=49
05/30/2022 13:45:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=50
05/30/2022 13:45:26 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=51
05/30/2022 13:45:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=52
05/30/2022 13:45:31 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=52
05/30/2022 13:45:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=53
05/30/2022 13:45:40 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.8254590839268259 on epoch=53
05/30/2022 13:45:42 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=54
05/30/2022 13:45:45 - INFO - __main__ - Step 770 Global step 770 Train loss 0.28 on epoch=54
05/30/2022 13:45:47 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=55
05/30/2022 13:45:50 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=56
05/30/2022 13:45:52 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=57
05/30/2022 13:45:58 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.5967300980346522 on epoch=57
05/30/2022 13:46:01 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=57
05/30/2022 13:46:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=58
05/30/2022 13:46:06 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=59
05/30/2022 13:46:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=59
05/30/2022 13:46:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=60
05/30/2022 13:46:16 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.6412966596414503 on epoch=60
05/30/2022 13:46:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=61
05/30/2022 13:46:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=62
05/30/2022 13:46:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=62
05/30/2022 13:46:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.24 on epoch=63
05/30/2022 13:46:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=64
05/30/2022 13:46:35 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.8908347980038748 on epoch=64
05/30/2022 13:46:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8567508320406112 -> 0.8908347980038748 on epoch=64, global_step=900
05/30/2022 13:46:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=64
05/30/2022 13:46:40 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=65
05/30/2022 13:46:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=66
05/30/2022 13:46:45 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=67
05/30/2022 13:46:47 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=67
05/30/2022 13:46:53 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.9394513687950842 on epoch=67
05/30/2022 13:46:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8908347980038748 -> 0.9394513687950842 on epoch=67, global_step=950
05/30/2022 13:46:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=68
05/30/2022 13:46:58 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=69
05/30/2022 13:47:01 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=69
05/30/2022 13:47:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=70
05/30/2022 13:47:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=71
05/30/2022 13:47:11 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.9595316086794714 on epoch=71
05/30/2022 13:47:12 - INFO - __main__ - Saving model with best Classification-F1: 0.9394513687950842 -> 0.9595316086794714 on epoch=71, global_step=1000
05/30/2022 13:47:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=72
05/30/2022 13:47:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=72
05/30/2022 13:47:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=73
05/30/2022 13:47:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=74
05/30/2022 13:47:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=74
05/30/2022 13:47:30 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.9554569855211442 on epoch=74
05/30/2022 13:47:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
05/30/2022 13:47:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=76
05/30/2022 13:47:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=77
05/30/2022 13:47:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=77
05/30/2022 13:47:42 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=78
05/30/2022 13:47:48 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.8991848736663236 on epoch=78
05/30/2022 13:47:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=79
05/30/2022 13:47:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=79
05/30/2022 13:47:56 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=80
05/30/2022 13:47:58 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=81
05/30/2022 13:48:01 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=82
05/30/2022 13:48:07 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.9016484811472706 on epoch=82
05/30/2022 13:48:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
05/30/2022 13:48:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
05/30/2022 13:48:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=84
05/30/2022 13:48:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=84
05/30/2022 13:48:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=85
05/30/2022 13:48:25 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.906035205533995 on epoch=85
05/30/2022 13:48:27 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=86
05/30/2022 13:48:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=87
05/30/2022 13:48:32 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
05/30/2022 13:48:34 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=88
05/30/2022 13:48:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=89
05/30/2022 13:48:43 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.859103128054741 on epoch=89
05/30/2022 13:48:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=89
05/30/2022 13:48:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=90
05/30/2022 13:48:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
05/30/2022 13:48:53 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=92
05/30/2022 13:48:55 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=92
05/30/2022 13:49:01 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.9011223901546482 on epoch=92
05/30/2022 13:49:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=93
05/30/2022 13:49:06 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=94
05/30/2022 13:49:09 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=94
05/30/2022 13:49:11 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
05/30/2022 13:49:14 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
05/30/2022 13:49:19 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.9062396258601192 on epoch=96
05/30/2022 13:49:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
05/30/2022 13:49:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=97
05/30/2022 13:49:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
05/30/2022 13:49:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
05/30/2022 13:49:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
05/30/2022 13:49:37 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.8238442057343267 on epoch=99
05/30/2022 13:49:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
05/30/2022 13:49:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
05/30/2022 13:49:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
05/30/2022 13:49:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
05/30/2022 13:49:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
05/30/2022 13:49:56 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.9730221707451309 on epoch=103
05/30/2022 13:49:56 - INFO - __main__ - Saving model with best Classification-F1: 0.9595316086794714 -> 0.9730221707451309 on epoch=103, global_step=1450
05/30/2022 13:49:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
05/30/2022 13:50:01 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=104
05/30/2022 13:50:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
05/30/2022 13:50:06 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
05/30/2022 13:50:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
05/30/2022 13:50:14 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.959331694554655 on epoch=107
05/30/2022 13:50:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
05/30/2022 13:50:19 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
05/30/2022 13:50:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
05/30/2022 13:50:24 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
05/30/2022 13:50:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
05/30/2022 13:50:32 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.973196830051669 on epoch=110
05/30/2022 13:50:32 - INFO - __main__ - Saving model with best Classification-F1: 0.9730221707451309 -> 0.973196830051669 on epoch=110, global_step=1550
05/30/2022 13:50:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=111
05/30/2022 13:50:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=112
05/30/2022 13:50:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
05/30/2022 13:50:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
05/30/2022 13:50:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=114
05/30/2022 13:50:51 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.89876462510713 on epoch=114
05/30/2022 13:50:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
05/30/2022 13:50:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=115
05/30/2022 13:50:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
05/30/2022 13:51:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
05/30/2022 13:51:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
05/30/2022 13:51:09 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.9776567518503005 on epoch=117
05/30/2022 13:51:09 - INFO - __main__ - Saving model with best Classification-F1: 0.973196830051669 -> 0.9776567518503005 on epoch=117, global_step=1650
05/30/2022 13:51:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
05/30/2022 13:51:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
05/30/2022 13:51:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=119
05/30/2022 13:51:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
05/30/2022 13:51:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=121
05/30/2022 13:51:27 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.9776567518503005 on epoch=121
05/30/2022 13:51:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=122
05/30/2022 13:51:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
05/30/2022 13:51:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=123
05/30/2022 13:51:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
05/30/2022 13:51:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=124
05/30/2022 13:51:45 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.9776567518503005 on epoch=124
05/30/2022 13:51:48 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
05/30/2022 13:51:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
05/30/2022 13:51:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
05/30/2022 13:51:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=127
05/30/2022 13:51:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
05/30/2022 13:52:04 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.9776348295916607 on epoch=128
05/30/2022 13:52:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
05/30/2022 13:52:09 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
05/30/2022 13:52:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/30/2022 13:52:14 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
05/30/2022 13:52:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
05/30/2022 13:52:22 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.9821254014802404 on epoch=132
05/30/2022 13:52:22 - INFO - __main__ - Saving model with best Classification-F1: 0.9776567518503005 -> 0.9821254014802404 on epoch=132, global_step=1850
05/30/2022 13:52:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
05/30/2022 13:52:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
05/30/2022 13:52:30 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
05/30/2022 13:52:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
05/30/2022 13:52:35 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
05/30/2022 13:52:40 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.9685535211151911 on epoch=135
05/30/2022 13:52:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=136
05/30/2022 13:52:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
05/30/2022 13:52:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
05/30/2022 13:52:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
05/30/2022 13:52:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
05/30/2022 13:52:59 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.8942677820445603 on epoch=139
05/30/2022 13:53:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
05/30/2022 13:53:04 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
05/30/2022 13:53:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
05/30/2022 13:53:09 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
05/30/2022 13:53:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
05/30/2022 13:53:17 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9821254014802404 on epoch=142
05/30/2022 13:53:19 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
05/30/2022 13:53:22 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
05/30/2022 13:53:24 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
05/30/2022 13:53:27 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=145
05/30/2022 13:53:29 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
05/30/2022 13:53:35 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9776567518503005 on epoch=146
05/30/2022 13:53:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=147
05/30/2022 13:53:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
05/30/2022 13:53:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
05/30/2022 13:53:45 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
05/30/2022 13:53:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.10 on epoch=149
05/30/2022 13:53:53 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.9821297653958947 on epoch=149
05/30/2022 13:53:53 - INFO - __main__ - Saving model with best Classification-F1: 0.9821254014802404 -> 0.9821297653958947 on epoch=149, global_step=2100
05/30/2022 13:53:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
05/30/2022 13:53:58 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
05/30/2022 13:54:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=152
05/30/2022 13:54:03 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
05/30/2022 13:54:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
05/30/2022 13:54:11 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9822527251369758 on epoch=153
05/30/2022 13:54:11 - INFO - __main__ - Saving model with best Classification-F1: 0.9821297653958947 -> 0.9822527251369758 on epoch=153, global_step=2150
05/30/2022 13:54:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
05/30/2022 13:54:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
05/30/2022 13:54:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
05/30/2022 13:54:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
05/30/2022 13:54:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
05/30/2022 13:54:30 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.9776567518503005 on epoch=157
05/30/2022 13:54:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
05/30/2022 13:54:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
05/30/2022 13:54:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=159
05/30/2022 13:54:40 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
05/30/2022 13:54:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
05/30/2022 13:54:48 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.9819717916492111 on epoch=160
05/30/2022 13:54:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
05/30/2022 13:54:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
05/30/2022 13:54:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
05/30/2022 13:54:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
05/30/2022 13:55:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
05/30/2022 13:55:06 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9865940511101802 on epoch=164
05/30/2022 13:55:06 - INFO - __main__ - Saving model with best Classification-F1: 0.9822527251369758 -> 0.9865940511101802 on epoch=164, global_step=2300
05/30/2022 13:55:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
05/30/2022 13:55:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
05/30/2022 13:55:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
05/30/2022 13:55:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
05/30/2022 13:55:18 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
05/30/2022 13:55:24 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.977796397151236 on epoch=167
05/30/2022 13:55:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
05/30/2022 13:55:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
05/30/2022 13:55:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
05/30/2022 13:55:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
05/30/2022 13:55:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
05/30/2022 13:55:42 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9821254014802404 on epoch=171
05/30/2022 13:55:44 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
05/30/2022 13:55:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/30/2022 13:55:49 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/30/2022 13:55:52 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
05/30/2022 13:55:54 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
05/30/2022 13:55:59 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9777840755070358 on epoch=174
05/30/2022 13:56:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
05/30/2022 13:56:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/30/2022 13:56:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/30/2022 13:56:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
05/30/2022 13:56:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
05/30/2022 13:56:17 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9776567518503005 on epoch=178
05/30/2022 13:56:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
05/30/2022 13:56:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
05/30/2022 13:56:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/30/2022 13:56:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
05/30/2022 13:56:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=182
05/30/2022 13:56:36 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9029598985244147 on epoch=182
05/30/2022 13:56:38 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
05/30/2022 13:56:41 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/30/2022 13:56:43 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
05/30/2022 13:56:46 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/30/2022 13:56:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
05/30/2022 13:56:54 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9821254014802402 on epoch=185
05/30/2022 13:56:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
05/30/2022 13:56:59 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
05/30/2022 13:57:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
05/30/2022 13:57:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
05/30/2022 13:57:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
05/30/2022 13:57:12 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9731618160460666 on epoch=189
05/30/2022 13:57:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/30/2022 13:57:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/30/2022 13:57:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
05/30/2022 13:57:22 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
05/30/2022 13:57:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
05/30/2022 13:57:31 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9685885351207933 on epoch=192
05/30/2022 13:57:33 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
05/30/2022 13:57:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/30/2022 13:57:38 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
05/30/2022 13:57:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/30/2022 13:57:43 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
05/30/2022 13:57:48 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9776567518503005 on epoch=196
05/30/2022 13:57:51 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
05/30/2022 13:57:53 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/30/2022 13:57:56 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
05/30/2022 13:57:58 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
05/30/2022 13:58:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/30/2022 13:58:07 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9776567518503005 on epoch=199
05/30/2022 13:58:09 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
05/30/2022 13:58:12 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
05/30/2022 13:58:14 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
05/30/2022 13:58:17 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/30/2022 13:58:19 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
05/30/2022 13:58:25 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9776567518503005 on epoch=203
05/30/2022 13:58:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
05/30/2022 13:58:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
05/30/2022 13:58:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/30/2022 13:58:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/30/2022 13:58:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/30/2022 13:58:43 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9731881022203606 on epoch=207
05/30/2022 13:58:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
05/30/2022 13:58:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
05/30/2022 13:58:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
05/30/2022 13:58:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
05/30/2022 13:58:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
05/30/2022 13:59:01 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.9733321114369503 on epoch=210
05/30/2022 13:59:04 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
05/30/2022 13:59:06 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
05/30/2022 13:59:09 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
05/30/2022 13:59:11 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=213
05/30/2022 13:59:14 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
05/30/2022 13:59:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 13:59:15 - INFO - __main__ - Printing 3 examples
05/30/2022 13:59:15 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/30/2022 13:59:15 - INFO - __main__ - ['Film']
05/30/2022 13:59:15 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/30/2022 13:59:15 - INFO - __main__ - ['Film']
05/30/2022 13:59:15 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/30/2022 13:59:15 - INFO - __main__ - ['Film']
05/30/2022 13:59:15 - INFO - __main__ - Tokenizing Input ...
05/30/2022 13:59:15 - INFO - __main__ - Tokenizing Output ...
05/30/2022 13:59:15 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 13:59:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 13:59:15 - INFO - __main__ - Printing 3 examples
05/30/2022 13:59:15 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/30/2022 13:59:15 - INFO - __main__ - ['Film']
05/30/2022 13:59:15 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/30/2022 13:59:15 - INFO - __main__ - ['Film']
05/30/2022 13:59:15 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/30/2022 13:59:15 - INFO - __main__ - ['Film']
05/30/2022 13:59:15 - INFO - __main__ - Tokenizing Input ...
05/30/2022 13:59:15 - INFO - __main__ - Tokenizing Output ...
05/30/2022 13:59:16 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 13:59:19 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9688371756327167 on epoch=214
05/30/2022 13:59:19 - INFO - __main__ - save last model!
05/30/2022 13:59:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 13:59:19 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 13:59:19 - INFO - __main__ - Printing 3 examples
05/30/2022 13:59:19 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 13:59:19 - INFO - __main__ - ['Animal']
05/30/2022 13:59:19 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 13:59:19 - INFO - __main__ - ['Animal']
05/30/2022 13:59:19 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 13:59:19 - INFO - __main__ - ['Village']
05/30/2022 13:59:19 - INFO - __main__ - Tokenizing Input ...
05/30/2022 13:59:21 - INFO - __main__ - Tokenizing Output ...
05/30/2022 13:59:25 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 13:59:30 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 13:59:30 - INFO - __main__ - task name: dbpedia_14
05/30/2022 13:59:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 13:59:31 - INFO - __main__ - Starting training!
05/30/2022 14:01:22 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
05/30/2022 14:01:22 - INFO - __main__ - Classification-F1 on test data: 0.7189
05/30/2022 14:01:23 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.9865940511101802, test_performance=0.7188728633188853
05/30/2022 14:01:23 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
05/30/2022 14:01:24 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 14:01:24 - INFO - __main__ - Printing 3 examples
05/30/2022 14:01:24 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/30/2022 14:01:24 - INFO - __main__ - ['Film']
05/30/2022 14:01:24 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/30/2022 14:01:24 - INFO - __main__ - ['Film']
05/30/2022 14:01:24 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/30/2022 14:01:24 - INFO - __main__ - ['Film']
05/30/2022 14:01:24 - INFO - __main__ - Tokenizing Input ...
05/30/2022 14:01:24 - INFO - __main__ - Tokenizing Output ...
05/30/2022 14:01:24 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 14:01:24 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 14:01:24 - INFO - __main__ - Printing 3 examples
05/30/2022 14:01:24 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/30/2022 14:01:24 - INFO - __main__ - ['Film']
05/30/2022 14:01:24 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/30/2022 14:01:24 - INFO - __main__ - ['Film']
05/30/2022 14:01:24 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/30/2022 14:01:24 - INFO - __main__ - ['Film']
05/30/2022 14:01:24 - INFO - __main__ - Tokenizing Input ...
05/30/2022 14:01:24 - INFO - __main__ - Tokenizing Output ...
05/30/2022 14:01:24 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 14:01:39 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 14:01:39 - INFO - __main__ - task name: dbpedia_14
05/30/2022 14:01:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 14:01:40 - INFO - __main__ - Starting training!
05/30/2022 14:01:43 - INFO - __main__ - Step 10 Global step 10 Train loss 6.93 on epoch=0
05/30/2022 14:01:46 - INFO - __main__ - Step 20 Global step 20 Train loss 6.04 on epoch=1
05/30/2022 14:01:48 - INFO - __main__ - Step 30 Global step 30 Train loss 4.96 on epoch=2
05/30/2022 14:01:50 - INFO - __main__ - Step 40 Global step 40 Train loss 3.99 on epoch=2
05/30/2022 14:01:53 - INFO - __main__ - Step 50 Global step 50 Train loss 3.33 on epoch=3
05/30/2022 14:02:16 - INFO - __main__ - Global step 50 Train loss 5.05 Classification-F1 0.025881157087156947 on epoch=3
05/30/2022 14:02:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.025881157087156947 on epoch=3, global_step=50
05/30/2022 14:02:18 - INFO - __main__ - Step 60 Global step 60 Train loss 2.83 on epoch=4
05/30/2022 14:02:21 - INFO - __main__ - Step 70 Global step 70 Train loss 2.64 on epoch=4
05/30/2022 14:02:23 - INFO - __main__ - Step 80 Global step 80 Train loss 2.38 on epoch=5
05/30/2022 14:02:26 - INFO - __main__ - Step 90 Global step 90 Train loss 2.18 on epoch=6
05/30/2022 14:02:28 - INFO - __main__ - Step 100 Global step 100 Train loss 1.97 on epoch=7
05/30/2022 14:02:36 - INFO - __main__ - Global step 100 Train loss 2.40 Classification-F1 0.18754002210330142 on epoch=7
05/30/2022 14:02:36 - INFO - __main__ - Saving model with best Classification-F1: 0.025881157087156947 -> 0.18754002210330142 on epoch=7, global_step=100
05/30/2022 14:02:38 - INFO - __main__ - Step 110 Global step 110 Train loss 1.74 on epoch=7
05/30/2022 14:02:41 - INFO - __main__ - Step 120 Global step 120 Train loss 1.71 on epoch=8
05/30/2022 14:02:43 - INFO - __main__ - Step 130 Global step 130 Train loss 1.55 on epoch=9
05/30/2022 14:02:46 - INFO - __main__ - Step 140 Global step 140 Train loss 1.53 on epoch=9
05/30/2022 14:02:48 - INFO - __main__ - Step 150 Global step 150 Train loss 1.37 on epoch=10
05/30/2022 14:02:56 - INFO - __main__ - Global step 150 Train loss 1.58 Classification-F1 0.2721981686832852 on epoch=10
05/30/2022 14:02:56 - INFO - __main__ - Saving model with best Classification-F1: 0.18754002210330142 -> 0.2721981686832852 on epoch=10, global_step=150
05/30/2022 14:02:59 - INFO - __main__ - Step 160 Global step 160 Train loss 1.21 on epoch=11
05/30/2022 14:03:01 - INFO - __main__ - Step 170 Global step 170 Train loss 1.17 on epoch=12
05/30/2022 14:03:04 - INFO - __main__ - Step 180 Global step 180 Train loss 1.06 on epoch=12
05/30/2022 14:03:06 - INFO - __main__ - Step 190 Global step 190 Train loss 1.15 on epoch=13
05/30/2022 14:03:09 - INFO - __main__ - Step 200 Global step 200 Train loss 1.05 on epoch=14
05/30/2022 14:03:15 - INFO - __main__ - Global step 200 Train loss 1.13 Classification-F1 0.4707238825143881 on epoch=14
05/30/2022 14:03:15 - INFO - __main__ - Saving model with best Classification-F1: 0.2721981686832852 -> 0.4707238825143881 on epoch=14, global_step=200
05/30/2022 14:03:17 - INFO - __main__ - Step 210 Global step 210 Train loss 1.01 on epoch=14
05/30/2022 14:03:20 - INFO - __main__ - Step 220 Global step 220 Train loss 0.97 on epoch=15
05/30/2022 14:03:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.94 on epoch=16
05/30/2022 14:03:25 - INFO - __main__ - Step 240 Global step 240 Train loss 0.88 on epoch=17
05/30/2022 14:03:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.88 on epoch=17
05/30/2022 14:03:33 - INFO - __main__ - Global step 250 Train loss 0.94 Classification-F1 0.38264944796358785 on epoch=17
05/30/2022 14:03:36 - INFO - __main__ - Step 260 Global step 260 Train loss 0.81 on epoch=18
05/30/2022 14:03:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.86 on epoch=19
05/30/2022 14:03:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.72 on epoch=19
05/30/2022 14:03:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.78 on epoch=20
05/30/2022 14:03:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.78 on epoch=21
05/30/2022 14:03:52 - INFO - __main__ - Global step 300 Train loss 0.79 Classification-F1 0.5142013037065243 on epoch=21
05/30/2022 14:03:52 - INFO - __main__ - Saving model with best Classification-F1: 0.4707238825143881 -> 0.5142013037065243 on epoch=21, global_step=300
05/30/2022 14:03:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.63 on epoch=22
05/30/2022 14:03:57 - INFO - __main__ - Step 320 Global step 320 Train loss 0.71 on epoch=22
05/30/2022 14:03:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.72 on epoch=23
05/30/2022 14:04:02 - INFO - __main__ - Step 340 Global step 340 Train loss 0.64 on epoch=24
05/30/2022 14:04:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.67 on epoch=24
05/30/2022 14:04:10 - INFO - __main__ - Global step 350 Train loss 0.68 Classification-F1 0.4322832886276496 on epoch=24
05/30/2022 14:04:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.59 on epoch=25
05/30/2022 14:04:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.57 on epoch=26
05/30/2022 14:04:17 - INFO - __main__ - Step 380 Global step 380 Train loss 0.54 on epoch=27
05/30/2022 14:04:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=27
05/30/2022 14:04:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.55 on epoch=28
05/30/2022 14:04:29 - INFO - __main__ - Global step 400 Train loss 0.55 Classification-F1 0.482298685359304 on epoch=28
05/30/2022 14:04:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.49 on epoch=29
05/30/2022 14:04:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.52 on epoch=29
05/30/2022 14:04:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.46 on epoch=30
05/30/2022 14:04:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.49 on epoch=31
05/30/2022 14:04:41 - INFO - __main__ - Step 450 Global step 450 Train loss 0.51 on epoch=32
05/30/2022 14:04:48 - INFO - __main__ - Global step 450 Train loss 0.49 Classification-F1 0.6971341713565146 on epoch=32
05/30/2022 14:04:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5142013037065243 -> 0.6971341713565146 on epoch=32, global_step=450
05/30/2022 14:04:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.45 on epoch=32
05/30/2022 14:04:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.45 on epoch=33
05/30/2022 14:04:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.47 on epoch=34
05/30/2022 14:04:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=34
05/30/2022 14:05:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.38 on epoch=35
05/30/2022 14:05:07 - INFO - __main__ - Global step 500 Train loss 0.41 Classification-F1 0.5443689418108559 on epoch=35
05/30/2022 14:05:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.49 on epoch=36
05/30/2022 14:05:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.48 on epoch=37
05/30/2022 14:05:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=37
05/30/2022 14:05:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.37 on epoch=38
05/30/2022 14:05:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.47 on epoch=39
05/30/2022 14:05:26 - INFO - __main__ - Global step 550 Train loss 0.43 Classification-F1 0.5443037893127161 on epoch=39
05/30/2022 14:05:28 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=39
05/30/2022 14:05:31 - INFO - __main__ - Step 570 Global step 570 Train loss 0.41 on epoch=40
05/30/2022 14:05:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.42 on epoch=41
05/30/2022 14:05:36 - INFO - __main__ - Step 590 Global step 590 Train loss 0.37 on epoch=42
05/30/2022 14:05:38 - INFO - __main__ - Step 600 Global step 600 Train loss 0.38 on epoch=42
05/30/2022 14:05:44 - INFO - __main__ - Global step 600 Train loss 0.38 Classification-F1 0.5236578357950156 on epoch=42
05/30/2022 14:05:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.33 on epoch=43
05/30/2022 14:05:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.37 on epoch=44
05/30/2022 14:05:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.36 on epoch=44
05/30/2022 14:05:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.30 on epoch=45
05/30/2022 14:05:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.34 on epoch=46
05/30/2022 14:06:03 - INFO - __main__ - Global step 650 Train loss 0.34 Classification-F1 0.5971760821495822 on epoch=46
05/30/2022 14:06:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=47
05/30/2022 14:06:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.33 on epoch=47
05/30/2022 14:06:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=48
05/30/2022 14:06:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=49
05/30/2022 14:06:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.30 on epoch=49
05/30/2022 14:06:21 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.6293416112554617 on epoch=49
05/30/2022 14:06:23 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=50
05/30/2022 14:06:26 - INFO - __main__ - Step 720 Global step 720 Train loss 0.28 on epoch=51
05/30/2022 14:06:28 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=52
05/30/2022 14:06:31 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=52
05/30/2022 14:06:33 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=53
05/30/2022 14:06:40 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.6612486637741307 on epoch=53
05/30/2022 14:06:43 - INFO - __main__ - Step 760 Global step 760 Train loss 0.25 on epoch=54
05/30/2022 14:06:45 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=54
05/30/2022 14:06:48 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=55
05/30/2022 14:06:50 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=56
05/30/2022 14:06:53 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=57
05/30/2022 14:06:59 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.7368668642863635 on epoch=57
05/30/2022 14:06:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6971341713565146 -> 0.7368668642863635 on epoch=57, global_step=800
05/30/2022 14:07:01 - INFO - __main__ - Step 810 Global step 810 Train loss 0.26 on epoch=57
05/30/2022 14:07:04 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=58
05/30/2022 14:07:06 - INFO - __main__ - Step 830 Global step 830 Train loss 0.26 on epoch=59
05/30/2022 14:07:09 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=59
05/30/2022 14:07:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=60
05/30/2022 14:07:18 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.8005981146102115 on epoch=60
05/30/2022 14:07:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7368668642863635 -> 0.8005981146102115 on epoch=60, global_step=850
05/30/2022 14:07:21 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=61
05/30/2022 14:07:23 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=62
05/30/2022 14:07:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=62
05/30/2022 14:07:28 - INFO - __main__ - Step 890 Global step 890 Train loss 0.24 on epoch=63
05/30/2022 14:07:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=64
05/30/2022 14:07:37 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.6976470109450468 on epoch=64
05/30/2022 14:07:40 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=64
05/30/2022 14:07:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.21 on epoch=65
05/30/2022 14:07:45 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=66
05/30/2022 14:07:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=67
05/30/2022 14:07:50 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=67
05/30/2022 14:07:56 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.6167665805180514 on epoch=67
05/30/2022 14:07:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=68
05/30/2022 14:08:01 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=69
05/30/2022 14:08:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=69
05/30/2022 14:08:06 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=70
05/30/2022 14:08:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
05/30/2022 14:08:15 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.8209862449378578 on epoch=71
05/30/2022 14:08:15 - INFO - __main__ - Saving model with best Classification-F1: 0.8005981146102115 -> 0.8209862449378578 on epoch=71, global_step=1000
05/30/2022 14:08:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=72
05/30/2022 14:08:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=72
05/30/2022 14:08:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
05/30/2022 14:08:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=74
05/30/2022 14:08:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.21 on epoch=74
05/30/2022 14:08:34 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.7596280676950374 on epoch=74
05/30/2022 14:08:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=75
05/30/2022 14:08:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.15 on epoch=76
05/30/2022 14:08:42 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=77
05/30/2022 14:08:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
05/30/2022 14:08:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=78
05/30/2022 14:08:54 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.9630242126175984 on epoch=78
05/30/2022 14:08:54 - INFO - __main__ - Saving model with best Classification-F1: 0.8209862449378578 -> 0.9630242126175984 on epoch=78, global_step=1100
05/30/2022 14:08:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=79
05/30/2022 14:08:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=79
05/30/2022 14:09:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.17 on epoch=80
05/30/2022 14:09:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=81
05/30/2022 14:09:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=82
05/30/2022 14:09:12 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.6644100621591542 on epoch=82
05/30/2022 14:09:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
05/30/2022 14:09:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=83
05/30/2022 14:09:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=84
05/30/2022 14:09:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=84
05/30/2022 14:09:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
05/30/2022 14:09:31 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.802188324009956 on epoch=85
05/30/2022 14:09:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
05/30/2022 14:09:36 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
05/30/2022 14:09:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=87
05/30/2022 14:09:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=88
05/30/2022 14:09:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=89
05/30/2022 14:09:49 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.7099962593121487 on epoch=89
05/30/2022 14:09:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=89
05/30/2022 14:09:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=90
05/30/2022 14:09:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=91
05/30/2022 14:09:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=92
05/30/2022 14:10:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=92
05/30/2022 14:10:08 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.7546037707187274 on epoch=92
05/30/2022 14:10:11 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
05/30/2022 14:10:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=94
05/30/2022 14:10:16 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
05/30/2022 14:10:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
05/30/2022 14:10:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=96
05/30/2022 14:10:27 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.9642121951419865 on epoch=96
05/30/2022 14:10:27 - INFO - __main__ - Saving model with best Classification-F1: 0.9630242126175984 -> 0.9642121951419865 on epoch=96, global_step=1350
05/30/2022 14:10:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=97
05/30/2022 14:10:32 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
05/30/2022 14:10:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
05/30/2022 14:10:37 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=99
05/30/2022 14:10:40 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=99
05/30/2022 14:10:46 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.959753933342643 on epoch=99
05/30/2022 14:10:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
05/30/2022 14:10:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
05/30/2022 14:10:54 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=102
05/30/2022 14:10:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=102
05/30/2022 14:10:59 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=103
05/30/2022 14:11:05 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.9728948470883955 on epoch=103
05/30/2022 14:11:05 - INFO - __main__ - Saving model with best Classification-F1: 0.9642121951419865 -> 0.9728948470883955 on epoch=103, global_step=1450
05/30/2022 14:11:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
05/30/2022 14:11:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
05/30/2022 14:11:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
05/30/2022 14:11:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
05/30/2022 14:11:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=107
05/30/2022 14:11:24 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.8433322641739981 on epoch=107
05/30/2022 14:11:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
05/30/2022 14:11:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=108
05/30/2022 14:11:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
05/30/2022 14:11:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
05/30/2022 14:11:37 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
05/30/2022 14:11:43 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.9773073553417727 on epoch=110
05/30/2022 14:11:43 - INFO - __main__ - Saving model with best Classification-F1: 0.9728948470883955 -> 0.9773073553417727 on epoch=110, global_step=1550
05/30/2022 14:11:45 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=111
05/30/2022 14:11:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
05/30/2022 14:11:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
05/30/2022 14:11:53 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
05/30/2022 14:11:55 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=114
05/30/2022 14:12:01 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7787468963614796 on epoch=114
05/30/2022 14:12:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=114
05/30/2022 14:12:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
05/30/2022 14:12:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
05/30/2022 14:12:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
05/30/2022 14:12:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
05/30/2022 14:12:19 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.8551930596285435 on epoch=117
05/30/2022 14:12:22 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=118
05/30/2022 14:12:24 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
05/30/2022 14:12:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
05/30/2022 14:12:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
05/30/2022 14:12:32 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
05/30/2022 14:12:38 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.9821297653958947 on epoch=121
05/30/2022 14:12:38 - INFO - __main__ - Saving model with best Classification-F1: 0.9773073553417727 -> 0.9821297653958947 on epoch=121, global_step=1700
05/30/2022 14:12:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
05/30/2022 14:12:43 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
05/30/2022 14:12:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
05/30/2022 14:12:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
05/30/2022 14:12:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
05/30/2022 14:12:56 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.9058363273512459 on epoch=124
05/30/2022 14:12:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
05/30/2022 14:13:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
05/30/2022 14:13:03 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
05/30/2022 14:13:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
05/30/2022 14:13:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
05/30/2022 14:13:14 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.9865677649358864 on epoch=128
05/30/2022 14:13:14 - INFO - __main__ - Saving model with best Classification-F1: 0.9821297653958947 -> 0.9865677649358864 on epoch=128, global_step=1800
05/30/2022 14:13:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
05/30/2022 14:13:19 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
05/30/2022 14:13:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
05/30/2022 14:13:24 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
05/30/2022 14:13:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
05/30/2022 14:13:32 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8010708716814311 on epoch=132
05/30/2022 14:13:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
05/30/2022 14:13:37 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
05/30/2022 14:13:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
05/30/2022 14:13:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=134
05/30/2022 14:13:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
05/30/2022 14:13:50 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.9185312805474095 on epoch=135
05/30/2022 14:13:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
05/30/2022 14:13:55 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
05/30/2022 14:13:57 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
05/30/2022 14:14:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
05/30/2022 14:14:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
05/30/2022 14:14:08 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.8465485532176771 on epoch=139
05/30/2022 14:14:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
05/30/2022 14:14:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
05/30/2022 14:14:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
05/30/2022 14:14:18 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
05/30/2022 14:14:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
05/30/2022 14:14:26 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9730082062150375 on epoch=142
05/30/2022 14:14:29 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
05/30/2022 14:14:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
05/30/2022 14:14:34 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
05/30/2022 14:14:36 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
05/30/2022 14:14:39 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/30/2022 14:14:44 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9061092902459128 on epoch=146
05/30/2022 14:14:47 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
05/30/2022 14:14:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
05/30/2022 14:14:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
05/30/2022 14:14:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
05/30/2022 14:14:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
05/30/2022 14:15:03 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.8929231783723703 on epoch=149
05/30/2022 14:15:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
05/30/2022 14:15:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
05/30/2022 14:15:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
05/30/2022 14:15:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
05/30/2022 14:15:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
05/30/2022 14:15:21 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7938678371315943 on epoch=153
05/30/2022 14:15:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
05/30/2022 14:15:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
05/30/2022 14:15:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
05/30/2022 14:15:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
05/30/2022 14:15:33 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/30/2022 14:15:39 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9100423590746173 on epoch=157
05/30/2022 14:15:41 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/30/2022 14:15:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
05/30/2022 14:15:46 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
05/30/2022 14:15:49 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
05/30/2022 14:15:51 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
05/30/2022 14:15:57 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9775075059349254 on epoch=160
05/30/2022 14:16:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
05/30/2022 14:16:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
05/30/2022 14:16:05 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/30/2022 14:16:07 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
05/30/2022 14:16:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
05/30/2022 14:16:15 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7356891209197693 on epoch=164
05/30/2022 14:16:17 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
05/30/2022 14:16:20 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
05/30/2022 14:16:22 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
05/30/2022 14:16:25 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
05/30/2022 14:16:27 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
05/30/2022 14:16:33 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7965992262007442 on epoch=167
05/30/2022 14:16:36 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
05/30/2022 14:16:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
05/30/2022 14:16:41 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
05/30/2022 14:16:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
05/30/2022 14:16:46 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
05/30/2022 14:16:51 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8029900523259158 on epoch=171
05/30/2022 14:16:54 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
05/30/2022 14:16:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
05/30/2022 14:16:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
05/30/2022 14:17:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
05/30/2022 14:17:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/30/2022 14:17:10 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.848461674587926 on epoch=174
05/30/2022 14:17:12 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/30/2022 14:17:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/30/2022 14:17:17 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=177
05/30/2022 14:17:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
05/30/2022 14:17:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/30/2022 14:17:28 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9069962295768749 on epoch=178
05/30/2022 14:17:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
05/30/2022 14:17:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
05/30/2022 14:17:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
05/30/2022 14:17:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/30/2022 14:17:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
05/30/2022 14:17:46 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7596922131961065 on epoch=182
05/30/2022 14:17:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/30/2022 14:17:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/30/2022 14:17:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
05/30/2022 14:17:56 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
05/30/2022 14:17:59 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
05/30/2022 14:18:05 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8551930596285435 on epoch=185
05/30/2022 14:18:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
05/30/2022 14:18:10 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/30/2022 14:18:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
05/30/2022 14:18:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
05/30/2022 14:18:17 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/30/2022 14:18:23 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7868928927975697 on epoch=189
05/30/2022 14:18:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
05/30/2022 14:18:28 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/30/2022 14:18:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
05/30/2022 14:18:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
05/30/2022 14:18:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
05/30/2022 14:18:41 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8003841453780064 on epoch=192
05/30/2022 14:18:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=193
05/30/2022 14:18:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=194
05/30/2022 14:18:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/30/2022 14:18:51 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/30/2022 14:18:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
05/30/2022 14:18:59 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8562351626867756 on epoch=196
05/30/2022 14:19:02 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/30/2022 14:19:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
05/30/2022 14:19:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
05/30/2022 14:19:09 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
05/30/2022 14:19:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
05/30/2022 14:19:18 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8421719111235241 on epoch=199
05/30/2022 14:19:20 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/30/2022 14:19:23 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
05/30/2022 14:19:25 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
05/30/2022 14:19:28 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
05/30/2022 14:19:30 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
05/30/2022 14:19:36 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8507436714194223 on epoch=203
05/30/2022 14:19:39 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
05/30/2022 14:19:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/30/2022 14:19:44 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/30/2022 14:19:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
05/30/2022 14:19:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/30/2022 14:19:54 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9059904548329598 on epoch=207
05/30/2022 14:19:57 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
05/30/2022 14:19:59 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/30/2022 14:20:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=209
05/30/2022 14:20:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/30/2022 14:20:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/30/2022 14:20:13 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8008120911346718 on epoch=210
05/30/2022 14:20:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
05/30/2022 14:20:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/30/2022 14:20:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/30/2022 14:20:23 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/30/2022 14:20:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
05/30/2022 14:20:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 14:20:26 - INFO - __main__ - Printing 3 examples
05/30/2022 14:20:26 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/30/2022 14:20:26 - INFO - __main__ - ['Film']
05/30/2022 14:20:26 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/30/2022 14:20:26 - INFO - __main__ - ['Film']
05/30/2022 14:20:26 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/30/2022 14:20:26 - INFO - __main__ - ['Film']
05/30/2022 14:20:26 - INFO - __main__ - Tokenizing Input ...
05/30/2022 14:20:27 - INFO - __main__ - Tokenizing Output ...
05/30/2022 14:20:27 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 14:20:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 14:20:27 - INFO - __main__ - Printing 3 examples
05/30/2022 14:20:27 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/30/2022 14:20:27 - INFO - __main__ - ['Film']
05/30/2022 14:20:27 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/30/2022 14:20:27 - INFO - __main__ - ['Film']
05/30/2022 14:20:27 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/30/2022 14:20:27 - INFO - __main__ - ['Film']
05/30/2022 14:20:27 - INFO - __main__ - Tokenizing Input ...
05/30/2022 14:20:27 - INFO - __main__ - Tokenizing Output ...
05/30/2022 14:20:27 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 14:20:31 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7968905225072208 on epoch=214
05/30/2022 14:20:31 - INFO - __main__ - save last model!
05/30/2022 14:20:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 14:20:31 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 14:20:31 - INFO - __main__ - Printing 3 examples
05/30/2022 14:20:31 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 14:20:31 - INFO - __main__ - ['Animal']
05/30/2022 14:20:31 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 14:20:31 - INFO - __main__ - ['Animal']
05/30/2022 14:20:31 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 14:20:31 - INFO - __main__ - ['Village']
05/30/2022 14:20:31 - INFO - __main__ - Tokenizing Input ...
05/30/2022 14:20:33 - INFO - __main__ - Tokenizing Output ...
05/30/2022 14:20:36 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 14:20:42 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 14:20:42 - INFO - __main__ - task name: dbpedia_14
05/30/2022 14:20:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 14:20:42 - INFO - __main__ - Starting training!
05/30/2022 14:22:36 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
05/30/2022 14:22:36 - INFO - __main__ - Classification-F1 on test data: 0.6415
05/30/2022 14:22:36 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.9865677649358864, test_performance=0.6414684076304007
05/30/2022 14:22:36 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
05/30/2022 14:22:37 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 14:22:37 - INFO - __main__ - Printing 3 examples
05/30/2022 14:22:37 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/30/2022 14:22:37 - INFO - __main__ - ['Film']
05/30/2022 14:22:37 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/30/2022 14:22:37 - INFO - __main__ - ['Film']
05/30/2022 14:22:37 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/30/2022 14:22:37 - INFO - __main__ - ['Film']
05/30/2022 14:22:37 - INFO - __main__ - Tokenizing Input ...
05/30/2022 14:22:37 - INFO - __main__ - Tokenizing Output ...
05/30/2022 14:22:38 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 14:22:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 14:22:38 - INFO - __main__ - Printing 3 examples
05/30/2022 14:22:38 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/30/2022 14:22:38 - INFO - __main__ - ['Film']
05/30/2022 14:22:38 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/30/2022 14:22:38 - INFO - __main__ - ['Film']
05/30/2022 14:22:38 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/30/2022 14:22:38 - INFO - __main__ - ['Film']
05/30/2022 14:22:38 - INFO - __main__ - Tokenizing Input ...
05/30/2022 14:22:38 - INFO - __main__ - Tokenizing Output ...
05/30/2022 14:22:38 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 14:22:56 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 14:22:56 - INFO - __main__ - task name: dbpedia_14
05/30/2022 14:22:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 14:22:57 - INFO - __main__ - Starting training!
05/30/2022 14:23:00 - INFO - __main__ - Step 10 Global step 10 Train loss 6.95 on epoch=0
05/30/2022 14:23:02 - INFO - __main__ - Step 20 Global step 20 Train loss 6.14 on epoch=1
05/30/2022 14:23:05 - INFO - __main__ - Step 30 Global step 30 Train loss 5.21 on epoch=2
05/30/2022 14:23:07 - INFO - __main__ - Step 40 Global step 40 Train loss 4.32 on epoch=2
05/30/2022 14:23:10 - INFO - __main__ - Step 50 Global step 50 Train loss 3.59 on epoch=3
05/30/2022 14:23:45 - INFO - __main__ - Global step 50 Train loss 5.24 Classification-F1 0.020252558673931643 on epoch=3
05/30/2022 14:23:45 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.020252558673931643 on epoch=3, global_step=50
05/30/2022 14:23:47 - INFO - __main__ - Step 60 Global step 60 Train loss 3.17 on epoch=4
05/30/2022 14:23:50 - INFO - __main__ - Step 70 Global step 70 Train loss 2.73 on epoch=4
05/30/2022 14:23:52 - INFO - __main__ - Step 80 Global step 80 Train loss 2.51 on epoch=5
05/30/2022 14:23:55 - INFO - __main__ - Step 90 Global step 90 Train loss 2.27 on epoch=6
05/30/2022 14:23:57 - INFO - __main__ - Step 100 Global step 100 Train loss 2.09 on epoch=7
05/30/2022 14:24:13 - INFO - __main__ - Global step 100 Train loss 2.55 Classification-F1 0.23978104250283025 on epoch=7
05/30/2022 14:24:13 - INFO - __main__ - Saving model with best Classification-F1: 0.020252558673931643 -> 0.23978104250283025 on epoch=7, global_step=100
05/30/2022 14:24:16 - INFO - __main__ - Step 110 Global step 110 Train loss 1.79 on epoch=7
05/30/2022 14:24:18 - INFO - __main__ - Step 120 Global step 120 Train loss 1.74 on epoch=8
05/30/2022 14:24:21 - INFO - __main__ - Step 130 Global step 130 Train loss 1.76 on epoch=9
05/30/2022 14:24:23 - INFO - __main__ - Step 140 Global step 140 Train loss 1.50 on epoch=9
05/30/2022 14:24:26 - INFO - __main__ - Step 150 Global step 150 Train loss 1.45 on epoch=10
05/30/2022 14:24:33 - INFO - __main__ - Global step 150 Train loss 1.65 Classification-F1 0.26459249628684844 on epoch=10
05/30/2022 14:24:33 - INFO - __main__ - Saving model with best Classification-F1: 0.23978104250283025 -> 0.26459249628684844 on epoch=10, global_step=150
05/30/2022 14:24:36 - INFO - __main__ - Step 160 Global step 160 Train loss 1.33 on epoch=11
05/30/2022 14:24:38 - INFO - __main__ - Step 170 Global step 170 Train loss 1.24 on epoch=12
05/30/2022 14:24:41 - INFO - __main__ - Step 180 Global step 180 Train loss 1.20 on epoch=12
05/30/2022 14:24:43 - INFO - __main__ - Step 190 Global step 190 Train loss 1.27 on epoch=13
05/30/2022 14:24:45 - INFO - __main__ - Step 200 Global step 200 Train loss 1.19 on epoch=14
05/30/2022 14:24:53 - INFO - __main__ - Global step 200 Train loss 1.25 Classification-F1 0.3903755115649365 on epoch=14
05/30/2022 14:24:53 - INFO - __main__ - Saving model with best Classification-F1: 0.26459249628684844 -> 0.3903755115649365 on epoch=14, global_step=200
05/30/2022 14:24:56 - INFO - __main__ - Step 210 Global step 210 Train loss 1.14 on epoch=14
05/30/2022 14:24:58 - INFO - __main__ - Step 220 Global step 220 Train loss 1.19 on epoch=15
05/30/2022 14:25:01 - INFO - __main__ - Step 230 Global step 230 Train loss 1.00 on epoch=16
05/30/2022 14:25:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.98 on epoch=17
05/30/2022 14:25:05 - INFO - __main__ - Step 250 Global step 250 Train loss 1.01 on epoch=17
05/30/2022 14:25:11 - INFO - __main__ - Global step 250 Train loss 1.06 Classification-F1 0.339301012070095 on epoch=17
05/30/2022 14:25:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.93 on epoch=18
05/30/2022 14:25:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.97 on epoch=19
05/30/2022 14:25:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.87 on epoch=19
05/30/2022 14:25:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.80 on epoch=20
05/30/2022 14:25:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.84 on epoch=21
05/30/2022 14:25:29 - INFO - __main__ - Global step 300 Train loss 0.88 Classification-F1 0.3189037033346496 on epoch=21
05/30/2022 14:25:31 - INFO - __main__ - Step 310 Global step 310 Train loss 0.84 on epoch=22
05/30/2022 14:25:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.75 on epoch=22
05/30/2022 14:25:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.72 on epoch=23
05/30/2022 14:25:38 - INFO - __main__ - Step 340 Global step 340 Train loss 0.79 on epoch=24
05/30/2022 14:25:41 - INFO - __main__ - Step 350 Global step 350 Train loss 0.72 on epoch=24
05/30/2022 14:25:47 - INFO - __main__ - Global step 350 Train loss 0.77 Classification-F1 0.3904113710388398 on epoch=24
05/30/2022 14:25:47 - INFO - __main__ - Saving model with best Classification-F1: 0.3903755115649365 -> 0.3904113710388398 on epoch=24, global_step=350
05/30/2022 14:25:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.59 on epoch=25
05/30/2022 14:25:51 - INFO - __main__ - Step 370 Global step 370 Train loss 0.66 on epoch=26
05/30/2022 14:25:54 - INFO - __main__ - Step 380 Global step 380 Train loss 0.66 on epoch=27
05/30/2022 14:25:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.58 on epoch=27
05/30/2022 14:25:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.56 on epoch=28
05/30/2022 14:26:05 - INFO - __main__ - Global step 400 Train loss 0.61 Classification-F1 0.5368959504079681 on epoch=28
05/30/2022 14:26:05 - INFO - __main__ - Saving model with best Classification-F1: 0.3904113710388398 -> 0.5368959504079681 on epoch=28, global_step=400
05/30/2022 14:26:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.62 on epoch=29
05/30/2022 14:26:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.63 on epoch=29
05/30/2022 14:26:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.50 on epoch=30
05/30/2022 14:26:14 - INFO - __main__ - Step 440 Global step 440 Train loss 0.56 on epoch=31
05/30/2022 14:26:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.56 on epoch=32
05/30/2022 14:26:22 - INFO - __main__ - Global step 450 Train loss 0.57 Classification-F1 0.5379380618610015 on epoch=32
05/30/2022 14:26:22 - INFO - __main__ - Saving model with best Classification-F1: 0.5368959504079681 -> 0.5379380618610015 on epoch=32, global_step=450
05/30/2022 14:26:25 - INFO - __main__ - Step 460 Global step 460 Train loss 0.50 on epoch=32
05/30/2022 14:26:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.44 on epoch=33
05/30/2022 14:26:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.41 on epoch=34
05/30/2022 14:26:32 - INFO - __main__ - Step 490 Global step 490 Train loss 0.47 on epoch=34
05/30/2022 14:26:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.44 on epoch=35
05/30/2022 14:26:40 - INFO - __main__ - Global step 500 Train loss 0.45 Classification-F1 0.6922904829899267 on epoch=35
05/30/2022 14:26:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5379380618610015 -> 0.6922904829899267 on epoch=35, global_step=500
05/30/2022 14:26:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.41 on epoch=36
05/30/2022 14:26:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.59 on epoch=37
05/30/2022 14:26:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=37
05/30/2022 14:26:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.46 on epoch=38
05/30/2022 14:26:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.44 on epoch=39
05/30/2022 14:26:58 - INFO - __main__ - Global step 550 Train loss 0.46 Classification-F1 0.5768422401059973 on epoch=39
05/30/2022 14:27:00 - INFO - __main__ - Step 560 Global step 560 Train loss 0.44 on epoch=39
05/30/2022 14:27:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.46 on epoch=40
05/30/2022 14:27:05 - INFO - __main__ - Step 580 Global step 580 Train loss 0.44 on epoch=41
05/30/2022 14:27:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.41 on epoch=42
05/30/2022 14:27:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.38 on epoch=42
05/30/2022 14:27:15 - INFO - __main__ - Global step 600 Train loss 0.43 Classification-F1 0.5158493996131053 on epoch=42
05/30/2022 14:27:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.42 on epoch=43
05/30/2022 14:27:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.38 on epoch=44
05/30/2022 14:27:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.43 on epoch=44
05/30/2022 14:27:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.38 on epoch=45
05/30/2022 14:27:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.35 on epoch=46
05/30/2022 14:27:33 - INFO - __main__ - Global step 650 Train loss 0.39 Classification-F1 0.6572281628241502 on epoch=46
05/30/2022 14:27:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.37 on epoch=47
05/30/2022 14:27:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.35 on epoch=47
05/30/2022 14:27:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.42 on epoch=48
05/30/2022 14:27:42 - INFO - __main__ - Step 690 Global step 690 Train loss 0.40 on epoch=49
05/30/2022 14:27:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.28 on epoch=49
05/30/2022 14:27:51 - INFO - __main__ - Global step 700 Train loss 0.36 Classification-F1 0.6730181402456152 on epoch=49
05/30/2022 14:27:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.37 on epoch=50
05/30/2022 14:27:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.35 on epoch=51
05/30/2022 14:27:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.29 on epoch=52
05/30/2022 14:28:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.29 on epoch=52
05/30/2022 14:28:03 - INFO - __main__ - Step 750 Global step 750 Train loss 0.32 on epoch=53
05/30/2022 14:28:09 - INFO - __main__ - Global step 750 Train loss 0.32 Classification-F1 0.640044733492314 on epoch=53
05/30/2022 14:28:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.32 on epoch=54
05/30/2022 14:28:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=54
05/30/2022 14:28:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.27 on epoch=55
05/30/2022 14:28:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.26 on epoch=56
05/30/2022 14:28:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=57
05/30/2022 14:28:27 - INFO - __main__ - Global step 800 Train loss 0.27 Classification-F1 0.7285950015841889 on epoch=57
05/30/2022 14:28:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6922904829899267 -> 0.7285950015841889 on epoch=57, global_step=800
05/30/2022 14:28:29 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=57
05/30/2022 14:28:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.31 on epoch=58
05/30/2022 14:28:34 - INFO - __main__ - Step 830 Global step 830 Train loss 0.25 on epoch=59
05/30/2022 14:28:36 - INFO - __main__ - Step 840 Global step 840 Train loss 0.26 on epoch=59
05/30/2022 14:28:39 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=60
05/30/2022 14:28:45 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.6720012134695116 on epoch=60
05/30/2022 14:28:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=61
05/30/2022 14:28:50 - INFO - __main__ - Step 870 Global step 870 Train loss 0.22 on epoch=62
05/30/2022 14:28:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=62
05/30/2022 14:28:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=63
05/30/2022 14:28:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.25 on epoch=64
05/30/2022 14:29:03 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.701202962011454 on epoch=64
05/30/2022 14:29:05 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=64
05/30/2022 14:29:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=65
05/30/2022 14:29:10 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=66
05/30/2022 14:29:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.22 on epoch=67
05/30/2022 14:29:15 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=67
05/30/2022 14:29:21 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.6669614256711032 on epoch=67
05/30/2022 14:29:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=68
05/30/2022 14:29:26 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=69
05/30/2022 14:29:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=69
05/30/2022 14:29:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=70
05/30/2022 14:29:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=71
05/30/2022 14:29:39 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.9822527251369758 on epoch=71
05/30/2022 14:29:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7285950015841889 -> 0.9822527251369758 on epoch=71, global_step=1000
05/30/2022 14:29:41 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=72
05/30/2022 14:29:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
05/30/2022 14:29:46 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=73
05/30/2022 14:29:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.20 on epoch=74
05/30/2022 14:29:51 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=74
05/30/2022 14:29:57 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.672951635843043 on epoch=74
05/30/2022 14:29:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=75
05/30/2022 14:30:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=76
05/30/2022 14:30:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=77
05/30/2022 14:30:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=77
05/30/2022 14:30:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=78
05/30/2022 14:30:15 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.9103886794209376 on epoch=78
05/30/2022 14:30:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=79
05/30/2022 14:30:20 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=79
05/30/2022 14:30:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=80
05/30/2022 14:30:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=81
05/30/2022 14:30:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.16 on epoch=82
05/30/2022 14:30:33 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.8028707377379104 on epoch=82
05/30/2022 14:30:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
05/30/2022 14:30:38 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=83
05/30/2022 14:30:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=84
05/30/2022 14:30:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=84
05/30/2022 14:30:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
05/30/2022 14:30:52 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.7817093547905563 on epoch=85
05/30/2022 14:30:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=86
05/30/2022 14:30:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=87
05/30/2022 14:30:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
05/30/2022 14:31:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=88
05/30/2022 14:31:04 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=89
05/30/2022 14:31:10 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.99553135037006 on epoch=89
05/30/2022 14:31:10 - INFO - __main__ - Saving model with best Classification-F1: 0.9822527251369758 -> 0.99553135037006 on epoch=89, global_step=1250
05/30/2022 14:31:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=89
05/30/2022 14:31:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=90
05/30/2022 14:31:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=91
05/30/2022 14:31:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=92
05/30/2022 14:31:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=92
05/30/2022 14:31:28 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.9015959906282487 on epoch=92
05/30/2022 14:31:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
05/30/2022 14:31:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
05/30/2022 14:31:35 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=94
05/30/2022 14:31:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
05/30/2022 14:31:40 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=96
05/30/2022 14:31:45 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.9910627007401202 on epoch=96
05/30/2022 14:31:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=97
05/30/2022 14:31:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
05/30/2022 14:31:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=98
05/30/2022 14:31:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
05/30/2022 14:31:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
05/30/2022 14:32:03 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.9101611944875702 on epoch=99
05/30/2022 14:32:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
05/30/2022 14:32:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=101
05/30/2022 14:32:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
05/30/2022 14:32:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
05/30/2022 14:32:15 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=103
05/30/2022 14:32:21 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.8649193548387097 on epoch=103
05/30/2022 14:32:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=104
05/30/2022 14:32:26 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
05/30/2022 14:32:28 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
05/30/2022 14:32:31 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
05/30/2022 14:32:33 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=107
05/30/2022 14:32:39 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.9061378969965309 on epoch=107
05/30/2022 14:32:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
05/30/2022 14:32:44 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
05/30/2022 14:32:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
05/30/2022 14:32:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.12 on epoch=109
05/30/2022 14:32:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
05/30/2022 14:32:57 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.9867213747669157 on epoch=110
05/30/2022 14:32:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
05/30/2022 14:33:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
05/30/2022 14:33:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
05/30/2022 14:33:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
05/30/2022 14:33:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
05/30/2022 14:33:15 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.9910627007401202 on epoch=114
05/30/2022 14:33:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
05/30/2022 14:33:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
05/30/2022 14:33:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
05/30/2022 14:33:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
05/30/2022 14:33:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
05/30/2022 14:33:33 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.9729660293685681 on epoch=117
05/30/2022 14:33:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=118
05/30/2022 14:33:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
05/30/2022 14:33:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=119
05/30/2022 14:33:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
05/30/2022 14:33:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=121
05/30/2022 14:33:51 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.914360540892799 on epoch=121
05/30/2022 14:33:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
05/30/2022 14:33:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
05/30/2022 14:33:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
05/30/2022 14:34:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
05/30/2022 14:34:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
05/30/2022 14:34:09 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.9820991153059465 on epoch=124
05/30/2022 14:34:12 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
05/30/2022 14:34:14 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
05/30/2022 14:34:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=127
05/30/2022 14:34:19 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
05/30/2022 14:34:21 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
05/30/2022 14:34:28 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.9228453893776475 on epoch=128
05/30/2022 14:34:30 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
05/30/2022 14:34:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
05/30/2022 14:34:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
05/30/2022 14:34:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=131
05/30/2022 14:34:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.13 on epoch=132
05/30/2022 14:34:45 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.8358484999466298 on epoch=132
05/30/2022 14:34:48 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
05/30/2022 14:34:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=133
05/30/2022 14:34:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
05/30/2022 14:34:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=134
05/30/2022 14:34:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/30/2022 14:35:04 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7599435212338439 on epoch=135
05/30/2022 14:35:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
05/30/2022 14:35:08 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=137
05/30/2022 14:35:11 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=137
05/30/2022 14:35:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=138
05/30/2022 14:35:16 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
05/30/2022 14:35:22 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.8511154962857325 on epoch=139
05/30/2022 14:35:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.11 on epoch=139
05/30/2022 14:35:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
05/30/2022 14:35:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
05/30/2022 14:35:31 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
05/30/2022 14:35:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
05/30/2022 14:35:40 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8066773043528263 on epoch=142
05/30/2022 14:35:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
05/30/2022 14:35:45 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
05/30/2022 14:35:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
05/30/2022 14:35:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
05/30/2022 14:35:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
05/30/2022 14:35:58 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.9143360071301248 on epoch=146
05/30/2022 14:36:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
05/30/2022 14:36:03 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
05/30/2022 14:36:06 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
05/30/2022 14:36:08 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
05/30/2022 14:36:10 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
05/30/2022 14:36:16 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9821297653958945 on epoch=149
05/30/2022 14:36:18 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.17 on epoch=150
05/30/2022 14:36:21 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
05/30/2022 14:36:23 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
05/30/2022 14:36:26 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
05/30/2022 14:36:28 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
05/30/2022 14:36:34 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.9140589712475141 on epoch=153
05/30/2022 14:36:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
05/30/2022 14:36:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
05/30/2022 14:36:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=155
05/30/2022 14:36:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
05/30/2022 14:36:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
05/30/2022 14:36:52 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9018685388673284 on epoch=157
05/30/2022 14:36:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
05/30/2022 14:36:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.13 on epoch=158
05/30/2022 14:36:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=159
05/30/2022 14:37:02 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
05/30/2022 14:37:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
05/30/2022 14:37:10 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.9910627007401202 on epoch=160
05/30/2022 14:37:12 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
05/30/2022 14:37:14 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.09 on epoch=162
05/30/2022 14:37:17 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/30/2022 14:37:19 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
05/30/2022 14:37:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
05/30/2022 14:37:27 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9865940511101802 on epoch=164
05/30/2022 14:37:30 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
05/30/2022 14:37:32 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/30/2022 14:37:35 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
05/30/2022 14:37:37 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
05/30/2022 14:37:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
05/30/2022 14:37:45 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9821297653958945 on epoch=167
05/30/2022 14:37:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=168
05/30/2022 14:37:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
05/30/2022 14:37:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
05/30/2022 14:37:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
05/30/2022 14:37:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
05/30/2022 14:38:03 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.9865940511101802 on epoch=171
05/30/2022 14:38:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
05/30/2022 14:38:07 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
05/30/2022 14:38:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/30/2022 14:38:12 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
05/30/2022 14:38:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=174
05/30/2022 14:38:20 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.9776304656760065 on epoch=174
05/30/2022 14:38:22 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
05/30/2022 14:38:25 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
05/30/2022 14:38:27 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/30/2022 14:38:29 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
05/30/2022 14:38:32 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/30/2022 14:38:37 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9186705767350929 on epoch=178
05/30/2022 14:38:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
05/30/2022 14:38:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
05/30/2022 14:38:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
05/30/2022 14:38:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
05/30/2022 14:38:49 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=182
05/30/2022 14:38:55 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9145039100684262 on epoch=182
05/30/2022 14:38:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/30/2022 14:39:00 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
05/30/2022 14:39:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=184
05/30/2022 14:39:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
05/30/2022 14:39:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
05/30/2022 14:39:12 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.8552006964809384 on epoch=185
05/30/2022 14:39:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
05/30/2022 14:39:17 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/30/2022 14:39:20 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
05/30/2022 14:39:22 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
05/30/2022 14:39:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
05/30/2022 14:39:30 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=189
05/30/2022 14:39:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/30/2022 14:39:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
05/30/2022 14:39:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/30/2022 14:39:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=192
05/30/2022 14:39:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
05/30/2022 14:39:47 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9185272075594656 on epoch=192
05/30/2022 14:39:50 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
05/30/2022 14:39:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/30/2022 14:39:54 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/30/2022 14:39:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/30/2022 14:39:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
05/30/2022 14:40:05 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9017992544036187 on epoch=196
05/30/2022 14:40:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/30/2022 14:40:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
05/30/2022 14:40:12 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/30/2022 14:40:14 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
05/30/2022 14:40:17 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/30/2022 14:40:22 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9101652674755142 on epoch=199
05/30/2022 14:40:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
05/30/2022 14:40:27 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
05/30/2022 14:40:29 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=202
05/30/2022 14:40:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
05/30/2022 14:40:34 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
05/30/2022 14:40:40 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9910627007401202 on epoch=203
05/30/2022 14:40:42 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
05/30/2022 14:40:45 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/30/2022 14:40:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/30/2022 14:40:49 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
05/30/2022 14:40:52 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
05/30/2022 14:40:57 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=207
05/30/2022 14:41:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/30/2022 14:41:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
05/30/2022 14:41:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/30/2022 14:41:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
05/30/2022 14:41:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
05/30/2022 14:41:15 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=210
05/30/2022 14:41:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.38 on epoch=211
05/30/2022 14:41:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/30/2022 14:41:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
05/30/2022 14:41:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/30/2022 14:41:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
05/30/2022 14:41:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 14:41:28 - INFO - __main__ - Printing 3 examples
05/30/2022 14:41:28 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/30/2022 14:41:28 - INFO - __main__ - ['Film']
05/30/2022 14:41:28 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/30/2022 14:41:28 - INFO - __main__ - ['Film']
05/30/2022 14:41:28 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/30/2022 14:41:28 - INFO - __main__ - ['Film']
05/30/2022 14:41:28 - INFO - __main__ - Tokenizing Input ...
05/30/2022 14:41:28 - INFO - __main__ - Tokenizing Output ...
05/30/2022 14:41:28 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 14:41:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 14:41:28 - INFO - __main__ - Printing 3 examples
05/30/2022 14:41:28 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/30/2022 14:41:28 - INFO - __main__ - ['Film']
05/30/2022 14:41:28 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/30/2022 14:41:28 - INFO - __main__ - ['Film']
05/30/2022 14:41:28 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/30/2022 14:41:28 - INFO - __main__ - ['Film']
05/30/2022 14:41:28 - INFO - __main__ - Tokenizing Input ...
05/30/2022 14:41:29 - INFO - __main__ - Tokenizing Output ...
05/30/2022 14:41:29 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 14:41:32 - INFO - __main__ - Global step 3000 Train loss 0.09 Classification-F1 0.9867213747669157 on epoch=214
05/30/2022 14:41:32 - INFO - __main__ - save last model!
05/30/2022 14:41:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 14:41:32 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 14:41:32 - INFO - __main__ - Printing 3 examples
05/30/2022 14:41:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 14:41:32 - INFO - __main__ - ['Animal']
05/30/2022 14:41:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 14:41:32 - INFO - __main__ - ['Animal']
05/30/2022 14:41:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 14:41:32 - INFO - __main__ - ['Village']
05/30/2022 14:41:32 - INFO - __main__ - Tokenizing Input ...
05/30/2022 14:41:34 - INFO - __main__ - Tokenizing Output ...
05/30/2022 14:41:37 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 14:41:47 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 14:41:47 - INFO - __main__ - task name: dbpedia_14
05/30/2022 14:41:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 14:41:48 - INFO - __main__ - Starting training!
05/30/2022 14:43:35 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
05/30/2022 14:43:35 - INFO - __main__ - Classification-F1 on test data: 0.7581
05/30/2022 14:43:35 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.99553135037006, test_performance=0.758127415810192
05/30/2022 14:43:35 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
05/30/2022 14:43:36 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 14:43:36 - INFO - __main__ - Printing 3 examples
05/30/2022 14:43:36 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/30/2022 14:43:36 - INFO - __main__ - ['Film']
05/30/2022 14:43:36 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/30/2022 14:43:36 - INFO - __main__ - ['Film']
05/30/2022 14:43:36 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/30/2022 14:43:36 - INFO - __main__ - ['Film']
05/30/2022 14:43:36 - INFO - __main__ - Tokenizing Input ...
05/30/2022 14:43:36 - INFO - __main__ - Tokenizing Output ...
05/30/2022 14:43:37 - INFO - __main__ - Loaded 224 examples from train data
05/30/2022 14:43:37 - INFO - __main__ - Start tokenizing ... 224 instances
05/30/2022 14:43:37 - INFO - __main__ - Printing 3 examples
05/30/2022 14:43:37 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/30/2022 14:43:37 - INFO - __main__ - ['Film']
05/30/2022 14:43:37 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/30/2022 14:43:37 - INFO - __main__ - ['Film']
05/30/2022 14:43:37 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/30/2022 14:43:37 - INFO - __main__ - ['Film']
05/30/2022 14:43:37 - INFO - __main__ - Tokenizing Input ...
05/30/2022 14:43:37 - INFO - __main__ - Tokenizing Output ...
05/30/2022 14:43:37 - INFO - __main__ - Loaded 224 examples from dev data
05/30/2022 14:43:52 - INFO - __main__ - try to initialize prompt embeddings
05/30/2022 14:43:52 - INFO - __main__ - task name: dbpedia_14
05/30/2022 14:43:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
05/30/2022 14:43:53 - INFO - __main__ - Starting training!
05/30/2022 14:43:55 - INFO - __main__ - Step 10 Global step 10 Train loss 7.30 on epoch=0
05/30/2022 14:43:58 - INFO - __main__ - Step 20 Global step 20 Train loss 6.71 on epoch=1
05/30/2022 14:44:00 - INFO - __main__ - Step 30 Global step 30 Train loss 6.00 on epoch=2
05/30/2022 14:44:03 - INFO - __main__ - Step 40 Global step 40 Train loss 5.17 on epoch=2
05/30/2022 14:44:05 - INFO - __main__ - Step 50 Global step 50 Train loss 4.42 on epoch=3
05/30/2022 14:44:48 - INFO - __main__ - Global step 50 Train loss 5.92 Classification-F1 0.006197478991596639 on epoch=3
05/30/2022 14:44:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.006197478991596639 on epoch=3, global_step=50
05/30/2022 14:44:51 - INFO - __main__ - Step 60 Global step 60 Train loss 3.72 on epoch=4
05/30/2022 14:44:53 - INFO - __main__ - Step 70 Global step 70 Train loss 3.37 on epoch=4
05/30/2022 14:44:55 - INFO - __main__ - Step 80 Global step 80 Train loss 3.16 on epoch=5
05/30/2022 14:44:58 - INFO - __main__ - Step 90 Global step 90 Train loss 2.82 on epoch=6
05/30/2022 14:45:00 - INFO - __main__ - Step 100 Global step 100 Train loss 2.69 on epoch=7
05/30/2022 14:45:09 - INFO - __main__ - Global step 100 Train loss 3.15 Classification-F1 0.06774912904943864 on epoch=7
05/30/2022 14:45:09 - INFO - __main__ - Saving model with best Classification-F1: 0.006197478991596639 -> 0.06774912904943864 on epoch=7, global_step=100
05/30/2022 14:45:11 - INFO - __main__ - Step 110 Global step 110 Train loss 2.55 on epoch=7
05/30/2022 14:45:14 - INFO - __main__ - Step 120 Global step 120 Train loss 2.55 on epoch=8
05/30/2022 14:45:16 - INFO - __main__ - Step 130 Global step 130 Train loss 2.32 on epoch=9
05/30/2022 14:45:19 - INFO - __main__ - Step 140 Global step 140 Train loss 2.04 on epoch=9
05/30/2022 14:45:21 - INFO - __main__ - Step 150 Global step 150 Train loss 2.04 on epoch=10
05/30/2022 14:45:26 - INFO - __main__ - Global step 150 Train loss 2.30 Classification-F1 0.22485153898389196 on epoch=10
05/30/2022 14:45:26 - INFO - __main__ - Saving model with best Classification-F1: 0.06774912904943864 -> 0.22485153898389196 on epoch=10, global_step=150
05/30/2022 14:45:29 - INFO - __main__ - Step 160 Global step 160 Train loss 1.85 on epoch=11
05/30/2022 14:45:31 - INFO - __main__ - Step 170 Global step 170 Train loss 1.94 on epoch=12
05/30/2022 14:45:33 - INFO - __main__ - Step 180 Global step 180 Train loss 1.72 on epoch=12
05/30/2022 14:45:36 - INFO - __main__ - Step 190 Global step 190 Train loss 1.80 on epoch=13
05/30/2022 14:45:38 - INFO - __main__ - Step 200 Global step 200 Train loss 1.64 on epoch=14
05/30/2022 14:45:44 - INFO - __main__ - Global step 200 Train loss 1.79 Classification-F1 0.3137170015029358 on epoch=14
05/30/2022 14:45:44 - INFO - __main__ - Saving model with best Classification-F1: 0.22485153898389196 -> 0.3137170015029358 on epoch=14, global_step=200
05/30/2022 14:45:47 - INFO - __main__ - Step 210 Global step 210 Train loss 1.47 on epoch=14
05/30/2022 14:45:49 - INFO - __main__ - Step 220 Global step 220 Train loss 1.58 on epoch=15
05/30/2022 14:45:52 - INFO - __main__ - Step 230 Global step 230 Train loss 1.51 on epoch=16
05/30/2022 14:45:54 - INFO - __main__ - Step 240 Global step 240 Train loss 1.35 on epoch=17
05/30/2022 14:45:57 - INFO - __main__ - Step 250 Global step 250 Train loss 1.42 on epoch=17
05/30/2022 14:46:02 - INFO - __main__ - Global step 250 Train loss 1.47 Classification-F1 0.2994639430736574 on epoch=17
05/30/2022 14:46:05 - INFO - __main__ - Step 260 Global step 260 Train loss 1.28 on epoch=18
05/30/2022 14:46:07 - INFO - __main__ - Step 270 Global step 270 Train loss 1.35 on epoch=19
05/30/2022 14:46:10 - INFO - __main__ - Step 280 Global step 280 Train loss 1.17 on epoch=19
05/30/2022 14:46:12 - INFO - __main__ - Step 290 Global step 290 Train loss 1.19 on epoch=20
05/30/2022 14:46:14 - INFO - __main__ - Step 300 Global step 300 Train loss 1.17 on epoch=21
05/30/2022 14:46:21 - INFO - __main__ - Global step 300 Train loss 1.23 Classification-F1 0.297234796649646 on epoch=21
05/30/2022 14:46:23 - INFO - __main__ - Step 310 Global step 310 Train loss 1.17 on epoch=22
05/30/2022 14:46:25 - INFO - __main__ - Step 320 Global step 320 Train loss 1.18 on epoch=22
05/30/2022 14:46:28 - INFO - __main__ - Step 330 Global step 330 Train loss 1.08 on epoch=23
05/30/2022 14:46:30 - INFO - __main__ - Step 340 Global step 340 Train loss 1.06 on epoch=24
05/30/2022 14:46:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.97 on epoch=24
05/30/2022 14:46:39 - INFO - __main__ - Global step 350 Train loss 1.09 Classification-F1 0.3592817611914386 on epoch=24
05/30/2022 14:46:39 - INFO - __main__ - Saving model with best Classification-F1: 0.3137170015029358 -> 0.3592817611914386 on epoch=24, global_step=350
05/30/2022 14:46:41 - INFO - __main__ - Step 360 Global step 360 Train loss 1.00 on epoch=25
05/30/2022 14:46:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.91 on epoch=26
05/30/2022 14:46:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.88 on epoch=27
05/30/2022 14:46:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.95 on epoch=27
05/30/2022 14:46:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.91 on epoch=28
05/30/2022 14:46:58 - INFO - __main__ - Global step 400 Train loss 0.93 Classification-F1 0.34787118750279694 on epoch=28
05/30/2022 14:47:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.93 on epoch=29
05/30/2022 14:47:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.88 on epoch=29
05/30/2022 14:47:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.80 on epoch=30
05/30/2022 14:47:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.85 on epoch=31
05/30/2022 14:47:10 - INFO - __main__ - Step 450 Global step 450 Train loss 0.74 on epoch=32
05/30/2022 14:47:16 - INFO - __main__ - Global step 450 Train loss 0.84 Classification-F1 0.5733335167004932 on epoch=32
05/30/2022 14:47:16 - INFO - __main__ - Saving model with best Classification-F1: 0.3592817611914386 -> 0.5733335167004932 on epoch=32, global_step=450
05/30/2022 14:47:19 - INFO - __main__ - Step 460 Global step 460 Train loss 0.78 on epoch=32
05/30/2022 14:47:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.78 on epoch=33
05/30/2022 14:47:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.82 on epoch=34
05/30/2022 14:47:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.76 on epoch=34
05/30/2022 14:47:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.75 on epoch=35
05/30/2022 14:47:35 - INFO - __main__ - Global step 500 Train loss 0.78 Classification-F1 0.5103818926685998 on epoch=35
05/30/2022 14:47:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.74 on epoch=36
05/30/2022 14:47:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.70 on epoch=37
05/30/2022 14:47:42 - INFO - __main__ - Step 530 Global step 530 Train loss 0.79 on epoch=37
05/30/2022 14:47:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.79 on epoch=38
05/30/2022 14:47:47 - INFO - __main__ - Step 550 Global step 550 Train loss 0.75 on epoch=39
05/30/2022 14:47:53 - INFO - __main__ - Global step 550 Train loss 0.76 Classification-F1 0.5123881767739753 on epoch=39
05/30/2022 14:47:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.64 on epoch=39
05/30/2022 14:47:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.71 on epoch=40
05/30/2022 14:48:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.68 on epoch=41
05/30/2022 14:48:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.69 on epoch=42
05/30/2022 14:48:05 - INFO - __main__ - Step 600 Global step 600 Train loss 0.65 on epoch=42
05/30/2022 14:48:11 - INFO - __main__ - Global step 600 Train loss 0.67 Classification-F1 0.5637765758945725 on epoch=42
05/30/2022 14:48:14 - INFO - __main__ - Step 610 Global step 610 Train loss 0.64 on epoch=43
05/30/2022 14:48:16 - INFO - __main__ - Step 620 Global step 620 Train loss 0.69 on epoch=44
05/30/2022 14:48:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.55 on epoch=44
05/30/2022 14:48:21 - INFO - __main__ - Step 640 Global step 640 Train loss 0.59 on epoch=45
05/30/2022 14:48:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.59 on epoch=46
05/30/2022 14:48:30 - INFO - __main__ - Global step 650 Train loss 0.61 Classification-F1 0.5621563945610358 on epoch=46
05/30/2022 14:48:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.65 on epoch=47
05/30/2022 14:48:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.56 on epoch=47
05/30/2022 14:48:37 - INFO - __main__ - Step 680 Global step 680 Train loss 0.58 on epoch=48
05/30/2022 14:48:40 - INFO - __main__ - Step 690 Global step 690 Train loss 0.61 on epoch=49
05/30/2022 14:48:42 - INFO - __main__ - Step 700 Global step 700 Train loss 0.57 on epoch=49
05/30/2022 14:48:48 - INFO - __main__ - Global step 700 Train loss 0.60 Classification-F1 0.5264294740823549 on epoch=49
05/30/2022 14:48:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.54 on epoch=50
05/30/2022 14:48:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.58 on epoch=51
05/30/2022 14:48:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.65 on epoch=52
05/30/2022 14:48:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.48 on epoch=52
05/30/2022 14:49:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.60 on epoch=53
05/30/2022 14:49:07 - INFO - __main__ - Global step 750 Train loss 0.57 Classification-F1 0.4893259636756602 on epoch=53
05/30/2022 14:49:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.65 on epoch=54
05/30/2022 14:49:11 - INFO - __main__ - Step 770 Global step 770 Train loss 0.49 on epoch=54
05/30/2022 14:49:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.56 on epoch=55
05/30/2022 14:49:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.52 on epoch=56
05/30/2022 14:49:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.49 on epoch=57
05/30/2022 14:49:25 - INFO - __main__ - Global step 800 Train loss 0.54 Classification-F1 0.5092334261824638 on epoch=57
05/30/2022 14:49:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.45 on epoch=57
05/30/2022 14:49:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.53 on epoch=58
05/30/2022 14:49:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.48 on epoch=59
05/30/2022 14:49:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.56 on epoch=59
05/30/2022 14:49:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.47 on epoch=60
05/30/2022 14:49:43 - INFO - __main__ - Global step 850 Train loss 0.50 Classification-F1 0.6339026538123147 on epoch=60
05/30/2022 14:49:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5733335167004932 -> 0.6339026538123147 on epoch=60, global_step=850
05/30/2022 14:49:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.53 on epoch=61
05/30/2022 14:49:48 - INFO - __main__ - Step 870 Global step 870 Train loss 0.46 on epoch=62
05/30/2022 14:49:50 - INFO - __main__ - Step 880 Global step 880 Train loss 0.48 on epoch=62
05/30/2022 14:49:53 - INFO - __main__ - Step 890 Global step 890 Train loss 0.37 on epoch=63
05/30/2022 14:49:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.45 on epoch=64
05/30/2022 14:50:01 - INFO - __main__ - Global step 900 Train loss 0.46 Classification-F1 0.44723485639592425 on epoch=64
05/30/2022 14:50:04 - INFO - __main__ - Step 910 Global step 910 Train loss 0.46 on epoch=64
05/30/2022 14:50:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.53 on epoch=65
05/30/2022 14:50:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.41 on epoch=66
05/30/2022 14:50:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.32 on epoch=67
05/30/2022 14:50:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.44 on epoch=67
05/30/2022 14:50:20 - INFO - __main__ - Global step 950 Train loss 0.43 Classification-F1 0.5999459880565506 on epoch=67
05/30/2022 14:50:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.41 on epoch=68
05/30/2022 14:50:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.47 on epoch=69
05/30/2022 14:50:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.50 on epoch=69
05/30/2022 14:50:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.36 on epoch=70
05/30/2022 14:50:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.35 on epoch=71
05/30/2022 14:50:38 - INFO - __main__ - Global step 1000 Train loss 0.42 Classification-F1 0.7652072201139634 on epoch=71
05/30/2022 14:50:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6339026538123147 -> 0.7652072201139634 on epoch=71, global_step=1000
05/30/2022 14:50:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.37 on epoch=72
05/30/2022 14:50:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.37 on epoch=72
05/30/2022 14:50:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.44 on epoch=73
05/30/2022 14:50:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.35 on epoch=74
05/30/2022 14:50:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.34 on epoch=74
05/30/2022 14:50:55 - INFO - __main__ - Global step 1050 Train loss 0.38 Classification-F1 0.6856819549949844 on epoch=74
05/30/2022 14:50:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.33 on epoch=75
05/30/2022 14:51:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.34 on epoch=76
05/30/2022 14:51:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.42 on epoch=77
05/30/2022 14:51:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.31 on epoch=77
05/30/2022 14:51:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.35 on epoch=78
05/30/2022 14:51:13 - INFO - __main__ - Global step 1100 Train loss 0.35 Classification-F1 0.6961624081168674 on epoch=78
05/30/2022 14:51:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.32 on epoch=79
05/30/2022 14:51:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.36 on epoch=79
05/30/2022 14:51:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.26 on epoch=80
05/30/2022 14:51:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.35 on epoch=81
05/30/2022 14:51:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.40 on epoch=82
05/30/2022 14:51:31 - INFO - __main__ - Global step 1150 Train loss 0.34 Classification-F1 0.7174718743128087 on epoch=82
05/30/2022 14:51:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.25 on epoch=82
05/30/2022 14:51:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.25 on epoch=83
05/30/2022 14:51:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.32 on epoch=84
05/30/2022 14:51:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.33 on epoch=84
05/30/2022 14:51:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.31 on epoch=85
05/30/2022 14:51:49 - INFO - __main__ - Global step 1200 Train loss 0.29 Classification-F1 0.7618501127129484 on epoch=85
05/30/2022 14:51:52 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.31 on epoch=86
05/30/2022 14:51:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.32 on epoch=87
05/30/2022 14:51:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.36 on epoch=87
05/30/2022 14:51:59 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.35 on epoch=88
05/30/2022 14:52:01 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.26 on epoch=89
05/30/2022 14:52:07 - INFO - __main__ - Global step 1250 Train loss 0.32 Classification-F1 0.7111172490121034 on epoch=89
05/30/2022 14:52:10 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.21 on epoch=89
05/30/2022 14:52:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.26 on epoch=90
05/30/2022 14:52:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.27 on epoch=91
05/30/2022 14:52:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.23 on epoch=92
05/30/2022 14:52:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.31 on epoch=92
05/30/2022 14:52:25 - INFO - __main__ - Global step 1300 Train loss 0.25 Classification-F1 0.8257297836045464 on epoch=92
05/30/2022 14:52:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7652072201139634 -> 0.8257297836045464 on epoch=92, global_step=1300
05/30/2022 14:52:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.26 on epoch=93
05/30/2022 14:52:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.29 on epoch=94
05/30/2022 14:52:32 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.24 on epoch=94
05/30/2022 14:52:35 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.23 on epoch=95
05/30/2022 14:52:37 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.27 on epoch=96
05/30/2022 14:52:43 - INFO - __main__ - Global step 1350 Train loss 0.26 Classification-F1 0.7760072109855672 on epoch=96
05/30/2022 14:52:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.26 on epoch=97
05/30/2022 14:52:48 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.24 on epoch=97
05/30/2022 14:52:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.27 on epoch=98
05/30/2022 14:52:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.25 on epoch=99
05/30/2022 14:52:55 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.27 on epoch=99
05/30/2022 14:53:01 - INFO - __main__ - Global step 1400 Train loss 0.26 Classification-F1 0.7780495235117508 on epoch=99
05/30/2022 14:53:04 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.24 on epoch=100
05/30/2022 14:53:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.25 on epoch=101
05/30/2022 14:53:09 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.22 on epoch=102
05/30/2022 14:53:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.21 on epoch=102
05/30/2022 14:53:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.22 on epoch=103
05/30/2022 14:53:20 - INFO - __main__ - Global step 1450 Train loss 0.23 Classification-F1 0.8294226021156461 on epoch=103
05/30/2022 14:53:20 - INFO - __main__ - Saving model with best Classification-F1: 0.8257297836045464 -> 0.8294226021156461 on epoch=103, global_step=1450
05/30/2022 14:53:23 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.22 on epoch=104
05/30/2022 14:53:25 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.28 on epoch=104
05/30/2022 14:53:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=105
05/30/2022 14:53:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.17 on epoch=106
05/30/2022 14:53:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.22 on epoch=107
05/30/2022 14:53:38 - INFO - __main__ - Global step 1500 Train loss 0.21 Classification-F1 0.7842332091072011 on epoch=107
05/30/2022 14:53:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.17 on epoch=107
05/30/2022 14:53:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.26 on epoch=108
05/30/2022 14:53:45 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.23 on epoch=109
05/30/2022 14:53:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.22 on epoch=109
05/30/2022 14:53:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.19 on epoch=110
05/30/2022 14:53:57 - INFO - __main__ - Global step 1550 Train loss 0.21 Classification-F1 0.8308461497366985 on epoch=110
05/30/2022 14:53:57 - INFO - __main__ - Saving model with best Classification-F1: 0.8294226021156461 -> 0.8308461497366985 on epoch=110, global_step=1550
05/30/2022 14:53:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.20 on epoch=111
05/30/2022 14:54:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=112
05/30/2022 14:54:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.17 on epoch=112
05/30/2022 14:54:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.22 on epoch=113
05/30/2022 14:54:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.23 on epoch=114
05/30/2022 14:54:14 - INFO - __main__ - Global step 1600 Train loss 0.19 Classification-F1 0.8339834280433241 on epoch=114
05/30/2022 14:54:14 - INFO - __main__ - Saving model with best Classification-F1: 0.8308461497366985 -> 0.8339834280433241 on epoch=114, global_step=1600
05/30/2022 14:54:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.23 on epoch=114
05/30/2022 14:54:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.19 on epoch=115
05/30/2022 14:54:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.17 on epoch=116
05/30/2022 14:54:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.24 on epoch=117
05/30/2022 14:54:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.20 on epoch=117
05/30/2022 14:54:32 - INFO - __main__ - Global step 1650 Train loss 0.20 Classification-F1 0.7793132942326491 on epoch=117
05/30/2022 14:54:34 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=118
05/30/2022 14:54:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=119
05/30/2022 14:54:39 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=119
05/30/2022 14:54:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.15 on epoch=120
05/30/2022 14:54:44 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=121
05/30/2022 14:54:50 - INFO - __main__ - Global step 1700 Train loss 0.14 Classification-F1 0.8305752926157465 on epoch=121
05/30/2022 14:54:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.18 on epoch=122
05/30/2022 14:54:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.21 on epoch=122
05/30/2022 14:54:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.15 on epoch=123
05/30/2022 14:55:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.14 on epoch=124
05/30/2022 14:55:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.18 on epoch=124
05/30/2022 14:55:08 - INFO - __main__ - Global step 1750 Train loss 0.17 Classification-F1 0.8488908059493797 on epoch=124
05/30/2022 14:55:08 - INFO - __main__ - Saving model with best Classification-F1: 0.8339834280433241 -> 0.8488908059493797 on epoch=124, global_step=1750
05/30/2022 14:55:10 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=125
05/30/2022 14:55:13 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
05/30/2022 14:55:15 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.16 on epoch=127
05/30/2022 14:55:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.13 on epoch=127
05/30/2022 14:55:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.15 on epoch=128
05/30/2022 14:55:26 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.7820000128276352 on epoch=128
05/30/2022 14:55:28 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=129
05/30/2022 14:55:31 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.17 on epoch=129
05/30/2022 14:55:33 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.19 on epoch=130
05/30/2022 14:55:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.14 on epoch=131
05/30/2022 14:55:38 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.14 on epoch=132
05/30/2022 14:55:46 - INFO - __main__ - Global step 1850 Train loss 0.15 Classification-F1 0.863663361727878 on epoch=132
05/30/2022 14:55:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8488908059493797 -> 0.863663361727878 on epoch=132, global_step=1850
05/30/2022 14:55:48 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.12 on epoch=132
05/30/2022 14:55:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.15 on epoch=133
05/30/2022 14:55:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.21 on epoch=134
05/30/2022 14:55:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.21 on epoch=134
05/30/2022 14:55:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.15 on epoch=135
05/30/2022 14:56:04 - INFO - __main__ - Global step 1900 Train loss 0.17 Classification-F1 0.7745220116040124 on epoch=135
05/30/2022 14:56:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.17 on epoch=136
05/30/2022 14:56:08 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=137
05/30/2022 14:56:11 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.12 on epoch=137
05/30/2022 14:56:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.13 on epoch=138
05/30/2022 14:56:16 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.11 on epoch=139
05/30/2022 14:56:21 - INFO - __main__ - Global step 1950 Train loss 0.13 Classification-F1 0.7941234970897612 on epoch=139
05/30/2022 14:56:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=139
05/30/2022 14:56:26 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=140
05/30/2022 14:56:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.12 on epoch=141
05/30/2022 14:56:31 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=142
05/30/2022 14:56:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=142
05/30/2022 14:56:40 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.7113368558023839 on epoch=142
05/30/2022 14:56:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.14 on epoch=143
05/30/2022 14:56:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=144
05/30/2022 14:56:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.12 on epoch=144
05/30/2022 14:56:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=145
05/30/2022 14:56:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=146
05/30/2022 14:56:58 - INFO - __main__ - Global step 2050 Train loss 0.11 Classification-F1 0.9776348295916607 on epoch=146
05/30/2022 14:56:58 - INFO - __main__ - Saving model with best Classification-F1: 0.863663361727878 -> 0.9776348295916607 on epoch=146, global_step=2050
05/30/2022 14:57:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.15 on epoch=147
05/30/2022 14:57:03 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=147
05/30/2022 14:57:05 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.14 on epoch=148
05/30/2022 14:57:08 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.11 on epoch=149
05/30/2022 14:57:10 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.12 on epoch=149
05/30/2022 14:57:17 - INFO - __main__ - Global step 2100 Train loss 0.12 Classification-F1 0.8414081284901294 on epoch=149
05/30/2022 14:57:20 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.12 on epoch=150
05/30/2022 14:57:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.11 on epoch=151
05/30/2022 14:57:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.10 on epoch=152
05/30/2022 14:57:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.10 on epoch=152
05/30/2022 14:57:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=153
05/30/2022 14:57:36 - INFO - __main__ - Global step 2150 Train loss 0.11 Classification-F1 0.9685918676804326 on epoch=153
05/30/2022 14:57:38 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.12 on epoch=154
05/30/2022 14:57:41 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=154
05/30/2022 14:57:43 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=155
05/30/2022 14:57:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.11 on epoch=156
05/30/2022 14:57:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=157
05/30/2022 14:57:54 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.9144793763057522 on epoch=157
05/30/2022 14:57:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=157
05/30/2022 14:57:59 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=158
05/30/2022 14:58:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.16 on epoch=159
05/30/2022 14:58:04 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=159
05/30/2022 14:58:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.09 on epoch=160
05/30/2022 14:58:13 - INFO - __main__ - Global step 2250 Train loss 0.11 Classification-F1 0.8307033099058041 on epoch=160
05/30/2022 14:58:16 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.14 on epoch=161
05/30/2022 14:58:18 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=162
05/30/2022 14:58:21 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.09 on epoch=162
05/30/2022 14:58:23 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.11 on epoch=163
05/30/2022 14:58:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.09 on epoch=164
05/30/2022 14:58:32 - INFO - __main__ - Global step 2300 Train loss 0.10 Classification-F1 0.9059986008088475 on epoch=164
05/30/2022 14:58:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=164
05/30/2022 14:58:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
05/30/2022 14:58:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.13 on epoch=166
05/30/2022 14:58:42 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.16 on epoch=167
05/30/2022 14:58:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=167
05/30/2022 14:58:52 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.7993214881260423 on epoch=167
05/30/2022 14:58:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=168
05/30/2022 14:58:56 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=169
05/30/2022 14:58:59 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=169
05/30/2022 14:59:01 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=170
05/30/2022 14:59:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=171
05/30/2022 14:59:11 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.8975674635985111 on epoch=171
05/30/2022 14:59:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.10 on epoch=172
05/30/2022 14:59:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.10 on epoch=172
05/30/2022 14:59:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=173
05/30/2022 14:59:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.09 on epoch=174
05/30/2022 14:59:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.09 on epoch=174
05/30/2022 14:59:29 - INFO - __main__ - Global step 2450 Train loss 0.09 Classification-F1 0.7803043112201982 on epoch=174
05/30/2022 14:59:31 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=175
05/30/2022 14:59:34 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.14 on epoch=176
05/30/2022 14:59:36 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.14 on epoch=177
05/30/2022 14:59:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
05/30/2022 14:59:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=178
05/30/2022 14:59:47 - INFO - __main__ - Global step 2500 Train loss 0.10 Classification-F1 0.7473944614586995 on epoch=178
05/30/2022 14:59:49 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=179
05/30/2022 14:59:52 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.11 on epoch=179
05/30/2022 14:59:54 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=180
05/30/2022 14:59:57 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.07 on epoch=181
05/30/2022 14:59:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=182
05/30/2022 15:00:05 - INFO - __main__ - Global step 2550 Train loss 0.08 Classification-F1 0.9019556571406667 on epoch=182
05/30/2022 15:00:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/30/2022 15:00:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=183
05/30/2022 15:00:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=184
05/30/2022 15:00:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.11 on epoch=184
05/30/2022 15:00:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
05/30/2022 15:00:24 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.798613114384964 on epoch=185
05/30/2022 15:00:26 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
05/30/2022 15:00:28 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
05/30/2022 15:00:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.10 on epoch=187
05/30/2022 15:00:33 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
05/30/2022 15:00:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.07 on epoch=189
05/30/2022 15:00:44 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.7975698818426802 on epoch=189
05/30/2022 15:00:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=189
05/30/2022 15:00:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=190
05/30/2022 15:00:51 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=191
05/30/2022 15:00:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.09 on epoch=192
05/30/2022 15:00:56 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=192
05/30/2022 15:01:06 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.8452765578877925 on epoch=192
05/30/2022 15:01:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.09 on epoch=193
05/30/2022 15:01:11 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
05/30/2022 15:01:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=194
05/30/2022 15:01:16 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
05/30/2022 15:01:18 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=196
05/30/2022 15:01:25 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.9730561533947182 on epoch=196
05/30/2022 15:01:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=197
05/30/2022 15:01:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
05/30/2022 15:01:32 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
05/30/2022 15:01:35 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=199
05/30/2022 15:01:37 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=199
05/30/2022 15:01:45 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.855304467828187 on epoch=199
05/30/2022 15:01:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
05/30/2022 15:01:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.11 on epoch=201
05/30/2022 15:01:52 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.09 on epoch=202
05/30/2022 15:01:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
05/30/2022 15:01:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
05/30/2022 15:02:05 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.8425223816205114 on epoch=203
05/30/2022 15:02:08 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
05/30/2022 15:02:10 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.09 on epoch=204
05/30/2022 15:02:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=205
05/30/2022 15:02:15 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=206
05/30/2022 15:02:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.07 on epoch=207
05/30/2022 15:02:24 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.8491216721292623 on epoch=207
05/30/2022 15:02:26 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=207
05/30/2022 15:02:29 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=208
05/30/2022 15:02:31 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=209
05/30/2022 15:02:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=209
05/30/2022 15:02:36 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.11 on epoch=210
05/30/2022 15:02:43 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.8551930596285435 on epoch=210
05/30/2022 15:02:45 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=211
05/30/2022 15:02:48 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=212
05/30/2022 15:02:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=212
05/30/2022 15:02:53 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.11 on epoch=213
05/30/2022 15:02:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.08 on epoch=214
05/30/2022 15:03:02 - INFO - __main__ - Global step 3000 Train loss 0.07 Classification-F1 0.7117025671461155 on epoch=214
05/30/2022 15:03:02 - INFO - __main__ - save last model!
05/30/2022 15:03:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 15:03:02 - INFO - __main__ - Start tokenizing ... 3500 instances
05/30/2022 15:03:02 - INFO - __main__ - Printing 3 examples
05/30/2022 15:03:02 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/30/2022 15:03:02 - INFO - __main__ - ['Animal']
05/30/2022 15:03:02 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/30/2022 15:03:02 - INFO - __main__ - ['Animal']
05/30/2022 15:03:02 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/30/2022 15:03:02 - INFO - __main__ - ['Village']
05/30/2022 15:03:02 - INFO - __main__ - Tokenizing Input ...
05/30/2022 15:03:04 - INFO - __main__ - Tokenizing Output ...
05/30/2022 15:03:07 - INFO - __main__ - Loaded 3500 examples from test data
05/30/2022 15:05:10 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-50prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
05/30/2022 15:05:10 - INFO - __main__ - Classification-F1 on test data: 0.5427
05/30/2022 15:05:11 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.9776348295916607, test_performance=0.5427133112146977
