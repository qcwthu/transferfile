05/21/2022 21:18:11 - INFO - __main__ - Namespace(task_dir='data_32/emo/', task_name='emo', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 21:18:11 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo
05/21/2022 21:18:11 - INFO - __main__ - Namespace(task_dir='data_32/emo/', task_name='emo', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 21:18:11 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo
05/21/2022 21:18:12 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:18:12 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:18:12 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:18:12 - INFO - __main__ - Using 2 gpus
05/21/2022 21:18:12 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:18:12 - INFO - __main__ - Using 2 gpus
05/21/2022 21:18:12 - INFO - __main__ - Fine-tuning the following samples: ['emo_32_100', 'emo_32_13', 'emo_32_21', 'emo_32_42', 'emo_32_87']
05/21/2022 21:18:12 - INFO - __main__ - Fine-tuning the following samples: ['emo_32_100', 'emo_32_13', 'emo_32_21', 'emo_32_42', 'emo_32_87']
05/21/2022 21:18:18 - INFO - __main__ - Running ... prefix=emo_32_100, lr=0.5, bsz=8 ...
06/08/2022 10:15:05 - INFO - __main__ - Namespace(task_dir='data_32/emo/', task_name='emo', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/08/2022 10:15:05 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo
06/08/2022 10:15:05 - INFO - __main__ - Namespace(task_dir='data_32/emo/', task_name='emo', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/08/2022 10:15:05 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo
06/08/2022 10:15:06 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/08/2022 10:15:06 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/08/2022 10:15:06 - INFO - __main__ - args.device: cuda:0
06/08/2022 10:15:06 - INFO - __main__ - Using 2 gpus
06/08/2022 10:15:06 - INFO - __main__ - Fine-tuning the following samples: ['emo_32_100', 'emo_32_13', 'emo_32_21', 'emo_32_42', 'emo_32_87']
06/08/2022 10:15:06 - INFO - __main__ - args.device: cuda:1
06/08/2022 10:15:06 - INFO - __main__ - Using 2 gpus
06/08/2022 10:15:06 - INFO - __main__ - Fine-tuning the following samples: ['emo_32_100', 'emo_32_13', 'emo_32_21', 'emo_32_42', 'emo_32_87']
06/08/2022 10:15:11 - INFO - __main__ - Running ... prefix=emo_32_100, lr=0.5, bsz=8 ...
06/08/2022 10:15:12 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 10:15:12 - INFO - __main__ - Printing 3 examples
06/08/2022 10:15:12 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 10:15:12 - INFO - __main__ - ['others']
06/08/2022 10:15:12 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 10:15:12 - INFO - __main__ - ['others']
06/08/2022 10:15:12 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 10:15:12 - INFO - __main__ - ['others']
06/08/2022 10:15:12 - INFO - __main__ - Tokenizing Input ...
06/08/2022 10:15:12 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 10:15:12 - INFO - __main__ - Printing 3 examples
06/08/2022 10:15:12 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 10:15:12 - INFO - __main__ - ['others']
06/08/2022 10:15:12 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 10:15:12 - INFO - __main__ - ['others']
06/08/2022 10:15:12 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 10:15:12 - INFO - __main__ - ['others']
06/08/2022 10:15:12 - INFO - __main__ - Tokenizing Input ...
06/08/2022 10:15:12 - INFO - __main__ - Tokenizing Output ...
06/08/2022 10:15:12 - INFO - __main__ - Tokenizing Output ...
06/08/2022 10:15:12 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 10:15:12 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 10:15:12 - INFO - __main__ - Printing 3 examples
06/08/2022 10:15:12 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/08/2022 10:15:12 - INFO - __main__ - ['others']
06/08/2022 10:15:12 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/08/2022 10:15:12 - INFO - __main__ - ['others']
06/08/2022 10:15:12 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/08/2022 10:15:12 - INFO - __main__ - ['others']
06/08/2022 10:15:12 - INFO - __main__ - Tokenizing Input ...
06/08/2022 10:15:12 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 10:15:12 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 10:15:12 - INFO - __main__ - Printing 3 examples
06/08/2022 10:15:12 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/08/2022 10:15:12 - INFO - __main__ - ['others']
06/08/2022 10:15:12 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/08/2022 10:15:12 - INFO - __main__ - ['others']
06/08/2022 10:15:12 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/08/2022 10:15:12 - INFO - __main__ - ['others']
06/08/2022 10:15:12 - INFO - __main__ - Tokenizing Input ...
06/08/2022 10:15:12 - INFO - __main__ - Tokenizing Output ...
06/08/2022 10:15:13 - INFO - __main__ - Tokenizing Output ...
06/08/2022 10:15:13 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 10:15:13 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 10:15:32 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 10:15:32 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 10:15:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 10:15:33 - INFO - __main__ - Starting training!
06/08/2022 10:15:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 10:15:39 - INFO - __main__ - Starting training!
06/08/2022 10:15:42 - INFO - __main__ - Step 10 Global step 10 Train loss 2.55 on epoch=1
06/08/2022 10:15:45 - INFO - __main__ - Step 20 Global step 20 Train loss 1.39 on epoch=2
06/08/2022 10:15:47 - INFO - __main__ - Step 30 Global step 30 Train loss 1.02 on epoch=3
06/08/2022 10:15:50 - INFO - __main__ - Step 40 Global step 40 Train loss 1.00 on epoch=4
06/08/2022 10:15:52 - INFO - __main__ - Step 50 Global step 50 Train loss 0.94 on epoch=6
06/08/2022 10:15:54 - INFO - __main__ - Global step 50 Train loss 1.38 Classification-F1 0.1 on epoch=6
06/08/2022 10:15:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=6, global_step=50
06/08/2022 10:15:57 - INFO - __main__ - Step 60 Global step 60 Train loss 0.86 on epoch=7
06/08/2022 10:15:59 - INFO - __main__ - Step 70 Global step 70 Train loss 0.83 on epoch=8
06/08/2022 10:16:02 - INFO - __main__ - Step 80 Global step 80 Train loss 0.91 on epoch=9
06/08/2022 10:16:04 - INFO - __main__ - Step 90 Global step 90 Train loss 1.72 on epoch=11
06/08/2022 10:16:07 - INFO - __main__ - Step 100 Global step 100 Train loss 1.16 on epoch=12
06/08/2022 10:16:09 - INFO - __main__ - Global step 100 Train loss 1.10 Classification-F1 0.2707070707070707 on epoch=12
06/08/2022 10:16:09 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.2707070707070707 on epoch=12, global_step=100
06/08/2022 10:16:11 - INFO - __main__ - Step 110 Global step 110 Train loss 0.96 on epoch=13
06/08/2022 10:16:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.78 on epoch=14
06/08/2022 10:16:16 - INFO - __main__ - Step 130 Global step 130 Train loss 0.81 on epoch=16
06/08/2022 10:16:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.83 on epoch=17
06/08/2022 10:16:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.82 on epoch=18
06/08/2022 10:16:23 - INFO - __main__ - Global step 150 Train loss 0.84 Classification-F1 0.3564168118056863 on epoch=18
06/08/2022 10:16:23 - INFO - __main__ - Saving model with best Classification-F1: 0.2707070707070707 -> 0.3564168118056863 on epoch=18, global_step=150
06/08/2022 10:16:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.88 on epoch=19
06/08/2022 10:16:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.82 on epoch=21
06/08/2022 10:16:31 - INFO - __main__ - Step 180 Global step 180 Train loss 0.81 on epoch=22
06/08/2022 10:16:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.86 on epoch=23
06/08/2022 10:16:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.82 on epoch=24
06/08/2022 10:16:38 - INFO - __main__ - Global step 200 Train loss 0.84 Classification-F1 0.2824958738309188 on epoch=24
06/08/2022 10:16:40 - INFO - __main__ - Step 210 Global step 210 Train loss 0.82 on epoch=26
06/08/2022 10:16:43 - INFO - __main__ - Step 220 Global step 220 Train loss 0.78 on epoch=27
06/08/2022 10:16:45 - INFO - __main__ - Step 230 Global step 230 Train loss 0.89 on epoch=28
06/08/2022 10:16:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.85 on epoch=29
06/08/2022 10:16:51 - INFO - __main__ - Step 250 Global step 250 Train loss 0.81 on epoch=31
06/08/2022 10:16:52 - INFO - __main__ - Global step 250 Train loss 0.83 Classification-F1 0.3909187785786251 on epoch=31
06/08/2022 10:16:52 - INFO - __main__ - Saving model with best Classification-F1: 0.3564168118056863 -> 0.3909187785786251 on epoch=31, global_step=250
06/08/2022 10:16:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.74 on epoch=32
06/08/2022 10:16:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.70 on epoch=33
06/08/2022 10:17:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.84 on epoch=34
06/08/2022 10:17:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.85 on epoch=36
06/08/2022 10:17:05 - INFO - __main__ - Step 300 Global step 300 Train loss 0.74 on epoch=37
06/08/2022 10:17:07 - INFO - __main__ - Global step 300 Train loss 0.77 Classification-F1 0.4437254901960784 on epoch=37
06/08/2022 10:17:07 - INFO - __main__ - Saving model with best Classification-F1: 0.3909187785786251 -> 0.4437254901960784 on epoch=37, global_step=300
06/08/2022 10:17:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.72 on epoch=38
06/08/2022 10:17:12 - INFO - __main__ - Step 320 Global step 320 Train loss 0.80 on epoch=39
06/08/2022 10:17:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.74 on epoch=41
06/08/2022 10:17:17 - INFO - __main__ - Step 340 Global step 340 Train loss 0.73 on epoch=42
06/08/2022 10:17:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.84 on epoch=43
06/08/2022 10:17:21 - INFO - __main__ - Global step 350 Train loss 0.76 Classification-F1 0.5423740510697033 on epoch=43
06/08/2022 10:17:21 - INFO - __main__ - Saving model with best Classification-F1: 0.4437254901960784 -> 0.5423740510697033 on epoch=43, global_step=350
06/08/2022 10:17:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.81 on epoch=44
06/08/2022 10:17:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.78 on epoch=46
06/08/2022 10:17:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.66 on epoch=47
06/08/2022 10:17:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.72 on epoch=48
06/08/2022 10:17:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.72 on epoch=49
06/08/2022 10:17:36 - INFO - __main__ - Global step 400 Train loss 0.74 Classification-F1 0.3388146167557933 on epoch=49
06/08/2022 10:17:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.69 on epoch=51
06/08/2022 10:17:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.66 on epoch=52
06/08/2022 10:17:44 - INFO - __main__ - Step 430 Global step 430 Train loss 0.71 on epoch=53
06/08/2022 10:17:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.65 on epoch=54
06/08/2022 10:17:49 - INFO - __main__ - Step 450 Global step 450 Train loss 0.69 on epoch=56
06/08/2022 10:17:51 - INFO - __main__ - Global step 450 Train loss 0.68 Classification-F1 0.5506840016708437 on epoch=56
06/08/2022 10:17:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5423740510697033 -> 0.5506840016708437 on epoch=56, global_step=450
06/08/2022 10:17:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.67 on epoch=57
06/08/2022 10:17:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.59 on epoch=58
06/08/2022 10:17:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.58 on epoch=59
06/08/2022 10:18:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.65 on epoch=61
06/08/2022 10:18:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.61 on epoch=62
06/08/2022 10:18:06 - INFO - __main__ - Global step 500 Train loss 0.62 Classification-F1 0.6512710737206131 on epoch=62
06/08/2022 10:18:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5506840016708437 -> 0.6512710737206131 on epoch=62, global_step=500
06/08/2022 10:18:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.71 on epoch=63
06/08/2022 10:18:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.60 on epoch=64
06/08/2022 10:18:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.54 on epoch=66
06/08/2022 10:18:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.64 on epoch=67
06/08/2022 10:18:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.53 on epoch=68
06/08/2022 10:18:20 - INFO - __main__ - Global step 550 Train loss 0.60 Classification-F1 0.730011408083442 on epoch=68
06/08/2022 10:18:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6512710737206131 -> 0.730011408083442 on epoch=68, global_step=550
06/08/2022 10:18:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.59 on epoch=69
06/08/2022 10:18:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.53 on epoch=71
06/08/2022 10:18:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.54 on epoch=72
06/08/2022 10:18:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.71 on epoch=73
06/08/2022 10:18:33 - INFO - __main__ - Step 600 Global step 600 Train loss 0.54 on epoch=74
06/08/2022 10:18:35 - INFO - __main__ - Global step 600 Train loss 0.58 Classification-F1 0.5869630161244679 on epoch=74
06/08/2022 10:18:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.54 on epoch=76
06/08/2022 10:18:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.55 on epoch=77
06/08/2022 10:18:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.51 on epoch=78
06/08/2022 10:18:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.54 on epoch=79
06/08/2022 10:18:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.51 on epoch=81
06/08/2022 10:18:50 - INFO - __main__ - Global step 650 Train loss 0.53 Classification-F1 0.7393253968253968 on epoch=81
06/08/2022 10:18:50 - INFO - __main__ - Saving model with best Classification-F1: 0.730011408083442 -> 0.7393253968253968 on epoch=81, global_step=650
06/08/2022 10:18:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.55 on epoch=82
06/08/2022 10:18:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.37 on epoch=83
06/08/2022 10:18:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.53 on epoch=84
06/08/2022 10:19:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.59 on epoch=86
06/08/2022 10:19:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.41 on epoch=87
06/08/2022 10:19:04 - INFO - __main__ - Global step 700 Train loss 0.49 Classification-F1 0.784665854978355 on epoch=87
06/08/2022 10:19:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7393253968253968 -> 0.784665854978355 on epoch=87, global_step=700
06/08/2022 10:19:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.46 on epoch=88
06/08/2022 10:19:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.35 on epoch=89
06/08/2022 10:19:12 - INFO - __main__ - Step 730 Global step 730 Train loss 0.47 on epoch=91
06/08/2022 10:19:15 - INFO - __main__ - Step 740 Global step 740 Train loss 0.44 on epoch=92
06/08/2022 10:19:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.41 on epoch=93
06/08/2022 10:19:19 - INFO - __main__ - Global step 750 Train loss 0.42 Classification-F1 0.7445381169709264 on epoch=93
06/08/2022 10:19:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.48 on epoch=94
06/08/2022 10:19:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.48 on epoch=96
06/08/2022 10:19:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.37 on epoch=97
06/08/2022 10:19:30 - INFO - __main__ - Step 790 Global step 790 Train loss 0.41 on epoch=98
06/08/2022 10:19:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.47 on epoch=99
06/08/2022 10:19:34 - INFO - __main__ - Global step 800 Train loss 0.44 Classification-F1 0.5345117732378953 on epoch=99
06/08/2022 10:19:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.40 on epoch=101
06/08/2022 10:19:39 - INFO - __main__ - Step 820 Global step 820 Train loss 0.41 on epoch=102
06/08/2022 10:19:42 - INFO - __main__ - Step 830 Global step 830 Train loss 0.43 on epoch=103
06/08/2022 10:19:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.44 on epoch=104
06/08/2022 10:19:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.50 on epoch=106
06/08/2022 10:19:49 - INFO - __main__ - Global step 850 Train loss 0.44 Classification-F1 0.7618802114656308 on epoch=106
06/08/2022 10:19:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.40 on epoch=107
06/08/2022 10:19:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.35 on epoch=108
06/08/2022 10:19:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.47 on epoch=109
06/08/2022 10:19:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.34 on epoch=111
06/08/2022 10:20:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.37 on epoch=112
06/08/2022 10:20:04 - INFO - __main__ - Global step 900 Train loss 0.38 Classification-F1 0.714484126984127 on epoch=112
06/08/2022 10:20:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.38 on epoch=113
06/08/2022 10:20:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.39 on epoch=114
06/08/2022 10:20:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.42 on epoch=116
06/08/2022 10:20:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.31 on epoch=117
06/08/2022 10:20:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.27 on epoch=118
06/08/2022 10:20:19 - INFO - __main__ - Global step 950 Train loss 0.35 Classification-F1 0.727123383795517 on epoch=118
06/08/2022 10:20:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.32 on epoch=119
06/08/2022 10:20:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.40 on epoch=121
06/08/2022 10:20:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.32 on epoch=122
06/08/2022 10:20:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.28 on epoch=123
06/08/2022 10:20:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.33 on epoch=124
06/08/2022 10:20:34 - INFO - __main__ - Global step 1000 Train loss 0.33 Classification-F1 0.7288841117842486 on epoch=124
06/08/2022 10:20:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.30 on epoch=126
06/08/2022 10:20:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.29 on epoch=127
06/08/2022 10:20:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.28 on epoch=128
06/08/2022 10:20:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.34 on epoch=129
06/08/2022 10:20:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.26 on epoch=131
06/08/2022 10:20:49 - INFO - __main__ - Global step 1050 Train loss 0.29 Classification-F1 0.7717730713800586 on epoch=131
06/08/2022 10:20:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.22 on epoch=132
06/08/2022 10:20:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.22 on epoch=133
06/08/2022 10:20:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.31 on epoch=134
06/08/2022 10:21:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.31 on epoch=136
06/08/2022 10:21:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=137
06/08/2022 10:21:04 - INFO - __main__ - Global step 1100 Train loss 0.27 Classification-F1 0.7717604617604618 on epoch=137
06/08/2022 10:21:07 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.22 on epoch=138
06/08/2022 10:21:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.26 on epoch=139
06/08/2022 10:21:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.24 on epoch=141
06/08/2022 10:21:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.24 on epoch=142
06/08/2022 10:21:17 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.27 on epoch=143
06/08/2022 10:21:19 - INFO - __main__ - Global step 1150 Train loss 0.25 Classification-F1 0.7725772143282565 on epoch=143
06/08/2022 10:21:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.21 on epoch=144
06/08/2022 10:21:24 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.21 on epoch=146
06/08/2022 10:21:27 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.28 on epoch=147
06/08/2022 10:21:29 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.25 on epoch=148
06/08/2022 10:21:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.17 on epoch=149
06/08/2022 10:21:34 - INFO - __main__ - Global step 1200 Train loss 0.22 Classification-F1 0.7649019297273039 on epoch=149
06/08/2022 10:21:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=151
06/08/2022 10:21:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.24 on epoch=152
06/08/2022 10:21:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.18 on epoch=153
06/08/2022 10:21:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=154
06/08/2022 10:21:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.21 on epoch=156
06/08/2022 10:21:48 - INFO - __main__ - Global step 1250 Train loss 0.20 Classification-F1 0.8017307671446532 on epoch=156
06/08/2022 10:21:48 - INFO - __main__ - Saving model with best Classification-F1: 0.784665854978355 -> 0.8017307671446532 on epoch=156, global_step=1250
06/08/2022 10:21:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=157
06/08/2022 10:21:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.21 on epoch=158
06/08/2022 10:21:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.29 on epoch=159
06/08/2022 10:21:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=161
06/08/2022 10:22:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.19 on epoch=162
06/08/2022 10:22:03 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.7082513802622498 on epoch=162
06/08/2022 10:22:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=163
06/08/2022 10:22:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=164
06/08/2022 10:22:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=166
06/08/2022 10:22:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.20 on epoch=167
06/08/2022 10:22:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=168
06/08/2022 10:22:17 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.7926588051228396 on epoch=168
06/08/2022 10:22:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=169
06/08/2022 10:22:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.13 on epoch=171
06/08/2022 10:22:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.19 on epoch=172
06/08/2022 10:22:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=173
06/08/2022 10:22:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=174
06/08/2022 10:22:32 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.7799920850293984 on epoch=174
06/08/2022 10:22:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=176
06/08/2022 10:22:37 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.30 on epoch=177
06/08/2022 10:22:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.16 on epoch=178
06/08/2022 10:22:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=179
06/08/2022 10:22:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.18 on epoch=181
06/08/2022 10:22:47 - INFO - __main__ - Global step 1450 Train loss 0.18 Classification-F1 0.7724811796046268 on epoch=181
06/08/2022 10:22:49 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=182
06/08/2022 10:22:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=183
06/08/2022 10:22:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=184
06/08/2022 10:22:57 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=186
06/08/2022 10:23:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.15 on epoch=187
06/08/2022 10:23:01 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.7873801220575415 on epoch=187
06/08/2022 10:23:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=188
06/08/2022 10:23:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.22 on epoch=189
06/08/2022 10:23:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=191
06/08/2022 10:23:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=192
06/08/2022 10:23:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.14 on epoch=193
06/08/2022 10:23:16 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.7483183267351013 on epoch=193
06/08/2022 10:23:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=194
06/08/2022 10:23:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=196
06/08/2022 10:23:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.16 on epoch=197
06/08/2022 10:23:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=198
06/08/2022 10:23:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.16 on epoch=199
06/08/2022 10:23:31 - INFO - __main__ - Global step 1600 Train loss 0.12 Classification-F1 0.7601536195286196 on epoch=199
06/08/2022 10:23:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=201
06/08/2022 10:23:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.11 on epoch=202
06/08/2022 10:23:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.15 on epoch=203
06/08/2022 10:23:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=204
06/08/2022 10:23:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.12 on epoch=206
06/08/2022 10:23:45 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.7837490094016787 on epoch=206
06/08/2022 10:23:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=207
06/08/2022 10:23:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=208
06/08/2022 10:23:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.17 on epoch=209
06/08/2022 10:23:56 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=211
06/08/2022 10:23:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=212
06/08/2022 10:24:00 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.7674043925295865 on epoch=212
06/08/2022 10:24:03 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=213
06/08/2022 10:24:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=214
06/08/2022 10:24:08 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.16 on epoch=216
06/08/2022 10:24:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.15 on epoch=217
06/08/2022 10:24:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=218
06/08/2022 10:24:15 - INFO - __main__ - Global step 1750 Train loss 0.12 Classification-F1 0.7994200781612754 on epoch=218
06/08/2022 10:24:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=219
06/08/2022 10:24:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=221
06/08/2022 10:24:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=222
06/08/2022 10:24:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=223
06/08/2022 10:24:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=224
06/08/2022 10:24:30 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.7063420219140557 on epoch=224
06/08/2022 10:24:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=226
06/08/2022 10:24:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=227
06/08/2022 10:24:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=228
06/08/2022 10:24:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=229
06/08/2022 10:24:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=231
06/08/2022 10:24:44 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.7658367207620939 on epoch=231
06/08/2022 10:24:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=232
06/08/2022 10:24:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=233
06/08/2022 10:24:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=234
06/08/2022 10:24:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=236
06/08/2022 10:24:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=237
06/08/2022 10:24:59 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.7729350119244175 on epoch=237
06/08/2022 10:25:02 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=238
06/08/2022 10:25:05 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=239
06/08/2022 10:25:07 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=241
06/08/2022 10:25:10 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.16 on epoch=242
06/08/2022 10:25:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=243
06/08/2022 10:25:14 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.7210061740304843 on epoch=243
06/08/2022 10:25:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=244
06/08/2022 10:25:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=246
06/08/2022 10:25:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=247
06/08/2022 10:25:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.12 on epoch=248
06/08/2022 10:25:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=249
06/08/2022 10:25:29 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.7514985747820255 on epoch=249
06/08/2022 10:25:32 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=251
06/08/2022 10:25:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=252
06/08/2022 10:25:37 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=253
06/08/2022 10:25:39 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=254
06/08/2022 10:25:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=256
06/08/2022 10:25:44 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7572684183297993 on epoch=256
06/08/2022 10:25:46 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=257
06/08/2022 10:25:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=258
06/08/2022 10:25:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=259
06/08/2022 10:25:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=261
06/08/2022 10:25:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=262
06/08/2022 10:25:59 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.8042540792540792 on epoch=262
06/08/2022 10:25:59 - INFO - __main__ - Saving model with best Classification-F1: 0.8017307671446532 -> 0.8042540792540792 on epoch=262, global_step=2100
06/08/2022 10:26:01 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=263
06/08/2022 10:26:04 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.11 on epoch=264
06/08/2022 10:26:06 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=266
06/08/2022 10:26:09 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=267
06/08/2022 10:26:12 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=268
06/08/2022 10:26:14 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7847199689956017 on epoch=268
06/08/2022 10:26:16 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.12 on epoch=269
06/08/2022 10:26:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=271
06/08/2022 10:26:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=272
06/08/2022 10:26:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=273
06/08/2022 10:26:27 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=274
06/08/2022 10:26:29 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.7899395710579209 on epoch=274
06/08/2022 10:26:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=276
06/08/2022 10:26:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=277
06/08/2022 10:26:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=278
06/08/2022 10:26:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=279
06/08/2022 10:26:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=281
06/08/2022 10:26:44 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8072325781612754 on epoch=281
06/08/2022 10:26:44 - INFO - __main__ - Saving model with best Classification-F1: 0.8042540792540792 -> 0.8072325781612754 on epoch=281, global_step=2250
06/08/2022 10:26:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=282
06/08/2022 10:26:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=283
06/08/2022 10:26:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=284
06/08/2022 10:26:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.11 on epoch=286
06/08/2022 10:26:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=287
06/08/2022 10:26:59 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.7829048037125298 on epoch=287
06/08/2022 10:27:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=288
06/08/2022 10:27:05 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=289
06/08/2022 10:27:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=291
06/08/2022 10:27:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=292
06/08/2022 10:27:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=293
06/08/2022 10:27:15 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.8065594469282993 on epoch=293
06/08/2022 10:27:17 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=294
06/08/2022 10:27:20 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=296
06/08/2022 10:27:23 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=297
06/08/2022 10:27:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=298
06/08/2022 10:27:28 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=299
06/08/2022 10:27:30 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7981468910074618 on epoch=299
06/08/2022 10:27:33 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
06/08/2022 10:27:35 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=302
06/08/2022 10:27:38 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
06/08/2022 10:27:41 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=304
06/08/2022 10:27:43 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=306
06/08/2022 10:27:45 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.767000191141385 on epoch=306
06/08/2022 10:27:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.11 on epoch=307
06/08/2022 10:27:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=308
06/08/2022 10:27:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=309
06/08/2022 10:27:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.21 on epoch=311
06/08/2022 10:27:58 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=312
06/08/2022 10:28:00 - INFO - __main__ - Global step 2500 Train loss 0.10 Classification-F1 0.7809523809523808 on epoch=312
06/08/2022 10:28:03 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=313
06/08/2022 10:28:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=314
06/08/2022 10:28:08 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=316
06/08/2022 10:28:11 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=317
06/08/2022 10:28:13 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=318
06/08/2022 10:28:15 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7828594446598179 on epoch=318
06/08/2022 10:28:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
06/08/2022 10:28:20 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=321
06/08/2022 10:28:23 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=322
06/08/2022 10:28:26 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=323
06/08/2022 10:28:28 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=324
06/08/2022 10:28:30 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7539484126984127 on epoch=324
06/08/2022 10:28:33 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=326
06/08/2022 10:28:35 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.12 on epoch=327
06/08/2022 10:28:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=328
06/08/2022 10:28:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=329
06/08/2022 10:28:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
06/08/2022 10:28:45 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7872831599486948 on epoch=331
06/08/2022 10:28:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=332
06/08/2022 10:28:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=333
06/08/2022 10:28:53 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.09 on epoch=334
06/08/2022 10:28:56 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.09 on epoch=336
06/08/2022 10:28:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=337
06/08/2022 10:29:00 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.7497413679713052 on epoch=337
06/08/2022 10:29:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.13 on epoch=338
06/08/2022 10:29:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=339
06/08/2022 10:29:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=341
06/08/2022 10:29:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=342
06/08/2022 10:29:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=343
06/08/2022 10:29:15 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.7861326962982311 on epoch=343
06/08/2022 10:29:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=344
06/08/2022 10:29:21 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=346
06/08/2022 10:29:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=347
06/08/2022 10:29:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=348
06/08/2022 10:29:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
06/08/2022 10:29:31 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7624116553455297 on epoch=349
06/08/2022 10:29:33 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
06/08/2022 10:29:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
06/08/2022 10:29:39 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=353
06/08/2022 10:29:41 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=354
06/08/2022 10:29:44 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
06/08/2022 10:29:46 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7877423965263457 on epoch=356
06/08/2022 10:29:48 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=357
06/08/2022 10:29:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=358
06/08/2022 10:29:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/08/2022 10:29:57 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=361
06/08/2022 10:30:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/08/2022 10:30:02 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7833141982395714 on epoch=362
06/08/2022 10:30:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=363
06/08/2022 10:30:07 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=364
06/08/2022 10:30:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=366
06/08/2022 10:30:13 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/08/2022 10:30:15 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
06/08/2022 10:30:17 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7901184401184401 on epoch=368
06/08/2022 10:30:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=369
06/08/2022 10:30:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=371
06/08/2022 10:30:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=372
06/08/2022 10:30:27 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=373
06/08/2022 10:30:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
06/08/2022 10:30:31 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 10:30:31 - INFO - __main__ - Printing 3 examples
06/08/2022 10:30:31 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 10:30:31 - INFO - __main__ - ['others']
06/08/2022 10:30:31 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 10:30:31 - INFO - __main__ - ['others']
06/08/2022 10:30:31 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 10:30:31 - INFO - __main__ - ['others']
06/08/2022 10:30:31 - INFO - __main__ - Tokenizing Input ...
06/08/2022 10:30:31 - INFO - __main__ - Tokenizing Output ...
06/08/2022 10:30:31 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 10:30:31 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 10:30:31 - INFO - __main__ - Printing 3 examples
06/08/2022 10:30:31 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/08/2022 10:30:31 - INFO - __main__ - ['others']
06/08/2022 10:30:31 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/08/2022 10:30:31 - INFO - __main__ - ['others']
06/08/2022 10:30:31 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/08/2022 10:30:31 - INFO - __main__ - ['others']
06/08/2022 10:30:31 - INFO - __main__ - Tokenizing Input ...
06/08/2022 10:30:32 - INFO - __main__ - Tokenizing Output ...
06/08/2022 10:30:32 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 10:30:32 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7722898106459751 on epoch=374
06/08/2022 10:30:32 - INFO - __main__ - save last model!
06/08/2022 10:30:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 10:30:32 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 10:30:32 - INFO - __main__ - Printing 3 examples
06/08/2022 10:30:32 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 10:30:32 - INFO - __main__ - ['others']
06/08/2022 10:30:32 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 10:30:32 - INFO - __main__ - ['others']
06/08/2022 10:30:32 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 10:30:32 - INFO - __main__ - ['others']
06/08/2022 10:30:32 - INFO - __main__ - Tokenizing Input ...
06/08/2022 10:30:34 - INFO - __main__ - Tokenizing Output ...
06/08/2022 10:30:40 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 10:30:48 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 10:30:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 10:30:49 - INFO - __main__ - Starting training!
06/08/2022 10:31:55 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_100_0.5_8_predictions.txt
06/08/2022 10:31:55 - INFO - __main__ - Classification-F1 on test data: 0.3351
06/08/2022 10:31:55 - INFO - __main__ - prefix=emo_32_100, lr=0.5, bsz=8, dev_performance=0.8072325781612754, test_performance=0.335096714303573
06/08/2022 10:31:55 - INFO - __main__ - Running ... prefix=emo_32_100, lr=0.4, bsz=8 ...
06/08/2022 10:31:56 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 10:31:56 - INFO - __main__ - Printing 3 examples
06/08/2022 10:31:56 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 10:31:56 - INFO - __main__ - ['others']
06/08/2022 10:31:56 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 10:31:56 - INFO - __main__ - ['others']
06/08/2022 10:31:56 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 10:31:56 - INFO - __main__ - ['others']
06/08/2022 10:31:56 - INFO - __main__ - Tokenizing Input ...
06/08/2022 10:31:56 - INFO - __main__ - Tokenizing Output ...
06/08/2022 10:31:56 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 10:31:56 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 10:31:56 - INFO - __main__ - Printing 3 examples
06/08/2022 10:31:56 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/08/2022 10:31:56 - INFO - __main__ - ['others']
06/08/2022 10:31:56 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/08/2022 10:31:56 - INFO - __main__ - ['others']
06/08/2022 10:31:56 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/08/2022 10:31:56 - INFO - __main__ - ['others']
06/08/2022 10:31:56 - INFO - __main__ - Tokenizing Input ...
06/08/2022 10:31:56 - INFO - __main__ - Tokenizing Output ...
06/08/2022 10:31:57 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 10:32:15 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 10:32:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 10:32:16 - INFO - __main__ - Starting training!
06/08/2022 10:32:19 - INFO - __main__ - Step 10 Global step 10 Train loss 2.68 on epoch=1
06/08/2022 10:32:22 - INFO - __main__ - Step 20 Global step 20 Train loss 1.32 on epoch=2
06/08/2022 10:32:24 - INFO - __main__ - Step 30 Global step 30 Train loss 1.08 on epoch=3
06/08/2022 10:32:27 - INFO - __main__ - Step 40 Global step 40 Train loss 1.05 on epoch=4
06/08/2022 10:32:29 - INFO - __main__ - Step 50 Global step 50 Train loss 0.89 on epoch=6
06/08/2022 10:32:31 - INFO - __main__ - Global step 50 Train loss 1.40 Classification-F1 0.1 on epoch=6
06/08/2022 10:32:31 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=6, global_step=50
06/08/2022 10:32:34 - INFO - __main__ - Step 60 Global step 60 Train loss 0.90 on epoch=7
06/08/2022 10:32:37 - INFO - __main__ - Step 70 Global step 70 Train loss 0.88 on epoch=8
06/08/2022 10:32:39 - INFO - __main__ - Step 80 Global step 80 Train loss 0.89 on epoch=9
06/08/2022 10:32:42 - INFO - __main__ - Step 90 Global step 90 Train loss 0.93 on epoch=11
06/08/2022 10:32:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.87 on epoch=12
06/08/2022 10:32:46 - INFO - __main__ - Global step 100 Train loss 0.90 Classification-F1 0.40152853260869564 on epoch=12
06/08/2022 10:32:46 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.40152853260869564 on epoch=12, global_step=100
06/08/2022 10:32:49 - INFO - __main__ - Step 110 Global step 110 Train loss 0.82 on epoch=13
06/08/2022 10:32:52 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=14
06/08/2022 10:32:55 - INFO - __main__ - Step 130 Global step 130 Train loss 0.89 on epoch=16
06/08/2022 10:32:57 - INFO - __main__ - Step 140 Global step 140 Train loss 0.83 on epoch=17
06/08/2022 10:33:00 - INFO - __main__ - Step 150 Global step 150 Train loss 0.89 on epoch=18
06/08/2022 10:33:02 - INFO - __main__ - Global step 150 Train loss 0.87 Classification-F1 0.25595238095238093 on epoch=18
06/08/2022 10:33:04 - INFO - __main__ - Step 160 Global step 160 Train loss 0.82 on epoch=19
06/08/2022 10:33:07 - INFO - __main__ - Step 170 Global step 170 Train loss 0.82 on epoch=21
06/08/2022 10:33:10 - INFO - __main__ - Step 180 Global step 180 Train loss 0.78 on epoch=22
06/08/2022 10:33:12 - INFO - __main__ - Step 190 Global step 190 Train loss 0.85 on epoch=23
06/08/2022 10:33:15 - INFO - __main__ - Step 200 Global step 200 Train loss 0.83 on epoch=24
06/08/2022 10:33:17 - INFO - __main__ - Global step 200 Train loss 0.82 Classification-F1 0.30858279574643577 on epoch=24
06/08/2022 10:33:19 - INFO - __main__ - Step 210 Global step 210 Train loss 0.81 on epoch=26
06/08/2022 10:33:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.68 on epoch=27
06/08/2022 10:33:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.66 on epoch=28
06/08/2022 10:33:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.72 on epoch=29
06/08/2022 10:33:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.63 on epoch=31
06/08/2022 10:33:32 - INFO - __main__ - Global step 250 Train loss 0.70 Classification-F1 0.2754852721596308 on epoch=31
06/08/2022 10:33:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.69 on epoch=32
06/08/2022 10:33:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.77 on epoch=33
06/08/2022 10:33:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.65 on epoch=34
06/08/2022 10:33:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.66 on epoch=36
06/08/2022 10:33:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.60 on epoch=37
06/08/2022 10:33:47 - INFO - __main__ - Global step 300 Train loss 0.68 Classification-F1 0.4960898398398399 on epoch=37
06/08/2022 10:33:47 - INFO - __main__ - Saving model with best Classification-F1: 0.40152853260869564 -> 0.4960898398398399 on epoch=37, global_step=300
06/08/2022 10:33:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.62 on epoch=38
06/08/2022 10:33:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.65 on epoch=39
06/08/2022 10:33:55 - INFO - __main__ - Step 330 Global step 330 Train loss 0.66 on epoch=41
06/08/2022 10:33:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=42
06/08/2022 10:34:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.61 on epoch=43
06/08/2022 10:34:03 - INFO - __main__ - Global step 350 Train loss 0.62 Classification-F1 0.7613271578587893 on epoch=43
06/08/2022 10:34:03 - INFO - __main__ - Saving model with best Classification-F1: 0.4960898398398399 -> 0.7613271578587893 on epoch=43, global_step=350
06/08/2022 10:34:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=44
06/08/2022 10:34:08 - INFO - __main__ - Step 370 Global step 370 Train loss 0.59 on epoch=46
06/08/2022 10:34:11 - INFO - __main__ - Step 380 Global step 380 Train loss 0.56 on epoch=47
06/08/2022 10:34:14 - INFO - __main__ - Step 390 Global step 390 Train loss 0.60 on epoch=48
06/08/2022 10:34:16 - INFO - __main__ - Step 400 Global step 400 Train loss 0.65 on epoch=49
06/08/2022 10:34:18 - INFO - __main__ - Global step 400 Train loss 0.59 Classification-F1 0.6338889115487871 on epoch=49
06/08/2022 10:34:21 - INFO - __main__ - Step 410 Global step 410 Train loss 0.61 on epoch=51
06/08/2022 10:34:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.55 on epoch=52
06/08/2022 10:34:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.51 on epoch=53
06/08/2022 10:34:29 - INFO - __main__ - Step 440 Global step 440 Train loss 0.56 on epoch=54
06/08/2022 10:34:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.53 on epoch=56
06/08/2022 10:34:34 - INFO - __main__ - Global step 450 Train loss 0.55 Classification-F1 0.7247164294039294 on epoch=56
06/08/2022 10:34:37 - INFO - __main__ - Step 460 Global step 460 Train loss 0.49 on epoch=57
06/08/2022 10:34:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.52 on epoch=58
06/08/2022 10:34:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.56 on epoch=59
06/08/2022 10:34:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.48 on epoch=61
06/08/2022 10:34:48 - INFO - __main__ - Step 500 Global step 500 Train loss 0.45 on epoch=62
06/08/2022 10:34:50 - INFO - __main__ - Global step 500 Train loss 0.50 Classification-F1 0.7067666995183222 on epoch=62
06/08/2022 10:34:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.46 on epoch=63
06/08/2022 10:34:55 - INFO - __main__ - Step 520 Global step 520 Train loss 0.57 on epoch=64
06/08/2022 10:34:57 - INFO - __main__ - Step 530 Global step 530 Train loss 0.52 on epoch=66
06/08/2022 10:35:00 - INFO - __main__ - Step 540 Global step 540 Train loss 0.42 on epoch=67
06/08/2022 10:35:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.46 on epoch=68
06/08/2022 10:35:05 - INFO - __main__ - Global step 550 Train loss 0.48 Classification-F1 0.7557708260044386 on epoch=68
06/08/2022 10:35:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=69
06/08/2022 10:35:10 - INFO - __main__ - Step 570 Global step 570 Train loss 0.41 on epoch=71
06/08/2022 10:35:13 - INFO - __main__ - Step 580 Global step 580 Train loss 0.52 on epoch=72
06/08/2022 10:35:15 - INFO - __main__ - Step 590 Global step 590 Train loss 0.39 on epoch=73
06/08/2022 10:35:18 - INFO - __main__ - Step 600 Global step 600 Train loss 0.35 on epoch=74
06/08/2022 10:35:20 - INFO - __main__ - Global step 600 Train loss 0.41 Classification-F1 0.7814833911608104 on epoch=74
06/08/2022 10:35:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7613271578587893 -> 0.7814833911608104 on epoch=74, global_step=600
06/08/2022 10:35:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.41 on epoch=76
06/08/2022 10:35:25 - INFO - __main__ - Step 620 Global step 620 Train loss 0.40 on epoch=77
06/08/2022 10:35:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.40 on epoch=78
06/08/2022 10:35:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.46 on epoch=79
06/08/2022 10:35:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.34 on epoch=81
06/08/2022 10:35:35 - INFO - __main__ - Global step 650 Train loss 0.40 Classification-F1 0.7373641304347827 on epoch=81
06/08/2022 10:35:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.42 on epoch=82
06/08/2022 10:35:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.40 on epoch=83
06/08/2022 10:35:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.38 on epoch=84
06/08/2022 10:35:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.30 on epoch=86
06/08/2022 10:35:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.35 on epoch=87
06/08/2022 10:35:51 - INFO - __main__ - Global step 700 Train loss 0.37 Classification-F1 0.7111361907378253 on epoch=87
06/08/2022 10:35:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.36 on epoch=88
06/08/2022 10:35:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.37 on epoch=89
06/08/2022 10:35:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.32 on epoch=91
06/08/2022 10:36:01 - INFO - __main__ - Step 740 Global step 740 Train loss 0.34 on epoch=92
06/08/2022 10:36:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.30 on epoch=93
06/08/2022 10:36:06 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.7791156397499681 on epoch=93
06/08/2022 10:36:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.38 on epoch=94
06/08/2022 10:36:11 - INFO - __main__ - Step 770 Global step 770 Train loss 0.39 on epoch=96
06/08/2022 10:36:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.28 on epoch=97
06/08/2022 10:36:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.29 on epoch=98
06/08/2022 10:36:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.36 on epoch=99
06/08/2022 10:36:21 - INFO - __main__ - Global step 800 Train loss 0.34 Classification-F1 0.7507666780445253 on epoch=99
06/08/2022 10:36:23 - INFO - __main__ - Step 810 Global step 810 Train loss 0.36 on epoch=101
06/08/2022 10:36:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.34 on epoch=102
06/08/2022 10:36:29 - INFO - __main__ - Step 830 Global step 830 Train loss 0.35 on epoch=103
06/08/2022 10:36:31 - INFO - __main__ - Step 840 Global step 840 Train loss 0.40 on epoch=104
06/08/2022 10:36:34 - INFO - __main__ - Step 850 Global step 850 Train loss 0.28 on epoch=106
06/08/2022 10:36:36 - INFO - __main__ - Global step 850 Train loss 0.34 Classification-F1 0.760605625717566 on epoch=106
06/08/2022 10:36:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=107
06/08/2022 10:36:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.33 on epoch=108
06/08/2022 10:36:44 - INFO - __main__ - Step 880 Global step 880 Train loss 0.35 on epoch=109
06/08/2022 10:36:46 - INFO - __main__ - Step 890 Global step 890 Train loss 0.28 on epoch=111
06/08/2022 10:36:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.28 on epoch=112
06/08/2022 10:36:50 - INFO - __main__ - Global step 900 Train loss 0.29 Classification-F1 0.7184084533457308 on epoch=112
06/08/2022 10:36:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.29 on epoch=113
06/08/2022 10:36:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.34 on epoch=114
06/08/2022 10:36:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.29 on epoch=116
06/08/2022 10:37:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=117
06/08/2022 10:37:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.32 on epoch=118
06/08/2022 10:37:06 - INFO - __main__ - Global step 950 Train loss 0.29 Classification-F1 0.7806336932268995 on epoch=118
06/08/2022 10:37:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.32 on epoch=119
06/08/2022 10:37:11 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=121
06/08/2022 10:37:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.24 on epoch=122
06/08/2022 10:37:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.26 on epoch=123
06/08/2022 10:37:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.32 on epoch=124
06/08/2022 10:37:21 - INFO - __main__ - Global step 1000 Train loss 0.27 Classification-F1 0.7393939393939395 on epoch=124
06/08/2022 10:37:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.30 on epoch=126
06/08/2022 10:37:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.24 on epoch=127
06/08/2022 10:37:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=128
06/08/2022 10:37:32 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.26 on epoch=129
06/08/2022 10:37:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.27 on epoch=131
06/08/2022 10:37:36 - INFO - __main__ - Global step 1050 Train loss 0.25 Classification-F1 0.7116950735096299 on epoch=131
06/08/2022 10:37:39 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=132
06/08/2022 10:37:41 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.22 on epoch=133
06/08/2022 10:37:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.26 on epoch=134
06/08/2022 10:37:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.21 on epoch=136
06/08/2022 10:37:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.23 on epoch=137
06/08/2022 10:37:51 - INFO - __main__ - Global step 1100 Train loss 0.21 Classification-F1 0.7728218538455264 on epoch=137
06/08/2022 10:37:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=138
06/08/2022 10:37:56 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=139
06/08/2022 10:37:59 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.16 on epoch=141
06/08/2022 10:38:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.23 on epoch=142
06/08/2022 10:38:04 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.20 on epoch=143
06/08/2022 10:38:06 - INFO - __main__ - Global step 1150 Train loss 0.20 Classification-F1 0.7876976070524457 on epoch=143
06/08/2022 10:38:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7814833911608104 -> 0.7876976070524457 on epoch=143, global_step=1150
06/08/2022 10:38:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.33 on epoch=144
06/08/2022 10:38:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.19 on epoch=146
06/08/2022 10:38:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=147
06/08/2022 10:38:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.18 on epoch=148
06/08/2022 10:38:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.23 on epoch=149
06/08/2022 10:38:21 - INFO - __main__ - Global step 1200 Train loss 0.21 Classification-F1 0.792987294395745 on epoch=149
06/08/2022 10:38:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7876976070524457 -> 0.792987294395745 on epoch=149, global_step=1200
06/08/2022 10:38:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=151
06/08/2022 10:38:27 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=152
06/08/2022 10:38:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=153
06/08/2022 10:38:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=154
06/08/2022 10:38:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=156
06/08/2022 10:38:36 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.7886462665874431 on epoch=156
06/08/2022 10:38:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=157
06/08/2022 10:38:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=158
06/08/2022 10:38:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=159
06/08/2022 10:38:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=161
06/08/2022 10:38:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.16 on epoch=162
06/08/2022 10:38:51 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.7495023441176949 on epoch=162
06/08/2022 10:38:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=163
06/08/2022 10:38:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.21 on epoch=164
06/08/2022 10:38:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=166
06/08/2022 10:39:02 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.20 on epoch=167
06/08/2022 10:39:04 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=168
06/08/2022 10:39:06 - INFO - __main__ - Global step 1350 Train loss 0.16 Classification-F1 0.7299251810903545 on epoch=168
06/08/2022 10:39:09 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.17 on epoch=169
06/08/2022 10:39:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.17 on epoch=171
06/08/2022 10:39:14 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=172
06/08/2022 10:39:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=173
06/08/2022 10:39:20 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=174
06/08/2022 10:39:21 - INFO - __main__ - Global step 1400 Train loss 0.15 Classification-F1 0.7758515116724072 on epoch=174
06/08/2022 10:39:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=176
06/08/2022 10:39:27 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=177
06/08/2022 10:39:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=178
06/08/2022 10:39:32 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=179
06/08/2022 10:39:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=181
06/08/2022 10:39:36 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.7795051849765042 on epoch=181
06/08/2022 10:39:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=182
06/08/2022 10:39:42 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.16 on epoch=183
06/08/2022 10:39:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=184
06/08/2022 10:39:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=186
06/08/2022 10:39:50 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=187
06/08/2022 10:39:52 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.7445369340653316 on epoch=187
06/08/2022 10:39:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.16 on epoch=188
06/08/2022 10:39:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.20 on epoch=189
06/08/2022 10:39:59 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=191
06/08/2022 10:40:02 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=192
06/08/2022 10:40:05 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=193
06/08/2022 10:40:07 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.7627720861388437 on epoch=193
06/08/2022 10:40:09 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=194
06/08/2022 10:40:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=196
06/08/2022 10:40:15 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=197
06/08/2022 10:40:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.13 on epoch=198
06/08/2022 10:40:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=199
06/08/2022 10:40:22 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.7414113019195264 on epoch=199
06/08/2022 10:40:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.14 on epoch=201
06/08/2022 10:40:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=202
06/08/2022 10:40:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=203
06/08/2022 10:40:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=204
06/08/2022 10:40:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.15 on epoch=206
06/08/2022 10:40:37 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.7639699191382638 on epoch=206
06/08/2022 10:40:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=207
06/08/2022 10:40:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=208
06/08/2022 10:40:45 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=209
06/08/2022 10:40:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=211
06/08/2022 10:40:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=212
06/08/2022 10:40:52 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.7571017539976762 on epoch=212
06/08/2022 10:40:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=213
06/08/2022 10:40:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=214
06/08/2022 10:41:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=216
06/08/2022 10:41:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=217
06/08/2022 10:41:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=218
06/08/2022 10:41:07 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.7289566889293666 on epoch=218
06/08/2022 10:41:10 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=219
06/08/2022 10:41:12 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=221
06/08/2022 10:41:15 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=222
06/08/2022 10:41:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=223
06/08/2022 10:41:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=224
06/08/2022 10:41:22 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.6145600669053228 on epoch=224
06/08/2022 10:41:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=226
06/08/2022 10:41:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=227
06/08/2022 10:41:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=228
06/08/2022 10:41:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.14 on epoch=229
06/08/2022 10:41:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=231
06/08/2022 10:41:37 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.7202074654904843 on epoch=231
06/08/2022 10:41:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=232
06/08/2022 10:41:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=233
06/08/2022 10:41:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=234
06/08/2022 10:41:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=236
06/08/2022 10:41:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=237
06/08/2022 10:41:52 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.7517857142857143 on epoch=237
06/08/2022 10:41:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=238
06/08/2022 10:41:57 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=239
06/08/2022 10:42:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=241
06/08/2022 10:42:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=242
06/08/2022 10:42:05 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=243
06/08/2022 10:42:07 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.72526525198939 on epoch=243
06/08/2022 10:42:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=244
06/08/2022 10:42:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=246
06/08/2022 10:42:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=247
06/08/2022 10:42:18 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=248
06/08/2022 10:42:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=249
06/08/2022 10:42:23 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7733931389519377 on epoch=249
06/08/2022 10:42:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=251
06/08/2022 10:42:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=252
06/08/2022 10:42:30 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.16 on epoch=253
06/08/2022 10:42:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=254
06/08/2022 10:42:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=256
06/08/2022 10:42:38 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.7387895550840717 on epoch=256
06/08/2022 10:42:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=257
06/08/2022 10:42:43 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=258
06/08/2022 10:42:46 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=259
06/08/2022 10:42:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=261
06/08/2022 10:42:51 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=262
06/08/2022 10:42:53 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7410709096192967 on epoch=262
06/08/2022 10:42:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=263
06/08/2022 10:42:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.10 on epoch=264
06/08/2022 10:43:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=266
06/08/2022 10:43:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=267
06/08/2022 10:43:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=268
06/08/2022 10:43:09 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7083654257595207 on epoch=268
06/08/2022 10:43:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=269
06/08/2022 10:43:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=271
06/08/2022 10:43:17 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=272
06/08/2022 10:43:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=273
06/08/2022 10:43:22 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=274
06/08/2022 10:43:24 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7740345675829547 on epoch=274
06/08/2022 10:43:27 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=276
06/08/2022 10:43:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.11 on epoch=277
06/08/2022 10:43:32 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=278
06/08/2022 10:43:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=279
06/08/2022 10:43:37 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=281
06/08/2022 10:43:39 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.7422498949138294 on epoch=281
06/08/2022 10:43:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=282
06/08/2022 10:43:44 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
06/08/2022 10:43:47 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=284
06/08/2022 10:43:50 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=286
06/08/2022 10:43:52 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=287
06/08/2022 10:43:54 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7214187187432051 on epoch=287
06/08/2022 10:43:57 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=288
06/08/2022 10:44:00 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=289
06/08/2022 10:44:02 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=291
06/08/2022 10:44:05 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=292
06/08/2022 10:44:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=293
06/08/2022 10:44:09 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7648453165419173 on epoch=293
06/08/2022 10:44:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=294
06/08/2022 10:44:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=296
06/08/2022 10:44:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=297
06/08/2022 10:44:20 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=298
06/08/2022 10:44:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=299
06/08/2022 10:44:24 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7718630462937863 on epoch=299
06/08/2022 10:44:27 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=301
06/08/2022 10:44:30 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
06/08/2022 10:44:32 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=303
06/08/2022 10:44:35 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=304
06/08/2022 10:44:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=306
06/08/2022 10:44:40 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7505570659895138 on epoch=306
06/08/2022 10:44:42 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=307
06/08/2022 10:44:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=308
06/08/2022 10:44:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=309
06/08/2022 10:44:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=311
06/08/2022 10:44:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=312
06/08/2022 10:44:55 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7376939231014502 on epoch=312
06/08/2022 10:44:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=313
06/08/2022 10:45:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=314
06/08/2022 10:45:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=316
06/08/2022 10:45:05 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=317
06/08/2022 10:45:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=318
06/08/2022 10:45:10 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7337772996103746 on epoch=318
06/08/2022 10:45:13 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=319
06/08/2022 10:45:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=321
06/08/2022 10:45:18 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
06/08/2022 10:45:20 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=323
06/08/2022 10:45:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=324
06/08/2022 10:45:25 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7148776585733108 on epoch=324
06/08/2022 10:45:28 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=326
06/08/2022 10:45:31 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=327
06/08/2022 10:45:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=328
06/08/2022 10:45:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=329
06/08/2022 10:45:39 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.16 on epoch=331
06/08/2022 10:45:41 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.7497653823522841 on epoch=331
06/08/2022 10:45:44 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=332
06/08/2022 10:45:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=333
06/08/2022 10:45:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=334
06/08/2022 10:45:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=336
06/08/2022 10:45:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=337
06/08/2022 10:45:57 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7962363662456946 on epoch=337
06/08/2022 10:45:57 - INFO - __main__ - Saving model with best Classification-F1: 0.792987294395745 -> 0.7962363662456946 on epoch=337, global_step=2700
06/08/2022 10:46:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/08/2022 10:46:02 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=339
06/08/2022 10:46:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=341
06/08/2022 10:46:08 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=342
06/08/2022 10:46:10 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=343
06/08/2022 10:46:13 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7872487491373361 on epoch=343
06/08/2022 10:46:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
06/08/2022 10:46:18 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=346
06/08/2022 10:46:21 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=347
06/08/2022 10:46:24 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=348
06/08/2022 10:46:26 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
06/08/2022 10:46:29 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7706737879854673 on epoch=349
06/08/2022 10:46:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
06/08/2022 10:46:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
06/08/2022 10:46:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
06/08/2022 10:46:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/08/2022 10:46:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
06/08/2022 10:46:44 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7405357983955888 on epoch=356
06/08/2022 10:46:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=357
06/08/2022 10:46:50 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=358
06/08/2022 10:46:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=359
06/08/2022 10:46:55 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
06/08/2022 10:46:58 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.11 on epoch=362
06/08/2022 10:47:00 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.770116327755807 on epoch=362
06/08/2022 10:47:03 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=363
06/08/2022 10:47:05 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.07 on epoch=364
06/08/2022 10:47:08 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=366
06/08/2022 10:47:11 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=367
06/08/2022 10:47:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.09 on epoch=368
06/08/2022 10:47:15 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.8032216748439065 on epoch=368
06/08/2022 10:47:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7962363662456946 -> 0.8032216748439065 on epoch=368, global_step=2950
06/08/2022 10:47:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=369
06/08/2022 10:47:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=371
06/08/2022 10:47:23 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=372
06/08/2022 10:47:26 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=373
06/08/2022 10:47:29 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=374
06/08/2022 10:47:30 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 10:47:30 - INFO - __main__ - Printing 3 examples
06/08/2022 10:47:30 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 10:47:30 - INFO - __main__ - ['others']
06/08/2022 10:47:30 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 10:47:30 - INFO - __main__ - ['others']
06/08/2022 10:47:30 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 10:47:30 - INFO - __main__ - ['others']
06/08/2022 10:47:30 - INFO - __main__ - Tokenizing Input ...
06/08/2022 10:47:30 - INFO - __main__ - Tokenizing Output ...
06/08/2022 10:47:30 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 10:47:30 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 10:47:30 - INFO - __main__ - Printing 3 examples
06/08/2022 10:47:30 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/08/2022 10:47:30 - INFO - __main__ - ['others']
06/08/2022 10:47:30 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/08/2022 10:47:30 - INFO - __main__ - ['others']
06/08/2022 10:47:30 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/08/2022 10:47:30 - INFO - __main__ - ['others']
06/08/2022 10:47:30 - INFO - __main__ - Tokenizing Input ...
06/08/2022 10:47:30 - INFO - __main__ - Tokenizing Output ...
06/08/2022 10:47:30 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 10:47:30 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7492063492063492 on epoch=374
06/08/2022 10:47:31 - INFO - __main__ - save last model!
06/08/2022 10:47:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 10:47:31 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 10:47:31 - INFO - __main__ - Printing 3 examples
06/08/2022 10:47:31 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 10:47:31 - INFO - __main__ - ['others']
06/08/2022 10:47:31 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 10:47:31 - INFO - __main__ - ['others']
06/08/2022 10:47:31 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 10:47:31 - INFO - __main__ - ['others']
06/08/2022 10:47:31 - INFO - __main__ - Tokenizing Input ...
06/08/2022 10:47:33 - INFO - __main__ - Tokenizing Output ...
06/08/2022 10:47:38 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 10:47:46 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 10:47:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 10:47:46 - INFO - __main__ - Starting training!
06/08/2022 10:48:54 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_100_0.4_8_predictions.txt
06/08/2022 10:48:54 - INFO - __main__ - Classification-F1 on test data: 0.4035
06/08/2022 10:48:55 - INFO - __main__ - prefix=emo_32_100, lr=0.4, bsz=8, dev_performance=0.8032216748439065, test_performance=0.40347225502925993
06/08/2022 10:48:55 - INFO - __main__ - Running ... prefix=emo_32_100, lr=0.3, bsz=8 ...
06/08/2022 10:48:56 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 10:48:56 - INFO - __main__ - Printing 3 examples
06/08/2022 10:48:56 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 10:48:56 - INFO - __main__ - ['others']
06/08/2022 10:48:56 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 10:48:56 - INFO - __main__ - ['others']
06/08/2022 10:48:56 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 10:48:56 - INFO - __main__ - ['others']
06/08/2022 10:48:56 - INFO - __main__ - Tokenizing Input ...
06/08/2022 10:48:56 - INFO - __main__ - Tokenizing Output ...
06/08/2022 10:48:56 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 10:48:56 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 10:48:56 - INFO - __main__ - Printing 3 examples
06/08/2022 10:48:56 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/08/2022 10:48:56 - INFO - __main__ - ['others']
06/08/2022 10:48:56 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/08/2022 10:48:56 - INFO - __main__ - ['others']
06/08/2022 10:48:56 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/08/2022 10:48:56 - INFO - __main__ - ['others']
06/08/2022 10:48:56 - INFO - __main__ - Tokenizing Input ...
06/08/2022 10:48:56 - INFO - __main__ - Tokenizing Output ...
06/08/2022 10:48:56 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 10:49:14 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 10:49:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 10:49:15 - INFO - __main__ - Starting training!
06/08/2022 10:49:18 - INFO - __main__ - Step 10 Global step 10 Train loss 2.94 on epoch=1
06/08/2022 10:49:21 - INFO - __main__ - Step 20 Global step 20 Train loss 1.55 on epoch=2
06/08/2022 10:49:23 - INFO - __main__ - Step 30 Global step 30 Train loss 1.19 on epoch=3
06/08/2022 10:49:26 - INFO - __main__ - Step 40 Global step 40 Train loss 1.08 on epoch=4
06/08/2022 10:49:29 - INFO - __main__ - Step 50 Global step 50 Train loss 0.98 on epoch=6
06/08/2022 10:49:31 - INFO - __main__ - Global step 50 Train loss 1.55 Classification-F1 0.1 on epoch=6
06/08/2022 10:49:31 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=6, global_step=50
06/08/2022 10:49:33 - INFO - __main__ - Step 60 Global step 60 Train loss 0.90 on epoch=7
06/08/2022 10:49:36 - INFO - __main__ - Step 70 Global step 70 Train loss 0.90 on epoch=8
06/08/2022 10:49:39 - INFO - __main__ - Step 80 Global step 80 Train loss 0.89 on epoch=9
06/08/2022 10:49:41 - INFO - __main__ - Step 90 Global step 90 Train loss 1.33 on epoch=11
06/08/2022 10:49:44 - INFO - __main__ - Step 100 Global step 100 Train loss 1.95 on epoch=12
06/08/2022 10:49:46 - INFO - __main__ - Global step 100 Train loss 1.19 Classification-F1 0.13067758749069247 on epoch=12
06/08/2022 10:49:46 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.13067758749069247 on epoch=12, global_step=100
06/08/2022 10:49:49 - INFO - __main__ - Step 110 Global step 110 Train loss 1.40 on epoch=13
06/08/2022 10:49:51 - INFO - __main__ - Step 120 Global step 120 Train loss 1.17 on epoch=14
06/08/2022 10:49:54 - INFO - __main__ - Step 130 Global step 130 Train loss 0.98 on epoch=16
06/08/2022 10:49:56 - INFO - __main__ - Step 140 Global step 140 Train loss 0.92 on epoch=17
06/08/2022 10:49:59 - INFO - __main__ - Step 150 Global step 150 Train loss 0.90 on epoch=18
06/08/2022 10:50:01 - INFO - __main__ - Global step 150 Train loss 1.07 Classification-F1 0.38606517875967594 on epoch=18
06/08/2022 10:50:01 - INFO - __main__ - Saving model with best Classification-F1: 0.13067758749069247 -> 0.38606517875967594 on epoch=18, global_step=150
06/08/2022 10:50:03 - INFO - __main__ - Step 160 Global step 160 Train loss 0.95 on epoch=19
06/08/2022 10:50:06 - INFO - __main__ - Step 170 Global step 170 Train loss 0.84 on epoch=21
06/08/2022 10:50:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.80 on epoch=22
06/08/2022 10:50:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.94 on epoch=23
06/08/2022 10:50:14 - INFO - __main__ - Step 200 Global step 200 Train loss 0.88 on epoch=24
06/08/2022 10:50:16 - INFO - __main__ - Global step 200 Train loss 0.88 Classification-F1 0.35984848484848486 on epoch=24
06/08/2022 10:50:18 - INFO - __main__ - Step 210 Global step 210 Train loss 1.10 on epoch=26
06/08/2022 10:50:21 - INFO - __main__ - Step 220 Global step 220 Train loss 0.84 on epoch=27
06/08/2022 10:50:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.89 on epoch=28
06/08/2022 10:50:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.82 on epoch=29
06/08/2022 10:50:29 - INFO - __main__ - Step 250 Global step 250 Train loss 0.88 on epoch=31
06/08/2022 10:50:31 - INFO - __main__ - Global step 250 Train loss 0.91 Classification-F1 0.20298786181139122 on epoch=31
06/08/2022 10:50:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.91 on epoch=32
06/08/2022 10:50:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.81 on epoch=33
06/08/2022 10:50:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.83 on epoch=34
06/08/2022 10:50:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.79 on epoch=36
06/08/2022 10:50:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.81 on epoch=37
06/08/2022 10:50:46 - INFO - __main__ - Global step 300 Train loss 0.83 Classification-F1 0.37532558605489885 on epoch=37
06/08/2022 10:50:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.93 on epoch=38
06/08/2022 10:50:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.79 on epoch=39
06/08/2022 10:50:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.83 on epoch=41
06/08/2022 10:50:57 - INFO - __main__ - Step 340 Global step 340 Train loss 0.81 on epoch=42
06/08/2022 10:50:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.83 on epoch=43
06/08/2022 10:51:01 - INFO - __main__ - Global step 350 Train loss 0.84 Classification-F1 0.37665474621996364 on epoch=43
06/08/2022 10:51:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.82 on epoch=44
06/08/2022 10:51:06 - INFO - __main__ - Step 370 Global step 370 Train loss 0.82 on epoch=46
06/08/2022 10:51:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.86 on epoch=47
06/08/2022 10:51:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.82 on epoch=48
06/08/2022 10:51:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.77 on epoch=49
06/08/2022 10:51:16 - INFO - __main__ - Global step 400 Train loss 0.82 Classification-F1 0.35483571807101216 on epoch=49
06/08/2022 10:51:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.78 on epoch=51
06/08/2022 10:51:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.76 on epoch=52
06/08/2022 10:51:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.75 on epoch=53
06/08/2022 10:51:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.72 on epoch=54
06/08/2022 10:51:29 - INFO - __main__ - Step 450 Global step 450 Train loss 0.75 on epoch=56
06/08/2022 10:51:31 - INFO - __main__ - Global step 450 Train loss 0.75 Classification-F1 0.3814777585675418 on epoch=56
06/08/2022 10:51:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.82 on epoch=57
06/08/2022 10:51:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.75 on epoch=58
06/08/2022 10:51:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.73 on epoch=59
06/08/2022 10:51:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.76 on epoch=61
06/08/2022 10:51:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.78 on epoch=62
06/08/2022 10:51:47 - INFO - __main__ - Global step 500 Train loss 0.77 Classification-F1 0.580224500523008 on epoch=62
06/08/2022 10:51:47 - INFO - __main__ - Saving model with best Classification-F1: 0.38606517875967594 -> 0.580224500523008 on epoch=62, global_step=500
06/08/2022 10:51:49 - INFO - __main__ - Step 510 Global step 510 Train loss 0.79 on epoch=63
06/08/2022 10:51:52 - INFO - __main__ - Step 520 Global step 520 Train loss 0.72 on epoch=64
06/08/2022 10:51:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.83 on epoch=66
06/08/2022 10:51:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.79 on epoch=67
06/08/2022 10:52:00 - INFO - __main__ - Step 550 Global step 550 Train loss 0.75 on epoch=68
06/08/2022 10:52:02 - INFO - __main__ - Global step 550 Train loss 0.78 Classification-F1 0.4823853333820111 on epoch=68
06/08/2022 10:52:05 - INFO - __main__ - Step 560 Global step 560 Train loss 0.72 on epoch=69
06/08/2022 10:52:07 - INFO - __main__ - Step 570 Global step 570 Train loss 0.74 on epoch=71
06/08/2022 10:52:10 - INFO - __main__ - Step 580 Global step 580 Train loss 0.65 on epoch=72
06/08/2022 10:52:13 - INFO - __main__ - Step 590 Global step 590 Train loss 0.69 on epoch=73
06/08/2022 10:52:15 - INFO - __main__ - Step 600 Global step 600 Train loss 0.72 on epoch=74
06/08/2022 10:52:17 - INFO - __main__ - Global step 600 Train loss 0.70 Classification-F1 0.36704545454545456 on epoch=74
06/08/2022 10:52:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.77 on epoch=76
06/08/2022 10:52:23 - INFO - __main__ - Step 620 Global step 620 Train loss 0.65 on epoch=77
06/08/2022 10:52:25 - INFO - __main__ - Step 630 Global step 630 Train loss 0.68 on epoch=78
06/08/2022 10:52:28 - INFO - __main__ - Step 640 Global step 640 Train loss 0.66 on epoch=79
06/08/2022 10:52:30 - INFO - __main__ - Step 650 Global step 650 Train loss 0.75 on epoch=81
06/08/2022 10:52:32 - INFO - __main__ - Global step 650 Train loss 0.70 Classification-F1 0.541316048671196 on epoch=81
06/08/2022 10:52:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.64 on epoch=82
06/08/2022 10:52:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.70 on epoch=83
06/08/2022 10:52:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.68 on epoch=84
06/08/2022 10:52:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.64 on epoch=86
06/08/2022 10:52:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.64 on epoch=87
06/08/2022 10:52:47 - INFO - __main__ - Global step 700 Train loss 0.66 Classification-F1 0.6245753926833031 on epoch=87
06/08/2022 10:52:47 - INFO - __main__ - Saving model with best Classification-F1: 0.580224500523008 -> 0.6245753926833031 on epoch=87, global_step=700
06/08/2022 10:52:50 - INFO - __main__ - Step 710 Global step 710 Train loss 0.66 on epoch=88
06/08/2022 10:52:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.60 on epoch=89
06/08/2022 10:52:55 - INFO - __main__ - Step 730 Global step 730 Train loss 0.64 on epoch=91
06/08/2022 10:52:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.58 on epoch=92
06/08/2022 10:53:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.68 on epoch=93
06/08/2022 10:53:02 - INFO - __main__ - Global step 750 Train loss 0.63 Classification-F1 0.6291375705211663 on epoch=93
06/08/2022 10:53:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6245753926833031 -> 0.6291375705211663 on epoch=93, global_step=750
06/08/2022 10:53:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.63 on epoch=94
06/08/2022 10:53:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.63 on epoch=96
06/08/2022 10:53:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.62 on epoch=97
06/08/2022 10:53:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.64 on epoch=98
06/08/2022 10:53:15 - INFO - __main__ - Step 800 Global step 800 Train loss 0.58 on epoch=99
06/08/2022 10:53:17 - INFO - __main__ - Global step 800 Train loss 0.62 Classification-F1 0.4142246415820621 on epoch=99
06/08/2022 10:53:20 - INFO - __main__ - Step 810 Global step 810 Train loss 0.58 on epoch=101
06/08/2022 10:53:23 - INFO - __main__ - Step 820 Global step 820 Train loss 0.58 on epoch=102
06/08/2022 10:53:25 - INFO - __main__ - Step 830 Global step 830 Train loss 0.56 on epoch=103
06/08/2022 10:53:28 - INFO - __main__ - Step 840 Global step 840 Train loss 0.56 on epoch=104
06/08/2022 10:53:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.51 on epoch=106
06/08/2022 10:53:32 - INFO - __main__ - Global step 850 Train loss 0.56 Classification-F1 0.6143661720007152 on epoch=106
06/08/2022 10:53:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.55 on epoch=107
06/08/2022 10:53:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.61 on epoch=108
06/08/2022 10:53:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.56 on epoch=109
06/08/2022 10:53:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.53 on epoch=111
06/08/2022 10:53:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.52 on epoch=112
06/08/2022 10:53:47 - INFO - __main__ - Global step 900 Train loss 0.56 Classification-F1 0.6163667859488293 on epoch=112
06/08/2022 10:53:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.54 on epoch=113
06/08/2022 10:53:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.54 on epoch=114
06/08/2022 10:53:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.47 on epoch=116
06/08/2022 10:53:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.51 on epoch=117
06/08/2022 10:54:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.49 on epoch=118
06/08/2022 10:54:02 - INFO - __main__ - Global step 950 Train loss 0.51 Classification-F1 0.6355563612902537 on epoch=118
06/08/2022 10:54:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6291375705211663 -> 0.6355563612902537 on epoch=118, global_step=950
06/08/2022 10:54:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.45 on epoch=119
06/08/2022 10:54:08 - INFO - __main__ - Step 970 Global step 970 Train loss 0.41 on epoch=121
06/08/2022 10:54:10 - INFO - __main__ - Step 980 Global step 980 Train loss 0.41 on epoch=122
06/08/2022 10:54:13 - INFO - __main__ - Step 990 Global step 990 Train loss 0.52 on epoch=123
06/08/2022 10:54:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.46 on epoch=124
06/08/2022 10:54:18 - INFO - __main__ - Global step 1000 Train loss 0.45 Classification-F1 0.5919593819327773 on epoch=124
06/08/2022 10:54:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.39 on epoch=126
06/08/2022 10:54:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.41 on epoch=127
06/08/2022 10:54:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.41 on epoch=128
06/08/2022 10:54:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.51 on epoch=129
06/08/2022 10:54:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.53 on epoch=131
06/08/2022 10:54:32 - INFO - __main__ - Global step 1050 Train loss 0.45 Classification-F1 0.6270433258559062 on epoch=131
06/08/2022 10:54:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.41 on epoch=132
06/08/2022 10:54:38 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.43 on epoch=133
06/08/2022 10:54:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.32 on epoch=134
06/08/2022 10:54:43 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.42 on epoch=136
06/08/2022 10:54:46 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.39 on epoch=137
06/08/2022 10:54:47 - INFO - __main__ - Global step 1100 Train loss 0.39 Classification-F1 0.6449150969898071 on epoch=137
06/08/2022 10:54:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6355563612902537 -> 0.6449150969898071 on epoch=137, global_step=1100
06/08/2022 10:54:50 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.39 on epoch=138
06/08/2022 10:54:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.46 on epoch=139
06/08/2022 10:54:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.51 on epoch=141
06/08/2022 10:54:58 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.33 on epoch=142
06/08/2022 10:55:01 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.45 on epoch=143
06/08/2022 10:55:02 - INFO - __main__ - Global step 1150 Train loss 0.43 Classification-F1 0.7236871296170699 on epoch=143
06/08/2022 10:55:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6449150969898071 -> 0.7236871296170699 on epoch=143, global_step=1150
06/08/2022 10:55:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.36 on epoch=144
06/08/2022 10:55:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.46 on epoch=146
06/08/2022 10:55:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.40 on epoch=147
06/08/2022 10:55:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.36 on epoch=148
06/08/2022 10:55:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.40 on epoch=149
06/08/2022 10:55:18 - INFO - __main__ - Global step 1200 Train loss 0.40 Classification-F1 0.6845467783036039 on epoch=149
06/08/2022 10:55:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.45 on epoch=151
06/08/2022 10:55:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.28 on epoch=152
06/08/2022 10:55:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.45 on epoch=153
06/08/2022 10:55:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.37 on epoch=154
06/08/2022 10:55:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.34 on epoch=156
06/08/2022 10:55:33 - INFO - __main__ - Global step 1250 Train loss 0.38 Classification-F1 0.7636523520113982 on epoch=156
06/08/2022 10:55:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7236871296170699 -> 0.7636523520113982 on epoch=156, global_step=1250
06/08/2022 10:55:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.30 on epoch=157
06/08/2022 10:55:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.42 on epoch=158
06/08/2022 10:55:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.30 on epoch=159
06/08/2022 10:55:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.37 on epoch=161
06/08/2022 10:55:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.39 on epoch=162
06/08/2022 10:55:48 - INFO - __main__ - Global step 1300 Train loss 0.36 Classification-F1 0.7059093034128098 on epoch=162
06/08/2022 10:55:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.35 on epoch=163
06/08/2022 10:55:53 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.43 on epoch=164
06/08/2022 10:55:56 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.29 on epoch=166
06/08/2022 10:55:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.35 on epoch=167
06/08/2022 10:56:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.33 on epoch=168
06/08/2022 10:56:03 - INFO - __main__ - Global step 1350 Train loss 0.35 Classification-F1 0.7021008403361344 on epoch=168
06/08/2022 10:56:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.25 on epoch=169
06/08/2022 10:56:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.29 on epoch=171
06/08/2022 10:56:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.28 on epoch=172
06/08/2022 10:56:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.30 on epoch=173
06/08/2022 10:56:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.21 on epoch=174
06/08/2022 10:56:18 - INFO - __main__ - Global step 1400 Train loss 0.26 Classification-F1 0.7174609765234765 on epoch=174
06/08/2022 10:56:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.24 on epoch=176
06/08/2022 10:56:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.25 on epoch=177
06/08/2022 10:56:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.21 on epoch=178
06/08/2022 10:56:28 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.31 on epoch=179
06/08/2022 10:56:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.21 on epoch=181
06/08/2022 10:56:33 - INFO - __main__ - Global step 1450 Train loss 0.24 Classification-F1 0.6301724137931034 on epoch=181
06/08/2022 10:56:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.28 on epoch=182
06/08/2022 10:56:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.33 on epoch=183
06/08/2022 10:56:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.31 on epoch=184
06/08/2022 10:56:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.29 on epoch=186
06/08/2022 10:56:46 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.17 on epoch=187
06/08/2022 10:56:48 - INFO - __main__ - Global step 1500 Train loss 0.28 Classification-F1 0.689060254483393 on epoch=187
06/08/2022 10:56:50 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.20 on epoch=188
06/08/2022 10:56:53 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.22 on epoch=189
06/08/2022 10:56:55 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.31 on epoch=191
06/08/2022 10:56:58 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.17 on epoch=192
06/08/2022 10:57:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.23 on epoch=193
06/08/2022 10:57:02 - INFO - __main__ - Global step 1550 Train loss 0.22 Classification-F1 0.7500282677521484 on epoch=193
06/08/2022 10:57:05 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.15 on epoch=194
06/08/2022 10:57:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.17 on epoch=196
06/08/2022 10:57:10 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.17 on epoch=197
06/08/2022 10:57:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.20 on epoch=198
06/08/2022 10:57:15 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.29 on epoch=199
06/08/2022 10:57:17 - INFO - __main__ - Global step 1600 Train loss 0.20 Classification-F1 0.7356299983814585 on epoch=199
06/08/2022 10:57:20 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.19 on epoch=201
06/08/2022 10:57:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.22 on epoch=202
06/08/2022 10:57:25 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.23 on epoch=203
06/08/2022 10:57:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.23 on epoch=204
06/08/2022 10:57:30 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.23 on epoch=206
06/08/2022 10:57:32 - INFO - __main__ - Global step 1650 Train loss 0.22 Classification-F1 0.7823596597783242 on epoch=206
06/08/2022 10:57:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7636523520113982 -> 0.7823596597783242 on epoch=206, global_step=1650
06/08/2022 10:57:34 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.14 on epoch=207
06/08/2022 10:57:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=208
06/08/2022 10:57:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.17 on epoch=209
06/08/2022 10:57:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=211
06/08/2022 10:57:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=212
06/08/2022 10:57:47 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.7473192785886285 on epoch=212
06/08/2022 10:57:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.15 on epoch=213
06/08/2022 10:57:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.25 on epoch=214
06/08/2022 10:57:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=216
06/08/2022 10:57:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.21 on epoch=217
06/08/2022 10:58:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.17 on epoch=218
06/08/2022 10:58:02 - INFO - __main__ - Global step 1750 Train loss 0.18 Classification-F1 0.8183646524195529 on epoch=218
06/08/2022 10:58:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7823596597783242 -> 0.8183646524195529 on epoch=218, global_step=1750
06/08/2022 10:58:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.14 on epoch=219
06/08/2022 10:58:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.15 on epoch=221
06/08/2022 10:58:09 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=222
06/08/2022 10:58:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=223
06/08/2022 10:58:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.12 on epoch=224
06/08/2022 10:58:16 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.7456838314957619 on epoch=224
06/08/2022 10:58:19 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=226
06/08/2022 10:58:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=227
06/08/2022 10:58:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.23 on epoch=228
06/08/2022 10:58:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=229
06/08/2022 10:58:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.13 on epoch=231
06/08/2022 10:58:31 - INFO - __main__ - Global step 1850 Train loss 0.14 Classification-F1 0.7240879769927845 on epoch=231
06/08/2022 10:58:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.19 on epoch=232
06/08/2022 10:58:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=233
06/08/2022 10:58:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.14 on epoch=234
06/08/2022 10:58:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.10 on epoch=236
06/08/2022 10:58:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=237
06/08/2022 10:58:45 - INFO - __main__ - Global step 1900 Train loss 0.12 Classification-F1 0.7178030303030303 on epoch=237
06/08/2022 10:58:48 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.17 on epoch=238
06/08/2022 10:58:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.13 on epoch=239
06/08/2022 10:58:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=241
06/08/2022 10:58:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.11 on epoch=242
06/08/2022 10:58:58 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.09 on epoch=243
06/08/2022 10:59:00 - INFO - __main__ - Global step 1950 Train loss 0.12 Classification-F1 0.6817725752508362 on epoch=243
06/08/2022 10:59:03 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=244
06/08/2022 10:59:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.11 on epoch=246
06/08/2022 10:59:08 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=247
06/08/2022 10:59:11 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.16 on epoch=248
06/08/2022 10:59:13 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.11 on epoch=249
06/08/2022 10:59:15 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.6927051150150242 on epoch=249
06/08/2022 10:59:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.16 on epoch=251
06/08/2022 10:59:20 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=252
06/08/2022 10:59:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.11 on epoch=253
06/08/2022 10:59:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.14 on epoch=254
06/08/2022 10:59:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.14 on epoch=256
06/08/2022 10:59:30 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.7426885875979471 on epoch=256
06/08/2022 10:59:33 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=257
06/08/2022 10:59:35 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=258
06/08/2022 10:59:38 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.13 on epoch=259
06/08/2022 10:59:40 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=261
06/08/2022 10:59:43 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.15 on epoch=262
06/08/2022 10:59:45 - INFO - __main__ - Global step 2100 Train loss 0.09 Classification-F1 0.7394560404807085 on epoch=262
06/08/2022 10:59:47 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=263
06/08/2022 10:59:50 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=264
06/08/2022 10:59:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.14 on epoch=266
06/08/2022 10:59:55 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.12 on epoch=267
06/08/2022 10:59:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=268
06/08/2022 11:00:00 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.6823367941948056 on epoch=268
06/08/2022 11:00:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.14 on epoch=269
06/08/2022 11:00:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=271
06/08/2022 11:00:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=272
06/08/2022 11:00:10 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=273
06/08/2022 11:00:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=274
06/08/2022 11:00:15 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.7317552151238591 on epoch=274
06/08/2022 11:00:18 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=276
06/08/2022 11:00:20 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=277
06/08/2022 11:00:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=278
06/08/2022 11:00:26 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=279
06/08/2022 11:00:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.17 on epoch=281
06/08/2022 11:00:30 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.7073202614379085 on epoch=281
06/08/2022 11:00:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=282
06/08/2022 11:00:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=283
06/08/2022 11:00:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.10 on epoch=284
06/08/2022 11:00:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=286
06/08/2022 11:00:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=287
06/08/2022 11:00:45 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.7414964508184847 on epoch=287
06/08/2022 11:00:48 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=288
06/08/2022 11:00:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=289
06/08/2022 11:00:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.11 on epoch=291
06/08/2022 11:00:55 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.08 on epoch=292
06/08/2022 11:00:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.11 on epoch=293
06/08/2022 11:01:00 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.7054554292113873 on epoch=293
06/08/2022 11:01:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=294
06/08/2022 11:01:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=296
06/08/2022 11:01:08 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=297
06/08/2022 11:01:11 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=298
06/08/2022 11:01:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=299
06/08/2022 11:01:15 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.7702191312027378 on epoch=299
06/08/2022 11:01:18 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=301
06/08/2022 11:01:20 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
06/08/2022 11:01:23 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=303
06/08/2022 11:01:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=304
06/08/2022 11:01:28 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=306
06/08/2022 11:01:30 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.7604661429789307 on epoch=306
06/08/2022 11:01:33 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=307
06/08/2022 11:01:35 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=308
06/08/2022 11:01:38 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=309
06/08/2022 11:01:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=311
06/08/2022 11:01:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.10 on epoch=312
06/08/2022 11:01:45 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.7572418264332685 on epoch=312
06/08/2022 11:01:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=313
06/08/2022 11:01:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=314
06/08/2022 11:01:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=316
06/08/2022 11:01:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=317
06/08/2022 11:01:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=318
06/08/2022 11:02:00 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7337457837212565 on epoch=318
06/08/2022 11:02:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.11 on epoch=319
06/08/2022 11:02:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=321
06/08/2022 11:02:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=322
06/08/2022 11:02:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=323
06/08/2022 11:02:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.08 on epoch=324
06/08/2022 11:02:15 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.7379130897351236 on epoch=324
06/08/2022 11:02:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=326
06/08/2022 11:02:21 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.16 on epoch=327
06/08/2022 11:02:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=328
06/08/2022 11:02:26 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=329
06/08/2022 11:02:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=331
06/08/2022 11:02:31 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.7340340818601687 on epoch=331
06/08/2022 11:02:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=332
06/08/2022 11:02:36 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=333
06/08/2022 11:02:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=334
06/08/2022 11:02:41 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.11 on epoch=336
06/08/2022 11:02:44 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.10 on epoch=337
06/08/2022 11:02:46 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.7366091767775956 on epoch=337
06/08/2022 11:02:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.11 on epoch=338
06/08/2022 11:02:51 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=339
06/08/2022 11:02:54 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.11 on epoch=341
06/08/2022 11:02:56 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=342
06/08/2022 11:02:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.12 on epoch=343
06/08/2022 11:03:01 - INFO - __main__ - Global step 2750 Train loss 0.09 Classification-F1 0.7503083214289893 on epoch=343
06/08/2022 11:03:03 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=344
06/08/2022 11:03:06 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=346
06/08/2022 11:03:09 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=347
06/08/2022 11:03:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=348
06/08/2022 11:03:14 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.09 on epoch=349
06/08/2022 11:03:16 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.7430291026461802 on epoch=349
06/08/2022 11:03:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=351
06/08/2022 11:03:21 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=352
06/08/2022 11:03:23 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.12 on epoch=353
06/08/2022 11:03:26 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=354
06/08/2022 11:03:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=356
06/08/2022 11:03:31 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.7575146849325762 on epoch=356
06/08/2022 11:03:33 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=357
06/08/2022 11:03:36 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=358
06/08/2022 11:03:38 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.16 on epoch=359
06/08/2022 11:03:41 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=361
06/08/2022 11:03:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=362
06/08/2022 11:03:45 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7352279543727858 on epoch=362
06/08/2022 11:03:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=363
06/08/2022 11:03:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.08 on epoch=364
06/08/2022 11:03:53 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=366
06/08/2022 11:03:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.18 on epoch=367
06/08/2022 11:03:58 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.12 on epoch=368
06/08/2022 11:03:59 - INFO - __main__ - Global step 2950 Train loss 0.10 Classification-F1 0.740756015000974 on epoch=368
06/08/2022 11:04:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.12 on epoch=369
06/08/2022 11:04:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.10 on epoch=371
06/08/2022 11:04:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=372
06/08/2022 11:04:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=373
06/08/2022 11:04:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=374
06/08/2022 11:04:14 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:04:14 - INFO - __main__ - Printing 3 examples
06/08/2022 11:04:14 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 11:04:14 - INFO - __main__ - ['others']
06/08/2022 11:04:14 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 11:04:14 - INFO - __main__ - ['others']
06/08/2022 11:04:14 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 11:04:14 - INFO - __main__ - ['others']
06/08/2022 11:04:14 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:04:14 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:04:14 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 11:04:14 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:04:14 - INFO - __main__ - Printing 3 examples
06/08/2022 11:04:14 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/08/2022 11:04:14 - INFO - __main__ - ['others']
06/08/2022 11:04:14 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/08/2022 11:04:14 - INFO - __main__ - ['others']
06/08/2022 11:04:14 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/08/2022 11:04:14 - INFO - __main__ - ['others']
06/08/2022 11:04:14 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:04:14 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:04:14 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 11:04:14 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.7565082038998734 on epoch=374
06/08/2022 11:04:14 - INFO - __main__ - save last model!
06/08/2022 11:04:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 11:04:14 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 11:04:14 - INFO - __main__ - Printing 3 examples
06/08/2022 11:04:14 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 11:04:14 - INFO - __main__ - ['others']
06/08/2022 11:04:14 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 11:04:14 - INFO - __main__ - ['others']
06/08/2022 11:04:14 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 11:04:14 - INFO - __main__ - ['others']
06/08/2022 11:04:14 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:04:16 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:04:22 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 11:04:30 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 11:04:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 11:04:31 - INFO - __main__ - Starting training!
06/08/2022 11:05:35 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_100_0.3_8_predictions.txt
06/08/2022 11:05:35 - INFO - __main__ - Classification-F1 on test data: 0.4166
06/08/2022 11:05:35 - INFO - __main__ - prefix=emo_32_100, lr=0.3, bsz=8, dev_performance=0.8183646524195529, test_performance=0.41661261505902364
06/08/2022 11:05:35 - INFO - __main__ - Running ... prefix=emo_32_100, lr=0.2, bsz=8 ...
06/08/2022 11:05:36 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:05:36 - INFO - __main__ - Printing 3 examples
06/08/2022 11:05:36 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 11:05:36 - INFO - __main__ - ['others']
06/08/2022 11:05:36 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 11:05:36 - INFO - __main__ - ['others']
06/08/2022 11:05:36 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 11:05:36 - INFO - __main__ - ['others']
06/08/2022 11:05:36 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:05:36 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:05:36 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 11:05:36 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:05:36 - INFO - __main__ - Printing 3 examples
06/08/2022 11:05:36 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/08/2022 11:05:36 - INFO - __main__ - ['others']
06/08/2022 11:05:36 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/08/2022 11:05:36 - INFO - __main__ - ['others']
06/08/2022 11:05:36 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/08/2022 11:05:36 - INFO - __main__ - ['others']
06/08/2022 11:05:36 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:05:36 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:05:36 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 11:05:55 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 11:05:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 11:05:55 - INFO - __main__ - Starting training!
06/08/2022 11:05:58 - INFO - __main__ - Step 10 Global step 10 Train loss 3.08 on epoch=1
06/08/2022 11:06:01 - INFO - __main__ - Step 20 Global step 20 Train loss 1.88 on epoch=2
06/08/2022 11:06:03 - INFO - __main__ - Step 30 Global step 30 Train loss 1.41 on epoch=3
06/08/2022 11:06:06 - INFO - __main__ - Step 40 Global step 40 Train loss 1.09 on epoch=4
06/08/2022 11:06:08 - INFO - __main__ - Step 50 Global step 50 Train loss 1.15 on epoch=6
06/08/2022 11:06:10 - INFO - __main__ - Global step 50 Train loss 1.72 Classification-F1 0.1 on epoch=6
06/08/2022 11:06:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=6, global_step=50
06/08/2022 11:06:13 - INFO - __main__ - Step 60 Global step 60 Train loss 0.93 on epoch=7
06/08/2022 11:06:16 - INFO - __main__ - Step 70 Global step 70 Train loss 0.98 on epoch=8
06/08/2022 11:06:18 - INFO - __main__ - Step 80 Global step 80 Train loss 0.90 on epoch=9
06/08/2022 11:06:21 - INFO - __main__ - Step 90 Global step 90 Train loss 0.92 on epoch=11
06/08/2022 11:06:23 - INFO - __main__ - Step 100 Global step 100 Train loss 0.89 on epoch=12
06/08/2022 11:06:25 - INFO - __main__ - Global step 100 Train loss 0.92 Classification-F1 0.3960914988004771 on epoch=12
06/08/2022 11:06:25 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.3960914988004771 on epoch=12, global_step=100
06/08/2022 11:06:28 - INFO - __main__ - Step 110 Global step 110 Train loss 0.94 on epoch=13
06/08/2022 11:06:30 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=14
06/08/2022 11:06:33 - INFO - __main__ - Step 130 Global step 130 Train loss 0.86 on epoch=16
06/08/2022 11:06:35 - INFO - __main__ - Step 140 Global step 140 Train loss 0.87 on epoch=17
06/08/2022 11:06:38 - INFO - __main__ - Step 150 Global step 150 Train loss 0.83 on epoch=18
06/08/2022 11:06:40 - INFO - __main__ - Global step 150 Train loss 0.88 Classification-F1 0.2789855072463768 on epoch=18
06/08/2022 11:06:42 - INFO - __main__ - Step 160 Global step 160 Train loss 0.98 on epoch=19
06/08/2022 11:06:45 - INFO - __main__ - Step 170 Global step 170 Train loss 0.82 on epoch=21
06/08/2022 11:06:47 - INFO - __main__ - Step 180 Global step 180 Train loss 0.84 on epoch=22
06/08/2022 11:06:50 - INFO - __main__ - Step 190 Global step 190 Train loss 0.87 on epoch=23
06/08/2022 11:06:52 - INFO - __main__ - Step 200 Global step 200 Train loss 0.81 on epoch=24
06/08/2022 11:06:54 - INFO - __main__ - Global step 200 Train loss 0.86 Classification-F1 0.4069257195646525 on epoch=24
06/08/2022 11:06:54 - INFO - __main__ - Saving model with best Classification-F1: 0.3960914988004771 -> 0.4069257195646525 on epoch=24, global_step=200
06/08/2022 11:06:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.77 on epoch=26
06/08/2022 11:06:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.80 on epoch=27
06/08/2022 11:07:02 - INFO - __main__ - Step 230 Global step 230 Train loss 0.73 on epoch=28
06/08/2022 11:07:04 - INFO - __main__ - Step 240 Global step 240 Train loss 0.73 on epoch=29
06/08/2022 11:07:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.73 on epoch=31
06/08/2022 11:07:08 - INFO - __main__ - Global step 250 Train loss 0.75 Classification-F1 0.526756106982749 on epoch=31
06/08/2022 11:07:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4069257195646525 -> 0.526756106982749 on epoch=31, global_step=250
06/08/2022 11:07:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.74 on epoch=32
06/08/2022 11:07:14 - INFO - __main__ - Step 270 Global step 270 Train loss 0.73 on epoch=33
06/08/2022 11:07:16 - INFO - __main__ - Step 280 Global step 280 Train loss 0.69 on epoch=34
06/08/2022 11:07:19 - INFO - __main__ - Step 290 Global step 290 Train loss 0.71 on epoch=36
06/08/2022 11:07:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.65 on epoch=37
06/08/2022 11:07:23 - INFO - __main__ - Global step 300 Train loss 0.71 Classification-F1 0.4911192403486925 on epoch=37
06/08/2022 11:07:26 - INFO - __main__ - Step 310 Global step 310 Train loss 0.66 on epoch=38
06/08/2022 11:07:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.71 on epoch=39
06/08/2022 11:07:31 - INFO - __main__ - Step 330 Global step 330 Train loss 0.54 on epoch=41
06/08/2022 11:07:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.53 on epoch=42
06/08/2022 11:07:36 - INFO - __main__ - Step 350 Global step 350 Train loss 0.59 on epoch=43
06/08/2022 11:07:37 - INFO - __main__ - Global step 350 Train loss 0.61 Classification-F1 0.5408977182101711 on epoch=43
06/08/2022 11:07:37 - INFO - __main__ - Saving model with best Classification-F1: 0.526756106982749 -> 0.5408977182101711 on epoch=43, global_step=350
06/08/2022 11:07:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.58 on epoch=44
06/08/2022 11:07:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.60 on epoch=46
06/08/2022 11:07:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.61 on epoch=47
06/08/2022 11:07:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.55 on epoch=48
06/08/2022 11:07:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.62 on epoch=49
06/08/2022 11:07:52 - INFO - __main__ - Global step 400 Train loss 0.59 Classification-F1 0.45589570862294726 on epoch=49
06/08/2022 11:07:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.59 on epoch=51
06/08/2022 11:07:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.44 on epoch=52
06/08/2022 11:08:00 - INFO - __main__ - Step 430 Global step 430 Train loss 0.55 on epoch=53
06/08/2022 11:08:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.50 on epoch=54
06/08/2022 11:08:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.52 on epoch=56
06/08/2022 11:08:07 - INFO - __main__ - Global step 450 Train loss 0.52 Classification-F1 0.78145765508097 on epoch=56
06/08/2022 11:08:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5408977182101711 -> 0.78145765508097 on epoch=56, global_step=450
06/08/2022 11:08:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.54 on epoch=57
06/08/2022 11:08:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.61 on epoch=58
06/08/2022 11:08:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.52 on epoch=59
06/08/2022 11:08:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.50 on epoch=61
06/08/2022 11:08:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.47 on epoch=62
06/08/2022 11:08:21 - INFO - __main__ - Global step 500 Train loss 0.53 Classification-F1 0.5815122377622377 on epoch=62
06/08/2022 11:08:24 - INFO - __main__ - Step 510 Global step 510 Train loss 0.54 on epoch=63
06/08/2022 11:08:27 - INFO - __main__ - Step 520 Global step 520 Train loss 0.61 on epoch=64
06/08/2022 11:08:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.54 on epoch=66
06/08/2022 11:08:32 - INFO - __main__ - Step 540 Global step 540 Train loss 0.46 on epoch=67
06/08/2022 11:08:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.53 on epoch=68
06/08/2022 11:08:36 - INFO - __main__ - Global step 550 Train loss 0.54 Classification-F1 0.7635856066005745 on epoch=68
06/08/2022 11:08:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.48 on epoch=69
06/08/2022 11:08:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.45 on epoch=71
06/08/2022 11:08:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.39 on epoch=72
06/08/2022 11:08:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.41 on epoch=73
06/08/2022 11:08:50 - INFO - __main__ - Step 600 Global step 600 Train loss 0.48 on epoch=74
06/08/2022 11:08:51 - INFO - __main__ - Global step 600 Train loss 0.44 Classification-F1 0.6456417624521072 on epoch=74
06/08/2022 11:08:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.40 on epoch=76
06/08/2022 11:08:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.39 on epoch=77
06/08/2022 11:08:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.41 on epoch=78
06/08/2022 11:09:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.37 on epoch=79
06/08/2022 11:09:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.46 on epoch=81
06/08/2022 11:09:06 - INFO - __main__ - Global step 650 Train loss 0.40 Classification-F1 0.701274683356905 on epoch=81
06/08/2022 11:09:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.33 on epoch=82
06/08/2022 11:09:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.43 on epoch=83
06/08/2022 11:09:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.49 on epoch=84
06/08/2022 11:09:17 - INFO - __main__ - Step 690 Global step 690 Train loss 0.39 on epoch=86
06/08/2022 11:09:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.41 on epoch=87
06/08/2022 11:09:21 - INFO - __main__ - Global step 700 Train loss 0.41 Classification-F1 0.6155985163600775 on epoch=87
06/08/2022 11:09:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.35 on epoch=88
06/08/2022 11:09:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.42 on epoch=89
06/08/2022 11:09:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.46 on epoch=91
06/08/2022 11:09:32 - INFO - __main__ - Step 740 Global step 740 Train loss 0.32 on epoch=92
06/08/2022 11:09:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.34 on epoch=93
06/08/2022 11:09:36 - INFO - __main__ - Global step 750 Train loss 0.38 Classification-F1 0.7752235691573928 on epoch=93
06/08/2022 11:09:39 - INFO - __main__ - Step 760 Global step 760 Train loss 0.45 on epoch=94
06/08/2022 11:09:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.39 on epoch=96
06/08/2022 11:09:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.34 on epoch=97
06/08/2022 11:09:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.35 on epoch=98
06/08/2022 11:09:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.39 on epoch=99
06/08/2022 11:09:51 - INFO - __main__ - Global step 800 Train loss 0.39 Classification-F1 0.7250298110438451 on epoch=99
06/08/2022 11:09:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.36 on epoch=101
06/08/2022 11:09:57 - INFO - __main__ - Step 820 Global step 820 Train loss 0.28 on epoch=102
06/08/2022 11:09:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.40 on epoch=103
06/08/2022 11:10:02 - INFO - __main__ - Step 840 Global step 840 Train loss 0.41 on epoch=104
06/08/2022 11:10:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.26 on epoch=106
06/08/2022 11:10:06 - INFO - __main__ - Global step 850 Train loss 0.34 Classification-F1 0.7164164480021258 on epoch=106
06/08/2022 11:10:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=107
06/08/2022 11:10:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.32 on epoch=108
06/08/2022 11:10:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.35 on epoch=109
06/08/2022 11:10:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.28 on epoch=111
06/08/2022 11:10:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.27 on epoch=112
06/08/2022 11:10:22 - INFO - __main__ - Global step 900 Train loss 0.29 Classification-F1 0.7171611586245732 on epoch=112
06/08/2022 11:10:24 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=113
06/08/2022 11:10:27 - INFO - __main__ - Step 920 Global step 920 Train loss 0.33 on epoch=114
06/08/2022 11:10:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.37 on epoch=116
06/08/2022 11:10:32 - INFO - __main__ - Step 940 Global step 940 Train loss 0.28 on epoch=117
06/08/2022 11:10:35 - INFO - __main__ - Step 950 Global step 950 Train loss 0.27 on epoch=118
06/08/2022 11:10:37 - INFO - __main__ - Global step 950 Train loss 0.30 Classification-F1 0.7707158281675403 on epoch=118
06/08/2022 11:10:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.40 on epoch=119
06/08/2022 11:10:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.41 on epoch=121
06/08/2022 11:10:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.35 on epoch=122
06/08/2022 11:10:47 - INFO - __main__ - Step 990 Global step 990 Train loss 0.27 on epoch=123
06/08/2022 11:10:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.35 on epoch=124
06/08/2022 11:10:52 - INFO - __main__ - Global step 1000 Train loss 0.36 Classification-F1 0.727729310467516 on epoch=124
06/08/2022 11:10:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.26 on epoch=126
06/08/2022 11:10:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.20 on epoch=127
06/08/2022 11:11:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.29 on epoch=128
06/08/2022 11:11:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.24 on epoch=129
06/08/2022 11:11:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.28 on epoch=131
06/08/2022 11:11:07 - INFO - __main__ - Global step 1050 Train loss 0.25 Classification-F1 0.7779910214214353 on epoch=131
06/08/2022 11:11:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.22 on epoch=132
06/08/2022 11:11:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.24 on epoch=133
06/08/2022 11:11:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.22 on epoch=134
06/08/2022 11:11:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.21 on epoch=136
06/08/2022 11:11:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=137
06/08/2022 11:11:22 - INFO - __main__ - Global step 1100 Train loss 0.23 Classification-F1 0.7451619917373342 on epoch=137
06/08/2022 11:11:24 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.27 on epoch=138
06/08/2022 11:11:27 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.22 on epoch=139
06/08/2022 11:11:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.24 on epoch=141
06/08/2022 11:11:32 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.24 on epoch=142
06/08/2022 11:11:35 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.30 on epoch=143
06/08/2022 11:11:37 - INFO - __main__ - Global step 1150 Train loss 0.26 Classification-F1 0.795157967032967 on epoch=143
06/08/2022 11:11:37 - INFO - __main__ - Saving model with best Classification-F1: 0.78145765508097 -> 0.795157967032967 on epoch=143, global_step=1150
06/08/2022 11:11:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.25 on epoch=144
06/08/2022 11:11:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=146
06/08/2022 11:11:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=147
06/08/2022 11:11:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.18 on epoch=148
06/08/2022 11:11:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=149
06/08/2022 11:11:52 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.7556286264505803 on epoch=149
06/08/2022 11:11:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=151
06/08/2022 11:11:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=152
06/08/2022 11:12:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.19 on epoch=153
06/08/2022 11:12:02 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.21 on epoch=154
06/08/2022 11:12:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.28 on epoch=156
06/08/2022 11:12:07 - INFO - __main__ - Global step 1250 Train loss 0.19 Classification-F1 0.7399245354228503 on epoch=156
06/08/2022 11:12:10 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.18 on epoch=157
06/08/2022 11:12:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.20 on epoch=158
06/08/2022 11:12:15 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=159
06/08/2022 11:12:18 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.24 on epoch=161
06/08/2022 11:12:21 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.18 on epoch=162
06/08/2022 11:12:23 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.7896103896103897 on epoch=162
06/08/2022 11:12:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.23 on epoch=163
06/08/2022 11:12:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.19 on epoch=164
06/08/2022 11:12:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=166
06/08/2022 11:12:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=167
06/08/2022 11:12:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.17 on epoch=168
06/08/2022 11:12:38 - INFO - __main__ - Global step 1350 Train loss 0.18 Classification-F1 0.7755825823711631 on epoch=168
06/08/2022 11:12:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.32 on epoch=169
06/08/2022 11:12:43 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=171
06/08/2022 11:12:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.20 on epoch=172
06/08/2022 11:12:48 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.17 on epoch=173
06/08/2022 11:12:51 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.19 on epoch=174
06/08/2022 11:12:53 - INFO - __main__ - Global step 1400 Train loss 0.21 Classification-F1 0.8088640390511317 on epoch=174
06/08/2022 11:12:53 - INFO - __main__ - Saving model with best Classification-F1: 0.795157967032967 -> 0.8088640390511317 on epoch=174, global_step=1400
06/08/2022 11:12:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=176
06/08/2022 11:12:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=177
06/08/2022 11:13:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.15 on epoch=178
06/08/2022 11:13:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.25 on epoch=179
06/08/2022 11:13:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=181
06/08/2022 11:13:08 - INFO - __main__ - Global step 1450 Train loss 0.14 Classification-F1 0.801689431826418 on epoch=181
06/08/2022 11:13:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.15 on epoch=182
06/08/2022 11:13:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=183
06/08/2022 11:13:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=184
06/08/2022 11:13:19 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=186
06/08/2022 11:13:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=187
06/08/2022 11:13:23 - INFO - __main__ - Global step 1500 Train loss 0.13 Classification-F1 0.7060601959616737 on epoch=187
06/08/2022 11:13:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.15 on epoch=188
06/08/2022 11:13:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.19 on epoch=189
06/08/2022 11:13:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.16 on epoch=191
06/08/2022 11:13:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=192
06/08/2022 11:13:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=193
06/08/2022 11:13:38 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.7431164619017726 on epoch=193
06/08/2022 11:13:41 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=194
06/08/2022 11:13:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=196
06/08/2022 11:13:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.11 on epoch=197
06/08/2022 11:13:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.23 on epoch=198
06/08/2022 11:13:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.17 on epoch=199
06/08/2022 11:13:53 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.7667821067821068 on epoch=199
06/08/2022 11:13:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=201
06/08/2022 11:13:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=202
06/08/2022 11:14:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.18 on epoch=203
06/08/2022 11:14:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=204
06/08/2022 11:14:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.12 on epoch=206
06/08/2022 11:14:08 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.8034340659340659 on epoch=206
06/08/2022 11:14:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.15 on epoch=207
06/08/2022 11:14:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=208
06/08/2022 11:14:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=209
06/08/2022 11:14:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.17 on epoch=211
06/08/2022 11:14:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=212
06/08/2022 11:14:23 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.8010649132942596 on epoch=212
06/08/2022 11:14:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.17 on epoch=213
06/08/2022 11:14:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=214
06/08/2022 11:14:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.14 on epoch=216
06/08/2022 11:14:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.18 on epoch=217
06/08/2022 11:14:37 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.14 on epoch=218
06/08/2022 11:14:39 - INFO - __main__ - Global step 1750 Train loss 0.15 Classification-F1 0.8337386426184773 on epoch=218
06/08/2022 11:14:39 - INFO - __main__ - Saving model with best Classification-F1: 0.8088640390511317 -> 0.8337386426184773 on epoch=218, global_step=1750
06/08/2022 11:14:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=219
06/08/2022 11:14:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=221
06/08/2022 11:14:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=222
06/08/2022 11:14:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=223
06/08/2022 11:14:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=224
06/08/2022 11:14:54 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.7964903057576649 on epoch=224
06/08/2022 11:14:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=226
06/08/2022 11:14:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=227
06/08/2022 11:15:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.12 on epoch=228
06/08/2022 11:15:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.15 on epoch=229
06/08/2022 11:15:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=231
06/08/2022 11:15:09 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.8047885572139304 on epoch=231
06/08/2022 11:15:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=232
06/08/2022 11:15:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=233
06/08/2022 11:15:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=234
06/08/2022 11:15:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=236
06/08/2022 11:15:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=237
06/08/2022 11:15:24 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.8037176724137931 on epoch=237
06/08/2022 11:15:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=238
06/08/2022 11:15:29 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=239
06/08/2022 11:15:31 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=241
06/08/2022 11:15:34 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=242
06/08/2022 11:15:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=243
06/08/2022 11:15:38 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.8176083866382374 on epoch=243
06/08/2022 11:15:41 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.10 on epoch=244
06/08/2022 11:15:44 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.11 on epoch=246
06/08/2022 11:15:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=247
06/08/2022 11:15:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=248
06/08/2022 11:15:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.11 on epoch=249
06/08/2022 11:15:53 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.7739644983260892 on epoch=249
06/08/2022 11:15:56 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.13 on epoch=251
06/08/2022 11:15:58 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=252
06/08/2022 11:16:01 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=253
06/08/2022 11:16:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=254
06/08/2022 11:16:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=256
06/08/2022 11:16:08 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.7579607447817838 on epoch=256
06/08/2022 11:16:11 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=257
06/08/2022 11:16:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=258
06/08/2022 11:16:16 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=259
06/08/2022 11:16:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=261
06/08/2022 11:16:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=262
06/08/2022 11:16:23 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7795815295815296 on epoch=262
06/08/2022 11:16:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.11 on epoch=263
06/08/2022 11:16:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.11 on epoch=264
06/08/2022 11:16:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.12 on epoch=266
06/08/2022 11:16:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=267
06/08/2022 11:16:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=268
06/08/2022 11:16:38 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.809203707091031 on epoch=268
06/08/2022 11:16:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=269
06/08/2022 11:16:43 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=271
06/08/2022 11:16:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=272
06/08/2022 11:16:48 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.11 on epoch=273
06/08/2022 11:16:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=274
06/08/2022 11:16:53 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.7669266118418661 on epoch=274
06/08/2022 11:16:56 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=276
06/08/2022 11:16:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=277
06/08/2022 11:17:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.10 on epoch=278
06/08/2022 11:17:04 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=279
06/08/2022 11:17:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.11 on epoch=281
06/08/2022 11:17:08 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.7699399846940831 on epoch=281
06/08/2022 11:17:11 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=282
06/08/2022 11:17:13 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=283
06/08/2022 11:17:16 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=284
06/08/2022 11:17:18 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.08 on epoch=286
06/08/2022 11:17:21 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.17 on epoch=287
06/08/2022 11:17:23 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.7837672221233865 on epoch=287
06/08/2022 11:17:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=288
06/08/2022 11:17:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=289
06/08/2022 11:17:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=291
06/08/2022 11:17:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=292
06/08/2022 11:17:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=293
06/08/2022 11:17:38 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7890022513587687 on epoch=293
06/08/2022 11:17:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=294
06/08/2022 11:17:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=296
06/08/2022 11:17:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=297
06/08/2022 11:17:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=298
06/08/2022 11:17:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=299
06/08/2022 11:17:52 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7854701436148371 on epoch=299
06/08/2022 11:17:55 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
06/08/2022 11:17:58 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.12 on epoch=302
06/08/2022 11:18:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=303
06/08/2022 11:18:03 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=304
06/08/2022 11:18:06 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=306
06/08/2022 11:18:08 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.7816045015613394 on epoch=306
06/08/2022 11:18:11 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=307
06/08/2022 11:18:13 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=308
06/08/2022 11:18:16 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=309
06/08/2022 11:18:18 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=311
06/08/2022 11:18:21 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=312
06/08/2022 11:18:23 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.7410867820703886 on epoch=312
06/08/2022 11:18:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=313
06/08/2022 11:18:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.08 on epoch=314
06/08/2022 11:18:30 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.12 on epoch=316
06/08/2022 11:18:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=317
06/08/2022 11:18:36 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=318
06/08/2022 11:18:37 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.7873014280191191 on epoch=318
06/08/2022 11:18:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=319
06/08/2022 11:18:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=321
06/08/2022 11:18:45 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=322
06/08/2022 11:18:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=323
06/08/2022 11:18:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=324
06/08/2022 11:18:52 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7959863450152751 on epoch=324
06/08/2022 11:18:54 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=326
06/08/2022 11:18:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=327
06/08/2022 11:19:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.10 on epoch=328
06/08/2022 11:19:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=329
06/08/2022 11:19:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
06/08/2022 11:19:07 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.786817863921254 on epoch=331
06/08/2022 11:19:10 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=332
06/08/2022 11:19:12 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
06/08/2022 11:19:15 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.10 on epoch=334
06/08/2022 11:19:18 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=336
06/08/2022 11:19:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=337
06/08/2022 11:19:23 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.7702638752637438 on epoch=337
06/08/2022 11:19:26 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.10 on epoch=338
06/08/2022 11:19:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
06/08/2022 11:19:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=341
06/08/2022 11:19:34 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=342
06/08/2022 11:19:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
06/08/2022 11:19:39 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.767944152621572 on epoch=343
06/08/2022 11:19:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=344
06/08/2022 11:19:44 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=346
06/08/2022 11:19:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=347
06/08/2022 11:19:50 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=348
06/08/2022 11:19:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
06/08/2022 11:19:54 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7778496882624018 on epoch=349
06/08/2022 11:19:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=351
06/08/2022 11:19:59 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
06/08/2022 11:20:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=353
06/08/2022 11:20:05 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=354
06/08/2022 11:20:08 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=356
06/08/2022 11:20:09 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.764582916981154 on epoch=356
06/08/2022 11:20:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
06/08/2022 11:20:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=358
06/08/2022 11:20:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/08/2022 11:20:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=361
06/08/2022 11:20:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/08/2022 11:20:25 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7741226163828179 on epoch=362
06/08/2022 11:20:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=363
06/08/2022 11:20:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
06/08/2022 11:20:33 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
06/08/2022 11:20:35 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=367
06/08/2022 11:20:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=368
06/08/2022 11:20:40 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7951654456742325 on epoch=368
06/08/2022 11:20:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=369
06/08/2022 11:20:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=371
06/08/2022 11:20:48 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=372
06/08/2022 11:20:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=373
06/08/2022 11:20:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=374
06/08/2022 11:20:54 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:20:54 - INFO - __main__ - Printing 3 examples
06/08/2022 11:20:54 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 11:20:54 - INFO - __main__ - ['others']
06/08/2022 11:20:54 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 11:20:54 - INFO - __main__ - ['others']
06/08/2022 11:20:54 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 11:20:54 - INFO - __main__ - ['others']
06/08/2022 11:20:54 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:20:54 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:20:55 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 11:20:55 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:20:55 - INFO - __main__ - Printing 3 examples
06/08/2022 11:20:55 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/08/2022 11:20:55 - INFO - __main__ - ['others']
06/08/2022 11:20:55 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/08/2022 11:20:55 - INFO - __main__ - ['others']
06/08/2022 11:20:55 - INFO - __main__ -  [emo] u oly first  no you no u
06/08/2022 11:20:55 - INFO - __main__ - ['others']
06/08/2022 11:20:55 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:20:55 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:20:55 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 11:20:55 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.8044080627180207 on epoch=374
06/08/2022 11:20:55 - INFO - __main__ - save last model!
06/08/2022 11:20:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 11:20:55 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 11:20:55 - INFO - __main__ - Printing 3 examples
06/08/2022 11:20:55 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 11:20:55 - INFO - __main__ - ['others']
06/08/2022 11:20:55 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 11:20:55 - INFO - __main__ - ['others']
06/08/2022 11:20:55 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 11:20:55 - INFO - __main__ - ['others']
06/08/2022 11:20:55 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:20:58 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:21:04 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 11:21:11 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 11:21:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 11:21:12 - INFO - __main__ - Starting training!
06/08/2022 11:22:17 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_100_0.2_8_predictions.txt
06/08/2022 11:22:17 - INFO - __main__ - Classification-F1 on test data: 0.4423
06/08/2022 11:22:18 - INFO - __main__ - prefix=emo_32_100, lr=0.2, bsz=8, dev_performance=0.8337386426184773, test_performance=0.442275451705534
06/08/2022 11:22:18 - INFO - __main__ - Running ... prefix=emo_32_13, lr=0.5, bsz=8 ...
06/08/2022 11:22:19 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:22:19 - INFO - __main__ - Printing 3 examples
06/08/2022 11:22:19 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 11:22:19 - INFO - __main__ - ['others']
06/08/2022 11:22:19 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 11:22:19 - INFO - __main__ - ['others']
06/08/2022 11:22:19 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 11:22:19 - INFO - __main__ - ['others']
06/08/2022 11:22:19 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:22:19 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:22:19 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 11:22:19 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:22:19 - INFO - __main__ - Printing 3 examples
06/08/2022 11:22:19 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/08/2022 11:22:19 - INFO - __main__ - ['others']
06/08/2022 11:22:19 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/08/2022 11:22:19 - INFO - __main__ - ['others']
06/08/2022 11:22:19 - INFO - __main__ -  [emo] u oly first  no you no u
06/08/2022 11:22:19 - INFO - __main__ - ['others']
06/08/2022 11:22:19 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:22:19 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:22:19 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 11:22:36 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 11:22:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 11:22:37 - INFO - __main__ - Starting training!
06/08/2022 11:22:41 - INFO - __main__ - Step 10 Global step 10 Train loss 2.48 on epoch=1
06/08/2022 11:22:43 - INFO - __main__ - Step 20 Global step 20 Train loss 1.18 on epoch=2
06/08/2022 11:22:46 - INFO - __main__ - Step 30 Global step 30 Train loss 0.97 on epoch=3
06/08/2022 11:22:49 - INFO - __main__ - Step 40 Global step 40 Train loss 0.97 on epoch=4
06/08/2022 11:22:51 - INFO - __main__ - Step 50 Global step 50 Train loss 0.95 on epoch=6
06/08/2022 11:22:53 - INFO - __main__ - Global step 50 Train loss 1.31 Classification-F1 0.1 on epoch=6
06/08/2022 11:22:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=6, global_step=50
06/08/2022 11:22:56 - INFO - __main__ - Step 60 Global step 60 Train loss 0.91 on epoch=7
06/08/2022 11:22:58 - INFO - __main__ - Step 70 Global step 70 Train loss 1.00 on epoch=8
06/08/2022 11:23:01 - INFO - __main__ - Step 80 Global step 80 Train loss 0.86 on epoch=9
06/08/2022 11:23:04 - INFO - __main__ - Step 90 Global step 90 Train loss 0.87 on epoch=11
06/08/2022 11:23:06 - INFO - __main__ - Step 100 Global step 100 Train loss 0.81 on epoch=12
06/08/2022 11:23:08 - INFO - __main__ - Global step 100 Train loss 0.89 Classification-F1 0.23418229080249986 on epoch=12
06/08/2022 11:23:08 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.23418229080249986 on epoch=12, global_step=100
06/08/2022 11:23:11 - INFO - __main__ - Step 110 Global step 110 Train loss 0.81 on epoch=13
06/08/2022 11:23:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.75 on epoch=14
06/08/2022 11:23:16 - INFO - __main__ - Step 130 Global step 130 Train loss 0.77 on epoch=16
06/08/2022 11:23:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.82 on epoch=17
06/08/2022 11:23:22 - INFO - __main__ - Step 150 Global step 150 Train loss 0.74 on epoch=18
06/08/2022 11:23:24 - INFO - __main__ - Global step 150 Train loss 0.78 Classification-F1 0.45075185820468844 on epoch=18
06/08/2022 11:23:24 - INFO - __main__ - Saving model with best Classification-F1: 0.23418229080249986 -> 0.45075185820468844 on epoch=18, global_step=150
06/08/2022 11:23:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.71 on epoch=19
06/08/2022 11:23:29 - INFO - __main__ - Step 170 Global step 170 Train loss 0.72 on epoch=21
06/08/2022 11:23:32 - INFO - __main__ - Step 180 Global step 180 Train loss 0.75 on epoch=22
06/08/2022 11:23:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.73 on epoch=23
06/08/2022 11:23:37 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=24
06/08/2022 11:23:39 - INFO - __main__ - Global step 200 Train loss 0.72 Classification-F1 0.48683261183261184 on epoch=24
06/08/2022 11:23:39 - INFO - __main__ - Saving model with best Classification-F1: 0.45075185820468844 -> 0.48683261183261184 on epoch=24, global_step=200
06/08/2022 11:23:42 - INFO - __main__ - Step 210 Global step 210 Train loss 0.62 on epoch=26
06/08/2022 11:23:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.71 on epoch=27
06/08/2022 11:23:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.60 on epoch=28
06/08/2022 11:23:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.57 on epoch=29
06/08/2022 11:23:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.58 on epoch=31
06/08/2022 11:23:54 - INFO - __main__ - Global step 250 Train loss 0.62 Classification-F1 0.4017120134767194 on epoch=31
06/08/2022 11:23:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.57 on epoch=32
06/08/2022 11:23:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.56 on epoch=33
06/08/2022 11:24:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.50 on epoch=34
06/08/2022 11:24:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=36
06/08/2022 11:24:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.57 on epoch=37
06/08/2022 11:24:09 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.6022039273472787 on epoch=37
06/08/2022 11:24:09 - INFO - __main__ - Saving model with best Classification-F1: 0.48683261183261184 -> 0.6022039273472787 on epoch=37, global_step=300
06/08/2022 11:24:12 - INFO - __main__ - Step 310 Global step 310 Train loss 0.52 on epoch=38
06/08/2022 11:24:14 - INFO - __main__ - Step 320 Global step 320 Train loss 0.49 on epoch=39
06/08/2022 11:24:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.43 on epoch=41
06/08/2022 11:24:20 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=42
06/08/2022 11:24:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.49 on epoch=43
06/08/2022 11:24:24 - INFO - __main__ - Global step 350 Train loss 0.47 Classification-F1 0.5205480951685886 on epoch=43
06/08/2022 11:24:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.50 on epoch=44
06/08/2022 11:24:30 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=46
06/08/2022 11:24:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=47
06/08/2022 11:24:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=48
06/08/2022 11:24:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=49
06/08/2022 11:24:40 - INFO - __main__ - Global step 400 Train loss 0.42 Classification-F1 0.6186746987951808 on epoch=49
06/08/2022 11:24:40 - INFO - __main__ - Saving model with best Classification-F1: 0.6022039273472787 -> 0.6186746987951808 on epoch=49, global_step=400
06/08/2022 11:24:42 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=51
06/08/2022 11:24:45 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=52
06/08/2022 11:24:48 - INFO - __main__ - Step 430 Global step 430 Train loss 0.46 on epoch=53
06/08/2022 11:24:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=54
06/08/2022 11:24:53 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=56
06/08/2022 11:24:55 - INFO - __main__ - Global step 450 Train loss 0.35 Classification-F1 0.7061755146262187 on epoch=56
06/08/2022 11:24:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6186746987951808 -> 0.7061755146262187 on epoch=56, global_step=450
06/08/2022 11:24:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=57
06/08/2022 11:25:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=58
06/08/2022 11:25:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.43 on epoch=59
06/08/2022 11:25:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.40 on epoch=61
06/08/2022 11:25:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=62
06/08/2022 11:25:10 - INFO - __main__ - Global step 500 Train loss 0.37 Classification-F1 0.6974695334013015 on epoch=62
06/08/2022 11:25:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.38 on epoch=63
06/08/2022 11:25:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.36 on epoch=64
06/08/2022 11:25:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.35 on epoch=66
06/08/2022 11:25:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=67
06/08/2022 11:25:23 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=68
06/08/2022 11:25:25 - INFO - __main__ - Global step 550 Train loss 0.33 Classification-F1 0.4987837837837838 on epoch=68
06/08/2022 11:25:28 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=69
06/08/2022 11:25:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=71
06/08/2022 11:25:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=72
06/08/2022 11:25:36 - INFO - __main__ - Step 590 Global step 590 Train loss 0.31 on epoch=73
06/08/2022 11:25:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=74
06/08/2022 11:25:40 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.5234012273142707 on epoch=74
06/08/2022 11:25:43 - INFO - __main__ - Step 610 Global step 610 Train loss 0.27 on epoch=76
06/08/2022 11:25:46 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=77
06/08/2022 11:25:48 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=78
06/08/2022 11:25:51 - INFO - __main__ - Step 640 Global step 640 Train loss 0.26 on epoch=79
06/08/2022 11:25:54 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=81
06/08/2022 11:25:55 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.727486932745181 on epoch=81
06/08/2022 11:25:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7061755146262187 -> 0.727486932745181 on epoch=81, global_step=650
06/08/2022 11:25:58 - INFO - __main__ - Step 660 Global step 660 Train loss 0.30 on epoch=82
06/08/2022 11:26:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=83
06/08/2022 11:26:03 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=84
06/08/2022 11:26:06 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=86
06/08/2022 11:26:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=87
06/08/2022 11:26:10 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.717975206948712 on epoch=87
06/08/2022 11:26:13 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=88
06/08/2022 11:26:16 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=89
06/08/2022 11:26:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=91
06/08/2022 11:26:21 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=92
06/08/2022 11:26:24 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=93
06/08/2022 11:26:25 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.7173845446679645 on epoch=93
06/08/2022 11:26:28 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=94
06/08/2022 11:26:31 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=96
06/08/2022 11:26:33 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=97
06/08/2022 11:26:36 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=98
06/08/2022 11:26:39 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=99
06/08/2022 11:26:41 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.7004281949934124 on epoch=99
06/08/2022 11:26:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=101
06/08/2022 11:26:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=102
06/08/2022 11:26:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=103
06/08/2022 11:26:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=104
06/08/2022 11:26:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=106
06/08/2022 11:26:56 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.6016591663988 on epoch=106
06/08/2022 11:26:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=107
06/08/2022 11:27:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=108
06/08/2022 11:27:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=109
06/08/2022 11:27:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=111
06/08/2022 11:27:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=112
06/08/2022 11:27:11 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.6987438219322277 on epoch=112
06/08/2022 11:27:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=113
06/08/2022 11:27:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=114
06/08/2022 11:27:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=116
06/08/2022 11:27:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=117
06/08/2022 11:27:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=118
06/08/2022 11:27:27 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.7168828486035764 on epoch=118
06/08/2022 11:27:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=119
06/08/2022 11:27:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=121
06/08/2022 11:27:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=122
06/08/2022 11:27:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.29 on epoch=123
06/08/2022 11:27:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=124
06/08/2022 11:27:42 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.6267083688215287 on epoch=124
06/08/2022 11:27:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=126
06/08/2022 11:27:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=127
06/08/2022 11:27:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=128
06/08/2022 11:27:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=129
06/08/2022 11:27:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=131
06/08/2022 11:27:57 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.7361248847365034 on epoch=131
06/08/2022 11:27:57 - INFO - __main__ - Saving model with best Classification-F1: 0.727486932745181 -> 0.7361248847365034 on epoch=131, global_step=1050
06/08/2022 11:28:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=132
06/08/2022 11:28:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=133
06/08/2022 11:28:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=134
06/08/2022 11:28:08 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=136
06/08/2022 11:28:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=137
06/08/2022 11:28:13 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.7345645645645646 on epoch=137
06/08/2022 11:28:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=138
06/08/2022 11:28:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=139
06/08/2022 11:28:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=141
06/08/2022 11:28:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=142
06/08/2022 11:28:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=143
06/08/2022 11:28:28 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.6940177258754343 on epoch=143
06/08/2022 11:28:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=144
06/08/2022 11:28:33 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=146
06/08/2022 11:28:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=147
06/08/2022 11:28:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.25 on epoch=148
06/08/2022 11:28:41 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=149
06/08/2022 11:28:43 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.7135122779519331 on epoch=149
06/08/2022 11:28:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=151
06/08/2022 11:28:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=152
06/08/2022 11:28:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.18 on epoch=153
06/08/2022 11:28:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=154
06/08/2022 11:28:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=156
06/08/2022 11:28:58 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.7414355668505548 on epoch=156
06/08/2022 11:28:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7361248847365034 -> 0.7414355668505548 on epoch=156, global_step=1250
06/08/2022 11:29:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=157
06/08/2022 11:29:04 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=158
06/08/2022 11:29:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=159
06/08/2022 11:29:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=161
06/08/2022 11:29:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=162
06/08/2022 11:29:13 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.7547231164439242 on epoch=162
06/08/2022 11:29:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7414355668505548 -> 0.7547231164439242 on epoch=162, global_step=1300
06/08/2022 11:29:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=163
06/08/2022 11:29:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=164
06/08/2022 11:29:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=166
06/08/2022 11:29:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=167
06/08/2022 11:29:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.18 on epoch=168
06/08/2022 11:29:29 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.5847967569695628 on epoch=168
06/08/2022 11:29:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=169
06/08/2022 11:29:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=171
06/08/2022 11:29:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=172
06/08/2022 11:29:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=173
06/08/2022 11:29:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=174
06/08/2022 11:29:44 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.7009746774964165 on epoch=174
06/08/2022 11:29:46 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=176
06/08/2022 11:29:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=177
06/08/2022 11:29:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=178
06/08/2022 11:29:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=179
06/08/2022 11:29:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=181
06/08/2022 11:29:59 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7235384232158426 on epoch=181
06/08/2022 11:30:02 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=182
06/08/2022 11:30:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=183
06/08/2022 11:30:07 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=184
06/08/2022 11:30:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=186
06/08/2022 11:30:13 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=187
06/08/2022 11:30:15 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7170256852741096 on epoch=187
06/08/2022 11:30:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=188
06/08/2022 11:30:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=189
06/08/2022 11:30:23 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=191
06/08/2022 11:30:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=192
06/08/2022 11:30:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=193
06/08/2022 11:30:30 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7181089743589744 on epoch=193
06/08/2022 11:30:33 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=194
06/08/2022 11:30:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=196
06/08/2022 11:30:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=197
06/08/2022 11:30:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=198
06/08/2022 11:30:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=199
06/08/2022 11:30:45 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7169747885728899 on epoch=199
06/08/2022 11:30:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=201
06/08/2022 11:30:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=202
06/08/2022 11:30:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=203
06/08/2022 11:30:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=204
06/08/2022 11:30:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=206
06/08/2022 11:31:01 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7447600236099563 on epoch=206
06/08/2022 11:31:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=207
06/08/2022 11:31:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=208
06/08/2022 11:31:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=209
06/08/2022 11:31:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=211
06/08/2022 11:31:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.14 on epoch=212
06/08/2022 11:31:16 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.6813028775084543 on epoch=212
06/08/2022 11:31:19 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=213
06/08/2022 11:31:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=214
06/08/2022 11:31:24 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=216
06/08/2022 11:31:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=217
06/08/2022 11:31:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=218
06/08/2022 11:31:31 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7422800691436963 on epoch=218
06/08/2022 11:31:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=219
06/08/2022 11:31:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=221
06/08/2022 11:31:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=222
06/08/2022 11:31:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=223
06/08/2022 11:31:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=224
06/08/2022 11:31:47 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.6963011527911631 on epoch=224
06/08/2022 11:31:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=226
06/08/2022 11:31:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=227
06/08/2022 11:31:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=228
06/08/2022 11:31:57 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=229
06/08/2022 11:32:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=231
06/08/2022 11:32:02 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7286330950290564 on epoch=231
06/08/2022 11:32:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=232
06/08/2022 11:32:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=233
06/08/2022 11:32:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=234
06/08/2022 11:32:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=236
06/08/2022 11:32:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=237
06/08/2022 11:32:17 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.728006993006993 on epoch=237
06/08/2022 11:32:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=238
06/08/2022 11:32:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=239
06/08/2022 11:32:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=241
06/08/2022 11:32:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=242
06/08/2022 11:32:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=243
06/08/2022 11:32:33 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7057522740278908 on epoch=243
06/08/2022 11:32:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=244
06/08/2022 11:32:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.11 on epoch=246
06/08/2022 11:32:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=247
06/08/2022 11:32:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=248
06/08/2022 11:32:46 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=249
06/08/2022 11:32:48 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7136105599647267 on epoch=249
06/08/2022 11:32:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=251
06/08/2022 11:32:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=252
06/08/2022 11:32:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=253
06/08/2022 11:32:59 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=254
06/08/2022 11:33:02 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=256
06/08/2022 11:33:04 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7159637664697864 on epoch=256
06/08/2022 11:33:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=257
06/08/2022 11:33:09 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=258
06/08/2022 11:33:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=259
06/08/2022 11:33:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=261
06/08/2022 11:33:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=262
06/08/2022 11:33:19 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7226528986744041 on epoch=262
06/08/2022 11:33:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=263
06/08/2022 11:33:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=264
06/08/2022 11:33:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.10 on epoch=266
06/08/2022 11:33:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=267
06/08/2022 11:33:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=268
06/08/2022 11:33:35 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7098571499862764 on epoch=268
06/08/2022 11:33:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=269
06/08/2022 11:33:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=271
06/08/2022 11:33:43 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=272
06/08/2022 11:33:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.12 on epoch=273
06/08/2022 11:33:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=274
06/08/2022 11:33:50 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7246642246642248 on epoch=274
06/08/2022 11:33:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=276
06/08/2022 11:33:55 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=277
06/08/2022 11:33:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=278
06/08/2022 11:34:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=279
06/08/2022 11:34:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=281
06/08/2022 11:34:05 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7255799755799757 on epoch=281
06/08/2022 11:34:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=282
06/08/2022 11:34:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
06/08/2022 11:34:13 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=284
06/08/2022 11:34:16 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=286
06/08/2022 11:34:19 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=287
06/08/2022 11:34:21 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.714408799342445 on epoch=287
06/08/2022 11:34:23 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=288
06/08/2022 11:34:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=289
06/08/2022 11:34:29 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=291
06/08/2022 11:34:31 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=292
06/08/2022 11:34:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=293
06/08/2022 11:34:36 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7289411740035334 on epoch=293
06/08/2022 11:34:38 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=294
06/08/2022 11:34:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=296
06/08/2022 11:34:43 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=297
06/08/2022 11:34:46 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=298
06/08/2022 11:34:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=299
06/08/2022 11:34:51 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7321596907993967 on epoch=299
06/08/2022 11:34:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
06/08/2022 11:34:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
06/08/2022 11:34:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
06/08/2022 11:35:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=304
06/08/2022 11:35:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=306
06/08/2022 11:35:06 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7201422724340586 on epoch=306
06/08/2022 11:35:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=307
06/08/2022 11:35:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=308
06/08/2022 11:35:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=309
06/08/2022 11:35:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=311
06/08/2022 11:35:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=312
06/08/2022 11:35:21 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7163725163725164 on epoch=312
06/08/2022 11:35:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=313
06/08/2022 11:35:27 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/08/2022 11:35:29 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=316
06/08/2022 11:35:32 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=317
06/08/2022 11:35:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=318
06/08/2022 11:35:37 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.6945308467947644 on epoch=318
06/08/2022 11:35:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=319
06/08/2022 11:35:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=321
06/08/2022 11:35:45 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=322
06/08/2022 11:35:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=323
06/08/2022 11:35:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=324
06/08/2022 11:35:52 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7237020234971054 on epoch=324
06/08/2022 11:35:55 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=326
06/08/2022 11:35:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.08 on epoch=327
06/08/2022 11:36:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=328
06/08/2022 11:36:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=329
06/08/2022 11:36:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
06/08/2022 11:36:07 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.671612452264048 on epoch=331
06/08/2022 11:36:10 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=332
06/08/2022 11:36:12 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=333
06/08/2022 11:36:15 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=334
06/08/2022 11:36:18 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=336
06/08/2022 11:36:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=337
06/08/2022 11:36:23 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7099386240746843 on epoch=337
06/08/2022 11:36:25 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/08/2022 11:36:28 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=339
06/08/2022 11:36:31 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=341
06/08/2022 11:36:33 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
06/08/2022 11:36:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=343
06/08/2022 11:36:38 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7700047211224675 on epoch=343
06/08/2022 11:36:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7547231164439242 -> 0.7700047211224675 on epoch=343, global_step=2750
06/08/2022 11:36:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=344
06/08/2022 11:36:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
06/08/2022 11:36:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
06/08/2022 11:36:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=348
06/08/2022 11:36:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=349
06/08/2022 11:36:53 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.725555010736689 on epoch=349
06/08/2022 11:36:56 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=351
06/08/2022 11:36:59 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.12 on epoch=352
06/08/2022 11:37:01 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
06/08/2022 11:37:04 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=354
06/08/2022 11:37:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=356
06/08/2022 11:37:09 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7186321195144725 on epoch=356
06/08/2022 11:37:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.09 on epoch=357
06/08/2022 11:37:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=358
06/08/2022 11:37:17 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=359
06/08/2022 11:37:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
06/08/2022 11:37:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=362
06/08/2022 11:37:25 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.721728563833827 on epoch=362
06/08/2022 11:37:27 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=363
06/08/2022 11:37:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
06/08/2022 11:37:33 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=366
06/08/2022 11:37:36 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=367
06/08/2022 11:37:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=368
06/08/2022 11:37:40 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7239282939282938 on epoch=368
06/08/2022 11:37:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
06/08/2022 11:37:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=371
06/08/2022 11:37:48 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=372
06/08/2022 11:37:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=373
06/08/2022 11:37:54 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
06/08/2022 11:37:55 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:37:55 - INFO - __main__ - Printing 3 examples
06/08/2022 11:37:55 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 11:37:55 - INFO - __main__ - ['others']
06/08/2022 11:37:55 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 11:37:55 - INFO - __main__ - ['others']
06/08/2022 11:37:55 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 11:37:55 - INFO - __main__ - ['others']
06/08/2022 11:37:55 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:37:55 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:37:55 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 11:37:55 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:37:55 - INFO - __main__ - Printing 3 examples
06/08/2022 11:37:55 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/08/2022 11:37:55 - INFO - __main__ - ['others']
06/08/2022 11:37:55 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/08/2022 11:37:55 - INFO - __main__ - ['others']
06/08/2022 11:37:55 - INFO - __main__ -  [emo] u oly first  no you no u
06/08/2022 11:37:55 - INFO - __main__ - ['others']
06/08/2022 11:37:55 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:37:55 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:37:56 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 11:37:56 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7160555205971164 on epoch=374
06/08/2022 11:37:56 - INFO - __main__ - save last model!
06/08/2022 11:37:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 11:37:56 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 11:37:56 - INFO - __main__ - Printing 3 examples
06/08/2022 11:37:56 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 11:37:56 - INFO - __main__ - ['others']
06/08/2022 11:37:56 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 11:37:56 - INFO - __main__ - ['others']
06/08/2022 11:37:56 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 11:37:56 - INFO - __main__ - ['others']
06/08/2022 11:37:56 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:37:58 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:38:04 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 11:38:11 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 11:38:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 11:38:12 - INFO - __main__ - Starting training!
06/08/2022 11:39:23 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_13_0.5_8_predictions.txt
06/08/2022 11:39:23 - INFO - __main__ - Classification-F1 on test data: 0.4092
06/08/2022 11:39:23 - INFO - __main__ - prefix=emo_32_13, lr=0.5, bsz=8, dev_performance=0.7700047211224675, test_performance=0.40917321720065575
06/08/2022 11:39:23 - INFO - __main__ - Running ... prefix=emo_32_13, lr=0.4, bsz=8 ...
06/08/2022 11:39:24 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:39:24 - INFO - __main__ - Printing 3 examples
06/08/2022 11:39:24 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 11:39:24 - INFO - __main__ - ['others']
06/08/2022 11:39:24 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 11:39:24 - INFO - __main__ - ['others']
06/08/2022 11:39:24 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 11:39:24 - INFO - __main__ - ['others']
06/08/2022 11:39:24 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:39:24 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:39:24 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 11:39:24 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:39:24 - INFO - __main__ - Printing 3 examples
06/08/2022 11:39:24 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/08/2022 11:39:24 - INFO - __main__ - ['others']
06/08/2022 11:39:24 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/08/2022 11:39:24 - INFO - __main__ - ['others']
06/08/2022 11:39:24 - INFO - __main__ -  [emo] u oly first  no you no u
06/08/2022 11:39:24 - INFO - __main__ - ['others']
06/08/2022 11:39:24 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:39:24 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:39:25 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 11:39:44 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 11:39:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 11:39:45 - INFO - __main__ - Starting training!
06/08/2022 11:39:48 - INFO - __main__ - Step 10 Global step 10 Train loss 2.74 on epoch=1
06/08/2022 11:39:51 - INFO - __main__ - Step 20 Global step 20 Train loss 1.26 on epoch=2
06/08/2022 11:39:53 - INFO - __main__ - Step 30 Global step 30 Train loss 1.06 on epoch=3
06/08/2022 11:39:56 - INFO - __main__ - Step 40 Global step 40 Train loss 0.99 on epoch=4
06/08/2022 11:39:59 - INFO - __main__ - Step 50 Global step 50 Train loss 0.87 on epoch=6
06/08/2022 11:40:00 - INFO - __main__ - Global step 50 Train loss 1.38 Classification-F1 0.11578044596912522 on epoch=6
06/08/2022 11:40:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11578044596912522 on epoch=6, global_step=50
06/08/2022 11:40:03 - INFO - __main__ - Step 60 Global step 60 Train loss 0.90 on epoch=7
06/08/2022 11:40:06 - INFO - __main__ - Step 70 Global step 70 Train loss 0.90 on epoch=8
06/08/2022 11:40:09 - INFO - __main__ - Step 80 Global step 80 Train loss 0.97 on epoch=9
06/08/2022 11:40:11 - INFO - __main__ - Step 90 Global step 90 Train loss 0.91 on epoch=11
06/08/2022 11:40:14 - INFO - __main__ - Step 100 Global step 100 Train loss 0.91 on epoch=12
06/08/2022 11:40:15 - INFO - __main__ - Global step 100 Train loss 0.92 Classification-F1 0.22410714285714287 on epoch=12
06/08/2022 11:40:15 - INFO - __main__ - Saving model with best Classification-F1: 0.11578044596912522 -> 0.22410714285714287 on epoch=12, global_step=100
06/08/2022 11:40:18 - INFO - __main__ - Step 110 Global step 110 Train loss 0.83 on epoch=13
06/08/2022 11:40:21 - INFO - __main__ - Step 120 Global step 120 Train loss 0.81 on epoch=14
06/08/2022 11:40:23 - INFO - __main__ - Step 130 Global step 130 Train loss 0.85 on epoch=16
06/08/2022 11:40:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=17
06/08/2022 11:40:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.81 on epoch=18
06/08/2022 11:40:31 - INFO - __main__ - Global step 150 Train loss 0.81 Classification-F1 0.4093481989708405 on epoch=18
06/08/2022 11:40:31 - INFO - __main__ - Saving model with best Classification-F1: 0.22410714285714287 -> 0.4093481989708405 on epoch=18, global_step=150
06/08/2022 11:40:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.82 on epoch=19
06/08/2022 11:40:36 - INFO - __main__ - Step 170 Global step 170 Train loss 0.76 on epoch=21
06/08/2022 11:40:39 - INFO - __main__ - Step 180 Global step 180 Train loss 0.66 on epoch=22
06/08/2022 11:40:41 - INFO - __main__ - Step 190 Global step 190 Train loss 0.73 on epoch=23
06/08/2022 11:40:44 - INFO - __main__ - Step 200 Global step 200 Train loss 0.72 on epoch=24
06/08/2022 11:40:46 - INFO - __main__ - Global step 200 Train loss 0.74 Classification-F1 0.5559112249253094 on epoch=24
06/08/2022 11:40:46 - INFO - __main__ - Saving model with best Classification-F1: 0.4093481989708405 -> 0.5559112249253094 on epoch=24, global_step=200
06/08/2022 11:40:48 - INFO - __main__ - Step 210 Global step 210 Train loss 0.73 on epoch=26
06/08/2022 11:40:51 - INFO - __main__ - Step 220 Global step 220 Train loss 0.64 on epoch=27
06/08/2022 11:40:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=28
06/08/2022 11:40:56 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=29
06/08/2022 11:40:59 - INFO - __main__ - Step 250 Global step 250 Train loss 0.64 on epoch=31
06/08/2022 11:41:01 - INFO - __main__ - Global step 250 Train loss 0.65 Classification-F1 0.4446194818091541 on epoch=31
06/08/2022 11:41:04 - INFO - __main__ - Step 260 Global step 260 Train loss 0.64 on epoch=32
06/08/2022 11:41:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.58 on epoch=33
06/08/2022 11:41:09 - INFO - __main__ - Step 280 Global step 280 Train loss 0.54 on epoch=34
06/08/2022 11:41:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.61 on epoch=36
06/08/2022 11:41:14 - INFO - __main__ - Step 300 Global step 300 Train loss 0.60 on epoch=37
06/08/2022 11:41:16 - INFO - __main__ - Global step 300 Train loss 0.59 Classification-F1 0.46366402116402117 on epoch=37
06/08/2022 11:41:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.72 on epoch=38
06/08/2022 11:41:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.48 on epoch=39
06/08/2022 11:41:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.55 on epoch=41
06/08/2022 11:41:27 - INFO - __main__ - Step 340 Global step 340 Train loss 0.51 on epoch=42
06/08/2022 11:41:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.49 on epoch=43
06/08/2022 11:41:31 - INFO - __main__ - Global step 350 Train loss 0.55 Classification-F1 0.6090551026034897 on epoch=43
06/08/2022 11:41:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5559112249253094 -> 0.6090551026034897 on epoch=43, global_step=350
06/08/2022 11:41:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.52 on epoch=44
06/08/2022 11:41:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.76 on epoch=46
06/08/2022 11:41:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.75 on epoch=47
06/08/2022 11:41:42 - INFO - __main__ - Step 390 Global step 390 Train loss 0.49 on epoch=48
06/08/2022 11:41:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=49
06/08/2022 11:41:46 - INFO - __main__ - Global step 400 Train loss 0.58 Classification-F1 0.6716998220359695 on epoch=49
06/08/2022 11:41:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6090551026034897 -> 0.6716998220359695 on epoch=49, global_step=400
06/08/2022 11:41:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.49 on epoch=51
06/08/2022 11:41:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.42 on epoch=52
06/08/2022 11:41:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.52 on epoch=53
06/08/2022 11:41:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.44 on epoch=54
06/08/2022 11:41:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.42 on epoch=56
06/08/2022 11:42:01 - INFO - __main__ - Global step 450 Train loss 0.46 Classification-F1 0.7045209298039486 on epoch=56
06/08/2022 11:42:01 - INFO - __main__ - Saving model with best Classification-F1: 0.6716998220359695 -> 0.7045209298039486 on epoch=56, global_step=450
06/08/2022 11:42:04 - INFO - __main__ - Step 460 Global step 460 Train loss 0.49 on epoch=57
06/08/2022 11:42:06 - INFO - __main__ - Step 470 Global step 470 Train loss 0.45 on epoch=58
06/08/2022 11:42:09 - INFO - __main__ - Step 480 Global step 480 Train loss 0.36 on epoch=59
06/08/2022 11:42:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.39 on epoch=61
06/08/2022 11:42:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.50 on epoch=62
06/08/2022 11:42:16 - INFO - __main__ - Global step 500 Train loss 0.44 Classification-F1 0.6866264605053123 on epoch=62
06/08/2022 11:42:19 - INFO - __main__ - Step 510 Global step 510 Train loss 0.45 on epoch=63
06/08/2022 11:42:21 - INFO - __main__ - Step 520 Global step 520 Train loss 0.35 on epoch=64
06/08/2022 11:42:24 - INFO - __main__ - Step 530 Global step 530 Train loss 0.43 on epoch=66
06/08/2022 11:42:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=67
06/08/2022 11:42:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.43 on epoch=68
06/08/2022 11:42:31 - INFO - __main__ - Global step 550 Train loss 0.42 Classification-F1 0.613668354458307 on epoch=68
06/08/2022 11:42:34 - INFO - __main__ - Step 560 Global step 560 Train loss 0.37 on epoch=69
06/08/2022 11:42:37 - INFO - __main__ - Step 570 Global step 570 Train loss 0.46 on epoch=71
06/08/2022 11:42:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.34 on epoch=72
06/08/2022 11:42:42 - INFO - __main__ - Step 590 Global step 590 Train loss 0.45 on epoch=73
06/08/2022 11:42:45 - INFO - __main__ - Step 600 Global step 600 Train loss 0.49 on epoch=74
06/08/2022 11:42:47 - INFO - __main__ - Global step 600 Train loss 0.42 Classification-F1 0.732939981729328 on epoch=74
06/08/2022 11:42:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7045209298039486 -> 0.732939981729328 on epoch=74, global_step=600
06/08/2022 11:42:49 - INFO - __main__ - Step 610 Global step 610 Train loss 0.43 on epoch=76
06/08/2022 11:42:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=77
06/08/2022 11:42:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=78
06/08/2022 11:42:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=79
06/08/2022 11:43:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.35 on epoch=81
06/08/2022 11:43:01 - INFO - __main__ - Global step 650 Train loss 0.34 Classification-F1 0.7109942419681999 on epoch=81
06/08/2022 11:43:04 - INFO - __main__ - Step 660 Global step 660 Train loss 0.39 on epoch=82
06/08/2022 11:43:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.38 on epoch=83
06/08/2022 11:43:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.42 on epoch=84
06/08/2022 11:43:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.36 on epoch=86
06/08/2022 11:43:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.33 on epoch=87
06/08/2022 11:43:17 - INFO - __main__ - Global step 700 Train loss 0.37 Classification-F1 0.7360584817481369 on epoch=87
06/08/2022 11:43:17 - INFO - __main__ - Saving model with best Classification-F1: 0.732939981729328 -> 0.7360584817481369 on epoch=87, global_step=700
06/08/2022 11:43:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.37 on epoch=88
06/08/2022 11:43:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.29 on epoch=89
06/08/2022 11:43:25 - INFO - __main__ - Step 730 Global step 730 Train loss 0.30 on epoch=91
06/08/2022 11:43:27 - INFO - __main__ - Step 740 Global step 740 Train loss 0.32 on epoch=92
06/08/2022 11:43:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.40 on epoch=93
06/08/2022 11:43:32 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.6914525088438133 on epoch=93
06/08/2022 11:43:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.31 on epoch=94
06/08/2022 11:43:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.39 on epoch=96
06/08/2022 11:43:40 - INFO - __main__ - Step 780 Global step 780 Train loss 0.30 on epoch=97
06/08/2022 11:43:43 - INFO - __main__ - Step 790 Global step 790 Train loss 0.29 on epoch=98
06/08/2022 11:43:45 - INFO - __main__ - Step 800 Global step 800 Train loss 0.29 on epoch=99
06/08/2022 11:43:47 - INFO - __main__ - Global step 800 Train loss 0.32 Classification-F1 0.7405129330721956 on epoch=99
06/08/2022 11:43:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7360584817481369 -> 0.7405129330721956 on epoch=99, global_step=800
06/08/2022 11:43:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=101
06/08/2022 11:43:52 - INFO - __main__ - Step 820 Global step 820 Train loss 0.33 on epoch=102
06/08/2022 11:43:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.28 on epoch=103
06/08/2022 11:43:58 - INFO - __main__ - Step 840 Global step 840 Train loss 0.27 on epoch=104
06/08/2022 11:44:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.27 on epoch=106
06/08/2022 11:44:02 - INFO - __main__ - Global step 850 Train loss 0.28 Classification-F1 0.7506832272491468 on epoch=106
06/08/2022 11:44:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7405129330721956 -> 0.7506832272491468 on epoch=106, global_step=850
06/08/2022 11:44:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.33 on epoch=107
06/08/2022 11:44:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.36 on epoch=108
06/08/2022 11:44:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.28 on epoch=109
06/08/2022 11:44:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.28 on epoch=111
06/08/2022 11:44:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.25 on epoch=112
06/08/2022 11:44:17 - INFO - __main__ - Global step 900 Train loss 0.30 Classification-F1 0.5936067005191429 on epoch=112
06/08/2022 11:44:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.23 on epoch=113
06/08/2022 11:44:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.26 on epoch=114
06/08/2022 11:44:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.31 on epoch=116
06/08/2022 11:44:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.25 on epoch=117
06/08/2022 11:44:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.27 on epoch=118
06/08/2022 11:44:32 - INFO - __main__ - Global step 950 Train loss 0.26 Classification-F1 0.5845068938154044 on epoch=118
06/08/2022 11:44:35 - INFO - __main__ - Step 960 Global step 960 Train loss 0.28 on epoch=119
06/08/2022 11:44:38 - INFO - __main__ - Step 970 Global step 970 Train loss 0.24 on epoch=121
06/08/2022 11:44:41 - INFO - __main__ - Step 980 Global step 980 Train loss 0.31 on epoch=122
06/08/2022 11:44:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.28 on epoch=123
06/08/2022 11:44:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.29 on epoch=124
06/08/2022 11:44:48 - INFO - __main__ - Global step 1000 Train loss 0.28 Classification-F1 0.6789760963674006 on epoch=124
06/08/2022 11:44:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.23 on epoch=126
06/08/2022 11:44:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.24 on epoch=127
06/08/2022 11:44:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.27 on epoch=128
06/08/2022 11:44:59 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.22 on epoch=129
06/08/2022 11:45:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=131
06/08/2022 11:45:03 - INFO - __main__ - Global step 1050 Train loss 0.23 Classification-F1 0.7047153586575913 on epoch=131
06/08/2022 11:45:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=132
06/08/2022 11:45:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=133
06/08/2022 11:45:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.20 on epoch=134
06/08/2022 11:45:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.22 on epoch=136
06/08/2022 11:45:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.23 on epoch=137
06/08/2022 11:45:18 - INFO - __main__ - Global step 1100 Train loss 0.21 Classification-F1 0.5786353861192571 on epoch=137
06/08/2022 11:45:21 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=138
06/08/2022 11:45:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.23 on epoch=139
06/08/2022 11:45:26 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.21 on epoch=141
06/08/2022 11:45:29 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=142
06/08/2022 11:45:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.28 on epoch=143
06/08/2022 11:45:33 - INFO - __main__ - Global step 1150 Train loss 0.21 Classification-F1 0.7422762694821519 on epoch=143
06/08/2022 11:45:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=144
06/08/2022 11:45:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.25 on epoch=146
06/08/2022 11:45:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=147
06/08/2022 11:45:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.27 on epoch=148
06/08/2022 11:45:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.27 on epoch=149
06/08/2022 11:45:48 - INFO - __main__ - Global step 1200 Train loss 0.22 Classification-F1 0.5448132714836073 on epoch=149
06/08/2022 11:45:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=151
06/08/2022 11:45:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.27 on epoch=152
06/08/2022 11:45:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.21 on epoch=153
06/08/2022 11:45:59 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=154
06/08/2022 11:46:02 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=156
06/08/2022 11:46:03 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.733635523548531 on epoch=156
06/08/2022 11:46:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.20 on epoch=157
06/08/2022 11:46:09 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=158
06/08/2022 11:46:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=159
06/08/2022 11:46:14 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.21 on epoch=161
06/08/2022 11:46:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=162
06/08/2022 11:46:19 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.7083158508158508 on epoch=162
06/08/2022 11:46:22 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.24 on epoch=163
06/08/2022 11:46:24 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=164
06/08/2022 11:46:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=166
06/08/2022 11:46:30 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=167
06/08/2022 11:46:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=168
06/08/2022 11:46:34 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.726370613782117 on epoch=168
06/08/2022 11:46:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=169
06/08/2022 11:46:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=171
06/08/2022 11:46:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=172
06/08/2022 11:46:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=173
06/08/2022 11:46:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=174
06/08/2022 11:46:50 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.718625992063492 on epoch=174
06/08/2022 11:46:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=176
06/08/2022 11:46:55 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=177
06/08/2022 11:46:58 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=178
06/08/2022 11:47:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=179
06/08/2022 11:47:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=181
06/08/2022 11:47:05 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.7208269182609881 on epoch=181
06/08/2022 11:47:08 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=182
06/08/2022 11:47:11 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=183
06/08/2022 11:47:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=184
06/08/2022 11:47:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=186
06/08/2022 11:47:20 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.17 on epoch=187
06/08/2022 11:47:22 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.5708126826788664 on epoch=187
06/08/2022 11:47:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.24 on epoch=188
06/08/2022 11:47:27 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=189
06/08/2022 11:47:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=191
06/08/2022 11:47:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=192
06/08/2022 11:47:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=193
06/08/2022 11:47:37 - INFO - __main__ - Global step 1550 Train loss 0.14 Classification-F1 0.5110896932486138 on epoch=193
06/08/2022 11:47:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=194
06/08/2022 11:47:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=196
06/08/2022 11:47:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=197
06/08/2022 11:47:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=198
06/08/2022 11:47:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=199
06/08/2022 11:47:53 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.6574081212789447 on epoch=199
06/08/2022 11:47:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=201
06/08/2022 11:47:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=202
06/08/2022 11:48:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=203
06/08/2022 11:48:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=204
06/08/2022 11:48:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=206
06/08/2022 11:48:08 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.659562647581133 on epoch=206
06/08/2022 11:48:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=207
06/08/2022 11:48:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=208
06/08/2022 11:48:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=209
06/08/2022 11:48:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=211
06/08/2022 11:48:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=212
06/08/2022 11:48:23 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.7230431822068056 on epoch=212
06/08/2022 11:48:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.17 on epoch=213
06/08/2022 11:48:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=214
06/08/2022 11:48:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=216
06/08/2022 11:48:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=217
06/08/2022 11:48:37 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=218
06/08/2022 11:48:39 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.7065077779363493 on epoch=218
06/08/2022 11:48:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=219
06/08/2022 11:48:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=221
06/08/2022 11:48:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=222
06/08/2022 11:48:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=223
06/08/2022 11:48:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=224
06/08/2022 11:48:54 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.7323019086176981 on epoch=224
06/08/2022 11:48:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=226
06/08/2022 11:49:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=227
06/08/2022 11:49:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=228
06/08/2022 11:49:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=229
06/08/2022 11:49:08 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=231
06/08/2022 11:49:10 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.7235590842778588 on epoch=231
06/08/2022 11:49:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=232
06/08/2022 11:49:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=233
06/08/2022 11:49:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=234
06/08/2022 11:49:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=236
06/08/2022 11:49:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=237
06/08/2022 11:49:26 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.7227182778849245 on epoch=237
06/08/2022 11:49:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=238
06/08/2022 11:49:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=239
06/08/2022 11:49:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=241
06/08/2022 11:49:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=242
06/08/2022 11:49:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=243
06/08/2022 11:49:41 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.7252112474922306 on epoch=243
06/08/2022 11:49:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=244
06/08/2022 11:49:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=246
06/08/2022 11:49:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=247
06/08/2022 11:49:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=248
06/08/2022 11:49:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=249
06/08/2022 11:49:56 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7549587667234725 on epoch=249
06/08/2022 11:49:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7506832272491468 -> 0.7549587667234725 on epoch=249, global_step=2000
06/08/2022 11:49:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=251
06/08/2022 11:50:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=252
06/08/2022 11:50:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=253
06/08/2022 11:50:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=254
06/08/2022 11:50:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.14 on epoch=256
06/08/2022 11:50:11 - INFO - __main__ - Global step 2050 Train loss 0.09 Classification-F1 0.7293595679012346 on epoch=256
06/08/2022 11:50:14 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=257
06/08/2022 11:50:16 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=258
06/08/2022 11:50:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=259
06/08/2022 11:50:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=261
06/08/2022 11:50:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=262
06/08/2022 11:50:26 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.6240738428238428 on epoch=262
06/08/2022 11:50:29 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.17 on epoch=263
06/08/2022 11:50:32 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=264
06/08/2022 11:50:34 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=266
06/08/2022 11:50:37 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=267
06/08/2022 11:50:40 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=268
06/08/2022 11:50:42 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.7248113207547169 on epoch=268
06/08/2022 11:50:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=269
06/08/2022 11:50:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=271
06/08/2022 11:50:50 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=272
06/08/2022 11:50:53 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=273
06/08/2022 11:50:55 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=274
06/08/2022 11:50:57 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7255818048244416 on epoch=274
06/08/2022 11:51:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.13 on epoch=276
06/08/2022 11:51:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=277
06/08/2022 11:51:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=278
06/08/2022 11:51:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=279
06/08/2022 11:51:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.14 on epoch=281
06/08/2022 11:51:13 - INFO - __main__ - Global step 2250 Train loss 0.09 Classification-F1 0.6989687743494033 on epoch=281
06/08/2022 11:51:15 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=282
06/08/2022 11:51:18 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.09 on epoch=283
06/08/2022 11:51:21 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=284
06/08/2022 11:51:23 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=286
06/08/2022 11:51:26 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.10 on epoch=287
06/08/2022 11:51:28 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7365182186234818 on epoch=287
06/08/2022 11:51:30 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=288
06/08/2022 11:51:33 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=289
06/08/2022 11:51:36 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=291
06/08/2022 11:51:38 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=292
06/08/2022 11:51:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=293
06/08/2022 11:51:43 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7292830695358303 on epoch=293
06/08/2022 11:51:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=294
06/08/2022 11:51:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=296
06/08/2022 11:51:51 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=297
06/08/2022 11:51:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=298
06/08/2022 11:51:56 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=299
06/08/2022 11:51:58 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7308871632451377 on epoch=299
06/08/2022 11:52:00 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=301
06/08/2022 11:52:03 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=302
06/08/2022 11:52:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=303
06/08/2022 11:52:08 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=304
06/08/2022 11:52:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=306
06/08/2022 11:52:13 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.7305683644765922 on epoch=306
06/08/2022 11:52:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=307
06/08/2022 11:52:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=308
06/08/2022 11:52:20 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=309
06/08/2022 11:52:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=311
06/08/2022 11:52:26 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=312
06/08/2022 11:52:27 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7235394467960883 on epoch=312
06/08/2022 11:52:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=313
06/08/2022 11:52:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=314
06/08/2022 11:52:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=316
06/08/2022 11:52:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=317
06/08/2022 11:52:41 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=318
06/08/2022 11:52:42 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7231170993141205 on epoch=318
06/08/2022 11:52:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=319
06/08/2022 11:52:48 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=321
06/08/2022 11:52:50 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
06/08/2022 11:52:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=323
06/08/2022 11:52:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=324
06/08/2022 11:52:58 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7245174867776146 on epoch=324
06/08/2022 11:53:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
06/08/2022 11:53:03 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=327
06/08/2022 11:53:06 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=328
06/08/2022 11:53:08 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.12 on epoch=329
06/08/2022 11:53:11 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=331
06/08/2022 11:53:13 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.7469433465085639 on epoch=331
06/08/2022 11:53:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=332
06/08/2022 11:53:18 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=333
06/08/2022 11:53:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=334
06/08/2022 11:53:24 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=336
06/08/2022 11:53:26 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=337
06/08/2022 11:53:28 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7300949245950248 on epoch=337
06/08/2022 11:53:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=338
06/08/2022 11:53:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=339
06/08/2022 11:53:36 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=341
06/08/2022 11:53:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.07 on epoch=342
06/08/2022 11:53:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
06/08/2022 11:53:43 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7111893281902925 on epoch=343
06/08/2022 11:53:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
06/08/2022 11:53:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=346
06/08/2022 11:53:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=347
06/08/2022 11:53:54 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=348
06/08/2022 11:53:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=349
06/08/2022 11:53:58 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7375055939138216 on epoch=349
06/08/2022 11:54:01 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=351
06/08/2022 11:54:03 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=352
06/08/2022 11:54:06 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=353
06/08/2022 11:54:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/08/2022 11:54:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.07 on epoch=356
06/08/2022 11:54:13 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6862162146506481 on epoch=356
06/08/2022 11:54:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.09 on epoch=357
06/08/2022 11:54:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=358
06/08/2022 11:54:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/08/2022 11:54:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
06/08/2022 11:54:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/08/2022 11:54:28 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.6713446651870297 on epoch=362
06/08/2022 11:54:31 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=363
06/08/2022 11:54:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=364
06/08/2022 11:54:36 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=366
06/08/2022 11:54:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/08/2022 11:54:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=368
06/08/2022 11:54:43 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7153573973312606 on epoch=368
06/08/2022 11:54:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=369
06/08/2022 11:54:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=371
06/08/2022 11:54:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=372
06/08/2022 11:54:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.07 on epoch=373
06/08/2022 11:54:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.08 on epoch=374
06/08/2022 11:54:58 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:54:58 - INFO - __main__ - Printing 3 examples
06/08/2022 11:54:58 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 11:54:58 - INFO - __main__ - ['others']
06/08/2022 11:54:58 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 11:54:58 - INFO - __main__ - ['others']
06/08/2022 11:54:58 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 11:54:58 - INFO - __main__ - ['others']
06/08/2022 11:54:58 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:54:58 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:54:58 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 11:54:58 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:54:58 - INFO - __main__ - Printing 3 examples
06/08/2022 11:54:58 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/08/2022 11:54:58 - INFO - __main__ - ['others']
06/08/2022 11:54:58 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/08/2022 11:54:58 - INFO - __main__ - ['others']
06/08/2022 11:54:58 - INFO - __main__ -  [emo] u oly first  no you no u
06/08/2022 11:54:58 - INFO - __main__ - ['others']
06/08/2022 11:54:58 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:54:58 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:54:58 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.6760469420164809 on epoch=374
06/08/2022 11:54:58 - INFO - __main__ - save last model!
06/08/2022 11:54:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 11:54:58 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 11:54:58 - INFO - __main__ - Printing 3 examples
06/08/2022 11:54:58 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 11:54:58 - INFO - __main__ - ['others']
06/08/2022 11:54:58 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 11:54:58 - INFO - __main__ - ['others']
06/08/2022 11:54:58 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 11:54:58 - INFO - __main__ - ['others']
06/08/2022 11:54:58 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:54:59 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 11:55:01 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:55:07 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 11:55:18 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 11:55:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 11:55:19 - INFO - __main__ - Starting training!
06/08/2022 11:56:25 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_13_0.4_8_predictions.txt
06/08/2022 11:56:25 - INFO - __main__ - Classification-F1 on test data: 0.2816
06/08/2022 11:56:25 - INFO - __main__ - prefix=emo_32_13, lr=0.4, bsz=8, dev_performance=0.7549587667234725, test_performance=0.281599761478914
06/08/2022 11:56:25 - INFO - __main__ - Running ... prefix=emo_32_13, lr=0.3, bsz=8 ...
06/08/2022 11:56:26 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:56:26 - INFO - __main__ - Printing 3 examples
06/08/2022 11:56:26 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 11:56:26 - INFO - __main__ - ['others']
06/08/2022 11:56:26 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 11:56:26 - INFO - __main__ - ['others']
06/08/2022 11:56:26 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 11:56:26 - INFO - __main__ - ['others']
06/08/2022 11:56:26 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:56:26 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:56:26 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 11:56:26 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 11:56:26 - INFO - __main__ - Printing 3 examples
06/08/2022 11:56:26 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/08/2022 11:56:26 - INFO - __main__ - ['others']
06/08/2022 11:56:26 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/08/2022 11:56:26 - INFO - __main__ - ['others']
06/08/2022 11:56:26 - INFO - __main__ -  [emo] u oly first  no you no u
06/08/2022 11:56:26 - INFO - __main__ - ['others']
06/08/2022 11:56:26 - INFO - __main__ - Tokenizing Input ...
06/08/2022 11:56:26 - INFO - __main__ - Tokenizing Output ...
06/08/2022 11:56:27 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 11:56:46 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 11:56:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 11:56:47 - INFO - __main__ - Starting training!
06/08/2022 11:56:50 - INFO - __main__ - Step 10 Global step 10 Train loss 2.85 on epoch=1
06/08/2022 11:56:53 - INFO - __main__ - Step 20 Global step 20 Train loss 1.58 on epoch=2
06/08/2022 11:56:55 - INFO - __main__ - Step 30 Global step 30 Train loss 1.21 on epoch=3
06/08/2022 11:56:58 - INFO - __main__ - Step 40 Global step 40 Train loss 0.91 on epoch=4
06/08/2022 11:57:00 - INFO - __main__ - Step 50 Global step 50 Train loss 1.06 on epoch=6
06/08/2022 11:57:02 - INFO - __main__ - Global step 50 Train loss 1.52 Classification-F1 0.21167325092391998 on epoch=6
06/08/2022 11:57:02 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.21167325092391998 on epoch=6, global_step=50
06/08/2022 11:57:05 - INFO - __main__ - Step 60 Global step 60 Train loss 1.03 on epoch=7
06/08/2022 11:57:07 - INFO - __main__ - Step 70 Global step 70 Train loss 0.98 on epoch=8
06/08/2022 11:57:10 - INFO - __main__ - Step 80 Global step 80 Train loss 0.94 on epoch=9
06/08/2022 11:57:13 - INFO - __main__ - Step 90 Global step 90 Train loss 0.85 on epoch=11
06/08/2022 11:57:15 - INFO - __main__ - Step 100 Global step 100 Train loss 0.91 on epoch=12
06/08/2022 11:57:17 - INFO - __main__ - Global step 100 Train loss 0.94 Classification-F1 0.2222222222222222 on epoch=12
06/08/2022 11:57:17 - INFO - __main__ - Saving model with best Classification-F1: 0.21167325092391998 -> 0.2222222222222222 on epoch=12, global_step=100
06/08/2022 11:57:20 - INFO - __main__ - Step 110 Global step 110 Train loss 0.81 on epoch=13
06/08/2022 11:57:22 - INFO - __main__ - Step 120 Global step 120 Train loss 0.85 on epoch=14
06/08/2022 11:57:25 - INFO - __main__ - Step 130 Global step 130 Train loss 0.87 on epoch=16
06/08/2022 11:57:28 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=17
06/08/2022 11:57:30 - INFO - __main__ - Step 150 Global step 150 Train loss 0.88 on epoch=18
06/08/2022 11:57:32 - INFO - __main__ - Global step 150 Train loss 0.84 Classification-F1 0.2815492713393477 on epoch=18
06/08/2022 11:57:32 - INFO - __main__ - Saving model with best Classification-F1: 0.2222222222222222 -> 0.2815492713393477 on epoch=18, global_step=150
06/08/2022 11:57:34 - INFO - __main__ - Step 160 Global step 160 Train loss 0.77 on epoch=19
06/08/2022 11:57:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.80 on epoch=21
06/08/2022 11:57:40 - INFO - __main__ - Step 180 Global step 180 Train loss 0.75 on epoch=22
06/08/2022 11:57:42 - INFO - __main__ - Step 190 Global step 190 Train loss 0.81 on epoch=23
06/08/2022 11:57:45 - INFO - __main__ - Step 200 Global step 200 Train loss 0.77 on epoch=24
06/08/2022 11:57:47 - INFO - __main__ - Global step 200 Train loss 0.78 Classification-F1 0.5798679550662629 on epoch=24
06/08/2022 11:57:47 - INFO - __main__ - Saving model with best Classification-F1: 0.2815492713393477 -> 0.5798679550662629 on epoch=24, global_step=200
06/08/2022 11:57:49 - INFO - __main__ - Step 210 Global step 210 Train loss 0.67 on epoch=26
06/08/2022 11:57:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.68 on epoch=27
06/08/2022 11:57:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.65 on epoch=28
06/08/2022 11:57:57 - INFO - __main__ - Step 240 Global step 240 Train loss 0.62 on epoch=29
06/08/2022 11:58:00 - INFO - __main__ - Step 250 Global step 250 Train loss 0.66 on epoch=31
06/08/2022 11:58:01 - INFO - __main__ - Global step 250 Train loss 0.66 Classification-F1 0.4380054286596343 on epoch=31
06/08/2022 11:58:04 - INFO - __main__ - Step 260 Global step 260 Train loss 0.62 on epoch=32
06/08/2022 11:58:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.61 on epoch=33
06/08/2022 11:58:09 - INFO - __main__ - Step 280 Global step 280 Train loss 0.53 on epoch=34
06/08/2022 11:58:11 - INFO - __main__ - Step 290 Global step 290 Train loss 0.62 on epoch=36
06/08/2022 11:58:14 - INFO - __main__ - Step 300 Global step 300 Train loss 0.67 on epoch=37
06/08/2022 11:58:16 - INFO - __main__ - Global step 300 Train loss 0.61 Classification-F1 0.46324459837446785 on epoch=37
06/08/2022 11:58:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.62 on epoch=38
06/08/2022 11:58:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.52 on epoch=39
06/08/2022 11:58:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.61 on epoch=41
06/08/2022 11:58:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.61 on epoch=42
06/08/2022 11:58:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.54 on epoch=43
06/08/2022 11:58:30 - INFO - __main__ - Global step 350 Train loss 0.58 Classification-F1 0.5179110798351552 on epoch=43
06/08/2022 11:58:33 - INFO - __main__ - Step 360 Global step 360 Train loss 0.46 on epoch=44
06/08/2022 11:58:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.52 on epoch=46
06/08/2022 11:58:38 - INFO - __main__ - Step 380 Global step 380 Train loss 0.44 on epoch=47
06/08/2022 11:58:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.50 on epoch=48
06/08/2022 11:58:43 - INFO - __main__ - Step 400 Global step 400 Train loss 0.45 on epoch=49
06/08/2022 11:58:45 - INFO - __main__ - Global step 400 Train loss 0.47 Classification-F1 0.6731193009118542 on epoch=49
06/08/2022 11:58:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5798679550662629 -> 0.6731193009118542 on epoch=49, global_step=400
06/08/2022 11:58:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.51 on epoch=51
06/08/2022 11:58:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.39 on epoch=52
06/08/2022 11:58:53 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=53
06/08/2022 11:58:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.43 on epoch=54
06/08/2022 11:58:58 - INFO - __main__ - Step 450 Global step 450 Train loss 0.42 on epoch=56
06/08/2022 11:58:59 - INFO - __main__ - Global step 450 Train loss 0.44 Classification-F1 0.4674307442798282 on epoch=56
06/08/2022 11:59:02 - INFO - __main__ - Step 460 Global step 460 Train loss 0.40 on epoch=57
06/08/2022 11:59:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.49 on epoch=58
06/08/2022 11:59:07 - INFO - __main__ - Step 480 Global step 480 Train loss 0.41 on epoch=59
06/08/2022 11:59:09 - INFO - __main__ - Step 490 Global step 490 Train loss 0.42 on epoch=61
06/08/2022 11:59:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.50 on epoch=62
06/08/2022 11:59:14 - INFO - __main__ - Global step 500 Train loss 0.44 Classification-F1 0.4428131223142229 on epoch=62
06/08/2022 11:59:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.45 on epoch=63
06/08/2022 11:59:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.29 on epoch=64
06/08/2022 11:59:22 - INFO - __main__ - Step 530 Global step 530 Train loss 0.31 on epoch=66
06/08/2022 11:59:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.42 on epoch=67
06/08/2022 11:59:27 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=68
06/08/2022 11:59:29 - INFO - __main__ - Global step 550 Train loss 0.37 Classification-F1 0.4237321588606779 on epoch=68
06/08/2022 11:59:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=69
06/08/2022 11:59:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.31 on epoch=71
06/08/2022 11:59:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.37 on epoch=72
06/08/2022 11:59:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=73
06/08/2022 11:59:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.31 on epoch=74
06/08/2022 11:59:43 - INFO - __main__ - Global step 600 Train loss 0.32 Classification-F1 0.5204179988493715 on epoch=74
06/08/2022 11:59:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.27 on epoch=76
06/08/2022 11:59:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.35 on epoch=77
06/08/2022 11:59:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.41 on epoch=78
06/08/2022 11:59:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=79
06/08/2022 11:59:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=81
06/08/2022 11:59:58 - INFO - __main__ - Global step 650 Train loss 0.31 Classification-F1 0.554671201814059 on epoch=81
06/08/2022 12:00:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.33 on epoch=82
06/08/2022 12:00:03 - INFO - __main__ - Step 670 Global step 670 Train loss 0.31 on epoch=83
06/08/2022 12:00:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.28 on epoch=84
06/08/2022 12:00:08 - INFO - __main__ - Step 690 Global step 690 Train loss 0.34 on epoch=86
06/08/2022 12:00:11 - INFO - __main__ - Step 700 Global step 700 Train loss 0.25 on epoch=87
06/08/2022 12:00:13 - INFO - __main__ - Global step 700 Train loss 0.30 Classification-F1 0.6100939920294759 on epoch=87
06/08/2022 12:00:15 - INFO - __main__ - Step 710 Global step 710 Train loss 0.38 on epoch=88
06/08/2022 12:00:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.25 on epoch=89
06/08/2022 12:00:20 - INFO - __main__ - Step 730 Global step 730 Train loss 0.31 on epoch=91
06/08/2022 12:00:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.27 on epoch=92
06/08/2022 12:00:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.30 on epoch=93
06/08/2022 12:00:27 - INFO - __main__ - Global step 750 Train loss 0.30 Classification-F1 0.5439894242068155 on epoch=93
06/08/2022 12:00:30 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=94
06/08/2022 12:00:33 - INFO - __main__ - Step 770 Global step 770 Train loss 0.26 on epoch=96
06/08/2022 12:00:35 - INFO - __main__ - Step 780 Global step 780 Train loss 0.25 on epoch=97
06/08/2022 12:00:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.32 on epoch=98
06/08/2022 12:00:40 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=99
06/08/2022 12:00:42 - INFO - __main__ - Global step 800 Train loss 0.25 Classification-F1 0.6010996460043685 on epoch=99
06/08/2022 12:00:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.27 on epoch=101
06/08/2022 12:00:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=102
06/08/2022 12:00:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=103
06/08/2022 12:00:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=104
06/08/2022 12:00:55 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=106
06/08/2022 12:00:57 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.5898720329237022 on epoch=106
06/08/2022 12:00:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=107
06/08/2022 12:01:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.26 on epoch=108
06/08/2022 12:01:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.28 on epoch=109
06/08/2022 12:01:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.27 on epoch=111
06/08/2022 12:01:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=112
06/08/2022 12:01:11 - INFO - __main__ - Global step 900 Train loss 0.25 Classification-F1 0.5062122210714622 on epoch=112
06/08/2022 12:01:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.26 on epoch=113
06/08/2022 12:01:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=114
06/08/2022 12:01:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=116
06/08/2022 12:01:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.22 on epoch=117
06/08/2022 12:01:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.26 on epoch=118
06/08/2022 12:01:25 - INFO - __main__ - Global step 950 Train loss 0.22 Classification-F1 0.559478912426076 on epoch=118
06/08/2022 12:01:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.22 on epoch=119
06/08/2022 12:01:30 - INFO - __main__ - Step 970 Global step 970 Train loss 0.23 on epoch=121
06/08/2022 12:01:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.30 on epoch=122
06/08/2022 12:01:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.30 on epoch=123
06/08/2022 12:01:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=124
06/08/2022 12:01:40 - INFO - __main__ - Global step 1000 Train loss 0.26 Classification-F1 0.693020594965675 on epoch=124
06/08/2022 12:01:40 - INFO - __main__ - Saving model with best Classification-F1: 0.6731193009118542 -> 0.693020594965675 on epoch=124, global_step=1000
06/08/2022 12:01:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=126
06/08/2022 12:01:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.21 on epoch=127
06/08/2022 12:01:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.32 on epoch=128
06/08/2022 12:01:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=129
06/08/2022 12:01:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.22 on epoch=131
06/08/2022 12:01:54 - INFO - __main__ - Global step 1050 Train loss 0.22 Classification-F1 0.4700774042609677 on epoch=131
06/08/2022 12:01:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=132
06/08/2022 12:01:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.22 on epoch=133
06/08/2022 12:02:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=134
06/08/2022 12:02:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=136
06/08/2022 12:02:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.19 on epoch=137
06/08/2022 12:02:08 - INFO - __main__ - Global step 1100 Train loss 0.21 Classification-F1 0.5585986288551215 on epoch=137
06/08/2022 12:02:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.30 on epoch=138
06/08/2022 12:02:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=139
06/08/2022 12:02:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.19 on epoch=141
06/08/2022 12:02:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.23 on epoch=142
06/08/2022 12:02:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.20 on epoch=143
06/08/2022 12:02:24 - INFO - __main__ - Global step 1150 Train loss 0.21 Classification-F1 0.5929931545750755 on epoch=143
06/08/2022 12:02:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=144
06/08/2022 12:02:29 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=146
06/08/2022 12:02:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=147
06/08/2022 12:02:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=148
06/08/2022 12:02:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.24 on epoch=149
06/08/2022 12:02:38 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.5700833333333334 on epoch=149
06/08/2022 12:02:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=151
06/08/2022 12:02:44 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.18 on epoch=152
06/08/2022 12:02:46 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.23 on epoch=153
06/08/2022 12:02:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=154
06/08/2022 12:02:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=156
06/08/2022 12:02:53 - INFO - __main__ - Global step 1250 Train loss 0.17 Classification-F1 0.5829094698497683 on epoch=156
06/08/2022 12:02:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=157
06/08/2022 12:02:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=158
06/08/2022 12:03:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=159
06/08/2022 12:03:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=161
06/08/2022 12:03:06 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.15 on epoch=162
06/08/2022 12:03:07 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.4652143428013866 on epoch=162
06/08/2022 12:03:10 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=163
06/08/2022 12:03:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=164
06/08/2022 12:03:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=166
06/08/2022 12:03:17 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.16 on epoch=167
06/08/2022 12:03:20 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.15 on epoch=168
06/08/2022 12:03:22 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.5837657053431701 on epoch=168
06/08/2022 12:03:24 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=169
06/08/2022 12:03:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.20 on epoch=171
06/08/2022 12:03:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=172
06/08/2022 12:03:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=173
06/08/2022 12:03:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=174
06/08/2022 12:03:36 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.5527398729477765 on epoch=174
06/08/2022 12:03:39 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.17 on epoch=176
06/08/2022 12:03:41 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=177
06/08/2022 12:03:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.19 on epoch=178
06/08/2022 12:03:46 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=179
06/08/2022 12:03:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=181
06/08/2022 12:03:51 - INFO - __main__ - Global step 1450 Train loss 0.15 Classification-F1 0.589231799753217 on epoch=181
06/08/2022 12:03:53 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=182
06/08/2022 12:03:55 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=183
06/08/2022 12:03:58 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=184
06/08/2022 12:04:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=186
06/08/2022 12:04:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.22 on epoch=187
06/08/2022 12:04:05 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.5777354827355266 on epoch=187
06/08/2022 12:04:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=188
06/08/2022 12:04:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=189
06/08/2022 12:04:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=191
06/08/2022 12:04:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=192
06/08/2022 12:04:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=193
06/08/2022 12:04:20 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.5883664807179239 on epoch=193
06/08/2022 12:04:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=194
06/08/2022 12:04:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=196
06/08/2022 12:04:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=197
06/08/2022 12:04:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=198
06/08/2022 12:04:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=199
06/08/2022 12:04:35 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.5585197505197506 on epoch=199
06/08/2022 12:04:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=201
06/08/2022 12:04:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=202
06/08/2022 12:04:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=203
06/08/2022 12:04:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=204
06/08/2022 12:04:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=206
06/08/2022 12:04:50 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.5695238095238094 on epoch=206
06/08/2022 12:04:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=207
06/08/2022 12:04:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=208
06/08/2022 12:04:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=209
06/08/2022 12:05:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.14 on epoch=211
06/08/2022 12:05:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=212
06/08/2022 12:05:04 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.7179931288644659 on epoch=212
06/08/2022 12:05:04 - INFO - __main__ - Saving model with best Classification-F1: 0.693020594965675 -> 0.7179931288644659 on epoch=212, global_step=1700
06/08/2022 12:05:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=213
06/08/2022 12:05:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=214
06/08/2022 12:05:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.13 on epoch=216
06/08/2022 12:05:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=217
06/08/2022 12:05:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=218
06/08/2022 12:05:19 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.5942063492063492 on epoch=218
06/08/2022 12:05:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=219
06/08/2022 12:05:24 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=221
06/08/2022 12:05:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=222
06/08/2022 12:05:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=223
06/08/2022 12:05:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=224
06/08/2022 12:05:33 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.5597775392003086 on epoch=224
06/08/2022 12:05:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=226
06/08/2022 12:05:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=227
06/08/2022 12:05:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=228
06/08/2022 12:05:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=229
06/08/2022 12:05:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=231
06/08/2022 12:05:49 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.6795386594354054 on epoch=231
06/08/2022 12:05:51 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=232
06/08/2022 12:05:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=233
06/08/2022 12:05:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=234
06/08/2022 12:05:59 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=236
06/08/2022 12:06:02 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=237
06/08/2022 12:06:04 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.7243031121559347 on epoch=237
06/08/2022 12:06:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7179931288644659 -> 0.7243031121559347 on epoch=237, global_step=1900
06/08/2022 12:06:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=238
06/08/2022 12:06:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=239
06/08/2022 12:06:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=241
06/08/2022 12:06:14 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=242
06/08/2022 12:06:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=243
06/08/2022 12:06:19 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.6940974932778212 on epoch=243
06/08/2022 12:06:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=244
06/08/2022 12:06:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=246
06/08/2022 12:06:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=247
06/08/2022 12:06:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=248
06/08/2022 12:06:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=249
06/08/2022 12:06:34 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.6699098848011891 on epoch=249
06/08/2022 12:06:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=251
06/08/2022 12:06:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=252
06/08/2022 12:06:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=253
06/08/2022 12:06:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=254
06/08/2022 12:06:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=256
06/08/2022 12:06:49 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.6535529250300223 on epoch=256
06/08/2022 12:06:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=257
06/08/2022 12:06:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=258
06/08/2022 12:06:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=259
06/08/2022 12:07:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.11 on epoch=261
06/08/2022 12:07:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=262
06/08/2022 12:07:05 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.5649687450230929 on epoch=262
06/08/2022 12:07:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=263
06/08/2022 12:07:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=264
06/08/2022 12:07:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=266
06/08/2022 12:07:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=267
06/08/2022 12:07:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.17 on epoch=268
06/08/2022 12:07:20 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.6671611627106984 on epoch=268
06/08/2022 12:07:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=269
06/08/2022 12:07:25 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=271
06/08/2022 12:07:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=272
06/08/2022 12:07:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=273
06/08/2022 12:07:33 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=274
06/08/2022 12:07:35 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.5669921925454607 on epoch=274
06/08/2022 12:07:38 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=276
06/08/2022 12:07:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=277
06/08/2022 12:07:43 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=278
06/08/2022 12:07:46 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=279
06/08/2022 12:07:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=281
06/08/2022 12:07:50 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.5598032147249672 on epoch=281
06/08/2022 12:07:53 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=282
06/08/2022 12:07:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=283
06/08/2022 12:07:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=284
06/08/2022 12:08:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=286
06/08/2022 12:08:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=287
06/08/2022 12:08:06 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.5478464590964591 on epoch=287
06/08/2022 12:08:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=288
06/08/2022 12:08:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=289
06/08/2022 12:08:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=291
06/08/2022 12:08:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=292
06/08/2022 12:08:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.14 on epoch=293
06/08/2022 12:08:21 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.5593352619736419 on epoch=293
06/08/2022 12:08:23 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=294
06/08/2022 12:08:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=296
06/08/2022 12:08:29 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=297
06/08/2022 12:08:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=298
06/08/2022 12:08:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=299
06/08/2022 12:08:37 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.5275391376993207 on epoch=299
06/08/2022 12:08:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=301
06/08/2022 12:08:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
06/08/2022 12:08:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=303
06/08/2022 12:08:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=304
06/08/2022 12:08:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=306
06/08/2022 12:08:52 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6686101174096496 on epoch=306
06/08/2022 12:08:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.13 on epoch=307
06/08/2022 12:08:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=308
06/08/2022 12:09:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=309
06/08/2022 12:09:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=311
06/08/2022 12:09:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=312
06/08/2022 12:09:07 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.6984174370826914 on epoch=312
06/08/2022 12:09:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=313
06/08/2022 12:09:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/08/2022 12:09:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=316
06/08/2022 12:09:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=317
06/08/2022 12:09:20 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=318
06/08/2022 12:09:22 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.6988839285714286 on epoch=318
06/08/2022 12:09:24 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=319
06/08/2022 12:09:27 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=321
06/08/2022 12:09:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=322
06/08/2022 12:09:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=323
06/08/2022 12:09:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=324
06/08/2022 12:09:36 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7203501543717834 on epoch=324
06/08/2022 12:09:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
06/08/2022 12:09:41 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=327
06/08/2022 12:09:44 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=328
06/08/2022 12:09:47 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=329
06/08/2022 12:09:49 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
06/08/2022 12:09:51 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7287179487179487 on epoch=331
06/08/2022 12:09:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7243031121559347 -> 0.7287179487179487 on epoch=331, global_step=2650
06/08/2022 12:09:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=332
06/08/2022 12:09:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
06/08/2022 12:09:59 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=334
06/08/2022 12:10:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=336
06/08/2022 12:10:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=337
06/08/2022 12:10:06 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.5751927317272356 on epoch=337
06/08/2022 12:10:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/08/2022 12:10:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
06/08/2022 12:10:14 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
06/08/2022 12:10:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=342
06/08/2022 12:10:19 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=343
06/08/2022 12:10:22 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6948517277838714 on epoch=343
06/08/2022 12:10:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=344
06/08/2022 12:10:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
06/08/2022 12:10:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=347
06/08/2022 12:10:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=348
06/08/2022 12:10:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
06/08/2022 12:10:37 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6886311324603743 on epoch=349
06/08/2022 12:10:40 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
06/08/2022 12:10:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
06/08/2022 12:10:45 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
06/08/2022 12:10:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.08 on epoch=354
06/08/2022 12:10:51 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=356
06/08/2022 12:10:53 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7016564517568653 on epoch=356
06/08/2022 12:10:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=357
06/08/2022 12:10:58 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.11 on epoch=358
06/08/2022 12:11:01 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=359
06/08/2022 12:11:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=361
06/08/2022 12:11:06 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=362
06/08/2022 12:11:08 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.5502809975412715 on epoch=362
06/08/2022 12:11:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=363
06/08/2022 12:11:14 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=364
06/08/2022 12:11:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
06/08/2022 12:11:19 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/08/2022 12:11:22 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=368
06/08/2022 12:11:24 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6795639613613795 on epoch=368
06/08/2022 12:11:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=369
06/08/2022 12:11:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
06/08/2022 12:11:32 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=372
06/08/2022 12:11:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=373
06/08/2022 12:11:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
06/08/2022 12:11:38 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 12:11:38 - INFO - __main__ - Printing 3 examples
06/08/2022 12:11:38 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 12:11:38 - INFO - __main__ - ['others']
06/08/2022 12:11:38 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 12:11:38 - INFO - __main__ - ['others']
06/08/2022 12:11:38 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 12:11:38 - INFO - __main__ - ['others']
06/08/2022 12:11:38 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:11:38 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:11:38 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 12:11:38 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 12:11:38 - INFO - __main__ - Printing 3 examples
06/08/2022 12:11:38 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/08/2022 12:11:38 - INFO - __main__ - ['others']
06/08/2022 12:11:38 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/08/2022 12:11:38 - INFO - __main__ - ['others']
06/08/2022 12:11:38 - INFO - __main__ -  [emo] u oly first  no you no u
06/08/2022 12:11:38 - INFO - __main__ - ['others']
06/08/2022 12:11:38 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:11:39 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:11:39 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 12:11:39 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7029085806446715 on epoch=374
06/08/2022 12:11:39 - INFO - __main__ - save last model!
06/08/2022 12:11:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 12:11:39 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 12:11:39 - INFO - __main__ - Printing 3 examples
06/08/2022 12:11:39 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 12:11:39 - INFO - __main__ - ['others']
06/08/2022 12:11:39 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 12:11:39 - INFO - __main__ - ['others']
06/08/2022 12:11:39 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 12:11:39 - INFO - __main__ - ['others']
06/08/2022 12:11:39 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:11:42 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:11:48 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 12:11:58 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 12:11:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 12:11:58 - INFO - __main__ - Starting training!
06/08/2022 12:13:24 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_13_0.3_8_predictions.txt
06/08/2022 12:13:24 - INFO - __main__ - Classification-F1 on test data: 0.3381
06/08/2022 12:13:24 - INFO - __main__ - prefix=emo_32_13, lr=0.3, bsz=8, dev_performance=0.7287179487179487, test_performance=0.3381447600968437
06/08/2022 12:13:24 - INFO - __main__ - Running ... prefix=emo_32_13, lr=0.2, bsz=8 ...
06/08/2022 12:13:25 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 12:13:25 - INFO - __main__ - Printing 3 examples
06/08/2022 12:13:25 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 12:13:25 - INFO - __main__ - ['others']
06/08/2022 12:13:25 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 12:13:25 - INFO - __main__ - ['others']
06/08/2022 12:13:25 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 12:13:25 - INFO - __main__ - ['others']
06/08/2022 12:13:25 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:13:25 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:13:25 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 12:13:25 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 12:13:25 - INFO - __main__ - Printing 3 examples
06/08/2022 12:13:25 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/08/2022 12:13:25 - INFO - __main__ - ['others']
06/08/2022 12:13:25 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/08/2022 12:13:25 - INFO - __main__ - ['others']
06/08/2022 12:13:25 - INFO - __main__ -  [emo] u oly first  no you no u
06/08/2022 12:13:25 - INFO - __main__ - ['others']
06/08/2022 12:13:25 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:13:25 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:13:26 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 12:13:41 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 12:13:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 12:13:42 - INFO - __main__ - Starting training!
06/08/2022 12:13:46 - INFO - __main__ - Step 10 Global step 10 Train loss 3.24 on epoch=1
06/08/2022 12:13:49 - INFO - __main__ - Step 20 Global step 20 Train loss 1.81 on epoch=2
06/08/2022 12:13:51 - INFO - __main__ - Step 30 Global step 30 Train loss 1.48 on epoch=3
06/08/2022 12:13:54 - INFO - __main__ - Step 40 Global step 40 Train loss 1.11 on epoch=4
06/08/2022 12:13:57 - INFO - __main__ - Step 50 Global step 50 Train loss 1.12 on epoch=6
06/08/2022 12:13:58 - INFO - __main__ - Global step 50 Train loss 1.75 Classification-F1 0.17551020408163265 on epoch=6
06/08/2022 12:13:58 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.17551020408163265 on epoch=6, global_step=50
06/08/2022 12:14:01 - INFO - __main__ - Step 60 Global step 60 Train loss 0.99 on epoch=7
06/08/2022 12:14:04 - INFO - __main__ - Step 70 Global step 70 Train loss 1.01 on epoch=8
06/08/2022 12:14:06 - INFO - __main__ - Step 80 Global step 80 Train loss 0.89 on epoch=9
06/08/2022 12:14:09 - INFO - __main__ - Step 90 Global step 90 Train loss 0.98 on epoch=11
06/08/2022 12:14:12 - INFO - __main__ - Step 100 Global step 100 Train loss 0.82 on epoch=12
06/08/2022 12:14:14 - INFO - __main__ - Global step 100 Train loss 0.94 Classification-F1 0.11578044596912522 on epoch=12
06/08/2022 12:14:16 - INFO - __main__ - Step 110 Global step 110 Train loss 0.88 on epoch=13
06/08/2022 12:14:19 - INFO - __main__ - Step 120 Global step 120 Train loss 0.96 on epoch=14
06/08/2022 12:14:21 - INFO - __main__ - Step 130 Global step 130 Train loss 0.85 on epoch=16
06/08/2022 12:14:24 - INFO - __main__ - Step 140 Global step 140 Train loss 0.81 on epoch=17
06/08/2022 12:14:27 - INFO - __main__ - Step 150 Global step 150 Train loss 0.83 on epoch=18
06/08/2022 12:14:29 - INFO - __main__ - Global step 150 Train loss 0.87 Classification-F1 0.21789158553864435 on epoch=18
06/08/2022 12:14:29 - INFO - __main__ - Saving model with best Classification-F1: 0.17551020408163265 -> 0.21789158553864435 on epoch=18, global_step=150
06/08/2022 12:14:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.89 on epoch=19
06/08/2022 12:14:34 - INFO - __main__ - Step 170 Global step 170 Train loss 0.77 on epoch=21
06/08/2022 12:14:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.72 on epoch=22
06/08/2022 12:14:39 - INFO - __main__ - Step 190 Global step 190 Train loss 0.74 on epoch=23
06/08/2022 12:14:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.81 on epoch=24
06/08/2022 12:14:44 - INFO - __main__ - Global step 200 Train loss 0.79 Classification-F1 0.4018583042973287 on epoch=24
06/08/2022 12:14:44 - INFO - __main__ - Saving model with best Classification-F1: 0.21789158553864435 -> 0.4018583042973287 on epoch=24, global_step=200
06/08/2022 12:14:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.87 on epoch=26
06/08/2022 12:14:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.70 on epoch=27
06/08/2022 12:14:52 - INFO - __main__ - Step 230 Global step 230 Train loss 0.77 on epoch=28
06/08/2022 12:14:55 - INFO - __main__ - Step 240 Global step 240 Train loss 0.79 on epoch=29
06/08/2022 12:14:58 - INFO - __main__ - Step 250 Global step 250 Train loss 0.74 on epoch=31
06/08/2022 12:14:59 - INFO - __main__ - Global step 250 Train loss 0.78 Classification-F1 0.2936781790298523 on epoch=31
06/08/2022 12:15:02 - INFO - __main__ - Step 260 Global step 260 Train loss 0.75 on epoch=32
06/08/2022 12:15:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.74 on epoch=33
06/08/2022 12:15:07 - INFO - __main__ - Step 280 Global step 280 Train loss 0.67 on epoch=34
06/08/2022 12:15:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.80 on epoch=36
06/08/2022 12:15:13 - INFO - __main__ - Step 300 Global step 300 Train loss 0.77 on epoch=37
06/08/2022 12:15:15 - INFO - __main__ - Global step 300 Train loss 0.75 Classification-F1 0.3020070207570208 on epoch=37
06/08/2022 12:15:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.69 on epoch=38
06/08/2022 12:15:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.64 on epoch=39
06/08/2022 12:15:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.65 on epoch=41
06/08/2022 12:15:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.68 on epoch=42
06/08/2022 12:15:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.77 on epoch=43
06/08/2022 12:15:30 - INFO - __main__ - Global step 350 Train loss 0.69 Classification-F1 0.49341924997097414 on epoch=43
06/08/2022 12:15:30 - INFO - __main__ - Saving model with best Classification-F1: 0.4018583042973287 -> 0.49341924997097414 on epoch=43, global_step=350
06/08/2022 12:15:33 - INFO - __main__ - Step 360 Global step 360 Train loss 0.64 on epoch=44
06/08/2022 12:15:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.63 on epoch=46
06/08/2022 12:15:38 - INFO - __main__ - Step 380 Global step 380 Train loss 0.52 on epoch=47
06/08/2022 12:15:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.59 on epoch=48
06/08/2022 12:15:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.58 on epoch=49
06/08/2022 12:15:46 - INFO - __main__ - Global step 400 Train loss 0.59 Classification-F1 0.588601598173516 on epoch=49
06/08/2022 12:15:46 - INFO - __main__ - Saving model with best Classification-F1: 0.49341924997097414 -> 0.588601598173516 on epoch=49, global_step=400
06/08/2022 12:15:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.59 on epoch=51
06/08/2022 12:15:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.56 on epoch=52
06/08/2022 12:15:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.72 on epoch=53
06/08/2022 12:15:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.55 on epoch=54
06/08/2022 12:15:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.52 on epoch=56
06/08/2022 12:16:01 - INFO - __main__ - Global step 450 Train loss 0.59 Classification-F1 0.4538979384857391 on epoch=56
06/08/2022 12:16:04 - INFO - __main__ - Step 460 Global step 460 Train loss 0.63 on epoch=57
06/08/2022 12:16:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.58 on epoch=58
06/08/2022 12:16:10 - INFO - __main__ - Step 480 Global step 480 Train loss 0.42 on epoch=59
06/08/2022 12:16:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.45 on epoch=61
06/08/2022 12:16:15 - INFO - __main__ - Step 500 Global step 500 Train loss 0.52 on epoch=62
06/08/2022 12:16:17 - INFO - __main__ - Global step 500 Train loss 0.52 Classification-F1 0.5563125425046149 on epoch=62
06/08/2022 12:16:19 - INFO - __main__ - Step 510 Global step 510 Train loss 0.53 on epoch=63
06/08/2022 12:16:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.47 on epoch=64
06/08/2022 12:16:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.49 on epoch=66
06/08/2022 12:16:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.40 on epoch=67
06/08/2022 12:16:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.53 on epoch=68
06/08/2022 12:16:33 - INFO - __main__ - Global step 550 Train loss 0.49 Classification-F1 0.5683294716278224 on epoch=68
06/08/2022 12:16:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.50 on epoch=69
06/08/2022 12:16:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.47 on epoch=71
06/08/2022 12:16:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.49 on epoch=72
06/08/2022 12:16:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.59 on epoch=73
06/08/2022 12:16:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.45 on epoch=74
06/08/2022 12:16:48 - INFO - __main__ - Global step 600 Train loss 0.50 Classification-F1 0.5354545454545454 on epoch=74
06/08/2022 12:16:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.46 on epoch=76
06/08/2022 12:16:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.40 on epoch=77
06/08/2022 12:16:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.41 on epoch=78
06/08/2022 12:16:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.39 on epoch=79
06/08/2022 12:17:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.44 on epoch=81
06/08/2022 12:17:04 - INFO - __main__ - Global step 650 Train loss 0.42 Classification-F1 0.5327347728211549 on epoch=81
06/08/2022 12:17:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.48 on epoch=82
06/08/2022 12:17:09 - INFO - __main__ - Step 670 Global step 670 Train loss 0.39 on epoch=83
06/08/2022 12:17:12 - INFO - __main__ - Step 680 Global step 680 Train loss 0.38 on epoch=84
06/08/2022 12:17:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.45 on epoch=86
06/08/2022 12:17:17 - INFO - __main__ - Step 700 Global step 700 Train loss 0.42 on epoch=87
06/08/2022 12:17:19 - INFO - __main__ - Global step 700 Train loss 0.42 Classification-F1 0.6094398185453787 on epoch=87
06/08/2022 12:17:19 - INFO - __main__ - Saving model with best Classification-F1: 0.588601598173516 -> 0.6094398185453787 on epoch=87, global_step=700
06/08/2022 12:17:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.43 on epoch=88
06/08/2022 12:17:24 - INFO - __main__ - Step 720 Global step 720 Train loss 0.39 on epoch=89
06/08/2022 12:17:27 - INFO - __main__ - Step 730 Global step 730 Train loss 0.42 on epoch=91
06/08/2022 12:17:30 - INFO - __main__ - Step 740 Global step 740 Train loss 0.44 on epoch=92
06/08/2022 12:17:32 - INFO - __main__ - Step 750 Global step 750 Train loss 0.40 on epoch=93
06/08/2022 12:17:34 - INFO - __main__ - Global step 750 Train loss 0.42 Classification-F1 0.6463912282598684 on epoch=93
06/08/2022 12:17:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6094398185453787 -> 0.6463912282598684 on epoch=93, global_step=750
06/08/2022 12:17:37 - INFO - __main__ - Step 760 Global step 760 Train loss 0.43 on epoch=94
06/08/2022 12:17:40 - INFO - __main__ - Step 770 Global step 770 Train loss 0.40 on epoch=96
06/08/2022 12:17:42 - INFO - __main__ - Step 780 Global step 780 Train loss 0.32 on epoch=97
06/08/2022 12:17:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.38 on epoch=98
06/08/2022 12:17:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=99
06/08/2022 12:17:49 - INFO - __main__ - Global step 800 Train loss 0.36 Classification-F1 0.6056247554454155 on epoch=99
06/08/2022 12:17:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.36 on epoch=101
06/08/2022 12:17:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.36 on epoch=102
06/08/2022 12:17:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.40 on epoch=103
06/08/2022 12:18:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.33 on epoch=104
06/08/2022 12:18:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.31 on epoch=106
06/08/2022 12:18:04 - INFO - __main__ - Global step 850 Train loss 0.35 Classification-F1 0.7350159968755794 on epoch=106
06/08/2022 12:18:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6463912282598684 -> 0.7350159968755794 on epoch=106, global_step=850
06/08/2022 12:18:07 - INFO - __main__ - Step 860 Global step 860 Train loss 0.32 on epoch=107
06/08/2022 12:18:10 - INFO - __main__ - Step 870 Global step 870 Train loss 0.38 on epoch=108
06/08/2022 12:18:12 - INFO - __main__ - Step 880 Global step 880 Train loss 0.27 on epoch=109
06/08/2022 12:18:15 - INFO - __main__ - Step 890 Global step 890 Train loss 0.32 on epoch=111
06/08/2022 12:18:18 - INFO - __main__ - Step 900 Global step 900 Train loss 0.32 on epoch=112
06/08/2022 12:18:20 - INFO - __main__ - Global step 900 Train loss 0.32 Classification-F1 0.5459388185654008 on epoch=112
06/08/2022 12:18:22 - INFO - __main__ - Step 910 Global step 910 Train loss 0.29 on epoch=113
06/08/2022 12:18:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.25 on epoch=114
06/08/2022 12:18:27 - INFO - __main__ - Step 930 Global step 930 Train loss 0.32 on epoch=116
06/08/2022 12:18:30 - INFO - __main__ - Step 940 Global step 940 Train loss 0.25 on epoch=117
06/08/2022 12:18:32 - INFO - __main__ - Step 950 Global step 950 Train loss 0.38 on epoch=118
06/08/2022 12:18:34 - INFO - __main__ - Global step 950 Train loss 0.30 Classification-F1 0.6417462000706964 on epoch=118
06/08/2022 12:18:37 - INFO - __main__ - Step 960 Global step 960 Train loss 0.21 on epoch=119
06/08/2022 12:18:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.25 on epoch=121
06/08/2022 12:18:42 - INFO - __main__ - Step 980 Global step 980 Train loss 0.27 on epoch=122
06/08/2022 12:18:44 - INFO - __main__ - Step 990 Global step 990 Train loss 0.35 on epoch=123
06/08/2022 12:18:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.26 on epoch=124
06/08/2022 12:18:49 - INFO - __main__ - Global step 1000 Train loss 0.27 Classification-F1 0.6918187007693014 on epoch=124
06/08/2022 12:18:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.27 on epoch=126
06/08/2022 12:18:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.30 on epoch=127
06/08/2022 12:18:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.30 on epoch=128
06/08/2022 12:19:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.28 on epoch=129
06/08/2022 12:19:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.29 on epoch=131
06/08/2022 12:19:04 - INFO - __main__ - Global step 1050 Train loss 0.29 Classification-F1 0.611803925325279 on epoch=131
06/08/2022 12:19:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.21 on epoch=132
06/08/2022 12:19:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.27 on epoch=133
06/08/2022 12:19:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.25 on epoch=134
06/08/2022 12:19:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.26 on epoch=136
06/08/2022 12:19:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.24 on epoch=137
06/08/2022 12:19:19 - INFO - __main__ - Global step 1100 Train loss 0.25 Classification-F1 0.7406597774244833 on epoch=137
06/08/2022 12:19:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7350159968755794 -> 0.7406597774244833 on epoch=137, global_step=1100
06/08/2022 12:19:21 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.22 on epoch=138
06/08/2022 12:19:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.30 on epoch=139
06/08/2022 12:19:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.26 on epoch=141
06/08/2022 12:19:29 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.27 on epoch=142
06/08/2022 12:19:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.30 on epoch=143
06/08/2022 12:19:34 - INFO - __main__ - Global step 1150 Train loss 0.27 Classification-F1 0.5951282051282052 on epoch=143
06/08/2022 12:19:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.23 on epoch=144
06/08/2022 12:19:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.22 on epoch=146
06/08/2022 12:19:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.28 on epoch=147
06/08/2022 12:19:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.29 on epoch=148
06/08/2022 12:19:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.21 on epoch=149
06/08/2022 12:19:49 - INFO - __main__ - Global step 1200 Train loss 0.25 Classification-F1 0.710217920863783 on epoch=149
06/08/2022 12:19:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.25 on epoch=151
06/08/2022 12:19:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.32 on epoch=152
06/08/2022 12:19:57 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.28 on epoch=153
06/08/2022 12:19:59 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.20 on epoch=154
06/08/2022 12:20:02 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.24 on epoch=156
06/08/2022 12:20:04 - INFO - __main__ - Global step 1250 Train loss 0.26 Classification-F1 0.7286816269284713 on epoch=156
06/08/2022 12:20:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.23 on epoch=157
06/08/2022 12:20:09 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.17 on epoch=158
06/08/2022 12:20:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.25 on epoch=159
06/08/2022 12:20:14 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=161
06/08/2022 12:20:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.16 on epoch=162
06/08/2022 12:20:19 - INFO - __main__ - Global step 1300 Train loss 0.19 Classification-F1 0.5679388300077955 on epoch=162
06/08/2022 12:20:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.19 on epoch=163
06/08/2022 12:20:24 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.24 on epoch=164
06/08/2022 12:20:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.20 on epoch=166
06/08/2022 12:20:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.17 on epoch=167
06/08/2022 12:20:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.24 on epoch=168
06/08/2022 12:20:33 - INFO - __main__ - Global step 1350 Train loss 0.21 Classification-F1 0.7311089317924241 on epoch=168
06/08/2022 12:20:36 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.13 on epoch=169
06/08/2022 12:20:39 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.16 on epoch=171
06/08/2022 12:20:41 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.19 on epoch=172
06/08/2022 12:20:44 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.18 on epoch=173
06/08/2022 12:20:47 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=174
06/08/2022 12:20:49 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.6907825137314432 on epoch=174
06/08/2022 12:20:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=176
06/08/2022 12:20:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.23 on epoch=177
06/08/2022 12:20:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.16 on epoch=178
06/08/2022 12:20:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=179
06/08/2022 12:21:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=181
06/08/2022 12:21:03 - INFO - __main__ - Global step 1450 Train loss 0.16 Classification-F1 0.6127472527472527 on epoch=181
06/08/2022 12:21:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.24 on epoch=182
06/08/2022 12:21:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.25 on epoch=183
06/08/2022 12:21:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=184
06/08/2022 12:21:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=186
06/08/2022 12:21:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=187
06/08/2022 12:21:19 - INFO - __main__ - Global step 1500 Train loss 0.17 Classification-F1 0.602132740081572 on epoch=187
06/08/2022 12:21:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.25 on epoch=188
06/08/2022 12:21:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=189
06/08/2022 12:21:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.17 on epoch=191
06/08/2022 12:21:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.14 on epoch=192
06/08/2022 12:21:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.19 on epoch=193
06/08/2022 12:21:34 - INFO - __main__ - Global step 1550 Train loss 0.17 Classification-F1 0.6133821733821734 on epoch=193
06/08/2022 12:21:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.18 on epoch=194
06/08/2022 12:21:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.19 on epoch=196
06/08/2022 12:21:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.21 on epoch=197
06/08/2022 12:21:44 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.20 on epoch=198
06/08/2022 12:21:47 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.13 on epoch=199
06/08/2022 12:21:49 - INFO - __main__ - Global step 1600 Train loss 0.18 Classification-F1 0.5670132357082511 on epoch=199
06/08/2022 12:21:51 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=201
06/08/2022 12:21:54 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=202
06/08/2022 12:21:57 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.19 on epoch=203
06/08/2022 12:21:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=204
06/08/2022 12:22:02 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.13 on epoch=206
06/08/2022 12:22:04 - INFO - __main__ - Global step 1650 Train loss 0.14 Classification-F1 0.5967674026132193 on epoch=206
06/08/2022 12:22:06 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=207
06/08/2022 12:22:09 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=208
06/08/2022 12:22:11 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=209
06/08/2022 12:22:14 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=211
06/08/2022 12:22:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.15 on epoch=212
06/08/2022 12:22:18 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.5939454022988506 on epoch=212
06/08/2022 12:22:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.16 on epoch=213
06/08/2022 12:22:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.14 on epoch=214
06/08/2022 12:22:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=216
06/08/2022 12:22:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.14 on epoch=217
06/08/2022 12:22:31 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.14 on epoch=218
06/08/2022 12:22:33 - INFO - __main__ - Global step 1750 Train loss 0.13 Classification-F1 0.7573260073260073 on epoch=218
06/08/2022 12:22:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7406597774244833 -> 0.7573260073260073 on epoch=218, global_step=1750
06/08/2022 12:22:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.13 on epoch=219
06/08/2022 12:22:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.13 on epoch=221
06/08/2022 12:22:41 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=222
06/08/2022 12:22:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=223
06/08/2022 12:22:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=224
06/08/2022 12:22:48 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.7322387113787939 on epoch=224
06/08/2022 12:22:51 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=226
06/08/2022 12:22:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=227
06/08/2022 12:22:56 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.21 on epoch=228
06/08/2022 12:22:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=229
06/08/2022 12:23:01 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=231
06/08/2022 12:23:03 - INFO - __main__ - Global step 1850 Train loss 0.12 Classification-F1 0.7232808796556957 on epoch=231
06/08/2022 12:23:06 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=232
06/08/2022 12:23:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=233
06/08/2022 12:23:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.14 on epoch=234
06/08/2022 12:23:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=236
06/08/2022 12:23:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=237
06/08/2022 12:23:18 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.7100463633729354 on epoch=237
06/08/2022 12:23:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.17 on epoch=238
06/08/2022 12:23:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=239
06/08/2022 12:23:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=241
06/08/2022 12:23:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.13 on epoch=242
06/08/2022 12:23:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=243
06/08/2022 12:23:33 - INFO - __main__ - Global step 1950 Train loss 0.11 Classification-F1 0.5806209807866809 on epoch=243
06/08/2022 12:23:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=244
06/08/2022 12:23:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=246
06/08/2022 12:23:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=247
06/08/2022 12:23:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=248
06/08/2022 12:23:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=249
06/08/2022 12:23:49 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.5872815554040373 on epoch=249
06/08/2022 12:23:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=251
06/08/2022 12:23:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=252
06/08/2022 12:23:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.13 on epoch=253
06/08/2022 12:24:00 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=254
06/08/2022 12:24:02 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.17 on epoch=256
06/08/2022 12:24:04 - INFO - __main__ - Global step 2050 Train loss 0.10 Classification-F1 0.582576672154137 on epoch=256
06/08/2022 12:24:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=257
06/08/2022 12:24:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=258
06/08/2022 12:24:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=259
06/08/2022 12:24:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=261
06/08/2022 12:24:18 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.12 on epoch=262
06/08/2022 12:24:20 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.7152393955379029 on epoch=262
06/08/2022 12:24:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=263
06/08/2022 12:24:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=264
06/08/2022 12:24:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.14 on epoch=266
06/08/2022 12:24:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.10 on epoch=267
06/08/2022 12:24:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.11 on epoch=268
06/08/2022 12:24:35 - INFO - __main__ - Global step 2150 Train loss 0.09 Classification-F1 0.7236390345765347 on epoch=268
06/08/2022 12:24:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=269
06/08/2022 12:24:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=271
06/08/2022 12:24:43 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=272
06/08/2022 12:24:46 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=273
06/08/2022 12:24:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=274
06/08/2022 12:24:50 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.7061728395061728 on epoch=274
06/08/2022 12:24:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=276
06/08/2022 12:24:55 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=277
06/08/2022 12:24:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.12 on epoch=278
06/08/2022 12:25:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=279
06/08/2022 12:25:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=281
06/08/2022 12:25:05 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.7437782198338473 on epoch=281
06/08/2022 12:25:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=282
06/08/2022 12:25:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.12 on epoch=283
06/08/2022 12:25:13 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=284
06/08/2022 12:25:16 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=286
06/08/2022 12:25:19 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=287
06/08/2022 12:25:21 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7500926410762476 on epoch=287
06/08/2022 12:25:23 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.14 on epoch=288
06/08/2022 12:25:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.15 on epoch=289
06/08/2022 12:25:28 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=291
06/08/2022 12:25:31 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=292
06/08/2022 12:25:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.18 on epoch=293
06/08/2022 12:25:35 - INFO - __main__ - Global step 2350 Train loss 0.12 Classification-F1 0.7416087069775594 on epoch=293
06/08/2022 12:25:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=294
06/08/2022 12:25:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=296
06/08/2022 12:25:43 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=297
06/08/2022 12:25:45 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.12 on epoch=298
06/08/2022 12:25:48 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=299
06/08/2022 12:25:49 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.724833183844314 on epoch=299
06/08/2022 12:25:52 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.08 on epoch=301
06/08/2022 12:25:54 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=302
06/08/2022 12:25:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=303
06/08/2022 12:26:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=304
06/08/2022 12:26:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=306
06/08/2022 12:26:04 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.6836915270771866 on epoch=306
06/08/2022 12:26:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=307
06/08/2022 12:26:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=308
06/08/2022 12:26:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=309
06/08/2022 12:26:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=311
06/08/2022 12:26:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=312
06/08/2022 12:26:19 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.7297803874371646 on epoch=312
06/08/2022 12:26:22 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=313
06/08/2022 12:26:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=314
06/08/2022 12:26:27 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=316
06/08/2022 12:26:30 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=317
06/08/2022 12:26:32 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=318
06/08/2022 12:26:34 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.7132016632016632 on epoch=318
06/08/2022 12:26:37 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=319
06/08/2022 12:26:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=321
06/08/2022 12:26:42 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=322
06/08/2022 12:26:45 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.09 on epoch=323
06/08/2022 12:26:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=324
06/08/2022 12:26:50 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.7332451923076924 on epoch=324
06/08/2022 12:26:52 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=326
06/08/2022 12:26:55 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.12 on epoch=327
06/08/2022 12:26:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.10 on epoch=328
06/08/2022 12:27:00 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=329
06/08/2022 12:27:03 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=331
06/08/2022 12:27:04 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.5830212392598272 on epoch=331
06/08/2022 12:27:07 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=332
06/08/2022 12:27:10 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=333
06/08/2022 12:27:13 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=334
06/08/2022 12:27:16 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=336
06/08/2022 12:27:18 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=337
06/08/2022 12:27:20 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7280551415797317 on epoch=337
06/08/2022 12:27:23 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=338
06/08/2022 12:27:25 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=339
06/08/2022 12:27:28 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=341
06/08/2022 12:27:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=342
06/08/2022 12:27:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=343
06/08/2022 12:27:35 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.5892345960914522 on epoch=343
06/08/2022 12:27:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=344
06/08/2022 12:27:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=346
06/08/2022 12:27:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=347
06/08/2022 12:27:46 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=348
06/08/2022 12:27:48 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=349
06/08/2022 12:27:50 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.5674230769230769 on epoch=349
06/08/2022 12:27:53 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=351
06/08/2022 12:27:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=352
06/08/2022 12:27:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=353
06/08/2022 12:28:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.10 on epoch=354
06/08/2022 12:28:03 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=356
06/08/2022 12:28:05 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7006474519632415 on epoch=356
06/08/2022 12:28:08 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=357
06/08/2022 12:28:10 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=358
06/08/2022 12:28:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/08/2022 12:28:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=361
06/08/2022 12:28:18 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=362
06/08/2022 12:28:20 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7335777126099707 on epoch=362
06/08/2022 12:28:23 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=363
06/08/2022 12:28:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
06/08/2022 12:28:28 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=366
06/08/2022 12:28:31 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/08/2022 12:28:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=368
06/08/2022 12:28:35 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7476041666666667 on epoch=368
06/08/2022 12:28:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=369
06/08/2022 12:28:41 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=371
06/08/2022 12:28:43 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=372
06/08/2022 12:28:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=373
06/08/2022 12:28:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=374
06/08/2022 12:28:50 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 12:28:50 - INFO - __main__ - Printing 3 examples
06/08/2022 12:28:50 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 12:28:50 - INFO - __main__ - ['sad']
06/08/2022 12:28:50 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 12:28:50 - INFO - __main__ - ['sad']
06/08/2022 12:28:50 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 12:28:50 - INFO - __main__ - ['sad']
06/08/2022 12:28:50 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:28:50 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:28:50 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 12:28:50 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 12:28:50 - INFO - __main__ - Printing 3 examples
06/08/2022 12:28:50 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/08/2022 12:28:50 - INFO - __main__ - ['sad']
06/08/2022 12:28:50 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/08/2022 12:28:50 - INFO - __main__ - ['sad']
06/08/2022 12:28:50 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/08/2022 12:28:50 - INFO - __main__ - ['sad']
06/08/2022 12:28:50 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:28:50 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:28:50 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 12:28:50 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.5797945231068107 on epoch=374
06/08/2022 12:28:50 - INFO - __main__ - save last model!
06/08/2022 12:28:50 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 12:28:50 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 12:28:50 - INFO - __main__ - Printing 3 examples
06/08/2022 12:28:50 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 12:28:50 - INFO - __main__ - ['others']
06/08/2022 12:28:50 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 12:28:50 - INFO - __main__ - ['others']
06/08/2022 12:28:50 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 12:28:50 - INFO - __main__ - ['others']
06/08/2022 12:28:50 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:28:53 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:28:58 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 12:29:09 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 12:29:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 12:29:10 - INFO - __main__ - Starting training!
06/08/2022 12:30:15 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_13_0.2_8_predictions.txt
06/08/2022 12:30:15 - INFO - __main__ - Classification-F1 on test data: 0.3611
06/08/2022 12:30:15 - INFO - __main__ - prefix=emo_32_13, lr=0.2, bsz=8, dev_performance=0.7573260073260073, test_performance=0.36107363598844067
06/08/2022 12:30:15 - INFO - __main__ - Running ... prefix=emo_32_21, lr=0.5, bsz=8 ...
06/08/2022 12:30:16 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 12:30:16 - INFO - __main__ - Printing 3 examples
06/08/2022 12:30:16 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 12:30:16 - INFO - __main__ - ['sad']
06/08/2022 12:30:16 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 12:30:16 - INFO - __main__ - ['sad']
06/08/2022 12:30:16 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 12:30:16 - INFO - __main__ - ['sad']
06/08/2022 12:30:16 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:30:16 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:30:16 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 12:30:16 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 12:30:16 - INFO - __main__ - Printing 3 examples
06/08/2022 12:30:16 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/08/2022 12:30:16 - INFO - __main__ - ['sad']
06/08/2022 12:30:16 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/08/2022 12:30:16 - INFO - __main__ - ['sad']
06/08/2022 12:30:16 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/08/2022 12:30:16 - INFO - __main__ - ['sad']
06/08/2022 12:30:16 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:30:16 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:30:17 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 12:30:35 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 12:30:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 12:30:36 - INFO - __main__ - Starting training!
06/08/2022 12:30:39 - INFO - __main__ - Step 10 Global step 10 Train loss 2.43 on epoch=1
06/08/2022 12:30:42 - INFO - __main__ - Step 20 Global step 20 Train loss 1.27 on epoch=2
06/08/2022 12:30:44 - INFO - __main__ - Step 30 Global step 30 Train loss 1.05 on epoch=3
06/08/2022 12:30:47 - INFO - __main__ - Step 40 Global step 40 Train loss 0.91 on epoch=4
06/08/2022 12:30:49 - INFO - __main__ - Step 50 Global step 50 Train loss 0.90 on epoch=6
06/08/2022 12:30:51 - INFO - __main__ - Global step 50 Train loss 1.31 Classification-F1 0.4080725756020436 on epoch=6
06/08/2022 12:30:51 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.4080725756020436 on epoch=6, global_step=50
06/08/2022 12:30:54 - INFO - __main__ - Step 60 Global step 60 Train loss 0.84 on epoch=7
06/08/2022 12:30:56 - INFO - __main__ - Step 70 Global step 70 Train loss 0.89 on epoch=8
06/08/2022 12:30:59 - INFO - __main__ - Step 80 Global step 80 Train loss 0.83 on epoch=9
06/08/2022 12:31:02 - INFO - __main__ - Step 90 Global step 90 Train loss 0.82 on epoch=11
06/08/2022 12:31:04 - INFO - __main__ - Step 100 Global step 100 Train loss 0.78 on epoch=12
06/08/2022 12:31:06 - INFO - __main__ - Global step 100 Train loss 0.83 Classification-F1 0.4416666666666667 on epoch=12
06/08/2022 12:31:06 - INFO - __main__ - Saving model with best Classification-F1: 0.4080725756020436 -> 0.4416666666666667 on epoch=12, global_step=100
06/08/2022 12:31:09 - INFO - __main__ - Step 110 Global step 110 Train loss 0.73 on epoch=13
06/08/2022 12:31:11 - INFO - __main__ - Step 120 Global step 120 Train loss 0.67 on epoch=14
06/08/2022 12:31:14 - INFO - __main__ - Step 130 Global step 130 Train loss 0.71 on epoch=16
06/08/2022 12:31:16 - INFO - __main__ - Step 140 Global step 140 Train loss 0.57 on epoch=17
06/08/2022 12:31:19 - INFO - __main__ - Step 150 Global step 150 Train loss 0.79 on epoch=18
06/08/2022 12:31:21 - INFO - __main__ - Global step 150 Train loss 0.70 Classification-F1 0.6005645679324362 on epoch=18
06/08/2022 12:31:21 - INFO - __main__ - Saving model with best Classification-F1: 0.4416666666666667 -> 0.6005645679324362 on epoch=18, global_step=150
06/08/2022 12:31:23 - INFO - __main__ - Step 160 Global step 160 Train loss 0.60 on epoch=19
06/08/2022 12:31:26 - INFO - __main__ - Step 170 Global step 170 Train loss 0.68 on epoch=21
06/08/2022 12:31:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.65 on epoch=22
06/08/2022 12:31:31 - INFO - __main__ - Step 190 Global step 190 Train loss 0.69 on epoch=23
06/08/2022 12:31:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.63 on epoch=24
06/08/2022 12:31:35 - INFO - __main__ - Global step 200 Train loss 0.65 Classification-F1 0.5899638688533398 on epoch=24
06/08/2022 12:31:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.62 on epoch=26
06/08/2022 12:31:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.73 on epoch=27
06/08/2022 12:31:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.63 on epoch=28
06/08/2022 12:31:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.59 on epoch=29
06/08/2022 12:31:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.59 on epoch=31
06/08/2022 12:31:50 - INFO - __main__ - Global step 250 Train loss 0.63 Classification-F1 0.4957031389979787 on epoch=31
06/08/2022 12:31:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.50 on epoch=32
06/08/2022 12:31:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.63 on epoch=33
06/08/2022 12:31:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.62 on epoch=34
06/08/2022 12:32:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=36
06/08/2022 12:32:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.49 on epoch=37
06/08/2022 12:32:05 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.661118430683648 on epoch=37
06/08/2022 12:32:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6005645679324362 -> 0.661118430683648 on epoch=37, global_step=300
06/08/2022 12:32:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.62 on epoch=38
06/08/2022 12:32:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.50 on epoch=39
06/08/2022 12:32:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.51 on epoch=41
06/08/2022 12:32:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.57 on epoch=42
06/08/2022 12:32:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.54 on epoch=43
06/08/2022 12:32:20 - INFO - __main__ - Global step 350 Train loss 0.55 Classification-F1 0.5591501480975165 on epoch=43
06/08/2022 12:32:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.49 on epoch=44
06/08/2022 12:32:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.52 on epoch=46
06/08/2022 12:32:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.50 on epoch=47
06/08/2022 12:32:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.64 on epoch=48
06/08/2022 12:32:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.52 on epoch=49
06/08/2022 12:32:35 - INFO - __main__ - Global step 400 Train loss 0.53 Classification-F1 0.6779874661729098 on epoch=49
06/08/2022 12:32:35 - INFO - __main__ - Saving model with best Classification-F1: 0.661118430683648 -> 0.6779874661729098 on epoch=49, global_step=400
06/08/2022 12:32:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.51 on epoch=51
06/08/2022 12:32:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.45 on epoch=52
06/08/2022 12:32:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.50 on epoch=53
06/08/2022 12:32:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.35 on epoch=54
06/08/2022 12:32:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.52 on epoch=56
06/08/2022 12:32:50 - INFO - __main__ - Global step 450 Train loss 0.47 Classification-F1 0.6737597822866541 on epoch=56
06/08/2022 12:32:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.46 on epoch=57
06/08/2022 12:32:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.42 on epoch=58
06/08/2022 12:32:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.40 on epoch=59
06/08/2022 12:33:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.49 on epoch=61
06/08/2022 12:33:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.43 on epoch=62
06/08/2022 12:33:05 - INFO - __main__ - Global step 500 Train loss 0.44 Classification-F1 0.6734201871188172 on epoch=62
06/08/2022 12:33:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.42 on epoch=63
06/08/2022 12:33:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.38 on epoch=64
06/08/2022 12:33:13 - INFO - __main__ - Step 530 Global step 530 Train loss 0.34 on epoch=66
06/08/2022 12:33:15 - INFO - __main__ - Step 540 Global step 540 Train loss 0.35 on epoch=67
06/08/2022 12:33:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.46 on epoch=68
06/08/2022 12:33:20 - INFO - __main__ - Global step 550 Train loss 0.39 Classification-F1 0.6115027928323232 on epoch=68
06/08/2022 12:33:22 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=69
06/08/2022 12:33:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.41 on epoch=71
06/08/2022 12:33:27 - INFO - __main__ - Step 580 Global step 580 Train loss 0.37 on epoch=72
06/08/2022 12:33:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.35 on epoch=73
06/08/2022 12:33:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.27 on epoch=74
06/08/2022 12:33:34 - INFO - __main__ - Global step 600 Train loss 0.33 Classification-F1 0.6899966200279151 on epoch=74
06/08/2022 12:33:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6779874661729098 -> 0.6899966200279151 on epoch=74, global_step=600
06/08/2022 12:33:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=76
06/08/2022 12:33:39 - INFO - __main__ - Step 620 Global step 620 Train loss 0.30 on epoch=77
06/08/2022 12:33:42 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=78
06/08/2022 12:33:44 - INFO - __main__ - Step 640 Global step 640 Train loss 0.29 on epoch=79
06/08/2022 12:33:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.34 on epoch=81
06/08/2022 12:33:49 - INFO - __main__ - Global step 650 Train loss 0.30 Classification-F1 0.6827220434121465 on epoch=81
06/08/2022 12:33:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.29 on epoch=82
06/08/2022 12:33:54 - INFO - __main__ - Step 670 Global step 670 Train loss 0.32 on epoch=83
06/08/2022 12:33:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=84
06/08/2022 12:34:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.29 on epoch=86
06/08/2022 12:34:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=87
06/08/2022 12:34:04 - INFO - __main__ - Global step 700 Train loss 0.28 Classification-F1 0.7311806396287328 on epoch=87
06/08/2022 12:34:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6899966200279151 -> 0.7311806396287328 on epoch=87, global_step=700
06/08/2022 12:34:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=88
06/08/2022 12:34:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.31 on epoch=89
06/08/2022 12:34:12 - INFO - __main__ - Step 730 Global step 730 Train loss 0.29 on epoch=91
06/08/2022 12:34:15 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=92
06/08/2022 12:34:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=93
06/08/2022 12:34:19 - INFO - __main__ - Global step 750 Train loss 0.25 Classification-F1 0.6996812542090424 on epoch=93
06/08/2022 12:34:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=94
06/08/2022 12:34:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=96
06/08/2022 12:34:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=97
06/08/2022 12:34:30 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=98
06/08/2022 12:34:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=99
06/08/2022 12:34:34 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.6718475490027214 on epoch=99
06/08/2022 12:34:37 - INFO - __main__ - Step 810 Global step 810 Train loss 0.30 on epoch=101
06/08/2022 12:34:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=102
06/08/2022 12:34:42 - INFO - __main__ - Step 830 Global step 830 Train loss 0.27 on epoch=103
06/08/2022 12:34:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=104
06/08/2022 12:34:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=106
06/08/2022 12:34:49 - INFO - __main__ - Global step 850 Train loss 0.24 Classification-F1 0.7574652777777778 on epoch=106
06/08/2022 12:34:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7311806396287328 -> 0.7574652777777778 on epoch=106, global_step=850
06/08/2022 12:34:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=107
06/08/2022 12:34:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=108
06/08/2022 12:34:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=109
06/08/2022 12:35:00 - INFO - __main__ - Step 890 Global step 890 Train loss 0.22 on epoch=111
06/08/2022 12:35:03 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=112
06/08/2022 12:35:04 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.6433727740455801 on epoch=112
06/08/2022 12:35:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.28 on epoch=113
06/08/2022 12:35:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=114
06/08/2022 12:35:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=116
06/08/2022 12:35:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=117
06/08/2022 12:35:18 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=118
06/08/2022 12:35:20 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.6736602914868989 on epoch=118
06/08/2022 12:35:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=119
06/08/2022 12:35:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=121
06/08/2022 12:35:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=122
06/08/2022 12:35:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=123
06/08/2022 12:35:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=124
06/08/2022 12:35:35 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.5510650811916634 on epoch=124
06/08/2022 12:35:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=126
06/08/2022 12:35:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=127
06/08/2022 12:35:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=128
06/08/2022 12:35:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=129
06/08/2022 12:35:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=131
06/08/2022 12:35:50 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.5726613863784715 on epoch=131
06/08/2022 12:35:53 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=132
06/08/2022 12:35:55 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=133
06/08/2022 12:35:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=134
06/08/2022 12:36:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=136
06/08/2022 12:36:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=137
06/08/2022 12:36:05 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.6874391014694163 on epoch=137
06/08/2022 12:36:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=138
06/08/2022 12:36:11 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=139
06/08/2022 12:36:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=141
06/08/2022 12:36:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=142
06/08/2022 12:36:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=143
06/08/2022 12:36:20 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.6804536141492663 on epoch=143
06/08/2022 12:36:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=144
06/08/2022 12:36:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=146
06/08/2022 12:36:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=147
06/08/2022 12:36:31 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=148
06/08/2022 12:36:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=149
06/08/2022 12:36:36 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.7079047056558301 on epoch=149
06/08/2022 12:36:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=151
06/08/2022 12:36:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=152
06/08/2022 12:36:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=153
06/08/2022 12:36:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=154
06/08/2022 12:36:48 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=156
06/08/2022 12:36:51 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6438492063492063 on epoch=156
06/08/2022 12:36:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=157
06/08/2022 12:36:56 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=158
06/08/2022 12:36:58 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=159
06/08/2022 12:37:01 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=161
06/08/2022 12:37:03 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=162
06/08/2022 12:37:05 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.6549366553997612 on epoch=162
06/08/2022 12:37:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=163
06/08/2022 12:37:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=164
06/08/2022 12:37:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=166
06/08/2022 12:37:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=167
06/08/2022 12:37:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=168
06/08/2022 12:37:20 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.6433951341890126 on epoch=168
06/08/2022 12:37:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=169
06/08/2022 12:37:25 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=171
06/08/2022 12:37:28 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=172
06/08/2022 12:37:30 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=173
06/08/2022 12:37:33 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.18 on epoch=174
06/08/2022 12:37:35 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.6225417731932996 on epoch=174
06/08/2022 12:37:37 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=176
06/08/2022 12:37:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=177
06/08/2022 12:37:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=178
06/08/2022 12:37:45 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=179
06/08/2022 12:37:48 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=181
06/08/2022 12:37:50 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.6733805000969181 on epoch=181
06/08/2022 12:37:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=182
06/08/2022 12:37:55 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=183
06/08/2022 12:37:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=184
06/08/2022 12:38:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=186
06/08/2022 12:38:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=187
06/08/2022 12:38:05 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.6657425436386127 on epoch=187
06/08/2022 12:38:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.13 on epoch=188
06/08/2022 12:38:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=189
06/08/2022 12:38:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=191
06/08/2022 12:38:15 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=192
06/08/2022 12:38:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=193
06/08/2022 12:38:19 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.6698444026190463 on epoch=193
06/08/2022 12:38:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=194
06/08/2022 12:38:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=196
06/08/2022 12:38:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=197
06/08/2022 12:38:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=198
06/08/2022 12:38:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=199
06/08/2022 12:38:34 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.5602131470139519 on epoch=199
06/08/2022 12:38:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=201
06/08/2022 12:38:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=202
06/08/2022 12:38:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=203
06/08/2022 12:38:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=204
06/08/2022 12:38:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=206
06/08/2022 12:38:49 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.6683101168395286 on epoch=206
06/08/2022 12:38:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=207
06/08/2022 12:38:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=208
06/08/2022 12:38:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=209
06/08/2022 12:38:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=211
06/08/2022 12:39:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=212
06/08/2022 12:39:04 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.6412088805311095 on epoch=212
06/08/2022 12:39:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=213
06/08/2022 12:39:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=214
06/08/2022 12:39:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=216
06/08/2022 12:39:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=217
06/08/2022 12:39:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=218
06/08/2022 12:39:19 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6694082021858809 on epoch=218
06/08/2022 12:39:22 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=219
06/08/2022 12:39:24 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=221
06/08/2022 12:39:27 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=222
06/08/2022 12:39:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=223
06/08/2022 12:39:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=224
06/08/2022 12:39:34 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.6929587356780249 on epoch=224
06/08/2022 12:39:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=226
06/08/2022 12:39:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=227
06/08/2022 12:39:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=228
06/08/2022 12:39:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=229
06/08/2022 12:39:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=231
06/08/2022 12:39:49 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.6947570123939987 on epoch=231
06/08/2022 12:39:51 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=232
06/08/2022 12:39:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=233
06/08/2022 12:39:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=234
06/08/2022 12:40:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=236
06/08/2022 12:40:02 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=237
06/08/2022 12:40:05 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6739367614367615 on epoch=237
06/08/2022 12:40:07 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=238
06/08/2022 12:40:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=239
06/08/2022 12:40:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=241
06/08/2022 12:40:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=242
06/08/2022 12:40:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=243
06/08/2022 12:40:21 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6631534644692538 on epoch=243
06/08/2022 12:40:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=244
06/08/2022 12:40:26 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=246
06/08/2022 12:40:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=247
06/08/2022 12:40:31 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=248
06/08/2022 12:40:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=249
06/08/2022 12:40:36 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.669693467792526 on epoch=249
06/08/2022 12:40:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=251
06/08/2022 12:40:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=252
06/08/2022 12:40:43 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=253
06/08/2022 12:40:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=254
06/08/2022 12:40:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=256
06/08/2022 12:40:51 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.5690491014361982 on epoch=256
06/08/2022 12:40:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=257
06/08/2022 12:40:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=258
06/08/2022 12:40:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=259
06/08/2022 12:41:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=261
06/08/2022 12:41:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=262
06/08/2022 12:41:06 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.538766551856104 on epoch=262
06/08/2022 12:41:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=263
06/08/2022 12:41:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=264
06/08/2022 12:41:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=266
06/08/2022 12:41:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=267
06/08/2022 12:41:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=268
06/08/2022 12:41:21 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.6692156336474417 on epoch=268
06/08/2022 12:41:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=269
06/08/2022 12:41:27 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=271
06/08/2022 12:41:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=272
06/08/2022 12:41:32 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=273
06/08/2022 12:41:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=274
06/08/2022 12:41:37 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7028484357147144 on epoch=274
06/08/2022 12:41:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=276
06/08/2022 12:41:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=277
06/08/2022 12:41:45 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=278
06/08/2022 12:41:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=279
06/08/2022 12:41:50 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=281
06/08/2022 12:41:52 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.5754158452693703 on epoch=281
06/08/2022 12:41:55 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=282
06/08/2022 12:41:58 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
06/08/2022 12:42:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=284
06/08/2022 12:42:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=286
06/08/2022 12:42:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=287
06/08/2022 12:42:08 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.5345028357552233 on epoch=287
06/08/2022 12:42:10 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=288
06/08/2022 12:42:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=289
06/08/2022 12:42:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=291
06/08/2022 12:42:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=292
06/08/2022 12:42:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=293
06/08/2022 12:42:23 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.5464693274455478 on epoch=293
06/08/2022 12:42:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=294
06/08/2022 12:42:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=296
06/08/2022 12:42:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=297
06/08/2022 12:42:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=298
06/08/2022 12:42:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=299
06/08/2022 12:42:38 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6946117607482912 on epoch=299
06/08/2022 12:42:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
06/08/2022 12:42:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=302
06/08/2022 12:42:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=303
06/08/2022 12:42:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.18 on epoch=304
06/08/2022 12:42:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=306
06/08/2022 12:42:54 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6741303375810418 on epoch=306
06/08/2022 12:42:57 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=307
06/08/2022 12:42:59 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=308
06/08/2022 12:43:02 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.09 on epoch=309
06/08/2022 12:43:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=311
06/08/2022 12:43:07 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=312
06/08/2022 12:43:09 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.666620613429124 on epoch=312
06/08/2022 12:43:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=313
06/08/2022 12:43:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/08/2022 12:43:17 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=316
06/08/2022 12:43:20 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=317
06/08/2022 12:43:22 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=318
06/08/2022 12:43:25 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6986113537880906 on epoch=318
06/08/2022 12:43:27 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
06/08/2022 12:43:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=321
06/08/2022 12:43:33 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=322
06/08/2022 12:43:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=323
06/08/2022 12:43:38 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=324
06/08/2022 12:43:40 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6749924491191444 on epoch=324
06/08/2022 12:43:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=326
06/08/2022 12:43:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=327
06/08/2022 12:43:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=328
06/08/2022 12:43:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=329
06/08/2022 12:43:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=331
06/08/2022 12:43:55 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.6635245901639345 on epoch=331
06/08/2022 12:43:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=332
06/08/2022 12:44:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=333
06/08/2022 12:44:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=334
06/08/2022 12:44:06 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=336
06/08/2022 12:44:09 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
06/08/2022 12:44:11 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6772296768618109 on epoch=337
06/08/2022 12:44:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=338
06/08/2022 12:44:16 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=339
06/08/2022 12:44:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
06/08/2022 12:44:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
06/08/2022 12:44:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=343
06/08/2022 12:44:26 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6592223495839813 on epoch=343
06/08/2022 12:44:29 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
06/08/2022 12:44:32 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=346
06/08/2022 12:44:34 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=347
06/08/2022 12:44:37 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=348
06/08/2022 12:44:40 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=349
06/08/2022 12:44:42 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6728550633686969 on epoch=349
06/08/2022 12:44:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=351
06/08/2022 12:44:47 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=352
06/08/2022 12:44:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=353
06/08/2022 12:44:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=354
06/08/2022 12:44:55 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=356
06/08/2022 12:44:57 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7016746367955672 on epoch=356
06/08/2022 12:45:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=357
06/08/2022 12:45:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=358
06/08/2022 12:45:05 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=359
06/08/2022 12:45:08 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=361
06/08/2022 12:45:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=362
06/08/2022 12:45:13 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7318901183736489 on epoch=362
06/08/2022 12:45:15 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=363
06/08/2022 12:45:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
06/08/2022 12:45:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=366
06/08/2022 12:45:23 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=367
06/08/2022 12:45:25 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
06/08/2022 12:45:28 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7126114081996435 on epoch=368
06/08/2022 12:45:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=369
06/08/2022 12:45:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
06/08/2022 12:45:35 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=372
06/08/2022 12:45:38 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=373
06/08/2022 12:45:41 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
06/08/2022 12:45:42 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 12:45:42 - INFO - __main__ - Printing 3 examples
06/08/2022 12:45:42 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 12:45:42 - INFO - __main__ - ['sad']
06/08/2022 12:45:42 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 12:45:42 - INFO - __main__ - ['sad']
06/08/2022 12:45:42 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 12:45:42 - INFO - __main__ - ['sad']
06/08/2022 12:45:42 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:45:42 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:45:42 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 12:45:42 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 12:45:42 - INFO - __main__ - Printing 3 examples
06/08/2022 12:45:42 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/08/2022 12:45:42 - INFO - __main__ - ['sad']
06/08/2022 12:45:42 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/08/2022 12:45:42 - INFO - __main__ - ['sad']
06/08/2022 12:45:42 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/08/2022 12:45:42 - INFO - __main__ - ['sad']
06/08/2022 12:45:42 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:45:42 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:45:43 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 12:45:43 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7317013245976356 on epoch=374
06/08/2022 12:45:43 - INFO - __main__ - save last model!
06/08/2022 12:45:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 12:45:43 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 12:45:43 - INFO - __main__ - Printing 3 examples
06/08/2022 12:45:43 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 12:45:43 - INFO - __main__ - ['others']
06/08/2022 12:45:43 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 12:45:43 - INFO - __main__ - ['others']
06/08/2022 12:45:43 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 12:45:43 - INFO - __main__ - ['others']
06/08/2022 12:45:43 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:45:45 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:45:51 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 12:46:01 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 12:46:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 12:46:02 - INFO - __main__ - Starting training!
06/08/2022 12:47:27 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_21_0.5_8_predictions.txt
06/08/2022 12:47:27 - INFO - __main__ - Classification-F1 on test data: 0.1515
06/08/2022 12:47:28 - INFO - __main__ - prefix=emo_32_21, lr=0.5, bsz=8, dev_performance=0.7574652777777778, test_performance=0.1515228266503644
06/08/2022 12:47:28 - INFO - __main__ - Running ... prefix=emo_32_21, lr=0.4, bsz=8 ...
06/08/2022 12:47:30 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 12:47:30 - INFO - __main__ - Printing 3 examples
06/08/2022 12:47:30 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 12:47:30 - INFO - __main__ - ['sad']
06/08/2022 12:47:30 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 12:47:30 - INFO - __main__ - ['sad']
06/08/2022 12:47:30 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 12:47:30 - INFO - __main__ - ['sad']
06/08/2022 12:47:30 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:47:30 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:47:30 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 12:47:30 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 12:47:30 - INFO - __main__ - Printing 3 examples
06/08/2022 12:47:30 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/08/2022 12:47:30 - INFO - __main__ - ['sad']
06/08/2022 12:47:30 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/08/2022 12:47:30 - INFO - __main__ - ['sad']
06/08/2022 12:47:30 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/08/2022 12:47:30 - INFO - __main__ - ['sad']
06/08/2022 12:47:30 - INFO - __main__ - Tokenizing Input ...
06/08/2022 12:47:30 - INFO - __main__ - Tokenizing Output ...
06/08/2022 12:47:30 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 12:47:49 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 12:47:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 12:47:50 - INFO - __main__ - Starting training!
06/08/2022 12:47:53 - INFO - __main__ - Step 10 Global step 10 Train loss 2.63 on epoch=1
06/08/2022 12:47:56 - INFO - __main__ - Step 20 Global step 20 Train loss 1.35 on epoch=2
06/08/2022 12:47:58 - INFO - __main__ - Step 30 Global step 30 Train loss 1.02 on epoch=3
06/08/2022 12:48:01 - INFO - __main__ - Step 40 Global step 40 Train loss 1.02 on epoch=4
06/08/2022 12:48:04 - INFO - __main__ - Step 50 Global step 50 Train loss 0.98 on epoch=6
06/08/2022 12:48:06 - INFO - __main__ - Global step 50 Train loss 1.40 Classification-F1 0.16078883166169694 on epoch=6
06/08/2022 12:48:06 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.16078883166169694 on epoch=6, global_step=50
06/08/2022 12:48:08 - INFO - __main__ - Step 60 Global step 60 Train loss 0.97 on epoch=7
06/08/2022 12:48:11 - INFO - __main__ - Step 70 Global step 70 Train loss 0.89 on epoch=8
06/08/2022 12:48:13 - INFO - __main__ - Step 80 Global step 80 Train loss 0.83 on epoch=9
06/08/2022 12:48:16 - INFO - __main__ - Step 90 Global step 90 Train loss 0.85 on epoch=11
06/08/2022 12:48:18 - INFO - __main__ - Step 100 Global step 100 Train loss 0.82 on epoch=12
06/08/2022 12:48:20 - INFO - __main__ - Global step 100 Train loss 0.87 Classification-F1 0.4771223550786412 on epoch=12
06/08/2022 12:48:20 - INFO - __main__ - Saving model with best Classification-F1: 0.16078883166169694 -> 0.4771223550786412 on epoch=12, global_step=100
06/08/2022 12:48:23 - INFO - __main__ - Step 110 Global step 110 Train loss 0.92 on epoch=13
06/08/2022 12:48:26 - INFO - __main__ - Step 120 Global step 120 Train loss 0.83 on epoch=14
06/08/2022 12:48:28 - INFO - __main__ - Step 130 Global step 130 Train loss 0.79 on epoch=16
06/08/2022 12:48:31 - INFO - __main__ - Step 140 Global step 140 Train loss 0.73 on epoch=17
06/08/2022 12:48:33 - INFO - __main__ - Step 150 Global step 150 Train loss 0.88 on epoch=18
06/08/2022 12:48:35 - INFO - __main__ - Global step 150 Train loss 0.83 Classification-F1 0.5021097603946441 on epoch=18
06/08/2022 12:48:35 - INFO - __main__ - Saving model with best Classification-F1: 0.4771223550786412 -> 0.5021097603946441 on epoch=18, global_step=150
06/08/2022 12:48:38 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=19
06/08/2022 12:48:41 - INFO - __main__ - Step 170 Global step 170 Train loss 0.72 on epoch=21
06/08/2022 12:48:43 - INFO - __main__ - Step 180 Global step 180 Train loss 0.70 on epoch=22
06/08/2022 12:48:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.72 on epoch=23
06/08/2022 12:48:48 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=24
06/08/2022 12:48:50 - INFO - __main__ - Global step 200 Train loss 0.70 Classification-F1 0.3743009185936015 on epoch=24
06/08/2022 12:48:53 - INFO - __main__ - Step 210 Global step 210 Train loss 0.63 on epoch=26
06/08/2022 12:48:55 - INFO - __main__ - Step 220 Global step 220 Train loss 0.61 on epoch=27
06/08/2022 12:48:58 - INFO - __main__ - Step 230 Global step 230 Train loss 0.56 on epoch=28
06/08/2022 12:49:01 - INFO - __main__ - Step 240 Global step 240 Train loss 0.58 on epoch=29
06/08/2022 12:49:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.66 on epoch=31
06/08/2022 12:49:05 - INFO - __main__ - Global step 250 Train loss 0.61 Classification-F1 0.49341867851544297 on epoch=31
06/08/2022 12:49:08 - INFO - __main__ - Step 260 Global step 260 Train loss 0.59 on epoch=32
06/08/2022 12:49:11 - INFO - __main__ - Step 270 Global step 270 Train loss 0.59 on epoch=33
06/08/2022 12:49:13 - INFO - __main__ - Step 280 Global step 280 Train loss 0.54 on epoch=34
06/08/2022 12:49:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.57 on epoch=36
06/08/2022 12:49:18 - INFO - __main__ - Step 300 Global step 300 Train loss 0.56 on epoch=37
06/08/2022 12:49:20 - INFO - __main__ - Global step 300 Train loss 0.57 Classification-F1 0.6258042583904362 on epoch=37
06/08/2022 12:49:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5021097603946441 -> 0.6258042583904362 on epoch=37, global_step=300
06/08/2022 12:49:23 - INFO - __main__ - Step 310 Global step 310 Train loss 0.68 on epoch=38
06/08/2022 12:49:26 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=39
06/08/2022 12:49:28 - INFO - __main__ - Step 330 Global step 330 Train loss 0.59 on epoch=41
06/08/2022 12:49:31 - INFO - __main__ - Step 340 Global step 340 Train loss 0.54 on epoch=42
06/08/2022 12:49:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.55 on epoch=43
06/08/2022 12:49:35 - INFO - __main__ - Global step 350 Train loss 0.56 Classification-F1 0.6501881945737878 on epoch=43
06/08/2022 12:49:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6258042583904362 -> 0.6501881945737878 on epoch=43, global_step=350
06/08/2022 12:49:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.52 on epoch=44
06/08/2022 12:49:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.49 on epoch=46
06/08/2022 12:49:43 - INFO - __main__ - Step 380 Global step 380 Train loss 0.41 on epoch=47
06/08/2022 12:49:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.43 on epoch=48
06/08/2022 12:49:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.43 on epoch=49
06/08/2022 12:49:50 - INFO - __main__ - Global step 400 Train loss 0.46 Classification-F1 0.6591602818045942 on epoch=49
06/08/2022 12:49:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6501881945737878 -> 0.6591602818045942 on epoch=49, global_step=400
06/08/2022 12:49:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.56 on epoch=51
06/08/2022 12:49:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.40 on epoch=52
06/08/2022 12:49:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.45 on epoch=53
06/08/2022 12:50:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.48 on epoch=54
06/08/2022 12:50:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=56
06/08/2022 12:50:05 - INFO - __main__ - Global step 450 Train loss 0.45 Classification-F1 0.6445561693359925 on epoch=56
06/08/2022 12:50:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=57
06/08/2022 12:50:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.45 on epoch=58
06/08/2022 12:50:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.48 on epoch=59
06/08/2022 12:50:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.55 on epoch=61
06/08/2022 12:50:18 - INFO - __main__ - Step 500 Global step 500 Train loss 0.33 on epoch=62
06/08/2022 12:50:20 - INFO - __main__ - Global step 500 Train loss 0.44 Classification-F1 0.6320754716981133 on epoch=62
06/08/2022 12:50:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.36 on epoch=63
06/08/2022 12:50:25 - INFO - __main__ - Step 520 Global step 520 Train loss 0.31 on epoch=64
06/08/2022 12:50:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.47 on epoch=66
06/08/2022 12:50:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.35 on epoch=67
06/08/2022 12:50:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.43 on epoch=68
06/08/2022 12:50:35 - INFO - __main__ - Global step 550 Train loss 0.38 Classification-F1 0.6596234175181543 on epoch=68
06/08/2022 12:50:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6591602818045942 -> 0.6596234175181543 on epoch=68, global_step=550
06/08/2022 12:50:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.29 on epoch=69
06/08/2022 12:50:40 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=71
06/08/2022 12:50:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=72
06/08/2022 12:50:45 - INFO - __main__ - Step 590 Global step 590 Train loss 0.31 on epoch=73
06/08/2022 12:50:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.31 on epoch=74
06/08/2022 12:50:50 - INFO - __main__ - Global step 600 Train loss 0.32 Classification-F1 0.6999854600275688 on epoch=74
06/08/2022 12:50:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6596234175181543 -> 0.6999854600275688 on epoch=74, global_step=600
06/08/2022 12:50:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=76
06/08/2022 12:50:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=77
06/08/2022 12:50:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=78
06/08/2022 12:51:00 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=79
06/08/2022 12:51:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=81
06/08/2022 12:51:05 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.6717129333617505 on epoch=81
06/08/2022 12:51:08 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=82
06/08/2022 12:51:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.29 on epoch=83
06/08/2022 12:51:13 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=84
06/08/2022 12:51:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=86
06/08/2022 12:51:18 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=87
06/08/2022 12:51:20 - INFO - __main__ - Global step 700 Train loss 0.24 Classification-F1 0.6473793950512013 on epoch=87
06/08/2022 12:51:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=88
06/08/2022 12:51:25 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=89
06/08/2022 12:51:28 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=91
06/08/2022 12:51:30 - INFO - __main__ - Step 740 Global step 740 Train loss 0.35 on epoch=92
06/08/2022 12:51:33 - INFO - __main__ - Step 750 Global step 750 Train loss 0.29 on epoch=93
06/08/2022 12:51:35 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.6564628512238702 on epoch=93
06/08/2022 12:51:37 - INFO - __main__ - Step 760 Global step 760 Train loss 0.28 on epoch=94
06/08/2022 12:51:40 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=96
06/08/2022 12:51:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=97
06/08/2022 12:51:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=98
06/08/2022 12:51:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=99
06/08/2022 12:51:50 - INFO - __main__ - Global step 800 Train loss 0.25 Classification-F1 0.6820604833762729 on epoch=99
06/08/2022 12:51:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=101
06/08/2022 12:51:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=102
06/08/2022 12:51:58 - INFO - __main__ - Step 830 Global step 830 Train loss 0.25 on epoch=103
06/08/2022 12:52:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.21 on epoch=104
06/08/2022 12:52:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=106
06/08/2022 12:52:05 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.6996754232948874 on epoch=106
06/08/2022 12:52:08 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=107
06/08/2022 12:52:10 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=108
06/08/2022 12:52:13 - INFO - __main__ - Step 880 Global step 880 Train loss 0.28 on epoch=109
06/08/2022 12:52:15 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=111
06/08/2022 12:52:18 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=112
06/08/2022 12:52:20 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.6802477840451249 on epoch=112
06/08/2022 12:52:22 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=113
06/08/2022 12:52:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=114
06/08/2022 12:52:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=116
06/08/2022 12:52:30 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=117
06/08/2022 12:52:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=118
06/08/2022 12:52:35 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.6671755022392292 on epoch=118
06/08/2022 12:52:37 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=119
06/08/2022 12:52:40 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=121
06/08/2022 12:52:43 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=122
06/08/2022 12:52:45 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=123
06/08/2022 12:52:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=124
06/08/2022 12:52:50 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.6975879568911444 on epoch=124
06/08/2022 12:52:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=126
06/08/2022 12:52:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=127
06/08/2022 12:52:58 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=128
06/08/2022 12:53:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=129
06/08/2022 12:53:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=131
06/08/2022 12:53:05 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.698524374176548 on epoch=131
06/08/2022 12:53:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=132
06/08/2022 12:53:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=133
06/08/2022 12:53:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=134
06/08/2022 12:53:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=136
06/08/2022 12:53:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=137
06/08/2022 12:53:20 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.7235783516692358 on epoch=137
06/08/2022 12:53:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6999854600275688 -> 0.7235783516692358 on epoch=137, global_step=1100
06/08/2022 12:53:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=138
06/08/2022 12:53:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=139
06/08/2022 12:53:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=141
06/08/2022 12:53:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=142
06/08/2022 12:53:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=143
06/08/2022 12:53:36 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.7049642699367132 on epoch=143
06/08/2022 12:53:38 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=144
06/08/2022 12:53:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=146
06/08/2022 12:53:43 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=147
06/08/2022 12:53:46 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=148
06/08/2022 12:53:49 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=149
06/08/2022 12:53:51 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.658375990057297 on epoch=149
06/08/2022 12:53:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=151
06/08/2022 12:53:56 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.21 on epoch=152
06/08/2022 12:53:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.18 on epoch=153
06/08/2022 12:54:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=154
06/08/2022 12:54:04 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=156
06/08/2022 12:54:06 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.7275726771214281 on epoch=156
06/08/2022 12:54:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7235783516692358 -> 0.7275726771214281 on epoch=156, global_step=1250
06/08/2022 12:54:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=157
06/08/2022 12:54:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=158
06/08/2022 12:54:15 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=159
06/08/2022 12:54:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=161
06/08/2022 12:54:20 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=162
06/08/2022 12:54:22 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6901201253900106 on epoch=162
06/08/2022 12:54:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=163
06/08/2022 12:54:27 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=164
06/08/2022 12:54:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=166
06/08/2022 12:54:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=167
06/08/2022 12:54:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=168
06/08/2022 12:54:37 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.6927929383811736 on epoch=168
06/08/2022 12:54:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=169
06/08/2022 12:54:43 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=171
06/08/2022 12:54:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=172
06/08/2022 12:54:48 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=173
06/08/2022 12:54:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=174
06/08/2022 12:54:52 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7123564397046759 on epoch=174
06/08/2022 12:54:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=176
06/08/2022 12:54:57 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=177
06/08/2022 12:55:00 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=178
06/08/2022 12:55:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=179
06/08/2022 12:55:05 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=181
06/08/2022 12:55:07 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6646164796681799 on epoch=181
06/08/2022 12:55:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=182
06/08/2022 12:55:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=183
06/08/2022 12:55:15 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=184
06/08/2022 12:55:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=186
06/08/2022 12:55:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=187
06/08/2022 12:55:22 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6392842822774659 on epoch=187
06/08/2022 12:55:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=188
06/08/2022 12:55:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=189
06/08/2022 12:55:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=191
06/08/2022 12:55:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=192
06/08/2022 12:55:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=193
06/08/2022 12:55:38 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6859529505582137 on epoch=193
06/08/2022 12:55:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=194
06/08/2022 12:55:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=196
06/08/2022 12:55:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=197
06/08/2022 12:55:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=198
06/08/2022 12:55:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=199
06/08/2022 12:55:53 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7478150713722239 on epoch=199
06/08/2022 12:55:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7275726771214281 -> 0.7478150713722239 on epoch=199, global_step=1600
06/08/2022 12:55:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=201
06/08/2022 12:55:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=202
06/08/2022 12:56:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.12 on epoch=203
06/08/2022 12:56:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=204
06/08/2022 12:56:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=206
06/08/2022 12:56:09 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.7137085137085137 on epoch=206
06/08/2022 12:56:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=207
06/08/2022 12:56:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=208
06/08/2022 12:56:17 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=209
06/08/2022 12:56:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=211
06/08/2022 12:56:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=212
06/08/2022 12:56:24 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7068678040130838 on epoch=212
06/08/2022 12:56:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=213
06/08/2022 12:56:30 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=214
06/08/2022 12:56:32 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=216
06/08/2022 12:56:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=217
06/08/2022 12:56:37 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=218
06/08/2022 12:56:40 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6912820644502384 on epoch=218
06/08/2022 12:56:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=219
06/08/2022 12:56:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=221
06/08/2022 12:56:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=222
06/08/2022 12:56:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=223
06/08/2022 12:56:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=224
06/08/2022 12:56:55 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.6965734265734266 on epoch=224
06/08/2022 12:56:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=226
06/08/2022 12:57:01 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=227
06/08/2022 12:57:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=228
06/08/2022 12:57:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=229
06/08/2022 12:57:08 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=231
06/08/2022 12:57:11 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.6844593989996699 on epoch=231
06/08/2022 12:57:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=232
06/08/2022 12:57:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=233
06/08/2022 12:57:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=234
06/08/2022 12:57:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=236
06/08/2022 12:57:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=237
06/08/2022 12:57:26 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.6965946799743962 on epoch=237
06/08/2022 12:57:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=238
06/08/2022 12:57:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=239
06/08/2022 12:57:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.15 on epoch=241
06/08/2022 12:57:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=242
06/08/2022 12:57:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=243
06/08/2022 12:57:41 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.6754463475155844 on epoch=243
06/08/2022 12:57:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.10 on epoch=244
06/08/2022 12:57:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=246
06/08/2022 12:57:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=247
06/08/2022 12:57:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=248
06/08/2022 12:57:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=249
06/08/2022 12:57:56 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7202361557200267 on epoch=249
06/08/2022 12:57:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=251
06/08/2022 12:58:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=252
06/08/2022 12:58:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.11 on epoch=253
06/08/2022 12:58:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=254
06/08/2022 12:58:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=256
06/08/2022 12:58:11 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7195607209691717 on epoch=256
06/08/2022 12:58:14 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=257
06/08/2022 12:58:16 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=258
06/08/2022 12:58:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=259
06/08/2022 12:58:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.11 on epoch=261
06/08/2022 12:58:25 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=262
06/08/2022 12:58:27 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.6824796014687553 on epoch=262
06/08/2022 12:58:30 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=263
06/08/2022 12:58:33 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=264
06/08/2022 12:58:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=266
06/08/2022 12:58:38 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=267
06/08/2022 12:58:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=268
06/08/2022 12:58:43 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.6968709171834172 on epoch=268
06/08/2022 12:58:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=269
06/08/2022 12:58:48 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.17 on epoch=271
06/08/2022 12:58:51 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=272
06/08/2022 12:58:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=273
06/08/2022 12:58:56 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=274
06/08/2022 12:58:59 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.6903958614484931 on epoch=274
06/08/2022 12:59:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.10 on epoch=276
06/08/2022 12:59:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=277
06/08/2022 12:59:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=278
06/08/2022 12:59:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=279
06/08/2022 12:59:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=281
06/08/2022 12:59:14 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.7178344245508425 on epoch=281
06/08/2022 12:59:16 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=282
06/08/2022 12:59:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=283
06/08/2022 12:59:21 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=284
06/08/2022 12:59:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=286
06/08/2022 12:59:27 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=287
06/08/2022 12:59:29 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.49272030651341 on epoch=287
06/08/2022 12:59:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.11 on epoch=288
06/08/2022 12:59:34 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=289
06/08/2022 12:59:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=291
06/08/2022 12:59:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=292
06/08/2022 12:59:42 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=293
06/08/2022 12:59:44 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.6628341412562035 on epoch=293
06/08/2022 12:59:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=294
06/08/2022 12:59:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=296
06/08/2022 12:59:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=297
06/08/2022 12:59:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=298
06/08/2022 12:59:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=299
06/08/2022 12:59:59 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6603971390927913 on epoch=299
06/08/2022 13:00:02 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
06/08/2022 13:00:05 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=302
06/08/2022 13:00:07 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=303
06/08/2022 13:00:10 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=304
06/08/2022 13:00:12 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=306
06/08/2022 13:00:14 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7052503116137467 on epoch=306
06/08/2022 13:00:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=307
06/08/2022 13:00:20 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=308
06/08/2022 13:00:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=309
06/08/2022 13:00:25 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.13 on epoch=311
06/08/2022 13:00:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=312
06/08/2022 13:00:29 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.6803194789081886 on epoch=312
06/08/2022 13:00:32 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=313
06/08/2022 13:00:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=314
06/08/2022 13:00:37 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=316
06/08/2022 13:00:40 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.07 on epoch=317
06/08/2022 13:00:42 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=318
06/08/2022 13:00:44 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.7099736864442747 on epoch=318
06/08/2022 13:00:47 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=319
06/08/2022 13:00:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=321
06/08/2022 13:00:52 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=322
06/08/2022 13:00:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.10 on epoch=323
06/08/2022 13:00:57 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=324
06/08/2022 13:00:59 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.6824869729704007 on epoch=324
06/08/2022 13:01:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
06/08/2022 13:01:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=327
06/08/2022 13:01:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=328
06/08/2022 13:01:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=329
06/08/2022 13:01:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
06/08/2022 13:01:14 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6845919388489049 on epoch=331
06/08/2022 13:01:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=332
06/08/2022 13:01:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=333
06/08/2022 13:01:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=334
06/08/2022 13:01:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=336
06/08/2022 13:01:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=337
06/08/2022 13:01:29 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6924928774928775 on epoch=337
06/08/2022 13:01:32 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/08/2022 13:01:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=339
06/08/2022 13:01:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
06/08/2022 13:01:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=342
06/08/2022 13:01:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=343
06/08/2022 13:01:44 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6929965836512325 on epoch=343
06/08/2022 13:01:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=344
06/08/2022 13:01:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=346
06/08/2022 13:01:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=347
06/08/2022 13:01:54 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.09 on epoch=348
06/08/2022 13:01:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=349
06/08/2022 13:01:59 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7025701871657755 on epoch=349
06/08/2022 13:02:01 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
06/08/2022 13:02:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.11 on epoch=352
06/08/2022 13:02:06 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=353
06/08/2022 13:02:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/08/2022 13:02:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
06/08/2022 13:02:13 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7115714706935407 on epoch=356
06/08/2022 13:02:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
06/08/2022 13:02:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=358
06/08/2022 13:02:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=359
06/08/2022 13:02:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=361
06/08/2022 13:02:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/08/2022 13:02:28 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7161015498781456 on epoch=362
06/08/2022 13:02:31 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=363
06/08/2022 13:02:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=364
06/08/2022 13:02:36 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
06/08/2022 13:02:38 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=367
06/08/2022 13:02:41 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=368
06/08/2022 13:02:43 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6817157752283702 on epoch=368
06/08/2022 13:02:45 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=369
06/08/2022 13:02:48 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=371
06/08/2022 13:02:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=372
06/08/2022 13:02:53 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=373
06/08/2022 13:02:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=374
06/08/2022 13:02:57 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:02:57 - INFO - __main__ - Printing 3 examples
06/08/2022 13:02:57 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 13:02:57 - INFO - __main__ - ['sad']
06/08/2022 13:02:57 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 13:02:57 - INFO - __main__ - ['sad']
06/08/2022 13:02:57 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 13:02:57 - INFO - __main__ - ['sad']
06/08/2022 13:02:57 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:02:57 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:02:57 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 13:02:57 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:02:57 - INFO - __main__ - Printing 3 examples
06/08/2022 13:02:57 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/08/2022 13:02:57 - INFO - __main__ - ['sad']
06/08/2022 13:02:57 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/08/2022 13:02:57 - INFO - __main__ - ['sad']
06/08/2022 13:02:57 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/08/2022 13:02:57 - INFO - __main__ - ['sad']
06/08/2022 13:02:57 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:02:57 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:02:58 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 13:02:58 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7287795922228241 on epoch=374
06/08/2022 13:02:58 - INFO - __main__ - save last model!
06/08/2022 13:02:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 13:02:58 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 13:02:58 - INFO - __main__ - Printing 3 examples
06/08/2022 13:02:58 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 13:02:58 - INFO - __main__ - ['others']
06/08/2022 13:02:58 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 13:02:58 - INFO - __main__ - ['others']
06/08/2022 13:02:58 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 13:02:58 - INFO - __main__ - ['others']
06/08/2022 13:02:58 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:03:00 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:03:05 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 13:03:17 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 13:03:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 13:03:18 - INFO - __main__ - Starting training!
06/08/2022 13:04:21 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_21_0.4_8_predictions.txt
06/08/2022 13:04:21 - INFO - __main__ - Classification-F1 on test data: 0.1988
06/08/2022 13:04:21 - INFO - __main__ - prefix=emo_32_21, lr=0.4, bsz=8, dev_performance=0.7478150713722239, test_performance=0.19882167790363736
06/08/2022 13:04:21 - INFO - __main__ - Running ... prefix=emo_32_21, lr=0.3, bsz=8 ...
06/08/2022 13:04:22 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:04:22 - INFO - __main__ - Printing 3 examples
06/08/2022 13:04:22 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 13:04:22 - INFO - __main__ - ['sad']
06/08/2022 13:04:22 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 13:04:22 - INFO - __main__ - ['sad']
06/08/2022 13:04:22 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 13:04:22 - INFO - __main__ - ['sad']
06/08/2022 13:04:22 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:04:22 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:04:23 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 13:04:23 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:04:23 - INFO - __main__ - Printing 3 examples
06/08/2022 13:04:23 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/08/2022 13:04:23 - INFO - __main__ - ['sad']
06/08/2022 13:04:23 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/08/2022 13:04:23 - INFO - __main__ - ['sad']
06/08/2022 13:04:23 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/08/2022 13:04:23 - INFO - __main__ - ['sad']
06/08/2022 13:04:23 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:04:23 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:04:23 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 13:04:39 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 13:04:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 13:04:40 - INFO - __main__ - Starting training!
06/08/2022 13:04:43 - INFO - __main__ - Step 10 Global step 10 Train loss 2.86 on epoch=1
06/08/2022 13:04:46 - INFO - __main__ - Step 20 Global step 20 Train loss 1.59 on epoch=2
06/08/2022 13:04:48 - INFO - __main__ - Step 30 Global step 30 Train loss 1.18 on epoch=3
06/08/2022 13:04:51 - INFO - __main__ - Step 40 Global step 40 Train loss 0.87 on epoch=4
06/08/2022 13:04:54 - INFO - __main__ - Step 50 Global step 50 Train loss 1.01 on epoch=6
06/08/2022 13:04:56 - INFO - __main__ - Global step 50 Train loss 1.50 Classification-F1 0.24081632653061225 on epoch=6
06/08/2022 13:04:56 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.24081632653061225 on epoch=6, global_step=50
06/08/2022 13:04:58 - INFO - __main__ - Step 60 Global step 60 Train loss 0.89 on epoch=7
06/08/2022 13:05:01 - INFO - __main__ - Step 70 Global step 70 Train loss 0.89 on epoch=8
06/08/2022 13:05:04 - INFO - __main__ - Step 80 Global step 80 Train loss 0.77 on epoch=9
06/08/2022 13:05:06 - INFO - __main__ - Step 90 Global step 90 Train loss 0.88 on epoch=11
06/08/2022 13:05:09 - INFO - __main__ - Step 100 Global step 100 Train loss 0.73 on epoch=12
06/08/2022 13:05:10 - INFO - __main__ - Global step 100 Train loss 0.83 Classification-F1 0.3494642454319874 on epoch=12
06/08/2022 13:05:11 - INFO - __main__ - Saving model with best Classification-F1: 0.24081632653061225 -> 0.3494642454319874 on epoch=12, global_step=100
06/08/2022 13:05:13 - INFO - __main__ - Step 110 Global step 110 Train loss 0.89 on epoch=13
06/08/2022 13:05:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.82 on epoch=14
06/08/2022 13:05:19 - INFO - __main__ - Step 130 Global step 130 Train loss 0.85 on epoch=16
06/08/2022 13:05:21 - INFO - __main__ - Step 140 Global step 140 Train loss 0.70 on epoch=17
06/08/2022 13:05:24 - INFO - __main__ - Step 150 Global step 150 Train loss 0.81 on epoch=18
06/08/2022 13:05:26 - INFO - __main__ - Global step 150 Train loss 0.81 Classification-F1 0.5443632741409854 on epoch=18
06/08/2022 13:05:26 - INFO - __main__ - Saving model with best Classification-F1: 0.3494642454319874 -> 0.5443632741409854 on epoch=18, global_step=150
06/08/2022 13:05:28 - INFO - __main__ - Step 160 Global step 160 Train loss 0.75 on epoch=19
06/08/2022 13:05:31 - INFO - __main__ - Step 170 Global step 170 Train loss 0.66 on epoch=21
06/08/2022 13:05:34 - INFO - __main__ - Step 180 Global step 180 Train loss 0.76 on epoch=22
06/08/2022 13:05:36 - INFO - __main__ - Step 190 Global step 190 Train loss 0.72 on epoch=23
06/08/2022 13:05:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.62 on epoch=24
06/08/2022 13:05:41 - INFO - __main__ - Global step 200 Train loss 0.70 Classification-F1 0.5940136054938583 on epoch=24
06/08/2022 13:05:41 - INFO - __main__ - Saving model with best Classification-F1: 0.5443632741409854 -> 0.5940136054938583 on epoch=24, global_step=200
06/08/2022 13:05:44 - INFO - __main__ - Step 210 Global step 210 Train loss 0.67 on epoch=26
06/08/2022 13:05:46 - INFO - __main__ - Step 220 Global step 220 Train loss 0.69 on epoch=27
06/08/2022 13:05:49 - INFO - __main__ - Step 230 Global step 230 Train loss 0.67 on epoch=28
06/08/2022 13:05:52 - INFO - __main__ - Step 240 Global step 240 Train loss 0.61 on epoch=29
06/08/2022 13:05:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.70 on epoch=31
06/08/2022 13:05:56 - INFO - __main__ - Global step 250 Train loss 0.67 Classification-F1 0.546544969339087 on epoch=31
06/08/2022 13:05:59 - INFO - __main__ - Step 260 Global step 260 Train loss 0.64 on epoch=32
06/08/2022 13:06:02 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=33
06/08/2022 13:06:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.55 on epoch=34
06/08/2022 13:06:07 - INFO - __main__ - Step 290 Global step 290 Train loss 0.61 on epoch=36
06/08/2022 13:06:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.60 on epoch=37
06/08/2022 13:06:11 - INFO - __main__ - Global step 300 Train loss 0.59 Classification-F1 0.5988443621595796 on epoch=37
06/08/2022 13:06:11 - INFO - __main__ - Saving model with best Classification-F1: 0.5940136054938583 -> 0.5988443621595796 on epoch=37, global_step=300
06/08/2022 13:06:14 - INFO - __main__ - Step 310 Global step 310 Train loss 0.61 on epoch=38
06/08/2022 13:06:17 - INFO - __main__ - Step 320 Global step 320 Train loss 0.59 on epoch=39
06/08/2022 13:06:19 - INFO - __main__ - Step 330 Global step 330 Train loss 0.64 on epoch=41
06/08/2022 13:06:22 - INFO - __main__ - Step 340 Global step 340 Train loss 0.58 on epoch=42
06/08/2022 13:06:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.53 on epoch=43
06/08/2022 13:06:27 - INFO - __main__ - Global step 350 Train loss 0.59 Classification-F1 0.5970198765532806 on epoch=43
06/08/2022 13:06:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.53 on epoch=44
06/08/2022 13:06:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.55 on epoch=46
06/08/2022 13:06:35 - INFO - __main__ - Step 380 Global step 380 Train loss 0.54 on epoch=47
06/08/2022 13:06:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.45 on epoch=48
06/08/2022 13:06:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.44 on epoch=49
06/08/2022 13:06:42 - INFO - __main__ - Global step 400 Train loss 0.50 Classification-F1 0.6875923645320197 on epoch=49
06/08/2022 13:06:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5988443621595796 -> 0.6875923645320197 on epoch=49, global_step=400
06/08/2022 13:06:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.57 on epoch=51
06/08/2022 13:06:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.48 on epoch=52
06/08/2022 13:06:50 - INFO - __main__ - Step 430 Global step 430 Train loss 0.45 on epoch=53
06/08/2022 13:06:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.42 on epoch=54
06/08/2022 13:06:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.37 on epoch=56
06/08/2022 13:06:57 - INFO - __main__ - Global step 450 Train loss 0.46 Classification-F1 0.6617720507441816 on epoch=56
06/08/2022 13:07:00 - INFO - __main__ - Step 460 Global step 460 Train loss 0.39 on epoch=57
06/08/2022 13:07:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.45 on epoch=58
06/08/2022 13:07:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.39 on epoch=59
06/08/2022 13:07:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.48 on epoch=61
06/08/2022 13:07:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.41 on epoch=62
06/08/2022 13:07:12 - INFO - __main__ - Global step 500 Train loss 0.42 Classification-F1 0.6579606975833391 on epoch=62
06/08/2022 13:07:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=63
06/08/2022 13:07:18 - INFO - __main__ - Step 520 Global step 520 Train loss 0.33 on epoch=64
06/08/2022 13:07:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=66
06/08/2022 13:07:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.42 on epoch=67
06/08/2022 13:07:26 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=68
06/08/2022 13:07:28 - INFO - __main__ - Global step 550 Train loss 0.38 Classification-F1 0.4980705984370208 on epoch=68
06/08/2022 13:07:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.28 on epoch=69
06/08/2022 13:07:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=71
06/08/2022 13:07:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.36 on epoch=72
06/08/2022 13:07:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.42 on epoch=73
06/08/2022 13:07:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.42 on epoch=74
06/08/2022 13:07:43 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.6239767609988938 on epoch=74
06/08/2022 13:07:45 - INFO - __main__ - Step 610 Global step 610 Train loss 0.37 on epoch=76
06/08/2022 13:07:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.43 on epoch=77
06/08/2022 13:07:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.42 on epoch=78
06/08/2022 13:07:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.30 on epoch=79
06/08/2022 13:07:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.33 on epoch=81
06/08/2022 13:07:58 - INFO - __main__ - Global step 650 Train loss 0.37 Classification-F1 0.6157735960237753 on epoch=81
06/08/2022 13:08:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=82
06/08/2022 13:08:03 - INFO - __main__ - Step 670 Global step 670 Train loss 0.33 on epoch=83
06/08/2022 13:08:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.36 on epoch=84
06/08/2022 13:08:08 - INFO - __main__ - Step 690 Global step 690 Train loss 0.41 on epoch=86
06/08/2022 13:08:11 - INFO - __main__ - Step 700 Global step 700 Train loss 0.37 on epoch=87
06/08/2022 13:08:13 - INFO - __main__ - Global step 700 Train loss 0.34 Classification-F1 0.6581691297208538 on epoch=87
06/08/2022 13:08:16 - INFO - __main__ - Step 710 Global step 710 Train loss 0.30 on epoch=88
06/08/2022 13:08:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=89
06/08/2022 13:08:21 - INFO - __main__ - Step 730 Global step 730 Train loss 0.33 on epoch=91
06/08/2022 13:08:24 - INFO - __main__ - Step 740 Global step 740 Train loss 0.31 on epoch=92
06/08/2022 13:08:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.25 on epoch=93
06/08/2022 13:08:28 - INFO - __main__ - Global step 750 Train loss 0.29 Classification-F1 0.6458673407969182 on epoch=93
06/08/2022 13:08:31 - INFO - __main__ - Step 760 Global step 760 Train loss 0.30 on epoch=94
06/08/2022 13:08:34 - INFO - __main__ - Step 770 Global step 770 Train loss 0.28 on epoch=96
06/08/2022 13:08:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=97
06/08/2022 13:08:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.31 on epoch=98
06/08/2022 13:08:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=99
06/08/2022 13:08:43 - INFO - __main__ - Global step 800 Train loss 0.26 Classification-F1 0.6491778595032511 on epoch=99
06/08/2022 13:08:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=101
06/08/2022 13:08:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.36 on epoch=102
06/08/2022 13:08:51 - INFO - __main__ - Step 830 Global step 830 Train loss 0.23 on epoch=103
06/08/2022 13:08:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.27 on epoch=104
06/08/2022 13:08:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.24 on epoch=106
06/08/2022 13:08:58 - INFO - __main__ - Global step 850 Train loss 0.25 Classification-F1 0.7000827185334227 on epoch=106
06/08/2022 13:08:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6875923645320197 -> 0.7000827185334227 on epoch=106, global_step=850
06/08/2022 13:09:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=107
06/08/2022 13:09:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=108
06/08/2022 13:09:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=109
06/08/2022 13:09:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.37 on epoch=111
06/08/2022 13:09:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=112
06/08/2022 13:09:13 - INFO - __main__ - Global step 900 Train loss 0.23 Classification-F1 0.6747016999019287 on epoch=112
06/08/2022 13:09:16 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=113
06/08/2022 13:09:18 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=114
06/08/2022 13:09:21 - INFO - __main__ - Step 930 Global step 930 Train loss 0.29 on epoch=116
06/08/2022 13:09:24 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=117
06/08/2022 13:09:26 - INFO - __main__ - Step 950 Global step 950 Train loss 0.26 on epoch=118
06/08/2022 13:09:28 - INFO - __main__ - Global step 950 Train loss 0.23 Classification-F1 0.6101960536301544 on epoch=118
06/08/2022 13:09:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.23 on epoch=119
06/08/2022 13:09:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.27 on epoch=121
06/08/2022 13:09:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.21 on epoch=122
06/08/2022 13:09:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=123
06/08/2022 13:09:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=124
06/08/2022 13:09:44 - INFO - __main__ - Global step 1000 Train loss 0.21 Classification-F1 0.6897184592430773 on epoch=124
06/08/2022 13:09:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=126
06/08/2022 13:09:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=127
06/08/2022 13:09:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=128
06/08/2022 13:09:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.24 on epoch=129
06/08/2022 13:09:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.23 on epoch=131
06/08/2022 13:09:59 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.5945596478869 on epoch=131
06/08/2022 13:10:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=132
06/08/2022 13:10:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.26 on epoch=133
06/08/2022 13:10:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.21 on epoch=134
06/08/2022 13:10:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.18 on epoch=136
06/08/2022 13:10:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.20 on epoch=137
06/08/2022 13:10:14 - INFO - __main__ - Global step 1100 Train loss 0.20 Classification-F1 0.6754769984917044 on epoch=137
06/08/2022 13:10:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=138
06/08/2022 13:10:20 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=139
06/08/2022 13:10:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.21 on epoch=141
06/08/2022 13:10:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=142
06/08/2022 13:10:28 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=143
06/08/2022 13:10:29 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.7158498440296065 on epoch=143
06/08/2022 13:10:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7000827185334227 -> 0.7158498440296065 on epoch=143, global_step=1150
06/08/2022 13:10:32 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=144
06/08/2022 13:10:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=146
06/08/2022 13:10:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=147
06/08/2022 13:10:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=148
06/08/2022 13:10:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.23 on epoch=149
06/08/2022 13:10:45 - INFO - __main__ - Global step 1200 Train loss 0.16 Classification-F1 0.5252619956583577 on epoch=149
06/08/2022 13:10:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=151
06/08/2022 13:10:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.18 on epoch=152
06/08/2022 13:10:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=153
06/08/2022 13:10:56 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=154
06/08/2022 13:10:59 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=156
06/08/2022 13:11:00 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.7042352474739524 on epoch=156
06/08/2022 13:11:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=157
06/08/2022 13:11:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=158
06/08/2022 13:11:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=159
06/08/2022 13:11:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=161
06/08/2022 13:11:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=162
06/08/2022 13:11:16 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.5617481840193704 on epoch=162
06/08/2022 13:11:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=163
06/08/2022 13:11:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=164
06/08/2022 13:11:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=166
06/08/2022 13:11:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=167
06/08/2022 13:11:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=168
06/08/2022 13:11:31 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.6484967271050291 on epoch=168
06/08/2022 13:11:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.15 on epoch=169
06/08/2022 13:11:37 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=171
06/08/2022 13:11:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=172
06/08/2022 13:11:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=173
06/08/2022 13:11:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.19 on epoch=174
06/08/2022 13:11:47 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.6519220129011363 on epoch=174
06/08/2022 13:11:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=176
06/08/2022 13:11:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=177
06/08/2022 13:11:54 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=178
06/08/2022 13:11:57 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=179
06/08/2022 13:12:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=181
06/08/2022 13:12:01 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.7237374031984077 on epoch=181
06/08/2022 13:12:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7158498440296065 -> 0.7237374031984077 on epoch=181, global_step=1450
06/08/2022 13:12:04 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=182
06/08/2022 13:12:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=183
06/08/2022 13:12:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.16 on epoch=184
06/08/2022 13:12:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=186
06/08/2022 13:12:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=187
06/08/2022 13:12:16 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.6701834714992609 on epoch=187
06/08/2022 13:12:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=188
06/08/2022 13:12:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=189
06/08/2022 13:12:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=191
06/08/2022 13:12:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=192
06/08/2022 13:12:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=193
06/08/2022 13:12:31 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.7056313639871262 on epoch=193
06/08/2022 13:12:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=194
06/08/2022 13:12:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=196
06/08/2022 13:12:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=197
06/08/2022 13:12:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=198
06/08/2022 13:12:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=199
06/08/2022 13:12:47 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.7052834467120181 on epoch=199
06/08/2022 13:12:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=201
06/08/2022 13:12:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=202
06/08/2022 13:12:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=203
06/08/2022 13:12:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=204
06/08/2022 13:13:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=206
06/08/2022 13:13:02 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.6884239217572551 on epoch=206
06/08/2022 13:13:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=207
06/08/2022 13:13:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=208
06/08/2022 13:13:10 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=209
06/08/2022 13:13:13 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=211
06/08/2022 13:13:15 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=212
06/08/2022 13:13:17 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7221162343687861 on epoch=212
06/08/2022 13:13:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=213
06/08/2022 13:13:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=214
06/08/2022 13:13:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=216
06/08/2022 13:13:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.11 on epoch=217
06/08/2022 13:13:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=218
06/08/2022 13:13:33 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.7156454247339523 on epoch=218
06/08/2022 13:13:35 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=219
06/08/2022 13:13:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=221
06/08/2022 13:13:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=222
06/08/2022 13:13:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=223
06/08/2022 13:13:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=224
06/08/2022 13:13:48 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.6727374679874057 on epoch=224
06/08/2022 13:13:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=226
06/08/2022 13:13:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=227
06/08/2022 13:13:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=228
06/08/2022 13:13:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=229
06/08/2022 13:14:01 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.13 on epoch=231
06/08/2022 13:14:03 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.7228754940711463 on epoch=231
06/08/2022 13:14:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=232
06/08/2022 13:14:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=233
06/08/2022 13:14:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=234
06/08/2022 13:14:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=236
06/08/2022 13:14:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=237
06/08/2022 13:14:18 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.6837883874790166 on epoch=237
06/08/2022 13:14:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=238
06/08/2022 13:14:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=239
06/08/2022 13:14:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=241
06/08/2022 13:14:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.13 on epoch=242
06/08/2022 13:14:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=243
06/08/2022 13:14:33 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.7085459094731613 on epoch=243
06/08/2022 13:14:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=244
06/08/2022 13:14:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.12 on epoch=246
06/08/2022 13:14:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=247
06/08/2022 13:14:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=248
06/08/2022 13:14:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=249
06/08/2022 13:14:49 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.7092082626522077 on epoch=249
06/08/2022 13:14:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=251
06/08/2022 13:14:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=252
06/08/2022 13:14:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=253
06/08/2022 13:14:59 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=254
06/08/2022 13:15:02 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=256
06/08/2022 13:15:04 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.6698354341736695 on epoch=256
06/08/2022 13:15:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.13 on epoch=257
06/08/2022 13:15:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=258
06/08/2022 13:15:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=259
06/08/2022 13:15:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=261
06/08/2022 13:15:18 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=262
06/08/2022 13:15:20 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.7239971050454922 on epoch=262
06/08/2022 13:15:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7237374031984077 -> 0.7239971050454922 on epoch=262, global_step=2100
06/08/2022 13:15:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.11 on epoch=263
06/08/2022 13:15:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=264
06/08/2022 13:15:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=266
06/08/2022 13:15:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=267
06/08/2022 13:15:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=268
06/08/2022 13:15:35 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6745931964017071 on epoch=268
06/08/2022 13:15:38 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.09 on epoch=269
06/08/2022 13:15:41 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=271
06/08/2022 13:15:43 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=272
06/08/2022 13:15:46 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=273
06/08/2022 13:15:49 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=274
06/08/2022 13:15:51 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.6852159686354471 on epoch=274
06/08/2022 13:15:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=276
06/08/2022 13:15:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=277
06/08/2022 13:15:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=278
06/08/2022 13:16:02 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=279
06/08/2022 13:16:05 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.17 on epoch=281
06/08/2022 13:16:07 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.6841269841269841 on epoch=281
06/08/2022 13:16:09 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=282
06/08/2022 13:16:12 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=283
06/08/2022 13:16:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=284
06/08/2022 13:16:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=286
06/08/2022 13:16:20 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=287
06/08/2022 13:16:22 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7066722408026755 on epoch=287
06/08/2022 13:16:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=288
06/08/2022 13:16:27 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=289
06/08/2022 13:16:30 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=291
06/08/2022 13:16:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=292
06/08/2022 13:16:35 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=293
06/08/2022 13:16:38 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7190202162637145 on epoch=293
06/08/2022 13:16:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=294
06/08/2022 13:16:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=296
06/08/2022 13:16:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=297
06/08/2022 13:16:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=298
06/08/2022 13:16:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=299
06/08/2022 13:16:53 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7623086395464912 on epoch=299
06/08/2022 13:16:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7239971050454922 -> 0.7623086395464912 on epoch=299, global_step=2400
06/08/2022 13:16:56 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=301
06/08/2022 13:16:59 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=302
06/08/2022 13:17:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=303
06/08/2022 13:17:04 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.16 on epoch=304
06/08/2022 13:17:07 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=306
06/08/2022 13:17:09 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.6943806233228685 on epoch=306
06/08/2022 13:17:11 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=307
06/08/2022 13:17:14 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.11 on epoch=308
06/08/2022 13:17:16 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=309
06/08/2022 13:17:19 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=311
06/08/2022 13:17:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=312
06/08/2022 13:17:24 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.651498088998089 on epoch=312
06/08/2022 13:17:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=313
06/08/2022 13:17:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/08/2022 13:17:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=316
06/08/2022 13:17:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=317
06/08/2022 13:17:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=318
06/08/2022 13:17:40 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.6951610339809424 on epoch=318
06/08/2022 13:17:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=319
06/08/2022 13:17:45 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=321
06/08/2022 13:17:48 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=322
06/08/2022 13:17:50 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=323
06/08/2022 13:17:53 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=324
06/08/2022 13:17:55 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6773225843404548 on epoch=324
06/08/2022 13:17:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
06/08/2022 13:18:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=327
06/08/2022 13:18:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.08 on epoch=328
06/08/2022 13:18:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=329
06/08/2022 13:18:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=331
06/08/2022 13:18:11 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7319980375466969 on epoch=331
06/08/2022 13:18:13 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=332
06/08/2022 13:18:16 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=333
06/08/2022 13:18:19 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=334
06/08/2022 13:18:21 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=336
06/08/2022 13:18:24 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=337
06/08/2022 13:18:26 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.644216757741348 on epoch=337
06/08/2022 13:18:29 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/08/2022 13:18:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
06/08/2022 13:18:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=341
06/08/2022 13:18:37 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
06/08/2022 13:18:40 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
06/08/2022 13:18:42 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6834454796411318 on epoch=343
06/08/2022 13:18:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=344
06/08/2022 13:18:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.16 on epoch=346
06/08/2022 13:18:50 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=347
06/08/2022 13:18:53 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=348
06/08/2022 13:18:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
06/08/2022 13:18:57 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7543130888719124 on epoch=349
06/08/2022 13:19:00 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=351
06/08/2022 13:19:03 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=352
06/08/2022 13:19:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
06/08/2022 13:19:08 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=354
06/08/2022 13:19:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=356
06/08/2022 13:19:13 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.6698692810457516 on epoch=356
06/08/2022 13:19:15 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.15 on epoch=357
06/08/2022 13:19:18 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=358
06/08/2022 13:19:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/08/2022 13:19:23 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=361
06/08/2022 13:19:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/08/2022 13:19:28 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.6784242055030968 on epoch=362
06/08/2022 13:19:31 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=363
06/08/2022 13:19:34 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=364
06/08/2022 13:19:36 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=366
06/08/2022 13:19:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=367
06/08/2022 13:19:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=368
06/08/2022 13:19:44 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.705242744871228 on epoch=368
06/08/2022 13:19:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=369
06/08/2022 13:19:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=371
06/08/2022 13:19:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=372
06/08/2022 13:19:55 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=373
06/08/2022 13:19:58 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
06/08/2022 13:19:59 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:19:59 - INFO - __main__ - Printing 3 examples
06/08/2022 13:19:59 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 13:19:59 - INFO - __main__ - ['sad']
06/08/2022 13:19:59 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 13:19:59 - INFO - __main__ - ['sad']
06/08/2022 13:19:59 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 13:19:59 - INFO - __main__ - ['sad']
06/08/2022 13:19:59 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:19:59 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:19:59 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 13:19:59 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:19:59 - INFO - __main__ - Printing 3 examples
06/08/2022 13:19:59 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/08/2022 13:19:59 - INFO - __main__ - ['sad']
06/08/2022 13:19:59 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/08/2022 13:19:59 - INFO - __main__ - ['sad']
06/08/2022 13:19:59 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/08/2022 13:19:59 - INFO - __main__ - ['sad']
06/08/2022 13:19:59 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:19:59 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:19:59 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 13:20:00 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.6828066991172346 on epoch=374
06/08/2022 13:20:00 - INFO - __main__ - save last model!
06/08/2022 13:20:00 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 13:20:00 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 13:20:00 - INFO - __main__ - Printing 3 examples
06/08/2022 13:20:00 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 13:20:00 - INFO - __main__ - ['others']
06/08/2022 13:20:00 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 13:20:00 - INFO - __main__ - ['others']
06/08/2022 13:20:00 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 13:20:00 - INFO - __main__ - ['others']
06/08/2022 13:20:00 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:20:02 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:20:09 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 13:20:19 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 13:20:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 13:20:20 - INFO - __main__ - Starting training!
06/08/2022 13:21:49 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_21_0.3_8_predictions.txt
06/08/2022 13:21:49 - INFO - __main__ - Classification-F1 on test data: 0.2081
06/08/2022 13:21:50 - INFO - __main__ - prefix=emo_32_21, lr=0.3, bsz=8, dev_performance=0.7623086395464912, test_performance=0.2081054798985669
06/08/2022 13:21:50 - INFO - __main__ - Running ... prefix=emo_32_21, lr=0.2, bsz=8 ...
06/08/2022 13:21:51 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:21:51 - INFO - __main__ - Printing 3 examples
06/08/2022 13:21:51 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 13:21:51 - INFO - __main__ - ['sad']
06/08/2022 13:21:51 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 13:21:51 - INFO - __main__ - ['sad']
06/08/2022 13:21:51 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 13:21:51 - INFO - __main__ - ['sad']
06/08/2022 13:21:51 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:21:51 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:21:51 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 13:21:51 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:21:51 - INFO - __main__ - Printing 3 examples
06/08/2022 13:21:51 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/08/2022 13:21:51 - INFO - __main__ - ['sad']
06/08/2022 13:21:51 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/08/2022 13:21:51 - INFO - __main__ - ['sad']
06/08/2022 13:21:51 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/08/2022 13:21:51 - INFO - __main__ - ['sad']
06/08/2022 13:21:51 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:21:51 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:21:51 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 13:22:09 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 13:22:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 13:22:10 - INFO - __main__ - Starting training!
06/08/2022 13:22:13 - INFO - __main__ - Step 10 Global step 10 Train loss 3.17 on epoch=1
06/08/2022 13:22:16 - INFO - __main__ - Step 20 Global step 20 Train loss 1.93 on epoch=2
06/08/2022 13:22:18 - INFO - __main__ - Step 30 Global step 30 Train loss 1.40 on epoch=3
06/08/2022 13:22:21 - INFO - __main__ - Step 40 Global step 40 Train loss 1.14 on epoch=4
06/08/2022 13:22:23 - INFO - __main__ - Step 50 Global step 50 Train loss 1.12 on epoch=6
06/08/2022 13:22:25 - INFO - __main__ - Global step 50 Train loss 1.75 Classification-F1 0.11578044596912522 on epoch=6
06/08/2022 13:22:25 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11578044596912522 on epoch=6, global_step=50
06/08/2022 13:22:28 - INFO - __main__ - Step 60 Global step 60 Train loss 1.06 on epoch=7
06/08/2022 13:22:30 - INFO - __main__ - Step 70 Global step 70 Train loss 0.94 on epoch=8
06/08/2022 13:22:33 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=9
06/08/2022 13:22:35 - INFO - __main__ - Step 90 Global step 90 Train loss 0.83 on epoch=11
06/08/2022 13:22:38 - INFO - __main__ - Step 100 Global step 100 Train loss 0.89 on epoch=12
06/08/2022 13:22:40 - INFO - __main__ - Global step 100 Train loss 0.93 Classification-F1 0.22467836257309942 on epoch=12
06/08/2022 13:22:40 - INFO - __main__ - Saving model with best Classification-F1: 0.11578044596912522 -> 0.22467836257309942 on epoch=12, global_step=100
06/08/2022 13:22:42 - INFO - __main__ - Step 110 Global step 110 Train loss 0.88 on epoch=13
06/08/2022 13:22:45 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=14
06/08/2022 13:22:47 - INFO - __main__ - Step 130 Global step 130 Train loss 0.90 on epoch=16
06/08/2022 13:22:50 - INFO - __main__ - Step 140 Global step 140 Train loss 0.81 on epoch=17
06/08/2022 13:22:52 - INFO - __main__ - Step 150 Global step 150 Train loss 0.82 on epoch=18
06/08/2022 13:22:54 - INFO - __main__ - Global step 150 Train loss 0.87 Classification-F1 0.519276740546965 on epoch=18
06/08/2022 13:22:54 - INFO - __main__ - Saving model with best Classification-F1: 0.22467836257309942 -> 0.519276740546965 on epoch=18, global_step=150
06/08/2022 13:22:57 - INFO - __main__ - Step 160 Global step 160 Train loss 0.81 on epoch=19
06/08/2022 13:22:59 - INFO - __main__ - Step 170 Global step 170 Train loss 0.76 on epoch=21
06/08/2022 13:23:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.69 on epoch=22
06/08/2022 13:23:04 - INFO - __main__ - Step 190 Global step 190 Train loss 0.87 on epoch=23
06/08/2022 13:23:07 - INFO - __main__ - Step 200 Global step 200 Train loss 0.72 on epoch=24
06/08/2022 13:23:08 - INFO - __main__ - Global step 200 Train loss 0.77 Classification-F1 0.5321664242620125 on epoch=24
06/08/2022 13:23:08 - INFO - __main__ - Saving model with best Classification-F1: 0.519276740546965 -> 0.5321664242620125 on epoch=24, global_step=200
06/08/2022 13:23:11 - INFO - __main__ - Step 210 Global step 210 Train loss 0.79 on epoch=26
06/08/2022 13:23:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.72 on epoch=27
06/08/2022 13:23:16 - INFO - __main__ - Step 230 Global step 230 Train loss 0.67 on epoch=28
06/08/2022 13:23:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.72 on epoch=29
06/08/2022 13:23:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.65 on epoch=31
06/08/2022 13:23:23 - INFO - __main__ - Global step 250 Train loss 0.71 Classification-F1 0.5083769205622752 on epoch=31
06/08/2022 13:23:25 - INFO - __main__ - Step 260 Global step 260 Train loss 0.72 on epoch=32
06/08/2022 13:23:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.68 on epoch=33
06/08/2022 13:23:30 - INFO - __main__ - Step 280 Global step 280 Train loss 0.69 on epoch=34
06/08/2022 13:23:33 - INFO - __main__ - Step 290 Global step 290 Train loss 0.61 on epoch=36
06/08/2022 13:23:35 - INFO - __main__ - Step 300 Global step 300 Train loss 0.63 on epoch=37
06/08/2022 13:23:37 - INFO - __main__ - Global step 300 Train loss 0.67 Classification-F1 0.43407970973992105 on epoch=37
06/08/2022 13:23:40 - INFO - __main__ - Step 310 Global step 310 Train loss 0.66 on epoch=38
06/08/2022 13:23:42 - INFO - __main__ - Step 320 Global step 320 Train loss 0.73 on epoch=39
06/08/2022 13:23:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.63 on epoch=41
06/08/2022 13:23:47 - INFO - __main__ - Step 340 Global step 340 Train loss 0.77 on epoch=42
06/08/2022 13:23:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.69 on epoch=43
06/08/2022 13:23:52 - INFO - __main__ - Global step 350 Train loss 0.70 Classification-F1 0.6522360214163492 on epoch=43
06/08/2022 13:23:52 - INFO - __main__ - Saving model with best Classification-F1: 0.5321664242620125 -> 0.6522360214163492 on epoch=43, global_step=350
06/08/2022 13:23:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=44
06/08/2022 13:23:57 - INFO - __main__ - Step 370 Global step 370 Train loss 0.56 on epoch=46
06/08/2022 13:23:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.67 on epoch=47
06/08/2022 13:24:02 - INFO - __main__ - Step 390 Global step 390 Train loss 0.64 on epoch=48
06/08/2022 13:24:04 - INFO - __main__ - Step 400 Global step 400 Train loss 0.53 on epoch=49
06/08/2022 13:24:06 - INFO - __main__ - Global step 400 Train loss 0.59 Classification-F1 0.6717266253429774 on epoch=49
06/08/2022 13:24:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6522360214163492 -> 0.6717266253429774 on epoch=49, global_step=400
06/08/2022 13:24:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.61 on epoch=51
06/08/2022 13:24:11 - INFO - __main__ - Step 420 Global step 420 Train loss 0.63 on epoch=52
06/08/2022 13:24:14 - INFO - __main__ - Step 430 Global step 430 Train loss 0.60 on epoch=53
06/08/2022 13:24:16 - INFO - __main__ - Step 440 Global step 440 Train loss 0.47 on epoch=54
06/08/2022 13:24:19 - INFO - __main__ - Step 450 Global step 450 Train loss 0.61 on epoch=56
06/08/2022 13:24:21 - INFO - __main__ - Global step 450 Train loss 0.58 Classification-F1 0.5513468511120672 on epoch=56
06/08/2022 13:24:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.52 on epoch=57
06/08/2022 13:24:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.53 on epoch=58
06/08/2022 13:24:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.53 on epoch=59
06/08/2022 13:24:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.53 on epoch=61
06/08/2022 13:24:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.54 on epoch=62
06/08/2022 13:24:35 - INFO - __main__ - Global step 500 Train loss 0.53 Classification-F1 0.6241002214839424 on epoch=62
06/08/2022 13:24:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.52 on epoch=63
06/08/2022 13:24:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.59 on epoch=64
06/08/2022 13:24:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.47 on epoch=66
06/08/2022 13:24:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.51 on epoch=67
06/08/2022 13:24:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.45 on epoch=68
06/08/2022 13:24:50 - INFO - __main__ - Global step 550 Train loss 0.51 Classification-F1 0.6211639699466336 on epoch=68
06/08/2022 13:24:52 - INFO - __main__ - Step 560 Global step 560 Train loss 0.48 on epoch=69
06/08/2022 13:24:55 - INFO - __main__ - Step 570 Global step 570 Train loss 0.49 on epoch=71
06/08/2022 13:24:57 - INFO - __main__ - Step 580 Global step 580 Train loss 0.54 on epoch=72
06/08/2022 13:25:00 - INFO - __main__ - Step 590 Global step 590 Train loss 0.47 on epoch=73
06/08/2022 13:25:02 - INFO - __main__ - Step 600 Global step 600 Train loss 0.50 on epoch=74
06/08/2022 13:25:04 - INFO - __main__ - Global step 600 Train loss 0.49 Classification-F1 0.6703556083220262 on epoch=74
06/08/2022 13:25:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.50 on epoch=76
06/08/2022 13:25:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.50 on epoch=77
06/08/2022 13:25:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.52 on epoch=78
06/08/2022 13:25:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.35 on epoch=79
06/08/2022 13:25:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.42 on epoch=81
06/08/2022 13:25:18 - INFO - __main__ - Global step 650 Train loss 0.46 Classification-F1 0.6508940803230225 on epoch=81
06/08/2022 13:25:21 - INFO - __main__ - Step 660 Global step 660 Train loss 0.44 on epoch=82
06/08/2022 13:25:23 - INFO - __main__ - Step 670 Global step 670 Train loss 0.43 on epoch=83
06/08/2022 13:25:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.43 on epoch=84
06/08/2022 13:25:28 - INFO - __main__ - Step 690 Global step 690 Train loss 0.40 on epoch=86
06/08/2022 13:25:31 - INFO - __main__ - Step 700 Global step 700 Train loss 0.39 on epoch=87
06/08/2022 13:25:32 - INFO - __main__ - Global step 700 Train loss 0.42 Classification-F1 0.6399613899613901 on epoch=87
06/08/2022 13:25:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.41 on epoch=88
06/08/2022 13:25:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.39 on epoch=89
06/08/2022 13:25:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.41 on epoch=91
06/08/2022 13:25:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.42 on epoch=92
06/08/2022 13:25:45 - INFO - __main__ - Step 750 Global step 750 Train loss 0.47 on epoch=93
06/08/2022 13:25:47 - INFO - __main__ - Global step 750 Train loss 0.42 Classification-F1 0.7090027948728539 on epoch=93
06/08/2022 13:25:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6717266253429774 -> 0.7090027948728539 on epoch=93, global_step=750
06/08/2022 13:25:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.43 on epoch=94
06/08/2022 13:25:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.43 on epoch=96
06/08/2022 13:25:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.34 on epoch=97
06/08/2022 13:25:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.39 on epoch=98
06/08/2022 13:25:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.39 on epoch=99
06/08/2022 13:26:01 - INFO - __main__ - Global step 800 Train loss 0.40 Classification-F1 0.6452683763544325 on epoch=99
06/08/2022 13:26:04 - INFO - __main__ - Step 810 Global step 810 Train loss 0.38 on epoch=101
06/08/2022 13:26:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.40 on epoch=102
06/08/2022 13:26:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.39 on epoch=103
06/08/2022 13:26:11 - INFO - __main__ - Step 840 Global step 840 Train loss 0.32 on epoch=104
06/08/2022 13:26:14 - INFO - __main__ - Step 850 Global step 850 Train loss 0.35 on epoch=106
06/08/2022 13:26:16 - INFO - __main__ - Global step 850 Train loss 0.37 Classification-F1 0.5940562456866806 on epoch=106
06/08/2022 13:26:18 - INFO - __main__ - Step 860 Global step 860 Train loss 0.39 on epoch=107
06/08/2022 13:26:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.39 on epoch=108
06/08/2022 13:26:23 - INFO - __main__ - Step 880 Global step 880 Train loss 0.37 on epoch=109
06/08/2022 13:26:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.33 on epoch=111
06/08/2022 13:26:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.41 on epoch=112
06/08/2022 13:26:30 - INFO - __main__ - Global step 900 Train loss 0.38 Classification-F1 0.6759366364629522 on epoch=112
06/08/2022 13:26:32 - INFO - __main__ - Step 910 Global step 910 Train loss 0.41 on epoch=113
06/08/2022 13:26:35 - INFO - __main__ - Step 920 Global step 920 Train loss 0.35 on epoch=114
06/08/2022 13:26:38 - INFO - __main__ - Step 930 Global step 930 Train loss 0.36 on epoch=116
06/08/2022 13:26:40 - INFO - __main__ - Step 940 Global step 940 Train loss 0.30 on epoch=117
06/08/2022 13:26:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.36 on epoch=118
06/08/2022 13:26:44 - INFO - __main__ - Global step 950 Train loss 0.35 Classification-F1 0.699671468455304 on epoch=118
06/08/2022 13:26:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.37 on epoch=119
06/08/2022 13:26:49 - INFO - __main__ - Step 970 Global step 970 Train loss 0.28 on epoch=121
06/08/2022 13:26:52 - INFO - __main__ - Step 980 Global step 980 Train loss 0.31 on epoch=122
06/08/2022 13:26:54 - INFO - __main__ - Step 990 Global step 990 Train loss 0.40 on epoch=123
06/08/2022 13:26:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.23 on epoch=124
06/08/2022 13:26:58 - INFO - __main__ - Global step 1000 Train loss 0.32 Classification-F1 0.682882977237816 on epoch=124
06/08/2022 13:27:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.28 on epoch=126
06/08/2022 13:27:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.29 on epoch=127
06/08/2022 13:27:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.30 on epoch=128
06/08/2022 13:27:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.29 on epoch=129
06/08/2022 13:27:11 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.37 on epoch=131
06/08/2022 13:27:13 - INFO - __main__ - Global step 1050 Train loss 0.31 Classification-F1 0.4989177489177489 on epoch=131
06/08/2022 13:27:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.34 on epoch=132
06/08/2022 13:27:18 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=133
06/08/2022 13:27:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.28 on epoch=134
06/08/2022 13:27:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.31 on epoch=136
06/08/2022 13:27:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.27 on epoch=137
06/08/2022 13:27:27 - INFO - __main__ - Global step 1100 Train loss 0.28 Classification-F1 0.6413120436453045 on epoch=137
06/08/2022 13:27:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.22 on epoch=138
06/08/2022 13:27:32 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.27 on epoch=139
06/08/2022 13:27:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.28 on epoch=141
06/08/2022 13:27:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.29 on epoch=142
06/08/2022 13:27:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.22 on epoch=143
06/08/2022 13:27:42 - INFO - __main__ - Global step 1150 Train loss 0.26 Classification-F1 0.654900002270096 on epoch=143
06/08/2022 13:27:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.22 on epoch=144
06/08/2022 13:27:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.32 on epoch=146
06/08/2022 13:27:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=147
06/08/2022 13:27:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.23 on epoch=148
06/08/2022 13:27:54 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.21 on epoch=149
06/08/2022 13:27:56 - INFO - __main__ - Global step 1200 Train loss 0.23 Classification-F1 0.64187919408956 on epoch=149
06/08/2022 13:27:59 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.22 on epoch=151
06/08/2022 13:28:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.18 on epoch=152
06/08/2022 13:28:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.21 on epoch=153
06/08/2022 13:28:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.19 on epoch=154
06/08/2022 13:28:09 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.22 on epoch=156
06/08/2022 13:28:11 - INFO - __main__ - Global step 1250 Train loss 0.21 Classification-F1 0.6641431677890011 on epoch=156
06/08/2022 13:28:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.20 on epoch=157
06/08/2022 13:28:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.17 on epoch=158
06/08/2022 13:28:18 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=159
06/08/2022 13:28:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.25 on epoch=161
06/08/2022 13:28:24 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.22 on epoch=162
06/08/2022 13:28:26 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.5804421945910901 on epoch=162
06/08/2022 13:28:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.18 on epoch=163
06/08/2022 13:28:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.22 on epoch=164
06/08/2022 13:28:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=166
06/08/2022 13:28:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.16 on epoch=167
06/08/2022 13:28:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=168
06/08/2022 13:28:40 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.6382607275126461 on epoch=168
06/08/2022 13:28:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.19 on epoch=169
06/08/2022 13:28:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.22 on epoch=171
06/08/2022 13:28:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.22 on epoch=172
06/08/2022 13:28:51 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=173
06/08/2022 13:28:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.21 on epoch=174
06/08/2022 13:28:55 - INFO - __main__ - Global step 1400 Train loss 0.20 Classification-F1 0.6625120910835197 on epoch=174
06/08/2022 13:28:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=176
06/08/2022 13:29:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.22 on epoch=177
06/08/2022 13:29:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=178
06/08/2022 13:29:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=179
06/08/2022 13:29:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.24 on epoch=181
06/08/2022 13:29:09 - INFO - __main__ - Global step 1450 Train loss 0.17 Classification-F1 0.6472100397808791 on epoch=181
06/08/2022 13:29:12 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.15 on epoch=182
06/08/2022 13:29:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.13 on epoch=183
06/08/2022 13:29:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=184
06/08/2022 13:29:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.16 on epoch=186
06/08/2022 13:29:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.29 on epoch=187
06/08/2022 13:29:25 - INFO - __main__ - Global step 1500 Train loss 0.18 Classification-F1 0.6683017473399434 on epoch=187
06/08/2022 13:29:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.17 on epoch=188
06/08/2022 13:29:30 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=189
06/08/2022 13:29:33 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.25 on epoch=191
06/08/2022 13:29:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=192
06/08/2022 13:29:39 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=193
06/08/2022 13:29:41 - INFO - __main__ - Global step 1550 Train loss 0.16 Classification-F1 0.6693208729989983 on epoch=193
06/08/2022 13:29:43 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.14 on epoch=194
06/08/2022 13:29:46 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=196
06/08/2022 13:29:48 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.24 on epoch=197
06/08/2022 13:29:51 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=198
06/08/2022 13:29:54 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=199
06/08/2022 13:29:56 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.6954304233671246 on epoch=199
06/08/2022 13:29:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.17 on epoch=201
06/08/2022 13:30:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=202
06/08/2022 13:30:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=203
06/08/2022 13:30:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=204
06/08/2022 13:30:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.21 on epoch=206
06/08/2022 13:30:11 - INFO - __main__ - Global step 1650 Train loss 0.15 Classification-F1 0.6344144479579246 on epoch=206
06/08/2022 13:30:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.16 on epoch=207
06/08/2022 13:30:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.14 on epoch=208
06/08/2022 13:30:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=209
06/08/2022 13:30:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=211
06/08/2022 13:30:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.17 on epoch=212
06/08/2022 13:30:26 - INFO - __main__ - Global step 1700 Train loss 0.14 Classification-F1 0.6748643324412726 on epoch=212
06/08/2022 13:30:28 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.19 on epoch=213
06/08/2022 13:30:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.14 on epoch=214
06/08/2022 13:30:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=216
06/08/2022 13:30:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.18 on epoch=217
06/08/2022 13:30:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.18 on epoch=218
06/08/2022 13:30:41 - INFO - __main__ - Global step 1750 Train loss 0.16 Classification-F1 0.6901292109309477 on epoch=218
06/08/2022 13:30:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.14 on epoch=219
06/08/2022 13:30:46 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.12 on epoch=221
06/08/2022 13:30:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=222
06/08/2022 13:30:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=223
06/08/2022 13:30:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=224
06/08/2022 13:30:56 - INFO - __main__ - Global step 1800 Train loss 0.12 Classification-F1 0.6771352281598184 on epoch=224
06/08/2022 13:30:59 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=226
06/08/2022 13:31:01 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.12 on epoch=227
06/08/2022 13:31:04 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.13 on epoch=228
06/08/2022 13:31:07 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=229
06/08/2022 13:31:10 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=231
06/08/2022 13:31:11 - INFO - __main__ - Global step 1850 Train loss 0.11 Classification-F1 0.6659036953433614 on epoch=231
06/08/2022 13:31:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=232
06/08/2022 13:31:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.13 on epoch=233
06/08/2022 13:31:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=234
06/08/2022 13:31:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.16 on epoch=236
06/08/2022 13:31:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=237
06/08/2022 13:31:27 - INFO - __main__ - Global step 1900 Train loss 0.13 Classification-F1 0.6638160504345085 on epoch=237
06/08/2022 13:31:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=238
06/08/2022 13:31:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=239
06/08/2022 13:31:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.17 on epoch=241
06/08/2022 13:31:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.16 on epoch=242
06/08/2022 13:31:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.15 on epoch=243
06/08/2022 13:31:42 - INFO - __main__ - Global step 1950 Train loss 0.13 Classification-F1 0.6582078574272172 on epoch=243
06/08/2022 13:31:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=244
06/08/2022 13:31:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.12 on epoch=246
06/08/2022 13:31:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.15 on epoch=247
06/08/2022 13:31:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.13 on epoch=248
06/08/2022 13:31:55 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=249
06/08/2022 13:31:57 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.7127861513107414 on epoch=249
06/08/2022 13:31:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7090027948728539 -> 0.7127861513107414 on epoch=249, global_step=2000
06/08/2022 13:32:00 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=251
06/08/2022 13:32:02 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=252
06/08/2022 13:32:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=253
06/08/2022 13:32:08 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=254
06/08/2022 13:32:10 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.11 on epoch=256
06/08/2022 13:32:12 - INFO - __main__ - Global step 2050 Train loss 0.10 Classification-F1 0.636146959655854 on epoch=256
06/08/2022 13:32:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=257
06/08/2022 13:32:18 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=258
06/08/2022 13:32:20 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=259
06/08/2022 13:32:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.10 on epoch=261
06/08/2022 13:32:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.15 on epoch=262
06/08/2022 13:32:28 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.6680475713012478 on epoch=262
06/08/2022 13:32:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=263
06/08/2022 13:32:33 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=264
06/08/2022 13:32:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=266
06/08/2022 13:32:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.10 on epoch=267
06/08/2022 13:32:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.11 on epoch=268
06/08/2022 13:32:43 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.6527928861262194 on epoch=268
06/08/2022 13:32:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=269
06/08/2022 13:32:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=271
06/08/2022 13:32:51 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.12 on epoch=272
06/08/2022 13:32:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=273
06/08/2022 13:32:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.19 on epoch=274
06/08/2022 13:32:59 - INFO - __main__ - Global step 2200 Train loss 0.11 Classification-F1 0.6611489585683135 on epoch=274
06/08/2022 13:33:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.10 on epoch=276
06/08/2022 13:33:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=277
06/08/2022 13:33:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=278
06/08/2022 13:33:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.11 on epoch=279
06/08/2022 13:33:12 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.09 on epoch=281
06/08/2022 13:33:14 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.6757714863371509 on epoch=281
06/08/2022 13:33:16 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=282
06/08/2022 13:33:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=283
06/08/2022 13:33:21 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=284
06/08/2022 13:33:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=286
06/08/2022 13:33:27 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.20 on epoch=287
06/08/2022 13:33:29 - INFO - __main__ - Global step 2300 Train loss 0.09 Classification-F1 0.6604953186348536 on epoch=287
06/08/2022 13:33:32 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=288
06/08/2022 13:33:34 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.10 on epoch=289
06/08/2022 13:33:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=291
06/08/2022 13:33:40 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.08 on epoch=292
06/08/2022 13:33:42 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=293
06/08/2022 13:33:44 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.6889565077970875 on epoch=293
06/08/2022 13:33:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.10 on epoch=294
06/08/2022 13:33:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=296
06/08/2022 13:33:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=297
06/08/2022 13:33:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=298
06/08/2022 13:33:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=299
06/08/2022 13:33:59 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.6884948384948384 on epoch=299
06/08/2022 13:34:02 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.10 on epoch=301
06/08/2022 13:34:05 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=302
06/08/2022 13:34:07 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=303
06/08/2022 13:34:10 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=304
06/08/2022 13:34:13 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=306
06/08/2022 13:34:15 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.6718148830895523 on epoch=306
06/08/2022 13:34:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=307
06/08/2022 13:34:20 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=308
06/08/2022 13:34:23 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=309
06/08/2022 13:34:26 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=311
06/08/2022 13:34:28 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=312
06/08/2022 13:34:30 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.7134627683541912 on epoch=312
06/08/2022 13:34:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7127861513107414 -> 0.7134627683541912 on epoch=312, global_step=2500
06/08/2022 13:34:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=313
06/08/2022 13:34:36 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=314
06/08/2022 13:34:39 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=316
06/08/2022 13:34:41 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=317
06/08/2022 13:34:44 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=318
06/08/2022 13:34:46 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.6519908430812685 on epoch=318
06/08/2022 13:34:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.12 on epoch=319
06/08/2022 13:34:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.17 on epoch=321
06/08/2022 13:34:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=322
06/08/2022 13:34:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=323
06/08/2022 13:35:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=324
06/08/2022 13:35:02 - INFO - __main__ - Global step 2600 Train loss 0.09 Classification-F1 0.7147274294333117 on epoch=324
06/08/2022 13:35:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7134627683541912 -> 0.7147274294333117 on epoch=324, global_step=2600
06/08/2022 13:35:04 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=326
06/08/2022 13:35:07 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.09 on epoch=327
06/08/2022 13:35:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=328
06/08/2022 13:35:13 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=329
06/08/2022 13:35:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=331
06/08/2022 13:35:18 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.6780563554757102 on epoch=331
06/08/2022 13:35:21 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=332
06/08/2022 13:35:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.12 on epoch=333
06/08/2022 13:35:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=334
06/08/2022 13:35:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=336
06/08/2022 13:35:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=337
06/08/2022 13:35:33 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.6933974358974359 on epoch=337
06/08/2022 13:35:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.13 on epoch=338
06/08/2022 13:35:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=339
06/08/2022 13:35:41 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.13 on epoch=341
06/08/2022 13:35:44 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.08 on epoch=342
06/08/2022 13:35:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=343
06/08/2022 13:35:48 - INFO - __main__ - Global step 2750 Train loss 0.09 Classification-F1 0.6310849093655394 on epoch=343
06/08/2022 13:35:51 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=344
06/08/2022 13:35:54 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=346
06/08/2022 13:35:57 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=347
06/08/2022 13:35:59 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=348
06/08/2022 13:36:02 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=349
06/08/2022 13:36:04 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.6795823095823096 on epoch=349
06/08/2022 13:36:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=351
06/08/2022 13:36:09 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=352
06/08/2022 13:36:12 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
06/08/2022 13:36:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=354
06/08/2022 13:36:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.08 on epoch=356
06/08/2022 13:36:20 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7121891009925096 on epoch=356
06/08/2022 13:36:23 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=357
06/08/2022 13:36:25 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=358
06/08/2022 13:36:28 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=359
06/08/2022 13:36:31 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=361
06/08/2022 13:36:33 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=362
06/08/2022 13:36:36 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.6978571428571428 on epoch=362
06/08/2022 13:36:38 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.10 on epoch=363
06/08/2022 13:36:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.06 on epoch=364
06/08/2022 13:36:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=366
06/08/2022 13:36:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=367
06/08/2022 13:36:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.07 on epoch=368
06/08/2022 13:36:51 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.675797900682012 on epoch=368
06/08/2022 13:36:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=369
06/08/2022 13:36:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=371
06/08/2022 13:36:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=372
06/08/2022 13:37:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=373
06/08/2022 13:37:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=374
06/08/2022 13:37:06 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:37:06 - INFO - __main__ - Printing 3 examples
06/08/2022 13:37:06 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 13:37:06 - INFO - __main__ - ['happy']
06/08/2022 13:37:06 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 13:37:06 - INFO - __main__ - ['happy']
06/08/2022 13:37:06 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 13:37:06 - INFO - __main__ - ['happy']
06/08/2022 13:37:06 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:37:06 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:37:06 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 13:37:06 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:37:06 - INFO - __main__ - Printing 3 examples
06/08/2022 13:37:06 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/08/2022 13:37:06 - INFO - __main__ - ['happy']
06/08/2022 13:37:06 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/08/2022 13:37:06 - INFO - __main__ - ['happy']
06/08/2022 13:37:06 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/08/2022 13:37:06 - INFO - __main__ - ['happy']
06/08/2022 13:37:06 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:37:06 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:37:06 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.6406272281639929 on epoch=374
06/08/2022 13:37:06 - INFO - __main__ - save last model!
06/08/2022 13:37:06 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 13:37:06 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 13:37:06 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 13:37:06 - INFO - __main__ - Printing 3 examples
06/08/2022 13:37:06 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 13:37:06 - INFO - __main__ - ['others']
06/08/2022 13:37:06 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 13:37:06 - INFO - __main__ - ['others']
06/08/2022 13:37:06 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 13:37:06 - INFO - __main__ - ['others']
06/08/2022 13:37:06 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:37:08 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:37:14 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 13:37:25 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 13:37:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 13:37:26 - INFO - __main__ - Starting training!
06/08/2022 13:38:34 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_21_0.2_8_predictions.txt
06/08/2022 13:38:34 - INFO - __main__ - Classification-F1 on test data: 0.1949
06/08/2022 13:38:34 - INFO - __main__ - prefix=emo_32_21, lr=0.2, bsz=8, dev_performance=0.7147274294333117, test_performance=0.19487591561949452
06/08/2022 13:38:34 - INFO - __main__ - Running ... prefix=emo_32_42, lr=0.5, bsz=8 ...
06/08/2022 13:38:35 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:38:35 - INFO - __main__ - Printing 3 examples
06/08/2022 13:38:35 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 13:38:35 - INFO - __main__ - ['happy']
06/08/2022 13:38:35 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 13:38:35 - INFO - __main__ - ['happy']
06/08/2022 13:38:35 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 13:38:35 - INFO - __main__ - ['happy']
06/08/2022 13:38:35 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:38:35 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:38:36 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 13:38:36 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:38:36 - INFO - __main__ - Printing 3 examples
06/08/2022 13:38:36 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/08/2022 13:38:36 - INFO - __main__ - ['happy']
06/08/2022 13:38:36 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/08/2022 13:38:36 - INFO - __main__ - ['happy']
06/08/2022 13:38:36 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/08/2022 13:38:36 - INFO - __main__ - ['happy']
06/08/2022 13:38:36 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:38:36 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:38:36 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 13:38:55 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 13:38:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 13:38:56 - INFO - __main__ - Starting training!
06/08/2022 13:38:59 - INFO - __main__ - Step 10 Global step 10 Train loss 2.57 on epoch=1
06/08/2022 13:39:02 - INFO - __main__ - Step 20 Global step 20 Train loss 1.13 on epoch=2
06/08/2022 13:39:04 - INFO - __main__ - Step 30 Global step 30 Train loss 1.07 on epoch=3
06/08/2022 13:39:07 - INFO - __main__ - Step 40 Global step 40 Train loss 0.99 on epoch=4
06/08/2022 13:39:10 - INFO - __main__ - Step 50 Global step 50 Train loss 0.97 on epoch=6
06/08/2022 13:39:12 - INFO - __main__ - Global step 50 Train loss 1.35 Classification-F1 0.1 on epoch=6
06/08/2022 13:39:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=6, global_step=50
06/08/2022 13:39:14 - INFO - __main__ - Step 60 Global step 60 Train loss 0.91 on epoch=7
06/08/2022 13:39:17 - INFO - __main__ - Step 70 Global step 70 Train loss 0.90 on epoch=8
06/08/2022 13:39:20 - INFO - __main__ - Step 80 Global step 80 Train loss 0.94 on epoch=9
06/08/2022 13:39:23 - INFO - __main__ - Step 90 Global step 90 Train loss 0.82 on epoch=11
06/08/2022 13:39:25 - INFO - __main__ - Step 100 Global step 100 Train loss 0.80 on epoch=12
06/08/2022 13:39:27 - INFO - __main__ - Global step 100 Train loss 0.87 Classification-F1 0.2992106551358408 on epoch=12
06/08/2022 13:39:27 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.2992106551358408 on epoch=12, global_step=100
06/08/2022 13:39:30 - INFO - __main__ - Step 110 Global step 110 Train loss 0.85 on epoch=13
06/08/2022 13:39:32 - INFO - __main__ - Step 120 Global step 120 Train loss 0.80 on epoch=14
06/08/2022 13:39:35 - INFO - __main__ - Step 130 Global step 130 Train loss 0.73 on epoch=16
06/08/2022 13:39:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.69 on epoch=17
06/08/2022 13:39:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.67 on epoch=18
06/08/2022 13:39:42 - INFO - __main__ - Global step 150 Train loss 0.75 Classification-F1 0.42894345238095233 on epoch=18
06/08/2022 13:39:42 - INFO - __main__ - Saving model with best Classification-F1: 0.2992106551358408 -> 0.42894345238095233 on epoch=18, global_step=150
06/08/2022 13:39:45 - INFO - __main__ - Step 160 Global step 160 Train loss 0.60 on epoch=19
06/08/2022 13:39:48 - INFO - __main__ - Step 170 Global step 170 Train loss 0.64 on epoch=21
06/08/2022 13:39:50 - INFO - __main__ - Step 180 Global step 180 Train loss 0.66 on epoch=22
06/08/2022 13:39:53 - INFO - __main__ - Step 190 Global step 190 Train loss 0.62 on epoch=23
06/08/2022 13:39:56 - INFO - __main__ - Step 200 Global step 200 Train loss 0.64 on epoch=24
06/08/2022 13:39:58 - INFO - __main__ - Global step 200 Train loss 0.63 Classification-F1 0.6375807975807976 on epoch=24
06/08/2022 13:39:58 - INFO - __main__ - Saving model with best Classification-F1: 0.42894345238095233 -> 0.6375807975807976 on epoch=24, global_step=200
06/08/2022 13:40:00 - INFO - __main__ - Step 210 Global step 210 Train loss 0.59 on epoch=26
06/08/2022 13:40:03 - INFO - __main__ - Step 220 Global step 220 Train loss 0.61 on epoch=27
06/08/2022 13:40:05 - INFO - __main__ - Step 230 Global step 230 Train loss 0.61 on epoch=28
06/08/2022 13:40:08 - INFO - __main__ - Step 240 Global step 240 Train loss 0.55 on epoch=29
06/08/2022 13:40:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.52 on epoch=31
06/08/2022 13:40:12 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.46894940865914236 on epoch=31
06/08/2022 13:40:15 - INFO - __main__ - Step 260 Global step 260 Train loss 0.50 on epoch=32
06/08/2022 13:40:18 - INFO - __main__ - Step 270 Global step 270 Train loss 0.57 on epoch=33
06/08/2022 13:40:21 - INFO - __main__ - Step 280 Global step 280 Train loss 0.51 on epoch=34
06/08/2022 13:40:23 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=36
06/08/2022 13:40:26 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=37
06/08/2022 13:40:28 - INFO - __main__ - Global step 300 Train loss 0.51 Classification-F1 0.6583333333333333 on epoch=37
06/08/2022 13:40:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6375807975807976 -> 0.6583333333333333 on epoch=37, global_step=300
06/08/2022 13:40:30 - INFO - __main__ - Step 310 Global step 310 Train loss 0.45 on epoch=38
06/08/2022 13:40:33 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=39
06/08/2022 13:40:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.40 on epoch=41
06/08/2022 13:40:38 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=42
06/08/2022 13:40:41 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=43
06/08/2022 13:40:43 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.6399696778289262 on epoch=43
06/08/2022 13:40:45 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=44
06/08/2022 13:40:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.34 on epoch=46
06/08/2022 13:40:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=47
06/08/2022 13:40:54 - INFO - __main__ - Step 390 Global step 390 Train loss 0.40 on epoch=48
06/08/2022 13:40:56 - INFO - __main__ - Step 400 Global step 400 Train loss 0.32 on epoch=49
06/08/2022 13:40:58 - INFO - __main__ - Global step 400 Train loss 0.34 Classification-F1 0.600569628112001 on epoch=49
06/08/2022 13:41:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.39 on epoch=51
06/08/2022 13:41:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.32 on epoch=52
06/08/2022 13:41:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.40 on epoch=53
06/08/2022 13:41:09 - INFO - __main__ - Step 440 Global step 440 Train loss 0.40 on epoch=54
06/08/2022 13:41:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.40 on epoch=56
06/08/2022 13:41:13 - INFO - __main__ - Global step 450 Train loss 0.38 Classification-F1 0.6821109218650203 on epoch=56
06/08/2022 13:41:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6583333333333333 -> 0.6821109218650203 on epoch=56, global_step=450
06/08/2022 13:41:16 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=57
06/08/2022 13:41:19 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=58
06/08/2022 13:41:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=59
06/08/2022 13:41:24 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=61
06/08/2022 13:41:27 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=62
06/08/2022 13:41:29 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.6794269546642282 on epoch=62
06/08/2022 13:41:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=63
06/08/2022 13:41:34 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=64
06/08/2022 13:41:37 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=66
06/08/2022 13:41:39 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=67
06/08/2022 13:41:42 - INFO - __main__ - Step 550 Global step 550 Train loss 0.26 on epoch=68
06/08/2022 13:41:44 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.6650148692599698 on epoch=68
06/08/2022 13:41:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=69
06/08/2022 13:41:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.27 on epoch=71
06/08/2022 13:41:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=72
06/08/2022 13:41:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.29 on epoch=73
06/08/2022 13:41:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.34 on epoch=74
06/08/2022 13:41:59 - INFO - __main__ - Global step 600 Train loss 0.28 Classification-F1 0.6225415979117404 on epoch=74
06/08/2022 13:42:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.32 on epoch=76
06/08/2022 13:42:04 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=77
06/08/2022 13:42:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=78
06/08/2022 13:42:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=79
06/08/2022 13:42:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.31 on epoch=81
06/08/2022 13:42:14 - INFO - __main__ - Global step 650 Train loss 0.27 Classification-F1 0.66109900373599 on epoch=81
06/08/2022 13:42:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=82
06/08/2022 13:42:19 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=83
06/08/2022 13:42:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=84
06/08/2022 13:42:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=86
06/08/2022 13:42:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=87
06/08/2022 13:42:29 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.6984494629279915 on epoch=87
06/08/2022 13:42:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6821109218650203 -> 0.6984494629279915 on epoch=87, global_step=700
06/08/2022 13:42:32 - INFO - __main__ - Step 710 Global step 710 Train loss 0.32 on epoch=88
06/08/2022 13:42:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=89
06/08/2022 13:42:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=91
06/08/2022 13:42:40 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=92
06/08/2022 13:42:43 - INFO - __main__ - Step 750 Global step 750 Train loss 0.24 on epoch=93
06/08/2022 13:42:45 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.7054233511586452 on epoch=93
06/08/2022 13:42:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6984494629279915 -> 0.7054233511586452 on epoch=93, global_step=750
06/08/2022 13:42:47 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=94
06/08/2022 13:42:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=96
06/08/2022 13:42:53 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=97
06/08/2022 13:42:55 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=98
06/08/2022 13:42:58 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=99
06/08/2022 13:43:00 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.7082993446917524 on epoch=99
06/08/2022 13:43:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7054233511586452 -> 0.7082993446917524 on epoch=99, global_step=800
06/08/2022 13:43:03 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=101
06/08/2022 13:43:05 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=102
06/08/2022 13:43:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=103
06/08/2022 13:43:11 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=104
06/08/2022 13:43:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=106
06/08/2022 13:43:15 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.6953285256410257 on epoch=106
06/08/2022 13:43:18 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=107
06/08/2022 13:43:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=108
06/08/2022 13:43:23 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=109
06/08/2022 13:43:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=111
06/08/2022 13:43:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=112
06/08/2022 13:43:31 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.6720901098492593 on epoch=112
06/08/2022 13:43:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=113
06/08/2022 13:43:36 - INFO - __main__ - Step 920 Global step 920 Train loss 0.25 on epoch=114
06/08/2022 13:43:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=116
06/08/2022 13:43:41 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=117
06/08/2022 13:43:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=118
06/08/2022 13:43:46 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.680131339507634 on epoch=118
06/08/2022 13:43:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=119
06/08/2022 13:43:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=121
06/08/2022 13:43:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=122
06/08/2022 13:43:57 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=123
06/08/2022 13:43:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=124
06/08/2022 13:44:01 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.720061566293184 on epoch=124
06/08/2022 13:44:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7082993446917524 -> 0.720061566293184 on epoch=124, global_step=1000
06/08/2022 13:44:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=126
06/08/2022 13:44:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=127
06/08/2022 13:44:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=128
06/08/2022 13:44:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=129
06/08/2022 13:44:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=131
06/08/2022 13:44:17 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.6871390044828634 on epoch=131
06/08/2022 13:44:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=132
06/08/2022 13:44:22 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=133
06/08/2022 13:44:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=134
06/08/2022 13:44:27 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=136
06/08/2022 13:44:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=137
06/08/2022 13:44:32 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.664325251566477 on epoch=137
06/08/2022 13:44:35 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=138
06/08/2022 13:44:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=139
06/08/2022 13:44:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=141
06/08/2022 13:44:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=142
06/08/2022 13:44:45 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=143
06/08/2022 13:44:47 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.65201088246831 on epoch=143
06/08/2022 13:44:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=144
06/08/2022 13:44:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=146
06/08/2022 13:44:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=147
06/08/2022 13:44:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=148
06/08/2022 13:45:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=149
06/08/2022 13:45:02 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.6660051900092322 on epoch=149
06/08/2022 13:45:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=151
06/08/2022 13:45:08 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=152
06/08/2022 13:45:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=153
06/08/2022 13:45:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=154
06/08/2022 13:45:16 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=156
06/08/2022 13:45:18 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.6899322605662026 on epoch=156
06/08/2022 13:45:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=157
06/08/2022 13:45:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=158
06/08/2022 13:45:25 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=159
06/08/2022 13:45:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=161
06/08/2022 13:45:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=162
06/08/2022 13:45:33 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.6843515230876416 on epoch=162
06/08/2022 13:45:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=163
06/08/2022 13:45:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=164
06/08/2022 13:45:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=166
06/08/2022 13:45:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.18 on epoch=167
06/08/2022 13:45:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=168
06/08/2022 13:45:48 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.6162907268170426 on epoch=168
06/08/2022 13:45:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=169
06/08/2022 13:45:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=171
06/08/2022 13:45:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=172
06/08/2022 13:45:59 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=173
06/08/2022 13:46:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=174
06/08/2022 13:46:04 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6763550283771758 on epoch=174
06/08/2022 13:46:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.15 on epoch=176
06/08/2022 13:46:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=177
06/08/2022 13:46:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=178
06/08/2022 13:46:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=179
06/08/2022 13:46:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=181
06/08/2022 13:46:19 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.6903936102742984 on epoch=181
06/08/2022 13:46:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=182
06/08/2022 13:46:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=183
06/08/2022 13:46:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=184
06/08/2022 13:46:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=186
06/08/2022 13:46:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=187
06/08/2022 13:46:34 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.7032242790811339 on epoch=187
06/08/2022 13:46:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=188
06/08/2022 13:46:40 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=189
06/08/2022 13:46:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=191
06/08/2022 13:46:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=192
06/08/2022 13:46:48 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=193
06/08/2022 13:46:50 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6488045738045738 on epoch=193
06/08/2022 13:46:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=194
06/08/2022 13:46:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=196
06/08/2022 13:46:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=197
06/08/2022 13:47:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=198
06/08/2022 13:47:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=199
06/08/2022 13:47:05 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7094147648833238 on epoch=199
06/08/2022 13:47:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=201
06/08/2022 13:47:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=202
06/08/2022 13:47:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=203
06/08/2022 13:47:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=204
06/08/2022 13:47:19 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=206
06/08/2022 13:47:21 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6757907369189196 on epoch=206
06/08/2022 13:47:24 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=207
06/08/2022 13:47:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=208
06/08/2022 13:47:29 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=209
06/08/2022 13:47:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=211
06/08/2022 13:47:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.16 on epoch=212
06/08/2022 13:47:36 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.6516883351390395 on epoch=212
06/08/2022 13:47:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=213
06/08/2022 13:47:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=214
06/08/2022 13:47:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=216
06/08/2022 13:47:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=217
06/08/2022 13:47:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=218
06/08/2022 13:47:51 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.6845725515886014 on epoch=218
06/08/2022 13:47:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=219
06/08/2022 13:47:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=221
06/08/2022 13:48:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=222
06/08/2022 13:48:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=223
06/08/2022 13:48:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=224
06/08/2022 13:48:07 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.6983150010755586 on epoch=224
06/08/2022 13:48:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=226
06/08/2022 13:48:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=227
06/08/2022 13:48:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=228
06/08/2022 13:48:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=229
06/08/2022 13:48:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=231
06/08/2022 13:48:23 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.560845946599292 on epoch=231
06/08/2022 13:48:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=232
06/08/2022 13:48:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=233
06/08/2022 13:48:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=234
06/08/2022 13:48:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=236
06/08/2022 13:48:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=237
06/08/2022 13:48:38 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.6778110849488257 on epoch=237
06/08/2022 13:48:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=238
06/08/2022 13:48:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=239
06/08/2022 13:48:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=241
06/08/2022 13:48:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=242
06/08/2022 13:48:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=243
06/08/2022 13:48:53 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.5604488013791139 on epoch=243
06/08/2022 13:48:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=244
06/08/2022 13:48:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=246
06/08/2022 13:49:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=247
06/08/2022 13:49:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=248
06/08/2022 13:49:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=249
06/08/2022 13:49:09 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.6725319235675491 on epoch=249
06/08/2022 13:49:12 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=251
06/08/2022 13:49:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=252
06/08/2022 13:49:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=253
06/08/2022 13:49:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=254
06/08/2022 13:49:22 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=256
06/08/2022 13:49:24 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.6959913600186811 on epoch=256
06/08/2022 13:49:27 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=257
06/08/2022 13:49:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=258
06/08/2022 13:49:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=259
06/08/2022 13:49:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=261
06/08/2022 13:49:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=262
06/08/2022 13:49:40 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.6865634365634365 on epoch=262
06/08/2022 13:49:42 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=263
06/08/2022 13:49:45 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=264
06/08/2022 13:49:48 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=266
06/08/2022 13:49:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=267
06/08/2022 13:49:53 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=268
06/08/2022 13:49:55 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7007821486082356 on epoch=268
06/08/2022 13:49:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=269
06/08/2022 13:50:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=271
06/08/2022 13:50:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=272
06/08/2022 13:50:06 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=273
06/08/2022 13:50:09 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=274
06/08/2022 13:50:11 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7007181259241811 on epoch=274
06/08/2022 13:50:13 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=276
06/08/2022 13:50:16 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=277
06/08/2022 13:50:19 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=278
06/08/2022 13:50:21 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=279
06/08/2022 13:50:24 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=281
06/08/2022 13:50:26 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6791814735844587 on epoch=281
06/08/2022 13:50:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=282
06/08/2022 13:50:31 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
06/08/2022 13:50:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.09 on epoch=284
06/08/2022 13:50:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=286
06/08/2022 13:50:40 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=287
06/08/2022 13:50:42 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.69280868385346 on epoch=287
06/08/2022 13:50:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=288
06/08/2022 13:50:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=289
06/08/2022 13:50:50 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=291
06/08/2022 13:50:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=292
06/08/2022 13:50:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=293
06/08/2022 13:50:57 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.555486420533621 on epoch=293
06/08/2022 13:51:00 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=294
06/08/2022 13:51:02 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=296
06/08/2022 13:51:05 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=297
06/08/2022 13:51:08 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=298
06/08/2022 13:51:10 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=299
06/08/2022 13:51:13 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.5514505347593583 on epoch=299
06/08/2022 13:51:15 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=301
06/08/2022 13:51:18 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=302
06/08/2022 13:51:21 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
06/08/2022 13:51:24 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=304
06/08/2022 13:51:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=306
06/08/2022 13:51:29 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.5435039011380389 on epoch=306
06/08/2022 13:51:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=307
06/08/2022 13:51:35 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=308
06/08/2022 13:51:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=309
06/08/2022 13:51:40 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=311
06/08/2022 13:51:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=312
06/08/2022 13:51:45 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.5602857823291261 on epoch=312
06/08/2022 13:51:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=313
06/08/2022 13:51:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=314
06/08/2022 13:51:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=316
06/08/2022 13:51:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=317
06/08/2022 13:51:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=318
06/08/2022 13:52:00 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.5417737672044481 on epoch=318
06/08/2022 13:52:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
06/08/2022 13:52:06 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.18 on epoch=321
06/08/2022 13:52:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.14 on epoch=322
06/08/2022 13:52:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=323
06/08/2022 13:52:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=324
06/08/2022 13:52:17 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.533236653461611 on epoch=324
06/08/2022 13:52:19 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
06/08/2022 13:52:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.08 on epoch=327
06/08/2022 13:52:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=328
06/08/2022 13:52:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=329
06/08/2022 13:52:30 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
06/08/2022 13:52:33 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.533780337309749 on epoch=331
06/08/2022 13:52:35 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=332
06/08/2022 13:52:38 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
06/08/2022 13:52:41 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=334
06/08/2022 13:52:43 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=336
06/08/2022 13:52:46 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=337
06/08/2022 13:52:48 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.5602646834981487 on epoch=337
06/08/2022 13:52:51 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/08/2022 13:52:53 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
06/08/2022 13:52:56 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
06/08/2022 13:52:59 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=342
06/08/2022 13:53:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.24 on epoch=343
06/08/2022 13:53:03 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.5595326076101068 on epoch=343
06/08/2022 13:53:06 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
06/08/2022 13:53:09 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
06/08/2022 13:53:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=347
06/08/2022 13:53:14 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=348
06/08/2022 13:53:17 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
06/08/2022 13:53:19 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.5528544275871432 on epoch=349
06/08/2022 13:53:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
06/08/2022 13:53:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=352
06/08/2022 13:53:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=353
06/08/2022 13:53:29 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/08/2022 13:53:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=356
06/08/2022 13:53:34 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.5148360160965795 on epoch=356
06/08/2022 13:53:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
06/08/2022 13:53:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=358
06/08/2022 13:53:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=359
06/08/2022 13:53:45 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
06/08/2022 13:53:48 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/08/2022 13:53:50 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6912018786024337 on epoch=362
06/08/2022 13:53:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=363
06/08/2022 13:53:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=364
06/08/2022 13:53:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=366
06/08/2022 13:54:01 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=367
06/08/2022 13:54:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=368
06/08/2022 13:54:06 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6805613305613305 on epoch=368
06/08/2022 13:54:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=369
06/08/2022 13:54:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
06/08/2022 13:54:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=372
06/08/2022 13:54:16 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=373
06/08/2022 13:54:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
06/08/2022 13:54:21 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:54:21 - INFO - __main__ - Printing 3 examples
06/08/2022 13:54:21 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 13:54:21 - INFO - __main__ - ['happy']
06/08/2022 13:54:21 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 13:54:21 - INFO - __main__ - ['happy']
06/08/2022 13:54:21 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 13:54:21 - INFO - __main__ - ['happy']
06/08/2022 13:54:21 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:54:21 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:54:21 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 13:54:21 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:54:21 - INFO - __main__ - Printing 3 examples
06/08/2022 13:54:21 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/08/2022 13:54:21 - INFO - __main__ - ['happy']
06/08/2022 13:54:21 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/08/2022 13:54:21 - INFO - __main__ - ['happy']
06/08/2022 13:54:21 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/08/2022 13:54:21 - INFO - __main__ - ['happy']
06/08/2022 13:54:21 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:54:21 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:54:21 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 13:54:22 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6581636875206885 on epoch=374
06/08/2022 13:54:22 - INFO - __main__ - save last model!
06/08/2022 13:54:22 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 13:54:22 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 13:54:22 - INFO - __main__ - Printing 3 examples
06/08/2022 13:54:22 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 13:54:22 - INFO - __main__ - ['others']
06/08/2022 13:54:22 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 13:54:22 - INFO - __main__ - ['others']
06/08/2022 13:54:22 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 13:54:22 - INFO - __main__ - ['others']
06/08/2022 13:54:22 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:54:24 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:54:29 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 13:54:37 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 13:54:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 13:54:37 - INFO - __main__ - Starting training!
06/08/2022 13:56:17 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_42_0.5_8_predictions.txt
06/08/2022 13:56:17 - INFO - __main__ - Classification-F1 on test data: 0.2772
06/08/2022 13:56:17 - INFO - __main__ - prefix=emo_32_42, lr=0.5, bsz=8, dev_performance=0.720061566293184, test_performance=0.27717971042976147
06/08/2022 13:56:17 - INFO - __main__ - Running ... prefix=emo_32_42, lr=0.4, bsz=8 ...
06/08/2022 13:56:18 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:56:18 - INFO - __main__ - Printing 3 examples
06/08/2022 13:56:18 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 13:56:18 - INFO - __main__ - ['happy']
06/08/2022 13:56:18 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 13:56:18 - INFO - __main__ - ['happy']
06/08/2022 13:56:18 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 13:56:18 - INFO - __main__ - ['happy']
06/08/2022 13:56:18 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:56:18 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:56:18 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 13:56:18 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 13:56:18 - INFO - __main__ - Printing 3 examples
06/08/2022 13:56:18 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/08/2022 13:56:18 - INFO - __main__ - ['happy']
06/08/2022 13:56:18 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/08/2022 13:56:18 - INFO - __main__ - ['happy']
06/08/2022 13:56:18 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/08/2022 13:56:18 - INFO - __main__ - ['happy']
06/08/2022 13:56:18 - INFO - __main__ - Tokenizing Input ...
06/08/2022 13:56:18 - INFO - __main__ - Tokenizing Output ...
06/08/2022 13:56:19 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 13:56:37 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 13:56:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 13:56:38 - INFO - __main__ - Starting training!
06/08/2022 13:56:41 - INFO - __main__ - Step 10 Global step 10 Train loss 2.62 on epoch=1
06/08/2022 13:56:43 - INFO - __main__ - Step 20 Global step 20 Train loss 1.38 on epoch=2
06/08/2022 13:56:46 - INFO - __main__ - Step 30 Global step 30 Train loss 1.05 on epoch=3
06/08/2022 13:56:49 - INFO - __main__ - Step 40 Global step 40 Train loss 0.99 on epoch=4
06/08/2022 13:56:51 - INFO - __main__ - Step 50 Global step 50 Train loss 0.92 on epoch=6
06/08/2022 13:56:53 - INFO - __main__ - Global step 50 Train loss 1.39 Classification-F1 0.1 on epoch=6
06/08/2022 13:56:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=6, global_step=50
06/08/2022 13:56:55 - INFO - __main__ - Step 60 Global step 60 Train loss 0.98 on epoch=7
06/08/2022 13:56:58 - INFO - __main__ - Step 70 Global step 70 Train loss 0.96 on epoch=8
06/08/2022 13:57:01 - INFO - __main__ - Step 80 Global step 80 Train loss 0.92 on epoch=9
06/08/2022 13:57:03 - INFO - __main__ - Step 90 Global step 90 Train loss 0.85 on epoch=11
06/08/2022 13:57:06 - INFO - __main__ - Step 100 Global step 100 Train loss 0.82 on epoch=12
06/08/2022 13:57:08 - INFO - __main__ - Global step 100 Train loss 0.91 Classification-F1 0.15756302521008403 on epoch=12
06/08/2022 13:57:08 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.15756302521008403 on epoch=12, global_step=100
06/08/2022 13:57:10 - INFO - __main__ - Step 110 Global step 110 Train loss 0.71 on epoch=13
06/08/2022 13:57:13 - INFO - __main__ - Step 120 Global step 120 Train loss 0.73 on epoch=14
06/08/2022 13:57:16 - INFO - __main__ - Step 130 Global step 130 Train loss 0.80 on epoch=16
06/08/2022 13:57:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.84 on epoch=17
06/08/2022 13:57:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.85 on epoch=18
06/08/2022 13:57:22 - INFO - __main__ - Global step 150 Train loss 0.78 Classification-F1 0.47605105105105106 on epoch=18
06/08/2022 13:57:22 - INFO - __main__ - Saving model with best Classification-F1: 0.15756302521008403 -> 0.47605105105105106 on epoch=18, global_step=150
06/08/2022 13:57:25 - INFO - __main__ - Step 160 Global step 160 Train loss 0.78 on epoch=19
06/08/2022 13:57:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.72 on epoch=21
06/08/2022 13:57:30 - INFO - __main__ - Step 180 Global step 180 Train loss 0.69 on epoch=22
06/08/2022 13:57:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.71 on epoch=23
06/08/2022 13:57:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.67 on epoch=24
06/08/2022 13:57:37 - INFO - __main__ - Global step 200 Train loss 0.72 Classification-F1 0.5777793816353138 on epoch=24
06/08/2022 13:57:37 - INFO - __main__ - Saving model with best Classification-F1: 0.47605105105105106 -> 0.5777793816353138 on epoch=24, global_step=200
06/08/2022 13:57:40 - INFO - __main__ - Step 210 Global step 210 Train loss 0.70 on epoch=26
06/08/2022 13:57:43 - INFO - __main__ - Step 220 Global step 220 Train loss 0.67 on epoch=27
06/08/2022 13:57:45 - INFO - __main__ - Step 230 Global step 230 Train loss 0.62 on epoch=28
06/08/2022 13:57:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.55 on epoch=29
06/08/2022 13:57:50 - INFO - __main__ - Step 250 Global step 250 Train loss 0.53 on epoch=31
06/08/2022 13:57:52 - INFO - __main__ - Global step 250 Train loss 0.61 Classification-F1 0.5532410438361594 on epoch=31
06/08/2022 13:57:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.51 on epoch=32
06/08/2022 13:57:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.50 on epoch=33
06/08/2022 13:58:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.52 on epoch=34
06/08/2022 13:58:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.59 on epoch=36
06/08/2022 13:58:05 - INFO - __main__ - Step 300 Global step 300 Train loss 0.50 on epoch=37
06/08/2022 13:58:07 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.6315380569898642 on epoch=37
06/08/2022 13:58:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5777793816353138 -> 0.6315380569898642 on epoch=37, global_step=300
06/08/2022 13:58:09 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=38
06/08/2022 13:58:12 - INFO - __main__ - Step 320 Global step 320 Train loss 0.54 on epoch=39
06/08/2022 13:58:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=41
06/08/2022 13:58:17 - INFO - __main__ - Step 340 Global step 340 Train loss 0.47 on epoch=42
06/08/2022 13:58:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.50 on epoch=43
06/08/2022 13:58:22 - INFO - __main__ - Global step 350 Train loss 0.49 Classification-F1 0.49433622018598344 on epoch=43
06/08/2022 13:58:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.48 on epoch=44
06/08/2022 13:58:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.53 on epoch=46
06/08/2022 13:58:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.56 on epoch=47
06/08/2022 13:58:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.45 on epoch=48
06/08/2022 13:58:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.46 on epoch=49
06/08/2022 13:58:36 - INFO - __main__ - Global step 400 Train loss 0.50 Classification-F1 0.6683017326088114 on epoch=49
06/08/2022 13:58:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6315380569898642 -> 0.6683017326088114 on epoch=49, global_step=400
06/08/2022 13:58:39 - INFO - __main__ - Step 410 Global step 410 Train loss 0.39 on epoch=51
06/08/2022 13:58:42 - INFO - __main__ - Step 420 Global step 420 Train loss 0.44 on epoch=52
06/08/2022 13:58:44 - INFO - __main__ - Step 430 Global step 430 Train loss 0.36 on epoch=53
06/08/2022 13:58:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.49 on epoch=54
06/08/2022 13:58:49 - INFO - __main__ - Step 450 Global step 450 Train loss 0.41 on epoch=56
06/08/2022 13:58:51 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.6707452095323949 on epoch=56
06/08/2022 13:58:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6683017326088114 -> 0.6707452095323949 on epoch=56, global_step=450
06/08/2022 13:58:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.40 on epoch=57
06/08/2022 13:58:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=58
06/08/2022 13:58:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.33 on epoch=59
06/08/2022 13:59:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.45 on epoch=61
06/08/2022 13:59:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.30 on epoch=62
06/08/2022 13:59:06 - INFO - __main__ - Global step 500 Train loss 0.37 Classification-F1 0.6848453050341861 on epoch=62
06/08/2022 13:59:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6707452095323949 -> 0.6848453050341861 on epoch=62, global_step=500
06/08/2022 13:59:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.34 on epoch=63
06/08/2022 13:59:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.33 on epoch=64
06/08/2022 13:59:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.31 on epoch=66
06/08/2022 13:59:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.36 on epoch=67
06/08/2022 13:59:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.38 on epoch=68
06/08/2022 13:59:20 - INFO - __main__ - Global step 550 Train loss 0.34 Classification-F1 0.6770975056689342 on epoch=68
06/08/2022 13:59:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=69
06/08/2022 13:59:26 - INFO - __main__ - Step 570 Global step 570 Train loss 0.29 on epoch=71
06/08/2022 13:59:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=72
06/08/2022 13:59:31 - INFO - __main__ - Step 590 Global step 590 Train loss 0.33 on epoch=73
06/08/2022 13:59:33 - INFO - __main__ - Step 600 Global step 600 Train loss 0.36 on epoch=74
06/08/2022 13:59:35 - INFO - __main__ - Global step 600 Train loss 0.30 Classification-F1 0.6659047919293821 on epoch=74
06/08/2022 13:59:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.33 on epoch=76
06/08/2022 13:59:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.30 on epoch=77
06/08/2022 13:59:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=78
06/08/2022 13:59:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=79
06/08/2022 13:59:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.37 on epoch=81
06/08/2022 13:59:50 - INFO - __main__ - Global step 650 Train loss 0.31 Classification-F1 0.6877572042229708 on epoch=81
06/08/2022 13:59:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6848453050341861 -> 0.6877572042229708 on epoch=81, global_step=650
06/08/2022 13:59:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.35 on epoch=82
06/08/2022 13:59:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.30 on epoch=83
06/08/2022 13:59:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=84
06/08/2022 14:00:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.36 on epoch=86
06/08/2022 14:00:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=87
06/08/2022 14:00:04 - INFO - __main__ - Global step 700 Train loss 0.31 Classification-F1 0.5732934947751125 on epoch=87
06/08/2022 14:00:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.30 on epoch=88
06/08/2022 14:00:10 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=89
06/08/2022 14:00:12 - INFO - __main__ - Step 730 Global step 730 Train loss 0.26 on epoch=91
06/08/2022 14:00:15 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=92
06/08/2022 14:00:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=93
06/08/2022 14:00:19 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.5560094612935687 on epoch=93
06/08/2022 14:00:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=94
06/08/2022 14:00:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.29 on epoch=96
06/08/2022 14:00:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=97
06/08/2022 14:00:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=98
06/08/2022 14:00:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=99
06/08/2022 14:00:34 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.6820294668675076 on epoch=99
06/08/2022 14:00:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.27 on epoch=101
06/08/2022 14:00:39 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=102
06/08/2022 14:00:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=103
06/08/2022 14:00:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=104
06/08/2022 14:00:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.24 on epoch=106
06/08/2022 14:00:48 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.7092773892773894 on epoch=106
06/08/2022 14:00:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6877572042229708 -> 0.7092773892773894 on epoch=106, global_step=850
06/08/2022 14:00:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=107
06/08/2022 14:00:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=108
06/08/2022 14:00:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=109
06/08/2022 14:00:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=111
06/08/2022 14:01:01 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=112
06/08/2022 14:01:03 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.7505819547264613 on epoch=112
06/08/2022 14:01:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7092773892773894 -> 0.7505819547264613 on epoch=112, global_step=900
06/08/2022 14:01:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=113
06/08/2022 14:01:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=114
06/08/2022 14:01:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=116
06/08/2022 14:01:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=117
06/08/2022 14:01:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=118
06/08/2022 14:01:18 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.6384655450433095 on epoch=118
06/08/2022 14:01:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=119
06/08/2022 14:01:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=121
06/08/2022 14:01:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=122
06/08/2022 14:01:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.23 on epoch=123
06/08/2022 14:01:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=124
06/08/2022 14:01:33 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.7540717736369911 on epoch=124
06/08/2022 14:01:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7505819547264613 -> 0.7540717736369911 on epoch=124, global_step=1000
06/08/2022 14:01:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=126
06/08/2022 14:01:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=127
06/08/2022 14:01:41 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=128
06/08/2022 14:01:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=129
06/08/2022 14:01:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=131
06/08/2022 14:01:48 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.7234990384303885 on epoch=131
06/08/2022 14:01:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=132
06/08/2022 14:01:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.15 on epoch=133
06/08/2022 14:01:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=134
06/08/2022 14:01:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=136
06/08/2022 14:02:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=137
06/08/2022 14:02:03 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.7422260861645832 on epoch=137
06/08/2022 14:02:05 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=138
06/08/2022 14:02:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=139
06/08/2022 14:02:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=141
06/08/2022 14:02:13 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=142
06/08/2022 14:02:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=143
06/08/2022 14:02:18 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.6898312783906554 on epoch=143
06/08/2022 14:02:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=144
06/08/2022 14:02:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=146
06/08/2022 14:02:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=147
06/08/2022 14:02:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=148
06/08/2022 14:02:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.16 on epoch=149
06/08/2022 14:02:32 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.5412747252747252 on epoch=149
06/08/2022 14:02:35 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=151
06/08/2022 14:02:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=152
06/08/2022 14:02:40 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=153
06/08/2022 14:02:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=154
06/08/2022 14:02:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=156
06/08/2022 14:02:47 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.5461944777911164 on epoch=156
06/08/2022 14:02:49 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.19 on epoch=157
06/08/2022 14:02:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=158
06/08/2022 14:02:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=159
06/08/2022 14:02:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=161
06/08/2022 14:03:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=162
06/08/2022 14:03:02 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.7126357392271977 on epoch=162
06/08/2022 14:03:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=163
06/08/2022 14:03:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=164
06/08/2022 14:03:09 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=166
06/08/2022 14:03:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=167
06/08/2022 14:03:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=168
06/08/2022 14:03:16 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.5468480725623582 on epoch=168
06/08/2022 14:03:19 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=169
06/08/2022 14:03:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.14 on epoch=171
06/08/2022 14:03:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=172
06/08/2022 14:03:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=173
06/08/2022 14:03:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=174
06/08/2022 14:03:31 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.7407012556266287 on epoch=174
06/08/2022 14:03:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=176
06/08/2022 14:03:36 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=177
06/08/2022 14:03:39 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=178
06/08/2022 14:03:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=179
06/08/2022 14:03:44 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=181
06/08/2022 14:03:46 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7291723202170963 on epoch=181
06/08/2022 14:03:49 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=182
06/08/2022 14:03:51 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=183
06/08/2022 14:03:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=184
06/08/2022 14:03:57 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=186
06/08/2022 14:03:59 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=187
06/08/2022 14:04:01 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.5508432614609237 on epoch=187
06/08/2022 14:04:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=188
06/08/2022 14:04:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=189
06/08/2022 14:04:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=191
06/08/2022 14:04:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=192
06/08/2022 14:04:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=193
06/08/2022 14:04:16 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7333607858365623 on epoch=193
06/08/2022 14:04:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=194
06/08/2022 14:04:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.15 on epoch=196
06/08/2022 14:04:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=197
06/08/2022 14:04:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=198
06/08/2022 14:04:28 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=199
06/08/2022 14:04:30 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.702689336372847 on epoch=199
06/08/2022 14:04:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=201
06/08/2022 14:04:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.11 on epoch=202
06/08/2022 14:04:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=203
06/08/2022 14:04:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=204
06/08/2022 14:04:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=206
06/08/2022 14:04:45 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.7223592130590805 on epoch=206
06/08/2022 14:04:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=207
06/08/2022 14:04:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.17 on epoch=208
06/08/2022 14:04:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=209
06/08/2022 14:04:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=211
06/08/2022 14:04:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=212
06/08/2022 14:05:00 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.5446116438543289 on epoch=212
06/08/2022 14:05:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=213
06/08/2022 14:05:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=214
06/08/2022 14:05:08 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=216
06/08/2022 14:05:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.11 on epoch=217
06/08/2022 14:05:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=218
06/08/2022 14:05:14 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.5515215989684075 on epoch=218
06/08/2022 14:05:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=219
06/08/2022 14:05:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=221
06/08/2022 14:05:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=222
06/08/2022 14:05:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=223
06/08/2022 14:05:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.16 on epoch=224
06/08/2022 14:05:29 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.6957751741672178 on epoch=224
06/08/2022 14:05:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=226
06/08/2022 14:05:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=227
06/08/2022 14:05:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=228
06/08/2022 14:05:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=229
06/08/2022 14:05:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=231
06/08/2022 14:05:44 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.515687907454879 on epoch=231
06/08/2022 14:05:46 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=232
06/08/2022 14:05:49 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=233
06/08/2022 14:05:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=234
06/08/2022 14:05:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=236
06/08/2022 14:05:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=237
06/08/2022 14:05:59 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.5781247699668752 on epoch=237
06/08/2022 14:06:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=238
06/08/2022 14:06:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=239
06/08/2022 14:06:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=241
06/08/2022 14:06:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=242
06/08/2022 14:06:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=243
06/08/2022 14:06:13 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.5744581364338184 on epoch=243
06/08/2022 14:06:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=244
06/08/2022 14:06:18 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=246
06/08/2022 14:06:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=247
06/08/2022 14:06:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=248
06/08/2022 14:06:26 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=249
06/08/2022 14:06:28 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.572153449387492 on epoch=249
06/08/2022 14:06:31 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=251
06/08/2022 14:06:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=252
06/08/2022 14:06:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=253
06/08/2022 14:06:39 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=254
06/08/2022 14:06:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=256
06/08/2022 14:06:43 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.5487478262231902 on epoch=256
06/08/2022 14:06:46 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=257
06/08/2022 14:06:48 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=258
06/08/2022 14:06:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=259
06/08/2022 14:06:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=261
06/08/2022 14:06:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=262
06/08/2022 14:06:58 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.5534632034632034 on epoch=262
06/08/2022 14:07:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=263
06/08/2022 14:07:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=264
06/08/2022 14:07:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=266
06/08/2022 14:07:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=267
06/08/2022 14:07:11 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=268
06/08/2022 14:07:12 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.5574917042457244 on epoch=268
06/08/2022 14:07:15 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=269
06/08/2022 14:07:18 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=271
06/08/2022 14:07:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=272
06/08/2022 14:07:23 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=273
06/08/2022 14:07:26 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=274
06/08/2022 14:07:27 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7592165898617512 on epoch=274
06/08/2022 14:07:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7540717736369911 -> 0.7592165898617512 on epoch=274, global_step=2200
06/08/2022 14:07:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=276
06/08/2022 14:07:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=277
06/08/2022 14:07:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=278
06/08/2022 14:07:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=279
06/08/2022 14:07:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=281
06/08/2022 14:07:42 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.565309338347211 on epoch=281
06/08/2022 14:07:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=282
06/08/2022 14:07:48 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=283
06/08/2022 14:07:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=284
06/08/2022 14:07:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=286
06/08/2022 14:07:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=287
06/08/2022 14:07:58 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.5759292711158195 on epoch=287
06/08/2022 14:08:00 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=288
06/08/2022 14:08:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=289
06/08/2022 14:08:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=291
06/08/2022 14:08:08 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=292
06/08/2022 14:08:10 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=293
06/08/2022 14:08:12 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.5614687751813053 on epoch=293
06/08/2022 14:08:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=294
06/08/2022 14:08:17 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=296
06/08/2022 14:08:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=297
06/08/2022 14:08:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.16 on epoch=298
06/08/2022 14:08:25 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=299
06/08/2022 14:08:27 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.529401781533189 on epoch=299
06/08/2022 14:08:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
06/08/2022 14:08:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
06/08/2022 14:08:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=303
06/08/2022 14:08:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.10 on epoch=304
06/08/2022 14:08:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=306
06/08/2022 14:08:42 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.5220108329402251 on epoch=306
06/08/2022 14:08:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=307
06/08/2022 14:08:47 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=308
06/08/2022 14:08:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=309
06/08/2022 14:08:52 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=311
06/08/2022 14:08:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=312
06/08/2022 14:08:56 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.5589864253393665 on epoch=312
06/08/2022 14:08:59 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=313
06/08/2022 14:09:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/08/2022 14:09:04 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=316
06/08/2022 14:09:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=317
06/08/2022 14:09:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=318
06/08/2022 14:09:11 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.5601432273055454 on epoch=318
06/08/2022 14:09:13 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=319
06/08/2022 14:09:16 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=321
06/08/2022 14:09:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=322
06/08/2022 14:09:21 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=323
06/08/2022 14:09:24 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=324
06/08/2022 14:09:26 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.5352112676056338 on epoch=324
06/08/2022 14:09:28 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
06/08/2022 14:09:31 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=327
06/08/2022 14:09:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=328
06/08/2022 14:09:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=329
06/08/2022 14:09:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
06/08/2022 14:09:41 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.5510357904758392 on epoch=331
06/08/2022 14:09:43 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=332
06/08/2022 14:09:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.11 on epoch=333
06/08/2022 14:09:48 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.11 on epoch=334
06/08/2022 14:09:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=336
06/08/2022 14:09:53 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=337
06/08/2022 14:09:55 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.5643933811418291 on epoch=337
06/08/2022 14:09:58 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/08/2022 14:10:00 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
06/08/2022 14:10:03 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=341
06/08/2022 14:10:05 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=342
06/08/2022 14:10:08 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=343
06/08/2022 14:10:10 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.5749462270840002 on epoch=343
06/08/2022 14:10:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=344
06/08/2022 14:10:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
06/08/2022 14:10:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
06/08/2022 14:10:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=348
06/08/2022 14:10:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=349
06/08/2022 14:10:25 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.56693385467579 on epoch=349
06/08/2022 14:10:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.11 on epoch=351
06/08/2022 14:10:30 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=352
06/08/2022 14:10:32 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=353
06/08/2022 14:10:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=354
06/08/2022 14:10:38 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=356
06/08/2022 14:10:40 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7128367600141794 on epoch=356
06/08/2022 14:10:42 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
06/08/2022 14:10:45 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=358
06/08/2022 14:10:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/08/2022 14:10:50 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
06/08/2022 14:10:52 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/08/2022 14:10:54 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.5811373451056957 on epoch=362
06/08/2022 14:10:57 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=363
06/08/2022 14:10:59 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.06 on epoch=364
06/08/2022 14:11:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
06/08/2022 14:11:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/08/2022 14:11:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=368
06/08/2022 14:11:09 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.5627100918059786 on epoch=368
06/08/2022 14:11:12 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=369
06/08/2022 14:11:14 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=371
06/08/2022 14:11:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=372
06/08/2022 14:11:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=373
06/08/2022 14:11:22 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
06/08/2022 14:11:23 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 14:11:23 - INFO - __main__ - Printing 3 examples
06/08/2022 14:11:23 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 14:11:23 - INFO - __main__ - ['happy']
06/08/2022 14:11:23 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 14:11:23 - INFO - __main__ - ['happy']
06/08/2022 14:11:23 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 14:11:23 - INFO - __main__ - ['happy']
06/08/2022 14:11:23 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:11:24 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:11:24 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 14:11:24 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 14:11:24 - INFO - __main__ - Printing 3 examples
06/08/2022 14:11:24 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/08/2022 14:11:24 - INFO - __main__ - ['happy']
06/08/2022 14:11:24 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/08/2022 14:11:24 - INFO - __main__ - ['happy']
06/08/2022 14:11:24 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/08/2022 14:11:24 - INFO - __main__ - ['happy']
06/08/2022 14:11:24 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:11:24 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:11:24 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 14:11:24 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.6962506600950537 on epoch=374
06/08/2022 14:11:24 - INFO - __main__ - save last model!
06/08/2022 14:11:24 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 14:11:24 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 14:11:24 - INFO - __main__ - Printing 3 examples
06/08/2022 14:11:24 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 14:11:24 - INFO - __main__ - ['others']
06/08/2022 14:11:24 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 14:11:24 - INFO - __main__ - ['others']
06/08/2022 14:11:24 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 14:11:24 - INFO - __main__ - ['others']
06/08/2022 14:11:24 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:11:26 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:11:33 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 14:11:42 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 14:11:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 14:11:42 - INFO - __main__ - Starting training!
06/08/2022 14:12:51 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_42_0.4_8_predictions.txt
06/08/2022 14:12:51 - INFO - __main__ - Classification-F1 on test data: 0.2595
06/08/2022 14:12:52 - INFO - __main__ - prefix=emo_32_42, lr=0.4, bsz=8, dev_performance=0.7592165898617512, test_performance=0.25945542519093046
06/08/2022 14:12:52 - INFO - __main__ - Running ... prefix=emo_32_42, lr=0.3, bsz=8 ...
06/08/2022 14:12:53 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 14:12:53 - INFO - __main__ - Printing 3 examples
06/08/2022 14:12:53 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 14:12:53 - INFO - __main__ - ['happy']
06/08/2022 14:12:53 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 14:12:53 - INFO - __main__ - ['happy']
06/08/2022 14:12:53 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 14:12:53 - INFO - __main__ - ['happy']
06/08/2022 14:12:53 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:12:53 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:12:53 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 14:12:53 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 14:12:53 - INFO - __main__ - Printing 3 examples
06/08/2022 14:12:53 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/08/2022 14:12:53 - INFO - __main__ - ['happy']
06/08/2022 14:12:53 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/08/2022 14:12:53 - INFO - __main__ - ['happy']
06/08/2022 14:12:53 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/08/2022 14:12:53 - INFO - __main__ - ['happy']
06/08/2022 14:12:53 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:12:53 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:12:53 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 14:13:10 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 14:13:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 14:13:11 - INFO - __main__ - Starting training!
06/08/2022 14:13:15 - INFO - __main__ - Step 10 Global step 10 Train loss 2.94 on epoch=1
06/08/2022 14:13:17 - INFO - __main__ - Step 20 Global step 20 Train loss 1.70 on epoch=2
06/08/2022 14:13:20 - INFO - __main__ - Step 30 Global step 30 Train loss 1.19 on epoch=3
06/08/2022 14:13:22 - INFO - __main__ - Step 40 Global step 40 Train loss 1.00 on epoch=4
06/08/2022 14:13:25 - INFO - __main__ - Step 50 Global step 50 Train loss 0.95 on epoch=6
06/08/2022 14:13:27 - INFO - __main__ - Global step 50 Train loss 1.56 Classification-F1 0.13256113256113256 on epoch=6
06/08/2022 14:13:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13256113256113256 on epoch=6, global_step=50
06/08/2022 14:13:30 - INFO - __main__ - Step 60 Global step 60 Train loss 0.93 on epoch=7
06/08/2022 14:13:32 - INFO - __main__ - Step 70 Global step 70 Train loss 0.96 on epoch=8
06/08/2022 14:13:35 - INFO - __main__ - Step 80 Global step 80 Train loss 0.90 on epoch=9
06/08/2022 14:13:37 - INFO - __main__ - Step 90 Global step 90 Train loss 0.90 on epoch=11
06/08/2022 14:13:40 - INFO - __main__ - Step 100 Global step 100 Train loss 0.86 on epoch=12
06/08/2022 14:13:42 - INFO - __main__ - Global step 100 Train loss 0.91 Classification-F1 0.1 on epoch=12
06/08/2022 14:13:44 - INFO - __main__ - Step 110 Global step 110 Train loss 0.89 on epoch=13
06/08/2022 14:13:47 - INFO - __main__ - Step 120 Global step 120 Train loss 0.92 on epoch=14
06/08/2022 14:13:49 - INFO - __main__ - Step 130 Global step 130 Train loss 0.83 on epoch=16
06/08/2022 14:13:52 - INFO - __main__ - Step 140 Global step 140 Train loss 0.84 on epoch=17
06/08/2022 14:13:54 - INFO - __main__ - Step 150 Global step 150 Train loss 0.82 on epoch=18
06/08/2022 14:13:56 - INFO - __main__ - Global step 150 Train loss 0.86 Classification-F1 0.42605042016806716 on epoch=18
06/08/2022 14:13:56 - INFO - __main__ - Saving model with best Classification-F1: 0.13256113256113256 -> 0.42605042016806716 on epoch=18, global_step=150
06/08/2022 14:13:59 - INFO - __main__ - Step 160 Global step 160 Train loss 0.84 on epoch=19
06/08/2022 14:14:01 - INFO - __main__ - Step 170 Global step 170 Train loss 0.87 on epoch=21
06/08/2022 14:14:04 - INFO - __main__ - Step 180 Global step 180 Train loss 0.82 on epoch=22
06/08/2022 14:14:06 - INFO - __main__ - Step 190 Global step 190 Train loss 0.72 on epoch=23
06/08/2022 14:14:09 - INFO - __main__ - Step 200 Global step 200 Train loss 0.76 on epoch=24
06/08/2022 14:14:11 - INFO - __main__ - Global step 200 Train loss 0.80 Classification-F1 0.5779824648909875 on epoch=24
06/08/2022 14:14:11 - INFO - __main__ - Saving model with best Classification-F1: 0.42605042016806716 -> 0.5779824648909875 on epoch=24, global_step=200
06/08/2022 14:14:13 - INFO - __main__ - Step 210 Global step 210 Train loss 0.79 on epoch=26
06/08/2022 14:14:16 - INFO - __main__ - Step 220 Global step 220 Train loss 0.82 on epoch=27
06/08/2022 14:14:18 - INFO - __main__ - Step 230 Global step 230 Train loss 0.74 on epoch=28
06/08/2022 14:14:21 - INFO - __main__ - Step 240 Global step 240 Train loss 0.70 on epoch=29
06/08/2022 14:14:24 - INFO - __main__ - Step 250 Global step 250 Train loss 0.64 on epoch=31
06/08/2022 14:14:25 - INFO - __main__ - Global step 250 Train loss 0.74 Classification-F1 0.5769920044113592 on epoch=31
06/08/2022 14:14:28 - INFO - __main__ - Step 260 Global step 260 Train loss 0.65 on epoch=32
06/08/2022 14:14:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.62 on epoch=33
06/08/2022 14:14:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.58 on epoch=34
06/08/2022 14:14:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.67 on epoch=36
06/08/2022 14:14:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.68 on epoch=37
06/08/2022 14:14:40 - INFO - __main__ - Global step 300 Train loss 0.64 Classification-F1 0.6516789516789517 on epoch=37
06/08/2022 14:14:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5779824648909875 -> 0.6516789516789517 on epoch=37, global_step=300
06/08/2022 14:14:43 - INFO - __main__ - Step 310 Global step 310 Train loss 0.55 on epoch=38
06/08/2022 14:14:46 - INFO - __main__ - Step 320 Global step 320 Train loss 0.60 on epoch=39
06/08/2022 14:14:48 - INFO - __main__ - Step 330 Global step 330 Train loss 0.59 on epoch=41
06/08/2022 14:14:51 - INFO - __main__ - Step 340 Global step 340 Train loss 0.65 on epoch=42
06/08/2022 14:14:54 - INFO - __main__ - Step 350 Global step 350 Train loss 0.53 on epoch=43
06/08/2022 14:14:55 - INFO - __main__ - Global step 350 Train loss 0.59 Classification-F1 0.48269787644787643 on epoch=43
06/08/2022 14:14:58 - INFO - __main__ - Step 360 Global step 360 Train loss 0.59 on epoch=44
06/08/2022 14:15:00 - INFO - __main__ - Step 370 Global step 370 Train loss 0.52 on epoch=46
06/08/2022 14:15:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=47
06/08/2022 14:15:05 - INFO - __main__ - Step 390 Global step 390 Train loss 0.50 on epoch=48
06/08/2022 14:15:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.52 on epoch=49
06/08/2022 14:15:10 - INFO - __main__ - Global step 400 Train loss 0.53 Classification-F1 0.6898549534756431 on epoch=49
06/08/2022 14:15:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6516789516789517 -> 0.6898549534756431 on epoch=49, global_step=400
06/08/2022 14:15:12 - INFO - __main__ - Step 410 Global step 410 Train loss 0.58 on epoch=51
06/08/2022 14:15:15 - INFO - __main__ - Step 420 Global step 420 Train loss 0.56 on epoch=52
06/08/2022 14:15:18 - INFO - __main__ - Step 430 Global step 430 Train loss 0.52 on epoch=53
06/08/2022 14:15:20 - INFO - __main__ - Step 440 Global step 440 Train loss 0.58 on epoch=54
06/08/2022 14:15:23 - INFO - __main__ - Step 450 Global step 450 Train loss 0.49 on epoch=56
06/08/2022 14:15:25 - INFO - __main__ - Global step 450 Train loss 0.54 Classification-F1 0.6950646745521201 on epoch=56
06/08/2022 14:15:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6898549534756431 -> 0.6950646745521201 on epoch=56, global_step=450
06/08/2022 14:15:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.47 on epoch=57
06/08/2022 14:15:30 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=58
06/08/2022 14:15:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.47 on epoch=59
06/08/2022 14:15:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.46 on epoch=61
06/08/2022 14:15:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.44 on epoch=62
06/08/2022 14:15:40 - INFO - __main__ - Global step 500 Train loss 0.44 Classification-F1 0.5636749589831782 on epoch=62
06/08/2022 14:15:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.41 on epoch=63
06/08/2022 14:15:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.38 on epoch=64
06/08/2022 14:15:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.38 on epoch=66
06/08/2022 14:15:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.50 on epoch=67
06/08/2022 14:15:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.46 on epoch=68
06/08/2022 14:15:54 - INFO - __main__ - Global step 550 Train loss 0.43 Classification-F1 0.578968253968254 on epoch=68
06/08/2022 14:15:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.45 on epoch=69
06/08/2022 14:15:59 - INFO - __main__ - Step 570 Global step 570 Train loss 0.45 on epoch=71
06/08/2022 14:16:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=72
06/08/2022 14:16:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.38 on epoch=73
06/08/2022 14:16:07 - INFO - __main__ - Step 600 Global step 600 Train loss 0.28 on epoch=74
06/08/2022 14:16:09 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.6479793127172224 on epoch=74
06/08/2022 14:16:12 - INFO - __main__ - Step 610 Global step 610 Train loss 0.43 on epoch=76
06/08/2022 14:16:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.38 on epoch=77
06/08/2022 14:16:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.37 on epoch=78
06/08/2022 14:16:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.29 on epoch=79
06/08/2022 14:16:22 - INFO - __main__ - Step 650 Global step 650 Train loss 0.31 on epoch=81
06/08/2022 14:16:24 - INFO - __main__ - Global step 650 Train loss 0.35 Classification-F1 0.6020887325681846 on epoch=81
06/08/2022 14:16:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=82
06/08/2022 14:16:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=83
06/08/2022 14:16:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.33 on epoch=84
06/08/2022 14:16:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.36 on epoch=86
06/08/2022 14:16:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.39 on epoch=87
06/08/2022 14:16:38 - INFO - __main__ - Global step 700 Train loss 0.33 Classification-F1 0.6676288345720789 on epoch=87
06/08/2022 14:16:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=88
06/08/2022 14:16:43 - INFO - __main__ - Step 720 Global step 720 Train loss 0.30 on epoch=89
06/08/2022 14:16:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=91
06/08/2022 14:16:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.32 on epoch=92
06/08/2022 14:16:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=93
06/08/2022 14:16:53 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.6785824007022164 on epoch=93
06/08/2022 14:16:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=94
06/08/2022 14:16:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.38 on epoch=96
06/08/2022 14:17:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.36 on epoch=97
06/08/2022 14:17:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=98
06/08/2022 14:17:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=99
06/08/2022 14:17:08 - INFO - __main__ - Global step 800 Train loss 0.27 Classification-F1 0.6603331654626284 on epoch=99
06/08/2022 14:17:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.35 on epoch=101
06/08/2022 14:17:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=102
06/08/2022 14:17:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.26 on epoch=103
06/08/2022 14:17:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=104
06/08/2022 14:17:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.24 on epoch=106
06/08/2022 14:17:22 - INFO - __main__ - Global step 850 Train loss 0.26 Classification-F1 0.6493370322207928 on epoch=106
06/08/2022 14:17:25 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=107
06/08/2022 14:17:27 - INFO - __main__ - Step 870 Global step 870 Train loss 0.26 on epoch=108
06/08/2022 14:17:30 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=109
06/08/2022 14:17:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=111
06/08/2022 14:17:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.30 on epoch=112
06/08/2022 14:17:37 - INFO - __main__ - Global step 900 Train loss 0.24 Classification-F1 0.6756561085972851 on epoch=112
06/08/2022 14:17:39 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=113
06/08/2022 14:17:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=114
06/08/2022 14:17:44 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=116
06/08/2022 14:17:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=117
06/08/2022 14:17:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=118
06/08/2022 14:17:51 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.6967888433405675 on epoch=118
06/08/2022 14:17:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6950646745521201 -> 0.6967888433405675 on epoch=118, global_step=950
06/08/2022 14:17:54 - INFO - __main__ - Step 960 Global step 960 Train loss 0.24 on epoch=119
06/08/2022 14:17:56 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=121
06/08/2022 14:17:59 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=122
06/08/2022 14:18:01 - INFO - __main__ - Step 990 Global step 990 Train loss 0.29 on epoch=123
06/08/2022 14:18:04 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=124
06/08/2022 14:18:05 - INFO - __main__ - Global step 1000 Train loss 0.21 Classification-F1 0.7038179212092257 on epoch=124
06/08/2022 14:18:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6967888433405675 -> 0.7038179212092257 on epoch=124, global_step=1000
06/08/2022 14:18:08 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.22 on epoch=126
06/08/2022 14:18:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.24 on epoch=127
06/08/2022 14:18:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=128
06/08/2022 14:18:15 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=129
06/08/2022 14:18:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.17 on epoch=131
06/08/2022 14:18:20 - INFO - __main__ - Global step 1050 Train loss 0.19 Classification-F1 0.7459419981427023 on epoch=131
06/08/2022 14:18:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7038179212092257 -> 0.7459419981427023 on epoch=131, global_step=1050
06/08/2022 14:18:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=132
06/08/2022 14:18:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=133
06/08/2022 14:18:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=134
06/08/2022 14:18:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=136
06/08/2022 14:18:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=137
06/08/2022 14:18:34 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.695426715660266 on epoch=137
06/08/2022 14:18:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=138
06/08/2022 14:18:39 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=139
06/08/2022 14:18:41 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=141
06/08/2022 14:18:44 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=142
06/08/2022 14:18:47 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=143
06/08/2022 14:18:48 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.7096880692167576 on epoch=143
06/08/2022 14:18:51 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=144
06/08/2022 14:18:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=146
06/08/2022 14:18:56 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=147
06/08/2022 14:18:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=148
06/08/2022 14:19:01 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=149
06/08/2022 14:19:03 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.7131958649912332 on epoch=149
06/08/2022 14:19:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=151
06/08/2022 14:19:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.16 on epoch=152
06/08/2022 14:19:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=153
06/08/2022 14:19:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=154
06/08/2022 14:19:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=156
06/08/2022 14:19:17 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.6680628731998595 on epoch=156
06/08/2022 14:19:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=157
06/08/2022 14:19:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=158
06/08/2022 14:19:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=159
06/08/2022 14:19:27 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=161
06/08/2022 14:19:29 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=162
06/08/2022 14:19:31 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.6909591108293597 on epoch=162
06/08/2022 14:19:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=163
06/08/2022 14:19:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.24 on epoch=164
06/08/2022 14:19:39 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=166
06/08/2022 14:19:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=167
06/08/2022 14:19:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=168
06/08/2022 14:19:46 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.7357048748353097 on epoch=168
06/08/2022 14:19:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=169
06/08/2022 14:19:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=171
06/08/2022 14:19:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=172
06/08/2022 14:19:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=173
06/08/2022 14:19:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=174
06/08/2022 14:20:00 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.6976035196687371 on epoch=174
06/08/2022 14:20:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=176
06/08/2022 14:20:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=177
06/08/2022 14:20:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=178
06/08/2022 14:20:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=179
06/08/2022 14:20:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=181
06/08/2022 14:20:15 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.6552083333333333 on epoch=181
06/08/2022 14:20:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=182
06/08/2022 14:20:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=183
06/08/2022 14:20:23 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=184
06/08/2022 14:20:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.14 on epoch=186
06/08/2022 14:20:28 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=187
06/08/2022 14:20:30 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.7239212323693255 on epoch=187
06/08/2022 14:20:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.14 on epoch=188
06/08/2022 14:20:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=189
06/08/2022 14:20:37 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=191
06/08/2022 14:20:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=192
06/08/2022 14:20:43 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=193
06/08/2022 14:20:44 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.7007758670732079 on epoch=193
06/08/2022 14:20:47 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=194
06/08/2022 14:20:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=196
06/08/2022 14:20:52 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=197
06/08/2022 14:20:55 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=198
06/08/2022 14:20:57 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=199
06/08/2022 14:20:59 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.6222565137396879 on epoch=199
06/08/2022 14:21:02 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=201
06/08/2022 14:21:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=202
06/08/2022 14:21:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=203
06/08/2022 14:21:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=204
06/08/2022 14:21:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.12 on epoch=206
06/08/2022 14:21:14 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.6662141989008666 on epoch=206
06/08/2022 14:21:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=207
06/08/2022 14:21:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=208
06/08/2022 14:21:21 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=209
06/08/2022 14:21:24 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=211
06/08/2022 14:21:27 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=212
06/08/2022 14:21:28 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.7150740432812802 on epoch=212
06/08/2022 14:21:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=213
06/08/2022 14:21:34 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=214
06/08/2022 14:21:36 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=216
06/08/2022 14:21:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=217
06/08/2022 14:21:41 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=218
06/08/2022 14:21:43 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7145300777653719 on epoch=218
06/08/2022 14:21:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=219
06/08/2022 14:21:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=221
06/08/2022 14:21:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=222
06/08/2022 14:21:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=223
06/08/2022 14:21:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=224
06/08/2022 14:21:58 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.6892537790078774 on epoch=224
06/08/2022 14:22:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=226
06/08/2022 14:22:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=227
06/08/2022 14:22:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=228
06/08/2022 14:22:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=229
06/08/2022 14:22:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=231
06/08/2022 14:22:13 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6248164739018398 on epoch=231
06/08/2022 14:22:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=232
06/08/2022 14:22:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=233
06/08/2022 14:22:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=234
06/08/2022 14:22:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=236
06/08/2022 14:22:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=237
06/08/2022 14:22:29 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.6667694167007573 on epoch=237
06/08/2022 14:22:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=238
06/08/2022 14:22:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=239
06/08/2022 14:22:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=241
06/08/2022 14:22:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=242
06/08/2022 14:22:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=243
06/08/2022 14:22:43 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6281642987962816 on epoch=243
06/08/2022 14:22:46 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=244
06/08/2022 14:22:48 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=246
06/08/2022 14:22:51 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=247
06/08/2022 14:22:54 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=248
06/08/2022 14:22:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=249
06/08/2022 14:22:58 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6931802497019889 on epoch=249
06/08/2022 14:23:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=251
06/08/2022 14:23:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=252
06/08/2022 14:23:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=253
06/08/2022 14:23:08 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=254
06/08/2022 14:23:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=256
06/08/2022 14:23:13 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7158675206853433 on epoch=256
06/08/2022 14:23:16 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.15 on epoch=257
06/08/2022 14:23:18 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=258
06/08/2022 14:23:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=259
06/08/2022 14:23:24 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.14 on epoch=261
06/08/2022 14:23:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=262
06/08/2022 14:23:28 - INFO - __main__ - Global step 2100 Train loss 0.09 Classification-F1 0.6750241896468311 on epoch=262
06/08/2022 14:23:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=263
06/08/2022 14:23:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=264
06/08/2022 14:23:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.10 on epoch=266
06/08/2022 14:23:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=267
06/08/2022 14:23:42 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=268
06/08/2022 14:23:44 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.6979446460980036 on epoch=268
06/08/2022 14:23:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=269
06/08/2022 14:23:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=271
06/08/2022 14:23:51 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=272
06/08/2022 14:23:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=273
06/08/2022 14:23:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=274
06/08/2022 14:23:59 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.696343488796319 on epoch=274
06/08/2022 14:24:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=276
06/08/2022 14:24:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=277
06/08/2022 14:24:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=278
06/08/2022 14:24:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=279
06/08/2022 14:24:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=281
06/08/2022 14:24:13 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.6871216598749494 on epoch=281
06/08/2022 14:24:16 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=282
06/08/2022 14:24:18 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=283
06/08/2022 14:24:21 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=284
06/08/2022 14:24:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=286
06/08/2022 14:24:26 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=287
06/08/2022 14:24:28 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.6667277925663019 on epoch=287
06/08/2022 14:24:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=288
06/08/2022 14:24:33 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=289
06/08/2022 14:24:36 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=291
06/08/2022 14:24:38 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=292
06/08/2022 14:24:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=293
06/08/2022 14:24:43 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7321908978106036 on epoch=293
06/08/2022 14:24:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=294
06/08/2022 14:24:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=296
06/08/2022 14:24:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=297
06/08/2022 14:24:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=298
06/08/2022 14:24:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=299
06/08/2022 14:24:57 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7099051959064132 on epoch=299
06/08/2022 14:25:00 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
06/08/2022 14:25:02 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
06/08/2022 14:25:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=303
06/08/2022 14:25:08 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=304
06/08/2022 14:25:10 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=306
06/08/2022 14:25:12 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7156721805919359 on epoch=306
06/08/2022 14:25:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.07 on epoch=307
06/08/2022 14:25:17 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=308
06/08/2022 14:25:20 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=309
06/08/2022 14:25:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=311
06/08/2022 14:25:25 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=312
06/08/2022 14:25:27 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6839969834087481 on epoch=312
06/08/2022 14:25:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=313
06/08/2022 14:25:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/08/2022 14:25:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=316
06/08/2022 14:25:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=317
06/08/2022 14:25:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=318
06/08/2022 14:25:41 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7179153951694934 on epoch=318
06/08/2022 14:25:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
06/08/2022 14:25:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=321
06/08/2022 14:25:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
06/08/2022 14:25:52 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=323
06/08/2022 14:25:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=324
06/08/2022 14:25:56 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7272980019687658 on epoch=324
06/08/2022 14:25:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
06/08/2022 14:26:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=327
06/08/2022 14:26:04 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=328
06/08/2022 14:26:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=329
06/08/2022 14:26:09 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=331
06/08/2022 14:26:11 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6989360072320423 on epoch=331
06/08/2022 14:26:13 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=332
06/08/2022 14:26:16 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
06/08/2022 14:26:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=334
06/08/2022 14:26:21 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.10 on epoch=336
06/08/2022 14:26:24 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=337
06/08/2022 14:26:26 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.702002805965328 on epoch=337
06/08/2022 14:26:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/08/2022 14:26:31 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=339
06/08/2022 14:26:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
06/08/2022 14:26:36 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=342
06/08/2022 14:26:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=343
06/08/2022 14:26:40 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7134880664841095 on epoch=343
06/08/2022 14:26:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=344
06/08/2022 14:26:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=346
06/08/2022 14:26:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
06/08/2022 14:26:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=348
06/08/2022 14:26:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
06/08/2022 14:26:55 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7067669172932332 on epoch=349
06/08/2022 14:26:58 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
06/08/2022 14:27:00 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=352
06/08/2022 14:27:03 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=353
06/08/2022 14:27:06 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/08/2022 14:27:08 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=356
06/08/2022 14:27:10 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.699786536982407 on epoch=356
06/08/2022 14:27:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=357
06/08/2022 14:27:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=358
06/08/2022 14:27:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=359
06/08/2022 14:27:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=361
06/08/2022 14:27:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/08/2022 14:27:25 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.6984429516379143 on epoch=362
06/08/2022 14:27:27 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=363
06/08/2022 14:27:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=364
06/08/2022 14:27:33 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
06/08/2022 14:27:35 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=367
06/08/2022 14:27:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=368
06/08/2022 14:27:40 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.6716869865326182 on epoch=368
06/08/2022 14:27:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
06/08/2022 14:27:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=371
06/08/2022 14:27:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=372
06/08/2022 14:27:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=373
06/08/2022 14:27:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=374
06/08/2022 14:27:54 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 14:27:54 - INFO - __main__ - Printing 3 examples
06/08/2022 14:27:54 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 14:27:54 - INFO - __main__ - ['happy']
06/08/2022 14:27:54 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 14:27:54 - INFO - __main__ - ['happy']
06/08/2022 14:27:54 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 14:27:54 - INFO - __main__ - ['happy']
06/08/2022 14:27:54 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:27:54 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:27:54 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 14:27:54 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 14:27:54 - INFO - __main__ - Printing 3 examples
06/08/2022 14:27:54 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/08/2022 14:27:54 - INFO - __main__ - ['happy']
06/08/2022 14:27:54 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/08/2022 14:27:54 - INFO - __main__ - ['happy']
06/08/2022 14:27:54 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/08/2022 14:27:54 - INFO - __main__ - ['happy']
06/08/2022 14:27:54 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:27:54 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:27:54 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 14:27:54 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6794251808125282 on epoch=374
06/08/2022 14:27:54 - INFO - __main__ - save last model!
06/08/2022 14:27:54 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 14:27:54 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 14:27:54 - INFO - __main__ - Printing 3 examples
06/08/2022 14:27:54 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 14:27:54 - INFO - __main__ - ['others']
06/08/2022 14:27:54 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 14:27:54 - INFO - __main__ - ['others']
06/08/2022 14:27:54 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 14:27:54 - INFO - __main__ - ['others']
06/08/2022 14:27:54 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:27:57 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:28:03 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 14:28:09 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 14:28:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 14:28:10 - INFO - __main__ - Starting training!
06/08/2022 14:29:20 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_42_0.3_8_predictions.txt
06/08/2022 14:29:20 - INFO - __main__ - Classification-F1 on test data: 0.2838
06/08/2022 14:29:20 - INFO - __main__ - prefix=emo_32_42, lr=0.3, bsz=8, dev_performance=0.7459419981427023, test_performance=0.28380924379578726
06/08/2022 14:29:20 - INFO - __main__ - Running ... prefix=emo_32_42, lr=0.2, bsz=8 ...
06/08/2022 14:29:21 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 14:29:21 - INFO - __main__ - Printing 3 examples
06/08/2022 14:29:21 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 14:29:21 - INFO - __main__ - ['happy']
06/08/2022 14:29:21 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 14:29:21 - INFO - __main__ - ['happy']
06/08/2022 14:29:21 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 14:29:21 - INFO - __main__ - ['happy']
06/08/2022 14:29:21 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:29:21 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:29:21 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 14:29:21 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 14:29:21 - INFO - __main__ - Printing 3 examples
06/08/2022 14:29:21 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/08/2022 14:29:21 - INFO - __main__ - ['happy']
06/08/2022 14:29:21 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/08/2022 14:29:21 - INFO - __main__ - ['happy']
06/08/2022 14:29:21 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/08/2022 14:29:21 - INFO - __main__ - ['happy']
06/08/2022 14:29:21 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:29:21 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:29:21 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 14:29:38 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 14:29:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 14:29:39 - INFO - __main__ - Starting training!
06/08/2022 14:29:42 - INFO - __main__ - Step 10 Global step 10 Train loss 3.16 on epoch=1
06/08/2022 14:29:45 - INFO - __main__ - Step 20 Global step 20 Train loss 1.89 on epoch=2
06/08/2022 14:29:47 - INFO - __main__ - Step 30 Global step 30 Train loss 1.36 on epoch=3
06/08/2022 14:29:50 - INFO - __main__ - Step 40 Global step 40 Train loss 1.18 on epoch=4
06/08/2022 14:29:52 - INFO - __main__ - Step 50 Global step 50 Train loss 1.02 on epoch=6
06/08/2022 14:29:54 - INFO - __main__ - Global step 50 Train loss 1.72 Classification-F1 0.18406593406593408 on epoch=6
06/08/2022 14:29:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.18406593406593408 on epoch=6, global_step=50
06/08/2022 14:29:57 - INFO - __main__ - Step 60 Global step 60 Train loss 0.90 on epoch=7
06/08/2022 14:29:59 - INFO - __main__ - Step 70 Global step 70 Train loss 0.94 on epoch=8
06/08/2022 14:30:02 - INFO - __main__ - Step 80 Global step 80 Train loss 1.00 on epoch=9
06/08/2022 14:30:04 - INFO - __main__ - Step 90 Global step 90 Train loss 0.99 on epoch=11
06/08/2022 14:30:07 - INFO - __main__ - Step 100 Global step 100 Train loss 0.86 on epoch=12
06/08/2022 14:30:09 - INFO - __main__ - Global step 100 Train loss 0.94 Classification-F1 0.11578044596912522 on epoch=12
06/08/2022 14:30:11 - INFO - __main__ - Step 110 Global step 110 Train loss 0.89 on epoch=13
06/08/2022 14:30:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.95 on epoch=14
06/08/2022 14:30:16 - INFO - __main__ - Step 130 Global step 130 Train loss 0.86 on epoch=16
06/08/2022 14:30:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.87 on epoch=17
06/08/2022 14:30:22 - INFO - __main__ - Step 150 Global step 150 Train loss 0.80 on epoch=18
06/08/2022 14:30:23 - INFO - __main__ - Global step 150 Train loss 0.87 Classification-F1 0.3450624091257103 on epoch=18
06/08/2022 14:30:24 - INFO - __main__ - Saving model with best Classification-F1: 0.18406593406593408 -> 0.3450624091257103 on epoch=18, global_step=150
06/08/2022 14:30:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.81 on epoch=19
06/08/2022 14:30:29 - INFO - __main__ - Step 170 Global step 170 Train loss 0.92 on epoch=21
06/08/2022 14:30:31 - INFO - __main__ - Step 180 Global step 180 Train loss 0.77 on epoch=22
06/08/2022 14:30:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.84 on epoch=23
06/08/2022 14:30:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.78 on epoch=24
06/08/2022 14:30:38 - INFO - __main__ - Global step 200 Train loss 0.82 Classification-F1 0.13025283347863992 on epoch=24
06/08/2022 14:30:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.83 on epoch=26
06/08/2022 14:30:43 - INFO - __main__ - Step 220 Global step 220 Train loss 0.77 on epoch=27
06/08/2022 14:30:46 - INFO - __main__ - Step 230 Global step 230 Train loss 0.75 on epoch=28
06/08/2022 14:30:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.73 on epoch=29
06/08/2022 14:30:51 - INFO - __main__ - Step 250 Global step 250 Train loss 0.78 on epoch=31
06/08/2022 14:30:53 - INFO - __main__ - Global step 250 Train loss 0.77 Classification-F1 0.4947510822510822 on epoch=31
06/08/2022 14:30:53 - INFO - __main__ - Saving model with best Classification-F1: 0.3450624091257103 -> 0.4947510822510822 on epoch=31, global_step=250
06/08/2022 14:30:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.71 on epoch=32
06/08/2022 14:30:58 - INFO - __main__ - Step 270 Global step 270 Train loss 0.64 on epoch=33
06/08/2022 14:31:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.73 on epoch=34
06/08/2022 14:31:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.68 on epoch=36
06/08/2022 14:31:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.66 on epoch=37
06/08/2022 14:31:08 - INFO - __main__ - Global step 300 Train loss 0.68 Classification-F1 0.4948993928445983 on epoch=37
06/08/2022 14:31:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4947510822510822 -> 0.4948993928445983 on epoch=37, global_step=300
06/08/2022 14:31:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.64 on epoch=38
06/08/2022 14:31:14 - INFO - __main__ - Step 320 Global step 320 Train loss 0.67 on epoch=39
06/08/2022 14:31:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.58 on epoch=41
06/08/2022 14:31:19 - INFO - __main__ - Step 340 Global step 340 Train loss 0.65 on epoch=42
06/08/2022 14:31:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.62 on epoch=43
06/08/2022 14:31:24 - INFO - __main__ - Global step 350 Train loss 0.63 Classification-F1 0.5554955913651567 on epoch=43
06/08/2022 14:31:24 - INFO - __main__ - Saving model with best Classification-F1: 0.4948993928445983 -> 0.5554955913651567 on epoch=43, global_step=350
06/08/2022 14:31:26 - INFO - __main__ - Step 360 Global step 360 Train loss 0.58 on epoch=44
06/08/2022 14:31:29 - INFO - __main__ - Step 370 Global step 370 Train loss 0.57 on epoch=46
06/08/2022 14:31:31 - INFO - __main__ - Step 380 Global step 380 Train loss 0.60 on epoch=47
06/08/2022 14:31:34 - INFO - __main__ - Step 390 Global step 390 Train loss 0.61 on epoch=48
06/08/2022 14:31:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.61 on epoch=49
06/08/2022 14:31:38 - INFO - __main__ - Global step 400 Train loss 0.60 Classification-F1 0.5654419162603513 on epoch=49
06/08/2022 14:31:38 - INFO - __main__ - Saving model with best Classification-F1: 0.5554955913651567 -> 0.5654419162603513 on epoch=49, global_step=400
06/08/2022 14:31:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.59 on epoch=51
06/08/2022 14:31:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.56 on epoch=52
06/08/2022 14:31:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.50 on epoch=53
06/08/2022 14:31:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.53 on epoch=54
06/08/2022 14:31:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.56 on epoch=56
06/08/2022 14:31:53 - INFO - __main__ - Global step 450 Train loss 0.55 Classification-F1 0.5009157509157509 on epoch=56
06/08/2022 14:31:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.58 on epoch=57
06/08/2022 14:31:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.50 on epoch=58
06/08/2022 14:32:01 - INFO - __main__ - Step 480 Global step 480 Train loss 0.55 on epoch=59
06/08/2022 14:32:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.48 on epoch=61
06/08/2022 14:32:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.48 on epoch=62
06/08/2022 14:32:08 - INFO - __main__ - Global step 500 Train loss 0.52 Classification-F1 0.6555367508739636 on epoch=62
06/08/2022 14:32:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5654419162603513 -> 0.6555367508739636 on epoch=62, global_step=500
06/08/2022 14:32:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.48 on epoch=63
06/08/2022 14:32:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.49 on epoch=64
06/08/2022 14:32:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.52 on epoch=66
06/08/2022 14:32:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.46 on epoch=67
06/08/2022 14:32:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.47 on epoch=68
06/08/2022 14:32:23 - INFO - __main__ - Global step 550 Train loss 0.48 Classification-F1 0.6350827991452992 on epoch=68
06/08/2022 14:32:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.47 on epoch=69
06/08/2022 14:32:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.52 on epoch=71
06/08/2022 14:32:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.46 on epoch=72
06/08/2022 14:32:33 - INFO - __main__ - Step 590 Global step 590 Train loss 0.42 on epoch=73
06/08/2022 14:32:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.45 on epoch=74
06/08/2022 14:32:38 - INFO - __main__ - Global step 600 Train loss 0.46 Classification-F1 0.6420217209690894 on epoch=74
06/08/2022 14:32:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.54 on epoch=76
06/08/2022 14:32:43 - INFO - __main__ - Step 620 Global step 620 Train loss 0.43 on epoch=77
06/08/2022 14:32:46 - INFO - __main__ - Step 630 Global step 630 Train loss 0.41 on epoch=78
06/08/2022 14:32:48 - INFO - __main__ - Step 640 Global step 640 Train loss 0.46 on epoch=79
06/08/2022 14:32:51 - INFO - __main__ - Step 650 Global step 650 Train loss 0.38 on epoch=81
06/08/2022 14:32:53 - INFO - __main__ - Global step 650 Train loss 0.44 Classification-F1 0.6894349845201239 on epoch=81
06/08/2022 14:32:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6555367508739636 -> 0.6894349845201239 on epoch=81, global_step=650
06/08/2022 14:32:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.41 on epoch=82
06/08/2022 14:32:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.43 on epoch=83
06/08/2022 14:33:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.48 on epoch=84
06/08/2022 14:33:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.53 on epoch=86
06/08/2022 14:33:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.44 on epoch=87
06/08/2022 14:33:07 - INFO - __main__ - Global step 700 Train loss 0.46 Classification-F1 0.7056482262752141 on epoch=87
06/08/2022 14:33:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6894349845201239 -> 0.7056482262752141 on epoch=87, global_step=700
06/08/2022 14:33:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.53 on epoch=88
06/08/2022 14:33:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.42 on epoch=89
06/08/2022 14:33:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.34 on epoch=91
06/08/2022 14:33:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.42 on epoch=92
06/08/2022 14:33:20 - INFO - __main__ - Step 750 Global step 750 Train loss 0.41 on epoch=93
06/08/2022 14:33:21 - INFO - __main__ - Global step 750 Train loss 0.42 Classification-F1 0.7020249517717535 on epoch=93
06/08/2022 14:33:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.34 on epoch=94
06/08/2022 14:33:26 - INFO - __main__ - Step 770 Global step 770 Train loss 0.34 on epoch=96
06/08/2022 14:33:29 - INFO - __main__ - Step 780 Global step 780 Train loss 0.40 on epoch=97
06/08/2022 14:33:32 - INFO - __main__ - Step 790 Global step 790 Train loss 0.37 on epoch=98
06/08/2022 14:33:34 - INFO - __main__ - Step 800 Global step 800 Train loss 0.36 on epoch=99
06/08/2022 14:33:36 - INFO - __main__ - Global step 800 Train loss 0.36 Classification-F1 0.7178751952945501 on epoch=99
06/08/2022 14:33:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7056482262752141 -> 0.7178751952945501 on epoch=99, global_step=800
06/08/2022 14:33:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.51 on epoch=101
06/08/2022 14:33:41 - INFO - __main__ - Step 820 Global step 820 Train loss 0.35 on epoch=102
06/08/2022 14:33:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.37 on epoch=103
06/08/2022 14:33:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.37 on epoch=104
06/08/2022 14:33:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.37 on epoch=106
06/08/2022 14:33:51 - INFO - __main__ - Global step 850 Train loss 0.39 Classification-F1 0.6868197278911565 on epoch=106
06/08/2022 14:33:53 - INFO - __main__ - Step 860 Global step 860 Train loss 0.35 on epoch=107
06/08/2022 14:33:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.45 on epoch=108
06/08/2022 14:33:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.23 on epoch=109
06/08/2022 14:34:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.31 on epoch=111
06/08/2022 14:34:03 - INFO - __main__ - Step 900 Global step 900 Train loss 0.27 on epoch=112
06/08/2022 14:34:05 - INFO - __main__ - Global step 900 Train loss 0.32 Classification-F1 0.7384266832428189 on epoch=112
06/08/2022 14:34:05 - INFO - __main__ - Saving model with best Classification-F1: 0.7178751952945501 -> 0.7384266832428189 on epoch=112, global_step=900
06/08/2022 14:34:08 - INFO - __main__ - Step 910 Global step 910 Train loss 0.30 on epoch=113
06/08/2022 14:34:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.31 on epoch=114
06/08/2022 14:34:13 - INFO - __main__ - Step 930 Global step 930 Train loss 0.34 on epoch=116
06/08/2022 14:34:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.35 on epoch=117
06/08/2022 14:34:18 - INFO - __main__ - Step 950 Global step 950 Train loss 0.39 on epoch=118
06/08/2022 14:34:20 - INFO - __main__ - Global step 950 Train loss 0.34 Classification-F1 0.6888861856946963 on epoch=118
06/08/2022 14:34:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.32 on epoch=119
06/08/2022 14:34:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.34 on epoch=121
06/08/2022 14:34:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.33 on epoch=122
06/08/2022 14:34:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.32 on epoch=123
06/08/2022 14:34:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.39 on epoch=124
06/08/2022 14:34:35 - INFO - __main__ - Global step 1000 Train loss 0.34 Classification-F1 0.7139849038446351 on epoch=124
06/08/2022 14:34:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.28 on epoch=126
06/08/2022 14:34:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.32 on epoch=127
06/08/2022 14:34:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.31 on epoch=128
06/08/2022 14:34:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.35 on epoch=129
06/08/2022 14:34:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.32 on epoch=131
06/08/2022 14:34:49 - INFO - __main__ - Global step 1050 Train loss 0.31 Classification-F1 0.6756190637720488 on epoch=131
06/08/2022 14:34:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.30 on epoch=132
06/08/2022 14:34:55 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.27 on epoch=133
06/08/2022 14:34:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.27 on epoch=134
06/08/2022 14:35:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.32 on epoch=136
06/08/2022 14:35:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.24 on epoch=137
06/08/2022 14:35:04 - INFO - __main__ - Global step 1100 Train loss 0.28 Classification-F1 0.7167112612505954 on epoch=137
06/08/2022 14:35:07 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.28 on epoch=138
06/08/2022 14:35:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.29 on epoch=139
06/08/2022 14:35:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.26 on epoch=141
06/08/2022 14:35:15 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.26 on epoch=142
06/08/2022 14:35:17 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.23 on epoch=143
06/08/2022 14:35:19 - INFO - __main__ - Global step 1150 Train loss 0.26 Classification-F1 0.6544097222222222 on epoch=143
06/08/2022 14:35:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.30 on epoch=144
06/08/2022 14:35:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.26 on epoch=146
06/08/2022 14:35:27 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.20 on epoch=147
06/08/2022 14:35:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.25 on epoch=148
06/08/2022 14:35:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.26 on epoch=149
06/08/2022 14:35:34 - INFO - __main__ - Global step 1200 Train loss 0.26 Classification-F1 0.7006785199955688 on epoch=149
06/08/2022 14:35:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.23 on epoch=151
06/08/2022 14:35:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.18 on epoch=152
06/08/2022 14:35:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.26 on epoch=153
06/08/2022 14:35:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.25 on epoch=154
06/08/2022 14:35:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.19 on epoch=156
06/08/2022 14:35:49 - INFO - __main__ - Global step 1250 Train loss 0.22 Classification-F1 0.6639465664074738 on epoch=156
06/08/2022 14:35:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.25 on epoch=157
06/08/2022 14:35:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.28 on epoch=158
06/08/2022 14:35:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=159
06/08/2022 14:35:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.21 on epoch=161
06/08/2022 14:36:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.28 on epoch=162
06/08/2022 14:36:03 - INFO - __main__ - Global step 1300 Train loss 0.24 Classification-F1 0.6542487856695295 on epoch=162
06/08/2022 14:36:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.23 on epoch=163
06/08/2022 14:36:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.33 on epoch=164
06/08/2022 14:36:11 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.22 on epoch=166
06/08/2022 14:36:14 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.23 on epoch=167
06/08/2022 14:36:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.18 on epoch=168
06/08/2022 14:36:18 - INFO - __main__ - Global step 1350 Train loss 0.24 Classification-F1 0.666898656898657 on epoch=168
06/08/2022 14:36:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.29 on epoch=169
06/08/2022 14:36:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.33 on epoch=171
06/08/2022 14:36:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.16 on epoch=172
06/08/2022 14:36:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.19 on epoch=173
06/08/2022 14:36:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.24 on epoch=174
06/08/2022 14:36:33 - INFO - __main__ - Global step 1400 Train loss 0.24 Classification-F1 0.7303125197285638 on epoch=174
06/08/2022 14:36:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.22 on epoch=176
06/08/2022 14:36:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.18 on epoch=177
06/08/2022 14:36:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.20 on epoch=178
06/08/2022 14:36:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=179
06/08/2022 14:36:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.21 on epoch=181
06/08/2022 14:36:48 - INFO - __main__ - Global step 1450 Train loss 0.19 Classification-F1 0.7281743491250534 on epoch=181
06/08/2022 14:36:51 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.16 on epoch=182
06/08/2022 14:36:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.23 on epoch=183
06/08/2022 14:36:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.21 on epoch=184
06/08/2022 14:36:59 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.30 on epoch=186
06/08/2022 14:37:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.29 on epoch=187
06/08/2022 14:37:03 - INFO - __main__ - Global step 1500 Train loss 0.24 Classification-F1 0.7281296001884238 on epoch=187
06/08/2022 14:37:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=188
06/08/2022 14:37:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.26 on epoch=189
06/08/2022 14:37:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=191
06/08/2022 14:37:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.27 on epoch=192
06/08/2022 14:37:16 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.18 on epoch=193
06/08/2022 14:37:17 - INFO - __main__ - Global step 1550 Train loss 0.22 Classification-F1 0.7030101046494489 on epoch=193
06/08/2022 14:37:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.25 on epoch=194
06/08/2022 14:37:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.20 on epoch=196
06/08/2022 14:37:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=197
06/08/2022 14:37:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.20 on epoch=198
06/08/2022 14:37:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.15 on epoch=199
06/08/2022 14:37:33 - INFO - __main__ - Global step 1600 Train loss 0.18 Classification-F1 0.719669521299956 on epoch=199
06/08/2022 14:37:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.19 on epoch=201
06/08/2022 14:37:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.26 on epoch=202
06/08/2022 14:37:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.26 on epoch=203
06/08/2022 14:37:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.20 on epoch=204
06/08/2022 14:37:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.31 on epoch=206
06/08/2022 14:37:49 - INFO - __main__ - Global step 1650 Train loss 0.24 Classification-F1 0.6737161531279179 on epoch=206
06/08/2022 14:37:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.11 on epoch=207
06/08/2022 14:37:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=208
06/08/2022 14:37:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.13 on epoch=209
06/08/2022 14:37:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.16 on epoch=211
06/08/2022 14:38:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.15 on epoch=212
06/08/2022 14:38:04 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.6900593573405606 on epoch=212
06/08/2022 14:38:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.20 on epoch=213
06/08/2022 14:38:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=214
06/08/2022 14:38:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.19 on epoch=216
06/08/2022 14:38:15 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.19 on epoch=217
06/08/2022 14:38:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=218
06/08/2022 14:38:19 - INFO - __main__ - Global step 1750 Train loss 0.16 Classification-F1 0.7056721556721557 on epoch=218
06/08/2022 14:38:22 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.12 on epoch=219
06/08/2022 14:38:24 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.16 on epoch=221
06/08/2022 14:38:27 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=222
06/08/2022 14:38:30 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.13 on epoch=223
06/08/2022 14:38:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.15 on epoch=224
06/08/2022 14:38:34 - INFO - __main__ - Global step 1800 Train loss 0.14 Classification-F1 0.6977733087807714 on epoch=224
06/08/2022 14:38:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=226
06/08/2022 14:38:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.16 on epoch=227
06/08/2022 14:38:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.22 on epoch=228
06/08/2022 14:38:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.22 on epoch=229
06/08/2022 14:38:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.11 on epoch=231
06/08/2022 14:38:49 - INFO - __main__ - Global step 1850 Train loss 0.17 Classification-F1 0.7098435464758999 on epoch=231
06/08/2022 14:38:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=232
06/08/2022 14:38:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=233
06/08/2022 14:38:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.13 on epoch=234
06/08/2022 14:39:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.12 on epoch=236
06/08/2022 14:39:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.15 on epoch=237
06/08/2022 14:39:04 - INFO - __main__ - Global step 1900 Train loss 0.11 Classification-F1 0.7008817520028927 on epoch=237
06/08/2022 14:39:07 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.14 on epoch=238
06/08/2022 14:39:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.11 on epoch=239
06/08/2022 14:39:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.14 on epoch=241
06/08/2022 14:39:15 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.19 on epoch=242
06/08/2022 14:39:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=243
06/08/2022 14:39:20 - INFO - __main__ - Global step 1950 Train loss 0.13 Classification-F1 0.7031675177516175 on epoch=243
06/08/2022 14:39:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.13 on epoch=244
06/08/2022 14:39:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.12 on epoch=246
06/08/2022 14:39:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=247
06/08/2022 14:39:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.10 on epoch=248
06/08/2022 14:39:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=249
06/08/2022 14:39:35 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.7110597683771579 on epoch=249
06/08/2022 14:39:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.15 on epoch=251
06/08/2022 14:39:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=252
06/08/2022 14:39:43 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=253
06/08/2022 14:39:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.14 on epoch=254
06/08/2022 14:39:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.12 on epoch=256
06/08/2022 14:39:50 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.7090436661196167 on epoch=256
06/08/2022 14:39:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=257
06/08/2022 14:39:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=258
06/08/2022 14:39:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=259
06/08/2022 14:40:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.11 on epoch=261
06/08/2022 14:40:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=262
06/08/2022 14:40:05 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.7324478503845516 on epoch=262
06/08/2022 14:40:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.12 on epoch=263
06/08/2022 14:40:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=264
06/08/2022 14:40:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=266
06/08/2022 14:40:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=267
06/08/2022 14:40:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.11 on epoch=268
06/08/2022 14:40:21 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.7175543241232458 on epoch=268
06/08/2022 14:40:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.08 on epoch=269
06/08/2022 14:40:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.17 on epoch=271
06/08/2022 14:40:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.13 on epoch=272
06/08/2022 14:40:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.20 on epoch=273
06/08/2022 14:40:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.11 on epoch=274
06/08/2022 14:40:36 - INFO - __main__ - Global step 2200 Train loss 0.14 Classification-F1 0.6998956356736242 on epoch=274
06/08/2022 14:40:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.13 on epoch=276
06/08/2022 14:40:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.14 on epoch=277
06/08/2022 14:40:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.17 on epoch=278
06/08/2022 14:40:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.12 on epoch=279
06/08/2022 14:40:49 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.13 on epoch=281
06/08/2022 14:40:51 - INFO - __main__ - Global step 2250 Train loss 0.14 Classification-F1 0.7219966249517588 on epoch=281
06/08/2022 14:40:54 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=282
06/08/2022 14:40:57 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=283
06/08/2022 14:40:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.13 on epoch=284
06/08/2022 14:41:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.13 on epoch=286
06/08/2022 14:41:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.11 on epoch=287
06/08/2022 14:41:07 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.7179437679437679 on epoch=287
06/08/2022 14:41:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=288
06/08/2022 14:41:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=289
06/08/2022 14:41:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.14 on epoch=291
06/08/2022 14:41:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=292
06/08/2022 14:41:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=293
06/08/2022 14:41:22 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.6908247999552347 on epoch=293
06/08/2022 14:41:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=294
06/08/2022 14:41:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=296
06/08/2022 14:41:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.16 on epoch=297
06/08/2022 14:41:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=298
06/08/2022 14:41:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=299
06/08/2022 14:41:37 - INFO - __main__ - Global step 2400 Train loss 0.09 Classification-F1 0.7351511422992631 on epoch=299
06/08/2022 14:41:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.08 on epoch=301
06/08/2022 14:41:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.09 on epoch=302
06/08/2022 14:41:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.12 on epoch=303
06/08/2022 14:41:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.15 on epoch=304
06/08/2022 14:41:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=306
06/08/2022 14:41:52 - INFO - __main__ - Global step 2450 Train loss 0.10 Classification-F1 0.7199524507779776 on epoch=306
06/08/2022 14:41:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.11 on epoch=307
06/08/2022 14:41:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=308
06/08/2022 14:42:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.09 on epoch=309
06/08/2022 14:42:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.11 on epoch=311
06/08/2022 14:42:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=312
06/08/2022 14:42:08 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.7345418242959226 on epoch=312
06/08/2022 14:42:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=313
06/08/2022 14:42:13 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.11 on epoch=314
06/08/2022 14:42:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.13 on epoch=316
06/08/2022 14:42:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=317
06/08/2022 14:42:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.10 on epoch=318
06/08/2022 14:42:23 - INFO - __main__ - Global step 2550 Train loss 0.09 Classification-F1 0.7320614672268883 on epoch=318
06/08/2022 14:42:26 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.10 on epoch=319
06/08/2022 14:42:28 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.09 on epoch=321
06/08/2022 14:42:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=322
06/08/2022 14:42:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=323
06/08/2022 14:42:36 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=324
06/08/2022 14:42:39 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.7031104472899704 on epoch=324
06/08/2022 14:42:41 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.09 on epoch=326
06/08/2022 14:42:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.13 on epoch=327
06/08/2022 14:42:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.11 on epoch=328
06/08/2022 14:42:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=329
06/08/2022 14:42:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=331
06/08/2022 14:42:54 - INFO - __main__ - Global step 2650 Train loss 0.09 Classification-F1 0.7027950310559006 on epoch=331
06/08/2022 14:42:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=332
06/08/2022 14:42:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=333
06/08/2022 14:43:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.10 on epoch=334
06/08/2022 14:43:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.11 on epoch=336
06/08/2022 14:43:07 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=337
06/08/2022 14:43:10 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.7090084172626867 on epoch=337
06/08/2022 14:43:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=338
06/08/2022 14:43:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=339
06/08/2022 14:43:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.09 on epoch=341
06/08/2022 14:43:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=342
06/08/2022 14:43:23 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.22 on epoch=343
06/08/2022 14:43:25 - INFO - __main__ - Global step 2750 Train loss 0.09 Classification-F1 0.6820806680881308 on epoch=343
06/08/2022 14:43:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=344
06/08/2022 14:43:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.15 on epoch=346
06/08/2022 14:43:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=347
06/08/2022 14:43:35 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=348
06/08/2022 14:43:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=349
06/08/2022 14:43:40 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.6911973650219582 on epoch=349
06/08/2022 14:43:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=351
06/08/2022 14:43:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.18 on epoch=352
06/08/2022 14:43:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=353
06/08/2022 14:43:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=354
06/08/2022 14:43:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=356
06/08/2022 14:43:55 - INFO - __main__ - Global step 2850 Train loss 0.08 Classification-F1 0.6770236581151541 on epoch=356
06/08/2022 14:43:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=357
06/08/2022 14:44:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=358
06/08/2022 14:44:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=359
06/08/2022 14:44:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=361
06/08/2022 14:44:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=362
06/08/2022 14:44:11 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7252349281980015 on epoch=362
06/08/2022 14:44:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=363
06/08/2022 14:44:16 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=364
06/08/2022 14:44:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=366
06/08/2022 14:44:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=367
06/08/2022 14:44:24 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=368
06/08/2022 14:44:26 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7215065400549273 on epoch=368
06/08/2022 14:44:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=369
06/08/2022 14:44:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=371
06/08/2022 14:44:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.11 on epoch=372
06/08/2022 14:44:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=373
06/08/2022 14:44:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=374
06/08/2022 14:44:41 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 14:44:41 - INFO - __main__ - Printing 3 examples
06/08/2022 14:44:41 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 14:44:41 - INFO - __main__ - ['others']
06/08/2022 14:44:41 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 14:44:41 - INFO - __main__ - ['others']
06/08/2022 14:44:41 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 14:44:41 - INFO - __main__ - ['others']
06/08/2022 14:44:41 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:44:41 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:44:41 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 14:44:41 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 14:44:41 - INFO - __main__ - Printing 3 examples
06/08/2022 14:44:41 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/08/2022 14:44:41 - INFO - __main__ - ['others']
06/08/2022 14:44:41 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/08/2022 14:44:41 - INFO - __main__ - ['others']
06/08/2022 14:44:41 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/08/2022 14:44:41 - INFO - __main__ - ['others']
06/08/2022 14:44:41 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:44:41 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:44:41 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 14:44:42 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.7052283105022831 on epoch=374
06/08/2022 14:44:42 - INFO - __main__ - save last model!
06/08/2022 14:44:42 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 14:44:42 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 14:44:42 - INFO - __main__ - Printing 3 examples
06/08/2022 14:44:42 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 14:44:42 - INFO - __main__ - ['others']
06/08/2022 14:44:42 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 14:44:42 - INFO - __main__ - ['others']
06/08/2022 14:44:42 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 14:44:42 - INFO - __main__ - ['others']
06/08/2022 14:44:42 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:44:44 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:44:50 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 14:45:00 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 14:45:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 14:45:01 - INFO - __main__ - Starting training!
06/08/2022 14:46:27 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_42_0.2_8_predictions.txt
06/08/2022 14:46:27 - INFO - __main__ - Classification-F1 on test data: 0.1821
06/08/2022 14:46:27 - INFO - __main__ - prefix=emo_32_42, lr=0.2, bsz=8, dev_performance=0.7384266832428189, test_performance=0.18212244206611078
06/08/2022 14:46:27 - INFO - __main__ - Running ... prefix=emo_32_87, lr=0.5, bsz=8 ...
06/08/2022 14:46:28 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 14:46:28 - INFO - __main__ - Printing 3 examples
06/08/2022 14:46:28 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 14:46:28 - INFO - __main__ - ['others']
06/08/2022 14:46:28 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 14:46:28 - INFO - __main__ - ['others']
06/08/2022 14:46:28 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 14:46:28 - INFO - __main__ - ['others']
06/08/2022 14:46:28 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:46:28 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:46:28 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 14:46:28 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 14:46:28 - INFO - __main__ - Printing 3 examples
06/08/2022 14:46:28 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/08/2022 14:46:28 - INFO - __main__ - ['others']
06/08/2022 14:46:28 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/08/2022 14:46:28 - INFO - __main__ - ['others']
06/08/2022 14:46:28 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/08/2022 14:46:28 - INFO - __main__ - ['others']
06/08/2022 14:46:28 - INFO - __main__ - Tokenizing Input ...
06/08/2022 14:46:28 - INFO - __main__ - Tokenizing Output ...
06/08/2022 14:46:28 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 14:46:44 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 14:46:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 14:46:45 - INFO - __main__ - Starting training!
06/08/2022 14:46:48 - INFO - __main__ - Step 10 Global step 10 Train loss 2.42 on epoch=1
06/08/2022 14:46:51 - INFO - __main__ - Step 20 Global step 20 Train loss 1.18 on epoch=2
06/08/2022 14:46:53 - INFO - __main__ - Step 30 Global step 30 Train loss 1.00 on epoch=3
06/08/2022 14:46:56 - INFO - __main__ - Step 40 Global step 40 Train loss 1.00 on epoch=4
06/08/2022 14:46:59 - INFO - __main__ - Step 50 Global step 50 Train loss 0.96 on epoch=6
06/08/2022 14:47:00 - INFO - __main__ - Global step 50 Train loss 1.31 Classification-F1 0.3728398536448072 on epoch=6
06/08/2022 14:47:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3728398536448072 on epoch=6, global_step=50
06/08/2022 14:47:03 - INFO - __main__ - Step 60 Global step 60 Train loss 0.87 on epoch=7
06/08/2022 14:47:06 - INFO - __main__ - Step 70 Global step 70 Train loss 0.94 on epoch=8
06/08/2022 14:47:08 - INFO - __main__ - Step 80 Global step 80 Train loss 0.90 on epoch=9
06/08/2022 14:47:11 - INFO - __main__ - Step 90 Global step 90 Train loss 0.86 on epoch=11
06/08/2022 14:47:14 - INFO - __main__ - Step 100 Global step 100 Train loss 0.83 on epoch=12
06/08/2022 14:47:15 - INFO - __main__ - Global step 100 Train loss 0.88 Classification-F1 0.1 on epoch=12
06/08/2022 14:47:18 - INFO - __main__ - Step 110 Global step 110 Train loss 0.96 on epoch=13
06/08/2022 14:47:21 - INFO - __main__ - Step 120 Global step 120 Train loss 0.84 on epoch=14
06/08/2022 14:47:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.89 on epoch=16
06/08/2022 14:47:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.78 on epoch=17
06/08/2022 14:47:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.77 on epoch=18
06/08/2022 14:47:31 - INFO - __main__ - Global step 150 Train loss 0.85 Classification-F1 0.4225124140565316 on epoch=18
06/08/2022 14:47:31 - INFO - __main__ - Saving model with best Classification-F1: 0.3728398536448072 -> 0.4225124140565316 on epoch=18, global_step=150
06/08/2022 14:47:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.79 on epoch=19
06/08/2022 14:47:36 - INFO - __main__ - Step 170 Global step 170 Train loss 0.77 on epoch=21
06/08/2022 14:47:39 - INFO - __main__ - Step 180 Global step 180 Train loss 0.69 on epoch=22
06/08/2022 14:47:41 - INFO - __main__ - Step 190 Global step 190 Train loss 0.78 on epoch=23
06/08/2022 14:47:44 - INFO - __main__ - Step 200 Global step 200 Train loss 0.67 on epoch=24
06/08/2022 14:47:46 - INFO - __main__ - Global step 200 Train loss 0.74 Classification-F1 0.4279002967682214 on epoch=24
06/08/2022 14:47:46 - INFO - __main__ - Saving model with best Classification-F1: 0.4225124140565316 -> 0.4279002967682214 on epoch=24, global_step=200
06/08/2022 14:47:48 - INFO - __main__ - Step 210 Global step 210 Train loss 0.68 on epoch=26
06/08/2022 14:47:51 - INFO - __main__ - Step 220 Global step 220 Train loss 0.60 on epoch=27
06/08/2022 14:47:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.55 on epoch=28
06/08/2022 14:47:56 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=29
06/08/2022 14:47:59 - INFO - __main__ - Step 250 Global step 250 Train loss 0.56 on epoch=31
06/08/2022 14:48:01 - INFO - __main__ - Global step 250 Train loss 0.60 Classification-F1 0.615663630109858 on epoch=31
06/08/2022 14:48:01 - INFO - __main__ - Saving model with best Classification-F1: 0.4279002967682214 -> 0.615663630109858 on epoch=31, global_step=250
06/08/2022 14:48:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=32
06/08/2022 14:48:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.63 on epoch=33
06/08/2022 14:48:09 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=34
06/08/2022 14:48:11 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=36
06/08/2022 14:48:14 - INFO - __main__ - Step 300 Global step 300 Train loss 0.57 on epoch=37
06/08/2022 14:48:16 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.6542889250561885 on epoch=37
06/08/2022 14:48:16 - INFO - __main__ - Saving model with best Classification-F1: 0.615663630109858 -> 0.6542889250561885 on epoch=37, global_step=300
06/08/2022 14:48:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.57 on epoch=38
06/08/2022 14:48:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.57 on epoch=39
06/08/2022 14:48:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.53 on epoch=41
06/08/2022 14:48:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.48 on epoch=42
06/08/2022 14:48:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.50 on epoch=43
06/08/2022 14:48:31 - INFO - __main__ - Global step 350 Train loss 0.53 Classification-F1 0.6611246527974605 on epoch=43
06/08/2022 14:48:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6542889250561885 -> 0.6611246527974605 on epoch=43, global_step=350
06/08/2022 14:48:33 - INFO - __main__ - Step 360 Global step 360 Train loss 0.43 on epoch=44
06/08/2022 14:48:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.52 on epoch=46
06/08/2022 14:48:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=47
06/08/2022 14:48:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=48
06/08/2022 14:48:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.48 on epoch=49
06/08/2022 14:48:46 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.5480839044717247 on epoch=49
06/08/2022 14:48:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.54 on epoch=51
06/08/2022 14:48:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.51 on epoch=52
06/08/2022 14:48:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.47 on epoch=53
06/08/2022 14:48:56 - INFO - __main__ - Step 440 Global step 440 Train loss 0.44 on epoch=54
06/08/2022 14:48:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.48 on epoch=56
06/08/2022 14:49:00 - INFO - __main__ - Global step 450 Train loss 0.49 Classification-F1 0.6699162128997622 on epoch=56
06/08/2022 14:49:01 - INFO - __main__ - Saving model with best Classification-F1: 0.6611246527974605 -> 0.6699162128997622 on epoch=56, global_step=450
06/08/2022 14:49:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.40 on epoch=57
06/08/2022 14:49:06 - INFO - __main__ - Step 470 Global step 470 Train loss 0.43 on epoch=58
06/08/2022 14:49:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.40 on epoch=59
06/08/2022 14:49:11 - INFO - __main__ - Step 490 Global step 490 Train loss 0.49 on epoch=61
06/08/2022 14:49:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.70 on epoch=62
06/08/2022 14:49:15 - INFO - __main__ - Global step 500 Train loss 0.48 Classification-F1 0.6271062307149696 on epoch=62
06/08/2022 14:49:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.42 on epoch=63
06/08/2022 14:49:21 - INFO - __main__ - Step 520 Global step 520 Train loss 0.48 on epoch=64
06/08/2022 14:49:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.55 on epoch=66
06/08/2022 14:49:26 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=67
06/08/2022 14:49:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=68
06/08/2022 14:49:30 - INFO - __main__ - Global step 550 Train loss 0.45 Classification-F1 0.5812758148284465 on epoch=68
06/08/2022 14:49:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.45 on epoch=69
06/08/2022 14:49:35 - INFO - __main__ - Step 570 Global step 570 Train loss 0.38 on epoch=71
06/08/2022 14:49:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.45 on epoch=72
06/08/2022 14:49:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.37 on epoch=73
06/08/2022 14:49:44 - INFO - __main__ - Step 600 Global step 600 Train loss 0.40 on epoch=74
06/08/2022 14:49:45 - INFO - __main__ - Global step 600 Train loss 0.41 Classification-F1 0.6323301814177161 on epoch=74
06/08/2022 14:49:48 - INFO - __main__ - Step 610 Global step 610 Train loss 0.66 on epoch=76
06/08/2022 14:49:51 - INFO - __main__ - Step 620 Global step 620 Train loss 0.43 on epoch=77
06/08/2022 14:49:53 - INFO - __main__ - Step 630 Global step 630 Train loss 0.41 on epoch=78
06/08/2022 14:49:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.42 on epoch=79
06/08/2022 14:49:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.48 on epoch=81
06/08/2022 14:50:00 - INFO - __main__ - Global step 650 Train loss 0.48 Classification-F1 0.6485713088785086 on epoch=81
06/08/2022 14:50:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.62 on epoch=82
06/08/2022 14:50:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.50 on epoch=83
06/08/2022 14:50:08 - INFO - __main__ - Step 680 Global step 680 Train loss 0.30 on epoch=84
06/08/2022 14:50:11 - INFO - __main__ - Step 690 Global step 690 Train loss 0.24 on epoch=86
06/08/2022 14:50:13 - INFO - __main__ - Step 700 Global step 700 Train loss 0.34 on epoch=87
06/08/2022 14:50:15 - INFO - __main__ - Global step 700 Train loss 0.40 Classification-F1 0.5675286214920361 on epoch=87
06/08/2022 14:50:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.23 on epoch=88
06/08/2022 14:50:21 - INFO - __main__ - Step 720 Global step 720 Train loss 0.32 on epoch=89
06/08/2022 14:50:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.30 on epoch=91
06/08/2022 14:50:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.32 on epoch=92
06/08/2022 14:50:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.29 on epoch=93
06/08/2022 14:50:30 - INFO - __main__ - Global step 750 Train loss 0.29 Classification-F1 0.663869928811097 on epoch=93
06/08/2022 14:50:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.36 on epoch=94
06/08/2022 14:50:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.26 on epoch=96
06/08/2022 14:50:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=97
06/08/2022 14:50:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=98
06/08/2022 14:50:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.38 on epoch=99
06/08/2022 14:50:45 - INFO - __main__ - Global step 800 Train loss 0.30 Classification-F1 0.724047619047619 on epoch=99
06/08/2022 14:50:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6699162128997622 -> 0.724047619047619 on epoch=99, global_step=800
06/08/2022 14:50:48 - INFO - __main__ - Step 810 Global step 810 Train loss 0.32 on epoch=101
06/08/2022 14:50:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.38 on epoch=102
06/08/2022 14:50:53 - INFO - __main__ - Step 830 Global step 830 Train loss 0.23 on epoch=103
06/08/2022 14:50:56 - INFO - __main__ - Step 840 Global step 840 Train loss 0.26 on epoch=104
06/08/2022 14:50:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.34 on epoch=106
06/08/2022 14:51:00 - INFO - __main__ - Global step 850 Train loss 0.31 Classification-F1 0.701784353246256 on epoch=106
06/08/2022 14:51:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=107
06/08/2022 14:51:05 - INFO - __main__ - Step 870 Global step 870 Train loss 0.26 on epoch=108
06/08/2022 14:51:08 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=109
06/08/2022 14:51:11 - INFO - __main__ - Step 890 Global step 890 Train loss 0.29 on epoch=111
06/08/2022 14:51:13 - INFO - __main__ - Step 900 Global step 900 Train loss 0.34 on epoch=112
06/08/2022 14:51:15 - INFO - __main__ - Global step 900 Train loss 0.27 Classification-F1 0.7196463071296149 on epoch=112
06/08/2022 14:51:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.29 on epoch=113
06/08/2022 14:51:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=114
06/08/2022 14:51:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.30 on epoch=116
06/08/2022 14:51:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.26 on epoch=117
06/08/2022 14:51:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.23 on epoch=118
06/08/2022 14:51:30 - INFO - __main__ - Global step 950 Train loss 0.25 Classification-F1 0.676822372812715 on epoch=118
06/08/2022 14:51:33 - INFO - __main__ - Step 960 Global step 960 Train loss 0.25 on epoch=119
06/08/2022 14:51:35 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=121
06/08/2022 14:51:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=122
06/08/2022 14:51:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.21 on epoch=123
06/08/2022 14:51:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=124
06/08/2022 14:51:45 - INFO - __main__ - Global step 1000 Train loss 0.20 Classification-F1 0.7107940382168778 on epoch=124
06/08/2022 14:51:48 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=126
06/08/2022 14:51:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.28 on epoch=127
06/08/2022 14:51:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=128
06/08/2022 14:51:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=129
06/08/2022 14:51:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=131
06/08/2022 14:52:00 - INFO - __main__ - Global step 1050 Train loss 0.19 Classification-F1 0.7201497454327643 on epoch=131
06/08/2022 14:52:03 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=132
06/08/2022 14:52:06 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=133
06/08/2022 14:52:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=134
06/08/2022 14:52:11 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=136
06/08/2022 14:52:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=137
06/08/2022 14:52:15 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.7015530303030304 on epoch=137
06/08/2022 14:52:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=138
06/08/2022 14:52:21 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.22 on epoch=139
06/08/2022 14:52:23 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=141
06/08/2022 14:52:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=142
06/08/2022 14:52:28 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=143
06/08/2022 14:52:30 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.7482362717583423 on epoch=143
06/08/2022 14:52:30 - INFO - __main__ - Saving model with best Classification-F1: 0.724047619047619 -> 0.7482362717583423 on epoch=143, global_step=1150
06/08/2022 14:52:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=144
06/08/2022 14:52:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=146
06/08/2022 14:52:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=147
06/08/2022 14:52:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=148
06/08/2022 14:52:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=149
06/08/2022 14:52:45 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.7213262764632627 on epoch=149
06/08/2022 14:52:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=151
06/08/2022 14:52:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=152
06/08/2022 14:52:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=153
06/08/2022 14:52:56 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=154
06/08/2022 14:52:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=156
06/08/2022 14:53:00 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.7108172447954987 on epoch=156
06/08/2022 14:53:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=157
06/08/2022 14:53:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=158
06/08/2022 14:53:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=159
06/08/2022 14:53:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=161
06/08/2022 14:53:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=162
06/08/2022 14:53:15 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.7290994564740949 on epoch=162
06/08/2022 14:53:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=163
06/08/2022 14:53:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=164
06/08/2022 14:53:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.14 on epoch=166
06/08/2022 14:53:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=167
06/08/2022 14:53:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.28 on epoch=168
06/08/2022 14:53:31 - INFO - __main__ - Global step 1350 Train loss 0.16 Classification-F1 0.7212363660239773 on epoch=168
06/08/2022 14:53:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=169
06/08/2022 14:53:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=171
06/08/2022 14:53:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=172
06/08/2022 14:53:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.19 on epoch=173
06/08/2022 14:53:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=174
06/08/2022 14:53:46 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.7290933305364545 on epoch=174
06/08/2022 14:53:48 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=176
06/08/2022 14:53:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=177
06/08/2022 14:53:54 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=178
06/08/2022 14:53:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=179
06/08/2022 14:53:59 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=181
06/08/2022 14:54:01 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.737817140665242 on epoch=181
06/08/2022 14:54:03 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=182
06/08/2022 14:54:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=183
06/08/2022 14:54:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=184
06/08/2022 14:54:11 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.13 on epoch=186
06/08/2022 14:54:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.18 on epoch=187
06/08/2022 14:54:16 - INFO - __main__ - Global step 1500 Train loss 0.13 Classification-F1 0.7128153455739662 on epoch=187
06/08/2022 14:54:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=188
06/08/2022 14:54:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=189
06/08/2022 14:54:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=191
06/08/2022 14:54:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=192
06/08/2022 14:54:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=193
06/08/2022 14:54:31 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.7787629994526547 on epoch=193
06/08/2022 14:54:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7482362717583423 -> 0.7787629994526547 on epoch=193, global_step=1550
06/08/2022 14:54:33 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=194
06/08/2022 14:54:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.15 on epoch=196
06/08/2022 14:54:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=197
06/08/2022 14:54:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=198
06/08/2022 14:54:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=199
06/08/2022 14:54:46 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.7006379585326953 on epoch=199
06/08/2022 14:54:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=201
06/08/2022 14:54:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.15 on epoch=202
06/08/2022 14:54:53 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.16 on epoch=203
06/08/2022 14:54:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=204
06/08/2022 14:54:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=206
06/08/2022 14:55:01 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.7343384303323451 on epoch=206
06/08/2022 14:55:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=207
06/08/2022 14:55:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=208
06/08/2022 14:55:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=209
06/08/2022 14:55:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=211
06/08/2022 14:55:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=212
06/08/2022 14:55:15 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.728558881359589 on epoch=212
06/08/2022 14:55:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=213
06/08/2022 14:55:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=214
06/08/2022 14:55:24 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=216
06/08/2022 14:55:26 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.13 on epoch=217
06/08/2022 14:55:29 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=218
06/08/2022 14:55:31 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.753444666001994 on epoch=218
06/08/2022 14:55:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=219
06/08/2022 14:55:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=221
06/08/2022 14:55:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=222
06/08/2022 14:55:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=223
06/08/2022 14:55:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=224
06/08/2022 14:55:46 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.7140380805635043 on epoch=224
06/08/2022 14:55:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=226
06/08/2022 14:55:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.12 on epoch=227
06/08/2022 14:55:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=228
06/08/2022 14:55:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=229
06/08/2022 14:55:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=231
06/08/2022 14:56:01 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.6842989478290997 on epoch=231
06/08/2022 14:56:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.14 on epoch=232
06/08/2022 14:56:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=233
06/08/2022 14:56:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=234
06/08/2022 14:56:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=236
06/08/2022 14:56:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=237
06/08/2022 14:56:16 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.7097381954184198 on epoch=237
06/08/2022 14:56:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=238
06/08/2022 14:56:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=239
06/08/2022 14:56:24 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=241
06/08/2022 14:56:27 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=242
06/08/2022 14:56:29 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=243
06/08/2022 14:56:31 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.7069222896454829 on epoch=243
06/08/2022 14:56:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=244
06/08/2022 14:56:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=246
06/08/2022 14:56:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=247
06/08/2022 14:56:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=248
06/08/2022 14:56:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=249
06/08/2022 14:56:46 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.6945165945165946 on epoch=249
06/08/2022 14:56:49 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=251
06/08/2022 14:56:52 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=252
06/08/2022 14:56:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.12 on epoch=253
06/08/2022 14:56:57 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=254
06/08/2022 14:57:00 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=256
06/08/2022 14:57:01 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.7158706703255795 on epoch=256
06/08/2022 14:57:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=257
06/08/2022 14:57:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=258
06/08/2022 14:57:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.11 on epoch=259
06/08/2022 14:57:12 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=261
06/08/2022 14:57:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=262
06/08/2022 14:57:17 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7453432717517224 on epoch=262
06/08/2022 14:57:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=263
06/08/2022 14:57:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=264
06/08/2022 14:57:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=266
06/08/2022 14:57:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=267
06/08/2022 14:57:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=268
06/08/2022 14:57:32 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7309199505020183 on epoch=268
06/08/2022 14:57:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=269
06/08/2022 14:57:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=271
06/08/2022 14:57:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=272
06/08/2022 14:57:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.13 on epoch=273
06/08/2022 14:57:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=274
06/08/2022 14:57:47 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.692331313111836 on epoch=274
06/08/2022 14:57:50 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=276
06/08/2022 14:57:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=277
06/08/2022 14:57:56 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.09 on epoch=278
06/08/2022 14:57:58 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.11 on epoch=279
06/08/2022 14:58:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.09 on epoch=281
06/08/2022 14:58:03 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.734637643155956 on epoch=281
06/08/2022 14:58:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=282
06/08/2022 14:58:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=283
06/08/2022 14:58:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=284
06/08/2022 14:58:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=286
06/08/2022 14:58:16 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.11 on epoch=287
06/08/2022 14:58:18 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7075587084148728 on epoch=287
06/08/2022 14:58:20 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=288
06/08/2022 14:58:23 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=289
06/08/2022 14:58:26 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=291
06/08/2022 14:58:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=292
06/08/2022 14:58:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=293
06/08/2022 14:58:33 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7470889366329805 on epoch=293
06/08/2022 14:58:36 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=294
06/08/2022 14:58:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.14 on epoch=296
06/08/2022 14:58:41 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.16 on epoch=297
06/08/2022 14:58:44 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=298
06/08/2022 14:58:47 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=299
06/08/2022 14:58:48 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.7315519729312833 on epoch=299
06/08/2022 14:58:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=301
06/08/2022 14:58:54 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=302
06/08/2022 14:58:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
06/08/2022 14:58:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=304
06/08/2022 14:59:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=306
06/08/2022 14:59:04 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7232471505012489 on epoch=306
06/08/2022 14:59:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=307
06/08/2022 14:59:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=308
06/08/2022 14:59:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=309
06/08/2022 14:59:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=311
06/08/2022 14:59:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=312
06/08/2022 14:59:19 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7219144507117915 on epoch=312
06/08/2022 14:59:22 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=313
06/08/2022 14:59:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=314
06/08/2022 14:59:27 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=316
06/08/2022 14:59:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=317
06/08/2022 14:59:32 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=318
06/08/2022 14:59:34 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7293559419381788 on epoch=318
06/08/2022 14:59:36 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
06/08/2022 14:59:39 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=321
06/08/2022 14:59:42 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
06/08/2022 14:59:44 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=323
06/08/2022 14:59:47 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.11 on epoch=324
06/08/2022 14:59:49 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7416286618184805 on epoch=324
06/08/2022 14:59:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=326
06/08/2022 14:59:54 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=327
06/08/2022 14:59:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=328
06/08/2022 14:59:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.13 on epoch=329
06/08/2022 15:00:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=331
06/08/2022 15:00:04 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.7008859784283513 on epoch=331
06/08/2022 15:00:06 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=332
06/08/2022 15:00:09 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=333
06/08/2022 15:00:11 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=334
06/08/2022 15:00:14 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=336
06/08/2022 15:00:17 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=337
06/08/2022 15:00:18 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.6928354423296594 on epoch=337
06/08/2022 15:00:21 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=338
06/08/2022 15:00:24 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=339
06/08/2022 15:00:26 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=341
06/08/2022 15:00:29 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=342
06/08/2022 15:00:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=343
06/08/2022 15:00:34 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7002361542443063 on epoch=343
06/08/2022 15:00:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=344
06/08/2022 15:00:39 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=346
06/08/2022 15:00:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=347
06/08/2022 15:00:44 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=348
06/08/2022 15:00:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
06/08/2022 15:00:49 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6892378807633045 on epoch=349
06/08/2022 15:00:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
06/08/2022 15:00:54 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=352
06/08/2022 15:00:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
06/08/2022 15:00:59 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=354
06/08/2022 15:01:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=356
06/08/2022 15:01:04 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7459933163472545 on epoch=356
06/08/2022 15:01:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.09 on epoch=357
06/08/2022 15:01:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=358
06/08/2022 15:01:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/08/2022 15:01:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=361
06/08/2022 15:01:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/08/2022 15:01:19 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7143867466604535 on epoch=362
06/08/2022 15:01:21 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.11 on epoch=363
06/08/2022 15:01:24 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
06/08/2022 15:01:27 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=366
06/08/2022 15:01:29 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=367
06/08/2022 15:01:32 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=368
06/08/2022 15:01:34 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.7278543595707775 on epoch=368
06/08/2022 15:01:37 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=369
06/08/2022 15:01:39 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=371
06/08/2022 15:01:42 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=372
06/08/2022 15:01:44 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=373
06/08/2022 15:01:47 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.07 on epoch=374
06/08/2022 15:01:48 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 15:01:48 - INFO - __main__ - Printing 3 examples
06/08/2022 15:01:48 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 15:01:48 - INFO - __main__ - ['others']
06/08/2022 15:01:48 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 15:01:48 - INFO - __main__ - ['others']
06/08/2022 15:01:48 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 15:01:48 - INFO - __main__ - ['others']
06/08/2022 15:01:48 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:01:48 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:01:49 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 15:01:49 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 15:01:49 - INFO - __main__ - Printing 3 examples
06/08/2022 15:01:49 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/08/2022 15:01:49 - INFO - __main__ - ['others']
06/08/2022 15:01:49 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/08/2022 15:01:49 - INFO - __main__ - ['others']
06/08/2022 15:01:49 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/08/2022 15:01:49 - INFO - __main__ - ['others']
06/08/2022 15:01:49 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:01:49 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:01:49 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.738584997963046 on epoch=374
06/08/2022 15:01:49 - INFO - __main__ - save last model!
06/08/2022 15:01:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 15:01:49 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 15:01:49 - INFO - __main__ - Printing 3 examples
06/08/2022 15:01:49 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 15:01:49 - INFO - __main__ - ['others']
06/08/2022 15:01:49 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 15:01:49 - INFO - __main__ - ['others']
06/08/2022 15:01:49 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 15:01:49 - INFO - __main__ - ['others']
06/08/2022 15:01:49 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:01:49 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 15:01:51 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:01:56 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 15:02:07 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 15:02:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 15:02:08 - INFO - __main__ - Starting training!
06/08/2022 15:03:12 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_87_0.5_8_predictions.txt
06/08/2022 15:03:12 - INFO - __main__ - Classification-F1 on test data: 0.2174
06/08/2022 15:03:13 - INFO - __main__ - prefix=emo_32_87, lr=0.5, bsz=8, dev_performance=0.7787629994526547, test_performance=0.21738601362263074
06/08/2022 15:03:13 - INFO - __main__ - Running ... prefix=emo_32_87, lr=0.4, bsz=8 ...
06/08/2022 15:03:14 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 15:03:14 - INFO - __main__ - Printing 3 examples
06/08/2022 15:03:14 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 15:03:14 - INFO - __main__ - ['others']
06/08/2022 15:03:14 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 15:03:14 - INFO - __main__ - ['others']
06/08/2022 15:03:14 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 15:03:14 - INFO - __main__ - ['others']
06/08/2022 15:03:14 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:03:14 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:03:14 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 15:03:14 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 15:03:14 - INFO - __main__ - Printing 3 examples
06/08/2022 15:03:14 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/08/2022 15:03:14 - INFO - __main__ - ['others']
06/08/2022 15:03:14 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/08/2022 15:03:14 - INFO - __main__ - ['others']
06/08/2022 15:03:14 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/08/2022 15:03:14 - INFO - __main__ - ['others']
06/08/2022 15:03:14 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:03:14 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:03:14 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 15:03:33 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 15:03:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 15:03:34 - INFO - __main__ - Starting training!
06/08/2022 15:03:38 - INFO - __main__ - Step 10 Global step 10 Train loss 2.67 on epoch=1
06/08/2022 15:03:40 - INFO - __main__ - Step 20 Global step 20 Train loss 1.34 on epoch=2
06/08/2022 15:03:43 - INFO - __main__ - Step 30 Global step 30 Train loss 1.03 on epoch=3
06/08/2022 15:03:45 - INFO - __main__ - Step 40 Global step 40 Train loss 1.02 on epoch=4
06/08/2022 15:03:48 - INFO - __main__ - Step 50 Global step 50 Train loss 0.90 on epoch=6
06/08/2022 15:03:50 - INFO - __main__ - Global step 50 Train loss 1.39 Classification-F1 0.2834582834582835 on epoch=6
06/08/2022 15:03:50 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2834582834582835 on epoch=6, global_step=50
06/08/2022 15:03:53 - INFO - __main__ - Step 60 Global step 60 Train loss 0.87 on epoch=7
06/08/2022 15:03:55 - INFO - __main__ - Step 70 Global step 70 Train loss 0.95 on epoch=8
06/08/2022 15:03:58 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=9
06/08/2022 15:04:00 - INFO - __main__ - Step 90 Global step 90 Train loss 0.90 on epoch=11
06/08/2022 15:04:03 - INFO - __main__ - Step 100 Global step 100 Train loss 0.86 on epoch=12
06/08/2022 15:04:05 - INFO - __main__ - Global step 100 Train loss 0.90 Classification-F1 0.14476797088262056 on epoch=12
06/08/2022 15:04:08 - INFO - __main__ - Step 110 Global step 110 Train loss 0.92 on epoch=13
06/08/2022 15:04:10 - INFO - __main__ - Step 120 Global step 120 Train loss 0.81 on epoch=14
06/08/2022 15:04:13 - INFO - __main__ - Step 130 Global step 130 Train loss 0.77 on epoch=16
06/08/2022 15:04:16 - INFO - __main__ - Step 140 Global step 140 Train loss 0.75 on epoch=17
06/08/2022 15:04:18 - INFO - __main__ - Step 150 Global step 150 Train loss 0.71 on epoch=18
06/08/2022 15:04:20 - INFO - __main__ - Global step 150 Train loss 0.79 Classification-F1 0.3701042052040942 on epoch=18
06/08/2022 15:04:20 - INFO - __main__ - Saving model with best Classification-F1: 0.2834582834582835 -> 0.3701042052040942 on epoch=18, global_step=150
06/08/2022 15:04:23 - INFO - __main__ - Step 160 Global step 160 Train loss 0.62 on epoch=19
06/08/2022 15:04:25 - INFO - __main__ - Step 170 Global step 170 Train loss 0.71 on epoch=21
06/08/2022 15:04:28 - INFO - __main__ - Step 180 Global step 180 Train loss 0.62 on epoch=22
06/08/2022 15:04:31 - INFO - __main__ - Step 190 Global step 190 Train loss 0.73 on epoch=23
06/08/2022 15:04:33 - INFO - __main__ - Step 200 Global step 200 Train loss 0.67 on epoch=24
06/08/2022 15:04:35 - INFO - __main__ - Global step 200 Train loss 0.67 Classification-F1 0.3064602417543594 on epoch=24
06/08/2022 15:04:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.70 on epoch=26
06/08/2022 15:04:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.60 on epoch=27
06/08/2022 15:04:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=28
06/08/2022 15:04:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.58 on epoch=29
06/08/2022 15:04:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.67 on epoch=31
06/08/2022 15:04:50 - INFO - __main__ - Global step 250 Train loss 0.64 Classification-F1 0.49391693759163635 on epoch=31
06/08/2022 15:04:50 - INFO - __main__ - Saving model with best Classification-F1: 0.3701042052040942 -> 0.49391693759163635 on epoch=31, global_step=250
06/08/2022 15:04:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.57 on epoch=32
06/08/2022 15:04:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.65 on epoch=33
06/08/2022 15:04:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=34
06/08/2022 15:05:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.60 on epoch=36
06/08/2022 15:05:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.50 on epoch=37
06/08/2022 15:05:05 - INFO - __main__ - Global step 300 Train loss 0.56 Classification-F1 0.6813215193130286 on epoch=37
06/08/2022 15:05:05 - INFO - __main__ - Saving model with best Classification-F1: 0.49391693759163635 -> 0.6813215193130286 on epoch=37, global_step=300
06/08/2022 15:05:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.62 on epoch=38
06/08/2022 15:05:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.57 on epoch=39
06/08/2022 15:05:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.49 on epoch=41
06/08/2022 15:05:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.51 on epoch=42
06/08/2022 15:05:19 - INFO - __main__ - Step 350 Global step 350 Train loss 0.59 on epoch=43
06/08/2022 15:05:20 - INFO - __main__ - Global step 350 Train loss 0.56 Classification-F1 0.5783583730443057 on epoch=43
06/08/2022 15:05:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.49 on epoch=44
06/08/2022 15:05:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=46
06/08/2022 15:05:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.46 on epoch=47
06/08/2022 15:05:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.37 on epoch=48
06/08/2022 15:05:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=49
06/08/2022 15:05:35 - INFO - __main__ - Global step 400 Train loss 0.43 Classification-F1 0.7108822039780152 on epoch=49
06/08/2022 15:05:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6813215193130286 -> 0.7108822039780152 on epoch=49, global_step=400
06/08/2022 15:05:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.43 on epoch=51
06/08/2022 15:05:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.49 on epoch=52
06/08/2022 15:05:44 - INFO - __main__ - Step 430 Global step 430 Train loss 0.45 on epoch=53
06/08/2022 15:05:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.47 on epoch=54
06/08/2022 15:05:49 - INFO - __main__ - Step 450 Global step 450 Train loss 0.42 on epoch=56
06/08/2022 15:05:50 - INFO - __main__ - Global step 450 Train loss 0.45 Classification-F1 0.5515231514292465 on epoch=56
06/08/2022 15:05:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.43 on epoch=57
06/08/2022 15:05:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.47 on epoch=58
06/08/2022 15:05:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.35 on epoch=59
06/08/2022 15:06:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.35 on epoch=61
06/08/2022 15:06:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.39 on epoch=62
06/08/2022 15:06:05 - INFO - __main__ - Global step 500 Train loss 0.40 Classification-F1 0.7066082438115282 on epoch=62
06/08/2022 15:06:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.43 on epoch=63
06/08/2022 15:06:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.40 on epoch=64
06/08/2022 15:06:13 - INFO - __main__ - Step 530 Global step 530 Train loss 0.42 on epoch=66
06/08/2022 15:06:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=67
06/08/2022 15:06:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.38 on epoch=68
06/08/2022 15:06:20 - INFO - __main__ - Global step 550 Train loss 0.41 Classification-F1 0.6777621010579655 on epoch=68
06/08/2022 15:06:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=69
06/08/2022 15:06:26 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=71
06/08/2022 15:06:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.30 on epoch=72
06/08/2022 15:06:31 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=73
06/08/2022 15:06:34 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=74
06/08/2022 15:06:36 - INFO - __main__ - Global step 600 Train loss 0.33 Classification-F1 0.7557933342828657 on epoch=74
06/08/2022 15:06:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7108822039780152 -> 0.7557933342828657 on epoch=74, global_step=600
06/08/2022 15:06:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.33 on epoch=76
06/08/2022 15:06:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.34 on epoch=77
06/08/2022 15:06:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=78
06/08/2022 15:06:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.28 on epoch=79
06/08/2022 15:06:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.28 on epoch=81
06/08/2022 15:06:50 - INFO - __main__ - Global step 650 Train loss 0.30 Classification-F1 0.6798279845154845 on epoch=81
06/08/2022 15:06:53 - INFO - __main__ - Step 660 Global step 660 Train loss 0.26 on epoch=82
06/08/2022 15:06:56 - INFO - __main__ - Step 670 Global step 670 Train loss 0.26 on epoch=83
06/08/2022 15:06:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.31 on epoch=84
06/08/2022 15:07:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.28 on epoch=86
06/08/2022 15:07:04 - INFO - __main__ - Step 700 Global step 700 Train loss 0.32 on epoch=87
06/08/2022 15:07:05 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.6865427055087576 on epoch=87
06/08/2022 15:07:08 - INFO - __main__ - Step 710 Global step 710 Train loss 0.29 on epoch=88
06/08/2022 15:07:11 - INFO - __main__ - Step 720 Global step 720 Train loss 0.32 on epoch=89
06/08/2022 15:07:14 - INFO - __main__ - Step 730 Global step 730 Train loss 0.29 on epoch=91
06/08/2022 15:07:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.24 on epoch=92
06/08/2022 15:07:19 - INFO - __main__ - Step 750 Global step 750 Train loss 0.24 on epoch=93
06/08/2022 15:07:21 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.7510977492109567 on epoch=93
06/08/2022 15:07:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=94
06/08/2022 15:07:26 - INFO - __main__ - Step 770 Global step 770 Train loss 0.29 on epoch=96
06/08/2022 15:07:29 - INFO - __main__ - Step 780 Global step 780 Train loss 0.25 on epoch=97
06/08/2022 15:07:31 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=98
06/08/2022 15:07:34 - INFO - __main__ - Step 800 Global step 800 Train loss 0.32 on epoch=99
06/08/2022 15:07:36 - INFO - __main__ - Global step 800 Train loss 0.25 Classification-F1 0.771794932775241 on epoch=99
06/08/2022 15:07:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7557933342828657 -> 0.771794932775241 on epoch=99, global_step=800
06/08/2022 15:07:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.29 on epoch=101
06/08/2022 15:07:41 - INFO - __main__ - Step 820 Global step 820 Train loss 0.27 on epoch=102
06/08/2022 15:07:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.30 on epoch=103
06/08/2022 15:07:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=104
06/08/2022 15:07:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.27 on epoch=106
06/08/2022 15:07:51 - INFO - __main__ - Global step 850 Train loss 0.26 Classification-F1 0.7412842039800995 on epoch=106
06/08/2022 15:07:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.32 on epoch=107
06/08/2022 15:07:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=108
06/08/2022 15:07:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=109
06/08/2022 15:08:02 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=111
06/08/2022 15:08:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.37 on epoch=112
06/08/2022 15:08:06 - INFO - __main__ - Global step 900 Train loss 0.25 Classification-F1 0.7697421981004071 on epoch=112
06/08/2022 15:08:09 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=113
06/08/2022 15:08:11 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=114
06/08/2022 15:08:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=116
06/08/2022 15:08:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=117
06/08/2022 15:08:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.24 on epoch=118
06/08/2022 15:08:21 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.7169601584855823 on epoch=118
06/08/2022 15:08:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=119
06/08/2022 15:08:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.26 on epoch=121
06/08/2022 15:08:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=122
06/08/2022 15:08:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=123
06/08/2022 15:08:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=124
06/08/2022 15:08:36 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.734188917828101 on epoch=124
06/08/2022 15:08:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=126
06/08/2022 15:08:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=127
06/08/2022 15:08:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=128
06/08/2022 15:08:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=129
06/08/2022 15:08:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.17 on epoch=131
06/08/2022 15:08:51 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.7302746516969519 on epoch=131
06/08/2022 15:08:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.21 on epoch=132
06/08/2022 15:08:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=133
06/08/2022 15:08:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=134
06/08/2022 15:09:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=136
06/08/2022 15:09:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=137
06/08/2022 15:09:07 - INFO - __main__ - Global step 1100 Train loss 0.18 Classification-F1 0.7335018966840587 on epoch=137
06/08/2022 15:09:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=138
06/08/2022 15:09:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=139
06/08/2022 15:09:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.18 on epoch=141
06/08/2022 15:09:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=142
06/08/2022 15:09:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=143
06/08/2022 15:09:22 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.7528966131907308 on epoch=143
06/08/2022 15:09:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.24 on epoch=144
06/08/2022 15:09:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.19 on epoch=146
06/08/2022 15:09:30 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=147
06/08/2022 15:09:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.22 on epoch=148
06/08/2022 15:09:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.17 on epoch=149
06/08/2022 15:09:37 - INFO - __main__ - Global step 1200 Train loss 0.19 Classification-F1 0.7572321103927777 on epoch=149
06/08/2022 15:09:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=151
06/08/2022 15:09:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=152
06/08/2022 15:09:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=153
06/08/2022 15:09:48 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=154
06/08/2022 15:09:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=156
06/08/2022 15:09:52 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.7372932651321398 on epoch=156
06/08/2022 15:09:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=157
06/08/2022 15:09:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=158
06/08/2022 15:10:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=159
06/08/2022 15:10:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=161
06/08/2022 15:10:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=162
06/08/2022 15:10:07 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.7429495361144076 on epoch=162
06/08/2022 15:10:10 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=163
06/08/2022 15:10:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=164
06/08/2022 15:10:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=166
06/08/2022 15:10:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=167
06/08/2022 15:10:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=168
06/08/2022 15:10:23 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.7249827001134402 on epoch=168
06/08/2022 15:10:26 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=169
06/08/2022 15:10:28 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=171
06/08/2022 15:10:31 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=172
06/08/2022 15:10:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=173
06/08/2022 15:10:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=174
06/08/2022 15:10:38 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7596631629240325 on epoch=174
06/08/2022 15:10:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=176
06/08/2022 15:10:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=177
06/08/2022 15:10:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=178
06/08/2022 15:10:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.20 on epoch=179
06/08/2022 15:10:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=181
06/08/2022 15:10:53 - INFO - __main__ - Global step 1450 Train loss 0.12 Classification-F1 0.7474274216728944 on epoch=181
06/08/2022 15:10:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=182
06/08/2022 15:10:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=183
06/08/2022 15:11:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=184
06/08/2022 15:11:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.14 on epoch=186
06/08/2022 15:11:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=187
06/08/2022 15:11:08 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.7270688543971495 on epoch=187
06/08/2022 15:11:11 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=188
06/08/2022 15:11:13 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=189
06/08/2022 15:11:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=191
06/08/2022 15:11:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=192
06/08/2022 15:11:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=193
06/08/2022 15:11:23 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.7517731164168612 on epoch=193
06/08/2022 15:11:26 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=194
06/08/2022 15:11:28 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=196
06/08/2022 15:11:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=197
06/08/2022 15:11:34 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=198
06/08/2022 15:11:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=199
06/08/2022 15:11:39 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.726965753363269 on epoch=199
06/08/2022 15:11:41 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=201
06/08/2022 15:11:44 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.17 on epoch=202
06/08/2022 15:11:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=203
06/08/2022 15:11:49 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=204
06/08/2022 15:11:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=206
06/08/2022 15:11:54 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.7522971262656344 on epoch=206
06/08/2022 15:11:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=207
06/08/2022 15:11:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=208
06/08/2022 15:12:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=209
06/08/2022 15:12:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=211
06/08/2022 15:12:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=212
06/08/2022 15:12:09 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.6799849381753853 on epoch=212
06/08/2022 15:12:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=213
06/08/2022 15:12:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=214
06/08/2022 15:12:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.12 on epoch=216
06/08/2022 15:12:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=217
06/08/2022 15:12:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=218
06/08/2022 15:12:24 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.6754893923245793 on epoch=218
06/08/2022 15:12:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=219
06/08/2022 15:12:30 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=221
06/08/2022 15:12:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=222
06/08/2022 15:12:35 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=223
06/08/2022 15:12:38 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=224
06/08/2022 15:12:39 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.6944810918074151 on epoch=224
06/08/2022 15:12:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=226
06/08/2022 15:12:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=227
06/08/2022 15:12:47 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=228
06/08/2022 15:12:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=229
06/08/2022 15:12:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=231
06/08/2022 15:12:55 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.7373746099787128 on epoch=231
06/08/2022 15:12:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=232
06/08/2022 15:13:00 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=233
06/08/2022 15:13:03 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=234
06/08/2022 15:13:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.10 on epoch=236
06/08/2022 15:13:08 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=237
06/08/2022 15:13:10 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.7262494308531727 on epoch=237
06/08/2022 15:13:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.11 on epoch=238
06/08/2022 15:13:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=239
06/08/2022 15:13:18 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=241
06/08/2022 15:13:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=242
06/08/2022 15:13:23 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=243
06/08/2022 15:13:25 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.719158496732026 on epoch=243
06/08/2022 15:13:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=244
06/08/2022 15:13:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=246
06/08/2022 15:13:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=247
06/08/2022 15:13:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=248
06/08/2022 15:13:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=249
06/08/2022 15:13:40 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7008098314232918 on epoch=249
06/08/2022 15:13:43 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=251
06/08/2022 15:13:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.14 on epoch=252
06/08/2022 15:13:48 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.10 on epoch=253
06/08/2022 15:13:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=254
06/08/2022 15:13:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=256
06/08/2022 15:13:56 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.7163298313032136 on epoch=256
06/08/2022 15:13:58 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=257
06/08/2022 15:14:01 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=258
06/08/2022 15:14:04 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=259
06/08/2022 15:14:06 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.14 on epoch=261
06/08/2022 15:14:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=262
06/08/2022 15:14:11 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7058991178069698 on epoch=262
06/08/2022 15:14:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=263
06/08/2022 15:14:16 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=264
06/08/2022 15:14:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=266
06/08/2022 15:14:22 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=267
06/08/2022 15:14:24 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=268
06/08/2022 15:14:26 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7148658959170049 on epoch=268
06/08/2022 15:14:29 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.11 on epoch=269
06/08/2022 15:14:32 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=271
06/08/2022 15:14:34 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=272
06/08/2022 15:14:37 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=273
06/08/2022 15:14:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=274
06/08/2022 15:14:41 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7230197039011562 on epoch=274
06/08/2022 15:14:44 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=276
06/08/2022 15:14:47 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=277
06/08/2022 15:14:49 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=278
06/08/2022 15:14:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=279
06/08/2022 15:14:55 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=281
06/08/2022 15:14:56 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6959726867335563 on epoch=281
06/08/2022 15:14:59 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=282
06/08/2022 15:15:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=283
06/08/2022 15:15:04 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=284
06/08/2022 15:15:07 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=286
06/08/2022 15:15:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.09 on epoch=287
06/08/2022 15:15:11 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7401459740903737 on epoch=287
06/08/2022 15:15:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=288
06/08/2022 15:15:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=289
06/08/2022 15:15:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=291
06/08/2022 15:15:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=292
06/08/2022 15:15:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=293
06/08/2022 15:15:27 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.730252838948491 on epoch=293
06/08/2022 15:15:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.10 on epoch=294
06/08/2022 15:15:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=296
06/08/2022 15:15:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=297
06/08/2022 15:15:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=298
06/08/2022 15:15:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=299
06/08/2022 15:15:42 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.7396099674972914 on epoch=299
06/08/2022 15:15:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.21 on epoch=301
06/08/2022 15:15:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=302
06/08/2022 15:15:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
06/08/2022 15:15:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=304
06/08/2022 15:15:56 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=306
06/08/2022 15:15:57 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.7569210201563142 on epoch=306
06/08/2022 15:16:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=307
06/08/2022 15:16:03 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=308
06/08/2022 15:16:05 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=309
06/08/2022 15:16:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=311
06/08/2022 15:16:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=312
06/08/2022 15:16:12 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.750967704217898 on epoch=312
06/08/2022 15:16:15 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=313
06/08/2022 15:16:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=314
06/08/2022 15:16:20 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=316
06/08/2022 15:16:23 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=317
06/08/2022 15:16:25 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=318
06/08/2022 15:16:27 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6765768656975332 on epoch=318
06/08/2022 15:16:30 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=319
06/08/2022 15:16:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=321
06/08/2022 15:16:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=322
06/08/2022 15:16:38 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=323
06/08/2022 15:16:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=324
06/08/2022 15:16:42 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7689883456889066 on epoch=324
06/08/2022 15:16:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=326
06/08/2022 15:16:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=327
06/08/2022 15:16:50 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=328
06/08/2022 15:16:53 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=329
06/08/2022 15:16:55 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
06/08/2022 15:16:57 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7216978795852035 on epoch=331
06/08/2022 15:17:00 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=332
06/08/2022 15:17:02 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
06/08/2022 15:17:05 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=334
06/08/2022 15:17:07 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=336
06/08/2022 15:17:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=337
06/08/2022 15:17:12 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7004828055088522 on epoch=337
06/08/2022 15:17:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=338
06/08/2022 15:17:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=339
06/08/2022 15:17:20 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
06/08/2022 15:17:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=342
06/08/2022 15:17:25 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=343
06/08/2022 15:17:27 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7375622003349597 on epoch=343
06/08/2022 15:17:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
06/08/2022 15:17:32 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
06/08/2022 15:17:35 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=347
06/08/2022 15:17:37 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=348
06/08/2022 15:17:40 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=349
06/08/2022 15:17:42 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6890873015873016 on epoch=349
06/08/2022 15:17:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
06/08/2022 15:17:47 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=352
06/08/2022 15:17:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=353
06/08/2022 15:17:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/08/2022 15:17:55 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.08 on epoch=356
06/08/2022 15:17:57 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7338390775890776 on epoch=356
06/08/2022 15:18:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=357
06/08/2022 15:18:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=358
06/08/2022 15:18:05 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/08/2022 15:18:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=361
06/08/2022 15:18:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.21 on epoch=362
06/08/2022 15:18:12 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.7267311272335021 on epoch=362
06/08/2022 15:18:14 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=363
06/08/2022 15:18:17 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.09 on epoch=364
06/08/2022 15:18:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=366
06/08/2022 15:18:22 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=367
06/08/2022 15:18:25 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=368
06/08/2022 15:18:27 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.7859058565955117 on epoch=368
06/08/2022 15:18:27 - INFO - __main__ - Saving model with best Classification-F1: 0.771794932775241 -> 0.7859058565955117 on epoch=368, global_step=2950
06/08/2022 15:18:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=369
06/08/2022 15:18:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=371
06/08/2022 15:18:35 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=372
06/08/2022 15:18:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=373
06/08/2022 15:18:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
06/08/2022 15:18:42 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 15:18:42 - INFO - __main__ - Printing 3 examples
06/08/2022 15:18:42 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 15:18:42 - INFO - __main__ - ['others']
06/08/2022 15:18:42 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 15:18:42 - INFO - __main__ - ['others']
06/08/2022 15:18:42 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 15:18:42 - INFO - __main__ - ['others']
06/08/2022 15:18:42 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:18:42 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:18:42 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 15:18:42 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 15:18:42 - INFO - __main__ - Printing 3 examples
06/08/2022 15:18:42 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/08/2022 15:18:42 - INFO - __main__ - ['others']
06/08/2022 15:18:42 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/08/2022 15:18:42 - INFO - __main__ - ['others']
06/08/2022 15:18:42 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/08/2022 15:18:42 - INFO - __main__ - ['others']
06/08/2022 15:18:42 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:18:42 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:18:42 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7437693772699088 on epoch=374
06/08/2022 15:18:42 - INFO - __main__ - save last model!
06/08/2022 15:18:42 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 15:18:42 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 15:18:42 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 15:18:42 - INFO - __main__ - Printing 3 examples
06/08/2022 15:18:42 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 15:18:42 - INFO - __main__ - ['others']
06/08/2022 15:18:42 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 15:18:42 - INFO - __main__ - ['others']
06/08/2022 15:18:42 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 15:18:42 - INFO - __main__ - ['others']
06/08/2022 15:18:42 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:18:44 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:18:51 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 15:19:01 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 15:19:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 15:19:01 - INFO - __main__ - Starting training!
06/08/2022 15:20:10 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_87_0.4_8_predictions.txt
06/08/2022 15:20:10 - INFO - __main__ - Classification-F1 on test data: 0.1529
06/08/2022 15:20:10 - INFO - __main__ - prefix=emo_32_87, lr=0.4, bsz=8, dev_performance=0.7859058565955117, test_performance=0.15289049990891665
06/08/2022 15:20:10 - INFO - __main__ - Running ... prefix=emo_32_87, lr=0.3, bsz=8 ...
06/08/2022 15:20:11 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 15:20:11 - INFO - __main__ - Printing 3 examples
06/08/2022 15:20:11 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 15:20:11 - INFO - __main__ - ['others']
06/08/2022 15:20:11 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 15:20:11 - INFO - __main__ - ['others']
06/08/2022 15:20:11 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 15:20:11 - INFO - __main__ - ['others']
06/08/2022 15:20:11 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:20:11 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:20:11 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 15:20:11 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 15:20:11 - INFO - __main__ - Printing 3 examples
06/08/2022 15:20:11 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/08/2022 15:20:11 - INFO - __main__ - ['others']
06/08/2022 15:20:11 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/08/2022 15:20:11 - INFO - __main__ - ['others']
06/08/2022 15:20:11 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/08/2022 15:20:11 - INFO - __main__ - ['others']
06/08/2022 15:20:11 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:20:11 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:20:11 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 15:20:30 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 15:20:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 15:20:30 - INFO - __main__ - Starting training!
06/08/2022 15:20:34 - INFO - __main__ - Step 10 Global step 10 Train loss 2.89 on epoch=1
06/08/2022 15:20:36 - INFO - __main__ - Step 20 Global step 20 Train loss 1.46 on epoch=2
06/08/2022 15:20:39 - INFO - __main__ - Step 30 Global step 30 Train loss 1.08 on epoch=3
06/08/2022 15:20:42 - INFO - __main__ - Step 40 Global step 40 Train loss 1.07 on epoch=4
06/08/2022 15:20:44 - INFO - __main__ - Step 50 Global step 50 Train loss 1.11 on epoch=6
06/08/2022 15:20:46 - INFO - __main__ - Global step 50 Train loss 1.52 Classification-F1 0.15958815958815958 on epoch=6
06/08/2022 15:20:46 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.15958815958815958 on epoch=6, global_step=50
06/08/2022 15:20:49 - INFO - __main__ - Step 60 Global step 60 Train loss 0.87 on epoch=7
06/08/2022 15:20:51 - INFO - __main__ - Step 70 Global step 70 Train loss 0.88 on epoch=8
06/08/2022 15:20:54 - INFO - __main__ - Step 80 Global step 80 Train loss 0.90 on epoch=9
06/08/2022 15:20:56 - INFO - __main__ - Step 90 Global step 90 Train loss 0.90 on epoch=11
06/08/2022 15:20:59 - INFO - __main__ - Step 100 Global step 100 Train loss 0.88 on epoch=12
06/08/2022 15:21:00 - INFO - __main__ - Global step 100 Train loss 0.89 Classification-F1 0.24213286713286714 on epoch=12
06/08/2022 15:21:01 - INFO - __main__ - Saving model with best Classification-F1: 0.15958815958815958 -> 0.24213286713286714 on epoch=12, global_step=100
06/08/2022 15:21:03 - INFO - __main__ - Step 110 Global step 110 Train loss 0.89 on epoch=13
06/08/2022 15:21:06 - INFO - __main__ - Step 120 Global step 120 Train loss 0.89 on epoch=14
06/08/2022 15:21:08 - INFO - __main__ - Step 130 Global step 130 Train loss 0.91 on epoch=16
06/08/2022 15:21:11 - INFO - __main__ - Step 140 Global step 140 Train loss 0.85 on epoch=17
06/08/2022 15:21:14 - INFO - __main__ - Step 150 Global step 150 Train loss 0.88 on epoch=18
06/08/2022 15:21:16 - INFO - __main__ - Global step 150 Train loss 0.88 Classification-F1 0.5569564141020659 on epoch=18
06/08/2022 15:21:16 - INFO - __main__ - Saving model with best Classification-F1: 0.24213286713286714 -> 0.5569564141020659 on epoch=18, global_step=150
06/08/2022 15:21:18 - INFO - __main__ - Step 160 Global step 160 Train loss 0.75 on epoch=19
06/08/2022 15:21:21 - INFO - __main__ - Step 170 Global step 170 Train loss 0.76 on epoch=21
06/08/2022 15:21:23 - INFO - __main__ - Step 180 Global step 180 Train loss 0.88 on epoch=22
06/08/2022 15:21:26 - INFO - __main__ - Step 190 Global step 190 Train loss 0.73 on epoch=23
06/08/2022 15:21:29 - INFO - __main__ - Step 200 Global step 200 Train loss 0.70 on epoch=24
06/08/2022 15:21:31 - INFO - __main__ - Global step 200 Train loss 0.77 Classification-F1 0.42614225478675605 on epoch=24
06/08/2022 15:21:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.82 on epoch=26
06/08/2022 15:21:36 - INFO - __main__ - Step 220 Global step 220 Train loss 0.73 on epoch=27
06/08/2022 15:21:38 - INFO - __main__ - Step 230 Global step 230 Train loss 0.80 on epoch=28
06/08/2022 15:21:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.71 on epoch=29
06/08/2022 15:21:44 - INFO - __main__ - Step 250 Global step 250 Train loss 0.67 on epoch=31
06/08/2022 15:21:46 - INFO - __main__ - Global step 250 Train loss 0.75 Classification-F1 0.5270460505754623 on epoch=31
06/08/2022 15:21:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.70 on epoch=32
06/08/2022 15:21:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.69 on epoch=33
06/08/2022 15:21:53 - INFO - __main__ - Step 280 Global step 280 Train loss 0.62 on epoch=34
06/08/2022 15:21:56 - INFO - __main__ - Step 290 Global step 290 Train loss 0.68 on epoch=36
06/08/2022 15:21:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.70 on epoch=37
06/08/2022 15:22:00 - INFO - __main__ - Global step 300 Train loss 0.68 Classification-F1 0.44874213836477994 on epoch=37
06/08/2022 15:22:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.63 on epoch=38
06/08/2022 15:22:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.56 on epoch=39
06/08/2022 15:22:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.72 on epoch=41
06/08/2022 15:22:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.60 on epoch=42
06/08/2022 15:22:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.57 on epoch=43
06/08/2022 15:22:15 - INFO - __main__ - Global step 350 Train loss 0.62 Classification-F1 0.6198627174985438 on epoch=43
06/08/2022 15:22:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5569564141020659 -> 0.6198627174985438 on epoch=43, global_step=350
06/08/2022 15:22:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.60 on epoch=44
06/08/2022 15:22:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.62 on epoch=46
06/08/2022 15:22:23 - INFO - __main__ - Step 380 Global step 380 Train loss 0.60 on epoch=47
06/08/2022 15:22:26 - INFO - __main__ - Step 390 Global step 390 Train loss 0.69 on epoch=48
06/08/2022 15:22:29 - INFO - __main__ - Step 400 Global step 400 Train loss 0.52 on epoch=49
06/08/2022 15:22:31 - INFO - __main__ - Global step 400 Train loss 0.61 Classification-F1 0.5337393021724819 on epoch=49
06/08/2022 15:22:33 - INFO - __main__ - Step 410 Global step 410 Train loss 0.55 on epoch=51
06/08/2022 15:22:36 - INFO - __main__ - Step 420 Global step 420 Train loss 0.53 on epoch=52
06/08/2022 15:22:38 - INFO - __main__ - Step 430 Global step 430 Train loss 0.51 on epoch=53
06/08/2022 15:22:41 - INFO - __main__ - Step 440 Global step 440 Train loss 0.50 on epoch=54
06/08/2022 15:22:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.52 on epoch=56
06/08/2022 15:22:46 - INFO - __main__ - Global step 450 Train loss 0.52 Classification-F1 0.5132235930621751 on epoch=56
06/08/2022 15:22:48 - INFO - __main__ - Step 460 Global step 460 Train loss 0.52 on epoch=57
06/08/2022 15:22:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.64 on epoch=58
06/08/2022 15:22:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.57 on epoch=59
06/08/2022 15:22:56 - INFO - __main__ - Step 490 Global step 490 Train loss 0.47 on epoch=61
06/08/2022 15:22:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.49 on epoch=62
06/08/2022 15:23:01 - INFO - __main__ - Global step 500 Train loss 0.54 Classification-F1 0.5849559537364415 on epoch=62
06/08/2022 15:23:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.50 on epoch=63
06/08/2022 15:23:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.52 on epoch=64
06/08/2022 15:23:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.44 on epoch=66
06/08/2022 15:23:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.53 on epoch=67
06/08/2022 15:23:14 - INFO - __main__ - Step 550 Global step 550 Train loss 0.49 on epoch=68
06/08/2022 15:23:16 - INFO - __main__ - Global step 550 Train loss 0.50 Classification-F1 0.6668772643462509 on epoch=68
06/08/2022 15:23:16 - INFO - __main__ - Saving model with best Classification-F1: 0.6198627174985438 -> 0.6668772643462509 on epoch=68, global_step=550
06/08/2022 15:23:19 - INFO - __main__ - Step 560 Global step 560 Train loss 0.46 on epoch=69
06/08/2022 15:23:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.48 on epoch=71
06/08/2022 15:23:24 - INFO - __main__ - Step 580 Global step 580 Train loss 0.59 on epoch=72
06/08/2022 15:23:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.53 on epoch=73
06/08/2022 15:23:29 - INFO - __main__ - Step 600 Global step 600 Train loss 0.43 on epoch=74
06/08/2022 15:23:31 - INFO - __main__ - Global step 600 Train loss 0.50 Classification-F1 0.6572407045009785 on epoch=74
06/08/2022 15:23:34 - INFO - __main__ - Step 610 Global step 610 Train loss 0.49 on epoch=76
06/08/2022 15:23:36 - INFO - __main__ - Step 620 Global step 620 Train loss 0.52 on epoch=77
06/08/2022 15:23:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.46 on epoch=78
06/08/2022 15:23:42 - INFO - __main__ - Step 640 Global step 640 Train loss 0.42 on epoch=79
06/08/2022 15:23:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.53 on epoch=81
06/08/2022 15:23:46 - INFO - __main__ - Global step 650 Train loss 0.49 Classification-F1 0.6567056595365419 on epoch=81
06/08/2022 15:23:49 - INFO - __main__ - Step 660 Global step 660 Train loss 0.60 on epoch=82
06/08/2022 15:23:51 - INFO - __main__ - Step 670 Global step 670 Train loss 0.53 on epoch=83
06/08/2022 15:23:54 - INFO - __main__ - Step 680 Global step 680 Train loss 0.44 on epoch=84
06/08/2022 15:23:57 - INFO - __main__ - Step 690 Global step 690 Train loss 0.41 on epoch=86
06/08/2022 15:23:59 - INFO - __main__ - Step 700 Global step 700 Train loss 0.41 on epoch=87
06/08/2022 15:24:01 - INFO - __main__ - Global step 700 Train loss 0.48 Classification-F1 0.5078371272098665 on epoch=87
06/08/2022 15:24:04 - INFO - __main__ - Step 710 Global step 710 Train loss 0.45 on epoch=88
06/08/2022 15:24:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.42 on epoch=89
06/08/2022 15:24:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.34 on epoch=91
06/08/2022 15:24:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.43 on epoch=92
06/08/2022 15:24:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.34 on epoch=93
06/08/2022 15:24:16 - INFO - __main__ - Global step 750 Train loss 0.40 Classification-F1 0.6769936031922333 on epoch=93
06/08/2022 15:24:16 - INFO - __main__ - Saving model with best Classification-F1: 0.6668772643462509 -> 0.6769936031922333 on epoch=93, global_step=750
06/08/2022 15:24:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.44 on epoch=94
06/08/2022 15:24:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.44 on epoch=96
06/08/2022 15:24:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.33 on epoch=97
06/08/2022 15:24:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.41 on epoch=98
06/08/2022 15:24:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=99
06/08/2022 15:24:31 - INFO - __main__ - Global step 800 Train loss 0.39 Classification-F1 0.6244810994441634 on epoch=99
06/08/2022 15:24:34 - INFO - __main__ - Step 810 Global step 810 Train loss 0.44 on epoch=101
06/08/2022 15:24:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.35 on epoch=102
06/08/2022 15:24:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.43 on epoch=103
06/08/2022 15:24:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.34 on epoch=104
06/08/2022 15:24:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.33 on epoch=106
06/08/2022 15:24:46 - INFO - __main__ - Global step 850 Train loss 0.38 Classification-F1 0.6257751529557837 on epoch=106
06/08/2022 15:24:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.33 on epoch=107
06/08/2022 15:24:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.28 on epoch=108
06/08/2022 15:24:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.34 on epoch=109
06/08/2022 15:24:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.36 on epoch=111
06/08/2022 15:24:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.35 on epoch=112
06/08/2022 15:25:01 - INFO - __main__ - Global step 900 Train loss 0.33 Classification-F1 0.6543323472757292 on epoch=112
06/08/2022 15:25:04 - INFO - __main__ - Step 910 Global step 910 Train loss 0.34 on epoch=113
06/08/2022 15:25:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.31 on epoch=114
06/08/2022 15:25:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.37 on epoch=116
06/08/2022 15:25:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.34 on epoch=117
06/08/2022 15:25:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.34 on epoch=118
06/08/2022 15:25:16 - INFO - __main__ - Global step 950 Train loss 0.34 Classification-F1 0.6753067414247265 on epoch=118
06/08/2022 15:25:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.37 on epoch=119
06/08/2022 15:25:21 - INFO - __main__ - Step 970 Global step 970 Train loss 0.34 on epoch=121
06/08/2022 15:25:24 - INFO - __main__ - Step 980 Global step 980 Train loss 0.30 on epoch=122
06/08/2022 15:25:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.33 on epoch=123
06/08/2022 15:25:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.26 on epoch=124
06/08/2022 15:25:32 - INFO - __main__ - Global step 1000 Train loss 0.32 Classification-F1 0.710546494644596 on epoch=124
06/08/2022 15:25:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6769936031922333 -> 0.710546494644596 on epoch=124, global_step=1000
06/08/2022 15:25:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.34 on epoch=126
06/08/2022 15:25:37 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.30 on epoch=127
06/08/2022 15:25:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.39 on epoch=128
06/08/2022 15:25:42 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.31 on epoch=129
06/08/2022 15:25:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.37 on epoch=131
06/08/2022 15:25:46 - INFO - __main__ - Global step 1050 Train loss 0.34 Classification-F1 0.725991324721378 on epoch=131
06/08/2022 15:25:46 - INFO - __main__ - Saving model with best Classification-F1: 0.710546494644596 -> 0.725991324721378 on epoch=131, global_step=1050
06/08/2022 15:25:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.35 on epoch=132
06/08/2022 15:25:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.24 on epoch=133
06/08/2022 15:25:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.25 on epoch=134
06/08/2022 15:25:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=136
06/08/2022 15:26:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=137
06/08/2022 15:26:01 - INFO - __main__ - Global step 1100 Train loss 0.26 Classification-F1 0.6737825201097646 on epoch=137
06/08/2022 15:26:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.26 on epoch=138
06/08/2022 15:26:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.24 on epoch=139
06/08/2022 15:26:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.33 on epoch=141
06/08/2022 15:26:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.26 on epoch=142
06/08/2022 15:26:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.22 on epoch=143
06/08/2022 15:26:17 - INFO - __main__ - Global step 1150 Train loss 0.26 Classification-F1 0.5936618436618437 on epoch=143
06/08/2022 15:26:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.19 on epoch=144
06/08/2022 15:26:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.23 on epoch=146
06/08/2022 15:26:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.21 on epoch=147
06/08/2022 15:26:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=148
06/08/2022 15:26:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=149
06/08/2022 15:26:32 - INFO - __main__ - Global step 1200 Train loss 0.21 Classification-F1 0.7214163195295271 on epoch=149
06/08/2022 15:26:35 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.24 on epoch=151
06/08/2022 15:26:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.20 on epoch=152
06/08/2022 15:26:40 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.26 on epoch=153
06/08/2022 15:26:43 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.26 on epoch=154
06/08/2022 15:26:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.24 on epoch=156
06/08/2022 15:26:47 - INFO - __main__ - Global step 1250 Train loss 0.24 Classification-F1 0.7008989191870919 on epoch=156
06/08/2022 15:26:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.22 on epoch=157
06/08/2022 15:26:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.23 on epoch=158
06/08/2022 15:26:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.26 on epoch=159
06/08/2022 15:26:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.22 on epoch=161
06/08/2022 15:27:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.24 on epoch=162
06/08/2022 15:27:03 - INFO - __main__ - Global step 1300 Train loss 0.23 Classification-F1 0.6938083102193725 on epoch=162
06/08/2022 15:27:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.18 on epoch=163
06/08/2022 15:27:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.27 on epoch=164
06/08/2022 15:27:11 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.19 on epoch=166
06/08/2022 15:27:14 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.19 on epoch=167
06/08/2022 15:27:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.22 on epoch=168
06/08/2022 15:27:18 - INFO - __main__ - Global step 1350 Train loss 0.21 Classification-F1 0.6512607547491268 on epoch=168
06/08/2022 15:27:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=169
06/08/2022 15:27:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.18 on epoch=171
06/08/2022 15:27:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.20 on epoch=172
06/08/2022 15:27:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=173
06/08/2022 15:27:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.25 on epoch=174
06/08/2022 15:27:33 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.748030303030303 on epoch=174
06/08/2022 15:27:33 - INFO - __main__ - Saving model with best Classification-F1: 0.725991324721378 -> 0.748030303030303 on epoch=174, global_step=1400
06/08/2022 15:27:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.16 on epoch=176
06/08/2022 15:27:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.19 on epoch=177
06/08/2022 15:27:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.17 on epoch=178
06/08/2022 15:27:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.17 on epoch=179
06/08/2022 15:27:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.20 on epoch=181
06/08/2022 15:27:49 - INFO - __main__ - Global step 1450 Train loss 0.18 Classification-F1 0.6992651711245327 on epoch=181
06/08/2022 15:27:51 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.29 on epoch=182
06/08/2022 15:27:54 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.18 on epoch=183
06/08/2022 15:27:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=184
06/08/2022 15:27:59 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.25 on epoch=186
06/08/2022 15:28:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.25 on epoch=187
06/08/2022 15:28:04 - INFO - __main__ - Global step 1500 Train loss 0.23 Classification-F1 0.7033317303013128 on epoch=187
06/08/2022 15:28:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.23 on epoch=188
06/08/2022 15:28:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=189
06/08/2022 15:28:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=191
06/08/2022 15:28:15 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.18 on epoch=192
06/08/2022 15:28:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.25 on epoch=193
06/08/2022 15:28:19 - INFO - __main__ - Global step 1550 Train loss 0.19 Classification-F1 0.7201755616745882 on epoch=193
06/08/2022 15:28:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.21 on epoch=194
06/08/2022 15:28:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.20 on epoch=196
06/08/2022 15:28:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.17 on epoch=197
06/08/2022 15:28:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=198
06/08/2022 15:28:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.16 on epoch=199
06/08/2022 15:28:35 - INFO - __main__ - Global step 1600 Train loss 0.17 Classification-F1 0.7204303217598946 on epoch=199
06/08/2022 15:28:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.16 on epoch=201
06/08/2022 15:28:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.18 on epoch=202
06/08/2022 15:28:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.16 on epoch=203
06/08/2022 15:28:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.16 on epoch=204
06/08/2022 15:28:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.15 on epoch=206
06/08/2022 15:28:50 - INFO - __main__ - Global step 1650 Train loss 0.16 Classification-F1 0.7564196850903908 on epoch=206
06/08/2022 15:28:50 - INFO - __main__ - Saving model with best Classification-F1: 0.748030303030303 -> 0.7564196850903908 on epoch=206, global_step=1650
06/08/2022 15:28:53 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=207
06/08/2022 15:28:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=208
06/08/2022 15:28:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=209
06/08/2022 15:29:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.14 on epoch=211
06/08/2022 15:29:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.13 on epoch=212
06/08/2022 15:29:05 - INFO - __main__ - Global step 1700 Train loss 0.14 Classification-F1 0.7308805000969181 on epoch=212
06/08/2022 15:29:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=213
06/08/2022 15:29:10 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=214
06/08/2022 15:29:13 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.15 on epoch=216
06/08/2022 15:29:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.18 on epoch=217
06/08/2022 15:29:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=218
06/08/2022 15:29:20 - INFO - __main__ - Global step 1750 Train loss 0.14 Classification-F1 0.7021862430869783 on epoch=218
06/08/2022 15:29:23 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.14 on epoch=219
06/08/2022 15:29:25 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=221
06/08/2022 15:29:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=222
06/08/2022 15:29:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.18 on epoch=223
06/08/2022 15:29:33 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=224
06/08/2022 15:29:35 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.6929011463553141 on epoch=224
06/08/2022 15:29:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=226
06/08/2022 15:29:41 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=227
06/08/2022 15:29:43 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=228
06/08/2022 15:29:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=229
06/08/2022 15:29:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.14 on epoch=231
06/08/2022 15:29:51 - INFO - __main__ - Global step 1850 Train loss 0.11 Classification-F1 0.5957786195286195 on epoch=231
06/08/2022 15:29:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.14 on epoch=232
06/08/2022 15:29:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=233
06/08/2022 15:29:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.13 on epoch=234
06/08/2022 15:30:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.13 on epoch=236
06/08/2022 15:30:04 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=237
06/08/2022 15:30:06 - INFO - __main__ - Global step 1900 Train loss 0.11 Classification-F1 0.712848158131177 on epoch=237
06/08/2022 15:30:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.10 on epoch=238
06/08/2022 15:30:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=239
06/08/2022 15:30:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.23 on epoch=241
06/08/2022 15:30:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.14 on epoch=242
06/08/2022 15:30:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=243
06/08/2022 15:30:21 - INFO - __main__ - Global step 1950 Train loss 0.13 Classification-F1 0.5428883219954649 on epoch=243
06/08/2022 15:30:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=244
06/08/2022 15:30:26 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=246
06/08/2022 15:30:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=247
06/08/2022 15:30:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.10 on epoch=248
06/08/2022 15:30:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=249
06/08/2022 15:30:36 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.7203091019484462 on epoch=249
06/08/2022 15:30:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=251
06/08/2022 15:30:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=252
06/08/2022 15:30:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.09 on epoch=253
06/08/2022 15:30:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=254
06/08/2022 15:30:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=256
06/08/2022 15:30:51 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.5916785101690764 on epoch=256
06/08/2022 15:30:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.13 on epoch=257
06/08/2022 15:30:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=258
06/08/2022 15:30:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=259
06/08/2022 15:31:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.18 on epoch=261
06/08/2022 15:31:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.13 on epoch=262
06/08/2022 15:31:06 - INFO - __main__ - Global step 2100 Train loss 0.11 Classification-F1 0.7550877463054186 on epoch=262
06/08/2022 15:31:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.15 on epoch=263
06/08/2022 15:31:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=264
06/08/2022 15:31:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.15 on epoch=266
06/08/2022 15:31:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.12 on epoch=267
06/08/2022 15:31:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=268
06/08/2022 15:31:21 - INFO - __main__ - Global step 2150 Train loss 0.11 Classification-F1 0.5733019942931483 on epoch=268
06/08/2022 15:31:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.09 on epoch=269
06/08/2022 15:31:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=271
06/08/2022 15:31:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=272
06/08/2022 15:31:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=273
06/08/2022 15:31:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.12 on epoch=274
06/08/2022 15:31:36 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.7259297243181208 on epoch=274
06/08/2022 15:31:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.19 on epoch=276
06/08/2022 15:31:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.14 on epoch=277
06/08/2022 15:31:45 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=278
06/08/2022 15:31:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=279
06/08/2022 15:31:50 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.09 on epoch=281
06/08/2022 15:31:52 - INFO - __main__ - Global step 2250 Train loss 0.12 Classification-F1 0.7013933128919584 on epoch=281
06/08/2022 15:31:55 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.12 on epoch=282
06/08/2022 15:31:57 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=283
06/08/2022 15:32:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.13 on epoch=284
06/08/2022 15:32:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=286
06/08/2022 15:32:06 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.15 on epoch=287
06/08/2022 15:32:08 - INFO - __main__ - Global step 2300 Train loss 0.10 Classification-F1 0.5428706690561529 on epoch=287
06/08/2022 15:32:10 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=288
06/08/2022 15:32:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=289
06/08/2022 15:32:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=291
06/08/2022 15:32:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=292
06/08/2022 15:32:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=293
06/08/2022 15:32:23 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.5391135114782261 on epoch=293
06/08/2022 15:32:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.10 on epoch=294
06/08/2022 15:32:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=296
06/08/2022 15:32:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=297
06/08/2022 15:32:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=298
06/08/2022 15:32:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=299
06/08/2022 15:32:38 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.5663022287901749 on epoch=299
06/08/2022 15:32:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=301
06/08/2022 15:32:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=302
06/08/2022 15:32:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=303
06/08/2022 15:32:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=304
06/08/2022 15:32:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=306
06/08/2022 15:32:54 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.7162412229081098 on epoch=306
06/08/2022 15:32:56 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=307
06/08/2022 15:32:59 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=308
06/08/2022 15:33:02 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=309
06/08/2022 15:33:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.13 on epoch=311
06/08/2022 15:33:07 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=312
06/08/2022 15:33:09 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.5665995419726764 on epoch=312
06/08/2022 15:33:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.11 on epoch=313
06/08/2022 15:33:14 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=314
06/08/2022 15:33:17 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=316
06/08/2022 15:33:20 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=317
06/08/2022 15:33:23 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.11 on epoch=318
06/08/2022 15:33:24 - INFO - __main__ - Global step 2550 Train loss 0.09 Classification-F1 0.5372332506203474 on epoch=318
06/08/2022 15:33:27 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.10 on epoch=319
06/08/2022 15:33:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=321
06/08/2022 15:33:32 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=322
06/08/2022 15:33:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=323
06/08/2022 15:33:38 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=324
06/08/2022 15:33:40 - INFO - __main__ - Global step 2600 Train loss 0.08 Classification-F1 0.5406727745901714 on epoch=324
06/08/2022 15:33:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=326
06/08/2022 15:33:45 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=327
06/08/2022 15:33:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.08 on epoch=328
06/08/2022 15:33:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=329
06/08/2022 15:33:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.14 on epoch=331
06/08/2022 15:33:55 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.7413641686182669 on epoch=331
06/08/2022 15:33:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.11 on epoch=332
06/08/2022 15:34:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=333
06/08/2022 15:34:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=334
06/08/2022 15:34:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.10 on epoch=336
06/08/2022 15:34:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.11 on epoch=337
06/08/2022 15:34:10 - INFO - __main__ - Global step 2700 Train loss 0.09 Classification-F1 0.5787741436572752 on epoch=337
06/08/2022 15:34:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=338
06/08/2022 15:34:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.11 on epoch=339
06/08/2022 15:34:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=341
06/08/2022 15:34:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.08 on epoch=342
06/08/2022 15:34:23 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=343
06/08/2022 15:34:25 - INFO - __main__ - Global step 2750 Train loss 0.07 Classification-F1 0.5679483795915369 on epoch=343
06/08/2022 15:34:28 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=344
06/08/2022 15:34:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=346
06/08/2022 15:34:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.13 on epoch=347
06/08/2022 15:34:36 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=348
06/08/2022 15:34:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=349
06/08/2022 15:34:40 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.751498067581463 on epoch=349
06/08/2022 15:34:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=351
06/08/2022 15:34:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
06/08/2022 15:34:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=353
06/08/2022 15:34:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=354
06/08/2022 15:34:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=356
06/08/2022 15:34:55 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.578267614738203 on epoch=356
06/08/2022 15:34:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=357
06/08/2022 15:35:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=358
06/08/2022 15:35:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=359
06/08/2022 15:35:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=361
06/08/2022 15:35:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=362
06/08/2022 15:35:10 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7315973960640947 on epoch=362
06/08/2022 15:35:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=363
06/08/2022 15:35:16 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=364
06/08/2022 15:35:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.11 on epoch=366
06/08/2022 15:35:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=367
06/08/2022 15:35:24 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.07 on epoch=368
06/08/2022 15:35:26 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.7536661255411256 on epoch=368
06/08/2022 15:35:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=369
06/08/2022 15:35:31 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=371
06/08/2022 15:35:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.08 on epoch=372
06/08/2022 15:35:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=373
06/08/2022 15:35:39 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=374
06/08/2022 15:35:40 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 15:35:40 - INFO - __main__ - Printing 3 examples
06/08/2022 15:35:40 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 15:35:40 - INFO - __main__ - ['others']
06/08/2022 15:35:40 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 15:35:40 - INFO - __main__ - ['others']
06/08/2022 15:35:40 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 15:35:40 - INFO - __main__ - ['others']
06/08/2022 15:35:40 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:35:41 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:35:41 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 15:35:41 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 15:35:41 - INFO - __main__ - Printing 3 examples
06/08/2022 15:35:41 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/08/2022 15:35:41 - INFO - __main__ - ['others']
06/08/2022 15:35:41 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/08/2022 15:35:41 - INFO - __main__ - ['others']
06/08/2022 15:35:41 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/08/2022 15:35:41 - INFO - __main__ - ['others']
06/08/2022 15:35:41 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:35:41 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:35:41 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 15:35:41 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.7294799498746867 on epoch=374
06/08/2022 15:35:41 - INFO - __main__ - save last model!
06/08/2022 15:35:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 15:35:41 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 15:35:41 - INFO - __main__ - Printing 3 examples
06/08/2022 15:35:41 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 15:35:41 - INFO - __main__ - ['others']
06/08/2022 15:35:41 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 15:35:41 - INFO - __main__ - ['others']
06/08/2022 15:35:41 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 15:35:41 - INFO - __main__ - ['others']
06/08/2022 15:35:41 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:35:43 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:35:49 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 15:36:00 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 15:36:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 15:36:01 - INFO - __main__ - Starting training!
06/08/2022 15:37:08 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_87_0.3_8_predictions.txt
06/08/2022 15:37:08 - INFO - __main__ - Classification-F1 on test data: 0.1747
06/08/2022 15:37:09 - INFO - __main__ - prefix=emo_32_87, lr=0.3, bsz=8, dev_performance=0.7564196850903908, test_performance=0.17468442398694822
06/08/2022 15:37:09 - INFO - __main__ - Running ... prefix=emo_32_87, lr=0.2, bsz=8 ...
06/08/2022 15:37:10 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 15:37:10 - INFO - __main__ - Printing 3 examples
06/08/2022 15:37:10 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 15:37:10 - INFO - __main__ - ['others']
06/08/2022 15:37:10 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 15:37:10 - INFO - __main__ - ['others']
06/08/2022 15:37:10 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 15:37:10 - INFO - __main__ - ['others']
06/08/2022 15:37:10 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:37:10 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:37:10 - INFO - __main__ - Loaded 128 examples from train data
06/08/2022 15:37:10 - INFO - __main__ - Start tokenizing ... 128 instances
06/08/2022 15:37:10 - INFO - __main__ - Printing 3 examples
06/08/2022 15:37:10 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/08/2022 15:37:10 - INFO - __main__ - ['others']
06/08/2022 15:37:10 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/08/2022 15:37:10 - INFO - __main__ - ['others']
06/08/2022 15:37:10 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/08/2022 15:37:10 - INFO - __main__ - ['others']
06/08/2022 15:37:10 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:37:10 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:37:10 - INFO - __main__ - Loaded 128 examples from dev data
06/08/2022 15:37:26 - INFO - __main__ - load prompt embedding from ckpt
06/08/2022 15:37:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/08/2022 15:37:27 - INFO - __main__ - Starting training!
06/08/2022 15:37:30 - INFO - __main__ - Step 10 Global step 10 Train loss 3.32 on epoch=1
06/08/2022 15:37:33 - INFO - __main__ - Step 20 Global step 20 Train loss 1.75 on epoch=2
06/08/2022 15:37:35 - INFO - __main__ - Step 30 Global step 30 Train loss 1.41 on epoch=3
06/08/2022 15:37:38 - INFO - __main__ - Step 40 Global step 40 Train loss 1.23 on epoch=4
06/08/2022 15:37:40 - INFO - __main__ - Step 50 Global step 50 Train loss 1.13 on epoch=6
06/08/2022 15:37:42 - INFO - __main__ - Global step 50 Train loss 1.77 Classification-F1 0.24625448771057717 on epoch=6
06/08/2022 15:37:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.24625448771057717 on epoch=6, global_step=50
06/08/2022 15:37:45 - INFO - __main__ - Step 60 Global step 60 Train loss 0.99 on epoch=7
06/08/2022 15:37:47 - INFO - __main__ - Step 70 Global step 70 Train loss 0.99 on epoch=8
06/08/2022 15:37:50 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=9
06/08/2022 15:37:52 - INFO - __main__ - Step 90 Global step 90 Train loss 0.92 on epoch=11
06/08/2022 15:37:55 - INFO - __main__ - Step 100 Global step 100 Train loss 0.94 on epoch=12
06/08/2022 15:37:56 - INFO - __main__ - Global step 100 Train loss 0.95 Classification-F1 0.23191067164430096 on epoch=12
06/08/2022 15:37:59 - INFO - __main__ - Step 110 Global step 110 Train loss 0.97 on epoch=13
06/08/2022 15:38:02 - INFO - __main__ - Step 120 Global step 120 Train loss 0.82 on epoch=14
06/08/2022 15:38:04 - INFO - __main__ - Step 130 Global step 130 Train loss 0.94 on epoch=16
06/08/2022 15:38:07 - INFO - __main__ - Step 140 Global step 140 Train loss 0.79 on epoch=17
06/08/2022 15:38:09 - INFO - __main__ - Step 150 Global step 150 Train loss 0.83 on epoch=18
06/08/2022 15:38:11 - INFO - __main__ - Global step 150 Train loss 0.87 Classification-F1 0.43529130425422985 on epoch=18
06/08/2022 15:38:11 - INFO - __main__ - Saving model with best Classification-F1: 0.24625448771057717 -> 0.43529130425422985 on epoch=18, global_step=150
06/08/2022 15:38:14 - INFO - __main__ - Step 160 Global step 160 Train loss 0.86 on epoch=19
06/08/2022 15:38:17 - INFO - __main__ - Step 170 Global step 170 Train loss 0.81 on epoch=21
06/08/2022 15:38:19 - INFO - __main__ - Step 180 Global step 180 Train loss 0.78 on epoch=22
06/08/2022 15:38:22 - INFO - __main__ - Step 190 Global step 190 Train loss 0.81 on epoch=23
06/08/2022 15:38:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.85 on epoch=24
06/08/2022 15:38:26 - INFO - __main__ - Global step 200 Train loss 0.82 Classification-F1 0.32784480854016007 on epoch=24
06/08/2022 15:38:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.83 on epoch=26
06/08/2022 15:38:31 - INFO - __main__ - Step 220 Global step 220 Train loss 0.73 on epoch=27
06/08/2022 15:38:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.76 on epoch=28
06/08/2022 15:38:36 - INFO - __main__ - Step 240 Global step 240 Train loss 0.76 on epoch=29
06/08/2022 15:38:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.80 on epoch=31
06/08/2022 15:38:41 - INFO - __main__ - Global step 250 Train loss 0.78 Classification-F1 0.4617834143257872 on epoch=31
06/08/2022 15:38:41 - INFO - __main__ - Saving model with best Classification-F1: 0.43529130425422985 -> 0.4617834143257872 on epoch=31, global_step=250
06/08/2022 15:38:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.69 on epoch=32
06/08/2022 15:38:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.77 on epoch=33
06/08/2022 15:38:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=34
06/08/2022 15:38:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.77 on epoch=36
06/08/2022 15:38:54 - INFO - __main__ - Step 300 Global step 300 Train loss 0.65 on epoch=37
06/08/2022 15:38:56 - INFO - __main__ - Global step 300 Train loss 0.71 Classification-F1 0.46522383139236234 on epoch=37
06/08/2022 15:38:56 - INFO - __main__ - Saving model with best Classification-F1: 0.4617834143257872 -> 0.46522383139236234 on epoch=37, global_step=300
06/08/2022 15:38:58 - INFO - __main__ - Step 310 Global step 310 Train loss 0.73 on epoch=38
06/08/2022 15:39:01 - INFO - __main__ - Step 320 Global step 320 Train loss 0.62 on epoch=39
06/08/2022 15:39:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.65 on epoch=41
06/08/2022 15:39:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.64 on epoch=42
06/08/2022 15:39:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.64 on epoch=43
06/08/2022 15:39:10 - INFO - __main__ - Global step 350 Train loss 0.66 Classification-F1 0.4375161875161875 on epoch=43
06/08/2022 15:39:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.67 on epoch=44
06/08/2022 15:39:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.57 on epoch=46
06/08/2022 15:39:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.64 on epoch=47
06/08/2022 15:39:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.65 on epoch=48
06/08/2022 15:39:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.59 on epoch=49
06/08/2022 15:39:25 - INFO - __main__ - Global step 400 Train loss 0.62 Classification-F1 0.4320132718159034 on epoch=49
06/08/2022 15:39:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.62 on epoch=51
06/08/2022 15:39:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.60 on epoch=52
06/08/2022 15:39:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.55 on epoch=53
06/08/2022 15:39:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.64 on epoch=54
06/08/2022 15:39:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.55 on epoch=56
06/08/2022 15:39:39 - INFO - __main__ - Global step 450 Train loss 0.59 Classification-F1 0.6503527659463273 on epoch=56
06/08/2022 15:39:39 - INFO - __main__ - Saving model with best Classification-F1: 0.46522383139236234 -> 0.6503527659463273 on epoch=56, global_step=450
06/08/2022 15:39:42 - INFO - __main__ - Step 460 Global step 460 Train loss 0.53 on epoch=57
06/08/2022 15:39:45 - INFO - __main__ - Step 470 Global step 470 Train loss 0.49 on epoch=58
06/08/2022 15:39:47 - INFO - __main__ - Step 480 Global step 480 Train loss 0.59 on epoch=59
06/08/2022 15:39:50 - INFO - __main__ - Step 490 Global step 490 Train loss 0.59 on epoch=61
06/08/2022 15:39:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.54 on epoch=62
06/08/2022 15:39:55 - INFO - __main__ - Global step 500 Train loss 0.55 Classification-F1 0.6355247788627587 on epoch=62
06/08/2022 15:39:57 - INFO - __main__ - Step 510 Global step 510 Train loss 0.51 on epoch=63
06/08/2022 15:40:00 - INFO - __main__ - Step 520 Global step 520 Train loss 0.53 on epoch=64
06/08/2022 15:40:02 - INFO - __main__ - Step 530 Global step 530 Train loss 0.52 on epoch=66
06/08/2022 15:40:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.55 on epoch=67
06/08/2022 15:40:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.55 on epoch=68
06/08/2022 15:40:09 - INFO - __main__ - Global step 550 Train loss 0.53 Classification-F1 0.5420564646046212 on epoch=68
06/08/2022 15:40:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.50 on epoch=69
06/08/2022 15:40:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.52 on epoch=71
06/08/2022 15:40:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.47 on epoch=72
06/08/2022 15:40:20 - INFO - __main__ - Step 590 Global step 590 Train loss 0.53 on epoch=73
06/08/2022 15:40:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.48 on epoch=74
06/08/2022 15:40:24 - INFO - __main__ - Global step 600 Train loss 0.50 Classification-F1 0.6993958404265338 on epoch=74
06/08/2022 15:40:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6503527659463273 -> 0.6993958404265338 on epoch=74, global_step=600
06/08/2022 15:40:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.45 on epoch=76
06/08/2022 15:40:29 - INFO - __main__ - Step 620 Global step 620 Train loss 0.56 on epoch=77
06/08/2022 15:40:32 - INFO - __main__ - Step 630 Global step 630 Train loss 0.45 on epoch=78
06/08/2022 15:40:34 - INFO - __main__ - Step 640 Global step 640 Train loss 0.51 on epoch=79
06/08/2022 15:40:37 - INFO - __main__ - Step 650 Global step 650 Train loss 0.43 on epoch=81
06/08/2022 15:40:39 - INFO - __main__ - Global step 650 Train loss 0.48 Classification-F1 0.6913328174828585 on epoch=81
06/08/2022 15:40:41 - INFO - __main__ - Step 660 Global step 660 Train loss 0.44 on epoch=82
06/08/2022 15:40:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.49 on epoch=83
06/08/2022 15:40:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.44 on epoch=84
06/08/2022 15:40:49 - INFO - __main__ - Step 690 Global step 690 Train loss 0.47 on epoch=86
06/08/2022 15:40:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.39 on epoch=87
06/08/2022 15:40:54 - INFO - __main__ - Global step 700 Train loss 0.44 Classification-F1 0.67953716514056 on epoch=87
06/08/2022 15:40:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.43 on epoch=88
06/08/2022 15:40:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.48 on epoch=89
06/08/2022 15:41:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.37 on epoch=91
06/08/2022 15:41:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.36 on epoch=92
06/08/2022 15:41:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.41 on epoch=93
06/08/2022 15:41:09 - INFO - __main__ - Global step 750 Train loss 0.41 Classification-F1 0.5942379516938184 on epoch=93
06/08/2022 15:41:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.46 on epoch=94
06/08/2022 15:41:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.37 on epoch=96
06/08/2022 15:41:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.37 on epoch=97
06/08/2022 15:41:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.41 on epoch=98
06/08/2022 15:41:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.42 on epoch=99
06/08/2022 15:41:23 - INFO - __main__ - Global step 800 Train loss 0.41 Classification-F1 0.711346821587859 on epoch=99
06/08/2022 15:41:23 - INFO - __main__ - Saving model with best Classification-F1: 0.6993958404265338 -> 0.711346821587859 on epoch=99, global_step=800
06/08/2022 15:41:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.38 on epoch=101
06/08/2022 15:41:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.44 on epoch=102
06/08/2022 15:41:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.37 on epoch=103
06/08/2022 15:41:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.34 on epoch=104
06/08/2022 15:41:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.44 on epoch=106
06/08/2022 15:41:38 - INFO - __main__ - Global step 850 Train loss 0.39 Classification-F1 0.5528863810062631 on epoch=106
06/08/2022 15:41:40 - INFO - __main__ - Step 860 Global step 860 Train loss 0.45 on epoch=107
06/08/2022 15:41:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.32 on epoch=108
06/08/2022 15:41:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.40 on epoch=109
06/08/2022 15:41:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.35 on epoch=111
06/08/2022 15:41:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.46 on epoch=112
06/08/2022 15:41:52 - INFO - __main__ - Global step 900 Train loss 0.40 Classification-F1 0.6045198823679837 on epoch=112
06/08/2022 15:41:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.41 on epoch=113
06/08/2022 15:41:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.38 on epoch=114
06/08/2022 15:42:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.39 on epoch=116
06/08/2022 15:42:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.39 on epoch=117
06/08/2022 15:42:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.32 on epoch=118
06/08/2022 15:42:07 - INFO - __main__ - Global step 950 Train loss 0.38 Classification-F1 0.6431202600216684 on epoch=118
06/08/2022 15:42:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.32 on epoch=119
06/08/2022 15:42:12 - INFO - __main__ - Step 970 Global step 970 Train loss 0.38 on epoch=121
06/08/2022 15:42:15 - INFO - __main__ - Step 980 Global step 980 Train loss 0.25 on epoch=122
06/08/2022 15:42:18 - INFO - __main__ - Step 990 Global step 990 Train loss 0.33 on epoch=123
06/08/2022 15:42:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.34 on epoch=124
06/08/2022 15:42:22 - INFO - __main__ - Global step 1000 Train loss 0.33 Classification-F1 0.617707399985881 on epoch=124
06/08/2022 15:42:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.33 on epoch=126
06/08/2022 15:42:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.39 on epoch=127
06/08/2022 15:42:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.31 on epoch=128
06/08/2022 15:42:32 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.29 on epoch=129
06/08/2022 15:42:35 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.27 on epoch=131
06/08/2022 15:42:37 - INFO - __main__ - Global step 1050 Train loss 0.32 Classification-F1 0.658749903037422 on epoch=131
06/08/2022 15:42:39 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.34 on epoch=132
06/08/2022 15:42:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.32 on epoch=133
06/08/2022 15:42:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.26 on epoch=134
06/08/2022 15:42:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=136
06/08/2022 15:42:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=137
06/08/2022 15:42:51 - INFO - __main__ - Global step 1100 Train loss 0.30 Classification-F1 0.5390031986767981 on epoch=137
06/08/2022 15:42:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.42 on epoch=138
06/08/2022 15:42:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.29 on epoch=139
06/08/2022 15:42:59 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.26 on epoch=141
06/08/2022 15:43:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.32 on epoch=142
06/08/2022 15:43:04 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.28 on epoch=143
06/08/2022 15:43:06 - INFO - __main__ - Global step 1150 Train loss 0.31 Classification-F1 0.6306583989510819 on epoch=143
06/08/2022 15:43:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.29 on epoch=144
06/08/2022 15:43:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.25 on epoch=146
06/08/2022 15:43:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.26 on epoch=147
06/08/2022 15:43:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.28 on epoch=148
06/08/2022 15:43:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.25 on epoch=149
06/08/2022 15:43:21 - INFO - __main__ - Global step 1200 Train loss 0.26 Classification-F1 0.7493995341782496 on epoch=149
06/08/2022 15:43:21 - INFO - __main__ - Saving model with best Classification-F1: 0.711346821587859 -> 0.7493995341782496 on epoch=149, global_step=1200
06/08/2022 15:43:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.27 on epoch=151
06/08/2022 15:43:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.30 on epoch=152
06/08/2022 15:43:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.21 on epoch=153
06/08/2022 15:43:31 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.23 on epoch=154
06/08/2022 15:43:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.24 on epoch=156
06/08/2022 15:43:36 - INFO - __main__ - Global step 1250 Train loss 0.25 Classification-F1 0.7128769841269841 on epoch=156
06/08/2022 15:43:38 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.20 on epoch=157
06/08/2022 15:43:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.21 on epoch=158
06/08/2022 15:43:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.22 on epoch=159
06/08/2022 15:43:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.31 on epoch=161
06/08/2022 15:43:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.30 on epoch=162
06/08/2022 15:43:50 - INFO - __main__ - Global step 1300 Train loss 0.25 Classification-F1 0.6742883753735576 on epoch=162
06/08/2022 15:43:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.21 on epoch=163
06/08/2022 15:43:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.17 on epoch=164
06/08/2022 15:43:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.27 on epoch=166
06/08/2022 15:44:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.22 on epoch=167
06/08/2022 15:44:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.30 on epoch=168
06/08/2022 15:44:05 - INFO - __main__ - Global step 1350 Train loss 0.24 Classification-F1 0.7082963709677419 on epoch=168
06/08/2022 15:44:08 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.24 on epoch=169
06/08/2022 15:44:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.22 on epoch=171
06/08/2022 15:44:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.27 on epoch=172
06/08/2022 15:44:16 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.22 on epoch=173
06/08/2022 15:44:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.27 on epoch=174
06/08/2022 15:44:20 - INFO - __main__ - Global step 1400 Train loss 0.24 Classification-F1 0.6575056252009 on epoch=174
06/08/2022 15:44:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.24 on epoch=176
06/08/2022 15:44:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.19 on epoch=177
06/08/2022 15:44:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.25 on epoch=178
06/08/2022 15:44:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.28 on epoch=179
06/08/2022 15:44:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.28 on epoch=181
06/08/2022 15:44:35 - INFO - __main__ - Global step 1450 Train loss 0.25 Classification-F1 0.6517110308542893 on epoch=181
06/08/2022 15:44:38 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.27 on epoch=182
06/08/2022 15:44:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.27 on epoch=183
06/08/2022 15:44:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=184
06/08/2022 15:44:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.18 on epoch=186
06/08/2022 15:44:48 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.25 on epoch=187
06/08/2022 15:44:50 - INFO - __main__ - Global step 1500 Train loss 0.23 Classification-F1 0.6761571761571762 on epoch=187
06/08/2022 15:44:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=188
06/08/2022 15:44:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.19 on epoch=189
06/08/2022 15:44:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.22 on epoch=191
06/08/2022 15:45:00 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.25 on epoch=192
06/08/2022 15:45:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.29 on epoch=193
06/08/2022 15:45:04 - INFO - __main__ - Global step 1550 Train loss 0.23 Classification-F1 0.7359284716348776 on epoch=193
06/08/2022 15:45:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.23 on epoch=194
06/08/2022 15:45:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.21 on epoch=196
06/08/2022 15:45:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.17 on epoch=197
06/08/2022 15:45:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.20 on epoch=198
06/08/2022 15:45:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.16 on epoch=199
06/08/2022 15:45:19 - INFO - __main__ - Global step 1600 Train loss 0.19 Classification-F1 0.7363501116929725 on epoch=199
06/08/2022 15:45:22 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.19 on epoch=201
06/08/2022 15:45:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.16 on epoch=202
06/08/2022 15:45:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.18 on epoch=203
06/08/2022 15:45:30 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.26 on epoch=204
06/08/2022 15:45:32 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.15 on epoch=206
06/08/2022 15:45:34 - INFO - __main__ - Global step 1650 Train loss 0.19 Classification-F1 0.7540935998070107 on epoch=206
06/08/2022 15:45:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7493995341782496 -> 0.7540935998070107 on epoch=206, global_step=1650
06/08/2022 15:45:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.25 on epoch=207
06/08/2022 15:45:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.28 on epoch=208
06/08/2022 15:45:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=209
06/08/2022 15:45:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.21 on epoch=211
06/08/2022 15:45:47 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.24 on epoch=212
06/08/2022 15:45:49 - INFO - __main__ - Global step 1700 Train loss 0.22 Classification-F1 0.696371085747732 on epoch=212
06/08/2022 15:45:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=213
06/08/2022 15:45:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.20 on epoch=214
06/08/2022 15:45:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.17 on epoch=216
06/08/2022 15:45:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.19 on epoch=217
06/08/2022 15:46:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.18 on epoch=218
06/08/2022 15:46:04 - INFO - __main__ - Global step 1750 Train loss 0.18 Classification-F1 0.7449316615486955 on epoch=218
06/08/2022 15:46:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.17 on epoch=219
06/08/2022 15:46:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.23 on epoch=221
06/08/2022 15:46:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.18 on epoch=222
06/08/2022 15:46:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.14 on epoch=223
06/08/2022 15:46:17 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.14 on epoch=224
06/08/2022 15:46:19 - INFO - __main__ - Global step 1800 Train loss 0.17 Classification-F1 0.7711864376221487 on epoch=224
06/08/2022 15:46:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7540935998070107 -> 0.7711864376221487 on epoch=224, global_step=1800
06/08/2022 15:46:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=226
06/08/2022 15:46:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.17 on epoch=227
06/08/2022 15:46:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.22 on epoch=228
06/08/2022 15:46:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=229
06/08/2022 15:46:31 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.14 on epoch=231
06/08/2022 15:46:33 - INFO - __main__ - Global step 1850 Train loss 0.15 Classification-F1 0.7203475218260987 on epoch=231
06/08/2022 15:46:36 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.15 on epoch=232
06/08/2022 15:46:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=233
06/08/2022 15:46:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=234
06/08/2022 15:46:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.14 on epoch=236
06/08/2022 15:46:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.18 on epoch=237
06/08/2022 15:46:48 - INFO - __main__ - Global step 1900 Train loss 0.13 Classification-F1 0.7054699638261281 on epoch=237
06/08/2022 15:46:51 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.14 on epoch=238
06/08/2022 15:46:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.21 on epoch=239
06/08/2022 15:46:56 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.12 on epoch=241
06/08/2022 15:46:58 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.18 on epoch=242
06/08/2022 15:47:01 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.11 on epoch=243
06/08/2022 15:47:03 - INFO - __main__ - Global step 1950 Train loss 0.15 Classification-F1 0.6991192058356238 on epoch=243
06/08/2022 15:47:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.10 on epoch=244
06/08/2022 15:47:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.13 on epoch=246
06/08/2022 15:47:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.15 on epoch=247
06/08/2022 15:47:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.18 on epoch=248
06/08/2022 15:47:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=249
06/08/2022 15:47:17 - INFO - __main__ - Global step 2000 Train loss 0.13 Classification-F1 0.71365436669055 on epoch=249
06/08/2022 15:47:20 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=251
06/08/2022 15:47:22 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=252
06/08/2022 15:47:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.09 on epoch=253
06/08/2022 15:47:28 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.19 on epoch=254
06/08/2022 15:47:30 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.16 on epoch=256
06/08/2022 15:47:32 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.7161962365591399 on epoch=256
06/08/2022 15:47:34 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=257
06/08/2022 15:47:37 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.25 on epoch=258
06/08/2022 15:47:40 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=259
06/08/2022 15:47:42 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.18 on epoch=261
06/08/2022 15:47:45 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.11 on epoch=262
06/08/2022 15:47:46 - INFO - __main__ - Global step 2100 Train loss 0.13 Classification-F1 0.7746035033731802 on epoch=262
06/08/2022 15:47:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7711864376221487 -> 0.7746035033731802 on epoch=262, global_step=2100
06/08/2022 15:47:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.14 on epoch=263
06/08/2022 15:47:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.12 on epoch=264
06/08/2022 15:47:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=266
06/08/2022 15:47:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=267
06/08/2022 15:47:59 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=268
06/08/2022 15:48:01 - INFO - __main__ - Global step 2150 Train loss 0.09 Classification-F1 0.7823545806282379 on epoch=268
06/08/2022 15:48:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7746035033731802 -> 0.7823545806282379 on epoch=268, global_step=2150
06/08/2022 15:48:04 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=269
06/08/2022 15:48:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=271
06/08/2022 15:48:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.15 on epoch=272
06/08/2022 15:48:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.17 on epoch=273
06/08/2022 15:48:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=274
06/08/2022 15:48:15 - INFO - __main__ - Global step 2200 Train loss 0.10 Classification-F1 0.7910217580926537 on epoch=274
06/08/2022 15:48:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7823545806282379 -> 0.7910217580926537 on epoch=274, global_step=2200
06/08/2022 15:48:18 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=276
06/08/2022 15:48:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=277
06/08/2022 15:48:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=278
06/08/2022 15:48:26 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.11 on epoch=279
06/08/2022 15:48:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=281
06/08/2022 15:48:30 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.6955654514976548 on epoch=281
06/08/2022 15:48:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.13 on epoch=282
06/08/2022 15:48:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.14 on epoch=283
06/08/2022 15:48:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=284
06/08/2022 15:48:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=286
06/08/2022 15:48:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.08 on epoch=287
06/08/2022 15:48:45 - INFO - __main__ - Global step 2300 Train loss 0.09 Classification-F1 0.7612504968203498 on epoch=287
06/08/2022 15:48:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=288
06/08/2022 15:48:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=289
06/08/2022 15:48:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=291
06/08/2022 15:48:55 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=292
06/08/2022 15:48:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=293
06/08/2022 15:49:00 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7442853428637658 on epoch=293
06/08/2022 15:49:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=294
06/08/2022 15:49:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.12 on epoch=296
06/08/2022 15:49:08 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=297
06/08/2022 15:49:10 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=298
06/08/2022 15:49:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=299
06/08/2022 15:49:15 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.7471687370600414 on epoch=299
06/08/2022 15:49:18 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.08 on epoch=301
06/08/2022 15:49:20 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=302
06/08/2022 15:49:23 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=303
06/08/2022 15:49:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.10 on epoch=304
06/08/2022 15:49:28 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=306
06/08/2022 15:49:30 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.7882815320327373 on epoch=306
06/08/2022 15:49:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=307
06/08/2022 15:49:35 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=308
06/08/2022 15:49:38 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=309
06/08/2022 15:49:40 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=311
06/08/2022 15:49:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=312
06/08/2022 15:49:45 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7082465846454622 on epoch=312
06/08/2022 15:49:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=313
06/08/2022 15:49:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=314
06/08/2022 15:49:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=316
06/08/2022 15:49:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.15 on epoch=317
06/08/2022 15:49:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=318
06/08/2022 15:49:59 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.7295874948565444 on epoch=318
06/08/2022 15:50:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=319
06/08/2022 15:50:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=321
06/08/2022 15:50:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=322
06/08/2022 15:50:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=323
06/08/2022 15:50:13 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=324
06/08/2022 15:50:14 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.7731505047208891 on epoch=324
06/08/2022 15:50:17 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=326
06/08/2022 15:50:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=327
06/08/2022 15:50:22 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=328
06/08/2022 15:50:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.10 on epoch=329
06/08/2022 15:50:27 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.10 on epoch=331
06/08/2022 15:50:29 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7867050789586001 on epoch=331
06/08/2022 15:50:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=332
06/08/2022 15:50:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.10 on epoch=333
06/08/2022 15:50:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=334
06/08/2022 15:50:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=336
06/08/2022 15:50:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=337
06/08/2022 15:50:44 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.798413027182704 on epoch=337
06/08/2022 15:50:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7910217580926537 -> 0.798413027182704 on epoch=337, global_step=2700
06/08/2022 15:50:47 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=338
06/08/2022 15:50:49 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=339
06/08/2022 15:50:52 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
06/08/2022 15:50:55 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.14 on epoch=342
06/08/2022 15:50:57 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
06/08/2022 15:50:59 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.735902889655203 on epoch=343
06/08/2022 15:51:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.17 on epoch=344
06/08/2022 15:51:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=346
06/08/2022 15:51:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=347
06/08/2022 15:51:09 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=348
06/08/2022 15:51:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=349
06/08/2022 15:51:14 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.7625416089432772 on epoch=349
06/08/2022 15:51:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.10 on epoch=351
06/08/2022 15:51:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.10 on epoch=352
06/08/2022 15:51:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=353
06/08/2022 15:51:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/08/2022 15:51:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=356
06/08/2022 15:51:29 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.753691092709624 on epoch=356
06/08/2022 15:51:31 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=357
06/08/2022 15:51:34 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=358
06/08/2022 15:51:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=359
06/08/2022 15:51:39 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
06/08/2022 15:51:42 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=362
06/08/2022 15:51:44 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.756681240063593 on epoch=362
06/08/2022 15:51:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=363
06/08/2022 15:51:49 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.17 on epoch=364
06/08/2022 15:51:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=366
06/08/2022 15:51:54 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.08 on epoch=367
06/08/2022 15:51:57 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=368
06/08/2022 15:51:58 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.7314723994087536 on epoch=368
06/08/2022 15:52:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=369
06/08/2022 15:52:04 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.21 on epoch=371
06/08/2022 15:52:06 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=372
06/08/2022 15:52:09 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=373
06/08/2022 15:52:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
06/08/2022 15:52:14 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.7736061752455194 on epoch=374
06/08/2022 15:52:14 - INFO - __main__ - save last model!
06/08/2022 15:52:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 15:52:14 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 15:52:14 - INFO - __main__ - Printing 3 examples
06/08/2022 15:52:14 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 15:52:14 - INFO - __main__ - ['others']
06/08/2022 15:52:14 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 15:52:14 - INFO - __main__ - ['others']
06/08/2022 15:52:14 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 15:52:14 - INFO - __main__ - ['others']
06/08/2022 15:52:14 - INFO - __main__ - Tokenizing Input ...
06/08/2022 15:52:16 - INFO - __main__ - Tokenizing Output ...
06/08/2022 15:52:21 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 15:53:34 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-emo/emo_32_87_0.2_8_predictions.txt
06/08/2022 15:53:34 - INFO - __main__ - Classification-F1 on test data: 0.2316
06/08/2022 15:53:35 - INFO - __main__ - prefix=emo_32_87, lr=0.2, bsz=8, dev_performance=0.798413027182704, test_performance=0.23160390837987327
