05/21/2022 21:20:10 - INFO - __main__ - Namespace(task_dir='data_32/tab_fact/', task_name='tab_fact', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 21:20:10 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact
05/21/2022 21:20:10 - INFO - __main__ - Namespace(task_dir='data_32/tab_fact/', task_name='tab_fact', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 21:20:10 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact
05/21/2022 21:20:12 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:20:12 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:20:12 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:20:12 - INFO - __main__ - Using 2 gpus
05/21/2022 21:20:12 - INFO - __main__ - Fine-tuning the following samples: ['tab_fact_32_100', 'tab_fact_32_13', 'tab_fact_32_21', 'tab_fact_32_42', 'tab_fact_32_87']
05/21/2022 21:20:12 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:20:12 - INFO - __main__ - Using 2 gpus
05/21/2022 21:20:12 - INFO - __main__ - Fine-tuning the following samples: ['tab_fact_32_100', 'tab_fact_32_13', 'tab_fact_32_21', 'tab_fact_32_42', 'tab_fact_32_87']
05/21/2022 21:20:17 - INFO - __main__ - Running ... prefix=tab_fact_32_100, lr=0.5, bsz=8 ...
06/11/2022 21:18:42 - INFO - __main__ - Namespace(task_dir='data_32/tab_fact/', task_name='tab_fact', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/11/2022 21:18:42 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact
06/11/2022 21:18:42 - INFO - __main__ - Namespace(task_dir='data_32/tab_fact/', task_name='tab_fact', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/11/2022 21:18:42 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact
06/11/2022 21:18:44 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/11/2022 21:18:44 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/11/2022 21:18:44 - INFO - __main__ - args.device: cuda:0
06/11/2022 21:18:44 - INFO - __main__ - args.device: cuda:1
06/11/2022 21:18:44 - INFO - __main__ - Using 2 gpus
06/11/2022 21:18:44 - INFO - __main__ - Using 2 gpus
06/11/2022 21:18:44 - INFO - __main__ - Fine-tuning the following samples: ['tab_fact_32_100', 'tab_fact_32_13', 'tab_fact_32_21', 'tab_fact_32_42', 'tab_fact_32_87']
06/11/2022 21:18:44 - INFO - __main__ - Fine-tuning the following samples: ['tab_fact_32_100', 'tab_fact_32_13', 'tab_fact_32_21', 'tab_fact_32_42', 'tab_fact_32_87']
06/11/2022 21:18:49 - INFO - __main__ - Running ... prefix=tab_fact_32_100, lr=0.5, bsz=8 ...
06/11/2022 21:18:49 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 21:18:49 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 21:18:49 - INFO - __main__ - Printing 3 examples
06/11/2022 21:18:49 - INFO - __main__ - Printing 3 examples
06/11/2022 21:18:49 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/11/2022 21:18:49 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/11/2022 21:18:49 - INFO - __main__ - ['refuted']
06/11/2022 21:18:50 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/11/2022 21:18:50 - INFO - __main__ - ['refuted']
06/11/2022 21:18:50 - INFO - __main__ - ['refuted']
06/11/2022 21:18:50 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/11/2022 21:18:50 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/11/2022 21:18:50 - INFO - __main__ - ['refuted']
06/11/2022 21:18:50 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/11/2022 21:18:50 - INFO - __main__ - ['refuted']
06/11/2022 21:18:50 - INFO - __main__ - ['refuted']
06/11/2022 21:18:50 - INFO - __main__ - Tokenizing Input ...
06/11/2022 21:18:50 - INFO - __main__ - Tokenizing Input ...
06/11/2022 21:18:50 - INFO - __main__ - Tokenizing Output ...
06/11/2022 21:18:50 - INFO - __main__ - Tokenizing Output ...
06/11/2022 21:18:50 - INFO - __main__ - Loaded 64 examples from train data
06/11/2022 21:18:50 - INFO - __main__ - Loaded 64 examples from train data
06/11/2022 21:18:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 21:18:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 21:18:50 - INFO - __main__ - Printing 3 examples
06/11/2022 21:18:50 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/11/2022 21:18:50 - INFO - __main__ - Printing 3 examples
06/11/2022 21:18:50 - INFO - __main__ - ['refuted']
06/11/2022 21:18:50 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/11/2022 21:18:50 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/11/2022 21:18:50 - INFO - __main__ - ['refuted']
06/11/2022 21:18:50 - INFO - __main__ - ['refuted']
06/11/2022 21:18:50 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/11/2022 21:18:50 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/11/2022 21:18:50 - INFO - __main__ - ['refuted']
06/11/2022 21:18:50 - INFO - __main__ - ['refuted']
06/11/2022 21:18:50 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/11/2022 21:18:50 - INFO - __main__ - Tokenizing Input ...
06/11/2022 21:18:50 - INFO - __main__ - ['refuted']
06/11/2022 21:18:50 - INFO - __main__ - Tokenizing Input ...
06/11/2022 21:18:50 - INFO - __main__ - Tokenizing Output ...
06/11/2022 21:18:50 - INFO - __main__ - Tokenizing Output ...
06/11/2022 21:18:50 - INFO - __main__ - Loaded 64 examples from dev data
06/11/2022 21:18:50 - INFO - __main__ - Loaded 64 examples from dev data
06/11/2022 21:19:08 - INFO - __main__ - load prompt embedding from ckpt
06/11/2022 21:19:08 - INFO - __main__ - load prompt embedding from ckpt
06/11/2022 21:19:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/11/2022 21:19:09 - INFO - __main__ - Starting training!
06/11/2022 21:19:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/11/2022 21:19:14 - INFO - __main__ - Starting training!
06/11/2022 21:19:19 - INFO - __main__ - Step 10 Global step 10 Train loss 2.42 on epoch=2
06/11/2022 21:19:24 - INFO - __main__ - Step 20 Global step 20 Train loss 0.39 on epoch=4
06/11/2022 21:19:28 - INFO - __main__ - Step 30 Global step 30 Train loss 0.34 on epoch=7
06/11/2022 21:19:33 - INFO - __main__ - Step 40 Global step 40 Train loss 0.31 on epoch=9
06/11/2022 21:19:37 - INFO - __main__ - Step 50 Global step 50 Train loss 0.30 on epoch=12
06/11/2022 21:19:40 - INFO - __main__ - Global step 50 Train loss 0.75 Classification-F1 0.3333333333333333 on epoch=12
06/11/2022 21:19:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/11/2022 21:19:45 - INFO - __main__ - Step 60 Global step 60 Train loss 0.28 on epoch=14
06/11/2022 21:19:49 - INFO - __main__ - Step 70 Global step 70 Train loss 0.28 on epoch=17
06/11/2022 21:19:54 - INFO - __main__ - Step 80 Global step 80 Train loss 0.30 on epoch=19
06/11/2022 21:19:58 - INFO - __main__ - Step 90 Global step 90 Train loss 0.30 on epoch=22
06/11/2022 21:20:03 - INFO - __main__ - Step 100 Global step 100 Train loss 0.26 on epoch=24
06/11/2022 21:20:05 - INFO - __main__ - Global step 100 Train loss 0.28 Classification-F1 0.3333333333333333 on epoch=24
06/11/2022 21:20:10 - INFO - __main__ - Step 110 Global step 110 Train loss 0.24 on epoch=27
06/11/2022 21:20:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.25 on epoch=29
06/11/2022 21:20:19 - INFO - __main__ - Step 130 Global step 130 Train loss 0.24 on epoch=32
06/11/2022 21:20:23 - INFO - __main__ - Step 140 Global step 140 Train loss 0.26 on epoch=34
06/11/2022 21:20:28 - INFO - __main__ - Step 150 Global step 150 Train loss 0.27 on epoch=37
06/11/2022 21:20:30 - INFO - __main__ - Global step 150 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=37
06/11/2022 21:20:35 - INFO - __main__ - Step 160 Global step 160 Train loss 0.22 on epoch=39
06/11/2022 21:20:39 - INFO - __main__ - Step 170 Global step 170 Train loss 0.22 on epoch=42
06/11/2022 21:20:44 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=44
06/11/2022 21:20:48 - INFO - __main__ - Step 190 Global step 190 Train loss 0.22 on epoch=47
06/11/2022 21:20:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.22 on epoch=49
06/11/2022 21:20:55 - INFO - __main__ - Global step 200 Train loss 0.23 Classification-F1 0.19696969696969693 on epoch=49
06/11/2022 21:21:00 - INFO - __main__ - Step 210 Global step 210 Train loss 0.20 on epoch=52
06/11/2022 21:21:04 - INFO - __main__ - Step 220 Global step 220 Train loss 0.22 on epoch=54
06/11/2022 21:21:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.23 on epoch=57
06/11/2022 21:21:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.23 on epoch=59
06/11/2022 21:21:18 - INFO - __main__ - Step 250 Global step 250 Train loss 0.23 on epoch=62
06/11/2022 21:21:21 - INFO - __main__ - Global step 250 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=62
06/11/2022 21:21:25 - INFO - __main__ - Step 260 Global step 260 Train loss 0.24 on epoch=64
06/11/2022 21:21:29 - INFO - __main__ - Step 270 Global step 270 Train loss 0.23 on epoch=67
06/11/2022 21:21:34 - INFO - __main__ - Step 280 Global step 280 Train loss 0.24 on epoch=69
06/11/2022 21:21:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=72
06/11/2022 21:21:43 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=74
06/11/2022 21:21:46 - INFO - __main__ - Global step 300 Train loss 0.23 Classification-F1 0.4487674487674488 on epoch=74
06/11/2022 21:21:46 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.4487674487674488 on epoch=74, global_step=300
06/11/2022 21:21:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=77
06/11/2022 21:21:55 - INFO - __main__ - Step 320 Global step 320 Train loss 0.23 on epoch=79
06/11/2022 21:21:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/11/2022 21:22:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=84
06/11/2022 21:22:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=87
06/11/2022 21:22:11 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.1627906976744186 on epoch=87
06/11/2022 21:22:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=89
06/11/2022 21:22:20 - INFO - __main__ - Step 370 Global step 370 Train loss 0.20 on epoch=92
06/11/2022 21:22:24 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=94
06/11/2022 21:22:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.20 on epoch=97
06/11/2022 21:22:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=99
06/11/2022 21:22:36 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.14935064935064934 on epoch=99
06/11/2022 21:22:40 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=102
06/11/2022 21:22:45 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=104
06/11/2022 21:22:49 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=107
06/11/2022 21:22:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=109
06/11/2022 21:22:58 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/11/2022 21:23:01 - INFO - __main__ - Global step 450 Train loss 0.20 Classification-F1 0.22695035460992907 on epoch=112
06/11/2022 21:23:05 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=114
06/11/2022 21:23:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=117
06/11/2022 21:23:14 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=119
06/11/2022 21:23:19 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=122
06/11/2022 21:23:24 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=124
06/11/2022 21:23:26 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.3671451355661882 on epoch=124
06/11/2022 21:23:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=127
06/11/2022 21:23:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=129
06/11/2022 21:23:40 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=132
06/11/2022 21:23:44 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=134
06/11/2022 21:23:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
06/11/2022 21:23:51 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=137
06/11/2022 21:23:56 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/11/2022 21:24:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=142
06/11/2022 21:24:05 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/11/2022 21:24:09 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
06/11/2022 21:24:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=149
06/11/2022 21:24:17 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.3591989987484355 on epoch=149
06/11/2022 21:24:21 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
06/11/2022 21:24:26 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=154
06/11/2022 21:24:30 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=157
06/11/2022 21:24:35 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/11/2022 21:24:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=162
06/11/2022 21:24:42 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.3992490613266583 on epoch=162
06/11/2022 21:24:46 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=164
06/11/2022 21:24:51 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=167
06/11/2022 21:24:56 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=169
06/11/2022 21:25:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=172
06/11/2022 21:25:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=174
06/11/2022 21:25:07 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.4947797300738477 on epoch=174
06/11/2022 21:25:07 - INFO - __main__ - Saving model with best Classification-F1: 0.4487674487674488 -> 0.4947797300738477 on epoch=174, global_step=700
06/11/2022 21:25:12 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=177
06/11/2022 21:25:17 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=179
06/11/2022 21:25:21 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=182
06/11/2022 21:25:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=184
06/11/2022 21:25:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=187
06/11/2022 21:25:33 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.5330817610062892 on epoch=187
06/11/2022 21:25:33 - INFO - __main__ - Saving model with best Classification-F1: 0.4947797300738477 -> 0.5330817610062892 on epoch=187, global_step=750
06/11/2022 21:25:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=189
06/11/2022 21:25:43 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=192
06/11/2022 21:25:47 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=194
06/11/2022 21:25:52 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=197
06/11/2022 21:25:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=199
06/11/2022 21:26:00 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.5607843137254902 on epoch=199
06/11/2022 21:26:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5330817610062892 -> 0.5607843137254902 on epoch=199, global_step=800
06/11/2022 21:26:05 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=202
06/11/2022 21:26:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=204
06/11/2022 21:26:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=207
06/11/2022 21:26:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=209
06/11/2022 21:26:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=212
06/11/2022 21:26:26 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.5465587044534412 on epoch=212
06/11/2022 21:26:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=214
06/11/2022 21:26:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=217
06/11/2022 21:26:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=219
06/11/2022 21:26:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=222
06/11/2022 21:26:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=224
06/11/2022 21:26:51 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.4458874458874459 on epoch=224
06/11/2022 21:26:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=227
06/11/2022 21:27:00 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=229
06/11/2022 21:27:05 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=232
06/11/2022 21:27:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=234
06/11/2022 21:27:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=237
06/11/2022 21:27:17 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.51417004048583 on epoch=237
06/11/2022 21:27:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=239
06/11/2022 21:27:26 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=242
06/11/2022 21:27:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=244
06/11/2022 21:27:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=247
06/11/2022 21:27:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=249
06/11/2022 21:27:42 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.3134751773049645 on epoch=249
06/11/2022 21:27:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=252
06/11/2022 21:27:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=254
06/11/2022 21:27:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/11/2022 21:28:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=259
06/11/2022 21:28:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/11/2022 21:28:08 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.366832504145937 on epoch=262
06/11/2022 21:28:12 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=264
06/11/2022 21:28:17 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=267
06/11/2022 21:28:21 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=269
06/11/2022 21:28:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=272
06/11/2022 21:28:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=274
06/11/2022 21:28:33 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.3569775132275132 on epoch=274
06/11/2022 21:28:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=277
06/11/2022 21:28:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=279
06/11/2022 21:28:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=282
06/11/2022 21:28:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=284
06/11/2022 21:28:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/11/2022 21:28:59 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.5038759689922481 on epoch=287
06/11/2022 21:29:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=289
06/11/2022 21:29:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/11/2022 21:29:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=294
06/11/2022 21:29:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=297
06/11/2022 21:29:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=299
06/11/2022 21:29:24 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.5413886829750433 on epoch=299
06/11/2022 21:29:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/11/2022 21:29:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
06/11/2022 21:29:37 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=307
06/11/2022 21:29:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=309
06/11/2022 21:29:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=312
06/11/2022 21:29:49 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.5555555555555556 on epoch=312
06/11/2022 21:29:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/11/2022 21:29:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/11/2022 21:30:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/11/2022 21:30:07 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=322
06/11/2022 21:30:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=324
06/11/2022 21:30:15 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.46880856760374834 on epoch=324
06/11/2022 21:30:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=327
06/11/2022 21:30:24 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/11/2022 21:30:28 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=332
06/11/2022 21:30:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=334
06/11/2022 21:30:37 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/11/2022 21:30:40 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.4666666666666667 on epoch=337
06/11/2022 21:30:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
06/11/2022 21:30:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=342
06/11/2022 21:30:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/11/2022 21:30:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=347
06/11/2022 21:31:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
06/11/2022 21:31:06 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.3671794871794871 on epoch=349
06/11/2022 21:31:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/11/2022 21:31:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/11/2022 21:31:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/11/2022 21:31:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/11/2022 21:31:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=362
06/11/2022 21:31:31 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.5058530510585305 on epoch=362
06/11/2022 21:31:36 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=364
06/11/2022 21:31:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/11/2022 21:31:45 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/11/2022 21:31:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/11/2022 21:31:54 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/11/2022 21:31:57 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.335970464135021 on epoch=374
06/11/2022 21:32:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=377
06/11/2022 21:32:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/11/2022 21:32:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/11/2022 21:32:15 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/11/2022 21:32:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/11/2022 21:32:22 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.5755342667649226 on epoch=387
06/11/2022 21:32:22 - INFO - __main__ - Saving model with best Classification-F1: 0.5607843137254902 -> 0.5755342667649226 on epoch=387, global_step=1550
06/11/2022 21:32:26 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/11/2022 21:32:31 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/11/2022 21:32:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/11/2022 21:32:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
06/11/2022 21:32:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/11/2022 21:32:47 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.5933528836754642 on epoch=399
06/11/2022 21:32:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5755342667649226 -> 0.5933528836754642 on epoch=399, global_step=1600
06/11/2022 21:32:52 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/11/2022 21:32:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
06/11/2022 21:33:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/11/2022 21:33:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/11/2022 21:33:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/11/2022 21:33:13 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.5730170496664195 on epoch=412
06/11/2022 21:33:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=414
06/11/2022 21:33:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/11/2022 21:33:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/11/2022 21:33:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/11/2022 21:33:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=424
06/11/2022 21:33:38 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.5238095238095238 on epoch=424
06/11/2022 21:33:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/11/2022 21:33:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/11/2022 21:33:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/11/2022 21:33:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/11/2022 21:34:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/11/2022 21:34:03 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.5921568627450979 on epoch=437
06/11/2022 21:34:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/11/2022 21:34:12 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/11/2022 21:34:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/11/2022 21:34:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/11/2022 21:34:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/11/2022 21:34:28 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.5413886829750433 on epoch=449
06/11/2022 21:34:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/11/2022 21:34:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/11/2022 21:34:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/11/2022 21:34:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/11/2022 21:34:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/11/2022 21:34:54 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.5145583557621727 on epoch=462
06/11/2022 21:34:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/11/2022 21:35:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/11/2022 21:35:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/11/2022 21:35:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/11/2022 21:35:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/11/2022 21:35:19 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.5155067155067155 on epoch=474
06/11/2022 21:35:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/11/2022 21:35:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/11/2022 21:35:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/11/2022 21:35:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/11/2022 21:35:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=487
06/11/2022 21:35:44 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.5294117647058825 on epoch=487
06/11/2022 21:35:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/11/2022 21:35:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/11/2022 21:35:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/11/2022 21:36:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/11/2022 21:36:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/11/2022 21:36:10 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.5696139476961395 on epoch=499
06/11/2022 21:36:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/11/2022 21:36:19 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=504
06/11/2022 21:36:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/11/2022 21:36:28 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/11/2022 21:36:32 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/11/2022 21:36:35 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.5145583557621727 on epoch=512
06/11/2022 21:36:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/11/2022 21:36:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/11/2022 21:36:49 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/11/2022 21:36:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/11/2022 21:36:58 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/11/2022 21:37:01 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.5270935960591133 on epoch=524
06/11/2022 21:37:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/11/2022 21:37:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/11/2022 21:37:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/11/2022 21:37:19 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/11/2022 21:37:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/11/2022 21:37:26 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.335978835978836 on epoch=537
06/11/2022 21:37:31 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/11/2022 21:37:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/11/2022 21:37:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/11/2022 21:37:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/11/2022 21:37:49 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/11/2022 21:37:52 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.48424908424908425 on epoch=549
06/11/2022 21:37:56 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/11/2022 21:38:01 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/11/2022 21:38:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/11/2022 21:38:10 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/11/2022 21:38:14 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/11/2022 21:38:17 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.335978835978836 on epoch=562
06/11/2022 21:38:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/11/2022 21:38:26 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=567
06/11/2022 21:38:30 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/11/2022 21:38:35 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/11/2022 21:38:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/11/2022 21:38:42 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.36678257989733404 on epoch=574
06/11/2022 21:38:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/11/2022 21:38:51 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/11/2022 21:38:55 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/11/2022 21:39:00 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/11/2022 21:39:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/11/2022 21:39:07 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.21076923076923074 on epoch=587
06/11/2022 21:39:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/11/2022 21:39:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/11/2022 21:39:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/11/2022 21:39:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/11/2022 21:39:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/11/2022 21:39:33 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.5458771715194519 on epoch=599
06/11/2022 21:39:37 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/11/2022 21:39:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/11/2022 21:39:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/11/2022 21:39:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/11/2022 21:39:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/11/2022 21:39:58 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.53125 on epoch=612
06/11/2022 21:40:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/11/2022 21:40:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/11/2022 21:40:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/11/2022 21:40:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/11/2022 21:40:21 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/11/2022 21:40:24 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.5440923605993613 on epoch=624
06/11/2022 21:40:28 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/11/2022 21:40:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/11/2022 21:40:37 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/11/2022 21:40:42 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/11/2022 21:40:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/11/2022 21:40:49 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.5 on epoch=637
06/11/2022 21:40:54 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/11/2022 21:40:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/11/2022 21:41:03 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/11/2022 21:41:07 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/11/2022 21:41:12 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/11/2022 21:41:15 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.5458771715194519 on epoch=649
06/11/2022 21:41:19 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/11/2022 21:41:24 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/11/2022 21:41:28 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/11/2022 21:41:33 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/11/2022 21:41:37 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/11/2022 21:41:40 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.4832395400048935 on epoch=662
06/11/2022 21:41:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/11/2022 21:41:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/11/2022 21:41:54 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/11/2022 21:41:58 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/11/2022 21:42:03 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/11/2022 21:42:06 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.34575260804769004 on epoch=674
06/11/2022 21:42:10 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/11/2022 21:42:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/11/2022 21:42:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/11/2022 21:42:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=684
06/11/2022 21:42:28 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/11/2022 21:42:31 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.5270935960591133 on epoch=687
06/11/2022 21:42:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/11/2022 21:42:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/11/2022 21:42:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/11/2022 21:42:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/11/2022 21:42:54 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/11/2022 21:42:57 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.36678257989733404 on epoch=699
06/11/2022 21:43:01 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/11/2022 21:43:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/11/2022 21:43:10 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/11/2022 21:43:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/11/2022 21:43:19 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/11/2022 21:43:22 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.3566583953680728 on epoch=712
06/11/2022 21:43:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/11/2022 21:43:31 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/11/2022 21:43:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/11/2022 21:43:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/11/2022 21:43:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/11/2022 21:43:48 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.5307917888563051 on epoch=724
06/11/2022 21:43:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/11/2022 21:43:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/11/2022 21:44:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/11/2022 21:44:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/11/2022 21:44:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/11/2022 21:44:13 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.4995112414467253 on epoch=737
06/11/2022 21:44:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/11/2022 21:44:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/11/2022 21:44:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/11/2022 21:44:31 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/11/2022 21:44:36 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/11/2022 21:44:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 21:44:37 - INFO - __main__ - Printing 3 examples
06/11/2022 21:44:37 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/11/2022 21:44:37 - INFO - __main__ - ['refuted']
06/11/2022 21:44:37 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/11/2022 21:44:37 - INFO - __main__ - ['refuted']
06/11/2022 21:44:37 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/11/2022 21:44:37 - INFO - __main__ - ['refuted']
06/11/2022 21:44:37 - INFO - __main__ - Tokenizing Input ...
06/11/2022 21:44:37 - INFO - __main__ - Tokenizing Output ...
06/11/2022 21:44:37 - INFO - __main__ - Loaded 64 examples from train data
06/11/2022 21:44:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 21:44:37 - INFO - __main__ - Printing 3 examples
06/11/2022 21:44:37 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/11/2022 21:44:37 - INFO - __main__ - ['refuted']
06/11/2022 21:44:37 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/11/2022 21:44:37 - INFO - __main__ - ['refuted']
06/11/2022 21:44:37 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/11/2022 21:44:37 - INFO - __main__ - ['refuted']
06/11/2022 21:44:37 - INFO - __main__ - Tokenizing Input ...
06/11/2022 21:44:37 - INFO - __main__ - Tokenizing Output ...
06/11/2022 21:44:38 - INFO - __main__ - Loaded 64 examples from dev data
06/11/2022 21:44:39 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.5145583557621727 on epoch=749
06/11/2022 21:44:39 - INFO - __main__ - save last model!
06/11/2022 21:44:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/11/2022 21:44:39 - INFO - __main__ - Start tokenizing ... 12792 instances
06/11/2022 21:44:39 - INFO - __main__ - Printing 3 examples
06/11/2022 21:44:39 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/11/2022 21:44:39 - INFO - __main__ - ['entailed']
06/11/2022 21:44:39 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/11/2022 21:44:39 - INFO - __main__ - ['entailed']
06/11/2022 21:44:39 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/11/2022 21:44:39 - INFO - __main__ - ['entailed']
06/11/2022 21:44:39 - INFO - __main__ - Tokenizing Input ...
06/11/2022 21:44:56 - INFO - __main__ - load prompt embedding from ckpt
06/11/2022 21:44:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/11/2022 21:44:57 - INFO - __main__ - Starting training!
06/11/2022 21:45:05 - INFO - __main__ - Tokenizing Output ...
06/11/2022 21:45:18 - INFO - __main__ - Loaded 12792 examples from test data
06/11/2022 21:54:15 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_100_0.5_8_predictions.txt
06/11/2022 21:54:15 - INFO - __main__ - Classification-F1 on test data: 0.0664
06/11/2022 21:54:16 - INFO - __main__ - prefix=tab_fact_32_100, lr=0.5, bsz=8, dev_performance=0.5933528836754642, test_performance=0.0664129890745875
06/11/2022 21:54:16 - INFO - __main__ - Running ... prefix=tab_fact_32_100, lr=0.4, bsz=8 ...
06/11/2022 21:54:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 21:54:17 - INFO - __main__ - Printing 3 examples
06/11/2022 21:54:17 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/11/2022 21:54:17 - INFO - __main__ - ['refuted']
06/11/2022 21:54:17 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/11/2022 21:54:17 - INFO - __main__ - ['refuted']
06/11/2022 21:54:17 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/11/2022 21:54:17 - INFO - __main__ - ['refuted']
06/11/2022 21:54:17 - INFO - __main__ - Tokenizing Input ...
06/11/2022 21:54:17 - INFO - __main__ - Tokenizing Output ...
06/11/2022 21:54:17 - INFO - __main__ - Loaded 64 examples from train data
06/11/2022 21:54:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 21:54:17 - INFO - __main__ - Printing 3 examples
06/11/2022 21:54:17 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/11/2022 21:54:17 - INFO - __main__ - ['refuted']
06/11/2022 21:54:17 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/11/2022 21:54:17 - INFO - __main__ - ['refuted']
06/11/2022 21:54:17 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/11/2022 21:54:17 - INFO - __main__ - ['refuted']
06/11/2022 21:54:17 - INFO - __main__ - Tokenizing Input ...
06/11/2022 21:54:17 - INFO - __main__ - Tokenizing Output ...
06/11/2022 21:54:17 - INFO - __main__ - Loaded 64 examples from dev data
06/11/2022 21:54:36 - INFO - __main__ - load prompt embedding from ckpt
06/11/2022 21:54:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/11/2022 21:54:37 - INFO - __main__ - Starting training!
06/11/2022 21:54:42 - INFO - __main__ - Step 10 Global step 10 Train loss 2.68 on epoch=2
06/11/2022 21:54:46 - INFO - __main__ - Step 20 Global step 20 Train loss 0.62 on epoch=4
06/11/2022 21:54:51 - INFO - __main__ - Step 30 Global step 30 Train loss 0.38 on epoch=7
06/11/2022 21:54:55 - INFO - __main__ - Step 40 Global step 40 Train loss 0.34 on epoch=9
06/11/2022 21:55:00 - INFO - __main__ - Step 50 Global step 50 Train loss 0.29 on epoch=12
06/11/2022 21:55:03 - INFO - __main__ - Global step 50 Train loss 0.86 Classification-F1 0.3333333333333333 on epoch=12
06/11/2022 21:55:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/11/2022 21:55:07 - INFO - __main__ - Step 60 Global step 60 Train loss 0.25 on epoch=14
06/11/2022 21:55:12 - INFO - __main__ - Step 70 Global step 70 Train loss 0.26 on epoch=17
06/11/2022 21:55:16 - INFO - __main__ - Step 80 Global step 80 Train loss 0.23 on epoch=19
06/11/2022 21:55:21 - INFO - __main__ - Step 90 Global step 90 Train loss 0.25 on epoch=22
06/11/2022 21:55:25 - INFO - __main__ - Step 100 Global step 100 Train loss 0.28 on epoch=24
06/11/2022 21:55:28 - INFO - __main__ - Global step 100 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=24
06/11/2022 21:55:32 - INFO - __main__ - Step 110 Global step 110 Train loss 0.25 on epoch=27
06/11/2022 21:55:37 - INFO - __main__ - Step 120 Global step 120 Train loss 0.24 on epoch=29
06/11/2022 21:55:41 - INFO - __main__ - Step 130 Global step 130 Train loss 0.24 on epoch=32
06/11/2022 21:55:46 - INFO - __main__ - Step 140 Global step 140 Train loss 0.22 on epoch=34
06/11/2022 21:55:50 - INFO - __main__ - Step 150 Global step 150 Train loss 0.25 on epoch=37
06/11/2022 21:55:53 - INFO - __main__ - Global step 150 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=37
06/11/2022 21:55:57 - INFO - __main__ - Step 160 Global step 160 Train loss 0.26 on epoch=39
06/11/2022 21:56:02 - INFO - __main__ - Step 170 Global step 170 Train loss 0.26 on epoch=42
06/11/2022 21:56:06 - INFO - __main__ - Step 180 Global step 180 Train loss 0.22 on epoch=44
06/11/2022 21:56:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.26 on epoch=47
06/11/2022 21:56:15 - INFO - __main__ - Step 200 Global step 200 Train loss 0.26 on epoch=49
06/11/2022 21:56:18 - INFO - __main__ - Global step 200 Train loss 0.25 Classification-F1 0.3992490613266583 on epoch=49
06/11/2022 21:56:18 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.3992490613266583 on epoch=49, global_step=200
06/11/2022 21:56:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.21 on epoch=52
06/11/2022 21:56:27 - INFO - __main__ - Step 220 Global step 220 Train loss 0.22 on epoch=54
06/11/2022 21:56:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.25 on epoch=57
06/11/2022 21:56:36 - INFO - __main__ - Step 240 Global step 240 Train loss 0.26 on epoch=59
06/11/2022 21:56:40 - INFO - __main__ - Step 250 Global step 250 Train loss 0.21 on epoch=62
06/11/2022 21:56:43 - INFO - __main__ - Global step 250 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=62
06/11/2022 21:56:47 - INFO - __main__ - Step 260 Global step 260 Train loss 0.27 on epoch=64
06/11/2022 21:56:52 - INFO - __main__ - Step 270 Global step 270 Train loss 0.23 on epoch=67
06/11/2022 21:56:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=69
06/11/2022 21:57:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.21 on epoch=72
06/11/2022 21:57:05 - INFO - __main__ - Step 300 Global step 300 Train loss 0.22 on epoch=74
06/11/2022 21:57:08 - INFO - __main__ - Global step 300 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=74
06/11/2022 21:57:12 - INFO - __main__ - Step 310 Global step 310 Train loss 0.21 on epoch=77
06/11/2022 21:57:17 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=79
06/11/2022 21:57:21 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=82
06/11/2022 21:57:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.20 on epoch=84
06/11/2022 21:57:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=87
06/11/2022 21:57:33 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.32631578947368417 on epoch=87
06/11/2022 21:57:37 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=89
06/11/2022 21:57:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.21 on epoch=92
06/11/2022 21:57:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=94
06/11/2022 21:57:51 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=97
06/11/2022 21:57:55 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/11/2022 21:57:58 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=99
06/11/2022 21:58:02 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=102
06/11/2022 21:58:07 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=104
06/11/2022 21:58:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=107
06/11/2022 21:58:16 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=109
06/11/2022 21:58:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=112
06/11/2022 21:58:23 - INFO - __main__ - Global step 450 Train loss 0.20 Classification-F1 0.1867992766726944 on epoch=112
06/11/2022 21:58:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=114
06/11/2022 21:58:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=117
06/11/2022 21:58:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=119
06/11/2022 21:58:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=122
06/11/2022 21:58:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=124
06/11/2022 21:58:48 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.32631578947368417 on epoch=124
06/11/2022 21:58:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=127
06/11/2022 21:58:57 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=129
06/11/2022 21:59:01 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=132
06/11/2022 21:59:06 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=134
06/11/2022 21:59:10 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
06/11/2022 21:59:13 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.42840679919331603 on epoch=137
06/11/2022 21:59:13 - INFO - __main__ - Saving model with best Classification-F1: 0.3992490613266583 -> 0.42840679919331603 on epoch=137, global_step=550
06/11/2022 21:59:18 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/11/2022 21:59:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.17 on epoch=142
06/11/2022 21:59:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=144
06/11/2022 21:59:31 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=147
06/11/2022 21:59:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=149
06/11/2022 21:59:38 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.39047619047619053 on epoch=149
06/11/2022 21:59:43 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=152
06/11/2022 21:59:47 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=154
06/11/2022 21:59:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.14 on epoch=157
06/11/2022 21:59:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=159
06/11/2022 22:00:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=162
06/11/2022 22:00:03 - INFO - __main__ - Global step 650 Train loss 0.16 Classification-F1 0.3915298184961106 on epoch=162
06/11/2022 22:00:08 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=164
06/11/2022 22:00:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=167
06/11/2022 22:00:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=169
06/11/2022 22:00:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=172
06/11/2022 22:00:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=174
06/11/2022 22:00:29 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.4519207242476144 on epoch=174
06/11/2022 22:00:29 - INFO - __main__ - Saving model with best Classification-F1: 0.42840679919331603 -> 0.4519207242476144 on epoch=174, global_step=700
06/11/2022 22:00:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=177
06/11/2022 22:00:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=179
06/11/2022 22:00:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=182
06/11/2022 22:00:47 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=184
06/11/2022 22:00:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=187
06/11/2022 22:00:54 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.3347193347193347 on epoch=187
06/11/2022 22:00:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=189
06/11/2022 22:01:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=192
06/11/2022 22:01:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=194
06/11/2022 22:01:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=197
06/11/2022 22:01:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=199
06/11/2022 22:01:20 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.39756367663344405 on epoch=199
06/11/2022 22:01:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=202
06/11/2022 22:01:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=204
06/11/2022 22:01:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=207
06/11/2022 22:01:38 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=209
06/11/2022 22:01:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=212
06/11/2022 22:01:45 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.3511520737327189 on epoch=212
06/11/2022 22:01:50 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=214
06/11/2022 22:01:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=217
06/11/2022 22:01:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=219
06/11/2022 22:02:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=222
06/11/2022 22:02:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=224
06/11/2022 22:02:11 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.3846153846153846 on epoch=224
06/11/2022 22:02:15 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=227
06/11/2022 22:02:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=229
06/11/2022 22:02:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=232
06/11/2022 22:02:29 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=234
06/11/2022 22:02:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=237
06/11/2022 22:02:36 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.34436564223798266 on epoch=237
06/11/2022 22:02:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=239
06/11/2022 22:02:45 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=242
06/11/2022 22:02:50 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=244
06/11/2022 22:02:54 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=247
06/11/2022 22:02:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=249
06/11/2022 22:03:02 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.4519207242476144 on epoch=249
06/11/2022 22:03:07 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=252
06/11/2022 22:03:11 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=254
06/11/2022 22:03:16 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=257
06/11/2022 22:03:20 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=259
06/11/2022 22:03:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/11/2022 22:03:28 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.3356515979466799 on epoch=262
06/11/2022 22:03:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=264
06/11/2022 22:03:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=267
06/11/2022 22:03:41 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=269
06/11/2022 22:03:46 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=272
06/11/2022 22:03:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=274
06/11/2022 22:03:53 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.4748717948717949 on epoch=274
06/11/2022 22:03:53 - INFO - __main__ - Saving model with best Classification-F1: 0.4519207242476144 -> 0.4748717948717949 on epoch=274, global_step=1100
06/11/2022 22:03:58 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/11/2022 22:04:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=279
06/11/2022 22:04:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=282
06/11/2022 22:04:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=284
06/11/2022 22:04:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/11/2022 22:04:19 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.4995112414467253 on epoch=287
06/11/2022 22:04:19 - INFO - __main__ - Saving model with best Classification-F1: 0.4748717948717949 -> 0.4995112414467253 on epoch=287, global_step=1150
06/11/2022 22:04:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=289
06/11/2022 22:04:28 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/11/2022 22:04:33 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/11/2022 22:04:37 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=297
06/11/2022 22:04:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=299
06/11/2022 22:04:45 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.45440454662877805 on epoch=299
06/11/2022 22:04:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/11/2022 22:04:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=304
06/11/2022 22:04:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/11/2022 22:05:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=309
06/11/2022 22:05:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/11/2022 22:05:11 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.5155067155067155 on epoch=312
06/11/2022 22:05:11 - INFO - __main__ - Saving model with best Classification-F1: 0.4995112414467253 -> 0.5155067155067155 on epoch=312, global_step=1250
06/11/2022 22:05:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
06/11/2022 22:05:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/11/2022 22:05:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/11/2022 22:05:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/11/2022 22:05:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=324
06/11/2022 22:05:37 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.4980392156862745 on epoch=324
06/11/2022 22:05:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/11/2022 22:05:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/11/2022 22:05:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=332
06/11/2022 22:05:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/11/2022 22:05:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/11/2022 22:06:03 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.5413886829750433 on epoch=337
06/11/2022 22:06:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5155067155067155 -> 0.5413886829750433 on epoch=337, global_step=1350
06/11/2022 22:06:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=339
06/11/2022 22:06:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/11/2022 22:06:16 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/11/2022 22:06:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/11/2022 22:06:25 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/11/2022 22:06:29 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.4748717948717949 on epoch=349
06/11/2022 22:06:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=352
06/11/2022 22:06:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/11/2022 22:06:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/11/2022 22:06:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/11/2022 22:06:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
06/11/2022 22:06:55 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.4920634920634921 on epoch=362
06/11/2022 22:06:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/11/2022 22:07:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=367
06/11/2022 22:07:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/11/2022 22:07:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/11/2022 22:07:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=374
06/11/2022 22:07:21 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.5155067155067155 on epoch=374
06/11/2022 22:07:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/11/2022 22:07:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=379
06/11/2022 22:07:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/11/2022 22:07:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/11/2022 22:07:43 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/11/2022 22:07:46 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.4874874874874875 on epoch=387
06/11/2022 22:07:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/11/2022 22:07:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/11/2022 22:08:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
06/11/2022 22:08:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=397
06/11/2022 22:08:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/11/2022 22:08:12 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.49556650246305417 on epoch=399
06/11/2022 22:08:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/11/2022 22:08:21 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/11/2022 22:08:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/11/2022 22:08:30 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/11/2022 22:08:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/11/2022 22:08:38 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.48424908424908425 on epoch=412
06/11/2022 22:08:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/11/2022 22:08:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=417
06/11/2022 22:08:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/11/2022 22:08:56 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=422
06/11/2022 22:09:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/11/2022 22:09:03 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.577195987276731 on epoch=424
06/11/2022 22:09:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5413886829750433 -> 0.577195987276731 on epoch=424, global_step=1700
06/11/2022 22:09:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/11/2022 22:09:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/11/2022 22:09:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/11/2022 22:09:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/11/2022 22:09:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/11/2022 22:09:29 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.473972602739726 on epoch=437
06/11/2022 22:09:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/11/2022 22:09:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/11/2022 22:09:43 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/11/2022 22:09:48 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/11/2022 22:09:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/11/2022 22:09:55 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.4832395400048935 on epoch=449
06/11/2022 22:10:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/11/2022 22:10:04 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/11/2022 22:10:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/11/2022 22:10:14 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/11/2022 22:10:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/11/2022 22:10:21 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.31464019851116626 on epoch=462
06/11/2022 22:10:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/11/2022 22:10:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/11/2022 22:10:35 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/11/2022 22:10:39 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/11/2022 22:10:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=474
06/11/2022 22:10:46 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.4920634920634921 on epoch=474
06/11/2022 22:10:51 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/11/2022 22:10:55 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/11/2022 22:11:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/11/2022 22:11:04 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/11/2022 22:11:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/11/2022 22:11:12 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.4995112414467253 on epoch=487
06/11/2022 22:11:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/11/2022 22:11:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/11/2022 22:11:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/11/2022 22:11:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/11/2022 22:11:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/11/2022 22:11:37 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.5097603162836669 on epoch=499
06/11/2022 22:11:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/11/2022 22:11:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/11/2022 22:11:51 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/11/2022 22:11:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/11/2022 22:12:00 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/11/2022 22:12:02 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.4493927125506073 on epoch=512
06/11/2022 22:12:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/11/2022 22:12:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/11/2022 22:12:16 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/11/2022 22:12:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=522
06/11/2022 22:12:25 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/11/2022 22:12:28 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.46218487394957986 on epoch=524
06/11/2022 22:12:33 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/11/2022 22:12:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/11/2022 22:12:42 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=532
06/11/2022 22:12:46 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/11/2022 22:12:51 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/11/2022 22:12:53 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.5097603162836669 on epoch=537
06/11/2022 22:12:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/11/2022 22:13:03 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/11/2022 22:13:07 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/11/2022 22:13:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/11/2022 22:13:16 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/11/2022 22:13:19 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.5270935960591133 on epoch=549
06/11/2022 22:13:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/11/2022 22:13:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/11/2022 22:13:33 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=557
06/11/2022 22:13:37 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/11/2022 22:13:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/11/2022 22:13:45 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.5270935960591133 on epoch=562
06/11/2022 22:13:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/11/2022 22:13:54 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/11/2022 22:13:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/11/2022 22:14:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/11/2022 22:14:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/11/2022 22:14:10 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.5097603162836669 on epoch=574
06/11/2022 22:14:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/11/2022 22:14:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/11/2022 22:14:23 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/11/2022 22:14:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/11/2022 22:14:32 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/11/2022 22:14:35 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.4980392156862745 on epoch=587
06/11/2022 22:14:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/11/2022 22:14:44 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/11/2022 22:14:49 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/11/2022 22:14:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/11/2022 22:14:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/11/2022 22:15:01 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.5145583557621727 on epoch=599
06/11/2022 22:15:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/11/2022 22:15:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/11/2022 22:15:14 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/11/2022 22:15:19 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/11/2022 22:15:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/11/2022 22:15:26 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.5097603162836669 on epoch=612
06/11/2022 22:15:31 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/11/2022 22:15:35 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/11/2022 22:15:40 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/11/2022 22:15:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/11/2022 22:15:49 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/11/2022 22:15:51 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.5467643467643467 on epoch=624
06/11/2022 22:15:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/11/2022 22:16:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/11/2022 22:16:05 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/11/2022 22:16:09 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/11/2022 22:16:14 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/11/2022 22:16:17 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.5270935960591133 on epoch=637
06/11/2022 22:16:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/11/2022 22:16:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/11/2022 22:16:30 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/11/2022 22:16:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/11/2022 22:16:39 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/11/2022 22:16:42 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.3247097844112769 on epoch=649
06/11/2022 22:16:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/11/2022 22:16:51 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/11/2022 22:16:55 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/11/2022 22:17:00 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/11/2022 22:17:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/11/2022 22:17:07 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.5145583557621727 on epoch=662
06/11/2022 22:17:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/11/2022 22:17:16 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/11/2022 22:17:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/11/2022 22:17:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/11/2022 22:17:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/11/2022 22:17:33 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.46875 on epoch=674
06/11/2022 22:17:38 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/11/2022 22:17:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=679
06/11/2022 22:17:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/11/2022 22:17:51 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/11/2022 22:17:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/11/2022 22:17:59 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.5 on epoch=687
06/11/2022 22:18:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/11/2022 22:18:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/11/2022 22:18:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/11/2022 22:18:17 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/11/2022 22:18:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/11/2022 22:18:25 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.5155067155067155 on epoch=699
06/11/2022 22:18:29 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/11/2022 22:18:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/11/2022 22:18:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/11/2022 22:18:43 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/11/2022 22:18:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/11/2022 22:18:50 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.5307917888563051 on epoch=712
06/11/2022 22:18:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=714
06/11/2022 22:18:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/11/2022 22:19:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/11/2022 22:19:08 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/11/2022 22:19:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/11/2022 22:19:16 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.5294117647058825 on epoch=724
06/11/2022 22:19:21 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/11/2022 22:19:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/11/2022 22:19:30 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/11/2022 22:19:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/11/2022 22:19:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/11/2022 22:19:42 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.5238095238095238 on epoch=737
06/11/2022 22:19:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/11/2022 22:19:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/11/2022 22:19:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/11/2022 22:20:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/11/2022 22:20:05 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/11/2022 22:20:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 22:20:06 - INFO - __main__ - Printing 3 examples
06/11/2022 22:20:06 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/11/2022 22:20:06 - INFO - __main__ - ['refuted']
06/11/2022 22:20:06 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/11/2022 22:20:06 - INFO - __main__ - ['refuted']
06/11/2022 22:20:06 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/11/2022 22:20:06 - INFO - __main__ - ['refuted']
06/11/2022 22:20:06 - INFO - __main__ - Tokenizing Input ...
06/11/2022 22:20:06 - INFO - __main__ - Tokenizing Output ...
06/11/2022 22:20:06 - INFO - __main__ - Loaded 64 examples from train data
06/11/2022 22:20:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 22:20:06 - INFO - __main__ - Printing 3 examples
06/11/2022 22:20:06 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/11/2022 22:20:06 - INFO - __main__ - ['refuted']
06/11/2022 22:20:06 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/11/2022 22:20:06 - INFO - __main__ - ['refuted']
06/11/2022 22:20:06 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/11/2022 22:20:06 - INFO - __main__ - ['refuted']
06/11/2022 22:20:06 - INFO - __main__ - Tokenizing Input ...
06/11/2022 22:20:06 - INFO - __main__ - Tokenizing Output ...
06/11/2022 22:20:07 - INFO - __main__ - Loaded 64 examples from dev data
06/11/2022 22:20:08 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.5155067155067155 on epoch=749
06/11/2022 22:20:08 - INFO - __main__ - save last model!
06/11/2022 22:20:08 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/11/2022 22:20:08 - INFO - __main__ - Start tokenizing ... 12792 instances
06/11/2022 22:20:08 - INFO - __main__ - Printing 3 examples
06/11/2022 22:20:08 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/11/2022 22:20:08 - INFO - __main__ - ['entailed']
06/11/2022 22:20:08 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/11/2022 22:20:08 - INFO - __main__ - ['entailed']
06/11/2022 22:20:08 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/11/2022 22:20:08 - INFO - __main__ - ['entailed']
06/11/2022 22:20:08 - INFO - __main__ - Tokenizing Input ...
06/11/2022 22:20:22 - INFO - __main__ - load prompt embedding from ckpt
06/11/2022 22:20:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/11/2022 22:20:23 - INFO - __main__ - Starting training!
06/11/2022 22:20:35 - INFO - __main__ - Tokenizing Output ...
06/11/2022 22:20:50 - INFO - __main__ - Loaded 12792 examples from test data
06/11/2022 22:30:30 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_100_0.4_8_predictions.txt
06/11/2022 22:30:30 - INFO - __main__ - Classification-F1 on test data: 0.0623
06/11/2022 22:30:30 - INFO - __main__ - prefix=tab_fact_32_100, lr=0.4, bsz=8, dev_performance=0.577195987276731, test_performance=0.06227755896738079
06/11/2022 22:30:30 - INFO - __main__ - Running ... prefix=tab_fact_32_100, lr=0.3, bsz=8 ...
06/11/2022 22:30:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 22:30:31 - INFO - __main__ - Printing 3 examples
06/11/2022 22:30:31 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/11/2022 22:30:31 - INFO - __main__ - ['refuted']
06/11/2022 22:30:31 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/11/2022 22:30:31 - INFO - __main__ - ['refuted']
06/11/2022 22:30:31 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/11/2022 22:30:31 - INFO - __main__ - ['refuted']
06/11/2022 22:30:31 - INFO - __main__ - Tokenizing Input ...
06/11/2022 22:30:31 - INFO - __main__ - Tokenizing Output ...
06/11/2022 22:30:31 - INFO - __main__ - Loaded 64 examples from train data
06/11/2022 22:30:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 22:30:31 - INFO - __main__ - Printing 3 examples
06/11/2022 22:30:31 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/11/2022 22:30:31 - INFO - __main__ - ['refuted']
06/11/2022 22:30:31 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/11/2022 22:30:31 - INFO - __main__ - ['refuted']
06/11/2022 22:30:31 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/11/2022 22:30:31 - INFO - __main__ - ['refuted']
06/11/2022 22:30:31 - INFO - __main__ - Tokenizing Input ...
06/11/2022 22:30:31 - INFO - __main__ - Tokenizing Output ...
06/11/2022 22:30:31 - INFO - __main__ - Loaded 64 examples from dev data
06/11/2022 22:30:47 - INFO - __main__ - load prompt embedding from ckpt
06/11/2022 22:30:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/11/2022 22:30:47 - INFO - __main__ - Starting training!
06/11/2022 22:30:52 - INFO - __main__ - Step 10 Global step 10 Train loss 2.83 on epoch=2
06/11/2022 22:30:57 - INFO - __main__ - Step 20 Global step 20 Train loss 0.66 on epoch=4
06/11/2022 22:31:01 - INFO - __main__ - Step 30 Global step 30 Train loss 0.51 on epoch=7
06/11/2022 22:31:06 - INFO - __main__ - Step 40 Global step 40 Train loss 0.40 on epoch=9
06/11/2022 22:31:10 - INFO - __main__ - Step 50 Global step 50 Train loss 0.37 on epoch=12
06/11/2022 22:31:13 - INFO - __main__ - Global step 50 Train loss 0.95 Classification-F1 0.3333333333333333 on epoch=12
06/11/2022 22:31:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/11/2022 22:31:17 - INFO - __main__ - Step 60 Global step 60 Train loss 0.32 on epoch=14
06/11/2022 22:31:22 - INFO - __main__ - Step 70 Global step 70 Train loss 0.32 on epoch=17
06/11/2022 22:31:26 - INFO - __main__ - Step 80 Global step 80 Train loss 0.26 on epoch=19
06/11/2022 22:31:31 - INFO - __main__ - Step 90 Global step 90 Train loss 0.29 on epoch=22
06/11/2022 22:31:35 - INFO - __main__ - Step 100 Global step 100 Train loss 0.30 on epoch=24
06/11/2022 22:31:38 - INFO - __main__ - Global step 100 Train loss 0.30 Classification-F1 0.3333333333333333 on epoch=24
06/11/2022 22:31:42 - INFO - __main__ - Step 110 Global step 110 Train loss 0.28 on epoch=27
06/11/2022 22:31:47 - INFO - __main__ - Step 120 Global step 120 Train loss 0.27 on epoch=29
06/11/2022 22:31:52 - INFO - __main__ - Step 130 Global step 130 Train loss 0.24 on epoch=32
06/11/2022 22:31:56 - INFO - __main__ - Step 140 Global step 140 Train loss 0.22 on epoch=34
06/11/2022 22:32:01 - INFO - __main__ - Step 150 Global step 150 Train loss 0.29 on epoch=37
06/11/2022 22:32:03 - INFO - __main__ - Global step 150 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=37
06/11/2022 22:32:08 - INFO - __main__ - Step 160 Global step 160 Train loss 0.22 on epoch=39
06/11/2022 22:32:12 - INFO - __main__ - Step 170 Global step 170 Train loss 0.25 on epoch=42
06/11/2022 22:32:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=44
06/11/2022 22:32:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.25 on epoch=47
06/11/2022 22:32:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=49
06/11/2022 22:32:29 - INFO - __main__ - Global step 200 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=49
06/11/2022 22:32:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.18 on epoch=52
06/11/2022 22:32:38 - INFO - __main__ - Step 220 Global step 220 Train loss 0.27 on epoch=54
06/11/2022 22:32:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.22 on epoch=57
06/11/2022 22:32:47 - INFO - __main__ - Step 240 Global step 240 Train loss 0.24 on epoch=59
06/11/2022 22:32:51 - INFO - __main__ - Step 250 Global step 250 Train loss 0.22 on epoch=62
06/11/2022 22:32:54 - INFO - __main__ - Global step 250 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=62
06/11/2022 22:32:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.23 on epoch=64
06/11/2022 22:33:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.22 on epoch=67
06/11/2022 22:33:07 - INFO - __main__ - Step 280 Global step 280 Train loss 0.21 on epoch=69
06/11/2022 22:33:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=72
06/11/2022 22:33:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.23 on epoch=74
06/11/2022 22:33:19 - INFO - __main__ - Global step 300 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=74
06/11/2022 22:33:24 - INFO - __main__ - Step 310 Global step 310 Train loss 0.26 on epoch=77
06/11/2022 22:33:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=79
06/11/2022 22:33:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/11/2022 22:33:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.21 on epoch=84
06/11/2022 22:33:42 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=87
06/11/2022 22:33:45 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=87
06/11/2022 22:33:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=89
06/11/2022 22:33:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=92
06/11/2022 22:33:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=94
06/11/2022 22:34:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=97
06/11/2022 22:34:07 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=99
06/11/2022 22:34:11 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=99
06/11/2022 22:34:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=102
06/11/2022 22:34:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/11/2022 22:34:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=107
06/11/2022 22:34:29 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=109
06/11/2022 22:34:33 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/11/2022 22:34:36 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.1716216216216216 on epoch=112
06/11/2022 22:34:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=114
06/11/2022 22:34:45 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=117
06/11/2022 22:34:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=119
06/11/2022 22:34:54 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=122
06/11/2022 22:34:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=124
06/11/2022 22:35:02 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.24812818209044624 on epoch=124
06/11/2022 22:35:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=127
06/11/2022 22:35:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/11/2022 22:35:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=132
06/11/2022 22:35:20 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/11/2022 22:35:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=137
06/11/2022 22:35:27 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.2554865424430642 on epoch=137
06/11/2022 22:35:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/11/2022 22:35:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=142
06/11/2022 22:35:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/11/2022 22:35:45 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=147
06/11/2022 22:35:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=149
06/11/2022 22:35:52 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.3591989987484355 on epoch=149
06/11/2022 22:35:52 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.3591989987484355 on epoch=149, global_step=600
06/11/2022 22:35:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=152
06/11/2022 22:36:01 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=154
06/11/2022 22:36:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=157
06/11/2022 22:36:10 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=159
06/11/2022 22:36:15 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=162
06/11/2022 22:36:18 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.5625 on epoch=162
06/11/2022 22:36:18 - INFO - __main__ - Saving model with best Classification-F1: 0.3591989987484355 -> 0.5625 on epoch=162, global_step=650
06/11/2022 22:36:22 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=164
06/11/2022 22:36:27 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=167
06/11/2022 22:36:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=169
06/11/2022 22:36:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=172
06/11/2022 22:36:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=174
06/11/2022 22:36:43 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.5330817610062892 on epoch=174
06/11/2022 22:36:48 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=177
06/11/2022 22:36:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=179
06/11/2022 22:36:57 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=182
06/11/2022 22:37:01 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=184
06/11/2022 22:37:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=187
06/11/2022 22:37:08 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.5586206896551724 on epoch=187
06/11/2022 22:37:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=189
06/11/2022 22:37:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=192
06/11/2022 22:37:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=194
06/11/2022 22:37:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=197
06/11/2022 22:37:31 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=199
06/11/2022 22:37:34 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.3776674937965261 on epoch=199
06/11/2022 22:37:39 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=202
06/11/2022 22:37:43 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=204
06/11/2022 22:37:48 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=207
06/11/2022 22:37:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=209
06/11/2022 22:37:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=212
06/11/2022 22:38:00 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.4018817204301075 on epoch=212
06/11/2022 22:38:04 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=214
06/11/2022 22:38:09 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=217
06/11/2022 22:38:13 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=219
06/11/2022 22:38:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=222
06/11/2022 22:38:22 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=224
06/11/2022 22:38:25 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.3966583124477861 on epoch=224
06/11/2022 22:38:30 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=227
06/11/2022 22:38:35 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=229
06/11/2022 22:38:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=232
06/11/2022 22:38:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=234
06/11/2022 22:38:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
06/11/2022 22:38:51 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.624633431085044 on epoch=237
06/11/2022 22:38:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5625 -> 0.624633431085044 on epoch=237, global_step=950
06/11/2022 22:38:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/11/2022 22:39:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=242
06/11/2022 22:39:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=244
06/11/2022 22:39:09 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=247
06/11/2022 22:39:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=249
06/11/2022 22:39:16 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.5755342667649226 on epoch=249
06/11/2022 22:39:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
06/11/2022 22:39:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/11/2022 22:39:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=257
06/11/2022 22:39:34 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=259
06/11/2022 22:39:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
06/11/2022 22:39:42 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.6296855345911949 on epoch=262
06/11/2022 22:39:42 - INFO - __main__ - Saving model with best Classification-F1: 0.624633431085044 -> 0.6296855345911949 on epoch=262, global_step=1050
06/11/2022 22:39:46 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=264
06/11/2022 22:39:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/11/2022 22:39:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
06/11/2022 22:40:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=272
06/11/2022 22:40:04 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/11/2022 22:40:07 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.43878060969515237 on epoch=274
06/11/2022 22:40:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/11/2022 22:40:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=279
06/11/2022 22:40:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/11/2022 22:40:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/11/2022 22:40:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/11/2022 22:40:32 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.59375 on epoch=287
06/11/2022 22:40:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/11/2022 22:40:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/11/2022 22:40:46 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/11/2022 22:40:50 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=297
06/11/2022 22:40:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/11/2022 22:40:58 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.5270935960591133 on epoch=299
06/11/2022 22:41:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/11/2022 22:41:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/11/2022 22:41:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=307
06/11/2022 22:41:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/11/2022 22:41:20 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=312
06/11/2022 22:41:23 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.3797979797979798 on epoch=312
06/11/2022 22:41:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=314
06/11/2022 22:41:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/11/2022 22:41:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/11/2022 22:41:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/11/2022 22:41:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/11/2022 22:41:48 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.5921568627450979 on epoch=324
06/11/2022 22:41:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/11/2022 22:41:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/11/2022 22:42:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/11/2022 22:42:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/11/2022 22:42:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/11/2022 22:42:13 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.5755342667649226 on epoch=337
06/11/2022 22:42:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=339
06/11/2022 22:42:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/11/2022 22:42:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/11/2022 22:42:31 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/11/2022 22:42:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/11/2022 22:42:38 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.625 on epoch=349
06/11/2022 22:42:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/11/2022 22:42:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=354
06/11/2022 22:42:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/11/2022 22:42:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/11/2022 22:43:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=362
06/11/2022 22:43:03 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.3883928571428572 on epoch=362
06/11/2022 22:43:08 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=364
06/11/2022 22:43:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/11/2022 22:43:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/11/2022 22:43:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/11/2022 22:43:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/11/2022 22:43:29 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.5921568627450979 on epoch=374
06/11/2022 22:43:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/11/2022 22:43:38 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/11/2022 22:43:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=382
06/11/2022 22:43:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=384
06/11/2022 22:43:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/11/2022 22:43:54 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.6092796092796093 on epoch=387
06/11/2022 22:43:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/11/2022 22:44:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/11/2022 22:44:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/11/2022 22:44:12 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/11/2022 22:44:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/11/2022 22:44:19 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.6532019704433498 on epoch=399
06/11/2022 22:44:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6296855345911949 -> 0.6532019704433498 on epoch=399, global_step=1600
06/11/2022 22:44:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/11/2022 22:44:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/11/2022 22:44:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/11/2022 22:44:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/11/2022 22:44:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/11/2022 22:44:44 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.5270935960591133 on epoch=412
06/11/2022 22:44:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/11/2022 22:44:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/11/2022 22:44:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/11/2022 22:45:02 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/11/2022 22:45:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/11/2022 22:45:09 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.5058530510585305 on epoch=424
06/11/2022 22:45:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/11/2022 22:45:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/11/2022 22:45:23 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/11/2022 22:45:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/11/2022 22:45:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/11/2022 22:45:34 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.5933528836754642 on epoch=437
06/11/2022 22:45:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/11/2022 22:45:43 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/11/2022 22:45:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/11/2022 22:45:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/11/2022 22:45:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/11/2022 22:45:59 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.5195195195195195 on epoch=449
06/11/2022 22:46:04 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=452
06/11/2022 22:46:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/11/2022 22:46:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/11/2022 22:46:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/11/2022 22:46:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/11/2022 22:46:25 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.5620723362658846 on epoch=462
06/11/2022 22:46:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/11/2022 22:46:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/11/2022 22:46:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/11/2022 22:46:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/11/2022 22:46:47 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/11/2022 22:46:50 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.624633431085044 on epoch=474
06/11/2022 22:46:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/11/2022 22:46:59 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/11/2022 22:47:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/11/2022 22:47:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=484
06/11/2022 22:47:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/11/2022 22:47:15 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.59375 on epoch=487
06/11/2022 22:47:19 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/11/2022 22:47:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/11/2022 22:47:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
06/11/2022 22:47:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/11/2022 22:47:37 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/11/2022 22:47:40 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.4158283031522469 on epoch=499
06/11/2022 22:47:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/11/2022 22:47:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/11/2022 22:47:53 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/11/2022 22:47:58 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/11/2022 22:48:02 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/11/2022 22:48:05 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.6085148030340103 on epoch=512
06/11/2022 22:48:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/11/2022 22:48:14 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/11/2022 22:48:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/11/2022 22:48:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/11/2022 22:48:27 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/11/2022 22:48:30 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.5238095238095238 on epoch=524
06/11/2022 22:48:35 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/11/2022 22:48:39 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/11/2022 22:48:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/11/2022 22:48:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/11/2022 22:48:53 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/11/2022 22:48:56 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6398336187912894 on epoch=537
06/11/2022 22:49:00 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/11/2022 22:49:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/11/2022 22:49:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/11/2022 22:49:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/11/2022 22:49:18 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/11/2022 22:49:21 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6085148030340103 on epoch=549
06/11/2022 22:49:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/11/2022 22:49:30 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/11/2022 22:49:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/11/2022 22:49:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/11/2022 22:49:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=562
06/11/2022 22:49:46 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.5901477832512315 on epoch=562
06/11/2022 22:49:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/11/2022 22:49:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/11/2022 22:50:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/11/2022 22:50:04 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/11/2022 22:50:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/11/2022 22:50:12 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.3762697396500214 on epoch=574
06/11/2022 22:50:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/11/2022 22:50:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/11/2022 22:50:25 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/11/2022 22:50:30 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/11/2022 22:50:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/11/2022 22:50:37 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.5730170496664195 on epoch=587
06/11/2022 22:50:41 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/11/2022 22:50:46 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/11/2022 22:50:51 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/11/2022 22:50:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/11/2022 22:51:00 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/11/2022 22:51:02 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.6405372405372406 on epoch=599
06/11/2022 22:51:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/11/2022 22:51:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/11/2022 22:51:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/11/2022 22:51:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/11/2022 22:51:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/11/2022 22:51:27 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.6092796092796093 on epoch=612
06/11/2022 22:51:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/11/2022 22:51:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/11/2022 22:51:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/11/2022 22:51:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/11/2022 22:51:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/11/2022 22:51:52 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6092796092796093 on epoch=624
06/11/2022 22:51:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/11/2022 22:52:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/11/2022 22:52:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/11/2022 22:52:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/11/2022 22:52:15 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/11/2022 22:52:17 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.6014943960149439 on epoch=637
06/11/2022 22:52:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/11/2022 22:52:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/11/2022 22:52:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
06/11/2022 22:52:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/11/2022 22:52:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/11/2022 22:52:42 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6092796092796093 on epoch=649
06/11/2022 22:52:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/11/2022 22:52:51 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=654
06/11/2022 22:52:55 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/11/2022 22:53:00 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/11/2022 22:53:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/11/2022 22:53:07 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6085148030340103 on epoch=662
06/11/2022 22:53:11 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/11/2022 22:53:16 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/11/2022 22:53:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/11/2022 22:53:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/11/2022 22:53:29 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/11/2022 22:53:32 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6092796092796093 on epoch=674
06/11/2022 22:53:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/11/2022 22:53:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/11/2022 22:53:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/11/2022 22:53:50 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/11/2022 22:53:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/11/2022 22:53:57 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.625 on epoch=687
06/11/2022 22:54:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/11/2022 22:54:06 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/11/2022 22:54:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/11/2022 22:54:15 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/11/2022 22:54:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/11/2022 22:54:22 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6085148030340103 on epoch=699
06/11/2022 22:54:26 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/11/2022 22:54:31 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/11/2022 22:54:36 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/11/2022 22:54:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/11/2022 22:54:45 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/11/2022 22:54:47 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.5755342667649226 on epoch=712
06/11/2022 22:54:52 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/11/2022 22:54:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/11/2022 22:55:01 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/11/2022 22:55:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=722
06/11/2022 22:55:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/11/2022 22:55:12 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.65625 on epoch=724
06/11/2022 22:55:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6532019704433498 -> 0.65625 on epoch=724, global_step=2900
06/11/2022 22:55:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/11/2022 22:55:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/11/2022 22:55:26 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/11/2022 22:55:30 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/11/2022 22:55:35 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/11/2022 22:55:37 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6085148030340103 on epoch=737
06/11/2022 22:55:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/11/2022 22:55:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/11/2022 22:55:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/11/2022 22:55:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/11/2022 22:56:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=749
06/11/2022 22:56:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 22:56:01 - INFO - __main__ - Printing 3 examples
06/11/2022 22:56:01 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/11/2022 22:56:01 - INFO - __main__ - ['refuted']
06/11/2022 22:56:01 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/11/2022 22:56:01 - INFO - __main__ - ['refuted']
06/11/2022 22:56:01 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/11/2022 22:56:01 - INFO - __main__ - ['refuted']
06/11/2022 22:56:01 - INFO - __main__ - Tokenizing Input ...
06/11/2022 22:56:02 - INFO - __main__ - Tokenizing Output ...
06/11/2022 22:56:02 - INFO - __main__ - Loaded 64 examples from train data
06/11/2022 22:56:02 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 22:56:02 - INFO - __main__ - Printing 3 examples
06/11/2022 22:56:02 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/11/2022 22:56:02 - INFO - __main__ - ['refuted']
06/11/2022 22:56:02 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/11/2022 22:56:02 - INFO - __main__ - ['refuted']
06/11/2022 22:56:02 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/11/2022 22:56:02 - INFO - __main__ - ['refuted']
06/11/2022 22:56:02 - INFO - __main__ - Tokenizing Input ...
06/11/2022 22:56:02 - INFO - __main__ - Tokenizing Output ...
06/11/2022 22:56:02 - INFO - __main__ - Loaded 64 examples from dev data
06/11/2022 22:56:03 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.5835835835835835 on epoch=749
06/11/2022 22:56:03 - INFO - __main__ - save last model!
06/11/2022 22:56:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/11/2022 22:56:03 - INFO - __main__ - Start tokenizing ... 12792 instances
06/11/2022 22:56:03 - INFO - __main__ - Printing 3 examples
06/11/2022 22:56:03 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/11/2022 22:56:03 - INFO - __main__ - ['entailed']
06/11/2022 22:56:03 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/11/2022 22:56:03 - INFO - __main__ - ['entailed']
06/11/2022 22:56:03 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/11/2022 22:56:03 - INFO - __main__ - ['entailed']
06/11/2022 22:56:03 - INFO - __main__ - Tokenizing Input ...
06/11/2022 22:56:17 - INFO - __main__ - load prompt embedding from ckpt
06/11/2022 22:56:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/11/2022 22:56:18 - INFO - __main__ - Starting training!
06/11/2022 22:56:27 - INFO - __main__ - Tokenizing Output ...
06/11/2022 22:56:40 - INFO - __main__ - Loaded 12792 examples from test data
06/11/2022 23:04:58 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_100_0.3_8_predictions.txt
06/11/2022 23:04:58 - INFO - __main__ - Classification-F1 on test data: 0.4872
06/11/2022 23:04:59 - INFO - __main__ - prefix=tab_fact_32_100, lr=0.3, bsz=8, dev_performance=0.65625, test_performance=0.48717664597055554
06/11/2022 23:04:59 - INFO - __main__ - Running ... prefix=tab_fact_32_100, lr=0.2, bsz=8 ...
06/11/2022 23:05:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 23:05:00 - INFO - __main__ - Printing 3 examples
06/11/2022 23:05:00 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/11/2022 23:05:00 - INFO - __main__ - ['refuted']
06/11/2022 23:05:00 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/11/2022 23:05:00 - INFO - __main__ - ['refuted']
06/11/2022 23:05:00 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/11/2022 23:05:00 - INFO - __main__ - ['refuted']
06/11/2022 23:05:00 - INFO - __main__ - Tokenizing Input ...
06/11/2022 23:05:00 - INFO - __main__ - Tokenizing Output ...
06/11/2022 23:05:00 - INFO - __main__ - Loaded 64 examples from train data
06/11/2022 23:05:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 23:05:00 - INFO - __main__ - Printing 3 examples
06/11/2022 23:05:00 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/11/2022 23:05:00 - INFO - __main__ - ['refuted']
06/11/2022 23:05:00 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/11/2022 23:05:00 - INFO - __main__ - ['refuted']
06/11/2022 23:05:00 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/11/2022 23:05:00 - INFO - __main__ - ['refuted']
06/11/2022 23:05:00 - INFO - __main__ - Tokenizing Input ...
06/11/2022 23:05:00 - INFO - __main__ - Tokenizing Output ...
06/11/2022 23:05:00 - INFO - __main__ - Loaded 64 examples from dev data
06/11/2022 23:05:15 - INFO - __main__ - load prompt embedding from ckpt
06/11/2022 23:05:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/11/2022 23:05:16 - INFO - __main__ - Starting training!
06/11/2022 23:05:21 - INFO - __main__ - Step 10 Global step 10 Train loss 3.59 on epoch=2
06/11/2022 23:05:25 - INFO - __main__ - Step 20 Global step 20 Train loss 1.17 on epoch=4
06/11/2022 23:05:30 - INFO - __main__ - Step 30 Global step 30 Train loss 0.55 on epoch=7
06/11/2022 23:05:34 - INFO - __main__ - Step 40 Global step 40 Train loss 0.47 on epoch=9
06/11/2022 23:05:39 - INFO - __main__ - Step 50 Global step 50 Train loss 0.42 on epoch=12
06/11/2022 23:05:42 - INFO - __main__ - Global step 50 Train loss 1.24 Classification-F1 0.3333333333333333 on epoch=12
06/11/2022 23:05:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/11/2022 23:05:46 - INFO - __main__ - Step 60 Global step 60 Train loss 0.31 on epoch=14
06/11/2022 23:05:51 - INFO - __main__ - Step 70 Global step 70 Train loss 0.33 on epoch=17
06/11/2022 23:05:55 - INFO - __main__ - Step 80 Global step 80 Train loss 0.32 on epoch=19
06/11/2022 23:06:00 - INFO - __main__ - Step 90 Global step 90 Train loss 0.31 on epoch=22
06/11/2022 23:06:04 - INFO - __main__ - Step 100 Global step 100 Train loss 0.31 on epoch=24
06/11/2022 23:06:08 - INFO - __main__ - Global step 100 Train loss 0.32 Classification-F1 0.3333333333333333 on epoch=24
06/11/2022 23:06:12 - INFO - __main__ - Step 110 Global step 110 Train loss 0.23 on epoch=27
06/11/2022 23:06:17 - INFO - __main__ - Step 120 Global step 120 Train loss 0.27 on epoch=29
06/11/2022 23:06:21 - INFO - __main__ - Step 130 Global step 130 Train loss 0.29 on epoch=32
06/11/2022 23:06:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.30 on epoch=34
06/11/2022 23:06:30 - INFO - __main__ - Step 150 Global step 150 Train loss 0.28 on epoch=37
06/11/2022 23:06:33 - INFO - __main__ - Global step 150 Train loss 0.27 Classification-F1 0.3333333333333333 on epoch=37
06/11/2022 23:06:37 - INFO - __main__ - Step 160 Global step 160 Train loss 0.23 on epoch=39
06/11/2022 23:06:42 - INFO - __main__ - Step 170 Global step 170 Train loss 0.25 on epoch=42
06/11/2022 23:06:47 - INFO - __main__ - Step 180 Global step 180 Train loss 0.27 on epoch=44
06/11/2022 23:06:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.27 on epoch=47
06/11/2022 23:06:56 - INFO - __main__ - Step 200 Global step 200 Train loss 0.23 on epoch=49
06/11/2022 23:06:59 - INFO - __main__ - Global step 200 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=49
06/11/2022 23:07:03 - INFO - __main__ - Step 210 Global step 210 Train loss 0.27 on epoch=52
06/11/2022 23:07:08 - INFO - __main__ - Step 220 Global step 220 Train loss 0.25 on epoch=54
06/11/2022 23:07:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.23 on epoch=57
06/11/2022 23:07:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.24 on epoch=59
06/11/2022 23:07:22 - INFO - __main__ - Step 250 Global step 250 Train loss 0.26 on epoch=62
06/11/2022 23:07:24 - INFO - __main__ - Global step 250 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=62
06/11/2022 23:07:29 - INFO - __main__ - Step 260 Global step 260 Train loss 0.24 on epoch=64
06/11/2022 23:07:33 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=67
06/11/2022 23:07:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=69
06/11/2022 23:07:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.23 on epoch=72
06/11/2022 23:07:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.28 on epoch=74
06/11/2022 23:07:50 - INFO - __main__ - Global step 300 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=74
06/11/2022 23:07:55 - INFO - __main__ - Step 310 Global step 310 Train loss 0.22 on epoch=77
06/11/2022 23:07:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=79
06/11/2022 23:08:04 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/11/2022 23:08:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=84
06/11/2022 23:08:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=87
06/11/2022 23:08:15 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=87
06/11/2022 23:08:20 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=89
06/11/2022 23:08:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=92
06/11/2022 23:08:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=94
06/11/2022 23:08:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/11/2022 23:08:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=99
06/11/2022 23:08:41 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.3671451355661882 on epoch=99
06/11/2022 23:08:41 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.3671451355661882 on epoch=99, global_step=400
06/11/2022 23:08:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=102
06/11/2022 23:08:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=104
06/11/2022 23:08:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=107
06/11/2022 23:08:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=109
06/11/2022 23:09:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.24 on epoch=112
06/11/2022 23:09:06 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=112
06/11/2022 23:09:11 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=114
06/11/2022 23:09:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=117
06/11/2022 23:09:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/11/2022 23:09:24 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=122
06/11/2022 23:09:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=124
06/11/2022 23:09:31 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=124
06/11/2022 23:09:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=127
06/11/2022 23:09:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/11/2022 23:09:45 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=132
06/11/2022 23:09:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=134
06/11/2022 23:09:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=137
06/11/2022 23:09:57 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.47885474126608885 on epoch=137
06/11/2022 23:09:57 - INFO - __main__ - Saving model with best Classification-F1: 0.3671451355661882 -> 0.47885474126608885 on epoch=137, global_step=550
06/11/2022 23:10:01 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=139
06/11/2022 23:10:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=142
06/11/2022 23:10:10 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=144
06/11/2022 23:10:15 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=147
06/11/2022 23:10:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=149
06/11/2022 23:10:22 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.41075141075141075 on epoch=149
06/11/2022 23:10:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=152
06/11/2022 23:10:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=154
06/11/2022 23:10:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=157
06/11/2022 23:10:40 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=159
06/11/2022 23:10:45 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=162
06/11/2022 23:10:48 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=162
06/11/2022 23:10:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=164
06/11/2022 23:10:57 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=167
06/11/2022 23:11:01 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=169
06/11/2022 23:11:06 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=172
06/11/2022 23:11:10 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=174
06/11/2022 23:11:13 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.25532370251471376 on epoch=174
06/11/2022 23:11:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=177
06/11/2022 23:11:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=179
06/11/2022 23:11:27 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=182
06/11/2022 23:11:31 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=184
06/11/2022 23:11:36 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=187
06/11/2022 23:11:39 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.6085148030340103 on epoch=187
06/11/2022 23:11:39 - INFO - __main__ - Saving model with best Classification-F1: 0.47885474126608885 -> 0.6085148030340103 on epoch=187, global_step=750
06/11/2022 23:11:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=189
06/11/2022 23:11:48 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=192
06/11/2022 23:11:53 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=194
06/11/2022 23:11:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=197
06/11/2022 23:12:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=199
06/11/2022 23:12:04 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.2726775956284153 on epoch=199
06/11/2022 23:12:09 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=202
06/11/2022 23:12:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=204
06/11/2022 23:12:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=207
06/11/2022 23:12:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=209
06/11/2022 23:12:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=212
06/11/2022 23:12:30 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.5780219780219781 on epoch=212
06/11/2022 23:12:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=214
06/11/2022 23:12:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=217
06/11/2022 23:12:43 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=219
06/11/2022 23:12:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=222
06/11/2022 23:12:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=224
06/11/2022 23:12:55 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.6092796092796093 on epoch=224
06/11/2022 23:12:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6085148030340103 -> 0.6092796092796093 on epoch=224, global_step=900
06/11/2022 23:13:00 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=227
06/11/2022 23:13:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=229
06/11/2022 23:13:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=232
06/11/2022 23:13:13 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=234
06/11/2022 23:13:18 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=237
06/11/2022 23:13:21 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.6405372405372406 on epoch=237
06/11/2022 23:13:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6092796092796093 -> 0.6405372405372406 on epoch=237, global_step=950
06/11/2022 23:13:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=239
06/11/2022 23:13:30 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=242
06/11/2022 23:13:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=244
06/11/2022 23:13:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=247
06/11/2022 23:13:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=249
06/11/2022 23:13:46 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.5515515515515517 on epoch=249
06/11/2022 23:13:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=252
06/11/2022 23:13:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=254
06/11/2022 23:14:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=257
06/11/2022 23:14:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=259
06/11/2022 23:14:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/11/2022 23:14:12 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.4231177094379639 on epoch=262
06/11/2022 23:14:16 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=264
06/11/2022 23:14:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=267
06/11/2022 23:14:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=269
06/11/2022 23:14:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=272
06/11/2022 23:14:34 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=274
06/11/2022 23:14:37 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.6216748768472906 on epoch=274
06/11/2022 23:14:42 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=277
06/11/2022 23:14:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=279
06/11/2022 23:14:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/11/2022 23:14:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=284
06/11/2022 23:15:00 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/11/2022 23:15:03 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.6559139784946237 on epoch=287
06/11/2022 23:15:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6405372405372406 -> 0.6559139784946237 on epoch=287, global_step=1150
06/11/2022 23:15:08 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=289
06/11/2022 23:15:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/11/2022 23:15:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/11/2022 23:15:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=297
06/11/2022 23:15:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/11/2022 23:15:29 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.5921568627450979 on epoch=299
06/11/2022 23:15:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=302
06/11/2022 23:15:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=304
06/11/2022 23:15:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/11/2022 23:15:47 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=309
06/11/2022 23:15:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/11/2022 23:15:54 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.5620723362658846 on epoch=312
06/11/2022 23:15:59 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/11/2022 23:16:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
06/11/2022 23:16:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
06/11/2022 23:16:13 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=322
06/11/2022 23:16:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=324
06/11/2022 23:16:20 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.5933528836754642 on epoch=324
06/11/2022 23:16:24 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=327
06/11/2022 23:16:29 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/11/2022 23:16:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=332
06/11/2022 23:16:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/11/2022 23:16:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=337
06/11/2022 23:16:45 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.5901477832512315 on epoch=337
06/11/2022 23:16:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=339
06/11/2022 23:16:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
06/11/2022 23:16:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/11/2022 23:17:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/11/2022 23:17:08 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=349
06/11/2022 23:17:11 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.5755342667649226 on epoch=349
06/11/2022 23:17:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/11/2022 23:17:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/11/2022 23:17:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/11/2022 23:17:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/11/2022 23:17:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=362
06/11/2022 23:17:36 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.5307917888563051 on epoch=362
06/11/2022 23:17:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/11/2022 23:17:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=367
06/11/2022 23:17:49 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=369
06/11/2022 23:17:54 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=372
06/11/2022 23:17:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/11/2022 23:18:01 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.5755342667649226 on epoch=374
06/11/2022 23:18:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/11/2022 23:18:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
06/11/2022 23:18:15 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/11/2022 23:18:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/11/2022 23:18:24 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/11/2022 23:18:27 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.5599694423223835 on epoch=387
06/11/2022 23:18:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=389
06/11/2022 23:18:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/11/2022 23:18:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/11/2022 23:18:45 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
06/11/2022 23:18:49 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/11/2022 23:18:52 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.5307917888563051 on epoch=399
06/11/2022 23:18:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/11/2022 23:19:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/11/2022 23:19:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/11/2022 23:19:10 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/11/2022 23:19:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/11/2022 23:19:17 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.5696139476961395 on epoch=412
06/11/2022 23:19:22 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/11/2022 23:19:26 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/11/2022 23:19:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/11/2022 23:19:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/11/2022 23:19:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/11/2022 23:19:42 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.5555555555555556 on epoch=424
06/11/2022 23:19:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/11/2022 23:19:51 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/11/2022 23:19:56 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/11/2022 23:20:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/11/2022 23:20:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/11/2022 23:20:07 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.5413886829750433 on epoch=437
06/11/2022 23:20:12 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/11/2022 23:20:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/11/2022 23:20:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/11/2022 23:20:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=447
06/11/2022 23:20:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
06/11/2022 23:20:33 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.5273745861981156 on epoch=449
06/11/2022 23:20:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=452
06/11/2022 23:20:42 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/11/2022 23:20:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/11/2022 23:20:51 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/11/2022 23:20:55 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/11/2022 23:20:58 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6069761729304839 on epoch=462
06/11/2022 23:21:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/11/2022 23:21:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/11/2022 23:21:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/11/2022 23:21:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/11/2022 23:21:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/11/2022 23:21:23 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.4947797300738477 on epoch=474
06/11/2022 23:21:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/11/2022 23:21:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/11/2022 23:21:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/11/2022 23:21:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/11/2022 23:21:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/11/2022 23:21:48 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.5901477832512315 on epoch=487
06/11/2022 23:21:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/11/2022 23:21:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/11/2022 23:22:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/11/2022 23:22:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/11/2022 23:22:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/11/2022 23:22:14 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.577195987276731 on epoch=499
06/11/2022 23:22:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/11/2022 23:22:23 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/11/2022 23:22:27 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/11/2022 23:22:32 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/11/2022 23:22:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/11/2022 23:22:39 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.5780219780219781 on epoch=512
06/11/2022 23:22:43 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/11/2022 23:22:48 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/11/2022 23:22:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/11/2022 23:22:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/11/2022 23:23:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/11/2022 23:23:04 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.5413886829750433 on epoch=524
06/11/2022 23:23:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=527
06/11/2022 23:23:13 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/11/2022 23:23:18 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/11/2022 23:23:22 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/11/2022 23:23:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/11/2022 23:23:30 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.5755342667649226 on epoch=537
06/11/2022 23:23:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/11/2022 23:23:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/11/2022 23:23:43 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/11/2022 23:23:48 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/11/2022 23:23:52 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/11/2022 23:23:55 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.5273745861981156 on epoch=549
06/11/2022 23:23:59 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/11/2022 23:24:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=554
06/11/2022 23:24:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/11/2022 23:24:13 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/11/2022 23:24:17 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=562
06/11/2022 23:24:20 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6069761729304839 on epoch=562
06/11/2022 23:24:25 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/11/2022 23:24:29 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/11/2022 23:24:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/11/2022 23:24:38 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/11/2022 23:24:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/11/2022 23:24:45 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.59375 on epoch=574
06/11/2022 23:24:50 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/11/2022 23:24:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/11/2022 23:24:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/11/2022 23:25:03 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/11/2022 23:25:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/11/2022 23:25:10 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.51417004048583 on epoch=587
06/11/2022 23:25:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/11/2022 23:25:20 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/11/2022 23:25:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=594
06/11/2022 23:25:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/11/2022 23:25:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/11/2022 23:25:36 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.5730170496664195 on epoch=599
06/11/2022 23:25:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/11/2022 23:25:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/11/2022 23:25:49 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=607
06/11/2022 23:25:54 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/11/2022 23:25:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/11/2022 23:26:01 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.5555555555555556 on epoch=612
06/11/2022 23:26:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/11/2022 23:26:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/11/2022 23:26:15 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/11/2022 23:26:19 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/11/2022 23:26:24 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/11/2022 23:26:27 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.5901477832512315 on epoch=624
06/11/2022 23:26:31 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/11/2022 23:26:36 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/11/2022 23:26:40 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/11/2022 23:26:45 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/11/2022 23:26:49 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/11/2022 23:26:52 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.5330817610062892 on epoch=637
06/11/2022 23:26:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/11/2022 23:27:01 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/11/2022 23:27:06 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/11/2022 23:27:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/11/2022 23:27:15 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/11/2022 23:27:17 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.5515515515515517 on epoch=649
06/11/2022 23:27:22 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/11/2022 23:27:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/11/2022 23:27:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/11/2022 23:27:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/11/2022 23:27:40 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/11/2022 23:27:43 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.577195987276731 on epoch=662
06/11/2022 23:27:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/11/2022 23:27:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/11/2022 23:27:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/11/2022 23:28:01 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/11/2022 23:28:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/11/2022 23:28:08 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.5780219780219781 on epoch=674
06/11/2022 23:28:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/11/2022 23:28:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/11/2022 23:28:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/11/2022 23:28:26 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/11/2022 23:28:31 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/11/2022 23:28:33 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.5933528836754642 on epoch=687
06/11/2022 23:28:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/11/2022 23:28:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/11/2022 23:28:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/11/2022 23:28:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/11/2022 23:28:56 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/11/2022 23:28:58 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.5515515515515517 on epoch=699
06/11/2022 23:29:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/11/2022 23:29:08 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/11/2022 23:29:12 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/11/2022 23:29:17 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/11/2022 23:29:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/11/2022 23:29:24 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.4947797300738477 on epoch=712
06/11/2022 23:29:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/11/2022 23:29:33 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/11/2022 23:29:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/11/2022 23:29:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/11/2022 23:29:46 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/11/2022 23:29:49 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.5555555555555556 on epoch=724
06/11/2022 23:29:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/11/2022 23:29:58 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/11/2022 23:30:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/11/2022 23:30:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/11/2022 23:30:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/11/2022 23:30:14 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.48747093774218553 on epoch=737
06/11/2022 23:30:19 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/11/2022 23:30:23 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/11/2022 23:30:28 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/11/2022 23:30:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=747
06/11/2022 23:30:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/11/2022 23:30:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 23:30:38 - INFO - __main__ - Printing 3 examples
06/11/2022 23:30:38 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/11/2022 23:30:38 - INFO - __main__ - ['refuted']
06/11/2022 23:30:38 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/11/2022 23:30:38 - INFO - __main__ - ['refuted']
06/11/2022 23:30:38 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/11/2022 23:30:38 - INFO - __main__ - ['refuted']
06/11/2022 23:30:38 - INFO - __main__ - Tokenizing Input ...
06/11/2022 23:30:38 - INFO - __main__ - Tokenizing Output ...
06/11/2022 23:30:39 - INFO - __main__ - Loaded 64 examples from train data
06/11/2022 23:30:39 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 23:30:39 - INFO - __main__ - Printing 3 examples
06/11/2022 23:30:39 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/11/2022 23:30:39 - INFO - __main__ - ['refuted']
06/11/2022 23:30:39 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/11/2022 23:30:39 - INFO - __main__ - ['refuted']
06/11/2022 23:30:39 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/11/2022 23:30:39 - INFO - __main__ - ['refuted']
06/11/2022 23:30:39 - INFO - __main__ - Tokenizing Input ...
06/11/2022 23:30:39 - INFO - __main__ - Tokenizing Output ...
06/11/2022 23:30:39 - INFO - __main__ - Loaded 64 examples from dev data
06/11/2022 23:30:40 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.51417004048583 on epoch=749
06/11/2022 23:30:40 - INFO - __main__ - save last model!
06/11/2022 23:30:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/11/2022 23:30:40 - INFO - __main__ - Start tokenizing ... 12792 instances
06/11/2022 23:30:40 - INFO - __main__ - Printing 3 examples
06/11/2022 23:30:40 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/11/2022 23:30:40 - INFO - __main__ - ['entailed']
06/11/2022 23:30:40 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/11/2022 23:30:40 - INFO - __main__ - ['entailed']
06/11/2022 23:30:40 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/11/2022 23:30:40 - INFO - __main__ - ['entailed']
06/11/2022 23:30:40 - INFO - __main__ - Tokenizing Input ...
06/11/2022 23:30:58 - INFO - __main__ - load prompt embedding from ckpt
06/11/2022 23:30:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/11/2022 23:30:58 - INFO - __main__ - Starting training!
06/11/2022 23:31:05 - INFO - __main__ - Tokenizing Output ...
06/11/2022 23:31:18 - INFO - __main__ - Loaded 12792 examples from test data
06/11/2022 23:39:38 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_100_0.2_8_predictions.txt
06/11/2022 23:39:38 - INFO - __main__ - Classification-F1 on test data: 0.4898
06/11/2022 23:39:38 - INFO - __main__ - prefix=tab_fact_32_100, lr=0.2, bsz=8, dev_performance=0.6559139784946237, test_performance=0.4897792059280772
06/11/2022 23:39:38 - INFO - __main__ - Running ... prefix=tab_fact_32_13, lr=0.5, bsz=8 ...
06/11/2022 23:39:39 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 23:39:39 - INFO - __main__ - Printing 3 examples
06/11/2022 23:39:39 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/11/2022 23:39:39 - INFO - __main__ - ['refuted']
06/11/2022 23:39:39 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/11/2022 23:39:39 - INFO - __main__ - ['refuted']
06/11/2022 23:39:39 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/11/2022 23:39:39 - INFO - __main__ - ['refuted']
06/11/2022 23:39:39 - INFO - __main__ - Tokenizing Input ...
06/11/2022 23:39:39 - INFO - __main__ - Tokenizing Output ...
06/11/2022 23:39:39 - INFO - __main__ - Loaded 64 examples from train data
06/11/2022 23:39:39 - INFO - __main__ - Start tokenizing ... 64 instances
06/11/2022 23:39:39 - INFO - __main__ - Printing 3 examples
06/11/2022 23:39:39 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/11/2022 23:39:39 - INFO - __main__ - ['refuted']
06/11/2022 23:39:39 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/11/2022 23:39:39 - INFO - __main__ - ['refuted']
06/11/2022 23:39:39 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/11/2022 23:39:39 - INFO - __main__ - ['refuted']
06/11/2022 23:39:39 - INFO - __main__ - Tokenizing Input ...
06/11/2022 23:39:39 - INFO - __main__ - Tokenizing Output ...
06/11/2022 23:39:39 - INFO - __main__ - Loaded 64 examples from dev data
06/11/2022 23:39:54 - INFO - __main__ - load prompt embedding from ckpt
06/11/2022 23:39:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/11/2022 23:39:55 - INFO - __main__ - Starting training!
06/11/2022 23:40:00 - INFO - __main__ - Step 10 Global step 10 Train loss 2.51 on epoch=2
06/11/2022 23:40:05 - INFO - __main__ - Step 20 Global step 20 Train loss 0.59 on epoch=4
06/11/2022 23:40:09 - INFO - __main__ - Step 30 Global step 30 Train loss 0.38 on epoch=7
06/11/2022 23:40:14 - INFO - __main__ - Step 40 Global step 40 Train loss 0.35 on epoch=9
06/11/2022 23:40:18 - INFO - __main__ - Step 50 Global step 50 Train loss 0.27 on epoch=12
06/11/2022 23:40:21 - INFO - __main__ - Global step 50 Train loss 0.82 Classification-F1 0.3333333333333333 on epoch=12
06/11/2022 23:40:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/11/2022 23:40:25 - INFO - __main__ - Step 60 Global step 60 Train loss 0.27 on epoch=14
06/11/2022 23:40:30 - INFO - __main__ - Step 70 Global step 70 Train loss 0.30 on epoch=17
06/11/2022 23:40:34 - INFO - __main__ - Step 80 Global step 80 Train loss 0.28 on epoch=19
06/11/2022 23:40:39 - INFO - __main__ - Step 90 Global step 90 Train loss 2.15 on epoch=22
06/11/2022 23:40:43 - INFO - __main__ - Step 100 Global step 100 Train loss 0.90 on epoch=24
06/11/2022 23:40:46 - INFO - __main__ - Global step 100 Train loss 0.78 Classification-F1 0.3333333333333333 on epoch=24
06/11/2022 23:40:50 - INFO - __main__ - Step 110 Global step 110 Train loss 0.30 on epoch=27
06/11/2022 23:40:55 - INFO - __main__ - Step 120 Global step 120 Train loss 0.29 on epoch=29
06/11/2022 23:40:59 - INFO - __main__ - Step 130 Global step 130 Train loss 0.26 on epoch=32
06/11/2022 23:41:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.30 on epoch=34
06/11/2022 23:41:08 - INFO - __main__ - Step 150 Global step 150 Train loss 0.28 on epoch=37
06/11/2022 23:41:11 - INFO - __main__ - Global step 150 Train loss 0.29 Classification-F1 0.3333333333333333 on epoch=37
06/11/2022 23:41:15 - INFO - __main__ - Step 160 Global step 160 Train loss 0.26 on epoch=39
06/11/2022 23:41:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.27 on epoch=42
06/11/2022 23:41:24 - INFO - __main__ - Step 180 Global step 180 Train loss 0.25 on epoch=44
06/11/2022 23:41:29 - INFO - __main__ - Step 190 Global step 190 Train loss 0.28 on epoch=47
06/11/2022 23:41:33 - INFO - __main__ - Step 200 Global step 200 Train loss 0.25 on epoch=49
06/11/2022 23:41:36 - INFO - __main__ - Global step 200 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=49
06/11/2022 23:41:40 - INFO - __main__ - Step 210 Global step 210 Train loss 0.29 on epoch=52
06/11/2022 23:41:45 - INFO - __main__ - Step 220 Global step 220 Train loss 0.30 on epoch=54
06/11/2022 23:41:49 - INFO - __main__ - Step 230 Global step 230 Train loss 0.23 on epoch=57
06/11/2022 23:41:54 - INFO - __main__ - Step 240 Global step 240 Train loss 0.25 on epoch=59
06/11/2022 23:41:58 - INFO - __main__ - Step 250 Global step 250 Train loss 0.26 on epoch=62
06/11/2022 23:42:01 - INFO - __main__ - Global step 250 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=62
06/11/2022 23:42:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.24 on epoch=64
06/11/2022 23:42:10 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=67
06/11/2022 23:42:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=69
06/11/2022 23:42:19 - INFO - __main__ - Step 290 Global step 290 Train loss 0.27 on epoch=72
06/11/2022 23:42:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=74
06/11/2022 23:42:26 - INFO - __main__ - Global step 300 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=74
06/11/2022 23:42:30 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=77
06/11/2022 23:42:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=79
06/11/2022 23:42:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/11/2022 23:42:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=84
06/11/2022 23:42:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=87
06/11/2022 23:42:51 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=87
06/11/2022 23:42:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=89
06/11/2022 23:42:59 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=92
06/11/2022 23:43:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=94
06/11/2022 23:43:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=97
06/11/2022 23:43:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=99
06/11/2022 23:43:16 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=99
06/11/2022 23:43:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=102
06/11/2022 23:43:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=104
06/11/2022 23:43:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.26 on epoch=107
06/11/2022 23:43:33 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=109
06/11/2022 23:43:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=112
06/11/2022 23:43:40 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=112
06/11/2022 23:43:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=114
06/11/2022 23:43:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=117
06/11/2022 23:43:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=119
06/11/2022 23:43:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=122
06/11/2022 23:44:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
06/11/2022 23:44:05 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=124
06/11/2022 23:44:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=127
06/11/2022 23:44:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=129
06/11/2022 23:44:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=132
06/11/2022 23:44:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=134
06/11/2022 23:44:28 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=137
06/11/2022 23:44:31 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=137
06/11/2022 23:44:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=139
06/11/2022 23:44:40 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=142
06/11/2022 23:44:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/11/2022 23:44:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=147
06/11/2022 23:44:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=149
06/11/2022 23:44:56 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=149
06/11/2022 23:45:00 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=152
06/11/2022 23:45:05 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=154
06/11/2022 23:45:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=157
06/11/2022 23:45:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/11/2022 23:45:18 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=162
06/11/2022 23:45:21 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=162
06/11/2022 23:45:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=164
06/11/2022 23:45:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
06/11/2022 23:45:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=169
06/11/2022 23:45:39 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=172
06/11/2022 23:45:44 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=174
06/11/2022 23:45:47 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.3671451355661882 on epoch=174
06/11/2022 23:45:47 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.3671451355661882 on epoch=174, global_step=700
06/11/2022 23:45:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=177
06/11/2022 23:45:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=179
06/11/2022 23:46:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=182
06/11/2022 23:46:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.24 on epoch=184
06/11/2022 23:46:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=187
06/11/2022 23:46:12 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=187
06/11/2022 23:46:16 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=189
06/11/2022 23:46:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=192
06/11/2022 23:46:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=194
06/11/2022 23:46:30 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=197
06/11/2022 23:46:34 - INFO - __main__ - Step 800 Global step 800 Train loss 0.24 on epoch=199
06/11/2022 23:46:37 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.3591989987484355 on epoch=199
06/11/2022 23:46:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=202
06/11/2022 23:46:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=204
06/11/2022 23:46:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=207
06/11/2022 23:46:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=209
06/11/2022 23:46:59 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=212
06/11/2022 23:47:02 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.32631578947368417 on epoch=212
06/11/2022 23:47:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.21 on epoch=214
06/11/2022 23:47:11 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=217
06/11/2022 23:47:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=219
06/11/2022 23:47:20 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=222
06/11/2022 23:47:24 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=224
06/11/2022 23:47:27 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.39047619047619053 on epoch=224
06/11/2022 23:47:27 - INFO - __main__ - Saving model with best Classification-F1: 0.3671451355661882 -> 0.39047619047619053 on epoch=224, global_step=900
06/11/2022 23:47:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=227
06/11/2022 23:47:36 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=229
06/11/2022 23:47:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=232
06/11/2022 23:47:45 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=234
06/11/2022 23:47:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.23 on epoch=237
06/11/2022 23:47:52 - INFO - __main__ - Global step 950 Train loss 0.21 Classification-F1 0.3591989987484355 on epoch=237
06/11/2022 23:47:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=239
06/11/2022 23:48:01 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=242
06/11/2022 23:48:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.20 on epoch=244
06/11/2022 23:48:10 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=247
06/11/2022 23:48:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.19 on epoch=249
06/11/2022 23:48:17 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.3591989987484355 on epoch=249
06/11/2022 23:48:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.20 on epoch=252
06/11/2022 23:48:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.21 on epoch=254
06/11/2022 23:48:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=257
06/11/2022 23:48:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.20 on epoch=259
06/11/2022 23:48:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=262
06/11/2022 23:48:42 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.3591989987484355 on epoch=262
06/11/2022 23:48:46 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=264
06/11/2022 23:48:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=267
06/11/2022 23:48:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.21 on epoch=269
06/11/2022 23:49:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.18 on epoch=272
06/11/2022 23:49:04 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=274
06/11/2022 23:49:07 - INFO - __main__ - Global step 1100 Train loss 0.18 Classification-F1 0.32631578947368417 on epoch=274
06/11/2022 23:49:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.20 on epoch=277
06/11/2022 23:49:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.19 on epoch=279
06/11/2022 23:49:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=282
06/11/2022 23:49:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.17 on epoch=284
06/11/2022 23:49:29 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=287
06/11/2022 23:49:32 - INFO - __main__ - Global step 1150 Train loss 0.19 Classification-F1 0.3591989987484355 on epoch=287
06/11/2022 23:49:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.19 on epoch=289
06/11/2022 23:49:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.17 on epoch=292
06/11/2022 23:49:46 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.20 on epoch=294
06/11/2022 23:49:50 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.18 on epoch=297
06/11/2022 23:49:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.17 on epoch=299
06/11/2022 23:49:57 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.3591989987484355 on epoch=299
06/11/2022 23:50:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=302
06/11/2022 23:50:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.20 on epoch=304
06/11/2022 23:50:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=307
06/11/2022 23:50:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.20 on epoch=309
06/11/2022 23:50:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=312
06/11/2022 23:50:22 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.3591989987484355 on epoch=312
06/11/2022 23:50:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=314
06/11/2022 23:50:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=317
06/11/2022 23:50:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=319
06/11/2022 23:50:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=322
06/11/2022 23:50:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.18 on epoch=324
06/11/2022 23:50:47 - INFO - __main__ - Global step 1300 Train loss 0.16 Classification-F1 0.4995112414467253 on epoch=324
06/11/2022 23:50:48 - INFO - __main__ - Saving model with best Classification-F1: 0.39047619047619053 -> 0.4995112414467253 on epoch=324, global_step=1300
06/11/2022 23:50:52 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=327
06/11/2022 23:50:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=329
06/11/2022 23:51:01 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=332
06/11/2022 23:51:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=334
06/11/2022 23:51:10 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.17 on epoch=337
06/11/2022 23:51:13 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.39047619047619053 on epoch=337
06/11/2022 23:51:17 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=339
06/11/2022 23:51:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=342
06/11/2022 23:51:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=344
06/11/2022 23:51:30 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=347
06/11/2022 23:51:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=349
06/11/2022 23:51:38 - INFO - __main__ - Global step 1400 Train loss 0.15 Classification-F1 0.34547008547008545 on epoch=349
06/11/2022 23:51:42 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=352
06/11/2022 23:51:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.16 on epoch=354
06/11/2022 23:51:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=357
06/11/2022 23:51:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=359
06/11/2022 23:52:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=362
06/11/2022 23:52:03 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.17481808971170676 on epoch=362
06/11/2022 23:52:08 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=364
06/11/2022 23:52:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=367
06/11/2022 23:52:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.13 on epoch=369
06/11/2022 23:52:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=372
06/11/2022 23:52:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=374
06/11/2022 23:52:28 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.503078982597055 on epoch=374
06/11/2022 23:52:28 - INFO - __main__ - Saving model with best Classification-F1: 0.4995112414467253 -> 0.503078982597055 on epoch=374, global_step=1500
06/11/2022 23:52:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=377
06/11/2022 23:52:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=379
06/11/2022 23:52:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=382
06/11/2022 23:52:46 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=384
06/11/2022 23:52:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=387
06/11/2022 23:52:53 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.22608695652173913 on epoch=387
06/11/2022 23:52:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.14 on epoch=389
06/11/2022 23:53:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=392
06/11/2022 23:53:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=394
06/11/2022 23:53:11 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=397
06/11/2022 23:53:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=399
06/11/2022 23:53:19 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.34547008547008545 on epoch=399
06/11/2022 23:53:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=402
06/11/2022 23:53:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=404
06/11/2022 23:53:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=407
06/11/2022 23:53:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=409
06/11/2022 23:53:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=412
06/11/2022 23:53:44 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.25297242600556535 on epoch=412
06/11/2022 23:53:49 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=414
06/11/2022 23:53:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=417
06/11/2022 23:53:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=419
06/11/2022 23:54:02 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=422
06/11/2022 23:54:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=424
06/11/2022 23:54:09 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.2906031385895254 on epoch=424
06/11/2022 23:54:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=427
06/11/2022 23:54:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=429
06/11/2022 23:54:23 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=432
06/11/2022 23:54:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=434
06/11/2022 23:54:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=437
06/11/2022 23:54:35 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.269609079445145 on epoch=437
06/11/2022 23:54:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=439
06/11/2022 23:54:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=442
06/11/2022 23:54:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=444
06/11/2022 23:54:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=447
06/11/2022 23:54:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=449
06/11/2022 23:55:00 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.2625 on epoch=449
06/11/2022 23:55:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=452
06/11/2022 23:55:09 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.11 on epoch=454
06/11/2022 23:55:14 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
06/11/2022 23:55:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=459
06/11/2022 23:55:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=462
06/11/2022 23:55:25 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.5145583557621727 on epoch=462
06/11/2022 23:55:25 - INFO - __main__ - Saving model with best Classification-F1: 0.503078982597055 -> 0.5145583557621727 on epoch=462, global_step=1850
06/11/2022 23:55:30 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=464
06/11/2022 23:55:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/11/2022 23:55:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/11/2022 23:55:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=472
06/11/2022 23:55:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=474
06/11/2022 23:55:51 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.5405128205128205 on epoch=474
06/11/2022 23:55:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5145583557621727 -> 0.5405128205128205 on epoch=474, global_step=1900
06/11/2022 23:55:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=477
06/11/2022 23:56:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=479
06/11/2022 23:56:04 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=482
06/11/2022 23:56:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/11/2022 23:56:13 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=487
06/11/2022 23:56:16 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.3346600331674958 on epoch=487
06/11/2022 23:56:20 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=489
06/11/2022 23:56:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/11/2022 23:56:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=494
06/11/2022 23:56:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/11/2022 23:56:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=499
06/11/2022 23:56:41 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.37543859649122807 on epoch=499
06/11/2022 23:56:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=502
06/11/2022 23:56:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=504
06/11/2022 23:56:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/11/2022 23:56:59 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/11/2022 23:57:03 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=512
06/11/2022 23:57:06 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.32170334585793525 on epoch=512
06/11/2022 23:57:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=514
06/11/2022 23:57:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/11/2022 23:57:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/11/2022 23:57:24 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=522
06/11/2022 23:57:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=524
06/11/2022 23:57:31 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.5515515515515517 on epoch=524
06/11/2022 23:57:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5405128205128205 -> 0.5515515515515517 on epoch=524, global_step=2100
06/11/2022 23:57:35 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=527
06/11/2022 23:57:40 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/11/2022 23:57:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/11/2022 23:57:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/11/2022 23:57:53 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/11/2022 23:57:56 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.5780219780219781 on epoch=537
06/11/2022 23:57:56 - INFO - __main__ - Saving model with best Classification-F1: 0.5515515515515517 -> 0.5780219780219781 on epoch=537, global_step=2150
06/11/2022 23:58:01 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=539
06/11/2022 23:58:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/11/2022 23:58:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/11/2022 23:58:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=547
06/11/2022 23:58:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/11/2022 23:58:21 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.53125 on epoch=549
06/11/2022 23:58:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/11/2022 23:58:30 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/11/2022 23:58:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=557
06/11/2022 23:58:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/11/2022 23:58:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=562
06/11/2022 23:58:46 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.3720213064199608 on epoch=562
06/11/2022 23:58:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=564
06/11/2022 23:58:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=567
06/11/2022 23:59:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/11/2022 23:59:04 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/11/2022 23:59:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/11/2022 23:59:12 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.500880503144654 on epoch=574
06/11/2022 23:59:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/11/2022 23:59:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=579
06/11/2022 23:59:25 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/11/2022 23:59:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/11/2022 23:59:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/11/2022 23:59:37 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.3425229741019214 on epoch=587
06/11/2022 23:59:42 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/11/2022 23:59:46 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/11/2022 23:59:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/11/2022 23:59:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=597
06/11/2022 23:59:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/12/2022 00:00:02 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.3923168451470338 on epoch=599
06/12/2022 00:00:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=602
06/12/2022 00:00:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/12/2022 00:00:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=607
06/12/2022 00:00:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/12/2022 00:00:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/12/2022 00:00:27 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.5270935960591133 on epoch=612
06/12/2022 00:00:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/12/2022 00:00:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/12/2022 00:00:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/12/2022 00:00:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/12/2022 00:00:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=624
06/12/2022 00:00:53 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.47885474126608885 on epoch=624
06/12/2022 00:00:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/12/2022 00:01:02 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/12/2022 00:01:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/12/2022 00:01:11 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=634
06/12/2022 00:01:15 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/12/2022 00:01:18 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.3614070691696263 on epoch=637
06/12/2022 00:01:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/12/2022 00:01:27 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/12/2022 00:01:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/12/2022 00:01:36 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/12/2022 00:01:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/12/2022 00:01:43 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.5076923076923077 on epoch=649
06/12/2022 00:01:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/12/2022 00:01:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/12/2022 00:01:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/12/2022 00:02:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/12/2022 00:02:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/12/2022 00:02:08 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.34446660019940184 on epoch=662
06/12/2022 00:02:13 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/12/2022 00:02:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/12/2022 00:02:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/12/2022 00:02:26 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=672
06/12/2022 00:02:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/12/2022 00:02:34 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.33300016658337495 on epoch=674
06/12/2022 00:02:38 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=677
06/12/2022 00:02:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/12/2022 00:02:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/12/2022 00:02:51 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/12/2022 00:02:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/12/2022 00:02:58 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.5333333333333333 on epoch=687
06/12/2022 00:03:03 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/12/2022 00:03:07 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/12/2022 00:03:12 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/12/2022 00:03:16 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/12/2022 00:03:21 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/12/2022 00:03:24 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.363849765258216 on epoch=699
06/12/2022 00:03:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/12/2022 00:03:33 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/12/2022 00:03:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/12/2022 00:03:42 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/12/2022 00:03:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/12/2022 00:03:49 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.5270935960591133 on epoch=712
06/12/2022 00:03:54 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/12/2022 00:03:58 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/12/2022 00:04:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/12/2022 00:04:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/12/2022 00:04:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/12/2022 00:04:14 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.5273745861981156 on epoch=724
06/12/2022 00:04:19 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/12/2022 00:04:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/12/2022 00:04:28 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/12/2022 00:04:32 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/12/2022 00:04:36 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/12/2022 00:04:39 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.3242753623188406 on epoch=737
06/12/2022 00:04:44 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/12/2022 00:04:48 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/12/2022 00:04:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/12/2022 00:04:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/12/2022 00:05:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/12/2022 00:05:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 00:05:03 - INFO - __main__ - Printing 3 examples
06/12/2022 00:05:03 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/12/2022 00:05:03 - INFO - __main__ - ['refuted']
06/12/2022 00:05:03 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/12/2022 00:05:03 - INFO - __main__ - ['refuted']
06/12/2022 00:05:03 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/12/2022 00:05:03 - INFO - __main__ - ['refuted']
06/12/2022 00:05:03 - INFO - __main__ - Tokenizing Input ...
06/12/2022 00:05:03 - INFO - __main__ - Tokenizing Output ...
06/12/2022 00:05:03 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 00:05:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 00:05:03 - INFO - __main__ - Printing 3 examples
06/12/2022 00:05:03 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/12/2022 00:05:03 - INFO - __main__ - ['refuted']
06/12/2022 00:05:03 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/12/2022 00:05:03 - INFO - __main__ - ['refuted']
06/12/2022 00:05:03 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/12/2022 00:05:03 - INFO - __main__ - ['refuted']
06/12/2022 00:05:03 - INFO - __main__ - Tokenizing Input ...
06/12/2022 00:05:03 - INFO - __main__ - Tokenizing Output ...
06/12/2022 00:05:03 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 00:05:04 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.37543859649122807 on epoch=749
06/12/2022 00:05:04 - INFO - __main__ - save last model!
06/12/2022 00:05:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 00:05:04 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 00:05:04 - INFO - __main__ - Printing 3 examples
06/12/2022 00:05:04 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 00:05:04 - INFO - __main__ - ['entailed']
06/12/2022 00:05:04 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 00:05:04 - INFO - __main__ - ['entailed']
06/12/2022 00:05:04 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 00:05:04 - INFO - __main__ - ['entailed']
06/12/2022 00:05:04 - INFO - __main__ - Tokenizing Input ...
06/12/2022 00:05:19 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 00:05:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 00:05:19 - INFO - __main__ - Starting training!
06/12/2022 00:05:29 - INFO - __main__ - Tokenizing Output ...
06/12/2022 00:05:42 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 00:14:31 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_13_0.5_8_predictions.txt
06/12/2022 00:14:31 - INFO - __main__ - Classification-F1 on test data: 0.0346
06/12/2022 00:14:31 - INFO - __main__ - prefix=tab_fact_32_13, lr=0.5, bsz=8, dev_performance=0.5780219780219781, test_performance=0.034576181992339396
06/12/2022 00:14:31 - INFO - __main__ - Running ... prefix=tab_fact_32_13, lr=0.4, bsz=8 ...
06/12/2022 00:14:32 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 00:14:32 - INFO - __main__ - Printing 3 examples
06/12/2022 00:14:32 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/12/2022 00:14:32 - INFO - __main__ - ['refuted']
06/12/2022 00:14:32 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/12/2022 00:14:32 - INFO - __main__ - ['refuted']
06/12/2022 00:14:32 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/12/2022 00:14:32 - INFO - __main__ - ['refuted']
06/12/2022 00:14:32 - INFO - __main__ - Tokenizing Input ...
06/12/2022 00:14:32 - INFO - __main__ - Tokenizing Output ...
06/12/2022 00:14:32 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 00:14:32 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 00:14:32 - INFO - __main__ - Printing 3 examples
06/12/2022 00:14:32 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/12/2022 00:14:32 - INFO - __main__ - ['refuted']
06/12/2022 00:14:32 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/12/2022 00:14:32 - INFO - __main__ - ['refuted']
06/12/2022 00:14:32 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/12/2022 00:14:32 - INFO - __main__ - ['refuted']
06/12/2022 00:14:32 - INFO - __main__ - Tokenizing Input ...
06/12/2022 00:14:32 - INFO - __main__ - Tokenizing Output ...
06/12/2022 00:14:32 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 00:14:49 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 00:14:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 00:14:50 - INFO - __main__ - Starting training!
06/12/2022 00:14:55 - INFO - __main__ - Step 10 Global step 10 Train loss 2.55 on epoch=2
06/12/2022 00:14:59 - INFO - __main__ - Step 20 Global step 20 Train loss 0.57 on epoch=4
06/12/2022 00:15:04 - INFO - __main__ - Step 30 Global step 30 Train loss 1.23 on epoch=7
06/12/2022 00:15:08 - INFO - __main__ - Step 40 Global step 40 Train loss 1.32 on epoch=9
06/12/2022 00:15:13 - INFO - __main__ - Step 50 Global step 50 Train loss 0.54 on epoch=12
06/12/2022 00:15:15 - INFO - __main__ - Global step 50 Train loss 1.24 Classification-F1 0.3333333333333333 on epoch=12
06/12/2022 00:15:15 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/12/2022 00:15:20 - INFO - __main__ - Step 60 Global step 60 Train loss 0.38 on epoch=14
06/12/2022 00:15:24 - INFO - __main__ - Step 70 Global step 70 Train loss 0.37 on epoch=17
06/12/2022 00:15:29 - INFO - __main__ - Step 80 Global step 80 Train loss 0.36 on epoch=19
06/12/2022 00:15:33 - INFO - __main__ - Step 90 Global step 90 Train loss 0.36 on epoch=22
06/12/2022 00:15:38 - INFO - __main__ - Step 100 Global step 100 Train loss 0.39 on epoch=24
06/12/2022 00:15:41 - INFO - __main__ - Global step 100 Train loss 0.37 Classification-F1 0.3333333333333333 on epoch=24
06/12/2022 00:15:45 - INFO - __main__ - Step 110 Global step 110 Train loss 0.33 on epoch=27
06/12/2022 00:15:50 - INFO - __main__ - Step 120 Global step 120 Train loss 0.31 on epoch=29
06/12/2022 00:15:54 - INFO - __main__ - Step 130 Global step 130 Train loss 0.32 on epoch=32
06/12/2022 00:15:59 - INFO - __main__ - Step 140 Global step 140 Train loss 0.30 on epoch=34
06/12/2022 00:16:03 - INFO - __main__ - Step 150 Global step 150 Train loss 0.32 on epoch=37
06/12/2022 00:16:06 - INFO - __main__ - Global step 150 Train loss 0.32 Classification-F1 0.3333333333333333 on epoch=37
06/12/2022 00:16:10 - INFO - __main__ - Step 160 Global step 160 Train loss 0.31 on epoch=39
06/12/2022 00:16:15 - INFO - __main__ - Step 170 Global step 170 Train loss 0.26 on epoch=42
06/12/2022 00:16:19 - INFO - __main__ - Step 180 Global step 180 Train loss 0.29 on epoch=44
06/12/2022 00:16:24 - INFO - __main__ - Step 190 Global step 190 Train loss 0.28 on epoch=47
06/12/2022 00:16:28 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=49
06/12/2022 00:16:31 - INFO - __main__ - Global step 200 Train loss 0.28 Classification-F1 0.3333333333333333 on epoch=49
06/12/2022 00:16:35 - INFO - __main__ - Step 210 Global step 210 Train loss 0.25 on epoch=52
06/12/2022 00:16:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.27 on epoch=54
06/12/2022 00:16:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.29 on epoch=57
06/12/2022 00:16:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.26 on epoch=59
06/12/2022 00:16:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.27 on epoch=62
06/12/2022 00:16:56 - INFO - __main__ - Global step 250 Train loss 0.27 Classification-F1 0.3333333333333333 on epoch=62
06/12/2022 00:17:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.21 on epoch=64
06/12/2022 00:17:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.29 on epoch=67
06/12/2022 00:17:10 - INFO - __main__ - Step 280 Global step 280 Train loss 0.28 on epoch=69
06/12/2022 00:17:14 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=72
06/12/2022 00:17:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=74
06/12/2022 00:17:22 - INFO - __main__ - Global step 300 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=74
06/12/2022 00:17:26 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=77
06/12/2022 00:17:31 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=79
06/12/2022 00:17:35 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=82
06/12/2022 00:17:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=84
06/12/2022 00:17:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.27 on epoch=87
06/12/2022 00:17:47 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=87
06/12/2022 00:17:51 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=89
06/12/2022 00:17:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.20 on epoch=92
06/12/2022 00:18:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=94
06/12/2022 00:18:05 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/12/2022 00:18:09 - INFO - __main__ - Step 400 Global step 400 Train loss 0.24 on epoch=99
06/12/2022 00:18:12 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=99
06/12/2022 00:18:17 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=102
06/12/2022 00:18:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.25 on epoch=104
06/12/2022 00:18:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=107
06/12/2022 00:18:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=109
06/12/2022 00:18:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/12/2022 00:18:37 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=112
06/12/2022 00:18:42 - INFO - __main__ - Step 460 Global step 460 Train loss 0.19 on epoch=114
06/12/2022 00:18:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=117
06/12/2022 00:18:51 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=119
06/12/2022 00:18:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=122
06/12/2022 00:19:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=124
06/12/2022 00:19:03 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.40116959064327484 on epoch=124
06/12/2022 00:19:03 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.40116959064327484 on epoch=124, global_step=500
06/12/2022 00:19:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=127
06/12/2022 00:19:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=129
06/12/2022 00:19:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=132
06/12/2022 00:19:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=134
06/12/2022 00:19:25 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
06/12/2022 00:19:28 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.32631578947368417 on epoch=137
06/12/2022 00:19:32 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=139
06/12/2022 00:19:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=142
06/12/2022 00:19:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=144
06/12/2022 00:19:45 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=147
06/12/2022 00:19:50 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=149
06/12/2022 00:19:52 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.32631578947368417 on epoch=149
06/12/2022 00:19:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=152
06/12/2022 00:20:01 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=154
06/12/2022 00:20:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=157
06/12/2022 00:20:10 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=159
06/12/2022 00:20:15 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=162
06/12/2022 00:20:18 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.4385964912280702 on epoch=162
06/12/2022 00:20:18 - INFO - __main__ - Saving model with best Classification-F1: 0.40116959064327484 -> 0.4385964912280702 on epoch=162, global_step=650
06/12/2022 00:20:22 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=164
06/12/2022 00:20:27 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=167
06/12/2022 00:20:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.23 on epoch=169
06/12/2022 00:20:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=172
06/12/2022 00:20:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=174
06/12/2022 00:20:43 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=174
06/12/2022 00:20:47 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=177
06/12/2022 00:20:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=179
06/12/2022 00:20:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=182
06/12/2022 00:21:01 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=184
06/12/2022 00:21:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=187
06/12/2022 00:21:08 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.48051948051948057 on epoch=187
06/12/2022 00:21:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4385964912280702 -> 0.48051948051948057 on epoch=187, global_step=750
06/12/2022 00:21:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=189
06/12/2022 00:21:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=192
06/12/2022 00:21:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=194
06/12/2022 00:21:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=197
06/12/2022 00:21:31 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=199
06/12/2022 00:21:33 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.3591989987484355 on epoch=199
06/12/2022 00:21:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=202
06/12/2022 00:21:43 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=204
06/12/2022 00:21:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=207
06/12/2022 00:21:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=209
06/12/2022 00:21:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=212
06/12/2022 00:21:59 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.4181818181818182 on epoch=212
06/12/2022 00:22:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=214
06/12/2022 00:22:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=217
06/12/2022 00:22:12 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=219
06/12/2022 00:22:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.22 on epoch=222
06/12/2022 00:22:21 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=224
06/12/2022 00:22:24 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.3816425120772947 on epoch=224
06/12/2022 00:22:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=227
06/12/2022 00:22:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=229
06/12/2022 00:22:37 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=232
06/12/2022 00:22:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=234
06/12/2022 00:22:46 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=237
06/12/2022 00:22:49 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.42840679919331603 on epoch=237
06/12/2022 00:22:54 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=239
06/12/2022 00:22:58 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=242
06/12/2022 00:23:03 - INFO - __main__ - Step 980 Global step 980 Train loss 0.19 on epoch=244
06/12/2022 00:23:07 - INFO - __main__ - Step 990 Global step 990 Train loss 0.20 on epoch=247
06/12/2022 00:23:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=249
06/12/2022 00:23:15 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.5465587044534412 on epoch=249
06/12/2022 00:23:15 - INFO - __main__ - Saving model with best Classification-F1: 0.48051948051948057 -> 0.5465587044534412 on epoch=249, global_step=1000
06/12/2022 00:23:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=252
06/12/2022 00:23:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=254
06/12/2022 00:23:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=257
06/12/2022 00:23:33 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=259
06/12/2022 00:23:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.17 on epoch=262
06/12/2022 00:23:40 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.4832395400048935 on epoch=262
06/12/2022 00:23:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=264
06/12/2022 00:23:49 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=267
06/12/2022 00:23:53 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=269
06/12/2022 00:23:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=272
06/12/2022 00:24:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.20 on epoch=274
06/12/2022 00:24:05 - INFO - __main__ - Global step 1100 Train loss 0.16 Classification-F1 0.537733499377335 on epoch=274
06/12/2022 00:24:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=277
06/12/2022 00:24:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=279
06/12/2022 00:24:19 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.17 on epoch=282
06/12/2022 00:24:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=284
06/12/2022 00:24:28 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=287
06/12/2022 00:24:30 - INFO - __main__ - Global step 1150 Train loss 0.16 Classification-F1 0.4385964912280702 on epoch=287
06/12/2022 00:24:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=289
06/12/2022 00:24:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=292
06/12/2022 00:24:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=294
06/12/2022 00:24:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=297
06/12/2022 00:24:53 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=299
06/12/2022 00:24:56 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.5195195195195195 on epoch=299
06/12/2022 00:25:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=302
06/12/2022 00:25:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=304
06/12/2022 00:25:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=307
06/12/2022 00:25:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=309
06/12/2022 00:25:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=312
06/12/2022 00:25:21 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.5155067155067155 on epoch=312
06/12/2022 00:25:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=314
06/12/2022 00:25:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=317
06/12/2022 00:25:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=319
06/12/2022 00:25:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=322
06/12/2022 00:25:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=324
06/12/2022 00:25:46 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.49220246238030096 on epoch=324
06/12/2022 00:25:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=327
06/12/2022 00:25:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=329
06/12/2022 00:26:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=332
06/12/2022 00:26:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=334
06/12/2022 00:26:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=337
06/12/2022 00:26:11 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.51417004048583 on epoch=337
06/12/2022 00:26:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=339
06/12/2022 00:26:20 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/12/2022 00:26:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=344
06/12/2022 00:26:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=347
06/12/2022 00:26:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=349
06/12/2022 00:26:37 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.5330817610062892 on epoch=349
06/12/2022 00:26:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=352
06/12/2022 00:26:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=354
06/12/2022 00:26:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=357
06/12/2022 00:26:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=359
06/12/2022 00:26:59 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=362
06/12/2022 00:27:02 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.5294117647058825 on epoch=362
06/12/2022 00:27:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=364
06/12/2022 00:27:11 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=367
06/12/2022 00:27:15 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=369
06/12/2022 00:27:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=372
06/12/2022 00:27:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=374
06/12/2022 00:27:27 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.5465587044534412 on epoch=374
06/12/2022 00:27:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=377
06/12/2022 00:27:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=379
06/12/2022 00:27:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=382
06/12/2022 00:27:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/12/2022 00:27:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/12/2022 00:27:52 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.3464019851116626 on epoch=387
06/12/2022 00:27:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=389
06/12/2022 00:28:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/12/2022 00:28:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=394
06/12/2022 00:28:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=397
06/12/2022 00:28:15 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
06/12/2022 00:28:17 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.5413886829750433 on epoch=399
06/12/2022 00:28:22 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=402
06/12/2022 00:28:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
06/12/2022 00:28:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=407
06/12/2022 00:28:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=409
06/12/2022 00:28:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=412
06/12/2022 00:28:42 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.4748717948717949 on epoch=412
06/12/2022 00:28:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=414
06/12/2022 00:28:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=417
06/12/2022 00:28:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/12/2022 00:29:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/12/2022 00:29:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=424
06/12/2022 00:29:08 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.4874874874874875 on epoch=424
06/12/2022 00:29:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/12/2022 00:29:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/12/2022 00:29:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=432
06/12/2022 00:29:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/12/2022 00:29:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=437
06/12/2022 00:29:33 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.4682306940371457 on epoch=437
06/12/2022 00:29:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=439
06/12/2022 00:29:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/12/2022 00:29:46 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=444
06/12/2022 00:29:51 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
06/12/2022 00:29:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/12/2022 00:29:58 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.5586206896551724 on epoch=449
06/12/2022 00:29:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5465587044534412 -> 0.5586206896551724 on epoch=449, global_step=1800
06/12/2022 00:30:02 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/12/2022 00:30:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
06/12/2022 00:30:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/12/2022 00:30:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/12/2022 00:30:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/12/2022 00:30:23 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.5620723362658846 on epoch=462
06/12/2022 00:30:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5586206896551724 -> 0.5620723362658846 on epoch=462, global_step=1850
06/12/2022 00:30:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/12/2022 00:30:32 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/12/2022 00:30:37 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=469
06/12/2022 00:30:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=472
06/12/2022 00:30:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/12/2022 00:30:49 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.31851851851851853 on epoch=474
06/12/2022 00:30:53 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/12/2022 00:30:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/12/2022 00:31:02 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/12/2022 00:31:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=484
06/12/2022 00:31:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/12/2022 00:31:14 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.4980392156862745 on epoch=487
06/12/2022 00:31:19 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/12/2022 00:31:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/12/2022 00:31:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/12/2022 00:31:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=497
06/12/2022 00:31:37 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/12/2022 00:31:39 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.5238095238095238 on epoch=499
06/12/2022 00:31:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/12/2022 00:31:48 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/12/2022 00:31:53 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/12/2022 00:31:57 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/12/2022 00:32:02 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/12/2022 00:32:05 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.5586206896551724 on epoch=512
06/12/2022 00:32:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/12/2022 00:32:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/12/2022 00:32:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/12/2022 00:32:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/12/2022 00:32:27 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/12/2022 00:32:30 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.5607843137254902 on epoch=524
06/12/2022 00:32:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=527
06/12/2022 00:32:39 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/12/2022 00:32:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/12/2022 00:32:48 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/12/2022 00:32:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=537
06/12/2022 00:32:55 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.5155067155067155 on epoch=537
06/12/2022 00:32:59 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/12/2022 00:33:04 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/12/2022 00:33:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/12/2022 00:33:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/12/2022 00:33:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/12/2022 00:33:20 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.5440923605993613 on epoch=549
06/12/2022 00:33:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/12/2022 00:33:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/12/2022 00:33:34 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/12/2022 00:33:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/12/2022 00:33:43 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/12/2022 00:33:46 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.5730170496664195 on epoch=562
06/12/2022 00:33:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5620723362658846 -> 0.5730170496664195 on epoch=562, global_step=2250
06/12/2022 00:33:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=564
06/12/2022 00:33:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/12/2022 00:34:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/12/2022 00:34:04 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/12/2022 00:34:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/12/2022 00:34:12 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.5307917888563051 on epoch=574
06/12/2022 00:34:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/12/2022 00:34:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/12/2022 00:34:25 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/12/2022 00:34:30 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/12/2022 00:34:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/12/2022 00:34:37 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.5620723362658846 on epoch=587
06/12/2022 00:34:42 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/12/2022 00:34:46 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=592
06/12/2022 00:34:51 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/12/2022 00:34:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/12/2022 00:35:00 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/12/2022 00:35:03 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.5294117647058825 on epoch=599
06/12/2022 00:35:08 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/12/2022 00:35:12 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/12/2022 00:35:17 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/12/2022 00:35:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/12/2022 00:35:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/12/2022 00:35:29 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.5126504544338 on epoch=612
06/12/2022 00:35:33 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/12/2022 00:35:38 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/12/2022 00:35:42 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/12/2022 00:35:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/12/2022 00:35:52 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/12/2022 00:35:54 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.5467643467643467 on epoch=624
06/12/2022 00:35:59 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/12/2022 00:36:03 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/12/2022 00:36:08 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/12/2022 00:36:13 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/12/2022 00:36:17 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/12/2022 00:36:20 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.53125 on epoch=637
06/12/2022 00:36:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/12/2022 00:36:29 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/12/2022 00:36:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
06/12/2022 00:36:38 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/12/2022 00:36:43 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/12/2022 00:36:46 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.577195987276731 on epoch=649
06/12/2022 00:36:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5730170496664195 -> 0.577195987276731 on epoch=649, global_step=2600
06/12/2022 00:36:50 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/12/2022 00:36:55 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/12/2022 00:36:59 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/12/2022 00:37:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/12/2022 00:37:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/12/2022 00:37:11 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.537733499377335 on epoch=662
06/12/2022 00:37:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/12/2022 00:37:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/12/2022 00:37:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/12/2022 00:37:29 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/12/2022 00:37:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/12/2022 00:37:36 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.5607843137254902 on epoch=674
06/12/2022 00:37:41 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/12/2022 00:37:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/12/2022 00:37:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/12/2022 00:37:55 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/12/2022 00:37:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/12/2022 00:38:02 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.3777115416459678 on epoch=687
06/12/2022 00:38:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/12/2022 00:38:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/12/2022 00:38:16 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/12/2022 00:38:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/12/2022 00:38:25 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/12/2022 00:38:27 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.53125 on epoch=699
06/12/2022 00:38:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/12/2022 00:38:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/12/2022 00:38:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/12/2022 00:38:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/12/2022 00:38:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/12/2022 00:38:53 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.5413886829750433 on epoch=712
06/12/2022 00:38:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/12/2022 00:39:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/12/2022 00:39:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=719
06/12/2022 00:39:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=722
06/12/2022 00:39:15 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/12/2022 00:39:18 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.5440923605993613 on epoch=724
06/12/2022 00:39:23 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/12/2022 00:39:27 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/12/2022 00:39:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/12/2022 00:39:36 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/12/2022 00:39:41 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/12/2022 00:39:44 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.5620723362658846 on epoch=737
06/12/2022 00:39:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/12/2022 00:39:53 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/12/2022 00:39:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/12/2022 00:40:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/12/2022 00:40:06 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/12/2022 00:40:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 00:40:08 - INFO - __main__ - Printing 3 examples
06/12/2022 00:40:08 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/12/2022 00:40:08 - INFO - __main__ - ['refuted']
06/12/2022 00:40:08 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/12/2022 00:40:08 - INFO - __main__ - ['refuted']
06/12/2022 00:40:08 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/12/2022 00:40:08 - INFO - __main__ - ['refuted']
06/12/2022 00:40:08 - INFO - __main__ - Tokenizing Input ...
06/12/2022 00:40:08 - INFO - __main__ - Tokenizing Output ...
06/12/2022 00:40:08 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 00:40:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 00:40:08 - INFO - __main__ - Printing 3 examples
06/12/2022 00:40:08 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/12/2022 00:40:08 - INFO - __main__ - ['refuted']
06/12/2022 00:40:08 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/12/2022 00:40:08 - INFO - __main__ - ['refuted']
06/12/2022 00:40:08 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/12/2022 00:40:08 - INFO - __main__ - ['refuted']
06/12/2022 00:40:08 - INFO - __main__ - Tokenizing Input ...
06/12/2022 00:40:08 - INFO - __main__ - Tokenizing Output ...
06/12/2022 00:40:08 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 00:40:09 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.5620723362658846 on epoch=749
06/12/2022 00:40:09 - INFO - __main__ - save last model!
06/12/2022 00:40:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 00:40:09 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 00:40:09 - INFO - __main__ - Printing 3 examples
06/12/2022 00:40:09 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 00:40:09 - INFO - __main__ - ['entailed']
06/12/2022 00:40:09 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 00:40:09 - INFO - __main__ - ['entailed']
06/12/2022 00:40:09 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 00:40:09 - INFO - __main__ - ['entailed']
06/12/2022 00:40:09 - INFO - __main__ - Tokenizing Input ...
06/12/2022 00:40:24 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 00:40:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 00:40:24 - INFO - __main__ - Starting training!
06/12/2022 00:40:36 - INFO - __main__ - Tokenizing Output ...
06/12/2022 00:40:51 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 00:49:19 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_13_0.4_8_predictions.txt
06/12/2022 00:49:19 - INFO - __main__ - Classification-F1 on test data: 0.1233
06/12/2022 00:49:20 - INFO - __main__ - prefix=tab_fact_32_13, lr=0.4, bsz=8, dev_performance=0.577195987276731, test_performance=0.1232640210815573
06/12/2022 00:49:20 - INFO - __main__ - Running ... prefix=tab_fact_32_13, lr=0.3, bsz=8 ...
06/12/2022 00:49:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 00:49:21 - INFO - __main__ - Printing 3 examples
06/12/2022 00:49:21 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/12/2022 00:49:21 - INFO - __main__ - ['refuted']
06/12/2022 00:49:21 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/12/2022 00:49:21 - INFO - __main__ - ['refuted']
06/12/2022 00:49:21 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/12/2022 00:49:21 - INFO - __main__ - ['refuted']
06/12/2022 00:49:21 - INFO - __main__ - Tokenizing Input ...
06/12/2022 00:49:21 - INFO - __main__ - Tokenizing Output ...
06/12/2022 00:49:21 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 00:49:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 00:49:21 - INFO - __main__ - Printing 3 examples
06/12/2022 00:49:21 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/12/2022 00:49:21 - INFO - __main__ - ['refuted']
06/12/2022 00:49:21 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/12/2022 00:49:21 - INFO - __main__ - ['refuted']
06/12/2022 00:49:21 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/12/2022 00:49:21 - INFO - __main__ - ['refuted']
06/12/2022 00:49:21 - INFO - __main__ - Tokenizing Input ...
06/12/2022 00:49:21 - INFO - __main__ - Tokenizing Output ...
06/12/2022 00:49:21 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 00:49:41 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 00:49:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 00:49:42 - INFO - __main__ - Starting training!
06/12/2022 00:49:47 - INFO - __main__ - Step 10 Global step 10 Train loss 3.11 on epoch=2
06/12/2022 00:49:51 - INFO - __main__ - Step 20 Global step 20 Train loss 1.03 on epoch=4
06/12/2022 00:49:56 - INFO - __main__ - Step 30 Global step 30 Train loss 0.58 on epoch=7
06/12/2022 00:50:01 - INFO - __main__ - Step 40 Global step 40 Train loss 0.37 on epoch=9
06/12/2022 00:50:05 - INFO - __main__ - Step 50 Global step 50 Train loss 0.36 on epoch=12
06/12/2022 00:50:08 - INFO - __main__ - Global step 50 Train loss 1.09 Classification-F1 0.3333333333333333 on epoch=12
06/12/2022 00:50:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/12/2022 00:50:12 - INFO - __main__ - Step 60 Global step 60 Train loss 0.31 on epoch=14
06/12/2022 00:50:17 - INFO - __main__ - Step 70 Global step 70 Train loss 0.33 on epoch=17
06/12/2022 00:50:21 - INFO - __main__ - Step 80 Global step 80 Train loss 0.29 on epoch=19
06/12/2022 00:50:26 - INFO - __main__ - Step 90 Global step 90 Train loss 0.29 on epoch=22
06/12/2022 00:50:30 - INFO - __main__ - Step 100 Global step 100 Train loss 0.30 on epoch=24
06/12/2022 00:50:33 - INFO - __main__ - Global step 100 Train loss 0.30 Classification-F1 0.4345381526104417 on epoch=24
06/12/2022 00:50:33 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.4345381526104417 on epoch=24, global_step=100
06/12/2022 00:50:37 - INFO - __main__ - Step 110 Global step 110 Train loss 0.25 on epoch=27
06/12/2022 00:50:42 - INFO - __main__ - Step 120 Global step 120 Train loss 0.26 on epoch=29
06/12/2022 00:50:46 - INFO - __main__ - Step 130 Global step 130 Train loss 0.28 on epoch=32
06/12/2022 00:50:51 - INFO - __main__ - Step 140 Global step 140 Train loss 0.25 on epoch=34
06/12/2022 00:50:55 - INFO - __main__ - Step 150 Global step 150 Train loss 0.24 on epoch=37
06/12/2022 00:50:58 - INFO - __main__ - Global step 150 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=37
06/12/2022 00:51:02 - INFO - __main__ - Step 160 Global step 160 Train loss 0.24 on epoch=39
06/12/2022 00:51:07 - INFO - __main__ - Step 170 Global step 170 Train loss 0.26 on epoch=42
06/12/2022 00:51:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.27 on epoch=44
06/12/2022 00:51:16 - INFO - __main__ - Step 190 Global step 190 Train loss 0.21 on epoch=47
06/12/2022 00:51:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.22 on epoch=49
06/12/2022 00:51:23 - INFO - __main__ - Global step 200 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=49
06/12/2022 00:51:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.20 on epoch=52
06/12/2022 00:51:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.24 on epoch=54
06/12/2022 00:51:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.23 on epoch=57
06/12/2022 00:51:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.22 on epoch=59
06/12/2022 00:51:45 - INFO - __main__ - Step 250 Global step 250 Train loss 0.22 on epoch=62
06/12/2022 00:51:48 - INFO - __main__ - Global step 250 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=62
06/12/2022 00:51:52 - INFO - __main__ - Step 260 Global step 260 Train loss 0.29 on epoch=64
06/12/2022 00:51:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=67
06/12/2022 00:52:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.24 on epoch=69
06/12/2022 00:52:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=72
06/12/2022 00:52:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=74
06/12/2022 00:52:12 - INFO - __main__ - Global step 300 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=74
06/12/2022 00:52:17 - INFO - __main__ - Step 310 Global step 310 Train loss 0.22 on epoch=77
06/12/2022 00:52:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=79
06/12/2022 00:52:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.24 on epoch=82
06/12/2022 00:52:30 - INFO - __main__ - Step 340 Global step 340 Train loss 0.18 on epoch=84
06/12/2022 00:52:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.22 on epoch=87
06/12/2022 00:52:37 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=87
06/12/2022 00:52:42 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=89
06/12/2022 00:52:46 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=92
06/12/2022 00:52:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=94
06/12/2022 00:52:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.17 on epoch=97
06/12/2022 00:53:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=99
06/12/2022 00:53:03 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.4487674487674488 on epoch=99
06/12/2022 00:53:03 - INFO - __main__ - Saving model with best Classification-F1: 0.4345381526104417 -> 0.4487674487674488 on epoch=99, global_step=400
06/12/2022 00:53:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/12/2022 00:53:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/12/2022 00:53:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=107
06/12/2022 00:53:21 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=109
06/12/2022 00:53:25 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=112
06/12/2022 00:53:28 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=112
06/12/2022 00:53:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=114
06/12/2022 00:53:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=117
06/12/2022 00:53:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=119
06/12/2022 00:53:46 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=122
06/12/2022 00:53:51 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
06/12/2022 00:53:53 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=124
06/12/2022 00:53:58 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=127
06/12/2022 00:54:02 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=129
06/12/2022 00:54:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=132
06/12/2022 00:54:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=134
06/12/2022 00:54:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=137
06/12/2022 00:54:19 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.39047619047619053 on epoch=137
06/12/2022 00:54:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=139
06/12/2022 00:54:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=142
06/12/2022 00:54:32 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/12/2022 00:54:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=147
06/12/2022 00:54:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=149
06/12/2022 00:54:44 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.3671451355661882 on epoch=149
06/12/2022 00:54:48 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=152
06/12/2022 00:54:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=154
06/12/2022 00:54:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=157
06/12/2022 00:55:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=159
06/12/2022 00:55:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=162
06/12/2022 00:55:09 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.47885474126608885 on epoch=162
06/12/2022 00:55:09 - INFO - __main__ - Saving model with best Classification-F1: 0.4487674487674488 -> 0.47885474126608885 on epoch=162, global_step=650
06/12/2022 00:55:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=164
06/12/2022 00:55:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=167
06/12/2022 00:55:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=169
06/12/2022 00:55:27 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=172
06/12/2022 00:55:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=174
06/12/2022 00:55:35 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.39047619047619053 on epoch=174
06/12/2022 00:55:39 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=177
06/12/2022 00:55:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=179
06/12/2022 00:55:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=182
06/12/2022 00:55:53 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=184
06/12/2022 00:55:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=187
06/12/2022 00:56:00 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.464039408866995 on epoch=187
06/12/2022 00:56:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=189
06/12/2022 00:56:09 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=192
06/12/2022 00:56:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=194
06/12/2022 00:56:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=197
06/12/2022 00:56:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=199
06/12/2022 00:56:25 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.30516705516705517 on epoch=199
06/12/2022 00:56:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=202
06/12/2022 00:56:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=204
06/12/2022 00:56:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=207
06/12/2022 00:56:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=209
06/12/2022 00:56:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=212
06/12/2022 00:56:51 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.41832473593711617 on epoch=212
06/12/2022 00:56:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=214
06/12/2022 00:57:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=217
06/12/2022 00:57:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=219
06/12/2022 00:57:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=222
06/12/2022 00:57:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=224
06/12/2022 00:57:16 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.32631578947368417 on epoch=224
06/12/2022 00:57:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=227
06/12/2022 00:57:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=229
06/12/2022 00:57:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=232
06/12/2022 00:57:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=234
06/12/2022 00:57:39 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=237
06/12/2022 00:57:42 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.3324675324675324 on epoch=237
06/12/2022 00:57:46 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=239
06/12/2022 00:57:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=242
06/12/2022 00:57:55 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=244
06/12/2022 00:58:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=247
06/12/2022 00:58:04 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=249
06/12/2022 00:58:07 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.4652837798905215 on epoch=249
06/12/2022 00:58:11 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=252
06/12/2022 00:58:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=254
06/12/2022 00:58:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=257
06/12/2022 00:58:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=259
06/12/2022 00:58:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=262
06/12/2022 00:58:33 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.4812085482682388 on epoch=262
06/12/2022 00:58:33 - INFO - __main__ - Saving model with best Classification-F1: 0.47885474126608885 -> 0.4812085482682388 on epoch=262, global_step=1050
06/12/2022 00:58:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=264
06/12/2022 00:58:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=267
06/12/2022 00:58:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=269
06/12/2022 00:58:51 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=272
06/12/2022 00:58:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=274
06/12/2022 00:58:58 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.4487674487674488 on epoch=274
06/12/2022 00:59:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=277
06/12/2022 00:59:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=279
06/12/2022 00:59:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=282
06/12/2022 00:59:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=284
06/12/2022 00:59:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=287
06/12/2022 00:59:23 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.36374269005847953 on epoch=287
06/12/2022 00:59:28 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=289
06/12/2022 00:59:33 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=292
06/12/2022 00:59:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=294
06/12/2022 00:59:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=297
06/12/2022 00:59:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=299
06/12/2022 00:59:49 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.5333333333333333 on epoch=299
06/12/2022 00:59:49 - INFO - __main__ - Saving model with best Classification-F1: 0.4812085482682388 -> 0.5333333333333333 on epoch=299, global_step=1200
06/12/2022 00:59:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=302
06/12/2022 00:59:58 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=304
06/12/2022 01:00:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=307
06/12/2022 01:00:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=309
06/12/2022 01:00:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=312
06/12/2022 01:00:14 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.5195195195195195 on epoch=312
06/12/2022 01:00:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=314
06/12/2022 01:00:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=317
06/12/2022 01:00:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=319
06/12/2022 01:00:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=322
06/12/2022 01:00:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=324
06/12/2022 01:00:40 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.537733499377335 on epoch=324
06/12/2022 01:00:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5333333333333333 -> 0.537733499377335 on epoch=324, global_step=1300
06/12/2022 01:00:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=327
06/12/2022 01:00:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=329
06/12/2022 01:00:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=332
06/12/2022 01:00:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=334
06/12/2022 01:01:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=337
06/12/2022 01:01:05 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.24993597951344432 on epoch=337
06/12/2022 01:01:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=339
06/12/2022 01:01:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=342
06/12/2022 01:01:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=344
06/12/2022 01:01:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=347
06/12/2022 01:01:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=349
06/12/2022 01:01:31 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.35829059829059823 on epoch=349
06/12/2022 01:01:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=352
06/12/2022 01:01:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=354
06/12/2022 01:01:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=357
06/12/2022 01:01:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=359
06/12/2022 01:01:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=362
06/12/2022 01:01:56 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.35202020202020207 on epoch=362
06/12/2022 01:02:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=364
06/12/2022 01:02:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=367
06/12/2022 01:02:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=369
06/12/2022 01:02:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/12/2022 01:02:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=374
06/12/2022 01:02:21 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.5273745861981156 on epoch=374
06/12/2022 01:02:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=377
06/12/2022 01:02:30 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
06/12/2022 01:02:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
06/12/2022 01:02:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=384
06/12/2022 01:02:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/12/2022 01:02:46 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.5273745861981156 on epoch=387
06/12/2022 01:02:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/12/2022 01:02:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/12/2022 01:03:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=394
06/12/2022 01:03:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=397
06/12/2022 01:03:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/12/2022 01:03:12 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.35576603522765043 on epoch=399
06/12/2022 01:03:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/12/2022 01:03:21 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=404
06/12/2022 01:03:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/12/2022 01:03:30 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=409
06/12/2022 01:03:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=412
06/12/2022 01:03:37 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.3356515979466799 on epoch=412
06/12/2022 01:03:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=414
06/12/2022 01:03:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=417
06/12/2022 01:03:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/12/2022 01:03:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=422
06/12/2022 01:04:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=424
06/12/2022 01:04:03 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.5270935960591133 on epoch=424
06/12/2022 01:04:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/12/2022 01:04:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=429
06/12/2022 01:04:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=432
06/12/2022 01:04:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/12/2022 01:04:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
06/12/2022 01:04:28 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.3519450033534541 on epoch=437
06/12/2022 01:04:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/12/2022 01:04:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/12/2022 01:04:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/12/2022 01:04:46 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
06/12/2022 01:04:51 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/12/2022 01:04:54 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.36678257989733404 on epoch=449
06/12/2022 01:04:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=452
06/12/2022 01:05:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/12/2022 01:05:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
06/12/2022 01:05:12 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
06/12/2022 01:05:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/12/2022 01:05:19 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.3707292197858236 on epoch=462
06/12/2022 01:05:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/12/2022 01:05:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/12/2022 01:05:33 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=469
06/12/2022 01:05:37 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/12/2022 01:05:42 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/12/2022 01:05:45 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.2589285714285714 on epoch=474
06/12/2022 01:05:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/12/2022 01:05:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/12/2022 01:05:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/12/2022 01:06:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/12/2022 01:06:07 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/12/2022 01:06:10 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.5307917888563051 on epoch=487
06/12/2022 01:06:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/12/2022 01:06:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/12/2022 01:06:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/12/2022 01:06:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/12/2022 01:06:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/12/2022 01:06:36 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.48424908424908425 on epoch=499
06/12/2022 01:06:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/12/2022 01:06:45 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=504
06/12/2022 01:06:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/12/2022 01:06:54 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/12/2022 01:06:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=512
06/12/2022 01:07:01 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.3306397306397306 on epoch=512
06/12/2022 01:07:06 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/12/2022 01:07:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/12/2022 01:07:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/12/2022 01:07:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/12/2022 01:07:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=524
06/12/2022 01:07:27 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.5307917888563051 on epoch=524
06/12/2022 01:07:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/12/2022 01:07:36 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=529
06/12/2022 01:07:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/12/2022 01:07:46 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/12/2022 01:07:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/12/2022 01:07:53 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.3656505080792937 on epoch=537
06/12/2022 01:07:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/12/2022 01:08:02 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/12/2022 01:08:07 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/12/2022 01:08:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/12/2022 01:08:16 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/12/2022 01:08:19 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.45705196182396607 on epoch=549
06/12/2022 01:08:23 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/12/2022 01:08:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/12/2022 01:08:32 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/12/2022 01:08:37 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/12/2022 01:08:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/12/2022 01:08:44 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.35829059829059823 on epoch=562
06/12/2022 01:08:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/12/2022 01:08:54 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=567
06/12/2022 01:08:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/12/2022 01:09:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/12/2022 01:09:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/12/2022 01:09:10 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.3614070691696263 on epoch=574
06/12/2022 01:09:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/12/2022 01:09:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/12/2022 01:09:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/12/2022 01:09:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/12/2022 01:09:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/12/2022 01:09:36 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.3707292197858236 on epoch=587
06/12/2022 01:09:41 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=589
06/12/2022 01:09:45 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/12/2022 01:09:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=594
06/12/2022 01:09:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/12/2022 01:09:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/12/2022 01:10:02 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.5413886829750433 on epoch=599
06/12/2022 01:10:02 - INFO - __main__ - Saving model with best Classification-F1: 0.537733499377335 -> 0.5413886829750433 on epoch=599, global_step=2400
06/12/2022 01:10:06 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/12/2022 01:10:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/12/2022 01:10:15 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/12/2022 01:10:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/12/2022 01:10:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=612
06/12/2022 01:10:27 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.3346626786307743 on epoch=612
06/12/2022 01:10:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=614
06/12/2022 01:10:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/12/2022 01:10:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/12/2022 01:10:46 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/12/2022 01:10:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/12/2022 01:10:53 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.3398989898989899 on epoch=624
06/12/2022 01:10:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/12/2022 01:11:02 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/12/2022 01:11:07 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/12/2022 01:11:11 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/12/2022 01:11:16 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/12/2022 01:11:18 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.3491415944246133 on epoch=637
06/12/2022 01:11:23 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/12/2022 01:11:27 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/12/2022 01:11:32 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/12/2022 01:11:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=647
06/12/2022 01:11:41 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/12/2022 01:11:44 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.26389247867666066 on epoch=649
06/12/2022 01:11:48 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/12/2022 01:11:53 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/12/2022 01:11:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/12/2022 01:12:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/12/2022 01:12:07 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/12/2022 01:12:10 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.537733499377335 on epoch=662
06/12/2022 01:12:14 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/12/2022 01:12:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/12/2022 01:12:23 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/12/2022 01:12:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/12/2022 01:12:32 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/12/2022 01:12:35 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.5413886829750433 on epoch=674
06/12/2022 01:12:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/12/2022 01:12:44 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/12/2022 01:12:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/12/2022 01:12:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/12/2022 01:12:58 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/12/2022 01:13:01 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.5730170496664195 on epoch=687
06/12/2022 01:13:01 - INFO - __main__ - Saving model with best Classification-F1: 0.5413886829750433 -> 0.5730170496664195 on epoch=687, global_step=2750
06/12/2022 01:13:06 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/12/2022 01:13:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/12/2022 01:13:15 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/12/2022 01:13:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/12/2022 01:13:24 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/12/2022 01:13:27 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.5097603162836669 on epoch=699
06/12/2022 01:13:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/12/2022 01:13:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/12/2022 01:13:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/12/2022 01:13:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=709
06/12/2022 01:13:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/12/2022 01:13:53 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.5586206896551724 on epoch=712
06/12/2022 01:13:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/12/2022 01:14:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/12/2022 01:14:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=719
06/12/2022 01:14:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/12/2022 01:14:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/12/2022 01:14:19 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.4812085482682388 on epoch=724
06/12/2022 01:14:23 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/12/2022 01:14:28 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/12/2022 01:14:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/12/2022 01:14:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/12/2022 01:14:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/12/2022 01:14:45 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.5 on epoch=737
06/12/2022 01:14:49 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/12/2022 01:14:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/12/2022 01:14:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/12/2022 01:15:03 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/12/2022 01:15:07 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/12/2022 01:15:09 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 01:15:09 - INFO - __main__ - Printing 3 examples
06/12/2022 01:15:09 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/12/2022 01:15:09 - INFO - __main__ - ['refuted']
06/12/2022 01:15:09 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/12/2022 01:15:09 - INFO - __main__ - ['refuted']
06/12/2022 01:15:09 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/12/2022 01:15:09 - INFO - __main__ - ['refuted']
06/12/2022 01:15:09 - INFO - __main__ - Tokenizing Input ...
06/12/2022 01:15:09 - INFO - __main__ - Tokenizing Output ...
06/12/2022 01:15:09 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 01:15:09 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 01:15:09 - INFO - __main__ - Printing 3 examples
06/12/2022 01:15:09 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/12/2022 01:15:09 - INFO - __main__ - ['refuted']
06/12/2022 01:15:09 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/12/2022 01:15:09 - INFO - __main__ - ['refuted']
06/12/2022 01:15:09 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/12/2022 01:15:09 - INFO - __main__ - ['refuted']
06/12/2022 01:15:09 - INFO - __main__ - Tokenizing Input ...
06/12/2022 01:15:09 - INFO - __main__ - Tokenizing Output ...
06/12/2022 01:15:09 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 01:15:10 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.5126504544338 on epoch=749
06/12/2022 01:15:10 - INFO - __main__ - save last model!
06/12/2022 01:15:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 01:15:10 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 01:15:10 - INFO - __main__ - Printing 3 examples
06/12/2022 01:15:10 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 01:15:10 - INFO - __main__ - ['entailed']
06/12/2022 01:15:10 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 01:15:10 - INFO - __main__ - ['entailed']
06/12/2022 01:15:10 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 01:15:10 - INFO - __main__ - ['entailed']
06/12/2022 01:15:10 - INFO - __main__ - Tokenizing Input ...
06/12/2022 01:15:24 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 01:15:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 01:15:25 - INFO - __main__ - Starting training!
06/12/2022 01:15:38 - INFO - __main__ - Tokenizing Output ...
06/12/2022 01:15:53 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 01:24:54 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_13_0.3_8_predictions.txt
06/12/2022 01:24:54 - INFO - __main__ - Classification-F1 on test data: 0.0497
06/12/2022 01:24:54 - INFO - __main__ - prefix=tab_fact_32_13, lr=0.3, bsz=8, dev_performance=0.5730170496664195, test_performance=0.049719834229258256
06/12/2022 01:24:54 - INFO - __main__ - Running ... prefix=tab_fact_32_13, lr=0.2, bsz=8 ...
06/12/2022 01:24:55 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 01:24:55 - INFO - __main__ - Printing 3 examples
06/12/2022 01:24:55 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/12/2022 01:24:55 - INFO - __main__ - ['refuted']
06/12/2022 01:24:55 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/12/2022 01:24:55 - INFO - __main__ - ['refuted']
06/12/2022 01:24:55 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/12/2022 01:24:55 - INFO - __main__ - ['refuted']
06/12/2022 01:24:55 - INFO - __main__ - Tokenizing Input ...
06/12/2022 01:24:55 - INFO - __main__ - Tokenizing Output ...
06/12/2022 01:24:55 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 01:24:55 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 01:24:55 - INFO - __main__ - Printing 3 examples
06/12/2022 01:24:55 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/12/2022 01:24:55 - INFO - __main__ - ['refuted']
06/12/2022 01:24:55 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/12/2022 01:24:55 - INFO - __main__ - ['refuted']
06/12/2022 01:24:55 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/12/2022 01:24:55 - INFO - __main__ - ['refuted']
06/12/2022 01:24:55 - INFO - __main__ - Tokenizing Input ...
06/12/2022 01:24:55 - INFO - __main__ - Tokenizing Output ...
06/12/2022 01:24:56 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 01:25:11 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 01:25:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 01:25:11 - INFO - __main__ - Starting training!
06/12/2022 01:25:17 - INFO - __main__ - Step 10 Global step 10 Train loss 3.69 on epoch=2
06/12/2022 01:25:21 - INFO - __main__ - Step 20 Global step 20 Train loss 1.16 on epoch=4
06/12/2022 01:25:26 - INFO - __main__ - Step 30 Global step 30 Train loss 0.65 on epoch=7
06/12/2022 01:25:30 - INFO - __main__ - Step 40 Global step 40 Train loss 0.46 on epoch=9
06/12/2022 01:25:35 - INFO - __main__ - Step 50 Global step 50 Train loss 0.45 on epoch=12
06/12/2022 01:25:38 - INFO - __main__ - Global step 50 Train loss 1.28 Classification-F1 0.3333333333333333 on epoch=12
06/12/2022 01:25:38 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/12/2022 01:25:42 - INFO - __main__ - Step 60 Global step 60 Train loss 0.38 on epoch=14
06/12/2022 01:25:47 - INFO - __main__ - Step 70 Global step 70 Train loss 0.34 on epoch=17
06/12/2022 01:25:51 - INFO - __main__ - Step 80 Global step 80 Train loss 0.31 on epoch=19
06/12/2022 01:25:56 - INFO - __main__ - Step 90 Global step 90 Train loss 0.31 on epoch=22
06/12/2022 01:26:00 - INFO - __main__ - Step 100 Global step 100 Train loss 0.25 on epoch=24
06/12/2022 01:26:03 - INFO - __main__ - Global step 100 Train loss 0.32 Classification-F1 0.3333333333333333 on epoch=24
06/12/2022 01:26:07 - INFO - __main__ - Step 110 Global step 110 Train loss 0.32 on epoch=27
06/12/2022 01:26:12 - INFO - __main__ - Step 120 Global step 120 Train loss 0.24 on epoch=29
06/12/2022 01:26:16 - INFO - __main__ - Step 130 Global step 130 Train loss 0.25 on epoch=32
06/12/2022 01:26:21 - INFO - __main__ - Step 140 Global step 140 Train loss 0.24 on epoch=34
06/12/2022 01:26:26 - INFO - __main__ - Step 150 Global step 150 Train loss 0.24 on epoch=37
06/12/2022 01:26:28 - INFO - __main__ - Global step 150 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=37
06/12/2022 01:26:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.23 on epoch=39
06/12/2022 01:26:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.26 on epoch=42
06/12/2022 01:26:42 - INFO - __main__ - Step 180 Global step 180 Train loss 0.29 on epoch=44
06/12/2022 01:26:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.27 on epoch=47
06/12/2022 01:26:51 - INFO - __main__ - Step 200 Global step 200 Train loss 0.24 on epoch=49
06/12/2022 01:26:54 - INFO - __main__ - Global step 200 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=49
06/12/2022 01:26:58 - INFO - __main__ - Step 210 Global step 210 Train loss 0.27 on epoch=52
06/12/2022 01:27:03 - INFO - __main__ - Step 220 Global step 220 Train loss 0.26 on epoch=54
06/12/2022 01:27:07 - INFO - __main__ - Step 230 Global step 230 Train loss 0.24 on epoch=57
06/12/2022 01:27:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.26 on epoch=59
06/12/2022 01:27:16 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=62
06/12/2022 01:27:19 - INFO - __main__ - Global step 250 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=62
06/12/2022 01:27:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.22 on epoch=64
06/12/2022 01:27:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.24 on epoch=67
06/12/2022 01:27:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.25 on epoch=69
06/12/2022 01:27:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.17 on epoch=72
06/12/2022 01:27:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=74
06/12/2022 01:27:45 - INFO - __main__ - Global step 300 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=74
06/12/2022 01:27:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.26 on epoch=77
06/12/2022 01:27:54 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=79
06/12/2022 01:27:58 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=82
06/12/2022 01:28:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=84
06/12/2022 01:28:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=87
06/12/2022 01:28:10 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=87
06/12/2022 01:28:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=89
06/12/2022 01:28:20 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=92
06/12/2022 01:28:24 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=94
06/12/2022 01:28:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/12/2022 01:28:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=99
06/12/2022 01:28:36 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=99
06/12/2022 01:28:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=102
06/12/2022 01:28:45 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/12/2022 01:28:50 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=107
06/12/2022 01:28:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=109
06/12/2022 01:28:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=112
06/12/2022 01:29:02 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=112
06/12/2022 01:29:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=114
06/12/2022 01:29:11 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=117
06/12/2022 01:29:16 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=119
06/12/2022 01:29:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=122
06/12/2022 01:29:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=124
06/12/2022 01:29:28 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.32631578947368417 on epoch=124
06/12/2022 01:29:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=127
06/12/2022 01:29:37 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=129
06/12/2022 01:29:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=132
06/12/2022 01:29:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=134
06/12/2022 01:29:50 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=137
06/12/2022 01:29:53 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.40116959064327484 on epoch=137
06/12/2022 01:29:53 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.40116959064327484 on epoch=137, global_step=550
06/12/2022 01:29:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=139
06/12/2022 01:30:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=142
06/12/2022 01:30:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/12/2022 01:30:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=147
06/12/2022 01:30:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=149
06/12/2022 01:30:19 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.41075141075141075 on epoch=149
06/12/2022 01:30:19 - INFO - __main__ - Saving model with best Classification-F1: 0.40116959064327484 -> 0.41075141075141075 on epoch=149, global_step=600
06/12/2022 01:30:24 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=152
06/12/2022 01:30:28 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=154
06/12/2022 01:30:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=157
06/12/2022 01:30:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/12/2022 01:30:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=162
06/12/2022 01:30:45 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.45705196182396607 on epoch=162
06/12/2022 01:30:45 - INFO - __main__ - Saving model with best Classification-F1: 0.41075141075141075 -> 0.45705196182396607 on epoch=162, global_step=650
06/12/2022 01:30:49 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=164
06/12/2022 01:30:54 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=167
06/12/2022 01:30:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=169
06/12/2022 01:31:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=172
06/12/2022 01:31:08 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=174
06/12/2022 01:31:11 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.45705196182396607 on epoch=174
06/12/2022 01:31:15 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=177
06/12/2022 01:31:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=179
06/12/2022 01:31:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=182
06/12/2022 01:31:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=184
06/12/2022 01:31:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=187
06/12/2022 01:31:36 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.42216142270861834 on epoch=187
06/12/2022 01:31:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=189
06/12/2022 01:31:46 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=192
06/12/2022 01:31:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=194
06/12/2022 01:31:55 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=197
06/12/2022 01:31:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=199
06/12/2022 01:32:02 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.500880503144654 on epoch=199
06/12/2022 01:32:02 - INFO - __main__ - Saving model with best Classification-F1: 0.45705196182396607 -> 0.500880503144654 on epoch=199, global_step=800
06/12/2022 01:32:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=202
06/12/2022 01:32:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=204
06/12/2022 01:32:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=207
06/12/2022 01:32:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=209
06/12/2022 01:32:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=212
06/12/2022 01:32:28 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.5195195195195195 on epoch=212
06/12/2022 01:32:28 - INFO - __main__ - Saving model with best Classification-F1: 0.500880503144654 -> 0.5195195195195195 on epoch=212, global_step=850
06/12/2022 01:32:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=214
06/12/2022 01:32:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=217
06/12/2022 01:32:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=219
06/12/2022 01:32:46 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=222
06/12/2022 01:32:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=224
06/12/2022 01:32:54 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.4682306940371457 on epoch=224
06/12/2022 01:32:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=227
06/12/2022 01:33:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=229
06/12/2022 01:33:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=232
06/12/2022 01:33:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=234
06/12/2022 01:33:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=237
06/12/2022 01:33:19 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.4947797300738477 on epoch=237
06/12/2022 01:33:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=239
06/12/2022 01:33:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.36 on epoch=242
06/12/2022 01:33:33 - INFO - __main__ - Step 980 Global step 980 Train loss 1.51 on epoch=244
06/12/2022 01:33:38 - INFO - __main__ - Step 990 Global step 990 Train loss 3.39 on epoch=247
06/12/2022 01:33:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.83 on epoch=249
06/12/2022 01:33:45 - INFO - __main__ - Global step 1000 Train loss 1.25 Classification-F1 0.46880856760374834 on epoch=249
06/12/2022 01:33:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=252
06/12/2022 01:33:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=254
06/12/2022 01:33:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=257
06/12/2022 01:34:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=259
06/12/2022 01:34:08 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=262
06/12/2022 01:34:11 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.47885474126608885 on epoch=262
06/12/2022 01:34:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=264
06/12/2022 01:34:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=267
06/12/2022 01:34:24 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=269
06/12/2022 01:34:29 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=272
06/12/2022 01:34:33 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=274
06/12/2022 01:34:36 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.47885474126608885 on epoch=274
06/12/2022 01:34:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=277
06/12/2022 01:34:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=279
06/12/2022 01:34:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=282
06/12/2022 01:34:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=284
06/12/2022 01:34:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.16 on epoch=287
06/12/2022 01:35:02 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.47885474126608885 on epoch=287
06/12/2022 01:35:06 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=289
06/12/2022 01:35:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=292
06/12/2022 01:35:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.16 on epoch=294
06/12/2022 01:35:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=297
06/12/2022 01:35:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=299
06/12/2022 01:35:27 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.47885474126608885 on epoch=299
06/12/2022 01:35:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=302
06/12/2022 01:35:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=304
06/12/2022 01:35:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.19 on epoch=307
06/12/2022 01:35:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.41 on epoch=309
06/12/2022 01:35:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.57 on epoch=312
06/12/2022 01:35:53 - INFO - __main__ - Global step 1250 Train loss 0.49 Classification-F1 0.47885474126608885 on epoch=312
06/12/2022 01:35:58 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.15 on epoch=314
06/12/2022 01:36:02 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.35 on epoch=317
06/12/2022 01:36:07 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=319
06/12/2022 01:36:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.14 on epoch=322
06/12/2022 01:36:16 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.16 on epoch=324
06/12/2022 01:36:19 - INFO - __main__ - Global step 1300 Train loss 0.18 Classification-F1 0.5 on epoch=324
06/12/2022 01:36:24 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=327
06/12/2022 01:36:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=329
06/12/2022 01:36:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=332
06/12/2022 01:36:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=334
06/12/2022 01:36:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=337
06/12/2022 01:36:45 - INFO - __main__ - Global step 1350 Train loss 0.14 Classification-F1 0.5 on epoch=337
06/12/2022 01:36:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.15 on epoch=339
06/12/2022 01:36:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.16 on epoch=342
06/12/2022 01:36:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=344
06/12/2022 01:37:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=347
06/12/2022 01:37:08 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.15 on epoch=349
06/12/2022 01:37:11 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.5 on epoch=349
06/12/2022 01:37:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=352
06/12/2022 01:37:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.16 on epoch=354
06/12/2022 01:37:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=357
06/12/2022 01:37:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=359
06/12/2022 01:37:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=362
06/12/2022 01:37:36 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.5205373288555928 on epoch=362
06/12/2022 01:37:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5195195195195195 -> 0.5205373288555928 on epoch=362, global_step=1450
06/12/2022 01:37:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=364
06/12/2022 01:37:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=367
06/12/2022 01:37:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.14 on epoch=369
06/12/2022 01:37:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.13 on epoch=372
06/12/2022 01:37:59 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=374
06/12/2022 01:38:02 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.5205373288555928 on epoch=374
06/12/2022 01:38:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.14 on epoch=377
06/12/2022 01:38:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=379
06/12/2022 01:38:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=382
06/12/2022 01:38:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.14 on epoch=384
06/12/2022 01:38:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=387
06/12/2022 01:38:28 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.5076923076923077 on epoch=387
06/12/2022 01:38:33 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.14 on epoch=389
06/12/2022 01:38:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=392
06/12/2022 01:38:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=394
06/12/2022 01:38:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=397
06/12/2022 01:38:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=399
06/12/2022 01:38:54 - INFO - __main__ - Global step 1600 Train loss 0.12 Classification-F1 0.5076923076923077 on epoch=399
06/12/2022 01:38:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.12 on epoch=402
06/12/2022 01:39:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.16 on epoch=404
06/12/2022 01:39:08 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.14 on epoch=407
06/12/2022 01:39:12 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.15 on epoch=409
06/12/2022 01:39:17 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=412
06/12/2022 01:39:20 - INFO - __main__ - Global step 1650 Train loss 0.13 Classification-F1 0.4909862142099682 on epoch=412
06/12/2022 01:39:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=414
06/12/2022 01:39:29 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=417
06/12/2022 01:39:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=419
06/12/2022 01:39:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=422
06/12/2022 01:39:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.14 on epoch=424
06/12/2022 01:39:46 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.4909862142099682 on epoch=424
06/12/2022 01:39:51 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=427
06/12/2022 01:39:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=429
06/12/2022 01:40:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.13 on epoch=432
06/12/2022 01:40:04 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.11 on epoch=434
06/12/2022 01:40:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=437
06/12/2022 01:40:12 - INFO - __main__ - Global step 1750 Train loss 0.12 Classification-F1 0.500880503144654 on epoch=437
06/12/2022 01:40:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.15 on epoch=439
06/12/2022 01:40:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.12 on epoch=442
06/12/2022 01:40:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=444
06/12/2022 01:40:30 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.13 on epoch=447
06/12/2022 01:40:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.13 on epoch=449
06/12/2022 01:40:38 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.47885474126608885 on epoch=449
06/12/2022 01:40:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=452
06/12/2022 01:40:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.13 on epoch=454
06/12/2022 01:40:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.13 on epoch=457
06/12/2022 01:40:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.13 on epoch=459
06/12/2022 01:41:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.14 on epoch=462
06/12/2022 01:41:04 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.47885474126608885 on epoch=462
06/12/2022 01:41:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.13 on epoch=464
06/12/2022 01:41:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=467
06/12/2022 01:41:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=469
06/12/2022 01:41:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.13 on epoch=472
06/12/2022 01:41:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=474
06/12/2022 01:41:30 - INFO - __main__ - Global step 1900 Train loss 0.11 Classification-F1 0.4947797300738477 on epoch=474
06/12/2022 01:41:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.13 on epoch=477
06/12/2022 01:41:39 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.15 on epoch=479
06/12/2022 01:41:43 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.11 on epoch=482
06/12/2022 01:41:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.13 on epoch=484
06/12/2022 01:41:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.13 on epoch=487
06/12/2022 01:41:55 - INFO - __main__ - Global step 1950 Train loss 0.13 Classification-F1 0.51417004048583 on epoch=487
06/12/2022 01:42:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.11 on epoch=489
06/12/2022 01:42:04 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.12 on epoch=492
06/12/2022 01:42:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=494
06/12/2022 01:42:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=497
06/12/2022 01:42:18 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.11 on epoch=499
06/12/2022 01:42:21 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.47885474126608885 on epoch=499
06/12/2022 01:42:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=502
06/12/2022 01:42:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=504
06/12/2022 01:42:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.11 on epoch=507
06/12/2022 01:42:39 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=509
06/12/2022 01:42:44 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=512
06/12/2022 01:42:47 - INFO - __main__ - Global step 2050 Train loss 0.10 Classification-F1 0.4874874874874875 on epoch=512
06/12/2022 01:42:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.15 on epoch=514
06/12/2022 01:42:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=517
06/12/2022 01:43:01 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=519
06/12/2022 01:43:05 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.11 on epoch=522
06/12/2022 01:43:10 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.11 on epoch=524
06/12/2022 01:43:13 - INFO - __main__ - Global step 2100 Train loss 0.12 Classification-F1 0.4748717948717949 on epoch=524
06/12/2022 01:43:18 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.14 on epoch=527
06/12/2022 01:43:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.10 on epoch=529
06/12/2022 01:43:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=532
06/12/2022 01:43:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.11 on epoch=534
06/12/2022 01:43:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.14 on epoch=537
06/12/2022 01:43:39 - INFO - __main__ - Global step 2150 Train loss 0.11 Classification-F1 0.5058530510585305 on epoch=537
06/12/2022 01:43:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.14 on epoch=539
06/12/2022 01:43:48 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=542
06/12/2022 01:43:53 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.11 on epoch=544
06/12/2022 01:43:57 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.12 on epoch=547
06/12/2022 01:44:02 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=549
06/12/2022 01:44:05 - INFO - __main__ - Global step 2200 Train loss 0.11 Classification-F1 0.5273745861981156 on epoch=549
06/12/2022 01:44:05 - INFO - __main__ - Saving model with best Classification-F1: 0.5205373288555928 -> 0.5273745861981156 on epoch=549, global_step=2200
06/12/2022 01:44:10 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=552
06/12/2022 01:44:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.11 on epoch=554
06/12/2022 01:44:19 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.11 on epoch=557
06/12/2022 01:44:23 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.12 on epoch=559
06/12/2022 01:44:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.12 on epoch=562
06/12/2022 01:44:31 - INFO - __main__ - Global step 2250 Train loss 0.11 Classification-F1 0.4812085482682388 on epoch=562
06/12/2022 01:44:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.12 on epoch=564
06/12/2022 01:44:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=567
06/12/2022 01:44:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.14 on epoch=569
06/12/2022 01:44:49 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.10 on epoch=572
06/12/2022 01:44:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.08 on epoch=574
06/12/2022 01:44:57 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.4947797300738477 on epoch=574
06/12/2022 01:45:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.11 on epoch=577
06/12/2022 01:45:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.12 on epoch=579
06/12/2022 01:45:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=582
06/12/2022 01:45:15 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=584
06/12/2022 01:45:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.12 on epoch=587
06/12/2022 01:45:23 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.464039408866995 on epoch=587
06/12/2022 01:45:27 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.10 on epoch=589
06/12/2022 01:45:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=592
06/12/2022 01:45:36 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.11 on epoch=594
06/12/2022 01:45:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.13 on epoch=597
06/12/2022 01:45:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=599
06/12/2022 01:45:49 - INFO - __main__ - Global step 2400 Train loss 0.11 Classification-F1 0.3148717948717949 on epoch=599
06/12/2022 01:45:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.10 on epoch=602
06/12/2022 01:45:58 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.10 on epoch=604
06/12/2022 01:46:02 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=607
06/12/2022 01:46:07 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.12 on epoch=609
06/12/2022 01:46:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.09 on epoch=612
06/12/2022 01:46:14 - INFO - __main__ - Global step 2450 Train loss 0.10 Classification-F1 0.3092592592592593 on epoch=612
06/12/2022 01:46:19 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.14 on epoch=614
06/12/2022 01:46:23 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=617
06/12/2022 01:46:28 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=619
06/12/2022 01:46:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=622
06/12/2022 01:46:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.08 on epoch=624
06/12/2022 01:46:40 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.327553969063403 on epoch=624
06/12/2022 01:46:44 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=627
06/12/2022 01:46:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.10 on epoch=629
06/12/2022 01:46:54 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=632
06/12/2022 01:46:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.13 on epoch=634
06/12/2022 01:47:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=637
06/12/2022 01:47:06 - INFO - __main__ - Global step 2550 Train loss 0.09 Classification-F1 0.46031746031746035 on epoch=637
06/12/2022 01:47:10 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.11 on epoch=639
06/12/2022 01:47:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.10 on epoch=642
06/12/2022 01:47:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=644
06/12/2022 01:47:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=647
06/12/2022 01:47:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.10 on epoch=649
06/12/2022 01:47:32 - INFO - __main__ - Global step 2600 Train loss 0.09 Classification-F1 0.32370141038871686 on epoch=649
06/12/2022 01:47:36 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=652
06/12/2022 01:47:41 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.09 on epoch=654
06/12/2022 01:47:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.12 on epoch=657
06/12/2022 01:47:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.11 on epoch=659
06/12/2022 01:47:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.11 on epoch=662
06/12/2022 01:47:57 - INFO - __main__ - Global step 2650 Train loss 0.10 Classification-F1 0.5333333333333333 on epoch=662
06/12/2022 01:47:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5273745861981156 -> 0.5333333333333333 on epoch=662, global_step=2650
06/12/2022 01:48:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.12 on epoch=664
06/12/2022 01:48:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.08 on epoch=667
06/12/2022 01:48:11 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=669
06/12/2022 01:48:16 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.08 on epoch=672
06/12/2022 01:48:20 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=674
06/12/2022 01:48:23 - INFO - __main__ - Global step 2700 Train loss 0.09 Classification-F1 0.327553969063403 on epoch=674
06/12/2022 01:48:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.09 on epoch=677
06/12/2022 01:48:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.12 on epoch=679
06/12/2022 01:48:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.09 on epoch=682
06/12/2022 01:48:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.10 on epoch=684
06/12/2022 01:48:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.12 on epoch=687
06/12/2022 01:48:49 - INFO - __main__ - Global step 2750 Train loss 0.10 Classification-F1 0.327553969063403 on epoch=687
06/12/2022 01:48:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.09 on epoch=689
06/12/2022 01:48:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.09 on epoch=692
06/12/2022 01:49:03 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.12 on epoch=694
06/12/2022 01:49:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.09 on epoch=697
06/12/2022 01:49:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.09 on epoch=699
06/12/2022 01:49:15 - INFO - __main__ - Global step 2800 Train loss 0.10 Classification-F1 0.3324675324675324 on epoch=699
06/12/2022 01:49:19 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.08 on epoch=702
06/12/2022 01:49:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=704
06/12/2022 01:49:28 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.10 on epoch=707
06/12/2022 01:49:33 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.10 on epoch=709
06/12/2022 01:49:37 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.11 on epoch=712
06/12/2022 01:49:40 - INFO - __main__ - Global step 2850 Train loss 0.09 Classification-F1 0.34554523563811484 on epoch=712
06/12/2022 01:49:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=714
06/12/2022 01:49:49 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.09 on epoch=717
06/12/2022 01:49:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.09 on epoch=719
06/12/2022 01:49:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=722
06/12/2022 01:50:03 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.10 on epoch=724
06/12/2022 01:50:06 - INFO - __main__ - Global step 2900 Train loss 0.09 Classification-F1 0.3117794486215539 on epoch=724
06/12/2022 01:50:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.09 on epoch=727
06/12/2022 01:50:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.12 on epoch=729
06/12/2022 01:50:19 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=732
06/12/2022 01:50:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.09 on epoch=734
06/12/2022 01:50:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=737
06/12/2022 01:50:32 - INFO - __main__ - Global step 2950 Train loss 0.09 Classification-F1 0.3306397306397306 on epoch=737
06/12/2022 01:50:36 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.09 on epoch=739
06/12/2022 01:50:41 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.10 on epoch=742
06/12/2022 01:50:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=744
06/12/2022 01:50:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.09 on epoch=747
06/12/2022 01:50:54 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.10 on epoch=749
06/12/2022 01:50:56 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 01:50:56 - INFO - __main__ - Printing 3 examples
06/12/2022 01:50:56 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/12/2022 01:50:56 - INFO - __main__ - ['entailed']
06/12/2022 01:50:56 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/12/2022 01:50:56 - INFO - __main__ - ['entailed']
06/12/2022 01:50:56 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/12/2022 01:50:56 - INFO - __main__ - ['entailed']
06/12/2022 01:50:56 - INFO - __main__ - Tokenizing Input ...
06/12/2022 01:50:56 - INFO - __main__ - Tokenizing Output ...
06/12/2022 01:50:56 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 01:50:56 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 01:50:56 - INFO - __main__ - Printing 3 examples
06/12/2022 01:50:56 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/12/2022 01:50:56 - INFO - __main__ - ['entailed']
06/12/2022 01:50:56 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/12/2022 01:50:56 - INFO - __main__ - ['entailed']
06/12/2022 01:50:56 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/12/2022 01:50:56 - INFO - __main__ - ['entailed']
06/12/2022 01:50:56 - INFO - __main__ - Tokenizing Input ...
06/12/2022 01:50:56 - INFO - __main__ - Tokenizing Output ...
06/12/2022 01:50:56 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 01:50:57 - INFO - __main__ - Global step 3000 Train loss 0.09 Classification-F1 0.3253968253968254 on epoch=749
06/12/2022 01:50:57 - INFO - __main__ - save last model!
06/12/2022 01:50:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 01:50:57 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 01:50:57 - INFO - __main__ - Printing 3 examples
06/12/2022 01:50:57 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 01:50:57 - INFO - __main__ - ['entailed']
06/12/2022 01:50:57 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 01:50:57 - INFO - __main__ - ['entailed']
06/12/2022 01:50:57 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 01:50:57 - INFO - __main__ - ['entailed']
06/12/2022 01:50:57 - INFO - __main__ - Tokenizing Input ...
06/12/2022 01:51:15 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 01:51:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 01:51:16 - INFO - __main__ - Starting training!
06/12/2022 01:51:25 - INFO - __main__ - Tokenizing Output ...
06/12/2022 01:51:39 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 02:00:50 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_13_0.2_8_predictions.txt
06/12/2022 02:00:50 - INFO - __main__ - Classification-F1 on test data: 0.0552
06/12/2022 02:00:51 - INFO - __main__ - prefix=tab_fact_32_13, lr=0.2, bsz=8, dev_performance=0.5333333333333333, test_performance=0.05519004260446178
06/12/2022 02:00:51 - INFO - __main__ - Running ... prefix=tab_fact_32_21, lr=0.5, bsz=8 ...
06/12/2022 02:00:52 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 02:00:52 - INFO - __main__ - Printing 3 examples
06/12/2022 02:00:52 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/12/2022 02:00:52 - INFO - __main__ - ['entailed']
06/12/2022 02:00:52 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/12/2022 02:00:52 - INFO - __main__ - ['entailed']
06/12/2022 02:00:52 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/12/2022 02:00:52 - INFO - __main__ - ['entailed']
06/12/2022 02:00:52 - INFO - __main__ - Tokenizing Input ...
06/12/2022 02:00:52 - INFO - __main__ - Tokenizing Output ...
06/12/2022 02:00:52 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 02:00:52 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 02:00:52 - INFO - __main__ - Printing 3 examples
06/12/2022 02:00:52 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/12/2022 02:00:52 - INFO - __main__ - ['entailed']
06/12/2022 02:00:52 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/12/2022 02:00:52 - INFO - __main__ - ['entailed']
06/12/2022 02:00:52 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/12/2022 02:00:52 - INFO - __main__ - ['entailed']
06/12/2022 02:00:52 - INFO - __main__ - Tokenizing Input ...
06/12/2022 02:00:52 - INFO - __main__ - Tokenizing Output ...
06/12/2022 02:00:52 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 02:01:07 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 02:01:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 02:01:08 - INFO - __main__ - Starting training!
06/12/2022 02:01:13 - INFO - __main__ - Step 10 Global step 10 Train loss 2.78 on epoch=2
06/12/2022 02:01:17 - INFO - __main__ - Step 20 Global step 20 Train loss 0.57 on epoch=4
06/12/2022 02:01:22 - INFO - __main__ - Step 30 Global step 30 Train loss 0.38 on epoch=7
06/12/2022 02:01:26 - INFO - __main__ - Step 40 Global step 40 Train loss 2.00 on epoch=9
06/12/2022 02:01:31 - INFO - __main__ - Step 50 Global step 50 Train loss 0.64 on epoch=12
06/12/2022 02:01:34 - INFO - __main__ - Global step 50 Train loss 1.27 Classification-F1 0.3333333333333333 on epoch=12
06/12/2022 02:01:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/12/2022 02:01:38 - INFO - __main__ - Step 60 Global step 60 Train loss 0.44 on epoch=14
06/12/2022 02:01:43 - INFO - __main__ - Step 70 Global step 70 Train loss 0.39 on epoch=17
06/12/2022 02:01:47 - INFO - __main__ - Step 80 Global step 80 Train loss 0.38 on epoch=19
06/12/2022 02:01:52 - INFO - __main__ - Step 90 Global step 90 Train loss 0.43 on epoch=22
06/12/2022 02:01:56 - INFO - __main__ - Step 100 Global step 100 Train loss 2.61 on epoch=24
06/12/2022 02:01:59 - INFO - __main__ - Global step 100 Train loss 0.85 Classification-F1 0.3333333333333333 on epoch=24
06/12/2022 02:02:03 - INFO - __main__ - Step 110 Global step 110 Train loss 2.96 on epoch=27
06/12/2022 02:02:08 - INFO - __main__ - Step 120 Global step 120 Train loss 1.47 on epoch=29
06/12/2022 02:02:12 - INFO - __main__ - Step 130 Global step 130 Train loss 1.61 on epoch=32
06/12/2022 02:02:17 - INFO - __main__ - Step 140 Global step 140 Train loss 3.61 on epoch=34
06/12/2022 02:02:21 - INFO - __main__ - Step 150 Global step 150 Train loss 3.38 on epoch=37
06/12/2022 02:02:24 - INFO - __main__ - Global step 150 Train loss 2.61 Classification-F1 0.3333333333333333 on epoch=37
06/12/2022 02:02:29 - INFO - __main__ - Step 160 Global step 160 Train loss 5.20 on epoch=39
06/12/2022 02:02:33 - INFO - __main__ - Step 170 Global step 170 Train loss 4.72 on epoch=42
06/12/2022 02:02:38 - INFO - __main__ - Step 180 Global step 180 Train loss 5.24 on epoch=44
06/12/2022 02:02:42 - INFO - __main__ - Step 190 Global step 190 Train loss 5.09 on epoch=47
06/12/2022 02:02:47 - INFO - __main__ - Step 200 Global step 200 Train loss 4.06 on epoch=49
06/12/2022 02:02:50 - INFO - __main__ - Global step 200 Train loss 4.86 Classification-F1 0.3333333333333333 on epoch=49
06/12/2022 02:02:54 - INFO - __main__ - Step 210 Global step 210 Train loss 3.15 on epoch=52
06/12/2022 02:02:59 - INFO - __main__ - Step 220 Global step 220 Train loss 2.55 on epoch=54
06/12/2022 02:03:03 - INFO - __main__ - Step 230 Global step 230 Train loss 2.24 on epoch=57
06/12/2022 02:03:08 - INFO - __main__ - Step 240 Global step 240 Train loss 1.21 on epoch=59
06/12/2022 02:03:12 - INFO - __main__ - Step 250 Global step 250 Train loss 1.37 on epoch=62
06/12/2022 02:03:15 - INFO - __main__ - Global step 250 Train loss 2.11 Classification-F1 0.3333333333333333 on epoch=62
06/12/2022 02:03:20 - INFO - __main__ - Step 260 Global step 260 Train loss 1.11 on epoch=64
06/12/2022 02:03:24 - INFO - __main__ - Step 270 Global step 270 Train loss 1.05 on epoch=67
06/12/2022 02:03:29 - INFO - __main__ - Step 280 Global step 280 Train loss 1.12 on epoch=69
06/12/2022 02:03:33 - INFO - __main__ - Step 290 Global step 290 Train loss 1.06 on epoch=72
06/12/2022 02:03:38 - INFO - __main__ - Step 300 Global step 300 Train loss 0.96 on epoch=74
06/12/2022 02:03:41 - INFO - __main__ - Global step 300 Train loss 1.06 Classification-F1 0.3333333333333333 on epoch=74
06/12/2022 02:03:45 - INFO - __main__ - Step 310 Global step 310 Train loss 0.92 on epoch=77
06/12/2022 02:03:50 - INFO - __main__ - Step 320 Global step 320 Train loss 0.85 on epoch=79
06/12/2022 02:03:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.67 on epoch=82
06/12/2022 02:03:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.73 on epoch=84
06/12/2022 02:04:03 - INFO - __main__ - Step 350 Global step 350 Train loss 0.67 on epoch=87
06/12/2022 02:04:06 - INFO - __main__ - Global step 350 Train loss 0.77 Classification-F1 0.3333333333333333 on epoch=87
06/12/2022 02:04:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.68 on epoch=89
06/12/2022 02:04:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.63 on epoch=92
06/12/2022 02:04:19 - INFO - __main__ - Step 380 Global step 380 Train loss 0.65 on epoch=94
06/12/2022 02:04:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.60 on epoch=97
06/12/2022 02:04:29 - INFO - __main__ - Step 400 Global step 400 Train loss 0.55 on epoch=99
06/12/2022 02:04:31 - INFO - __main__ - Global step 400 Train loss 0.62 Classification-F1 0.3333333333333333 on epoch=99
06/12/2022 02:04:36 - INFO - __main__ - Step 410 Global step 410 Train loss 0.53 on epoch=102
06/12/2022 02:04:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.53 on epoch=104
06/12/2022 02:04:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.50 on epoch=107
06/12/2022 02:04:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.52 on epoch=109
06/12/2022 02:04:54 - INFO - __main__ - Step 450 Global step 450 Train loss 0.49 on epoch=112
06/12/2022 02:04:57 - INFO - __main__ - Global step 450 Train loss 0.51 Classification-F1 0.3333333333333333 on epoch=112
06/12/2022 02:05:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.49 on epoch=114
06/12/2022 02:05:06 - INFO - __main__ - Step 470 Global step 470 Train loss 0.51 on epoch=117
06/12/2022 02:05:10 - INFO - __main__ - Step 480 Global step 480 Train loss 0.46 on epoch=119
06/12/2022 02:05:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.43 on epoch=122
06/12/2022 02:05:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.40 on epoch=124
06/12/2022 02:05:22 - INFO - __main__ - Global step 500 Train loss 0.46 Classification-F1 0.3333333333333333 on epoch=124
06/12/2022 02:05:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.45 on epoch=127
06/12/2022 02:05:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.42 on epoch=129
06/12/2022 02:05:36 - INFO - __main__ - Step 530 Global step 530 Train loss 0.42 on epoch=132
06/12/2022 02:05:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.43 on epoch=134
06/12/2022 02:05:45 - INFO - __main__ - Step 550 Global step 550 Train loss 0.45 on epoch=137
06/12/2022 02:05:48 - INFO - __main__ - Global step 550 Train loss 0.44 Classification-F1 0.3333333333333333 on epoch=137
06/12/2022 02:05:53 - INFO - __main__ - Step 560 Global step 560 Train loss 0.50 on epoch=139
06/12/2022 02:05:57 - INFO - __main__ - Step 570 Global step 570 Train loss 0.47 on epoch=142
06/12/2022 02:06:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.41 on epoch=144
06/12/2022 02:06:06 - INFO - __main__ - Step 590 Global step 590 Train loss 0.39 on epoch=147
06/12/2022 02:06:11 - INFO - __main__ - Step 600 Global step 600 Train loss 0.41 on epoch=149
06/12/2022 02:06:14 - INFO - __main__ - Global step 600 Train loss 0.44 Classification-F1 0.3333333333333333 on epoch=149
06/12/2022 02:06:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.42 on epoch=152
06/12/2022 02:06:23 - INFO - __main__ - Step 620 Global step 620 Train loss 0.43 on epoch=154
06/12/2022 02:06:27 - INFO - __main__ - Step 630 Global step 630 Train loss 0.43 on epoch=157
06/12/2022 02:06:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.41 on epoch=159
06/12/2022 02:06:37 - INFO - __main__ - Step 650 Global step 650 Train loss 0.38 on epoch=162
06/12/2022 02:06:39 - INFO - __main__ - Global step 650 Train loss 0.41 Classification-F1 0.3333333333333333 on epoch=162
06/12/2022 02:06:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.41 on epoch=164
06/12/2022 02:06:49 - INFO - __main__ - Step 670 Global step 670 Train loss 0.39 on epoch=167
06/12/2022 02:06:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.34 on epoch=169
06/12/2022 02:06:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.40 on epoch=172
06/12/2022 02:07:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.33 on epoch=174
06/12/2022 02:07:05 - INFO - __main__ - Global step 700 Train loss 0.37 Classification-F1 0.3333333333333333 on epoch=174
06/12/2022 02:07:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.33 on epoch=177
06/12/2022 02:07:14 - INFO - __main__ - Step 720 Global step 720 Train loss 0.33 on epoch=179
06/12/2022 02:07:19 - INFO - __main__ - Step 730 Global step 730 Train loss 0.34 on epoch=182
06/12/2022 02:07:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.38 on epoch=184
06/12/2022 02:07:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.37 on epoch=187
06/12/2022 02:07:31 - INFO - __main__ - Global step 750 Train loss 0.35 Classification-F1 0.3333333333333333 on epoch=187
06/12/2022 02:07:35 - INFO - __main__ - Step 760 Global step 760 Train loss 0.32 on epoch=189
06/12/2022 02:07:40 - INFO - __main__ - Step 770 Global step 770 Train loss 0.31 on epoch=192
06/12/2022 02:07:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.30 on epoch=194
06/12/2022 02:07:49 - INFO - __main__ - Step 790 Global step 790 Train loss 0.32 on epoch=197
06/12/2022 02:07:54 - INFO - __main__ - Step 800 Global step 800 Train loss 0.36 on epoch=199
06/12/2022 02:07:57 - INFO - __main__ - Global step 800 Train loss 0.32 Classification-F1 0.3333333333333333 on epoch=199
06/12/2022 02:08:01 - INFO - __main__ - Step 810 Global step 810 Train loss 0.34 on epoch=202
06/12/2022 02:08:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.29 on epoch=204
06/12/2022 02:08:10 - INFO - __main__ - Step 830 Global step 830 Train loss 0.32 on epoch=207
06/12/2022 02:08:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.29 on epoch=209
06/12/2022 02:08:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.34 on epoch=212
06/12/2022 02:08:22 - INFO - __main__ - Global step 850 Train loss 0.31 Classification-F1 0.3333333333333333 on epoch=212
06/12/2022 02:08:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.34 on epoch=214
06/12/2022 02:08:31 - INFO - __main__ - Step 870 Global step 870 Train loss 0.36 on epoch=217
06/12/2022 02:08:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.32 on epoch=219
06/12/2022 02:08:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.30 on epoch=222
06/12/2022 02:08:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.30 on epoch=224
06/12/2022 02:08:48 - INFO - __main__ - Global step 900 Train loss 0.32 Classification-F1 0.3333333333333333 on epoch=224
06/12/2022 02:08:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.30 on epoch=227
06/12/2022 02:08:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.25 on epoch=229
06/12/2022 02:09:02 - INFO - __main__ - Step 930 Global step 930 Train loss 0.32 on epoch=232
06/12/2022 02:09:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.30 on epoch=234
06/12/2022 02:09:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.29 on epoch=237
06/12/2022 02:09:14 - INFO - __main__ - Global step 950 Train loss 0.29 Classification-F1 0.3333333333333333 on epoch=237
06/12/2022 02:09:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.30 on epoch=239
06/12/2022 02:09:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.33 on epoch=242
06/12/2022 02:09:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.34 on epoch=244
06/12/2022 02:09:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.27 on epoch=247
06/12/2022 02:09:37 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.30 on epoch=249
06/12/2022 02:09:40 - INFO - __main__ - Global step 1000 Train loss 0.31 Classification-F1 0.3333333333333333 on epoch=249
06/12/2022 02:09:44 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.27 on epoch=252
06/12/2022 02:09:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.29 on epoch=254
06/12/2022 02:09:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.27 on epoch=257
06/12/2022 02:09:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.27 on epoch=259
06/12/2022 02:10:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.29 on epoch=262
06/12/2022 02:10:06 - INFO - __main__ - Global step 1050 Train loss 0.28 Classification-F1 0.3333333333333333 on epoch=262
06/12/2022 02:10:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.30 on epoch=264
06/12/2022 02:10:15 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.32 on epoch=267
06/12/2022 02:10:19 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.30 on epoch=269
06/12/2022 02:10:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.28 on epoch=272
06/12/2022 02:10:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.28 on epoch=274
06/12/2022 02:10:31 - INFO - __main__ - Global step 1100 Train loss 0.30 Classification-F1 0.3333333333333333 on epoch=274
06/12/2022 02:10:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.28 on epoch=277
06/12/2022 02:10:40 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.24 on epoch=279
06/12/2022 02:10:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.29 on epoch=282
06/12/2022 02:10:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.26 on epoch=284
06/12/2022 02:10:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.33 on epoch=287
06/12/2022 02:10:56 - INFO - __main__ - Global step 1150 Train loss 0.28 Classification-F1 0.3333333333333333 on epoch=287
06/12/2022 02:11:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.27 on epoch=289
06/12/2022 02:11:06 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.27 on epoch=292
06/12/2022 02:11:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.29 on epoch=294
06/12/2022 02:11:15 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.33 on epoch=297
06/12/2022 02:11:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.30 on epoch=299
06/12/2022 02:11:22 - INFO - __main__ - Global step 1200 Train loss 0.29 Classification-F1 0.3333333333333333 on epoch=299
06/12/2022 02:11:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.28 on epoch=302
06/12/2022 02:11:31 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.29 on epoch=304
06/12/2022 02:11:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.29 on epoch=307
06/12/2022 02:11:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.32 on epoch=309
06/12/2022 02:11:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.29 on epoch=312
06/12/2022 02:11:47 - INFO - __main__ - Global step 1250 Train loss 0.29 Classification-F1 0.3333333333333333 on epoch=312
06/12/2022 02:11:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.33 on epoch=314
06/12/2022 02:11:56 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.30 on epoch=317
06/12/2022 02:12:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.31 on epoch=319
06/12/2022 02:12:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.29 on epoch=322
06/12/2022 02:12:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.27 on epoch=324
06/12/2022 02:12:13 - INFO - __main__ - Global step 1300 Train loss 0.30 Classification-F1 0.3333333333333333 on epoch=324
06/12/2022 02:12:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.28 on epoch=327
06/12/2022 02:12:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.27 on epoch=329
06/12/2022 02:12:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.24 on epoch=332
06/12/2022 02:12:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.24 on epoch=334
06/12/2022 02:12:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.29 on epoch=337
06/12/2022 02:12:39 - INFO - __main__ - Global step 1350 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=337
06/12/2022 02:12:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.28 on epoch=339
06/12/2022 02:12:48 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.28 on epoch=342
06/12/2022 02:12:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.26 on epoch=344
06/12/2022 02:12:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.21 on epoch=347
06/12/2022 02:13:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.26 on epoch=349
06/12/2022 02:13:04 - INFO - __main__ - Global step 1400 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=349
06/12/2022 02:13:09 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.29 on epoch=352
06/12/2022 02:13:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.26 on epoch=354
06/12/2022 02:13:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.25 on epoch=357
06/12/2022 02:13:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.30 on epoch=359
06/12/2022 02:13:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.26 on epoch=362
06/12/2022 02:13:29 - INFO - __main__ - Global step 1450 Train loss 0.27 Classification-F1 0.3333333333333333 on epoch=362
06/12/2022 02:13:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.26 on epoch=364
06/12/2022 02:13:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.27 on epoch=367
06/12/2022 02:13:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.30 on epoch=369
06/12/2022 02:13:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.26 on epoch=372
06/12/2022 02:13:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.29 on epoch=374
06/12/2022 02:13:55 - INFO - __main__ - Global step 1500 Train loss 0.28 Classification-F1 0.3333333333333333 on epoch=374
06/12/2022 02:13:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.29 on epoch=377
06/12/2022 02:14:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.26 on epoch=379
06/12/2022 02:14:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.20 on epoch=382
06/12/2022 02:14:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.29 on epoch=384
06/12/2022 02:14:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.28 on epoch=387
06/12/2022 02:14:20 - INFO - __main__ - Global step 1550 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=387
06/12/2022 02:14:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.25 on epoch=389
06/12/2022 02:14:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.25 on epoch=392
06/12/2022 02:14:34 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.24 on epoch=394
06/12/2022 02:14:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.25 on epoch=397
06/12/2022 02:14:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.27 on epoch=399
06/12/2022 02:14:45 - INFO - __main__ - Global step 1600 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=399
06/12/2022 02:14:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.28 on epoch=402
06/12/2022 02:14:55 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.24 on epoch=404
06/12/2022 02:14:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.24 on epoch=407
06/12/2022 02:15:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.24 on epoch=409
06/12/2022 02:15:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.25 on epoch=412
06/12/2022 02:15:11 - INFO - __main__ - Global step 1650 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=412
06/12/2022 02:15:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.24 on epoch=414
06/12/2022 02:15:20 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.29 on epoch=417
06/12/2022 02:15:25 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.25 on epoch=419
06/12/2022 02:15:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.26 on epoch=422
06/12/2022 02:15:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.26 on epoch=424
06/12/2022 02:15:36 - INFO - __main__ - Global step 1700 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=424
06/12/2022 02:15:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.26 on epoch=427
06/12/2022 02:15:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.23 on epoch=429
06/12/2022 02:15:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.22 on epoch=432
06/12/2022 02:15:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.24 on epoch=434
06/12/2022 02:15:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.26 on epoch=437
06/12/2022 02:16:02 - INFO - __main__ - Global step 1750 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=437
06/12/2022 02:16:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.25 on epoch=439
06/12/2022 02:16:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.24 on epoch=442
06/12/2022 02:16:15 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.24 on epoch=444
06/12/2022 02:16:20 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.24 on epoch=447
06/12/2022 02:16:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.25 on epoch=449
06/12/2022 02:16:27 - INFO - __main__ - Global step 1800 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=449
06/12/2022 02:16:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.25 on epoch=452
06/12/2022 02:16:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.25 on epoch=454
06/12/2022 02:16:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.24 on epoch=457
06/12/2022 02:16:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.25 on epoch=459
06/12/2022 02:16:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.22 on epoch=462
06/12/2022 02:16:53 - INFO - __main__ - Global step 1850 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=462
06/12/2022 02:16:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.27 on epoch=464
06/12/2022 02:17:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.23 on epoch=467
06/12/2022 02:17:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.25 on epoch=469
06/12/2022 02:17:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.23 on epoch=472
06/12/2022 02:17:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.24 on epoch=474
06/12/2022 02:17:18 - INFO - __main__ - Global step 1900 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=474
06/12/2022 02:17:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.23 on epoch=477
06/12/2022 02:17:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.24 on epoch=479
06/12/2022 02:17:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.23 on epoch=482
06/12/2022 02:17:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.23 on epoch=484
06/12/2022 02:17:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.22 on epoch=487
06/12/2022 02:17:44 - INFO - __main__ - Global step 1950 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=487
06/12/2022 02:17:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.24 on epoch=489
06/12/2022 02:17:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.25 on epoch=492
06/12/2022 02:17:57 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.23 on epoch=494
06/12/2022 02:18:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.22 on epoch=497
06/12/2022 02:18:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.22 on epoch=499
06/12/2022 02:18:09 - INFO - __main__ - Global step 2000 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=499
06/12/2022 02:18:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.21 on epoch=502
06/12/2022 02:18:18 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.27 on epoch=504
06/12/2022 02:18:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.24 on epoch=507
06/12/2022 02:18:27 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.27 on epoch=509
06/12/2022 02:18:32 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.22 on epoch=512
06/12/2022 02:18:34 - INFO - __main__ - Global step 2050 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=512
06/12/2022 02:18:39 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.23 on epoch=514
06/12/2022 02:18:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.24 on epoch=517
06/12/2022 02:18:48 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.21 on epoch=519
06/12/2022 02:18:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.21 on epoch=522
06/12/2022 02:18:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.23 on epoch=524
06/12/2022 02:19:00 - INFO - __main__ - Global step 2100 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=524
06/12/2022 02:19:04 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.21 on epoch=527
06/12/2022 02:19:09 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.22 on epoch=529
06/12/2022 02:19:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.22 on epoch=532
06/12/2022 02:19:18 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.22 on epoch=534
06/12/2022 02:19:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.22 on epoch=537
06/12/2022 02:19:25 - INFO - __main__ - Global step 2150 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=537
06/12/2022 02:19:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.24 on epoch=539
06/12/2022 02:19:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.20 on epoch=542
06/12/2022 02:19:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.22 on epoch=544
06/12/2022 02:19:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.23 on epoch=547
06/12/2022 02:19:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.23 on epoch=549
06/12/2022 02:19:51 - INFO - __main__ - Global step 2200 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=549
06/12/2022 02:19:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.27 on epoch=552
06/12/2022 02:20:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.20 on epoch=554
06/12/2022 02:20:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.21 on epoch=557
06/12/2022 02:20:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.21 on epoch=559
06/12/2022 02:20:14 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.26 on epoch=562
06/12/2022 02:20:16 - INFO - __main__ - Global step 2250 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=562
06/12/2022 02:20:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.22 on epoch=564
06/12/2022 02:20:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.22 on epoch=567
06/12/2022 02:20:30 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.19 on epoch=569
06/12/2022 02:20:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.21 on epoch=572
06/12/2022 02:20:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.26 on epoch=574
06/12/2022 02:20:42 - INFO - __main__ - Global step 2300 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=574
06/12/2022 02:20:46 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.21 on epoch=577
06/12/2022 02:20:51 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.23 on epoch=579
06/12/2022 02:20:56 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.27 on epoch=582
06/12/2022 02:21:00 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.22 on epoch=584
06/12/2022 02:21:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.23 on epoch=587
06/12/2022 02:21:08 - INFO - __main__ - Global step 2350 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=587
06/12/2022 02:21:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.23 on epoch=589
06/12/2022 02:21:17 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.19 on epoch=592
06/12/2022 02:21:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.21 on epoch=594
06/12/2022 02:21:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.24 on epoch=597
06/12/2022 02:21:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.22 on epoch=599
06/12/2022 02:21:33 - INFO - __main__ - Global step 2400 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=599
06/12/2022 02:21:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.23 on epoch=602
06/12/2022 02:21:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.23 on epoch=604
06/12/2022 02:21:47 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.22 on epoch=607
06/12/2022 02:21:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.22 on epoch=609
06/12/2022 02:21:56 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.22 on epoch=612
06/12/2022 02:21:59 - INFO - __main__ - Global step 2450 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=612
06/12/2022 02:22:03 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.25 on epoch=614
06/12/2022 02:22:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.21 on epoch=617
06/12/2022 02:22:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.20 on epoch=619
06/12/2022 02:22:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.19 on epoch=622
06/12/2022 02:22:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.21 on epoch=624
06/12/2022 02:22:25 - INFO - __main__ - Global step 2500 Train loss 0.21 Classification-F1 0.1702127659574468 on epoch=624
06/12/2022 02:22:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.22 on epoch=627
06/12/2022 02:22:34 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.22 on epoch=629
06/12/2022 02:22:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.24 on epoch=632
06/12/2022 02:22:43 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.19 on epoch=634
06/12/2022 02:22:47 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.22 on epoch=637
06/12/2022 02:22:50 - INFO - __main__ - Global step 2550 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=637
06/12/2022 02:22:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.23 on epoch=639
06/12/2022 02:22:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.24 on epoch=642
06/12/2022 02:23:04 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.21 on epoch=644
06/12/2022 02:23:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.22 on epoch=647
06/12/2022 02:23:13 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.20 on epoch=649
06/12/2022 02:23:15 - INFO - __main__ - Global step 2600 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=649
06/12/2022 02:23:20 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.21 on epoch=652
06/12/2022 02:23:24 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.23 on epoch=654
06/12/2022 02:23:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.20 on epoch=657
06/12/2022 02:23:34 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.21 on epoch=659
06/12/2022 02:23:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.23 on epoch=662
06/12/2022 02:23:41 - INFO - __main__ - Global step 2650 Train loss 0.22 Classification-F1 0.24242424242424243 on epoch=662
06/12/2022 02:23:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.19 on epoch=664
06/12/2022 02:23:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.19 on epoch=667
06/12/2022 02:23:54 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.18 on epoch=669
06/12/2022 02:23:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.19 on epoch=672
06/12/2022 02:24:03 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.20 on epoch=674
06/12/2022 02:24:06 - INFO - __main__ - Global step 2700 Train loss 0.19 Classification-F1 0.24895351398986562 on epoch=674
06/12/2022 02:24:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.23 on epoch=677
06/12/2022 02:24:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.20 on epoch=679
06/12/2022 02:24:20 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.22 on epoch=682
06/12/2022 02:24:25 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.23 on epoch=684
06/12/2022 02:24:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.20 on epoch=687
06/12/2022 02:24:32 - INFO - __main__ - Global step 2750 Train loss 0.21 Classification-F1 0.39047619047619053 on epoch=687
06/12/2022 02:24:32 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.39047619047619053 on epoch=687, global_step=2750
06/12/2022 02:24:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.17 on epoch=689
06/12/2022 02:24:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.22 on epoch=692
06/12/2022 02:24:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.21 on epoch=694
06/12/2022 02:24:50 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.20 on epoch=697
06/12/2022 02:24:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.21 on epoch=699
06/12/2022 02:24:57 - INFO - __main__ - Global step 2800 Train loss 0.20 Classification-F1 0.39047619047619053 on epoch=699
06/12/2022 02:25:02 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.20 on epoch=702
06/12/2022 02:25:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.22 on epoch=704
06/12/2022 02:25:11 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.22 on epoch=707
06/12/2022 02:25:16 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.21 on epoch=709
06/12/2022 02:25:20 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.22 on epoch=712
06/12/2022 02:25:23 - INFO - __main__ - Global step 2850 Train loss 0.21 Classification-F1 0.2346616065781151 on epoch=712
06/12/2022 02:25:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.17 on epoch=714
06/12/2022 02:25:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.20 on epoch=717
06/12/2022 02:25:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.21 on epoch=719
06/12/2022 02:25:41 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.22 on epoch=722
06/12/2022 02:25:46 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.20 on epoch=724
06/12/2022 02:25:49 - INFO - __main__ - Global step 2900 Train loss 0.20 Classification-F1 0.3591989987484355 on epoch=724
06/12/2022 02:25:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.19 on epoch=727
06/12/2022 02:25:58 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.21 on epoch=729
06/12/2022 02:26:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.22 on epoch=732
06/12/2022 02:26:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.20 on epoch=734
06/12/2022 02:26:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.20 on epoch=737
06/12/2022 02:26:14 - INFO - __main__ - Global step 2950 Train loss 0.20 Classification-F1 0.3591989987484355 on epoch=737
06/12/2022 02:26:19 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.19 on epoch=739
06/12/2022 02:26:23 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.18 on epoch=742
06/12/2022 02:26:28 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.21 on epoch=744
06/12/2022 02:26:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.22 on epoch=747
06/12/2022 02:26:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.20 on epoch=749
06/12/2022 02:26:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 02:26:38 - INFO - __main__ - Printing 3 examples
06/12/2022 02:26:38 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/12/2022 02:26:38 - INFO - __main__ - ['entailed']
06/12/2022 02:26:38 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/12/2022 02:26:38 - INFO - __main__ - ['entailed']
06/12/2022 02:26:38 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/12/2022 02:26:38 - INFO - __main__ - ['entailed']
06/12/2022 02:26:38 - INFO - __main__ - Tokenizing Input ...
06/12/2022 02:26:39 - INFO - __main__ - Tokenizing Output ...
06/12/2022 02:26:39 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 02:26:39 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 02:26:39 - INFO - __main__ - Printing 3 examples
06/12/2022 02:26:39 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/12/2022 02:26:39 - INFO - __main__ - ['entailed']
06/12/2022 02:26:39 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/12/2022 02:26:39 - INFO - __main__ - ['entailed']
06/12/2022 02:26:39 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/12/2022 02:26:39 - INFO - __main__ - ['entailed']
06/12/2022 02:26:39 - INFO - __main__ - Tokenizing Input ...
06/12/2022 02:26:39 - INFO - __main__ - Tokenizing Output ...
06/12/2022 02:26:39 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 02:26:40 - INFO - __main__ - Global step 3000 Train loss 0.20 Classification-F1 0.3727353727353727 on epoch=749
06/12/2022 02:26:40 - INFO - __main__ - save last model!
06/12/2022 02:26:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 02:26:40 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 02:26:40 - INFO - __main__ - Printing 3 examples
06/12/2022 02:26:40 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 02:26:40 - INFO - __main__ - ['entailed']
06/12/2022 02:26:40 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 02:26:40 - INFO - __main__ - ['entailed']
06/12/2022 02:26:40 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 02:26:40 - INFO - __main__ - ['entailed']
06/12/2022 02:26:40 - INFO - __main__ - Tokenizing Input ...
06/12/2022 02:26:58 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 02:26:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 02:26:59 - INFO - __main__ - Starting training!
06/12/2022 02:27:05 - INFO - __main__ - Tokenizing Output ...
06/12/2022 02:27:17 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 02:36:33 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_21_0.5_8_predictions.txt
06/12/2022 02:36:33 - INFO - __main__ - Classification-F1 on test data: 0.3752
06/12/2022 02:36:33 - INFO - __main__ - prefix=tab_fact_32_21, lr=0.5, bsz=8, dev_performance=0.39047619047619053, test_performance=0.3752068319097928
06/12/2022 02:36:33 - INFO - __main__ - Running ... prefix=tab_fact_32_21, lr=0.4, bsz=8 ...
06/12/2022 02:36:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 02:36:34 - INFO - __main__ - Printing 3 examples
06/12/2022 02:36:34 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/12/2022 02:36:34 - INFO - __main__ - ['entailed']
06/12/2022 02:36:34 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/12/2022 02:36:34 - INFO - __main__ - ['entailed']
06/12/2022 02:36:34 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/12/2022 02:36:34 - INFO - __main__ - ['entailed']
06/12/2022 02:36:34 - INFO - __main__ - Tokenizing Input ...
06/12/2022 02:36:34 - INFO - __main__ - Tokenizing Output ...
06/12/2022 02:36:34 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 02:36:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 02:36:34 - INFO - __main__ - Printing 3 examples
06/12/2022 02:36:34 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/12/2022 02:36:34 - INFO - __main__ - ['entailed']
06/12/2022 02:36:34 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/12/2022 02:36:34 - INFO - __main__ - ['entailed']
06/12/2022 02:36:34 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/12/2022 02:36:34 - INFO - __main__ - ['entailed']
06/12/2022 02:36:34 - INFO - __main__ - Tokenizing Input ...
06/12/2022 02:36:34 - INFO - __main__ - Tokenizing Output ...
06/12/2022 02:36:34 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 02:36:54 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 02:36:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 02:36:55 - INFO - __main__ - Starting training!
06/12/2022 02:37:00 - INFO - __main__ - Step 10 Global step 10 Train loss 3.11 on epoch=2
06/12/2022 02:37:05 - INFO - __main__ - Step 20 Global step 20 Train loss 0.63 on epoch=4
06/12/2022 02:37:09 - INFO - __main__ - Step 30 Global step 30 Train loss 0.39 on epoch=7
06/12/2022 02:37:14 - INFO - __main__ - Step 40 Global step 40 Train loss 0.34 on epoch=9
06/12/2022 02:37:18 - INFO - __main__ - Step 50 Global step 50 Train loss 0.27 on epoch=12
06/12/2022 02:37:21 - INFO - __main__ - Global step 50 Train loss 0.95 Classification-F1 0.5058530510585305 on epoch=12
06/12/2022 02:37:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.5058530510585305 on epoch=12, global_step=50
06/12/2022 02:37:26 - INFO - __main__ - Step 60 Global step 60 Train loss 0.27 on epoch=14
06/12/2022 02:37:30 - INFO - __main__ - Step 70 Global step 70 Train loss 0.26 on epoch=17
06/12/2022 02:37:34 - INFO - __main__ - Step 80 Global step 80 Train loss 0.25 on epoch=19
06/12/2022 02:37:39 - INFO - __main__ - Step 90 Global step 90 Train loss 0.25 on epoch=22
06/12/2022 02:37:43 - INFO - __main__ - Step 100 Global step 100 Train loss 0.28 on epoch=24
06/12/2022 02:37:46 - INFO - __main__ - Global step 100 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=24
06/12/2022 02:37:50 - INFO - __main__ - Step 110 Global step 110 Train loss 0.28 on epoch=27
06/12/2022 02:37:55 - INFO - __main__ - Step 120 Global step 120 Train loss 0.23 on epoch=29
06/12/2022 02:37:59 - INFO - __main__ - Step 130 Global step 130 Train loss 0.24 on epoch=32
06/12/2022 02:38:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.28 on epoch=34
06/12/2022 02:38:08 - INFO - __main__ - Step 150 Global step 150 Train loss 0.22 on epoch=37
06/12/2022 02:38:11 - INFO - __main__ - Global step 150 Train loss 0.25 Classification-F1 0.21985815602836878 on epoch=37
06/12/2022 02:38:15 - INFO - __main__ - Step 160 Global step 160 Train loss 0.24 on epoch=39
06/12/2022 02:38:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.22 on epoch=42
06/12/2022 02:38:25 - INFO - __main__ - Step 180 Global step 180 Train loss 0.25 on epoch=44
06/12/2022 02:38:29 - INFO - __main__ - Step 190 Global step 190 Train loss 0.23 on epoch=47
06/12/2022 02:38:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.23 on epoch=49
06/12/2022 02:38:37 - INFO - __main__ - Global step 200 Train loss 0.23 Classification-F1 0.21276595744680848 on epoch=49
06/12/2022 02:38:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.24 on epoch=52
06/12/2022 02:38:46 - INFO - __main__ - Step 220 Global step 220 Train loss 0.22 on epoch=54
06/12/2022 02:38:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.21 on epoch=57
06/12/2022 02:38:55 - INFO - __main__ - Step 240 Global step 240 Train loss 0.24 on epoch=59
06/12/2022 02:38:59 - INFO - __main__ - Step 250 Global step 250 Train loss 0.22 on epoch=62
06/12/2022 02:39:02 - INFO - __main__ - Global step 250 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=62
06/12/2022 02:39:06 - INFO - __main__ - Step 260 Global step 260 Train loss 0.22 on epoch=64
06/12/2022 02:39:11 - INFO - __main__ - Step 270 Global step 270 Train loss 0.20 on epoch=67
06/12/2022 02:39:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.20 on epoch=69
06/12/2022 02:39:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.23 on epoch=72
06/12/2022 02:39:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.23 on epoch=74
06/12/2022 02:39:28 - INFO - __main__ - Global step 300 Train loss 0.21 Classification-F1 0.4181818181818182 on epoch=74
06/12/2022 02:39:32 - INFO - __main__ - Step 310 Global step 310 Train loss 0.20 on epoch=77
06/12/2022 02:39:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.19 on epoch=79
06/12/2022 02:39:41 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/12/2022 02:39:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=84
06/12/2022 02:39:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=87
06/12/2022 02:39:53 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.3671451355661882 on epoch=87
06/12/2022 02:39:58 - INFO - __main__ - Step 360 Global step 360 Train loss 0.19 on epoch=89
06/12/2022 02:40:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.20 on epoch=92
06/12/2022 02:40:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=94
06/12/2022 02:40:11 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/12/2022 02:40:16 - INFO - __main__ - Step 400 Global step 400 Train loss 0.18 on epoch=99
06/12/2022 02:40:19 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.39756367663344405 on epoch=99
06/12/2022 02:40:23 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=102
06/12/2022 02:40:28 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=104
06/12/2022 02:40:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.16 on epoch=107
06/12/2022 02:40:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.18 on epoch=109
06/12/2022 02:40:41 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=112
06/12/2022 02:40:44 - INFO - __main__ - Global step 450 Train loss 0.20 Classification-F1 0.3511520737327189 on epoch=112
06/12/2022 02:40:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=114
06/12/2022 02:40:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=117
06/12/2022 02:40:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=119
06/12/2022 02:41:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=122
06/12/2022 02:41:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.17 on epoch=124
06/12/2022 02:41:10 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.4181818181818182 on epoch=124
06/12/2022 02:41:14 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=127
06/12/2022 02:41:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=129
06/12/2022 02:41:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=132
06/12/2022 02:41:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=134
06/12/2022 02:41:32 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=137
06/12/2022 02:41:35 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.5620723362658846 on epoch=137
06/12/2022 02:41:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5058530510585305 -> 0.5620723362658846 on epoch=137, global_step=550
06/12/2022 02:41:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=139
06/12/2022 02:41:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=142
06/12/2022 02:41:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=144
06/12/2022 02:41:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
06/12/2022 02:41:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=149
06/12/2022 02:42:01 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.5195195195195195 on epoch=149
06/12/2022 02:42:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=152
06/12/2022 02:42:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=154
06/12/2022 02:42:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=157
06/12/2022 02:42:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=159
06/12/2022 02:42:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=162
06/12/2022 02:42:27 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.4980392156862745 on epoch=162
06/12/2022 02:42:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=164
06/12/2022 02:42:36 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=167
06/12/2022 02:42:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=169
06/12/2022 02:42:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=172
06/12/2022 02:42:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=174
06/12/2022 02:42:53 - INFO - __main__ - Global step 700 Train loss 0.14 Classification-F1 0.47813194959229055 on epoch=174
06/12/2022 02:42:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=177
06/12/2022 02:43:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=179
06/12/2022 02:43:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=182
06/12/2022 02:43:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=184
06/12/2022 02:43:16 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=187
06/12/2022 02:43:19 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.24344344344344346 on epoch=187
06/12/2022 02:43:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=189
06/12/2022 02:43:28 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=192
06/12/2022 02:43:33 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=194
06/12/2022 02:43:37 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=197
06/12/2022 02:43:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=199
06/12/2022 02:43:45 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.5270935960591133 on epoch=199
06/12/2022 02:43:49 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=202
06/12/2022 02:43:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=204
06/12/2022 02:43:58 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=207
06/12/2022 02:44:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=209
06/12/2022 02:44:08 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=212
06/12/2022 02:44:11 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.36374269005847953 on epoch=212
06/12/2022 02:44:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=214
06/12/2022 02:44:20 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=217
06/12/2022 02:44:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=219
06/12/2022 02:44:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=222
06/12/2022 02:44:34 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=224
06/12/2022 02:44:37 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.42216142270861834 on epoch=224
06/12/2022 02:44:41 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=227
06/12/2022 02:44:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=229
06/12/2022 02:44:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=232
06/12/2022 02:44:55 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
06/12/2022 02:45:00 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=237
06/12/2022 02:45:03 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.5625 on epoch=237
06/12/2022 02:45:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5620723362658846 -> 0.5625 on epoch=237, global_step=950
06/12/2022 02:45:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=239
06/12/2022 02:45:12 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=242
06/12/2022 02:45:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/12/2022 02:45:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
06/12/2022 02:45:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=249
06/12/2022 02:45:29 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.5205373288555928 on epoch=249
06/12/2022 02:45:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=252
06/12/2022 02:45:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/12/2022 02:45:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=257
06/12/2022 02:45:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=259
06/12/2022 02:45:51 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/12/2022 02:45:54 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.5974842767295597 on epoch=262
06/12/2022 02:45:54 - INFO - __main__ - Saving model with best Classification-F1: 0.5625 -> 0.5974842767295597 on epoch=262, global_step=1050
06/12/2022 02:45:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/12/2022 02:46:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
06/12/2022 02:46:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=269
06/12/2022 02:46:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/12/2022 02:46:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/12/2022 02:46:20 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.3868065967016492 on epoch=274
06/12/2022 02:46:24 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/12/2022 02:46:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=279
06/12/2022 02:46:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/12/2022 02:46:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=284
06/12/2022 02:46:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/12/2022 02:46:45 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.47885474126608885 on epoch=287
06/12/2022 02:46:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
06/12/2022 02:46:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/12/2022 02:46:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/12/2022 02:47:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/12/2022 02:47:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
06/12/2022 02:47:11 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.5413886829750433 on epoch=299
06/12/2022 02:47:16 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=302
06/12/2022 02:47:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/12/2022 02:47:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/12/2022 02:47:29 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=309
06/12/2022 02:47:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/12/2022 02:47:37 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.5730170496664195 on epoch=312
06/12/2022 02:47:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/12/2022 02:47:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/12/2022 02:47:51 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/12/2022 02:47:55 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/12/2022 02:48:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=324
06/12/2022 02:48:03 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.5921568627450979 on epoch=324
06/12/2022 02:48:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/12/2022 02:48:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/12/2022 02:48:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/12/2022 02:48:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/12/2022 02:48:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/12/2022 02:48:29 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.28702507107779784 on epoch=337
06/12/2022 02:48:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/12/2022 02:48:38 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/12/2022 02:48:43 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/12/2022 02:48:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/12/2022 02:48:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/12/2022 02:48:55 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.5273745861981156 on epoch=349
06/12/2022 02:48:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=352
06/12/2022 02:49:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/12/2022 02:49:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/12/2022 02:49:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/12/2022 02:49:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/12/2022 02:49:20 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.387893864013267 on epoch=362
06/12/2022 02:49:25 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=364
06/12/2022 02:49:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/12/2022 02:49:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/12/2022 02:49:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/12/2022 02:49:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/12/2022 02:49:46 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.625 on epoch=374
06/12/2022 02:49:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5974842767295597 -> 0.625 on epoch=374, global_step=1500
06/12/2022 02:49:50 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/12/2022 02:49:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/12/2022 02:49:59 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/12/2022 02:50:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/12/2022 02:50:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/12/2022 02:50:11 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.6190476190476191 on epoch=387
06/12/2022 02:50:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/12/2022 02:50:20 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/12/2022 02:50:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/12/2022 02:50:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/12/2022 02:50:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=399
06/12/2022 02:50:36 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.6559139784946237 on epoch=399
06/12/2022 02:50:36 - INFO - __main__ - Saving model with best Classification-F1: 0.625 -> 0.6559139784946237 on epoch=399, global_step=1600
06/12/2022 02:50:41 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/12/2022 02:50:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/12/2022 02:50:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/12/2022 02:50:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/12/2022 02:50:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/12/2022 02:51:01 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.5933528836754642 on epoch=412
06/12/2022 02:51:06 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/12/2022 02:51:10 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/12/2022 02:51:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/12/2022 02:51:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=422
06/12/2022 02:51:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/12/2022 02:51:27 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.5835835835835835 on epoch=424
06/12/2022 02:51:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/12/2022 02:51:36 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/12/2022 02:51:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/12/2022 02:51:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/12/2022 02:51:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/12/2022 02:51:52 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.6190476190476191 on epoch=437
06/12/2022 02:51:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=439
06/12/2022 02:52:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/12/2022 02:52:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/12/2022 02:52:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/12/2022 02:52:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/12/2022 02:52:17 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6559139784946237 on epoch=449
06/12/2022 02:52:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/12/2022 02:52:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/12/2022 02:52:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/12/2022 02:52:35 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/12/2022 02:52:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/12/2022 02:52:43 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6216748768472906 on epoch=462
06/12/2022 02:52:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/12/2022 02:52:52 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/12/2022 02:52:56 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/12/2022 02:53:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/12/2022 02:53:05 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/12/2022 02:53:08 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.3966583124477861 on epoch=474
06/12/2022 02:53:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/12/2022 02:53:17 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/12/2022 02:53:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/12/2022 02:53:26 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/12/2022 02:53:30 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/12/2022 02:53:33 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.47885474126608885 on epoch=487
06/12/2022 02:53:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/12/2022 02:53:42 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/12/2022 02:53:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/12/2022 02:53:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/12/2022 02:53:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/12/2022 02:53:59 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.624633431085044 on epoch=499
06/12/2022 02:54:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/12/2022 02:54:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/12/2022 02:54:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/12/2022 02:54:17 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/12/2022 02:54:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/12/2022 02:54:24 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.6398336187912894 on epoch=512
06/12/2022 02:54:29 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/12/2022 02:54:33 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/12/2022 02:54:38 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/12/2022 02:54:43 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/12/2022 02:54:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/12/2022 02:54:50 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.6235294117647059 on epoch=524
06/12/2022 02:54:54 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/12/2022 02:54:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/12/2022 02:55:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/12/2022 02:55:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/12/2022 02:55:12 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/12/2022 02:55:15 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.577195987276731 on epoch=537
06/12/2022 02:55:20 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/12/2022 02:55:25 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/12/2022 02:55:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/12/2022 02:55:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/12/2022 02:55:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/12/2022 02:55:41 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6405372405372406 on epoch=549
06/12/2022 02:55:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/12/2022 02:55:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=554
06/12/2022 02:55:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/12/2022 02:55:59 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/12/2022 02:56:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/12/2022 02:56:07 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.5586206896551724 on epoch=562
06/12/2022 02:56:11 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/12/2022 02:56:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/12/2022 02:56:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/12/2022 02:56:25 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/12/2022 02:56:30 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/12/2022 02:56:33 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.5555555555555556 on epoch=574
06/12/2022 02:56:37 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/12/2022 02:56:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/12/2022 02:56:46 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/12/2022 02:56:51 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/12/2022 02:56:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/12/2022 02:56:58 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.624633431085044 on epoch=587
06/12/2022 02:57:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/12/2022 02:57:07 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/12/2022 02:57:12 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/12/2022 02:57:16 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/12/2022 02:57:21 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/12/2022 02:57:24 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.6398336187912894 on epoch=599
06/12/2022 02:57:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/12/2022 02:57:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/12/2022 02:57:37 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/12/2022 02:57:42 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/12/2022 02:57:46 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/12/2022 02:57:49 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.4947797300738477 on epoch=612
06/12/2022 02:57:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/12/2022 02:57:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/12/2022 02:58:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/12/2022 02:58:07 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/12/2022 02:58:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/12/2022 02:58:15 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6046454163577959 on epoch=624
06/12/2022 02:58:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/12/2022 02:58:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/12/2022 02:58:29 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/12/2022 02:58:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/12/2022 02:58:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/12/2022 02:58:40 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.5873015873015872 on epoch=637
06/12/2022 02:58:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/12/2022 02:58:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/12/2022 02:58:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/12/2022 02:58:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=647
06/12/2022 02:59:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/12/2022 02:59:06 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.48747093774218553 on epoch=649
06/12/2022 02:59:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/12/2022 02:59:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/12/2022 02:59:20 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/12/2022 02:59:24 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/12/2022 02:59:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/12/2022 02:59:31 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.6216748768472906 on epoch=662
06/12/2022 02:59:36 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/12/2022 02:59:40 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/12/2022 02:59:45 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/12/2022 02:59:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/12/2022 02:59:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/12/2022 02:59:57 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.5205373288555928 on epoch=674
06/12/2022 03:00:01 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/12/2022 03:00:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/12/2022 03:00:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/12/2022 03:00:15 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/12/2022 03:00:19 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/12/2022 03:00:22 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.5730170496664195 on epoch=687
06/12/2022 03:00:26 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/12/2022 03:00:31 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/12/2022 03:00:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/12/2022 03:00:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/12/2022 03:00:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/12/2022 03:00:47 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.3707292197858236 on epoch=699
06/12/2022 03:00:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=702
06/12/2022 03:00:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/12/2022 03:01:01 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/12/2022 03:01:06 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/12/2022 03:01:10 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/12/2022 03:01:13 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6362737830491723 on epoch=712
06/12/2022 03:01:18 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/12/2022 03:01:22 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/12/2022 03:01:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=719
06/12/2022 03:01:31 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/12/2022 03:01:36 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/12/2022 03:01:38 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6085148030340103 on epoch=724
06/12/2022 03:01:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/12/2022 03:01:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/12/2022 03:01:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/12/2022 03:01:56 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/12/2022 03:02:01 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/12/2022 03:02:04 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6235294117647059 on epoch=737
06/12/2022 03:02:08 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/12/2022 03:02:13 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/12/2022 03:02:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/12/2022 03:02:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/12/2022 03:02:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/12/2022 03:02:27 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 03:02:27 - INFO - __main__ - Printing 3 examples
06/12/2022 03:02:27 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/12/2022 03:02:27 - INFO - __main__ - ['entailed']
06/12/2022 03:02:27 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/12/2022 03:02:27 - INFO - __main__ - ['entailed']
06/12/2022 03:02:27 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/12/2022 03:02:27 - INFO - __main__ - ['entailed']
06/12/2022 03:02:27 - INFO - __main__ - Tokenizing Input ...
06/12/2022 03:02:27 - INFO - __main__ - Tokenizing Output ...
06/12/2022 03:02:28 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 03:02:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 03:02:28 - INFO - __main__ - Printing 3 examples
06/12/2022 03:02:28 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/12/2022 03:02:28 - INFO - __main__ - ['entailed']
06/12/2022 03:02:28 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/12/2022 03:02:28 - INFO - __main__ - ['entailed']
06/12/2022 03:02:28 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/12/2022 03:02:28 - INFO - __main__ - ['entailed']
06/12/2022 03:02:28 - INFO - __main__ - Tokenizing Input ...
06/12/2022 03:02:28 - INFO - __main__ - Tokenizing Output ...
06/12/2022 03:02:28 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 03:02:29 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6085148030340103 on epoch=749
06/12/2022 03:02:29 - INFO - __main__ - save last model!
06/12/2022 03:02:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 03:02:29 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 03:02:29 - INFO - __main__ - Printing 3 examples
06/12/2022 03:02:29 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 03:02:29 - INFO - __main__ - ['entailed']
06/12/2022 03:02:29 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 03:02:29 - INFO - __main__ - ['entailed']
06/12/2022 03:02:29 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 03:02:29 - INFO - __main__ - ['entailed']
06/12/2022 03:02:29 - INFO - __main__ - Tokenizing Input ...
06/12/2022 03:02:48 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 03:02:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 03:02:49 - INFO - __main__ - Starting training!
06/12/2022 03:02:54 - INFO - __main__ - Tokenizing Output ...
06/12/2022 03:03:07 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 03:11:56 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_21_0.4_8_predictions.txt
06/12/2022 03:11:56 - INFO - __main__ - Classification-F1 on test data: 0.0368
06/12/2022 03:11:56 - INFO - __main__ - prefix=tab_fact_32_21, lr=0.4, bsz=8, dev_performance=0.6559139784946237, test_performance=0.0368001731539345
06/12/2022 03:11:56 - INFO - __main__ - Running ... prefix=tab_fact_32_21, lr=0.3, bsz=8 ...
06/12/2022 03:11:57 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 03:11:57 - INFO - __main__ - Printing 3 examples
06/12/2022 03:11:57 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/12/2022 03:11:57 - INFO - __main__ - ['entailed']
06/12/2022 03:11:57 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/12/2022 03:11:57 - INFO - __main__ - ['entailed']
06/12/2022 03:11:57 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/12/2022 03:11:57 - INFO - __main__ - ['entailed']
06/12/2022 03:11:57 - INFO - __main__ - Tokenizing Input ...
06/12/2022 03:11:57 - INFO - __main__ - Tokenizing Output ...
06/12/2022 03:11:58 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 03:11:58 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 03:11:58 - INFO - __main__ - Printing 3 examples
06/12/2022 03:11:58 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/12/2022 03:11:58 - INFO - __main__ - ['entailed']
06/12/2022 03:11:58 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/12/2022 03:11:58 - INFO - __main__ - ['entailed']
06/12/2022 03:11:58 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/12/2022 03:11:58 - INFO - __main__ - ['entailed']
06/12/2022 03:11:58 - INFO - __main__ - Tokenizing Input ...
06/12/2022 03:11:58 - INFO - __main__ - Tokenizing Output ...
06/12/2022 03:11:58 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 03:12:17 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 03:12:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 03:12:19 - INFO - __main__ - Starting training!
06/12/2022 03:12:24 - INFO - __main__ - Step 10 Global step 10 Train loss 3.38 on epoch=2
06/12/2022 03:12:28 - INFO - __main__ - Step 20 Global step 20 Train loss 0.78 on epoch=4
06/12/2022 03:12:33 - INFO - __main__ - Step 30 Global step 30 Train loss 0.44 on epoch=7
06/12/2022 03:12:37 - INFO - __main__ - Step 40 Global step 40 Train loss 0.37 on epoch=9
06/12/2022 03:12:42 - INFO - __main__ - Step 50 Global step 50 Train loss 0.33 on epoch=12
06/12/2022 03:12:44 - INFO - __main__ - Global step 50 Train loss 1.06 Classification-F1 0.3333333333333333 on epoch=12
06/12/2022 03:12:44 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/12/2022 03:12:49 - INFO - __main__ - Step 60 Global step 60 Train loss 0.30 on epoch=14
06/12/2022 03:12:54 - INFO - __main__ - Step 70 Global step 70 Train loss 0.28 on epoch=17
06/12/2022 03:12:58 - INFO - __main__ - Step 80 Global step 80 Train loss 0.32 on epoch=19
06/12/2022 03:13:03 - INFO - __main__ - Step 90 Global step 90 Train loss 0.28 on epoch=22
06/12/2022 03:13:07 - INFO - __main__ - Step 100 Global step 100 Train loss 0.27 on epoch=24
06/12/2022 03:13:10 - INFO - __main__ - Global step 100 Train loss 0.29 Classification-F1 0.3333333333333333 on epoch=24
06/12/2022 03:13:14 - INFO - __main__ - Step 110 Global step 110 Train loss 0.25 on epoch=27
06/12/2022 03:13:19 - INFO - __main__ - Step 120 Global step 120 Train loss 0.29 on epoch=29
06/12/2022 03:13:23 - INFO - __main__ - Step 130 Global step 130 Train loss 0.22 on epoch=32
06/12/2022 03:13:28 - INFO - __main__ - Step 140 Global step 140 Train loss 0.25 on epoch=34
06/12/2022 03:13:32 - INFO - __main__ - Step 150 Global step 150 Train loss 0.24 on epoch=37
06/12/2022 03:13:35 - INFO - __main__ - Global step 150 Train loss 0.25 Classification-F1 0.22456140350877193 on epoch=37
06/12/2022 03:13:40 - INFO - __main__ - Step 160 Global step 160 Train loss 0.22 on epoch=39
06/12/2022 03:13:44 - INFO - __main__ - Step 170 Global step 170 Train loss 0.27 on epoch=42
06/12/2022 03:13:49 - INFO - __main__ - Step 180 Global step 180 Train loss 0.21 on epoch=44
06/12/2022 03:13:53 - INFO - __main__ - Step 190 Global step 190 Train loss 0.22 on epoch=47
06/12/2022 03:13:58 - INFO - __main__ - Step 200 Global step 200 Train loss 0.21 on epoch=49
06/12/2022 03:14:01 - INFO - __main__ - Global step 200 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=49
06/12/2022 03:14:05 - INFO - __main__ - Step 210 Global step 210 Train loss 0.22 on epoch=52
06/12/2022 03:14:10 - INFO - __main__ - Step 220 Global step 220 Train loss 0.28 on epoch=54
06/12/2022 03:14:14 - INFO - __main__ - Step 230 Global step 230 Train loss 0.24 on epoch=57
06/12/2022 03:14:19 - INFO - __main__ - Step 240 Global step 240 Train loss 0.24 on epoch=59
06/12/2022 03:14:23 - INFO - __main__ - Step 250 Global step 250 Train loss 0.24 on epoch=62
06/12/2022 03:14:26 - INFO - __main__ - Global step 250 Train loss 0.24 Classification-F1 0.2175438596491228 on epoch=62
06/12/2022 03:14:31 - INFO - __main__ - Step 260 Global step 260 Train loss 0.22 on epoch=64
06/12/2022 03:14:35 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=67
06/12/2022 03:14:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.21 on epoch=69
06/12/2022 03:14:44 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=72
06/12/2022 03:14:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.22 on epoch=74
06/12/2022 03:14:51 - INFO - __main__ - Global step 300 Train loss 0.22 Classification-F1 0.3591989987484355 on epoch=74
06/12/2022 03:14:51 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.3591989987484355 on epoch=74, global_step=300
06/12/2022 03:14:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.21 on epoch=77
06/12/2022 03:15:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.20 on epoch=79
06/12/2022 03:15:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.24 on epoch=82
06/12/2022 03:15:09 - INFO - __main__ - Step 340 Global step 340 Train loss 0.20 on epoch=84
06/12/2022 03:15:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=87
06/12/2022 03:15:17 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=87
06/12/2022 03:15:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.19 on epoch=89
06/12/2022 03:15:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.18 on epoch=92
06/12/2022 03:15:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=94
06/12/2022 03:15:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=97
06/12/2022 03:15:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/12/2022 03:15:42 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.3511520737327189 on epoch=99
06/12/2022 03:15:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=102
06/12/2022 03:15:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.15 on epoch=104
06/12/2022 03:15:56 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=107
06/12/2022 03:16:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=109
06/12/2022 03:16:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/12/2022 03:16:08 - INFO - __main__ - Global step 450 Train loss 0.19 Classification-F1 0.3591989987484355 on epoch=112
06/12/2022 03:16:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=114
06/12/2022 03:16:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=117
06/12/2022 03:16:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=119
06/12/2022 03:16:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=122
06/12/2022 03:16:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=124
06/12/2022 03:16:33 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.39047619047619053 on epoch=124
06/12/2022 03:16:33 - INFO - __main__ - Saving model with best Classification-F1: 0.3591989987484355 -> 0.39047619047619053 on epoch=124, global_step=500
06/12/2022 03:16:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=127
06/12/2022 03:16:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.16 on epoch=129
06/12/2022 03:16:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=132
06/12/2022 03:16:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=134
06/12/2022 03:16:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=137
06/12/2022 03:16:58 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.3591989987484355 on epoch=137
06/12/2022 03:17:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.16 on epoch=139
06/12/2022 03:17:07 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=142
06/12/2022 03:17:12 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=144
06/12/2022 03:17:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=147
06/12/2022 03:17:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=149
06/12/2022 03:17:24 - INFO - __main__ - Global step 600 Train loss 0.16 Classification-F1 0.47885474126608885 on epoch=149
06/12/2022 03:17:24 - INFO - __main__ - Saving model with best Classification-F1: 0.39047619047619053 -> 0.47885474126608885 on epoch=149, global_step=600
06/12/2022 03:17:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=152
06/12/2022 03:17:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=154
06/12/2022 03:17:37 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=157
06/12/2022 03:17:42 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=159
06/12/2022 03:17:46 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=162
06/12/2022 03:17:49 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.4920634920634921 on epoch=162
06/12/2022 03:17:49 - INFO - __main__ - Saving model with best Classification-F1: 0.47885474126608885 -> 0.4920634920634921 on epoch=162, global_step=650
06/12/2022 03:17:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=164
06/12/2022 03:17:59 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
06/12/2022 03:18:03 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=169
06/12/2022 03:18:08 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=172
06/12/2022 03:18:12 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=174
06/12/2022 03:18:15 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.41075141075141075 on epoch=174
06/12/2022 03:18:20 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=177
06/12/2022 03:18:24 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=179
06/12/2022 03:18:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=182
06/12/2022 03:18:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.12 on epoch=184
06/12/2022 03:18:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=187
06/12/2022 03:18:41 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.5933528836754642 on epoch=187
06/12/2022 03:18:41 - INFO - __main__ - Saving model with best Classification-F1: 0.4920634920634921 -> 0.5933528836754642 on epoch=187, global_step=750
06/12/2022 03:18:45 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=189
06/12/2022 03:18:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=192
06/12/2022 03:18:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=194
06/12/2022 03:18:59 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=197
06/12/2022 03:19:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=199
06/12/2022 03:19:06 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.40116959064327484 on epoch=199
06/12/2022 03:19:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=202
06/12/2022 03:19:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=204
06/12/2022 03:19:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=207
06/12/2022 03:19:24 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=209
06/12/2022 03:19:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=212
06/12/2022 03:19:32 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.4420512820512821 on epoch=212
06/12/2022 03:19:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=214
06/12/2022 03:19:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=217
06/12/2022 03:19:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=219
06/12/2022 03:19:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=222
06/12/2022 03:19:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=224
06/12/2022 03:19:58 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.41075141075141075 on epoch=224
06/12/2022 03:20:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=227
06/12/2022 03:20:07 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=229
06/12/2022 03:20:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=232
06/12/2022 03:20:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=234
06/12/2022 03:20:21 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
06/12/2022 03:20:24 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.4452324665090622 on epoch=237
06/12/2022 03:20:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/12/2022 03:20:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=242
06/12/2022 03:20:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=244
06/12/2022 03:20:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
06/12/2022 03:20:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=249
06/12/2022 03:20:49 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.537733499377335 on epoch=249
06/12/2022 03:20:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=252
06/12/2022 03:20:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=254
06/12/2022 03:21:03 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/12/2022 03:21:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
06/12/2022 03:21:12 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
06/12/2022 03:21:15 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.46843853820598 on epoch=262
06/12/2022 03:21:20 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=264
06/12/2022 03:21:24 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
06/12/2022 03:21:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/12/2022 03:21:33 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/12/2022 03:21:38 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/12/2022 03:21:40 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.4330011074197121 on epoch=274
06/12/2022 03:21:45 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
06/12/2022 03:21:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=279
06/12/2022 03:21:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/12/2022 03:21:59 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=284
06/12/2022 03:22:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
06/12/2022 03:22:06 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.41832473593711617 on epoch=287
06/12/2022 03:22:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=289
06/12/2022 03:22:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
06/12/2022 03:22:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/12/2022 03:22:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
06/12/2022 03:22:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
06/12/2022 03:22:31 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.48747093774218553 on epoch=299
06/12/2022 03:22:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/12/2022 03:22:40 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=304
06/12/2022 03:22:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/12/2022 03:22:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=309
06/12/2022 03:22:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=312
06/12/2022 03:22:57 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.3247097844112769 on epoch=312
06/12/2022 03:23:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/12/2022 03:23:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=317
06/12/2022 03:23:10 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/12/2022 03:23:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/12/2022 03:23:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/12/2022 03:23:22 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.44379029997196523 on epoch=324
06/12/2022 03:23:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=327
06/12/2022 03:23:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/12/2022 03:23:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/12/2022 03:23:40 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/12/2022 03:23:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/12/2022 03:23:48 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.5155067155067155 on epoch=337
06/12/2022 03:23:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/12/2022 03:23:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/12/2022 03:24:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/12/2022 03:24:06 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=347
06/12/2022 03:24:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/12/2022 03:24:14 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.3671794871794871 on epoch=349
06/12/2022 03:24:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/12/2022 03:24:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/12/2022 03:24:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/12/2022 03:24:32 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=359
06/12/2022 03:24:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/12/2022 03:24:39 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.48424908424908425 on epoch=362
06/12/2022 03:24:43 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/12/2022 03:24:48 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/12/2022 03:24:52 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/12/2022 03:24:57 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/12/2022 03:25:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/12/2022 03:25:04 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.2925373134328358 on epoch=374
06/12/2022 03:25:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/12/2022 03:25:13 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/12/2022 03:25:18 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=382
06/12/2022 03:25:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/12/2022 03:25:27 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/12/2022 03:25:30 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.4920634920634921 on epoch=387
06/12/2022 03:25:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=389
06/12/2022 03:25:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/12/2022 03:25:43 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/12/2022 03:25:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=397
06/12/2022 03:25:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/12/2022 03:25:55 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.2513157894736842 on epoch=399
06/12/2022 03:26:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/12/2022 03:26:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/12/2022 03:26:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/12/2022 03:26:13 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/12/2022 03:26:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/12/2022 03:26:21 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.24084507042253522 on epoch=412
06/12/2022 03:26:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/12/2022 03:26:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/12/2022 03:26:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/12/2022 03:26:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/12/2022 03:26:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/12/2022 03:26:46 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.4748717948717949 on epoch=424
06/12/2022 03:26:51 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/12/2022 03:26:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/12/2022 03:27:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/12/2022 03:27:04 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/12/2022 03:27:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/12/2022 03:27:12 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.4995112414467253 on epoch=437
06/12/2022 03:27:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/12/2022 03:27:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/12/2022 03:27:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/12/2022 03:27:30 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/12/2022 03:27:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/12/2022 03:27:37 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.2513157894736842 on epoch=449
06/12/2022 03:27:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/12/2022 03:27:46 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/12/2022 03:27:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/12/2022 03:27:55 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/12/2022 03:28:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/12/2022 03:28:03 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.25396825396825395 on epoch=462
06/12/2022 03:28:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/12/2022 03:28:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/12/2022 03:28:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/12/2022 03:28:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/12/2022 03:28:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/12/2022 03:28:28 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.26606914212548016 on epoch=474
06/12/2022 03:28:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/12/2022 03:28:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/12/2022 03:28:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/12/2022 03:28:46 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/12/2022 03:28:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/12/2022 03:28:54 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.3443262411347518 on epoch=487
06/12/2022 03:28:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=489
06/12/2022 03:29:03 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/12/2022 03:29:07 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/12/2022 03:29:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/12/2022 03:29:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/12/2022 03:29:19 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.46666666666666656 on epoch=499
06/12/2022 03:29:24 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/12/2022 03:29:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/12/2022 03:29:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/12/2022 03:29:37 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/12/2022 03:29:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/12/2022 03:29:45 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.5413886829750433 on epoch=512
06/12/2022 03:29:49 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/12/2022 03:29:54 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/12/2022 03:29:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/12/2022 03:30:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/12/2022 03:30:07 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/12/2022 03:30:10 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.46031746031746035 on epoch=524
06/12/2022 03:30:15 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/12/2022 03:30:19 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/12/2022 03:30:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/12/2022 03:30:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/12/2022 03:30:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/12/2022 03:30:36 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.31851851851851853 on epoch=537
06/12/2022 03:30:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/12/2022 03:30:45 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/12/2022 03:30:49 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/12/2022 03:30:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/12/2022 03:30:58 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/12/2022 03:31:01 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.25554323725055433 on epoch=549
06/12/2022 03:31:06 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/12/2022 03:31:10 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/12/2022 03:31:15 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/12/2022 03:31:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/12/2022 03:31:24 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/12/2022 03:31:27 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.3356492969396195 on epoch=562
06/12/2022 03:31:32 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/12/2022 03:31:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/12/2022 03:31:41 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/12/2022 03:31:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/12/2022 03:31:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/12/2022 03:31:53 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.3398989898989899 on epoch=574
06/12/2022 03:31:57 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/12/2022 03:32:02 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/12/2022 03:32:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/12/2022 03:32:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/12/2022 03:32:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/12/2022 03:32:18 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.3980048159614724 on epoch=587
06/12/2022 03:32:23 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/12/2022 03:32:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/12/2022 03:32:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/12/2022 03:32:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/12/2022 03:32:41 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/12/2022 03:32:44 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.35815060343362237 on epoch=599
06/12/2022 03:32:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/12/2022 03:32:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/12/2022 03:32:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/12/2022 03:33:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/12/2022 03:33:06 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/12/2022 03:33:09 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.3718820861678005 on epoch=612
06/12/2022 03:33:13 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/12/2022 03:33:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/12/2022 03:33:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/12/2022 03:33:26 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/12/2022 03:33:31 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/12/2022 03:33:34 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.5058530510585305 on epoch=624
06/12/2022 03:33:38 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/12/2022 03:33:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/12/2022 03:33:47 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/12/2022 03:33:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/12/2022 03:33:56 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/12/2022 03:33:58 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.3566583953680728 on epoch=637
06/12/2022 03:34:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/12/2022 03:34:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/12/2022 03:34:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/12/2022 03:34:16 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/12/2022 03:34:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/12/2022 03:34:24 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.37678275290215585 on epoch=649
06/12/2022 03:34:28 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/12/2022 03:34:32 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/12/2022 03:34:37 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/12/2022 03:34:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/12/2022 03:34:46 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/12/2022 03:34:49 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.23132592401137245 on epoch=662
06/12/2022 03:34:53 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/12/2022 03:34:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/12/2022 03:35:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/12/2022 03:35:06 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/12/2022 03:35:11 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/12/2022 03:35:14 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.36127946127946126 on epoch=674
06/12/2022 03:35:18 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/12/2022 03:35:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/12/2022 03:35:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/12/2022 03:35:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/12/2022 03:35:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/12/2022 03:35:39 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.25554323725055433 on epoch=687
06/12/2022 03:35:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/12/2022 03:35:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/12/2022 03:35:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/12/2022 03:35:57 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/12/2022 03:36:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/12/2022 03:36:04 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.3671794871794871 on epoch=699
06/12/2022 03:36:08 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/12/2022 03:36:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/12/2022 03:36:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/12/2022 03:36:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/12/2022 03:36:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/12/2022 03:36:29 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.4094292803970223 on epoch=712
06/12/2022 03:36:33 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/12/2022 03:36:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/12/2022 03:36:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/12/2022 03:36:47 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/12/2022 03:36:51 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/12/2022 03:36:54 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.27300443458980045 on epoch=724
06/12/2022 03:36:59 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/12/2022 03:37:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/12/2022 03:37:08 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/12/2022 03:37:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/12/2022 03:37:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/12/2022 03:37:19 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.35415625520573046 on epoch=737
06/12/2022 03:37:24 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/12/2022 03:37:28 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/12/2022 03:37:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/12/2022 03:37:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/12/2022 03:37:42 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/12/2022 03:37:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 03:37:43 - INFO - __main__ - Printing 3 examples
06/12/2022 03:37:43 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/12/2022 03:37:43 - INFO - __main__ - ['entailed']
06/12/2022 03:37:43 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/12/2022 03:37:43 - INFO - __main__ - ['entailed']
06/12/2022 03:37:43 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/12/2022 03:37:43 - INFO - __main__ - ['entailed']
06/12/2022 03:37:43 - INFO - __main__ - Tokenizing Input ...
06/12/2022 03:37:43 - INFO - __main__ - Tokenizing Output ...
06/12/2022 03:37:43 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 03:37:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 03:37:43 - INFO - __main__ - Printing 3 examples
06/12/2022 03:37:43 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/12/2022 03:37:43 - INFO - __main__ - ['entailed']
06/12/2022 03:37:43 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/12/2022 03:37:43 - INFO - __main__ - ['entailed']
06/12/2022 03:37:43 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/12/2022 03:37:43 - INFO - __main__ - ['entailed']
06/12/2022 03:37:43 - INFO - __main__ - Tokenizing Input ...
06/12/2022 03:37:44 - INFO - __main__ - Tokenizing Output ...
06/12/2022 03:37:44 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 03:37:45 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.260395537525355 on epoch=749
06/12/2022 03:37:45 - INFO - __main__ - save last model!
06/12/2022 03:37:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 03:37:45 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 03:37:45 - INFO - __main__ - Printing 3 examples
06/12/2022 03:37:45 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 03:37:45 - INFO - __main__ - ['entailed']
06/12/2022 03:37:45 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 03:37:45 - INFO - __main__ - ['entailed']
06/12/2022 03:37:45 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 03:37:45 - INFO - __main__ - ['entailed']
06/12/2022 03:37:45 - INFO - __main__ - Tokenizing Input ...
06/12/2022 03:37:59 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 03:38:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 03:38:00 - INFO - __main__ - Starting training!
06/12/2022 03:38:10 - INFO - __main__ - Tokenizing Output ...
06/12/2022 03:38:23 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 03:47:19 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_21_0.3_8_predictions.txt
06/12/2022 03:47:19 - INFO - __main__ - Classification-F1 on test data: 0.0214
06/12/2022 03:47:19 - INFO - __main__ - prefix=tab_fact_32_21, lr=0.3, bsz=8, dev_performance=0.5933528836754642, test_performance=0.02141056377917967
06/12/2022 03:47:19 - INFO - __main__ - Running ... prefix=tab_fact_32_21, lr=0.2, bsz=8 ...
06/12/2022 03:47:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 03:47:20 - INFO - __main__ - Printing 3 examples
06/12/2022 03:47:20 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/12/2022 03:47:20 - INFO - __main__ - ['entailed']
06/12/2022 03:47:20 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/12/2022 03:47:20 - INFO - __main__ - ['entailed']
06/12/2022 03:47:20 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/12/2022 03:47:20 - INFO - __main__ - ['entailed']
06/12/2022 03:47:20 - INFO - __main__ - Tokenizing Input ...
06/12/2022 03:47:20 - INFO - __main__ - Tokenizing Output ...
06/12/2022 03:47:20 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 03:47:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 03:47:20 - INFO - __main__ - Printing 3 examples
06/12/2022 03:47:20 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/12/2022 03:47:20 - INFO - __main__ - ['entailed']
06/12/2022 03:47:20 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/12/2022 03:47:20 - INFO - __main__ - ['entailed']
06/12/2022 03:47:20 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/12/2022 03:47:20 - INFO - __main__ - ['entailed']
06/12/2022 03:47:20 - INFO - __main__ - Tokenizing Input ...
06/12/2022 03:47:21 - INFO - __main__ - Tokenizing Output ...
06/12/2022 03:47:21 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 03:47:36 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 03:47:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 03:47:37 - INFO - __main__ - Starting training!
06/12/2022 03:47:42 - INFO - __main__ - Step 10 Global step 10 Train loss 4.17 on epoch=2
06/12/2022 03:47:46 - INFO - __main__ - Step 20 Global step 20 Train loss 1.41 on epoch=4
06/12/2022 03:47:51 - INFO - __main__ - Step 30 Global step 30 Train loss 0.61 on epoch=7
06/12/2022 03:47:55 - INFO - __main__ - Step 40 Global step 40 Train loss 0.43 on epoch=9
06/12/2022 03:48:00 - INFO - __main__ - Step 50 Global step 50 Train loss 0.35 on epoch=12
06/12/2022 03:48:03 - INFO - __main__ - Global step 50 Train loss 1.39 Classification-F1 0.3333333333333333 on epoch=12
06/12/2022 03:48:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/12/2022 03:48:07 - INFO - __main__ - Step 60 Global step 60 Train loss 0.43 on epoch=14
06/12/2022 03:48:12 - INFO - __main__ - Step 70 Global step 70 Train loss 0.34 on epoch=17
06/12/2022 03:48:17 - INFO - __main__ - Step 80 Global step 80 Train loss 0.28 on epoch=19
06/12/2022 03:48:21 - INFO - __main__ - Step 90 Global step 90 Train loss 0.31 on epoch=22
06/12/2022 03:48:26 - INFO - __main__ - Step 100 Global step 100 Train loss 0.30 on epoch=24
06/12/2022 03:48:28 - INFO - __main__ - Global step 100 Train loss 0.33 Classification-F1 0.3333333333333333 on epoch=24
06/12/2022 03:48:33 - INFO - __main__ - Step 110 Global step 110 Train loss 0.34 on epoch=27
06/12/2022 03:48:37 - INFO - __main__ - Step 120 Global step 120 Train loss 0.28 on epoch=29
06/12/2022 03:48:42 - INFO - __main__ - Step 130 Global step 130 Train loss 0.24 on epoch=32
06/12/2022 03:48:46 - INFO - __main__ - Step 140 Global step 140 Train loss 0.28 on epoch=34
06/12/2022 03:48:51 - INFO - __main__ - Step 150 Global step 150 Train loss 0.24 on epoch=37
06/12/2022 03:48:53 - INFO - __main__ - Global step 150 Train loss 0.28 Classification-F1 0.3333333333333333 on epoch=37
06/12/2022 03:48:58 - INFO - __main__ - Step 160 Global step 160 Train loss 0.21 on epoch=39
06/12/2022 03:49:02 - INFO - __main__ - Step 170 Global step 170 Train loss 0.24 on epoch=42
06/12/2022 03:49:07 - INFO - __main__ - Step 180 Global step 180 Train loss 0.27 on epoch=44
06/12/2022 03:49:12 - INFO - __main__ - Step 190 Global step 190 Train loss 0.25 on epoch=47
06/12/2022 03:49:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=49
06/12/2022 03:49:19 - INFO - __main__ - Global step 200 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=49
06/12/2022 03:49:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.23 on epoch=52
06/12/2022 03:49:28 - INFO - __main__ - Step 220 Global step 220 Train loss 0.26 on epoch=54
06/12/2022 03:49:33 - INFO - __main__ - Step 230 Global step 230 Train loss 0.25 on epoch=57
06/12/2022 03:49:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.20 on epoch=59
06/12/2022 03:49:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.22 on epoch=62
06/12/2022 03:49:45 - INFO - __main__ - Global step 250 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=62
06/12/2022 03:49:49 - INFO - __main__ - Step 260 Global step 260 Train loss 0.21 on epoch=64
06/12/2022 03:49:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.23 on epoch=67
06/12/2022 03:49:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=69
06/12/2022 03:50:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.26 on epoch=72
06/12/2022 03:50:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=74
06/12/2022 03:50:10 - INFO - __main__ - Global step 300 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=74
06/12/2022 03:50:15 - INFO - __main__ - Step 310 Global step 310 Train loss 0.25 on epoch=77
06/12/2022 03:50:19 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=79
06/12/2022 03:50:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=82
06/12/2022 03:50:28 - INFO - __main__ - Step 340 Global step 340 Train loss 0.21 on epoch=84
06/12/2022 03:50:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.26 on epoch=87
06/12/2022 03:50:36 - INFO - __main__ - Global step 350 Train loss 0.24 Classification-F1 0.44379029997196523 on epoch=87
06/12/2022 03:50:36 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.44379029997196523 on epoch=87, global_step=350
06/12/2022 03:50:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=89
06/12/2022 03:50:45 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=92
06/12/2022 03:50:50 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=94
06/12/2022 03:50:54 - INFO - __main__ - Step 390 Global step 390 Train loss 0.20 on epoch=97
06/12/2022 03:50:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/12/2022 03:51:01 - INFO - __main__ - Global step 400 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=99
06/12/2022 03:51:06 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=102
06/12/2022 03:51:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=104
06/12/2022 03:51:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=107
06/12/2022 03:51:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=109
06/12/2022 03:51:24 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=112
06/12/2022 03:51:27 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=112
06/12/2022 03:51:31 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=114
06/12/2022 03:51:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=117
06/12/2022 03:51:40 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/12/2022 03:51:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=122
06/12/2022 03:51:49 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=124
06/12/2022 03:51:52 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.32631578947368417 on epoch=124
06/12/2022 03:51:57 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=127
06/12/2022 03:52:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=129
06/12/2022 03:52:06 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=132
06/12/2022 03:52:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=134
06/12/2022 03:52:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=137
06/12/2022 03:52:17 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=137
06/12/2022 03:52:22 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=139
06/12/2022 03:52:26 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=142
06/12/2022 03:52:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/12/2022 03:52:36 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=147
06/12/2022 03:52:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=149
06/12/2022 03:52:43 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.3591989987484355 on epoch=149
06/12/2022 03:52:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=152
06/12/2022 03:52:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=154
06/12/2022 03:52:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=157
06/12/2022 03:53:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/12/2022 03:53:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=162
06/12/2022 03:53:08 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.3671451355661882 on epoch=162
06/12/2022 03:53:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=164
06/12/2022 03:53:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=167
06/12/2022 03:53:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=169
06/12/2022 03:53:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=172
06/12/2022 03:53:30 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=174
06/12/2022 03:53:33 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.3511520737327189 on epoch=174
06/12/2022 03:53:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=177
06/12/2022 03:53:42 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=179
06/12/2022 03:53:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=182
06/12/2022 03:53:51 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=184
06/12/2022 03:53:56 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=187
06/12/2022 03:53:59 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.3591989987484355 on epoch=187
06/12/2022 03:54:03 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=189
06/12/2022 03:54:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=192
06/12/2022 03:54:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=194
06/12/2022 03:54:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=197
06/12/2022 03:54:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=199
06/12/2022 03:54:25 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.3591989987484355 on epoch=199
06/12/2022 03:54:29 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/12/2022 03:54:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=204
06/12/2022 03:54:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=207
06/12/2022 03:54:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=209
06/12/2022 03:54:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=212
06/12/2022 03:54:50 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.3727353727353727 on epoch=212
06/12/2022 03:54:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=214
06/12/2022 03:55:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=217
06/12/2022 03:55:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=219
06/12/2022 03:55:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=222
06/12/2022 03:55:13 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=224
06/12/2022 03:55:16 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.39047619047619053 on epoch=224
06/12/2022 03:55:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.25 on epoch=227
06/12/2022 03:55:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=229
06/12/2022 03:55:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=232
06/12/2022 03:55:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=234
06/12/2022 03:55:39 - INFO - __main__ - Step 950 Global step 950 Train loss 0.23 on epoch=237
06/12/2022 03:55:42 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.5 on epoch=237
06/12/2022 03:55:42 - INFO - __main__ - Saving model with best Classification-F1: 0.44379029997196523 -> 0.5 on epoch=237, global_step=950
06/12/2022 03:55:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=239
06/12/2022 03:55:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=242
06/12/2022 03:55:56 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=244
06/12/2022 03:56:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=247
06/12/2022 03:56:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=249
06/12/2022 03:56:08 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.5405128205128205 on epoch=249
06/12/2022 03:56:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5 -> 0.5405128205128205 on epoch=249, global_step=1000
06/12/2022 03:56:12 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=252
06/12/2022 03:56:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=254
06/12/2022 03:56:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=257
06/12/2022 03:56:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=259
06/12/2022 03:56:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=262
06/12/2022 03:56:34 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.4909862142099682 on epoch=262
06/12/2022 03:56:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=264
06/12/2022 03:56:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=267
06/12/2022 03:56:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=269
06/12/2022 03:56:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=272
06/12/2022 03:56:56 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=274
06/12/2022 03:56:59 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.3671451355661882 on epoch=274
06/12/2022 03:57:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=277
06/12/2022 03:57:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=279
06/12/2022 03:57:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=282
06/12/2022 03:57:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=284
06/12/2022 03:57:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=287
06/12/2022 03:57:25 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.5625 on epoch=287
06/12/2022 03:57:25 - INFO - __main__ - Saving model with best Classification-F1: 0.5405128205128205 -> 0.5625 on epoch=287, global_step=1150
06/12/2022 03:57:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=289
06/12/2022 03:57:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=292
06/12/2022 03:57:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=294
06/12/2022 03:57:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=297
06/12/2022 03:57:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=299
06/12/2022 03:57:50 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.5536037199690003 on epoch=299
06/12/2022 03:57:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=302
06/12/2022 03:57:59 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=304
06/12/2022 03:58:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=307
06/12/2022 03:58:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=309
06/12/2022 03:58:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=312
06/12/2022 03:58:16 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.43647798742138366 on epoch=312
06/12/2022 03:58:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=314
06/12/2022 03:58:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=317
06/12/2022 03:58:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=319
06/12/2022 03:58:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=322
06/12/2022 03:58:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=324
06/12/2022 03:58:41 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.47602339181286546 on epoch=324
06/12/2022 03:58:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.14 on epoch=327
06/12/2022 03:58:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=329
06/12/2022 03:58:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.14 on epoch=332
06/12/2022 03:58:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=334
06/12/2022 03:59:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=337
06/12/2022 03:59:06 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.5155592935239698 on epoch=337
06/12/2022 03:59:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=339
06/12/2022 03:59:15 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=342
06/12/2022 03:59:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=344
06/12/2022 03:59:24 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=347
06/12/2022 03:59:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=349
06/12/2022 03:59:31 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.5373493975903615 on epoch=349
06/12/2022 03:59:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=352
06/12/2022 03:59:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=354
06/12/2022 03:59:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=357
06/12/2022 03:59:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=359
06/12/2022 03:59:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=362
06/12/2022 03:59:56 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.35421888053467 on epoch=362
06/12/2022 04:00:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=364
06/12/2022 04:00:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=367
06/12/2022 04:00:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=369
06/12/2022 04:00:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=372
06/12/2022 04:00:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=374
06/12/2022 04:00:22 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.5273745861981156 on epoch=374
06/12/2022 04:00:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=377
06/12/2022 04:00:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
06/12/2022 04:00:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=382
06/12/2022 04:00:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=384
06/12/2022 04:00:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=387
06/12/2022 04:00:47 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.3543171654626763 on epoch=387
06/12/2022 04:00:52 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=389
06/12/2022 04:00:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=392
06/12/2022 04:01:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=394
06/12/2022 04:01:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=397
06/12/2022 04:01:10 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=399
06/12/2022 04:01:13 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.358546251791888 on epoch=399
06/12/2022 04:01:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=402
06/12/2022 04:01:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=404
06/12/2022 04:01:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=407
06/12/2022 04:01:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=409
06/12/2022 04:01:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=412
06/12/2022 04:01:38 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.5458771715194519 on epoch=412
06/12/2022 04:01:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=414
06/12/2022 04:01:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=417
06/12/2022 04:01:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=419
06/12/2022 04:01:56 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=422
06/12/2022 04:02:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/12/2022 04:02:03 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.5151515151515151 on epoch=424
06/12/2022 04:02:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=427
06/12/2022 04:02:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=429
06/12/2022 04:02:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=432
06/12/2022 04:02:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
06/12/2022 04:02:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=437
06/12/2022 04:02:28 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.36374269005847953 on epoch=437
06/12/2022 04:02:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/12/2022 04:02:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=442
06/12/2022 04:02:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=444
06/12/2022 04:02:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=447
06/12/2022 04:02:51 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/12/2022 04:02:54 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.38000000000000006 on epoch=449
06/12/2022 04:02:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=452
06/12/2022 04:03:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
06/12/2022 04:03:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=457
06/12/2022 04:03:12 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/12/2022 04:03:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=462
06/12/2022 04:03:19 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.5465587044534412 on epoch=462
06/12/2022 04:03:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=464
06/12/2022 04:03:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/12/2022 04:03:33 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=469
06/12/2022 04:03:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/12/2022 04:03:42 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/12/2022 04:03:45 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.5730170496664195 on epoch=474
06/12/2022 04:03:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5625 -> 0.5730170496664195 on epoch=474, global_step=1900
06/12/2022 04:03:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/12/2022 04:03:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/12/2022 04:03:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/12/2022 04:04:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/12/2022 04:04:07 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=487
06/12/2022 04:04:10 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.5730170496664195 on epoch=487
06/12/2022 04:04:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=489
06/12/2022 04:04:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/12/2022 04:04:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=494
06/12/2022 04:04:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/12/2022 04:04:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/12/2022 04:04:35 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.51417004048583 on epoch=499
06/12/2022 04:04:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
06/12/2022 04:04:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=504
06/12/2022 04:04:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=507
06/12/2022 04:04:53 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/12/2022 04:04:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/12/2022 04:05:01 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.5467643467643467 on epoch=512
06/12/2022 04:05:05 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=514
06/12/2022 04:05:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
06/12/2022 04:05:14 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/12/2022 04:05:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/12/2022 04:05:23 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=524
06/12/2022 04:05:26 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.5307917888563051 on epoch=524
06/12/2022 04:05:30 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/12/2022 04:05:35 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/12/2022 04:05:39 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/12/2022 04:05:44 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/12/2022 04:05:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/12/2022 04:05:51 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.5467643467643467 on epoch=537
06/12/2022 04:05:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/12/2022 04:06:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/12/2022 04:06:04 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/12/2022 04:06:09 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/12/2022 04:06:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/12/2022 04:06:16 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.5730170496664195 on epoch=549
06/12/2022 04:06:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=552
06/12/2022 04:06:25 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=554
06/12/2022 04:06:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/12/2022 04:06:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/12/2022 04:06:38 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=562
06/12/2022 04:06:41 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.5238095238095238 on epoch=562
06/12/2022 04:06:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/12/2022 04:06:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=567
06/12/2022 04:06:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/12/2022 04:06:59 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/12/2022 04:07:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=574
06/12/2022 04:07:07 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.5307917888563051 on epoch=574
06/12/2022 04:07:11 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/12/2022 04:07:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=579
06/12/2022 04:07:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/12/2022 04:07:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=584
06/12/2022 04:07:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/12/2022 04:07:32 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.5126504544338 on epoch=587
06/12/2022 04:07:36 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/12/2022 04:07:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=592
06/12/2022 04:07:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/12/2022 04:07:50 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/12/2022 04:07:54 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/12/2022 04:07:57 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.5413886829750433 on epoch=599
06/12/2022 04:08:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=602
06/12/2022 04:08:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/12/2022 04:08:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=607
06/12/2022 04:08:15 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/12/2022 04:08:19 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/12/2022 04:08:22 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.5873015873015872 on epoch=612
06/12/2022 04:08:22 - INFO - __main__ - Saving model with best Classification-F1: 0.5730170496664195 -> 0.5873015873015872 on epoch=612, global_step=2450
06/12/2022 04:08:26 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/12/2022 04:08:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/12/2022 04:08:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/12/2022 04:08:40 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/12/2022 04:08:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/12/2022 04:08:47 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.5901477832512315 on epoch=624
06/12/2022 04:08:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5873015873015872 -> 0.5901477832512315 on epoch=624, global_step=2500
06/12/2022 04:08:52 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=627
06/12/2022 04:08:56 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=629
06/12/2022 04:09:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/12/2022 04:09:05 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/12/2022 04:09:10 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/12/2022 04:09:12 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.5467643467643467 on epoch=637
06/12/2022 04:09:17 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/12/2022 04:09:21 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/12/2022 04:09:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
06/12/2022 04:09:30 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/12/2022 04:09:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/12/2022 04:09:38 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.3463955026455026 on epoch=649
06/12/2022 04:09:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/12/2022 04:09:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/12/2022 04:09:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/12/2022 04:09:56 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/12/2022 04:10:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/12/2022 04:10:03 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.5330817610062892 on epoch=662
06/12/2022 04:10:07 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/12/2022 04:10:12 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/12/2022 04:10:16 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/12/2022 04:10:21 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/12/2022 04:10:26 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/12/2022 04:10:28 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.5467643467643467 on epoch=674
06/12/2022 04:10:33 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/12/2022 04:10:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/12/2022 04:10:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/12/2022 04:10:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/12/2022 04:10:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/12/2022 04:10:53 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.5620723362658846 on epoch=687
06/12/2022 04:10:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/12/2022 04:11:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/12/2022 04:11:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/12/2022 04:11:12 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/12/2022 04:11:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/12/2022 04:11:19 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.3631168831168831 on epoch=699
06/12/2022 04:11:23 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=702
06/12/2022 04:11:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/12/2022 04:11:32 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/12/2022 04:11:37 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=709
06/12/2022 04:11:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/12/2022 04:11:44 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6333748443337484 on epoch=712
06/12/2022 04:11:44 - INFO - __main__ - Saving model with best Classification-F1: 0.5901477832512315 -> 0.6333748443337484 on epoch=712, global_step=2850
06/12/2022 04:11:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/12/2022 04:11:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=717
06/12/2022 04:11:58 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/12/2022 04:12:03 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/12/2022 04:12:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/12/2022 04:12:10 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.5901477832512315 on epoch=724
06/12/2022 04:12:14 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/12/2022 04:12:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/12/2022 04:12:23 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/12/2022 04:12:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=734
06/12/2022 04:12:32 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
06/12/2022 04:12:35 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.5620723362658846 on epoch=737
06/12/2022 04:12:40 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/12/2022 04:12:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/12/2022 04:12:49 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/12/2022 04:12:53 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/12/2022 04:12:58 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/12/2022 04:12:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 04:12:59 - INFO - __main__ - Printing 3 examples
06/12/2022 04:12:59 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/12/2022 04:12:59 - INFO - __main__ - ['refuted']
06/12/2022 04:12:59 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/12/2022 04:12:59 - INFO - __main__ - ['refuted']
06/12/2022 04:12:59 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/12/2022 04:12:59 - INFO - __main__ - ['refuted']
06/12/2022 04:12:59 - INFO - __main__ - Tokenizing Input ...
06/12/2022 04:12:59 - INFO - __main__ - Tokenizing Output ...
06/12/2022 04:13:00 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 04:13:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 04:13:00 - INFO - __main__ - Printing 3 examples
06/12/2022 04:13:00 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/12/2022 04:13:00 - INFO - __main__ - ['refuted']
06/12/2022 04:13:00 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/12/2022 04:13:00 - INFO - __main__ - ['refuted']
06/12/2022 04:13:00 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/12/2022 04:13:00 - INFO - __main__ - ['refuted']
06/12/2022 04:13:00 - INFO - __main__ - Tokenizing Input ...
06/12/2022 04:13:00 - INFO - __main__ - Tokenizing Output ...
06/12/2022 04:13:00 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 04:13:01 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.49556650246305417 on epoch=749
06/12/2022 04:13:01 - INFO - __main__ - save last model!
06/12/2022 04:13:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 04:13:01 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 04:13:01 - INFO - __main__ - Printing 3 examples
06/12/2022 04:13:01 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 04:13:01 - INFO - __main__ - ['entailed']
06/12/2022 04:13:01 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 04:13:01 - INFO - __main__ - ['entailed']
06/12/2022 04:13:01 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 04:13:01 - INFO - __main__ - ['entailed']
06/12/2022 04:13:01 - INFO - __main__ - Tokenizing Input ...
06/12/2022 04:13:15 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 04:13:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 04:13:16 - INFO - __main__ - Starting training!
06/12/2022 04:13:26 - INFO - __main__ - Tokenizing Output ...
06/12/2022 04:13:39 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 04:22:37 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_21_0.2_8_predictions.txt
06/12/2022 04:22:37 - INFO - __main__ - Classification-F1 on test data: 0.0370
06/12/2022 04:22:37 - INFO - __main__ - prefix=tab_fact_32_21, lr=0.2, bsz=8, dev_performance=0.6333748443337484, test_performance=0.0369557658542311
06/12/2022 04:22:37 - INFO - __main__ - Running ... prefix=tab_fact_32_42, lr=0.5, bsz=8 ...
06/12/2022 04:22:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 04:22:38 - INFO - __main__ - Printing 3 examples
06/12/2022 04:22:38 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/12/2022 04:22:38 - INFO - __main__ - ['refuted']
06/12/2022 04:22:38 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/12/2022 04:22:38 - INFO - __main__ - ['refuted']
06/12/2022 04:22:38 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/12/2022 04:22:38 - INFO - __main__ - ['refuted']
06/12/2022 04:22:38 - INFO - __main__ - Tokenizing Input ...
06/12/2022 04:22:38 - INFO - __main__ - Tokenizing Output ...
06/12/2022 04:22:38 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 04:22:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 04:22:38 - INFO - __main__ - Printing 3 examples
06/12/2022 04:22:38 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/12/2022 04:22:38 - INFO - __main__ - ['refuted']
06/12/2022 04:22:38 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/12/2022 04:22:38 - INFO - __main__ - ['refuted']
06/12/2022 04:22:38 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/12/2022 04:22:38 - INFO - __main__ - ['refuted']
06/12/2022 04:22:38 - INFO - __main__ - Tokenizing Input ...
06/12/2022 04:22:38 - INFO - __main__ - Tokenizing Output ...
06/12/2022 04:22:38 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 04:22:58 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 04:22:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 04:22:59 - INFO - __main__ - Starting training!
06/12/2022 04:23:04 - INFO - __main__ - Step 10 Global step 10 Train loss 2.58 on epoch=2
06/12/2022 04:23:09 - INFO - __main__ - Step 20 Global step 20 Train loss 0.72 on epoch=4
06/12/2022 04:23:13 - INFO - __main__ - Step 30 Global step 30 Train loss 0.42 on epoch=7
06/12/2022 04:23:18 - INFO - __main__ - Step 40 Global step 40 Train loss 0.40 on epoch=9
06/12/2022 04:23:22 - INFO - __main__ - Step 50 Global step 50 Train loss 0.29 on epoch=12
06/12/2022 04:23:25 - INFO - __main__ - Global step 50 Train loss 0.88 Classification-F1 0.3333333333333333 on epoch=12
06/12/2022 04:23:25 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/12/2022 04:23:30 - INFO - __main__ - Step 60 Global step 60 Train loss 0.27 on epoch=14
06/12/2022 04:23:34 - INFO - __main__ - Step 70 Global step 70 Train loss 0.30 on epoch=17
06/12/2022 04:23:38 - INFO - __main__ - Step 80 Global step 80 Train loss 0.28 on epoch=19
06/12/2022 04:23:43 - INFO - __main__ - Step 90 Global step 90 Train loss 0.27 on epoch=22
06/12/2022 04:23:47 - INFO - __main__ - Step 100 Global step 100 Train loss 0.28 on epoch=24
06/12/2022 04:23:50 - INFO - __main__ - Global step 100 Train loss 0.28 Classification-F1 0.3333333333333333 on epoch=24
06/12/2022 04:23:55 - INFO - __main__ - Step 110 Global step 110 Train loss 0.25 on epoch=27
06/12/2022 04:23:59 - INFO - __main__ - Step 120 Global step 120 Train loss 0.25 on epoch=29
06/12/2022 04:24:03 - INFO - __main__ - Step 130 Global step 130 Train loss 0.24 on epoch=32
06/12/2022 04:24:08 - INFO - __main__ - Step 140 Global step 140 Train loss 0.24 on epoch=34
06/12/2022 04:24:13 - INFO - __main__ - Step 150 Global step 150 Train loss 0.24 on epoch=37
06/12/2022 04:24:15 - INFO - __main__ - Global step 150 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=37
06/12/2022 04:24:20 - INFO - __main__ - Step 160 Global step 160 Train loss 0.26 on epoch=39
06/12/2022 04:24:24 - INFO - __main__ - Step 170 Global step 170 Train loss 0.22 on epoch=42
06/12/2022 04:24:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.23 on epoch=44
06/12/2022 04:24:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.24 on epoch=47
06/12/2022 04:24:38 - INFO - __main__ - Step 200 Global step 200 Train loss 0.23 on epoch=49
06/12/2022 04:24:41 - INFO - __main__ - Global step 200 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=49
06/12/2022 04:24:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.24 on epoch=52
06/12/2022 04:24:50 - INFO - __main__ - Step 220 Global step 220 Train loss 0.26 on epoch=54
06/12/2022 04:24:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.20 on epoch=57
06/12/2022 04:24:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.21 on epoch=59
06/12/2022 04:25:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.23 on epoch=62
06/12/2022 04:25:06 - INFO - __main__ - Global step 250 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=62
06/12/2022 04:25:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.23 on epoch=64
06/12/2022 04:25:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.24 on epoch=67
06/12/2022 04:25:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.24 on epoch=69
06/12/2022 04:25:24 - INFO - __main__ - Step 290 Global step 290 Train loss 0.23 on epoch=72
06/12/2022 04:25:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=74
06/12/2022 04:25:31 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.1937984496124031 on epoch=74
06/12/2022 04:25:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.21 on epoch=77
06/12/2022 04:25:40 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=79
06/12/2022 04:25:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=82
06/12/2022 04:25:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=84
06/12/2022 04:25:54 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=87
06/12/2022 04:25:56 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=87
06/12/2022 04:26:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=89
06/12/2022 04:26:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.21 on epoch=92
06/12/2022 04:26:10 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=94
06/12/2022 04:26:14 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=97
06/12/2022 04:26:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=99
06/12/2022 04:26:21 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=99
06/12/2022 04:26:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=102
06/12/2022 04:26:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=104
06/12/2022 04:26:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=107
06/12/2022 04:26:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=109
06/12/2022 04:26:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/12/2022 04:26:47 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.4493927125506073 on epoch=112
06/12/2022 04:26:47 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.4493927125506073 on epoch=112, global_step=450
06/12/2022 04:26:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=114
06/12/2022 04:26:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=117
06/12/2022 04:27:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/12/2022 04:27:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=122
06/12/2022 04:27:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=124
06/12/2022 04:27:12 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=124
06/12/2022 04:27:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=127
06/12/2022 04:27:21 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=129
06/12/2022 04:27:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=132
06/12/2022 04:27:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=134
06/12/2022 04:27:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=137
06/12/2022 04:27:37 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=137
06/12/2022 04:27:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=139
06/12/2022 04:27:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=142
06/12/2022 04:27:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=144
06/12/2022 04:27:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
06/12/2022 04:28:00 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=149
06/12/2022 04:28:02 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=149
06/12/2022 04:28:07 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=152
06/12/2022 04:28:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=154
06/12/2022 04:28:16 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=157
06/12/2022 04:28:21 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=159
06/12/2022 04:28:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=162
06/12/2022 04:28:28 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.4452324665090622 on epoch=162
06/12/2022 04:28:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=164
06/12/2022 04:28:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=167
06/12/2022 04:28:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=169
06/12/2022 04:28:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=172
06/12/2022 04:28:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=174
06/12/2022 04:28:53 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=174
06/12/2022 04:28:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=177
06/12/2022 04:29:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=179
06/12/2022 04:29:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=182
06/12/2022 04:29:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=184
06/12/2022 04:29:16 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=187
06/12/2022 04:29:18 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=187
06/12/2022 04:29:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=189
06/12/2022 04:29:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=192
06/12/2022 04:29:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=194
06/12/2022 04:29:36 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=197
06/12/2022 04:29:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
06/12/2022 04:29:43 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.5097603162836669 on epoch=199
06/12/2022 04:29:44 - INFO - __main__ - Saving model with best Classification-F1: 0.4493927125506073 -> 0.5097603162836669 on epoch=199, global_step=800
06/12/2022 04:29:48 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/12/2022 04:29:52 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=204
06/12/2022 04:29:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=207
06/12/2022 04:30:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=209
06/12/2022 04:30:06 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=212
06/12/2022 04:30:09 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.3882717644019633 on epoch=212
06/12/2022 04:30:13 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=214
06/12/2022 04:30:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=217
06/12/2022 04:30:22 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=219
06/12/2022 04:30:27 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=222
06/12/2022 04:30:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=224
06/12/2022 04:30:34 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.30364842454394697 on epoch=224
06/12/2022 04:30:38 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=227
06/12/2022 04:30:43 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=229
06/12/2022 04:30:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=232
06/12/2022 04:30:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=234
06/12/2022 04:30:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=237
06/12/2022 04:30:59 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.47813194959229055 on epoch=237
06/12/2022 04:31:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=239
06/12/2022 04:31:08 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=242
06/12/2022 04:31:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=244
06/12/2022 04:31:17 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=247
06/12/2022 04:31:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=249
06/12/2022 04:31:24 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.500880503144654 on epoch=249
06/12/2022 04:31:29 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=252
06/12/2022 04:31:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=254
06/12/2022 04:31:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/12/2022 04:31:42 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=259
06/12/2022 04:31:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=262
06/12/2022 04:31:49 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.5730170496664195 on epoch=262
06/12/2022 04:31:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5097603162836669 -> 0.5730170496664195 on epoch=262, global_step=1050
06/12/2022 04:31:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=264
06/12/2022 04:31:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=267
06/12/2022 04:32:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
06/12/2022 04:32:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=272
06/12/2022 04:32:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/12/2022 04:32:15 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.4874874874874875 on epoch=274
06/12/2022 04:32:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=277
06/12/2022 04:32:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/12/2022 04:32:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=282
06/12/2022 04:32:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/12/2022 04:32:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/12/2022 04:32:40 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.4812085482682388 on epoch=287
06/12/2022 04:32:45 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=289
06/12/2022 04:32:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/12/2022 04:32:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=294
06/12/2022 04:32:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=297
06/12/2022 04:33:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=299
06/12/2022 04:33:06 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.5126504544338 on epoch=299
06/12/2022 04:33:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/12/2022 04:33:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/12/2022 04:33:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/12/2022 04:33:24 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/12/2022 04:33:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/12/2022 04:33:31 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.5307917888563051 on epoch=312
06/12/2022 04:33:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/12/2022 04:33:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/12/2022 04:33:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/12/2022 04:33:50 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/12/2022 04:33:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/12/2022 04:33:57 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.5097603162836669 on epoch=324
06/12/2022 04:34:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/12/2022 04:34:06 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/12/2022 04:34:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=332
06/12/2022 04:34:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/12/2022 04:34:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/12/2022 04:34:22 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.5145583557621727 on epoch=337
06/12/2022 04:34:26 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=339
06/12/2022 04:34:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/12/2022 04:34:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/12/2022 04:34:40 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/12/2022 04:34:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/12/2022 04:34:47 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.46867924528301885 on epoch=349
06/12/2022 04:34:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/12/2022 04:34:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/12/2022 04:35:00 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=357
06/12/2022 04:35:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/12/2022 04:35:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/12/2022 04:35:13 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.5195195195195195 on epoch=362
06/12/2022 04:35:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/12/2022 04:35:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=367
06/12/2022 04:35:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/12/2022 04:35:31 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/12/2022 04:35:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/12/2022 04:35:39 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.43647798742138366 on epoch=374
06/12/2022 04:35:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/12/2022 04:35:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/12/2022 04:35:52 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/12/2022 04:35:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/12/2022 04:36:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/12/2022 04:36:04 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.5 on epoch=387
06/12/2022 04:36:09 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/12/2022 04:36:13 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/12/2022 04:36:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
06/12/2022 04:36:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/12/2022 04:36:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/12/2022 04:36:30 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.4812085482682388 on epoch=399
06/12/2022 04:36:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/12/2022 04:36:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/12/2022 04:36:44 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/12/2022 04:36:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/12/2022 04:36:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/12/2022 04:36:56 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.4420512820512821 on epoch=412
06/12/2022 04:37:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/12/2022 04:37:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/12/2022 04:37:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/12/2022 04:37:14 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/12/2022 04:37:18 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/12/2022 04:37:21 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.4832395400048935 on epoch=424
06/12/2022 04:37:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/12/2022 04:37:30 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/12/2022 04:37:35 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/12/2022 04:37:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/12/2022 04:37:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/12/2022 04:37:46 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.4832395400048935 on epoch=437
06/12/2022 04:37:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/12/2022 04:37:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
06/12/2022 04:38:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=444
06/12/2022 04:38:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/12/2022 04:38:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/12/2022 04:38:12 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.5126504544338 on epoch=449
06/12/2022 04:38:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/12/2022 04:38:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/12/2022 04:38:25 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/12/2022 04:38:30 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/12/2022 04:38:34 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/12/2022 04:38:37 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.4980392156862745 on epoch=462
06/12/2022 04:38:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/12/2022 04:38:46 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/12/2022 04:38:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/12/2022 04:38:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/12/2022 04:38:59 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/12/2022 04:39:02 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.4682306940371457 on epoch=474
06/12/2022 04:39:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/12/2022 04:39:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/12/2022 04:39:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/12/2022 04:39:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/12/2022 04:39:25 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/12/2022 04:39:27 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.4980392156862745 on epoch=487
06/12/2022 04:39:32 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/12/2022 04:39:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/12/2022 04:39:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/12/2022 04:39:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/12/2022 04:39:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/12/2022 04:39:52 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.47813194959229055 on epoch=499
06/12/2022 04:39:57 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/12/2022 04:40:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/12/2022 04:40:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/12/2022 04:40:11 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/12/2022 04:40:15 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/12/2022 04:40:18 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.4812085482682388 on epoch=512
06/12/2022 04:40:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/12/2022 04:40:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/12/2022 04:40:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/12/2022 04:40:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/12/2022 04:40:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/12/2022 04:40:43 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.47885474126608885 on epoch=524
06/12/2022 04:40:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/12/2022 04:40:52 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/12/2022 04:40:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/12/2022 04:41:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/12/2022 04:41:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/12/2022 04:41:09 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.4995112414467253 on epoch=537
06/12/2022 04:41:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/12/2022 04:41:18 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/12/2022 04:41:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/12/2022 04:41:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/12/2022 04:41:31 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/12/2022 04:41:34 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.4995112414467253 on epoch=549
06/12/2022 04:41:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/12/2022 04:41:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/12/2022 04:41:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/12/2022 04:41:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/12/2022 04:41:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/12/2022 04:41:59 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.4465035829009143 on epoch=562
06/12/2022 04:42:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/12/2022 04:42:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/12/2022 04:42:13 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/12/2022 04:42:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/12/2022 04:42:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/12/2022 04:42:24 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.44976664210267747 on epoch=574
06/12/2022 04:42:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/12/2022 04:42:34 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/12/2022 04:42:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/12/2022 04:42:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/12/2022 04:42:47 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/12/2022 04:42:50 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.4995112414467253 on epoch=587
06/12/2022 04:42:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/12/2022 04:42:59 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/12/2022 04:43:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/12/2022 04:43:08 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/12/2022 04:43:12 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/12/2022 04:43:15 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.46031746031746035 on epoch=599
06/12/2022 04:43:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/12/2022 04:43:24 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/12/2022 04:43:28 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/12/2022 04:43:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/12/2022 04:43:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/12/2022 04:43:40 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.5145583557621727 on epoch=612
06/12/2022 04:43:45 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/12/2022 04:43:49 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/12/2022 04:43:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/12/2022 04:43:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/12/2022 04:44:03 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/12/2022 04:44:05 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.49556650246305417 on epoch=624
06/12/2022 04:44:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/12/2022 04:44:14 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/12/2022 04:44:19 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/12/2022 04:44:23 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/12/2022 04:44:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/12/2022 04:44:31 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.4812085482682388 on epoch=637
06/12/2022 04:44:35 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/12/2022 04:44:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/12/2022 04:44:44 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/12/2022 04:44:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/12/2022 04:44:53 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/12/2022 04:44:56 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.49556650246305417 on epoch=649
06/12/2022 04:45:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=652
06/12/2022 04:45:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/12/2022 04:45:09 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/12/2022 04:45:13 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/12/2022 04:45:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/12/2022 04:45:21 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.46031746031746035 on epoch=662
06/12/2022 04:45:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/12/2022 04:45:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/12/2022 04:45:34 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/12/2022 04:45:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/12/2022 04:45:44 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/12/2022 04:45:46 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.4493927125506073 on epoch=674
06/12/2022 04:45:51 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/12/2022 04:45:55 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/12/2022 04:46:00 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/12/2022 04:46:04 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/12/2022 04:46:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/12/2022 04:46:11 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.4832395400048935 on epoch=687
06/12/2022 04:46:16 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/12/2022 04:46:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/12/2022 04:46:25 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/12/2022 04:46:30 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/12/2022 04:46:34 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/12/2022 04:46:37 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.47813194959229055 on epoch=699
06/12/2022 04:46:41 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/12/2022 04:46:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/12/2022 04:46:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/12/2022 04:46:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/12/2022 04:46:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/12/2022 04:47:02 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.32392575642003557 on epoch=712
06/12/2022 04:47:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/12/2022 04:47:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/12/2022 04:47:15 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/12/2022 04:47:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/12/2022 04:47:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/12/2022 04:47:27 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.31945535480492276 on epoch=724
06/12/2022 04:47:31 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/12/2022 04:47:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/12/2022 04:47:40 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/12/2022 04:47:45 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/12/2022 04:47:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/12/2022 04:47:52 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.4920634920634921 on epoch=737
06/12/2022 04:47:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/12/2022 04:48:01 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/12/2022 04:48:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/12/2022 04:48:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/12/2022 04:48:14 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/12/2022 04:48:16 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 04:48:16 - INFO - __main__ - Printing 3 examples
06/12/2022 04:48:16 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/12/2022 04:48:16 - INFO - __main__ - ['refuted']
06/12/2022 04:48:16 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/12/2022 04:48:16 - INFO - __main__ - ['refuted']
06/12/2022 04:48:16 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/12/2022 04:48:16 - INFO - __main__ - ['refuted']
06/12/2022 04:48:16 - INFO - __main__ - Tokenizing Input ...
06/12/2022 04:48:16 - INFO - __main__ - Tokenizing Output ...
06/12/2022 04:48:16 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 04:48:16 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 04:48:16 - INFO - __main__ - Printing 3 examples
06/12/2022 04:48:16 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/12/2022 04:48:16 - INFO - __main__ - ['refuted']
06/12/2022 04:48:16 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/12/2022 04:48:16 - INFO - __main__ - ['refuted']
06/12/2022 04:48:16 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/12/2022 04:48:16 - INFO - __main__ - ['refuted']
06/12/2022 04:48:16 - INFO - __main__ - Tokenizing Input ...
06/12/2022 04:48:16 - INFO - __main__ - Tokenizing Output ...
06/12/2022 04:48:16 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 04:48:17 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.46666666666666656 on epoch=749
06/12/2022 04:48:17 - INFO - __main__ - save last model!
06/12/2022 04:48:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 04:48:17 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 04:48:17 - INFO - __main__ - Printing 3 examples
06/12/2022 04:48:17 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 04:48:17 - INFO - __main__ - ['entailed']
06/12/2022 04:48:17 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 04:48:17 - INFO - __main__ - ['entailed']
06/12/2022 04:48:17 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 04:48:17 - INFO - __main__ - ['entailed']
06/12/2022 04:48:17 - INFO - __main__ - Tokenizing Input ...
06/12/2022 04:48:36 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 04:48:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 04:48:37 - INFO - __main__ - Starting training!
06/12/2022 04:48:42 - INFO - __main__ - Tokenizing Output ...
06/12/2022 04:48:55 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 04:57:16 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_42_0.5_8_predictions.txt
06/12/2022 04:57:16 - INFO - __main__ - Classification-F1 on test data: 0.5012
06/12/2022 04:57:16 - INFO - __main__ - prefix=tab_fact_32_42, lr=0.5, bsz=8, dev_performance=0.5730170496664195, test_performance=0.5011513288967163
06/12/2022 04:57:16 - INFO - __main__ - Running ... prefix=tab_fact_32_42, lr=0.4, bsz=8 ...
06/12/2022 04:57:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 04:57:17 - INFO - __main__ - Printing 3 examples
06/12/2022 04:57:17 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/12/2022 04:57:17 - INFO - __main__ - ['refuted']
06/12/2022 04:57:17 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/12/2022 04:57:17 - INFO - __main__ - ['refuted']
06/12/2022 04:57:17 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/12/2022 04:57:17 - INFO - __main__ - ['refuted']
06/12/2022 04:57:17 - INFO - __main__ - Tokenizing Input ...
06/12/2022 04:57:17 - INFO - __main__ - Tokenizing Output ...
06/12/2022 04:57:17 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 04:57:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 04:57:17 - INFO - __main__ - Printing 3 examples
06/12/2022 04:57:17 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/12/2022 04:57:17 - INFO - __main__ - ['refuted']
06/12/2022 04:57:17 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/12/2022 04:57:17 - INFO - __main__ - ['refuted']
06/12/2022 04:57:17 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/12/2022 04:57:17 - INFO - __main__ - ['refuted']
06/12/2022 04:57:17 - INFO - __main__ - Tokenizing Input ...
06/12/2022 04:57:17 - INFO - __main__ - Tokenizing Output ...
06/12/2022 04:57:17 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 04:57:36 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 04:57:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 04:57:37 - INFO - __main__ - Starting training!
06/12/2022 04:57:42 - INFO - __main__ - Step 10 Global step 10 Train loss 2.60 on epoch=2
06/12/2022 04:57:47 - INFO - __main__ - Step 20 Global step 20 Train loss 0.60 on epoch=4
06/12/2022 04:57:51 - INFO - __main__ - Step 30 Global step 30 Train loss 0.41 on epoch=7
06/12/2022 04:57:56 - INFO - __main__ - Step 40 Global step 40 Train loss 0.36 on epoch=9
06/12/2022 04:58:00 - INFO - __main__ - Step 50 Global step 50 Train loss 0.33 on epoch=12
06/12/2022 04:58:03 - INFO - __main__ - Global step 50 Train loss 0.86 Classification-F1 0.3333333333333333 on epoch=12
06/12/2022 04:58:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/12/2022 04:58:08 - INFO - __main__ - Step 60 Global step 60 Train loss 0.33 on epoch=14
06/12/2022 04:58:12 - INFO - __main__ - Step 70 Global step 70 Train loss 0.28 on epoch=17
06/12/2022 04:58:17 - INFO - __main__ - Step 80 Global step 80 Train loss 0.26 on epoch=19
06/12/2022 04:58:22 - INFO - __main__ - Step 90 Global step 90 Train loss 0.26 on epoch=22
06/12/2022 04:58:26 - INFO - __main__ - Step 100 Global step 100 Train loss 0.29 on epoch=24
06/12/2022 04:58:29 - INFO - __main__ - Global step 100 Train loss 0.28 Classification-F1 0.3333333333333333 on epoch=24
06/12/2022 04:58:33 - INFO - __main__ - Step 110 Global step 110 Train loss 0.26 on epoch=27
06/12/2022 04:58:38 - INFO - __main__ - Step 120 Global step 120 Train loss 0.27 on epoch=29
06/12/2022 04:58:42 - INFO - __main__ - Step 130 Global step 130 Train loss 0.23 on epoch=32
06/12/2022 04:58:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.23 on epoch=34
06/12/2022 04:58:52 - INFO - __main__ - Step 150 Global step 150 Train loss 0.28 on epoch=37
06/12/2022 04:58:54 - INFO - __main__ - Global step 150 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=37
06/12/2022 04:58:59 - INFO - __main__ - Step 160 Global step 160 Train loss 0.29 on epoch=39
06/12/2022 04:59:04 - INFO - __main__ - Step 170 Global step 170 Train loss 0.24 on epoch=42
06/12/2022 04:59:08 - INFO - __main__ - Step 180 Global step 180 Train loss 0.22 on epoch=44
06/12/2022 04:59:13 - INFO - __main__ - Step 190 Global step 190 Train loss 0.23 on epoch=47
06/12/2022 04:59:17 - INFO - __main__ - Step 200 Global step 200 Train loss 0.24 on epoch=49
06/12/2022 04:59:20 - INFO - __main__ - Global step 200 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=49
06/12/2022 04:59:25 - INFO - __main__ - Step 210 Global step 210 Train loss 0.23 on epoch=52
06/12/2022 04:59:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.20 on epoch=54
06/12/2022 04:59:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.21 on epoch=57
06/12/2022 04:59:39 - INFO - __main__ - Step 240 Global step 240 Train loss 0.22 on epoch=59
06/12/2022 04:59:43 - INFO - __main__ - Step 250 Global step 250 Train loss 0.20 on epoch=62
06/12/2022 04:59:46 - INFO - __main__ - Global step 250 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=62
06/12/2022 04:59:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.22 on epoch=64
06/12/2022 04:59:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.53 on epoch=67
06/12/2022 05:00:00 - INFO - __main__ - Step 280 Global step 280 Train loss 1.50 on epoch=69
06/12/2022 05:00:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.26 on epoch=72
06/12/2022 05:00:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=74
06/12/2022 05:00:12 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.3333333333333333 on epoch=74
06/12/2022 05:00:17 - INFO - __main__ - Step 310 Global step 310 Train loss 0.20 on epoch=77
06/12/2022 05:00:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=79
06/12/2022 05:00:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.20 on epoch=82
06/12/2022 05:00:30 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=84
06/12/2022 05:00:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.22 on epoch=87
06/12/2022 05:00:38 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=87
06/12/2022 05:00:42 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=89
06/12/2022 05:00:47 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=92
06/12/2022 05:00:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=94
06/12/2022 05:00:56 - INFO - __main__ - Step 390 Global step 390 Train loss 1.46 on epoch=97
06/12/2022 05:01:01 - INFO - __main__ - Step 400 Global step 400 Train loss 0.51 on epoch=99
06/12/2022 05:01:04 - INFO - __main__ - Global step 400 Train loss 0.53 Classification-F1 0.3333333333333333 on epoch=99
06/12/2022 05:01:08 - INFO - __main__ - Step 410 Global step 410 Train loss 2.03 on epoch=102
06/12/2022 05:01:13 - INFO - __main__ - Step 420 Global step 420 Train loss 4.16 on epoch=104
06/12/2022 05:01:17 - INFO - __main__ - Step 430 Global step 430 Train loss 2.35 on epoch=107
06/12/2022 05:01:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=109
06/12/2022 05:01:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=112
06/12/2022 05:01:29 - INFO - __main__ - Global step 450 Train loss 1.83 Classification-F1 0.2175438596491228 on epoch=112
06/12/2022 05:01:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=114
06/12/2022 05:01:38 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=117
06/12/2022 05:01:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=119
06/12/2022 05:01:47 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=122
06/12/2022 05:01:51 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=124
06/12/2022 05:01:54 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.21276595744680848 on epoch=124
06/12/2022 05:01:59 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=127
06/12/2022 05:02:03 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=129
06/12/2022 05:02:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=132
06/12/2022 05:02:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/12/2022 05:02:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.26 on epoch=137
06/12/2022 05:02:20 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.2175438596491228 on epoch=137
06/12/2022 05:02:24 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/12/2022 05:02:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=142
06/12/2022 05:02:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=144
06/12/2022 05:02:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
06/12/2022 05:02:42 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=149
06/12/2022 05:02:45 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.2175438596491228 on epoch=149
06/12/2022 05:02:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=152
06/12/2022 05:02:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=154
06/12/2022 05:02:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=157
06/12/2022 05:03:03 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=159
06/12/2022 05:03:08 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=162
06/12/2022 05:03:10 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.2175438596491228 on epoch=162
06/12/2022 05:03:15 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=164
06/12/2022 05:03:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.26 on epoch=167
06/12/2022 05:03:24 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=169
06/12/2022 05:03:28 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=172
06/12/2022 05:03:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=174
06/12/2022 05:03:36 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.2175438596491228 on epoch=174
06/12/2022 05:03:40 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=177
06/12/2022 05:03:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=179
06/12/2022 05:03:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=182
06/12/2022 05:03:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=184
06/12/2022 05:03:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=187
06/12/2022 05:04:01 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.2175438596491228 on epoch=187
06/12/2022 05:04:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=189
06/12/2022 05:04:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=192
06/12/2022 05:04:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=194
06/12/2022 05:04:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=197
06/12/2022 05:04:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
06/12/2022 05:04:26 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.2175438596491228 on epoch=199
06/12/2022 05:04:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=202
06/12/2022 05:04:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=204
06/12/2022 05:04:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.24 on epoch=207
06/12/2022 05:04:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=209
06/12/2022 05:04:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=212
06/12/2022 05:04:51 - INFO - __main__ - Global step 850 Train loss 0.22 Classification-F1 0.2175438596491228 on epoch=212
06/12/2022 05:04:56 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=214
06/12/2022 05:05:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=217
06/12/2022 05:05:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.25 on epoch=219
06/12/2022 05:05:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.24 on epoch=222
06/12/2022 05:05:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=224
06/12/2022 05:05:17 - INFO - __main__ - Global step 900 Train loss 0.23 Classification-F1 0.2175438596491228 on epoch=224
06/12/2022 05:05:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.21 on epoch=227
06/12/2022 05:05:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=229
06/12/2022 05:05:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.23 on epoch=232
06/12/2022 05:05:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=234
06/12/2022 05:05:39 - INFO - __main__ - Step 950 Global step 950 Train loss 0.23 on epoch=237
06/12/2022 05:05:42 - INFO - __main__ - Global step 950 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=237
06/12/2022 05:05:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=239
06/12/2022 05:05:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=242
06/12/2022 05:05:56 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=244
06/12/2022 05:06:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.23 on epoch=247
06/12/2022 05:06:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=249
06/12/2022 05:06:07 - INFO - __main__ - Global step 1000 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=249
06/12/2022 05:06:12 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.20 on epoch=252
06/12/2022 05:06:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.26 on epoch=254
06/12/2022 05:06:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.24 on epoch=257
06/12/2022 05:06:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.23 on epoch=259
06/12/2022 05:06:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.20 on epoch=262
06/12/2022 05:06:33 - INFO - __main__ - Global step 1050 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=262
06/12/2022 05:06:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.22 on epoch=264
06/12/2022 05:06:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=267
06/12/2022 05:06:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=269
06/12/2022 05:06:51 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.22 on epoch=272
06/12/2022 05:06:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.22 on epoch=274
06/12/2022 05:06:58 - INFO - __main__ - Global step 1100 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=274
06/12/2022 05:07:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.20 on epoch=277
06/12/2022 05:07:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.22 on epoch=279
06/12/2022 05:07:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.21 on epoch=282
06/12/2022 05:07:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=284
06/12/2022 05:07:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.22 on epoch=287
06/12/2022 05:07:24 - INFO - __main__ - Global step 1150 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=287
06/12/2022 05:07:28 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.23 on epoch=289
06/12/2022 05:07:33 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.20 on epoch=292
06/12/2022 05:07:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=294
06/12/2022 05:07:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.24 on epoch=297
06/12/2022 05:07:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.22 on epoch=299
06/12/2022 05:07:49 - INFO - __main__ - Global step 1200 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=299
06/12/2022 05:07:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=302
06/12/2022 05:07:58 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=304
06/12/2022 05:08:03 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.21 on epoch=307
06/12/2022 05:08:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.22 on epoch=309
06/12/2022 05:08:12 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.20 on epoch=312
06/12/2022 05:08:14 - INFO - __main__ - Global step 1250 Train loss 0.20 Classification-F1 0.22463768115942032 on epoch=312
06/12/2022 05:08:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.19 on epoch=314
06/12/2022 05:08:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.22 on epoch=317
06/12/2022 05:08:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=319
06/12/2022 05:08:33 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.24 on epoch=322
06/12/2022 05:08:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.20 on epoch=324
06/12/2022 05:08:40 - INFO - __main__ - Global step 1300 Train loss 0.21 Classification-F1 0.21985815602836878 on epoch=324
06/12/2022 05:08:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.20 on epoch=327
06/12/2022 05:08:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.20 on epoch=329
06/12/2022 05:08:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.21 on epoch=332
06/12/2022 05:08:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.21 on epoch=334
06/12/2022 05:09:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.20 on epoch=337
06/12/2022 05:09:05 - INFO - __main__ - Global step 1350 Train loss 0.20 Classification-F1 0.21985815602836878 on epoch=337
06/12/2022 05:09:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.21 on epoch=339
06/12/2022 05:09:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.19 on epoch=342
06/12/2022 05:09:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.20 on epoch=344
06/12/2022 05:09:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.21 on epoch=347
06/12/2022 05:09:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.23 on epoch=349
06/12/2022 05:09:31 - INFO - __main__ - Global step 1400 Train loss 0.21 Classification-F1 0.22456140350877193 on epoch=349
06/12/2022 05:09:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.23 on epoch=352
06/12/2022 05:09:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.18 on epoch=354
06/12/2022 05:09:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.19 on epoch=357
06/12/2022 05:09:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.23 on epoch=359
06/12/2022 05:09:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.22 on epoch=362
06/12/2022 05:09:56 - INFO - __main__ - Global step 1450 Train loss 0.21 Classification-F1 0.22456140350877193 on epoch=362
06/12/2022 05:10:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.21 on epoch=364
06/12/2022 05:10:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.23 on epoch=367
06/12/2022 05:10:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.18 on epoch=369
06/12/2022 05:10:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.16 on epoch=372
06/12/2022 05:10:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.22 on epoch=374
06/12/2022 05:10:22 - INFO - __main__ - Global step 1500 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=374
06/12/2022 05:10:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.19 on epoch=377
06/12/2022 05:10:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.23 on epoch=379
06/12/2022 05:10:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.20 on epoch=382
06/12/2022 05:10:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.19 on epoch=384
06/12/2022 05:10:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.20 on epoch=387
06/12/2022 05:10:47 - INFO - __main__ - Global step 1550 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=387
06/12/2022 05:10:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.20 on epoch=389
06/12/2022 05:10:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.23 on epoch=392
06/12/2022 05:11:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.21 on epoch=394
06/12/2022 05:11:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.23 on epoch=397
06/12/2022 05:11:10 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.23 on epoch=399
06/12/2022 05:11:12 - INFO - __main__ - Global step 1600 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=399
06/12/2022 05:11:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.23 on epoch=402
06/12/2022 05:11:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.21 on epoch=404
06/12/2022 05:11:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.19 on epoch=407
06/12/2022 05:11:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.22 on epoch=409
06/12/2022 05:11:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.20 on epoch=412
06/12/2022 05:11:38 - INFO - __main__ - Global step 1650 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=412
06/12/2022 05:11:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.21 on epoch=414
06/12/2022 05:11:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.23 on epoch=417
06/12/2022 05:11:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.20 on epoch=419
06/12/2022 05:11:56 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.21 on epoch=422
06/12/2022 05:12:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.22 on epoch=424
06/12/2022 05:12:03 - INFO - __main__ - Global step 1700 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=424
06/12/2022 05:12:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.20 on epoch=427
06/12/2022 05:12:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.22 on epoch=429
06/12/2022 05:12:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.20 on epoch=432
06/12/2022 05:12:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.20 on epoch=434
06/12/2022 05:12:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.21 on epoch=437
06/12/2022 05:12:29 - INFO - __main__ - Global step 1750 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=437
06/12/2022 05:12:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.22 on epoch=439
06/12/2022 05:12:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.20 on epoch=442
06/12/2022 05:12:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.21 on epoch=444
06/12/2022 05:12:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.21 on epoch=447
06/12/2022 05:12:51 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.23 on epoch=449
06/12/2022 05:12:54 - INFO - __main__ - Global step 1800 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=449
06/12/2022 05:12:59 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.19 on epoch=452
06/12/2022 05:13:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.21 on epoch=454
06/12/2022 05:13:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.21 on epoch=457
06/12/2022 05:13:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.20 on epoch=459
06/12/2022 05:13:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.22 on epoch=462
06/12/2022 05:13:20 - INFO - __main__ - Global step 1850 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=462
06/12/2022 05:13:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.22 on epoch=464
06/12/2022 05:13:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.20 on epoch=467
06/12/2022 05:13:33 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.21 on epoch=469
06/12/2022 05:13:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.23 on epoch=472
06/12/2022 05:13:42 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.21 on epoch=474
06/12/2022 05:13:45 - INFO - __main__ - Global step 1900 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=474
06/12/2022 05:13:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.20 on epoch=477
06/12/2022 05:13:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.20 on epoch=479
06/12/2022 05:13:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.19 on epoch=482
06/12/2022 05:14:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.20 on epoch=484
06/12/2022 05:14:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.21 on epoch=487
06/12/2022 05:14:10 - INFO - __main__ - Global step 1950 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=487
06/12/2022 05:14:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.20 on epoch=489
06/12/2022 05:14:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.21 on epoch=492
06/12/2022 05:14:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.20 on epoch=494
06/12/2022 05:14:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.22 on epoch=497
06/12/2022 05:14:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.25 on epoch=499
06/12/2022 05:14:35 - INFO - __main__ - Global step 2000 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=499
06/12/2022 05:14:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.19 on epoch=502
06/12/2022 05:14:45 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.22 on epoch=504
06/12/2022 05:14:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.21 on epoch=507
06/12/2022 05:14:54 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.20 on epoch=509
06/12/2022 05:14:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.21 on epoch=512
06/12/2022 05:15:01 - INFO - __main__ - Global step 2050 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=512
06/12/2022 05:15:05 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.21 on epoch=514
06/12/2022 05:15:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.20 on epoch=517
06/12/2022 05:15:14 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.19 on epoch=519
06/12/2022 05:15:19 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.22 on epoch=522
06/12/2022 05:15:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.19 on epoch=524
06/12/2022 05:15:26 - INFO - __main__ - Global step 2100 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=524
06/12/2022 05:15:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.19 on epoch=527
06/12/2022 05:15:35 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.21 on epoch=529
06/12/2022 05:15:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.20 on epoch=532
06/12/2022 05:15:44 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.21 on epoch=534
06/12/2022 05:15:49 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.19 on epoch=537
06/12/2022 05:15:52 - INFO - __main__ - Global step 2150 Train loss 0.20 Classification-F1 0.2175438596491228 on epoch=537
06/12/2022 05:15:56 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.20 on epoch=539
06/12/2022 05:16:01 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.22 on epoch=542
06/12/2022 05:16:05 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.21 on epoch=544
06/12/2022 05:16:10 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.21 on epoch=547
06/12/2022 05:16:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.19 on epoch=549
06/12/2022 05:16:17 - INFO - __main__ - Global step 2200 Train loss 0.21 Classification-F1 0.2175438596491228 on epoch=549
06/12/2022 05:16:22 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.22 on epoch=552
06/12/2022 05:16:26 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.20 on epoch=554
06/12/2022 05:16:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.19 on epoch=557
06/12/2022 05:16:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.20 on epoch=559
06/12/2022 05:16:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.21 on epoch=562
06/12/2022 05:16:43 - INFO - __main__ - Global step 2250 Train loss 0.20 Classification-F1 0.22456140350877193 on epoch=562
06/12/2022 05:16:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.17 on epoch=564
06/12/2022 05:16:52 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.23 on epoch=567
06/12/2022 05:16:57 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.20 on epoch=569
06/12/2022 05:17:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.16 on epoch=572
06/12/2022 05:17:06 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.19 on epoch=574
06/12/2022 05:17:09 - INFO - __main__ - Global step 2300 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=574
06/12/2022 05:17:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.21 on epoch=577
06/12/2022 05:17:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.20 on epoch=579
06/12/2022 05:17:22 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.22 on epoch=582
06/12/2022 05:17:27 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.23 on epoch=584
06/12/2022 05:17:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.22 on epoch=587
06/12/2022 05:17:34 - INFO - __main__ - Global step 2350 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=587
06/12/2022 05:17:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.19 on epoch=589
06/12/2022 05:17:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.16 on epoch=592
06/12/2022 05:17:48 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.18 on epoch=594
06/12/2022 05:17:52 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.20 on epoch=597
06/12/2022 05:17:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.22 on epoch=599
06/12/2022 05:18:00 - INFO - __main__ - Global step 2400 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=599
06/12/2022 05:18:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.22 on epoch=602
06/12/2022 05:18:09 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.23 on epoch=604
06/12/2022 05:18:14 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.20 on epoch=607
06/12/2022 05:18:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.19 on epoch=609
06/12/2022 05:18:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.20 on epoch=612
06/12/2022 05:18:26 - INFO - __main__ - Global step 2450 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=612
06/12/2022 05:18:30 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.20 on epoch=614
06/12/2022 05:18:35 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.19 on epoch=617
06/12/2022 05:18:39 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.19 on epoch=619
06/12/2022 05:18:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.19 on epoch=622
06/12/2022 05:18:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.18 on epoch=624
06/12/2022 05:18:51 - INFO - __main__ - Global step 2500 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=624
06/12/2022 05:18:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.21 on epoch=627
06/12/2022 05:19:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.23 on epoch=629
06/12/2022 05:19:05 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.20 on epoch=632
06/12/2022 05:19:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.21 on epoch=634
06/12/2022 05:19:14 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.23 on epoch=637
06/12/2022 05:19:17 - INFO - __main__ - Global step 2550 Train loss 0.22 Classification-F1 0.43529411764705883 on epoch=637
06/12/2022 05:19:17 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.43529411764705883 on epoch=637, global_step=2550
06/12/2022 05:19:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.20 on epoch=639
06/12/2022 05:19:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.23 on epoch=642
06/12/2022 05:19:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.20 on epoch=644
06/12/2022 05:19:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.20 on epoch=647
06/12/2022 05:19:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.19 on epoch=649
06/12/2022 05:19:43 - INFO - __main__ - Global step 2600 Train loss 0.20 Classification-F1 0.3818181818181818 on epoch=649
06/12/2022 05:19:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.23 on epoch=652
06/12/2022 05:19:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.20 on epoch=654
06/12/2022 05:19:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.21 on epoch=657
06/12/2022 05:20:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.19 on epoch=659
06/12/2022 05:20:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.20 on epoch=662
06/12/2022 05:20:08 - INFO - __main__ - Global step 2650 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=662
06/12/2022 05:20:13 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.20 on epoch=664
06/12/2022 05:20:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.22 on epoch=667
06/12/2022 05:20:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.20 on epoch=669
06/12/2022 05:20:26 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.22 on epoch=672
06/12/2022 05:20:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.19 on epoch=674
06/12/2022 05:20:34 - INFO - __main__ - Global step 2700 Train loss 0.21 Classification-F1 0.42840679919331603 on epoch=674
06/12/2022 05:20:38 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.17 on epoch=677
06/12/2022 05:20:43 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.18 on epoch=679
06/12/2022 05:20:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.19 on epoch=682
06/12/2022 05:20:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.19 on epoch=684
06/12/2022 05:20:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.20 on epoch=687
06/12/2022 05:20:59 - INFO - __main__ - Global step 2750 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=687
06/12/2022 05:21:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.22 on epoch=689
06/12/2022 05:21:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.19 on epoch=692
06/12/2022 05:21:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.20 on epoch=694
06/12/2022 05:21:17 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.22 on epoch=697
06/12/2022 05:21:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.20 on epoch=699
06/12/2022 05:21:25 - INFO - __main__ - Global step 2800 Train loss 0.21 Classification-F1 0.4420512820512821 on epoch=699
06/12/2022 05:21:25 - INFO - __main__ - Saving model with best Classification-F1: 0.43529411764705883 -> 0.4420512820512821 on epoch=699, global_step=2800
06/12/2022 05:21:29 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.19 on epoch=702
06/12/2022 05:21:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.19 on epoch=704
06/12/2022 05:21:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.19 on epoch=707
06/12/2022 05:21:43 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.18 on epoch=709
06/12/2022 05:21:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.17 on epoch=712
06/12/2022 05:21:50 - INFO - __main__ - Global step 2850 Train loss 0.18 Classification-F1 0.375 on epoch=712
06/12/2022 05:21:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.19 on epoch=714
06/12/2022 05:21:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.20 on epoch=717
06/12/2022 05:22:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.20 on epoch=719
06/12/2022 05:22:08 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.16 on epoch=722
06/12/2022 05:22:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.22 on epoch=724
06/12/2022 05:22:16 - INFO - __main__ - Global step 2900 Train loss 0.19 Classification-F1 0.42216142270861834 on epoch=724
06/12/2022 05:22:20 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.20 on epoch=727
06/12/2022 05:22:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.18 on epoch=729
06/12/2022 05:22:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.22 on epoch=732
06/12/2022 05:22:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.20 on epoch=734
06/12/2022 05:22:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.20 on epoch=737
06/12/2022 05:22:41 - INFO - __main__ - Global step 2950 Train loss 0.20 Classification-F1 0.3818181818181818 on epoch=737
06/12/2022 05:22:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.17 on epoch=739
06/12/2022 05:22:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.20 on epoch=742
06/12/2022 05:22:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.20 on epoch=744
06/12/2022 05:23:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.16 on epoch=747
06/12/2022 05:23:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.22 on epoch=749
06/12/2022 05:23:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 05:23:06 - INFO - __main__ - Printing 3 examples
06/12/2022 05:23:06 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/12/2022 05:23:06 - INFO - __main__ - ['refuted']
06/12/2022 05:23:06 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/12/2022 05:23:06 - INFO - __main__ - ['refuted']
06/12/2022 05:23:06 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/12/2022 05:23:06 - INFO - __main__ - ['refuted']
06/12/2022 05:23:06 - INFO - __main__ - Tokenizing Input ...
06/12/2022 05:23:06 - INFO - __main__ - Tokenizing Output ...
06/12/2022 05:23:06 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 05:23:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 05:23:06 - INFO - __main__ - Printing 3 examples
06/12/2022 05:23:06 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/12/2022 05:23:06 - INFO - __main__ - ['refuted']
06/12/2022 05:23:06 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/12/2022 05:23:06 - INFO - __main__ - ['refuted']
06/12/2022 05:23:06 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/12/2022 05:23:06 - INFO - __main__ - ['refuted']
06/12/2022 05:23:06 - INFO - __main__ - Tokenizing Input ...
06/12/2022 05:23:06 - INFO - __main__ - Tokenizing Output ...
06/12/2022 05:23:06 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 05:23:07 - INFO - __main__ - Global step 3000 Train loss 0.19 Classification-F1 0.429800307219662 on epoch=749
06/12/2022 05:23:07 - INFO - __main__ - save last model!
06/12/2022 05:23:07 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 05:23:07 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 05:23:07 - INFO - __main__ - Printing 3 examples
06/12/2022 05:23:07 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 05:23:07 - INFO - __main__ - ['entailed']
06/12/2022 05:23:07 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 05:23:07 - INFO - __main__ - ['entailed']
06/12/2022 05:23:07 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 05:23:07 - INFO - __main__ - ['entailed']
06/12/2022 05:23:07 - INFO - __main__ - Tokenizing Input ...
06/12/2022 05:23:22 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 05:23:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 05:23:22 - INFO - __main__ - Starting training!
06/12/2022 05:23:32 - INFO - __main__ - Tokenizing Output ...
06/12/2022 05:23:45 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 05:32:49 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_42_0.4_8_predictions.txt
06/12/2022 05:32:49 - INFO - __main__ - Classification-F1 on test data: 0.3795
06/12/2022 05:32:49 - INFO - __main__ - prefix=tab_fact_32_42, lr=0.4, bsz=8, dev_performance=0.4420512820512821, test_performance=0.3794908880158191
06/12/2022 05:32:49 - INFO - __main__ - Running ... prefix=tab_fact_32_42, lr=0.3, bsz=8 ...
06/12/2022 05:32:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 05:32:50 - INFO - __main__ - Printing 3 examples
06/12/2022 05:32:50 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/12/2022 05:32:50 - INFO - __main__ - ['refuted']
06/12/2022 05:32:50 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/12/2022 05:32:50 - INFO - __main__ - ['refuted']
06/12/2022 05:32:50 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/12/2022 05:32:50 - INFO - __main__ - ['refuted']
06/12/2022 05:32:50 - INFO - __main__ - Tokenizing Input ...
06/12/2022 05:32:50 - INFO - __main__ - Tokenizing Output ...
06/12/2022 05:32:50 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 05:32:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 05:32:50 - INFO - __main__ - Printing 3 examples
06/12/2022 05:32:50 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/12/2022 05:32:50 - INFO - __main__ - ['refuted']
06/12/2022 05:32:50 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/12/2022 05:32:50 - INFO - __main__ - ['refuted']
06/12/2022 05:32:50 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/12/2022 05:32:50 - INFO - __main__ - ['refuted']
06/12/2022 05:32:50 - INFO - __main__ - Tokenizing Input ...
06/12/2022 05:32:50 - INFO - __main__ - Tokenizing Output ...
06/12/2022 05:32:51 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 05:33:10 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 05:33:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 05:33:10 - INFO - __main__ - Starting training!
06/12/2022 05:33:16 - INFO - __main__ - Step 10 Global step 10 Train loss 3.13 on epoch=2
06/12/2022 05:33:20 - INFO - __main__ - Step 20 Global step 20 Train loss 0.79 on epoch=4
06/12/2022 05:33:25 - INFO - __main__ - Step 30 Global step 30 Train loss 0.43 on epoch=7
06/12/2022 05:33:29 - INFO - __main__ - Step 40 Global step 40 Train loss 0.36 on epoch=9
06/12/2022 05:33:34 - INFO - __main__ - Step 50 Global step 50 Train loss 0.38 on epoch=12
06/12/2022 05:33:36 - INFO - __main__ - Global step 50 Train loss 1.02 Classification-F1 0.3333333333333333 on epoch=12
06/12/2022 05:33:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/12/2022 05:33:41 - INFO - __main__ - Step 60 Global step 60 Train loss 0.31 on epoch=14
06/12/2022 05:33:45 - INFO - __main__ - Step 70 Global step 70 Train loss 0.31 on epoch=17
06/12/2022 05:33:50 - INFO - __main__ - Step 80 Global step 80 Train loss 0.27 on epoch=19
06/12/2022 05:33:54 - INFO - __main__ - Step 90 Global step 90 Train loss 0.24 on epoch=22
06/12/2022 05:33:59 - INFO - __main__ - Step 100 Global step 100 Train loss 0.31 on epoch=24
06/12/2022 05:34:01 - INFO - __main__ - Global step 100 Train loss 0.29 Classification-F1 0.3333333333333333 on epoch=24
06/12/2022 05:34:06 - INFO - __main__ - Step 110 Global step 110 Train loss 0.26 on epoch=27
06/12/2022 05:34:10 - INFO - __main__ - Step 120 Global step 120 Train loss 0.24 on epoch=29
06/12/2022 05:34:15 - INFO - __main__ - Step 130 Global step 130 Train loss 0.25 on epoch=32
06/12/2022 05:34:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.27 on epoch=34
06/12/2022 05:34:24 - INFO - __main__ - Step 150 Global step 150 Train loss 0.22 on epoch=37
06/12/2022 05:34:26 - INFO - __main__ - Global step 150 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=37
06/12/2022 05:34:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.22 on epoch=39
06/12/2022 05:34:36 - INFO - __main__ - Step 170 Global step 170 Train loss 0.23 on epoch=42
06/12/2022 05:34:40 - INFO - __main__ - Step 180 Global step 180 Train loss 0.25 on epoch=44
06/12/2022 05:34:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.23 on epoch=47
06/12/2022 05:34:49 - INFO - __main__ - Step 200 Global step 200 Train loss 0.22 on epoch=49
06/12/2022 05:34:52 - INFO - __main__ - Global step 200 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=49
06/12/2022 05:34:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.28 on epoch=52
06/12/2022 05:35:01 - INFO - __main__ - Step 220 Global step 220 Train loss 0.24 on epoch=54
06/12/2022 05:35:06 - INFO - __main__ - Step 230 Global step 230 Train loss 0.21 on epoch=57
06/12/2022 05:35:10 - INFO - __main__ - Step 240 Global step 240 Train loss 0.24 on epoch=59
06/12/2022 05:35:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.21 on epoch=62
06/12/2022 05:35:17 - INFO - __main__ - Global step 250 Train loss 0.24 Classification-F1 0.21722846441947566 on epoch=62
06/12/2022 05:35:22 - INFO - __main__ - Step 260 Global step 260 Train loss 0.27 on epoch=64
06/12/2022 05:35:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=67
06/12/2022 05:35:31 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=69
06/12/2022 05:35:35 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=72
06/12/2022 05:35:40 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=74
06/12/2022 05:35:42 - INFO - __main__ - Global step 300 Train loss 0.25 Classification-F1 0.22463768115942032 on epoch=74
06/12/2022 05:35:47 - INFO - __main__ - Step 310 Global step 310 Train loss 0.22 on epoch=77
06/12/2022 05:35:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=79
06/12/2022 05:35:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=82
06/12/2022 05:36:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.21 on epoch=84
06/12/2022 05:36:05 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=87
06/12/2022 05:36:08 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=87
06/12/2022 05:36:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=89
06/12/2022 05:36:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.21 on epoch=92
06/12/2022 05:36:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.18 on epoch=94
06/12/2022 05:36:26 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=97
06/12/2022 05:36:30 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/12/2022 05:36:33 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.21739130434782608 on epoch=99
06/12/2022 05:36:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.25 on epoch=102
06/12/2022 05:36:42 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=104
06/12/2022 05:36:47 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=107
06/12/2022 05:36:51 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=109
06/12/2022 05:36:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/12/2022 05:36:58 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.22456140350877193 on epoch=112
06/12/2022 05:37:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=114
06/12/2022 05:37:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=117
06/12/2022 05:37:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=119
06/12/2022 05:37:16 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=122
06/12/2022 05:37:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
06/12/2022 05:37:24 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=124
06/12/2022 05:37:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=127
06/12/2022 05:37:33 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=129
06/12/2022 05:37:37 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=132
06/12/2022 05:37:42 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/12/2022 05:37:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=137
06/12/2022 05:37:49 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.3671451355661882 on epoch=137
06/12/2022 05:37:49 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.3671451355661882 on epoch=137, global_step=550
06/12/2022 05:37:54 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=139
06/12/2022 05:37:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=142
06/12/2022 05:38:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=144
06/12/2022 05:38:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=147
06/12/2022 05:38:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=149
06/12/2022 05:38:14 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.2665910380034033 on epoch=149
06/12/2022 05:38:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=152
06/12/2022 05:38:23 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=154
06/12/2022 05:38:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=157
06/12/2022 05:38:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/12/2022 05:38:37 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=162
06/12/2022 05:38:39 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.4519207242476144 on epoch=162
06/12/2022 05:38:39 - INFO - __main__ - Saving model with best Classification-F1: 0.3671451355661882 -> 0.4519207242476144 on epoch=162, global_step=650
06/12/2022 05:38:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=164
06/12/2022 05:38:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
06/12/2022 05:38:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=169
06/12/2022 05:38:57 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=172
06/12/2022 05:39:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=174
06/12/2022 05:39:05 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=174
06/12/2022 05:39:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=177
06/12/2022 05:39:14 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=179
06/12/2022 05:39:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=182
06/12/2022 05:39:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=184
06/12/2022 05:39:27 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=187
06/12/2022 05:39:30 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.4452324665090622 on epoch=187
06/12/2022 05:39:35 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=189
06/12/2022 05:39:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=192
06/12/2022 05:39:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=194
06/12/2022 05:39:48 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=197
06/12/2022 05:39:53 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=199
06/12/2022 05:39:56 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.3915298184961106 on epoch=199
06/12/2022 05:40:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=202
06/12/2022 05:40:05 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=204
06/12/2022 05:40:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=207
06/12/2022 05:40:14 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=209
06/12/2022 05:40:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=212
06/12/2022 05:40:21 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.4385964912280702 on epoch=212
06/12/2022 05:40:26 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=214
06/12/2022 05:40:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=217
06/12/2022 05:40:35 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=219
06/12/2022 05:40:39 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=222
06/12/2022 05:40:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=224
06/12/2022 05:40:46 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.436950146627566 on epoch=224
06/12/2022 05:40:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=227
06/12/2022 05:40:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=229
06/12/2022 05:41:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=232
06/12/2022 05:41:04 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=234
06/12/2022 05:41:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=237
06/12/2022 05:41:12 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.40026773761713513 on epoch=237
06/12/2022 05:41:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=239
06/12/2022 05:41:21 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=242
06/12/2022 05:41:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=244
06/12/2022 05:41:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=247
06/12/2022 05:41:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=249
06/12/2022 05:41:38 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.4452324665090622 on epoch=249
06/12/2022 05:41:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=252
06/12/2022 05:41:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=254
06/12/2022 05:41:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=257
06/12/2022 05:41:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=259
06/12/2022 05:42:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/12/2022 05:42:03 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.4947797300738477 on epoch=262
06/12/2022 05:42:03 - INFO - __main__ - Saving model with best Classification-F1: 0.4519207242476144 -> 0.4947797300738477 on epoch=262, global_step=1050
06/12/2022 05:42:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=264
06/12/2022 05:42:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=267
06/12/2022 05:42:17 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
06/12/2022 05:42:22 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=272
06/12/2022 05:42:26 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=274
06/12/2022 05:42:29 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.5126504544338 on epoch=274
06/12/2022 05:42:29 - INFO - __main__ - Saving model with best Classification-F1: 0.4947797300738477 -> 0.5126504544338 on epoch=274, global_step=1100
06/12/2022 05:42:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=277
06/12/2022 05:42:38 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/12/2022 05:42:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=282
06/12/2022 05:42:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=284
06/12/2022 05:42:52 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/12/2022 05:42:55 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.4812085482682388 on epoch=287
06/12/2022 05:43:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/12/2022 05:43:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/12/2022 05:43:09 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=294
06/12/2022 05:43:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=297
06/12/2022 05:43:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=299
06/12/2022 05:43:21 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.4980392156862745 on epoch=299
06/12/2022 05:43:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/12/2022 05:43:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/12/2022 05:43:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.10 on epoch=307
06/12/2022 05:43:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=309
06/12/2022 05:43:44 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/12/2022 05:43:47 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.500880503144654 on epoch=312
06/12/2022 05:43:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
06/12/2022 05:43:56 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/12/2022 05:44:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/12/2022 05:44:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/12/2022 05:44:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=324
06/12/2022 05:44:12 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.4452324665090622 on epoch=324
06/12/2022 05:44:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/12/2022 05:44:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/12/2022 05:44:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/12/2022 05:44:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=334
06/12/2022 05:44:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/12/2022 05:44:38 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.46218487394957986 on epoch=337
06/12/2022 05:44:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/12/2022 05:44:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/12/2022 05:44:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=344
06/12/2022 05:44:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/12/2022 05:45:00 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/12/2022 05:45:03 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.500880503144654 on epoch=349
06/12/2022 05:45:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=352
06/12/2022 05:45:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/12/2022 05:45:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/12/2022 05:45:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/12/2022 05:45:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=362
06/12/2022 05:45:29 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.4817813765182186 on epoch=362
06/12/2022 05:45:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/12/2022 05:45:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=367
06/12/2022 05:45:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=369
06/12/2022 05:45:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/12/2022 05:45:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/12/2022 05:45:55 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.5195195195195195 on epoch=374
06/12/2022 05:45:55 - INFO - __main__ - Saving model with best Classification-F1: 0.5126504544338 -> 0.5195195195195195 on epoch=374, global_step=1500
06/12/2022 05:45:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/12/2022 05:46:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/12/2022 05:46:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=382
06/12/2022 05:46:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/12/2022 05:46:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/12/2022 05:46:21 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.5145583557621727 on epoch=387
06/12/2022 05:46:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=389
06/12/2022 05:46:30 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/12/2022 05:46:34 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/12/2022 05:46:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/12/2022 05:46:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/12/2022 05:46:46 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.45705196182396607 on epoch=399
06/12/2022 05:46:51 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/12/2022 05:46:55 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=404
06/12/2022 05:47:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/12/2022 05:47:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/12/2022 05:47:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/12/2022 05:47:11 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.47813194959229055 on epoch=412
06/12/2022 05:47:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/12/2022 05:47:20 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/12/2022 05:47:25 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/12/2022 05:47:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/12/2022 05:47:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/12/2022 05:47:37 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.464039408866995 on epoch=424
06/12/2022 05:47:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/12/2022 05:47:46 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/12/2022 05:47:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/12/2022 05:47:55 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/12/2022 05:47:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/12/2022 05:48:02 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.4874874874874875 on epoch=437
06/12/2022 05:48:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/12/2022 05:48:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/12/2022 05:48:15 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/12/2022 05:48:20 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
06/12/2022 05:48:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/12/2022 05:48:27 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.4666666666666667 on epoch=449
06/12/2022 05:48:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/12/2022 05:48:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/12/2022 05:48:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/12/2022 05:48:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/12/2022 05:48:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=462
06/12/2022 05:48:53 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.473972602739726 on epoch=462
06/12/2022 05:48:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/12/2022 05:49:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/12/2022 05:49:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/12/2022 05:49:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/12/2022 05:49:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/12/2022 05:49:18 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.4920634920634921 on epoch=474
06/12/2022 05:49:22 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/12/2022 05:49:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=479
06/12/2022 05:49:31 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/12/2022 05:49:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/12/2022 05:49:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/12/2022 05:49:43 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.43647798742138366 on epoch=487
06/12/2022 05:49:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/12/2022 05:49:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/12/2022 05:49:57 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/12/2022 05:50:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/12/2022 05:50:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/12/2022 05:50:08 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.46875 on epoch=499
06/12/2022 05:50:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/12/2022 05:50:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/12/2022 05:50:22 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/12/2022 05:50:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/12/2022 05:50:31 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/12/2022 05:50:33 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.464039408866995 on epoch=512
06/12/2022 05:50:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/12/2022 05:50:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/12/2022 05:50:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/12/2022 05:50:52 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/12/2022 05:50:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/12/2022 05:50:59 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.44976664210267747 on epoch=524
06/12/2022 05:51:04 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/12/2022 05:51:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/12/2022 05:51:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/12/2022 05:51:17 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/12/2022 05:51:22 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/12/2022 05:51:25 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.4682306940371457 on epoch=537
06/12/2022 05:51:29 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/12/2022 05:51:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/12/2022 05:51:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/12/2022 05:51:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/12/2022 05:51:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/12/2022 05:51:50 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.5145583557621727 on epoch=549
06/12/2022 05:51:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/12/2022 05:51:59 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/12/2022 05:52:04 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/12/2022 05:52:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/12/2022 05:52:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/12/2022 05:52:15 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.44209215442092153 on epoch=562
06/12/2022 05:52:20 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/12/2022 05:52:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/12/2022 05:52:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/12/2022 05:52:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=572
06/12/2022 05:52:38 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/12/2022 05:52:41 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.3969951617010441 on epoch=574
06/12/2022 05:52:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/12/2022 05:52:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=579
06/12/2022 05:52:55 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/12/2022 05:52:59 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/12/2022 05:53:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/12/2022 05:53:07 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.42342342342342343 on epoch=587
06/12/2022 05:53:11 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/12/2022 05:53:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/12/2022 05:53:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/12/2022 05:53:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/12/2022 05:53:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/12/2022 05:53:32 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.464039408866995 on epoch=599
06/12/2022 05:53:36 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/12/2022 05:53:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/12/2022 05:53:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/12/2022 05:53:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/12/2022 05:53:54 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=612
06/12/2022 05:53:57 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.41832473593711617 on epoch=612
06/12/2022 05:54:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/12/2022 05:54:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/12/2022 05:54:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/12/2022 05:54:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=622
06/12/2022 05:54:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=624
06/12/2022 05:54:23 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.4995112414467253 on epoch=624
06/12/2022 05:54:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/12/2022 05:54:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/12/2022 05:54:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/12/2022 05:54:41 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/12/2022 05:54:45 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/12/2022 05:54:48 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.4285714285714286 on epoch=637
06/12/2022 05:54:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/12/2022 05:54:57 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/12/2022 05:55:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/12/2022 05:55:06 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/12/2022 05:55:10 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/12/2022 05:55:13 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.4285714285714286 on epoch=649
06/12/2022 05:55:17 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/12/2022 05:55:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=654
06/12/2022 05:55:26 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/12/2022 05:55:31 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/12/2022 05:55:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/12/2022 05:55:38 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.46031746031746035 on epoch=662
06/12/2022 05:55:43 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/12/2022 05:55:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/12/2022 05:55:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/12/2022 05:55:56 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/12/2022 05:56:01 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/12/2022 05:56:04 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.4812085482682388 on epoch=674
06/12/2022 05:56:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/12/2022 05:56:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/12/2022 05:56:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/12/2022 05:56:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/12/2022 05:56:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/12/2022 05:56:29 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.46218487394957986 on epoch=687
06/12/2022 05:56:34 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/12/2022 05:56:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/12/2022 05:56:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/12/2022 05:56:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/12/2022 05:56:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/12/2022 05:56:54 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.4493927125506073 on epoch=699
06/12/2022 05:56:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/12/2022 05:57:03 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/12/2022 05:57:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/12/2022 05:57:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=709
06/12/2022 05:57:17 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/12/2022 05:57:20 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.46867924528301885 on epoch=712
06/12/2022 05:57:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/12/2022 05:57:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/12/2022 05:57:33 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/12/2022 05:57:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/12/2022 05:57:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/12/2022 05:57:45 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.473972602739726 on epoch=724
06/12/2022 05:57:50 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/12/2022 05:57:54 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/12/2022 05:57:59 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/12/2022 05:58:03 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/12/2022 05:58:08 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/12/2022 05:58:10 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.473972602739726 on epoch=737
06/12/2022 05:58:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/12/2022 05:58:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/12/2022 05:58:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/12/2022 05:58:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/12/2022 05:58:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/12/2022 05:58:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 05:58:34 - INFO - __main__ - Printing 3 examples
06/12/2022 05:58:34 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/12/2022 05:58:34 - INFO - __main__ - ['refuted']
06/12/2022 05:58:34 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/12/2022 05:58:34 - INFO - __main__ - ['refuted']
06/12/2022 05:58:34 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/12/2022 05:58:34 - INFO - __main__ - ['refuted']
06/12/2022 05:58:34 - INFO - __main__ - Tokenizing Input ...
06/12/2022 05:58:35 - INFO - __main__ - Tokenizing Output ...
06/12/2022 05:58:35 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 05:58:35 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 05:58:35 - INFO - __main__ - Printing 3 examples
06/12/2022 05:58:35 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/12/2022 05:58:35 - INFO - __main__ - ['refuted']
06/12/2022 05:58:35 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/12/2022 05:58:35 - INFO - __main__ - ['refuted']
06/12/2022 05:58:35 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/12/2022 05:58:35 - INFO - __main__ - ['refuted']
06/12/2022 05:58:35 - INFO - __main__ - Tokenizing Input ...
06/12/2022 05:58:35 - INFO - __main__ - Tokenizing Output ...
06/12/2022 05:58:35 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 05:58:36 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.4465035829009143 on epoch=749
06/12/2022 05:58:36 - INFO - __main__ - save last model!
06/12/2022 05:58:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 05:58:36 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 05:58:36 - INFO - __main__ - Printing 3 examples
06/12/2022 05:58:36 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 05:58:36 - INFO - __main__ - ['entailed']
06/12/2022 05:58:36 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 05:58:36 - INFO - __main__ - ['entailed']
06/12/2022 05:58:36 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 05:58:36 - INFO - __main__ - ['entailed']
06/12/2022 05:58:36 - INFO - __main__ - Tokenizing Input ...
06/12/2022 05:58:55 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 05:58:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 05:58:56 - INFO - __main__ - Starting training!
06/12/2022 05:59:00 - INFO - __main__ - Tokenizing Output ...
06/12/2022 05:59:13 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 06:07:37 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_42_0.3_8_predictions.txt
06/12/2022 06:07:37 - INFO - __main__ - Classification-F1 on test data: 0.4956
06/12/2022 06:07:37 - INFO - __main__ - prefix=tab_fact_32_42, lr=0.3, bsz=8, dev_performance=0.5195195195195195, test_performance=0.4956029981378617
06/12/2022 06:07:37 - INFO - __main__ - Running ... prefix=tab_fact_32_42, lr=0.2, bsz=8 ...
06/12/2022 06:07:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 06:07:38 - INFO - __main__ - Printing 3 examples
06/12/2022 06:07:38 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/12/2022 06:07:38 - INFO - __main__ - ['refuted']
06/12/2022 06:07:38 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/12/2022 06:07:38 - INFO - __main__ - ['refuted']
06/12/2022 06:07:38 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/12/2022 06:07:38 - INFO - __main__ - ['refuted']
06/12/2022 06:07:38 - INFO - __main__ - Tokenizing Input ...
06/12/2022 06:07:38 - INFO - __main__ - Tokenizing Output ...
06/12/2022 06:07:38 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 06:07:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 06:07:38 - INFO - __main__ - Printing 3 examples
06/12/2022 06:07:38 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/12/2022 06:07:39 - INFO - __main__ - ['refuted']
06/12/2022 06:07:39 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/12/2022 06:07:39 - INFO - __main__ - ['refuted']
06/12/2022 06:07:39 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/12/2022 06:07:39 - INFO - __main__ - ['refuted']
06/12/2022 06:07:39 - INFO - __main__ - Tokenizing Input ...
06/12/2022 06:07:39 - INFO - __main__ - Tokenizing Output ...
06/12/2022 06:07:39 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 06:07:57 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 06:07:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 06:07:58 - INFO - __main__ - Starting training!
06/12/2022 06:08:03 - INFO - __main__ - Step 10 Global step 10 Train loss 3.47 on epoch=2
06/12/2022 06:08:08 - INFO - __main__ - Step 20 Global step 20 Train loss 1.10 on epoch=4
06/12/2022 06:08:12 - INFO - __main__ - Step 30 Global step 30 Train loss 0.62 on epoch=7
06/12/2022 06:08:17 - INFO - __main__ - Step 40 Global step 40 Train loss 0.51 on epoch=9
06/12/2022 06:08:21 - INFO - __main__ - Step 50 Global step 50 Train loss 0.39 on epoch=12
06/12/2022 06:08:24 - INFO - __main__ - Global step 50 Train loss 1.22 Classification-F1 0.3333333333333333 on epoch=12
06/12/2022 06:08:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/12/2022 06:08:29 - INFO - __main__ - Step 60 Global step 60 Train loss 0.32 on epoch=14
06/12/2022 06:08:33 - INFO - __main__ - Step 70 Global step 70 Train loss 0.32 on epoch=17
06/12/2022 06:08:38 - INFO - __main__ - Step 80 Global step 80 Train loss 0.29 on epoch=19
06/12/2022 06:08:42 - INFO - __main__ - Step 90 Global step 90 Train loss 0.27 on epoch=22
06/12/2022 06:08:47 - INFO - __main__ - Step 100 Global step 100 Train loss 0.32 on epoch=24
06/12/2022 06:08:50 - INFO - __main__ - Global step 100 Train loss 0.30 Classification-F1 0.3333333333333333 on epoch=24
06/12/2022 06:08:54 - INFO - __main__ - Step 110 Global step 110 Train loss 0.29 on epoch=27
06/12/2022 06:08:59 - INFO - __main__ - Step 120 Global step 120 Train loss 0.27 on epoch=29
06/12/2022 06:09:03 - INFO - __main__ - Step 130 Global step 130 Train loss 0.27 on epoch=32
06/12/2022 06:09:08 - INFO - __main__ - Step 140 Global step 140 Train loss 0.26 on epoch=34
06/12/2022 06:09:12 - INFO - __main__ - Step 150 Global step 150 Train loss 0.28 on epoch=37
06/12/2022 06:09:15 - INFO - __main__ - Global step 150 Train loss 0.27 Classification-F1 0.3333333333333333 on epoch=37
06/12/2022 06:09:20 - INFO - __main__ - Step 160 Global step 160 Train loss 0.24 on epoch=39
06/12/2022 06:09:24 - INFO - __main__ - Step 170 Global step 170 Train loss 0.27 on epoch=42
06/12/2022 06:09:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.25 on epoch=44
06/12/2022 06:09:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.24 on epoch=47
06/12/2022 06:09:38 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=49
06/12/2022 06:09:40 - INFO - __main__ - Global step 200 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=49
06/12/2022 06:09:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.22 on epoch=52
06/12/2022 06:09:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.24 on epoch=54
06/12/2022 06:09:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.21 on epoch=57
06/12/2022 06:09:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.24 on epoch=59
06/12/2022 06:10:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.24 on epoch=62
06/12/2022 06:10:06 - INFO - __main__ - Global step 250 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=62
06/12/2022 06:10:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.27 on epoch=64
06/12/2022 06:10:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.28 on epoch=67
06/12/2022 06:10:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.21 on epoch=69
06/12/2022 06:10:24 - INFO - __main__ - Step 290 Global step 290 Train loss 0.19 on epoch=72
06/12/2022 06:10:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.22 on epoch=74
06/12/2022 06:10:31 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=74
06/12/2022 06:10:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=77
06/12/2022 06:10:40 - INFO - __main__ - Step 320 Global step 320 Train loss 0.23 on epoch=79
06/12/2022 06:10:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/12/2022 06:10:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=84
06/12/2022 06:10:54 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=87
06/12/2022 06:10:57 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=87
06/12/2022 06:11:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=89
06/12/2022 06:11:06 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=92
06/12/2022 06:11:10 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=94
06/12/2022 06:11:15 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/12/2022 06:11:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=99
06/12/2022 06:11:22 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=99
06/12/2022 06:11:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=102
06/12/2022 06:11:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=104
06/12/2022 06:11:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=107
06/12/2022 06:11:41 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=109
06/12/2022 06:11:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/12/2022 06:11:48 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=112
06/12/2022 06:11:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=114
06/12/2022 06:11:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=117
06/12/2022 06:12:02 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/12/2022 06:12:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.27 on epoch=122
06/12/2022 06:12:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=124
06/12/2022 06:12:14 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=124
06/12/2022 06:12:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=127
06/12/2022 06:12:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=129
06/12/2022 06:12:27 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=132
06/12/2022 06:12:32 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=134
06/12/2022 06:12:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
06/12/2022 06:12:39 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.3347193347193347 on epoch=137
06/12/2022 06:12:39 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.3347193347193347 on epoch=137, global_step=550
06/12/2022 06:12:44 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=139
06/12/2022 06:12:48 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=142
06/12/2022 06:12:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/12/2022 06:12:57 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=147
06/12/2022 06:13:02 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=149
06/12/2022 06:13:05 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=149
06/12/2022 06:13:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=152
06/12/2022 06:13:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=154
06/12/2022 06:13:18 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=157
06/12/2022 06:13:23 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=159
06/12/2022 06:13:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=162
06/12/2022 06:13:30 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=162
06/12/2022 06:13:34 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=164
06/12/2022 06:13:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
06/12/2022 06:13:44 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=169
06/12/2022 06:13:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=172
06/12/2022 06:13:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=174
06/12/2022 06:13:55 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=174
06/12/2022 06:14:00 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=177
06/12/2022 06:14:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=179
06/12/2022 06:14:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=182
06/12/2022 06:14:13 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=184
06/12/2022 06:14:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=187
06/12/2022 06:14:21 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.3816425120772947 on epoch=187
06/12/2022 06:14:21 - INFO - __main__ - Saving model with best Classification-F1: 0.3347193347193347 -> 0.3816425120772947 on epoch=187, global_step=750
06/12/2022 06:14:25 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=189
06/12/2022 06:14:30 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=192
06/12/2022 06:14:34 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=194
06/12/2022 06:14:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=197
06/12/2022 06:14:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=199
06/12/2022 06:14:46 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.4452324665090622 on epoch=199
06/12/2022 06:14:46 - INFO - __main__ - Saving model with best Classification-F1: 0.3816425120772947 -> 0.4452324665090622 on epoch=199, global_step=800
06/12/2022 06:14:51 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=202
06/12/2022 06:14:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=204
06/12/2022 06:15:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=207
06/12/2022 06:15:04 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=209
06/12/2022 06:15:09 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=212
06/12/2022 06:15:12 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.473972602739726 on epoch=212
06/12/2022 06:15:12 - INFO - __main__ - Saving model with best Classification-F1: 0.4452324665090622 -> 0.473972602739726 on epoch=212, global_step=850
06/12/2022 06:15:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=214
06/12/2022 06:15:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=217
06/12/2022 06:15:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=219
06/12/2022 06:15:30 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=222
06/12/2022 06:15:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=224
06/12/2022 06:15:37 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.4817813765182186 on epoch=224
06/12/2022 06:15:37 - INFO - __main__ - Saving model with best Classification-F1: 0.473972602739726 -> 0.4817813765182186 on epoch=224, global_step=900
06/12/2022 06:15:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=227
06/12/2022 06:15:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=229
06/12/2022 06:15:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=232
06/12/2022 06:15:56 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=234
06/12/2022 06:16:00 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=237
06/12/2022 06:16:03 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.45299145299145294 on epoch=237
06/12/2022 06:16:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=239
06/12/2022 06:16:12 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=242
06/12/2022 06:16:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=244
06/12/2022 06:16:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=247
06/12/2022 06:16:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=249
06/12/2022 06:16:29 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.4420512820512821 on epoch=249
06/12/2022 06:16:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=252
06/12/2022 06:16:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=254
06/12/2022 06:16:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=257
06/12/2022 06:16:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=259
06/12/2022 06:16:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=262
06/12/2022 06:16:54 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.44379029997196523 on epoch=262
06/12/2022 06:16:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=264
06/12/2022 06:17:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=267
06/12/2022 06:17:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=269
06/12/2022 06:17:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=272
06/12/2022 06:17:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=274
06/12/2022 06:17:21 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.4325123152709359 on epoch=274
06/12/2022 06:17:26 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=277
06/12/2022 06:17:30 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=279
06/12/2022 06:17:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=282
06/12/2022 06:17:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=284
06/12/2022 06:17:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=287
06/12/2022 06:17:47 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.4345381526104417 on epoch=287
06/12/2022 06:17:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=289
06/12/2022 06:17:56 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=292
06/12/2022 06:18:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=294
06/12/2022 06:18:06 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=297
06/12/2022 06:18:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=299
06/12/2022 06:18:14 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.46218487394957986 on epoch=299
06/12/2022 06:18:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=302
06/12/2022 06:18:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=304
06/12/2022 06:18:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=307
06/12/2022 06:18:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=309
06/12/2022 06:18:36 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=312
06/12/2022 06:18:39 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.4748717948717949 on epoch=312
06/12/2022 06:18:44 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/12/2022 06:18:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/12/2022 06:18:53 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
06/12/2022 06:18:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=322
06/12/2022 06:19:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=324
06/12/2022 06:19:05 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.500880503144654 on epoch=324
06/12/2022 06:19:05 - INFO - __main__ - Saving model with best Classification-F1: 0.4817813765182186 -> 0.500880503144654 on epoch=324, global_step=1300
06/12/2022 06:19:09 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=327
06/12/2022 06:19:14 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=329
06/12/2022 06:19:18 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=332
06/12/2022 06:19:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=334
06/12/2022 06:19:28 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/12/2022 06:19:30 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.436950146627566 on epoch=337
06/12/2022 06:19:35 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=339
06/12/2022 06:19:39 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=342
06/12/2022 06:19:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=344
06/12/2022 06:19:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=347
06/12/2022 06:19:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=349
06/12/2022 06:19:57 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.40026773761713513 on epoch=349
06/12/2022 06:20:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=352
06/12/2022 06:20:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=354
06/12/2022 06:20:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=357
06/12/2022 06:20:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=359
06/12/2022 06:20:19 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=362
06/12/2022 06:20:22 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.4465035829009143 on epoch=362
06/12/2022 06:20:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=364
06/12/2022 06:20:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=367
06/12/2022 06:20:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=369
06/12/2022 06:20:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=372
06/12/2022 06:20:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=374
06/12/2022 06:20:47 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.41832473593711617 on epoch=374
06/12/2022 06:20:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=377
06/12/2022 06:20:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=379
06/12/2022 06:21:01 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
06/12/2022 06:21:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/12/2022 06:21:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/12/2022 06:21:13 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.38324684951816157 on epoch=387
06/12/2022 06:21:17 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=389
06/12/2022 06:21:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/12/2022 06:21:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
06/12/2022 06:21:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=397
06/12/2022 06:21:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=399
06/12/2022 06:21:39 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.4554554554554554 on epoch=399
06/12/2022 06:21:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/12/2022 06:21:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/12/2022 06:21:52 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/12/2022 06:21:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/12/2022 06:22:01 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/12/2022 06:22:04 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.44976664210267747 on epoch=412
06/12/2022 06:22:09 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/12/2022 06:22:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=417
06/12/2022 06:22:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/12/2022 06:22:22 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=422
06/12/2022 06:22:27 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/12/2022 06:22:30 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.41487521620953793 on epoch=424
06/12/2022 06:22:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/12/2022 06:22:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=429
06/12/2022 06:22:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/12/2022 06:22:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/12/2022 06:22:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/12/2022 06:22:55 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.46875 on epoch=437
06/12/2022 06:23:00 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=439
06/12/2022 06:23:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
06/12/2022 06:23:09 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=444
06/12/2022 06:23:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/12/2022 06:23:18 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/12/2022 06:23:20 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.4217338217338217 on epoch=449
06/12/2022 06:23:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/12/2022 06:23:30 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/12/2022 06:23:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/12/2022 06:23:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
06/12/2022 06:23:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/12/2022 06:23:46 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.38324684951816157 on epoch=462
06/12/2022 06:23:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/12/2022 06:23:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/12/2022 06:24:00 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/12/2022 06:24:04 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/12/2022 06:24:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/12/2022 06:24:12 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.4420512820512821 on epoch=474
06/12/2022 06:24:16 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=477
06/12/2022 06:24:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/12/2022 06:24:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/12/2022 06:24:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/12/2022 06:24:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/12/2022 06:24:37 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.464039408866995 on epoch=487
06/12/2022 06:24:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/12/2022 06:24:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/12/2022 06:24:51 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
06/12/2022 06:24:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/12/2022 06:25:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/12/2022 06:25:03 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.4285714285714286 on epoch=499
06/12/2022 06:25:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/12/2022 06:25:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/12/2022 06:25:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/12/2022 06:25:21 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
06/12/2022 06:25:26 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/12/2022 06:25:28 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.40566959921798634 on epoch=512
06/12/2022 06:25:33 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/12/2022 06:25:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/12/2022 06:25:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/12/2022 06:25:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/12/2022 06:25:51 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=524
06/12/2022 06:25:54 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.43647798742138366 on epoch=524
06/12/2022 06:25:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/12/2022 06:26:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/12/2022 06:26:08 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/12/2022 06:26:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/12/2022 06:26:17 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/12/2022 06:26:19 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.43529411764705883 on epoch=537
06/12/2022 06:26:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/12/2022 06:26:29 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/12/2022 06:26:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/12/2022 06:26:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/12/2022 06:26:42 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=549
06/12/2022 06:26:45 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.45299145299145294 on epoch=549
06/12/2022 06:26:50 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/12/2022 06:26:54 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/12/2022 06:26:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/12/2022 06:27:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/12/2022 06:27:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/12/2022 06:27:11 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.2846270928462709 on epoch=562
06/12/2022 06:27:15 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/12/2022 06:27:20 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/12/2022 06:27:25 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/12/2022 06:27:29 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/12/2022 06:27:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/12/2022 06:27:37 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.4213381555153707 on epoch=574
06/12/2022 06:27:41 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/12/2022 06:27:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/12/2022 06:27:51 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/12/2022 06:27:55 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/12/2022 06:28:00 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/12/2022 06:28:02 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.38324684951816157 on epoch=587
06/12/2022 06:28:07 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/12/2022 06:28:12 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=592
06/12/2022 06:28:16 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/12/2022 06:28:21 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=597
06/12/2022 06:28:25 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/12/2022 06:28:28 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.44976664210267747 on epoch=599
06/12/2022 06:28:33 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/12/2022 06:28:37 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/12/2022 06:28:42 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/12/2022 06:28:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/12/2022 06:28:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/12/2022 06:28:54 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.48424908424908425 on epoch=612
06/12/2022 06:28:59 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/12/2022 06:29:03 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/12/2022 06:29:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/12/2022 06:29:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/12/2022 06:29:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/12/2022 06:29:20 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.4102117061021171 on epoch=624
06/12/2022 06:29:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=627
06/12/2022 06:29:29 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/12/2022 06:29:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=632
06/12/2022 06:29:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/12/2022 06:29:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
06/12/2022 06:29:46 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.4325123152709359 on epoch=637
06/12/2022 06:29:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/12/2022 06:29:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
06/12/2022 06:30:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/12/2022 06:30:04 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=647
06/12/2022 06:30:09 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/12/2022 06:30:12 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.44209215442092153 on epoch=649
06/12/2022 06:30:16 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/12/2022 06:30:21 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/12/2022 06:30:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/12/2022 06:30:30 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/12/2022 06:30:34 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/12/2022 06:30:37 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.46031746031746035 on epoch=662
06/12/2022 06:30:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/12/2022 06:30:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/12/2022 06:30:51 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/12/2022 06:30:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/12/2022 06:31:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/12/2022 06:31:03 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.40427672955974847 on epoch=674
06/12/2022 06:31:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/12/2022 06:31:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/12/2022 06:31:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/12/2022 06:31:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/12/2022 06:31:25 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/12/2022 06:31:28 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.41700404858299595 on epoch=687
06/12/2022 06:31:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/12/2022 06:31:37 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/12/2022 06:31:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/12/2022 06:31:46 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/12/2022 06:31:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/12/2022 06:31:54 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.44209215442092153 on epoch=699
06/12/2022 06:31:58 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/12/2022 06:32:03 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/12/2022 06:32:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/12/2022 06:32:12 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/12/2022 06:32:16 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/12/2022 06:32:19 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.4465035829009143 on epoch=712
06/12/2022 06:32:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/12/2022 06:32:28 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/12/2022 06:32:33 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=719
06/12/2022 06:32:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/12/2022 06:32:42 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/12/2022 06:32:45 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.4285714285714286 on epoch=724
06/12/2022 06:32:50 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
06/12/2022 06:32:54 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/12/2022 06:32:59 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/12/2022 06:33:03 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/12/2022 06:33:08 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/12/2022 06:33:11 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.4325123152709359 on epoch=737
06/12/2022 06:33:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
06/12/2022 06:33:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=742
06/12/2022 06:33:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/12/2022 06:33:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=747
06/12/2022 06:33:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/12/2022 06:33:35 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 06:33:35 - INFO - __main__ - Printing 3 examples
06/12/2022 06:33:35 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/12/2022 06:33:35 - INFO - __main__ - ['entailed']
06/12/2022 06:33:35 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/12/2022 06:33:35 - INFO - __main__ - ['entailed']
06/12/2022 06:33:35 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/12/2022 06:33:35 - INFO - __main__ - ['entailed']
06/12/2022 06:33:35 - INFO - __main__ - Tokenizing Input ...
06/12/2022 06:33:35 - INFO - __main__ - Tokenizing Output ...
06/12/2022 06:33:35 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 06:33:35 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 06:33:35 - INFO - __main__ - Printing 3 examples
06/12/2022 06:33:35 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/12/2022 06:33:35 - INFO - __main__ - ['entailed']
06/12/2022 06:33:35 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/12/2022 06:33:35 - INFO - __main__ - ['entailed']
06/12/2022 06:33:35 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/12/2022 06:33:35 - INFO - __main__ - ['entailed']
06/12/2022 06:33:35 - INFO - __main__ - Tokenizing Input ...
06/12/2022 06:33:35 - INFO - __main__ - Tokenizing Output ...
06/12/2022 06:33:35 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 06:33:36 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.5126504544338 on epoch=749
06/12/2022 06:33:36 - INFO - __main__ - Saving model with best Classification-F1: 0.500880503144654 -> 0.5126504544338 on epoch=749, global_step=3000
06/12/2022 06:33:36 - INFO - __main__ - save last model!
06/12/2022 06:33:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 06:33:37 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 06:33:37 - INFO - __main__ - Printing 3 examples
06/12/2022 06:33:37 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 06:33:37 - INFO - __main__ - ['entailed']
06/12/2022 06:33:37 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 06:33:37 - INFO - __main__ - ['entailed']
06/12/2022 06:33:37 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 06:33:37 - INFO - __main__ - ['entailed']
06/12/2022 06:33:37 - INFO - __main__ - Tokenizing Input ...
06/12/2022 06:33:55 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 06:33:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 06:33:56 - INFO - __main__ - Starting training!
06/12/2022 06:34:04 - INFO - __main__ - Tokenizing Output ...
06/12/2022 06:34:19 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 06:43:04 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_42_0.2_8_predictions.txt
06/12/2022 06:43:04 - INFO - __main__ - Classification-F1 on test data: 0.5003
06/12/2022 06:43:05 - INFO - __main__ - prefix=tab_fact_32_42, lr=0.2, bsz=8, dev_performance=0.5126504544338, test_performance=0.5003373831699327
06/12/2022 06:43:05 - INFO - __main__ - Running ... prefix=tab_fact_32_87, lr=0.5, bsz=8 ...
06/12/2022 06:43:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 06:43:05 - INFO - __main__ - Printing 3 examples
06/12/2022 06:43:05 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/12/2022 06:43:06 - INFO - __main__ - ['entailed']
06/12/2022 06:43:06 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/12/2022 06:43:06 - INFO - __main__ - ['entailed']
06/12/2022 06:43:06 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/12/2022 06:43:06 - INFO - __main__ - ['entailed']
06/12/2022 06:43:06 - INFO - __main__ - Tokenizing Input ...
06/12/2022 06:43:06 - INFO - __main__ - Tokenizing Output ...
06/12/2022 06:43:06 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 06:43:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 06:43:06 - INFO - __main__ - Printing 3 examples
06/12/2022 06:43:06 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/12/2022 06:43:06 - INFO - __main__ - ['entailed']
06/12/2022 06:43:06 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/12/2022 06:43:06 - INFO - __main__ - ['entailed']
06/12/2022 06:43:06 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/12/2022 06:43:06 - INFO - __main__ - ['entailed']
06/12/2022 06:43:06 - INFO - __main__ - Tokenizing Input ...
06/12/2022 06:43:06 - INFO - __main__ - Tokenizing Output ...
06/12/2022 06:43:06 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 06:43:21 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 06:43:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 06:43:22 - INFO - __main__ - Starting training!
06/12/2022 06:43:27 - INFO - __main__ - Step 10 Global step 10 Train loss 2.71 on epoch=2
06/12/2022 06:43:32 - INFO - __main__ - Step 20 Global step 20 Train loss 0.56 on epoch=4
06/12/2022 06:43:36 - INFO - __main__ - Step 30 Global step 30 Train loss 0.45 on epoch=7
06/12/2022 06:43:41 - INFO - __main__ - Step 40 Global step 40 Train loss 0.34 on epoch=9
06/12/2022 06:43:45 - INFO - __main__ - Step 50 Global step 50 Train loss 0.27 on epoch=12
06/12/2022 06:43:48 - INFO - __main__ - Global step 50 Train loss 0.87 Classification-F1 0.4519207242476144 on epoch=12
06/12/2022 06:43:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.4519207242476144 on epoch=12, global_step=50
06/12/2022 06:43:53 - INFO - __main__ - Step 60 Global step 60 Train loss 0.30 on epoch=14
06/12/2022 06:43:57 - INFO - __main__ - Step 70 Global step 70 Train loss 0.34 on epoch=17
06/12/2022 06:44:02 - INFO - __main__ - Step 80 Global step 80 Train loss 0.27 on epoch=19
06/12/2022 06:44:06 - INFO - __main__ - Step 90 Global step 90 Train loss 0.26 on epoch=22
06/12/2022 06:44:11 - INFO - __main__ - Step 100 Global step 100 Train loss 0.22 on epoch=24
06/12/2022 06:44:14 - INFO - __main__ - Global step 100 Train loss 0.28 Classification-F1 0.3333333333333333 on epoch=24
06/12/2022 06:44:18 - INFO - __main__ - Step 110 Global step 110 Train loss 0.26 on epoch=27
06/12/2022 06:44:23 - INFO - __main__ - Step 120 Global step 120 Train loss 0.25 on epoch=29
06/12/2022 06:44:27 - INFO - __main__ - Step 130 Global step 130 Train loss 0.67 on epoch=32
06/12/2022 06:44:32 - INFO - __main__ - Step 140 Global step 140 Train loss 0.93 on epoch=34
06/12/2022 06:44:36 - INFO - __main__ - Step 150 Global step 150 Train loss 0.22 on epoch=37
06/12/2022 06:44:39 - INFO - __main__ - Global step 150 Train loss 0.47 Classification-F1 0.3333333333333333 on epoch=37
06/12/2022 06:44:43 - INFO - __main__ - Step 160 Global step 160 Train loss 0.25 on epoch=39
06/12/2022 06:44:48 - INFO - __main__ - Step 170 Global step 170 Train loss 0.23 on epoch=42
06/12/2022 06:44:52 - INFO - __main__ - Step 180 Global step 180 Train loss 0.23 on epoch=44
06/12/2022 06:44:57 - INFO - __main__ - Step 190 Global step 190 Train loss 0.27 on epoch=47
06/12/2022 06:45:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.25 on epoch=49
06/12/2022 06:45:04 - INFO - __main__ - Global step 200 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=49
06/12/2022 06:45:09 - INFO - __main__ - Step 210 Global step 210 Train loss 0.24 on epoch=52
06/12/2022 06:45:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.23 on epoch=54
06/12/2022 06:45:18 - INFO - __main__ - Step 230 Global step 230 Train loss 0.23 on epoch=57
06/12/2022 06:45:22 - INFO - __main__ - Step 240 Global step 240 Train loss 0.25 on epoch=59
06/12/2022 06:45:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.27 on epoch=62
06/12/2022 06:45:30 - INFO - __main__ - Global step 250 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=62
06/12/2022 06:45:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.22 on epoch=64
06/12/2022 06:45:39 - INFO - __main__ - Step 270 Global step 270 Train loss 0.21 on epoch=67
06/12/2022 06:45:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.21 on epoch=69
06/12/2022 06:45:48 - INFO - __main__ - Step 290 Global step 290 Train loss 0.23 on epoch=72
06/12/2022 06:45:52 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=74
06/12/2022 06:45:55 - INFO - __main__ - Global step 300 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=74
06/12/2022 06:46:00 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=77
06/12/2022 06:46:04 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=79
06/12/2022 06:46:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=82
06/12/2022 06:46:13 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=84
06/12/2022 06:46:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.22 on epoch=87
06/12/2022 06:46:20 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=87
06/12/2022 06:46:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=89
06/12/2022 06:46:29 - INFO - __main__ - Step 370 Global step 370 Train loss 0.20 on epoch=92
06/12/2022 06:46:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=94
06/12/2022 06:46:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=97
06/12/2022 06:46:42 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=99
06/12/2022 06:46:45 - INFO - __main__ - Global step 400 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=99
06/12/2022 06:46:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=102
06/12/2022 06:46:54 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/12/2022 06:46:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=107
06/12/2022 06:47:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=109
06/12/2022 06:47:08 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/12/2022 06:47:10 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=112
06/12/2022 06:47:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=114
06/12/2022 06:47:19 - INFO - __main__ - Step 470 Global step 470 Train loss 0.24 on epoch=117
06/12/2022 06:47:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=119
06/12/2022 06:47:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=122
06/12/2022 06:47:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=124
06/12/2022 06:47:36 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=124
06/12/2022 06:47:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=127
06/12/2022 06:47:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=129
06/12/2022 06:47:49 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=132
06/12/2022 06:47:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=134
06/12/2022 06:47:58 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
06/12/2022 06:48:01 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=137
06/12/2022 06:48:06 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=139
06/12/2022 06:48:10 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=142
06/12/2022 06:48:15 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=144
06/12/2022 06:48:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
06/12/2022 06:48:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=149
06/12/2022 06:48:27 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=149
06/12/2022 06:48:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=152
06/12/2022 06:48:36 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=154
06/12/2022 06:48:40 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=157
06/12/2022 06:48:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/12/2022 06:48:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=162
06/12/2022 06:48:52 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.47885474126608885 on epoch=162
06/12/2022 06:48:52 - INFO - __main__ - Saving model with best Classification-F1: 0.4519207242476144 -> 0.47885474126608885 on epoch=162, global_step=650
06/12/2022 06:48:57 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=164
06/12/2022 06:49:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=167
06/12/2022 06:49:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=169
06/12/2022 06:49:10 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=172
06/12/2022 06:49:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=174
06/12/2022 06:49:18 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=174
06/12/2022 06:49:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=177
06/12/2022 06:49:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=179
06/12/2022 06:49:31 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=182
06/12/2022 06:49:36 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=184
06/12/2022 06:49:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=187
06/12/2022 06:49:43 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=187
06/12/2022 06:49:48 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=189
06/12/2022 06:49:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=192
06/12/2022 06:49:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=194
06/12/2022 06:50:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.23 on epoch=197
06/12/2022 06:50:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.22 on epoch=199
06/12/2022 06:50:09 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=199
06/12/2022 06:50:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=202
06/12/2022 06:50:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=204
06/12/2022 06:50:22 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=207
06/12/2022 06:50:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=209
06/12/2022 06:50:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=212
06/12/2022 06:50:34 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=212
06/12/2022 06:50:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=214
06/12/2022 06:50:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=217
06/12/2022 06:50:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=219
06/12/2022 06:50:52 - INFO - __main__ - Step 890 Global step 890 Train loss 0.20 on epoch=222
06/12/2022 06:50:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=224
06/12/2022 06:50:59 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.2518518518518518 on epoch=224
06/12/2022 06:51:04 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=227
06/12/2022 06:51:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=229
06/12/2022 06:51:13 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=232
06/12/2022 06:51:18 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=234
06/12/2022 06:51:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=237
06/12/2022 06:51:25 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.42840679919331603 on epoch=237
06/12/2022 06:51:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.21 on epoch=239
06/12/2022 06:51:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=242
06/12/2022 06:51:39 - INFO - __main__ - Step 980 Global step 980 Train loss 0.19 on epoch=244
06/12/2022 06:51:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=247
06/12/2022 06:51:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.18 on epoch=249
06/12/2022 06:51:51 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.24776785714285715 on epoch=249
06/12/2022 06:51:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=252
06/12/2022 06:52:00 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.20 on epoch=254
06/12/2022 06:52:04 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=257
06/12/2022 06:52:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=259
06/12/2022 06:52:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.22 on epoch=262
06/12/2022 06:52:16 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.5270935960591133 on epoch=262
06/12/2022 06:52:16 - INFO - __main__ - Saving model with best Classification-F1: 0.47885474126608885 -> 0.5270935960591133 on epoch=262, global_step=1050
06/12/2022 06:52:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.21 on epoch=264
06/12/2022 06:52:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=267
06/12/2022 06:52:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=269
06/12/2022 06:52:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=272
06/12/2022 06:52:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.20 on epoch=274
06/12/2022 06:52:42 - INFO - __main__ - Global step 1100 Train loss 0.20 Classification-F1 0.2451063829787234 on epoch=274
06/12/2022 06:52:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=277
06/12/2022 06:52:51 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=279
06/12/2022 06:52:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.18 on epoch=282
06/12/2022 06:53:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=284
06/12/2022 06:53:04 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.16 on epoch=287
06/12/2022 06:53:07 - INFO - __main__ - Global step 1150 Train loss 0.19 Classification-F1 0.3868065967016492 on epoch=287
06/12/2022 06:53:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.17 on epoch=289
06/12/2022 06:53:16 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.19 on epoch=292
06/12/2022 06:53:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=294
06/12/2022 06:53:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=297
06/12/2022 06:53:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=299
06/12/2022 06:53:32 - INFO - __main__ - Global step 1200 Train loss 0.19 Classification-F1 0.3591989987484355 on epoch=299
06/12/2022 06:53:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=302
06/12/2022 06:53:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=304
06/12/2022 06:53:46 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.18 on epoch=307
06/12/2022 06:53:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=309
06/12/2022 06:53:55 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.20 on epoch=312
06/12/2022 06:53:58 - INFO - __main__ - Global step 1250 Train loss 0.19 Classification-F1 0.51417004048583 on epoch=312
06/12/2022 06:54:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=314
06/12/2022 06:54:07 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.17 on epoch=317
06/12/2022 06:54:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=319
06/12/2022 06:54:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.20 on epoch=322
06/12/2022 06:54:21 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=324
06/12/2022 06:54:24 - INFO - __main__ - Global step 1300 Train loss 0.18 Classification-F1 0.500880503144654 on epoch=324
06/12/2022 06:54:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.17 on epoch=327
06/12/2022 06:54:33 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=329
06/12/2022 06:54:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=332
06/12/2022 06:54:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.18 on epoch=334
06/12/2022 06:54:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=337
06/12/2022 06:54:49 - INFO - __main__ - Global step 1350 Train loss 0.16 Classification-F1 0.5 on epoch=337
06/12/2022 06:54:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=339
06/12/2022 06:54:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.16 on epoch=342
06/12/2022 06:55:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.14 on epoch=344
06/12/2022 06:55:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.17 on epoch=347
06/12/2022 06:55:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=349
06/12/2022 06:55:15 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.5273745861981156 on epoch=349
06/12/2022 06:55:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5270935960591133 -> 0.5273745861981156 on epoch=349, global_step=1400
06/12/2022 06:55:19 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.15 on epoch=352
06/12/2022 06:55:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.16 on epoch=354
06/12/2022 06:55:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=357
06/12/2022 06:55:33 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=359
06/12/2022 06:55:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.17 on epoch=362
06/12/2022 06:55:40 - INFO - __main__ - Global step 1450 Train loss 0.16 Classification-F1 0.44209215442092153 on epoch=362
06/12/2022 06:55:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=364
06/12/2022 06:55:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.14 on epoch=367
06/12/2022 06:55:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=369
06/12/2022 06:55:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=372
06/12/2022 06:56:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=374
06/12/2022 06:56:06 - INFO - __main__ - Global step 1500 Train loss 0.14 Classification-F1 0.4420512820512821 on epoch=374
06/12/2022 06:56:10 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.14 on epoch=377
06/12/2022 06:56:15 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=379
06/12/2022 06:56:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=382
06/12/2022 06:56:24 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.13 on epoch=384
06/12/2022 06:56:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=387
06/12/2022 06:56:31 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.464039408866995 on epoch=387
06/12/2022 06:56:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=389
06/12/2022 06:56:40 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=392
06/12/2022 06:56:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=394
06/12/2022 06:56:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
06/12/2022 06:56:54 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=399
06/12/2022 06:56:57 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.5515515515515517 on epoch=399
06/12/2022 06:56:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5273745861981156 -> 0.5515515515515517 on epoch=399, global_step=1600
06/12/2022 06:57:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=402
06/12/2022 06:57:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=404
06/12/2022 06:57:10 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=407
06/12/2022 06:57:15 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=409
06/12/2022 06:57:19 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=412
06/12/2022 06:57:22 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.5145583557621727 on epoch=412
06/12/2022 06:57:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/12/2022 06:57:31 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=417
06/12/2022 06:57:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/12/2022 06:57:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=422
06/12/2022 06:57:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=424
06/12/2022 06:57:48 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.341991341991342 on epoch=424
06/12/2022 06:57:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=427
06/12/2022 06:57:57 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=429
06/12/2022 06:58:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/12/2022 06:58:06 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=434
06/12/2022 06:58:10 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/12/2022 06:58:13 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.4519207242476144 on epoch=437
06/12/2022 06:58:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=439
06/12/2022 06:58:22 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=442
06/12/2022 06:58:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/12/2022 06:58:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/12/2022 06:58:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/12/2022 06:58:38 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.4295900178253119 on epoch=449
06/12/2022 06:58:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/12/2022 06:58:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/12/2022 06:58:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/12/2022 06:58:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/12/2022 06:59:01 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/12/2022 06:59:03 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.49556650246305417 on epoch=462
06/12/2022 06:59:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/12/2022 06:59:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=467
06/12/2022 06:59:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/12/2022 06:59:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=472
06/12/2022 06:59:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/12/2022 06:59:29 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.4458874458874459 on epoch=474
06/12/2022 06:59:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=477
06/12/2022 06:59:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/12/2022 06:59:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=482
06/12/2022 06:59:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/12/2022 06:59:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/12/2022 06:59:54 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.4285714285714286 on epoch=487
06/12/2022 06:59:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=489
06/12/2022 07:00:03 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/12/2022 07:00:07 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
06/12/2022 07:00:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=497
06/12/2022 07:00:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/12/2022 07:00:19 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.375 on epoch=499
06/12/2022 07:00:24 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=502
06/12/2022 07:00:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/12/2022 07:00:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/12/2022 07:00:37 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/12/2022 07:00:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/12/2022 07:00:45 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.4217338217338217 on epoch=512
06/12/2022 07:00:49 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/12/2022 07:00:54 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/12/2022 07:00:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/12/2022 07:01:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=522
06/12/2022 07:01:07 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/12/2022 07:01:10 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.4682306940371457 on epoch=524
06/12/2022 07:01:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/12/2022 07:01:19 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/12/2022 07:01:23 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/12/2022 07:01:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=534
06/12/2022 07:01:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/12/2022 07:01:35 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.5145583557621727 on epoch=537
06/12/2022 07:01:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/12/2022 07:01:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/12/2022 07:01:49 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=544
06/12/2022 07:01:53 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/12/2022 07:01:58 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/12/2022 07:02:00 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.464039408866995 on epoch=549
06/12/2022 07:02:05 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/12/2022 07:02:09 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/12/2022 07:02:14 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/12/2022 07:02:18 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/12/2022 07:02:23 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/12/2022 07:02:26 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.464039408866995 on epoch=562
06/12/2022 07:02:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/12/2022 07:02:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/12/2022 07:02:39 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/12/2022 07:02:44 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/12/2022 07:02:48 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/12/2022 07:02:51 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.46218487394957986 on epoch=574
06/12/2022 07:02:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=577
06/12/2022 07:03:00 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/12/2022 07:03:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/12/2022 07:03:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/12/2022 07:03:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/12/2022 07:03:16 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.4682306940371457 on epoch=587
06/12/2022 07:03:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/12/2022 07:03:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=592
06/12/2022 07:03:29 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/12/2022 07:03:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/12/2022 07:03:38 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/12/2022 07:03:41 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.41832473593711617 on epoch=599
06/12/2022 07:03:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/12/2022 07:03:50 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/12/2022 07:03:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/12/2022 07:03:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/12/2022 07:04:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/12/2022 07:04:06 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.436950146627566 on epoch=612
06/12/2022 07:04:11 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/12/2022 07:04:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/12/2022 07:04:20 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/12/2022 07:04:24 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/12/2022 07:04:29 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/12/2022 07:04:31 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.48424908424908425 on epoch=624
06/12/2022 07:04:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/12/2022 07:04:40 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/12/2022 07:04:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/12/2022 07:04:49 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/12/2022 07:04:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/12/2022 07:04:56 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.40625 on epoch=637
06/12/2022 07:05:01 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=639
06/12/2022 07:05:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/12/2022 07:05:10 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/12/2022 07:05:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/12/2022 07:05:19 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/12/2022 07:05:22 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.436950146627566 on epoch=649
06/12/2022 07:05:26 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/12/2022 07:05:31 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/12/2022 07:05:35 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/12/2022 07:05:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/12/2022 07:05:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/12/2022 07:05:47 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.436950146627566 on epoch=662
06/12/2022 07:05:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/12/2022 07:05:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/12/2022 07:06:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/12/2022 07:06:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/12/2022 07:06:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/12/2022 07:06:12 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.4285714285714286 on epoch=674
06/12/2022 07:06:17 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=677
06/12/2022 07:06:22 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/12/2022 07:06:26 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/12/2022 07:06:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/12/2022 07:06:35 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/12/2022 07:06:38 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.4009852216748768 on epoch=687
06/12/2022 07:06:42 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/12/2022 07:06:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/12/2022 07:06:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/12/2022 07:06:56 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/12/2022 07:07:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/12/2022 07:07:04 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.44976664210267747 on epoch=699
06/12/2022 07:07:08 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/12/2022 07:07:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/12/2022 07:07:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/12/2022 07:07:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/12/2022 07:07:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/12/2022 07:07:29 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.464039408866995 on epoch=712
06/12/2022 07:07:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/12/2022 07:07:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/12/2022 07:07:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=719
06/12/2022 07:07:47 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/12/2022 07:07:52 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/12/2022 07:07:54 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.4519207242476144 on epoch=724
06/12/2022 07:07:59 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/12/2022 07:08:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/12/2022 07:08:08 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/12/2022 07:08:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/12/2022 07:08:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/12/2022 07:08:19 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.43529411764705883 on epoch=737
06/12/2022 07:08:24 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/12/2022 07:08:28 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/12/2022 07:08:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/12/2022 07:08:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/12/2022 07:08:42 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/12/2022 07:08:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 07:08:43 - INFO - __main__ - Printing 3 examples
06/12/2022 07:08:43 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/12/2022 07:08:43 - INFO - __main__ - ['entailed']
06/12/2022 07:08:43 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/12/2022 07:08:43 - INFO - __main__ - ['entailed']
06/12/2022 07:08:43 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/12/2022 07:08:43 - INFO - __main__ - ['entailed']
06/12/2022 07:08:43 - INFO - __main__ - Tokenizing Input ...
06/12/2022 07:08:44 - INFO - __main__ - Tokenizing Output ...
06/12/2022 07:08:44 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 07:08:44 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 07:08:44 - INFO - __main__ - Printing 3 examples
06/12/2022 07:08:44 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/12/2022 07:08:44 - INFO - __main__ - ['entailed']
06/12/2022 07:08:44 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/12/2022 07:08:44 - INFO - __main__ - ['entailed']
06/12/2022 07:08:44 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/12/2022 07:08:44 - INFO - __main__ - ['entailed']
06/12/2022 07:08:44 - INFO - __main__ - Tokenizing Input ...
06/12/2022 07:08:44 - INFO - __main__ - Tokenizing Output ...
06/12/2022 07:08:44 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 07:08:45 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.46666666666666656 on epoch=749
06/12/2022 07:08:45 - INFO - __main__ - save last model!
06/12/2022 07:08:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 07:08:45 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 07:08:45 - INFO - __main__ - Printing 3 examples
06/12/2022 07:08:45 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 07:08:45 - INFO - __main__ - ['entailed']
06/12/2022 07:08:45 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 07:08:45 - INFO - __main__ - ['entailed']
06/12/2022 07:08:45 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 07:08:45 - INFO - __main__ - ['entailed']
06/12/2022 07:08:45 - INFO - __main__ - Tokenizing Input ...
06/12/2022 07:09:03 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 07:09:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 07:09:03 - INFO - __main__ - Starting training!
06/12/2022 07:09:11 - INFO - __main__ - Tokenizing Output ...
06/12/2022 07:09:24 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 07:17:59 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_87_0.5_8_predictions.txt
06/12/2022 07:17:59 - INFO - __main__ - Classification-F1 on test data: 0.4988
06/12/2022 07:18:00 - INFO - __main__ - prefix=tab_fact_32_87, lr=0.5, bsz=8, dev_performance=0.5515515515515517, test_performance=0.4988473889381382
06/12/2022 07:18:00 - INFO - __main__ - Running ... prefix=tab_fact_32_87, lr=0.4, bsz=8 ...
06/12/2022 07:18:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 07:18:01 - INFO - __main__ - Printing 3 examples
06/12/2022 07:18:01 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/12/2022 07:18:01 - INFO - __main__ - ['entailed']
06/12/2022 07:18:01 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/12/2022 07:18:01 - INFO - __main__ - ['entailed']
06/12/2022 07:18:01 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/12/2022 07:18:01 - INFO - __main__ - ['entailed']
06/12/2022 07:18:01 - INFO - __main__ - Tokenizing Input ...
06/12/2022 07:18:01 - INFO - __main__ - Tokenizing Output ...
06/12/2022 07:18:01 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 07:18:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 07:18:01 - INFO - __main__ - Printing 3 examples
06/12/2022 07:18:01 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/12/2022 07:18:01 - INFO - __main__ - ['entailed']
06/12/2022 07:18:01 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/12/2022 07:18:01 - INFO - __main__ - ['entailed']
06/12/2022 07:18:01 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/12/2022 07:18:01 - INFO - __main__ - ['entailed']
06/12/2022 07:18:01 - INFO - __main__ - Tokenizing Input ...
06/12/2022 07:18:01 - INFO - __main__ - Tokenizing Output ...
06/12/2022 07:18:01 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 07:18:16 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 07:18:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 07:18:17 - INFO - __main__ - Starting training!
06/12/2022 07:18:22 - INFO - __main__ - Step 10 Global step 10 Train loss 2.72 on epoch=2
06/12/2022 07:18:26 - INFO - __main__ - Step 20 Global step 20 Train loss 0.50 on epoch=4
06/12/2022 07:18:31 - INFO - __main__ - Step 30 Global step 30 Train loss 0.39 on epoch=7
06/12/2022 07:18:35 - INFO - __main__ - Step 40 Global step 40 Train loss 0.36 on epoch=9
06/12/2022 07:18:40 - INFO - __main__ - Step 50 Global step 50 Train loss 0.32 on epoch=12
06/12/2022 07:18:42 - INFO - __main__ - Global step 50 Train loss 0.86 Classification-F1 0.3333333333333333 on epoch=12
06/12/2022 07:18:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/12/2022 07:18:47 - INFO - __main__ - Step 60 Global step 60 Train loss 0.29 on epoch=14
06/12/2022 07:18:52 - INFO - __main__ - Step 70 Global step 70 Train loss 0.28 on epoch=17
06/12/2022 07:18:56 - INFO - __main__ - Step 80 Global step 80 Train loss 0.26 on epoch=19
06/12/2022 07:19:01 - INFO - __main__ - Step 90 Global step 90 Train loss 0.25 on epoch=22
06/12/2022 07:19:05 - INFO - __main__ - Step 100 Global step 100 Train loss 0.22 on epoch=24
06/12/2022 07:19:08 - INFO - __main__ - Global step 100 Train loss 0.26 Classification-F1 0.44379029997196523 on epoch=24
06/12/2022 07:19:08 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.44379029997196523 on epoch=24, global_step=100
06/12/2022 07:19:12 - INFO - __main__ - Step 110 Global step 110 Train loss 0.25 on epoch=27
06/12/2022 07:19:17 - INFO - __main__ - Step 120 Global step 120 Train loss 0.22 on epoch=29
06/12/2022 07:19:21 - INFO - __main__ - Step 130 Global step 130 Train loss 0.24 on epoch=32
06/12/2022 07:19:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.23 on epoch=34
06/12/2022 07:19:30 - INFO - __main__ - Step 150 Global step 150 Train loss 0.26 on epoch=37
06/12/2022 07:19:33 - INFO - __main__ - Global step 150 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=37
06/12/2022 07:19:38 - INFO - __main__ - Step 160 Global step 160 Train loss 0.24 on epoch=39
06/12/2022 07:19:42 - INFO - __main__ - Step 170 Global step 170 Train loss 0.20 on epoch=42
06/12/2022 07:19:47 - INFO - __main__ - Step 180 Global step 180 Train loss 0.19 on epoch=44
06/12/2022 07:19:52 - INFO - __main__ - Step 190 Global step 190 Train loss 0.26 on epoch=47
06/12/2022 07:19:56 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=49
06/12/2022 07:19:59 - INFO - __main__ - Global step 200 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=49
06/12/2022 07:20:04 - INFO - __main__ - Step 210 Global step 210 Train loss 0.23 on epoch=52
06/12/2022 07:20:08 - INFO - __main__ - Step 220 Global step 220 Train loss 0.22 on epoch=54
06/12/2022 07:20:13 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=57
06/12/2022 07:20:17 - INFO - __main__ - Step 240 Global step 240 Train loss 2.37 on epoch=59
06/12/2022 07:20:22 - INFO - __main__ - Step 250 Global step 250 Train loss 2.87 on epoch=62
06/12/2022 07:20:25 - INFO - __main__ - Global step 250 Train loss 1.26 Classification-F1 0.3333333333333333 on epoch=62
06/12/2022 07:20:29 - INFO - __main__ - Step 260 Global step 260 Train loss 0.43 on epoch=64
06/12/2022 07:20:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.46 on epoch=67
06/12/2022 07:20:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.93 on epoch=69
06/12/2022 07:20:43 - INFO - __main__ - Step 290 Global step 290 Train loss 1.36 on epoch=72
06/12/2022 07:20:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.45 on epoch=74
06/12/2022 07:20:50 - INFO - __main__ - Global step 300 Train loss 0.73 Classification-F1 0.21739130434782608 on epoch=74
06/12/2022 07:20:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=77
06/12/2022 07:20:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.32 on epoch=79
06/12/2022 07:21:04 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=82
06/12/2022 07:21:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.35 on epoch=84
06/12/2022 07:21:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.33 on epoch=87
06/12/2022 07:21:15 - INFO - __main__ - Global step 350 Train loss 0.36 Classification-F1 0.3333333333333333 on epoch=87
06/12/2022 07:21:20 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=89
06/12/2022 07:21:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.34 on epoch=92
06/12/2022 07:21:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=94
06/12/2022 07:21:34 - INFO - __main__ - Step 390 Global step 390 Train loss 0.27 on epoch=97
06/12/2022 07:21:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=99
06/12/2022 07:21:41 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.3333333333333333 on epoch=99
06/12/2022 07:21:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.32 on epoch=102
06/12/2022 07:21:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=104
06/12/2022 07:21:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=107
06/12/2022 07:21:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.26 on epoch=109
06/12/2022 07:22:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=112
06/12/2022 07:22:06 - INFO - __main__ - Global step 450 Train loss 0.28 Classification-F1 0.3333333333333333 on epoch=112
06/12/2022 07:22:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=114
06/12/2022 07:22:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=117
06/12/2022 07:22:19 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=119
06/12/2022 07:22:24 - INFO - __main__ - Step 490 Global step 490 Train loss 0.27 on epoch=122
06/12/2022 07:22:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=124
06/12/2022 07:22:31 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=124
06/12/2022 07:22:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=127
06/12/2022 07:22:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=129
06/12/2022 07:22:45 - INFO - __main__ - Step 530 Global step 530 Train loss 0.25 on epoch=132
06/12/2022 07:22:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=134
06/12/2022 07:22:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=137
06/12/2022 07:22:56 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=137
06/12/2022 07:23:01 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=139
06/12/2022 07:23:05 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=142
06/12/2022 07:23:10 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=144
06/12/2022 07:23:14 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=147
06/12/2022 07:23:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=149
06/12/2022 07:23:21 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=149
06/12/2022 07:23:26 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=152
06/12/2022 07:23:30 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/12/2022 07:23:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=157
06/12/2022 07:23:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=159
06/12/2022 07:23:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=162
06/12/2022 07:23:46 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=162
06/12/2022 07:23:51 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=164
06/12/2022 07:23:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=167
06/12/2022 07:24:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.25 on epoch=169
06/12/2022 07:24:04 - INFO - __main__ - Step 690 Global step 690 Train loss 0.25 on epoch=172
06/12/2022 07:24:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=174
06/12/2022 07:24:11 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=174
06/12/2022 07:24:16 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=177
06/12/2022 07:24:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=179
06/12/2022 07:24:25 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=182
06/12/2022 07:24:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.24 on epoch=184
06/12/2022 07:24:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.24 on epoch=187
06/12/2022 07:24:37 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=187
06/12/2022 07:24:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=189
06/12/2022 07:24:46 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=192
06/12/2022 07:24:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=194
06/12/2022 07:24:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=197
06/12/2022 07:24:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=199
06/12/2022 07:25:02 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=199
06/12/2022 07:25:06 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=202
06/12/2022 07:25:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.24 on epoch=204
06/12/2022 07:25:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=207
06/12/2022 07:25:20 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=209
06/12/2022 07:25:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.24 on epoch=212
06/12/2022 07:25:27 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=212
06/12/2022 07:25:32 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=214
06/12/2022 07:25:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=217
06/12/2022 07:25:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=219
06/12/2022 07:25:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.26 on epoch=222
06/12/2022 07:25:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=224
06/12/2022 07:25:53 - INFO - __main__ - Global step 900 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=224
06/12/2022 07:25:57 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=227
06/12/2022 07:26:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=229
06/12/2022 07:26:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.24 on epoch=232
06/12/2022 07:26:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.22 on epoch=234
06/12/2022 07:26:15 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=237
06/12/2022 07:26:18 - INFO - __main__ - Global step 950 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=237
06/12/2022 07:26:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=239
06/12/2022 07:26:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=242
06/12/2022 07:26:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.23 on epoch=244
06/12/2022 07:26:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.23 on epoch=247
06/12/2022 07:26:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.25 on epoch=249
06/12/2022 07:26:43 - INFO - __main__ - Global step 1000 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=249
06/12/2022 07:26:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=252
06/12/2022 07:26:52 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.23 on epoch=254
06/12/2022 07:26:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.24 on epoch=257
06/12/2022 07:27:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.23 on epoch=259
06/12/2022 07:27:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=262
06/12/2022 07:27:08 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=262
06/12/2022 07:27:13 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.21 on epoch=264
06/12/2022 07:27:17 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.24 on epoch=267
06/12/2022 07:27:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.21 on epoch=269
06/12/2022 07:27:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.25 on epoch=272
06/12/2022 07:27:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.24 on epoch=274
06/12/2022 07:27:33 - INFO - __main__ - Global step 1100 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=274
06/12/2022 07:27:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.19 on epoch=277
06/12/2022 07:27:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=279
06/12/2022 07:27:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.23 on epoch=282
06/12/2022 07:27:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.20 on epoch=284
06/12/2022 07:27:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.21 on epoch=287
06/12/2022 07:27:58 - INFO - __main__ - Global step 1150 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=287
06/12/2022 07:28:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.21 on epoch=289
06/12/2022 07:28:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.20 on epoch=292
06/12/2022 07:28:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.21 on epoch=294
06/12/2022 07:28:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=297
06/12/2022 07:28:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.21 on epoch=299
06/12/2022 07:28:23 - INFO - __main__ - Global step 1200 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=299
06/12/2022 07:28:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.23 on epoch=302
06/12/2022 07:28:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.22 on epoch=304
06/12/2022 07:28:37 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.22 on epoch=307
06/12/2022 07:28:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.19 on epoch=309
06/12/2022 07:28:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.24 on epoch=312
06/12/2022 07:28:48 - INFO - __main__ - Global step 1250 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=312
06/12/2022 07:28:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.22 on epoch=314
06/12/2022 07:28:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.23 on epoch=317
06/12/2022 07:29:02 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.23 on epoch=319
06/12/2022 07:29:06 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.24 on epoch=322
06/12/2022 07:29:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.22 on epoch=324
06/12/2022 07:29:13 - INFO - __main__ - Global step 1300 Train loss 0.23 Classification-F1 0.272609819121447 on epoch=324
06/12/2022 07:29:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.21 on epoch=327
06/12/2022 07:29:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.19 on epoch=329
06/12/2022 07:29:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.21 on epoch=332
06/12/2022 07:29:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.21 on epoch=334
06/12/2022 07:29:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.21 on epoch=337
06/12/2022 07:29:38 - INFO - __main__ - Global step 1350 Train loss 0.21 Classification-F1 0.2762762762762763 on epoch=337
06/12/2022 07:29:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.19 on epoch=339
06/12/2022 07:29:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.19 on epoch=342
06/12/2022 07:29:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=344
06/12/2022 07:29:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.24 on epoch=347
06/12/2022 07:30:00 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.20 on epoch=349
06/12/2022 07:30:03 - INFO - __main__ - Global step 1400 Train loss 0.20 Classification-F1 0.21739130434782608 on epoch=349
06/12/2022 07:30:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.19 on epoch=352
06/12/2022 07:30:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.22 on epoch=354
06/12/2022 07:30:16 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.22 on epoch=357
06/12/2022 07:30:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.18 on epoch=359
06/12/2022 07:30:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.21 on epoch=362
06/12/2022 07:30:28 - INFO - __main__ - Global step 1450 Train loss 0.20 Classification-F1 0.31851851851851853 on epoch=362
06/12/2022 07:30:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.19 on epoch=364
06/12/2022 07:30:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.20 on epoch=367
06/12/2022 07:30:41 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.21 on epoch=369
06/12/2022 07:30:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.21 on epoch=372
06/12/2022 07:30:50 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.19 on epoch=374
06/12/2022 07:30:53 - INFO - __main__ - Global step 1500 Train loss 0.20 Classification-F1 0.4920634920634921 on epoch=374
06/12/2022 07:30:53 - INFO - __main__ - Saving model with best Classification-F1: 0.44379029997196523 -> 0.4920634920634921 on epoch=374, global_step=1500
06/12/2022 07:30:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.23 on epoch=377
06/12/2022 07:31:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.18 on epoch=379
06/12/2022 07:31:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=382
06/12/2022 07:31:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.22 on epoch=384
06/12/2022 07:31:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.22 on epoch=387
06/12/2022 07:31:18 - INFO - __main__ - Global step 1550 Train loss 0.21 Classification-F1 0.3915298184961106 on epoch=387
06/12/2022 07:31:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.22 on epoch=389
06/12/2022 07:31:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.23 on epoch=392
06/12/2022 07:31:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.20 on epoch=394
06/12/2022 07:31:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.21 on epoch=397
06/12/2022 07:31:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.18 on epoch=399
06/12/2022 07:31:43 - INFO - __main__ - Global step 1600 Train loss 0.21 Classification-F1 0.39047619047619053 on epoch=399
06/12/2022 07:31:47 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.21 on epoch=402
06/12/2022 07:31:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.20 on epoch=404
06/12/2022 07:31:56 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.21 on epoch=407
06/12/2022 07:32:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.18 on epoch=409
06/12/2022 07:32:05 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.21 on epoch=412
06/12/2022 07:32:08 - INFO - __main__ - Global step 1650 Train loss 0.20 Classification-F1 0.5058530510585305 on epoch=412
06/12/2022 07:32:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4920634920634921 -> 0.5058530510585305 on epoch=412, global_step=1650
06/12/2022 07:32:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.21 on epoch=414
06/12/2022 07:32:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.22 on epoch=417
06/12/2022 07:32:21 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.18 on epoch=419
06/12/2022 07:32:26 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.21 on epoch=422
06/12/2022 07:32:30 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.20 on epoch=424
06/12/2022 07:32:33 - INFO - __main__ - Global step 1700 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=424
06/12/2022 07:32:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.19 on epoch=427
06/12/2022 07:32:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.21 on epoch=429
06/12/2022 07:32:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.20 on epoch=432
06/12/2022 07:32:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.22 on epoch=434
06/12/2022 07:32:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.22 on epoch=437
06/12/2022 07:32:58 - INFO - __main__ - Global step 1750 Train loss 0.21 Classification-F1 0.4920634920634921 on epoch=437
06/12/2022 07:33:02 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.20 on epoch=439
06/12/2022 07:33:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.19 on epoch=442
06/12/2022 07:33:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.19 on epoch=444
06/12/2022 07:33:16 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.26 on epoch=447
06/12/2022 07:33:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.27 on epoch=449
06/12/2022 07:33:23 - INFO - __main__ - Global step 1800 Train loss 0.22 Classification-F1 0.30229120473022913 on epoch=449
06/12/2022 07:33:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.23 on epoch=452
06/12/2022 07:33:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.23 on epoch=454
06/12/2022 07:33:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.23 on epoch=457
06/12/2022 07:33:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.19 on epoch=459
06/12/2022 07:33:45 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.21 on epoch=462
06/12/2022 07:33:48 - INFO - __main__ - Global step 1850 Train loss 0.22 Classification-F1 0.5097603162836669 on epoch=462
06/12/2022 07:33:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5058530510585305 -> 0.5097603162836669 on epoch=462, global_step=1850
06/12/2022 07:33:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.21 on epoch=464
06/12/2022 07:33:57 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.21 on epoch=467
06/12/2022 07:34:01 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.21 on epoch=469
06/12/2022 07:34:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.20 on epoch=472
06/12/2022 07:34:10 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.20 on epoch=474
06/12/2022 07:34:13 - INFO - __main__ - Global step 1900 Train loss 0.21 Classification-F1 0.5607843137254902 on epoch=474
06/12/2022 07:34:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5097603162836669 -> 0.5607843137254902 on epoch=474, global_step=1900
06/12/2022 07:34:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.22 on epoch=477
06/12/2022 07:34:22 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.21 on epoch=479
06/12/2022 07:34:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.20 on epoch=482
06/12/2022 07:34:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.22 on epoch=484
06/12/2022 07:34:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.20 on epoch=487
06/12/2022 07:34:38 - INFO - __main__ - Global step 1950 Train loss 0.21 Classification-F1 0.5780219780219781 on epoch=487
06/12/2022 07:34:38 - INFO - __main__ - Saving model with best Classification-F1: 0.5607843137254902 -> 0.5780219780219781 on epoch=487, global_step=1950
06/12/2022 07:34:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.21 on epoch=489
06/12/2022 07:34:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.22 on epoch=492
06/12/2022 07:34:51 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.18 on epoch=494
06/12/2022 07:34:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.21 on epoch=497
06/12/2022 07:35:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.20 on epoch=499
06/12/2022 07:35:03 - INFO - __main__ - Global step 2000 Train loss 0.21 Classification-F1 0.5440923605993613 on epoch=499
06/12/2022 07:35:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.21 on epoch=502
06/12/2022 07:35:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.21 on epoch=504
06/12/2022 07:35:16 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.16 on epoch=507
06/12/2022 07:35:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.19 on epoch=509
06/12/2022 07:35:25 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.20 on epoch=512
06/12/2022 07:35:28 - INFO - __main__ - Global step 2050 Train loss 0.19 Classification-F1 0.5238095238095238 on epoch=512
06/12/2022 07:35:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.18 on epoch=514
06/12/2022 07:35:37 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.21 on epoch=517
06/12/2022 07:35:41 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.21 on epoch=519
06/12/2022 07:35:45 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.21 on epoch=522
06/12/2022 07:35:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.18 on epoch=524
06/12/2022 07:35:53 - INFO - __main__ - Global step 2100 Train loss 0.20 Classification-F1 0.4181818181818182 on epoch=524
06/12/2022 07:35:57 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.23 on epoch=527
06/12/2022 07:36:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.18 on epoch=529
06/12/2022 07:36:06 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.18 on epoch=532
06/12/2022 07:36:10 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.21 on epoch=534
06/12/2022 07:36:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.20 on epoch=537
06/12/2022 07:36:17 - INFO - __main__ - Global step 2150 Train loss 0.20 Classification-F1 0.4920634920634921 on epoch=537
06/12/2022 07:36:22 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.21 on epoch=539
06/12/2022 07:36:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.21 on epoch=542
06/12/2022 07:36:31 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.19 on epoch=544
06/12/2022 07:36:35 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.18 on epoch=547
06/12/2022 07:36:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.21 on epoch=549
06/12/2022 07:36:42 - INFO - __main__ - Global step 2200 Train loss 0.20 Classification-F1 0.08888888888888888 on epoch=549
06/12/2022 07:36:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.18 on epoch=552
06/12/2022 07:36:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.21 on epoch=554
06/12/2022 07:36:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.19 on epoch=557
06/12/2022 07:37:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.20 on epoch=559
06/12/2022 07:37:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.19 on epoch=562
06/12/2022 07:37:07 - INFO - __main__ - Global step 2250 Train loss 0.19 Classification-F1 0.5620723362658846 on epoch=562
06/12/2022 07:37:11 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.18 on epoch=564
06/12/2022 07:37:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.19 on epoch=567
06/12/2022 07:37:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.21 on epoch=569
06/12/2022 07:37:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.21 on epoch=572
06/12/2022 07:37:29 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.20 on epoch=574
06/12/2022 07:37:32 - INFO - __main__ - Global step 2300 Train loss 0.20 Classification-F1 0.5307917888563051 on epoch=574
06/12/2022 07:37:36 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.20 on epoch=577
06/12/2022 07:37:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.21 on epoch=579
06/12/2022 07:37:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.20 on epoch=582
06/12/2022 07:37:49 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.17 on epoch=584
06/12/2022 07:37:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.20 on epoch=587
06/12/2022 07:37:56 - INFO - __main__ - Global step 2350 Train loss 0.20 Classification-F1 0.21403508771929824 on epoch=587
06/12/2022 07:38:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.18 on epoch=589
06/12/2022 07:38:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.17 on epoch=592
06/12/2022 07:38:10 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.21 on epoch=594
06/12/2022 07:38:14 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.18 on epoch=597
06/12/2022 07:38:18 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.19 on epoch=599
06/12/2022 07:38:21 - INFO - __main__ - Global step 2400 Train loss 0.19 Classification-F1 0.41075141075141075 on epoch=599
06/12/2022 07:38:26 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.21 on epoch=602
06/12/2022 07:38:30 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.17 on epoch=604
06/12/2022 07:38:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.19 on epoch=607
06/12/2022 07:38:39 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.19 on epoch=609
06/12/2022 07:38:43 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.18 on epoch=612
06/12/2022 07:38:46 - INFO - __main__ - Global step 2450 Train loss 0.19 Classification-F1 0.4817813765182186 on epoch=612
06/12/2022 07:38:51 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.15 on epoch=614
06/12/2022 07:38:55 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.22 on epoch=617
06/12/2022 07:38:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.16 on epoch=619
06/12/2022 07:39:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.19 on epoch=622
06/12/2022 07:39:08 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.17 on epoch=624
06/12/2022 07:39:11 - INFO - __main__ - Global step 2500 Train loss 0.18 Classification-F1 0.5413886829750433 on epoch=624
06/12/2022 07:39:15 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.18 on epoch=627
06/12/2022 07:39:20 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.17 on epoch=629
06/12/2022 07:39:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.20 on epoch=632
06/12/2022 07:39:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.20 on epoch=634
06/12/2022 07:39:33 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.17 on epoch=637
06/12/2022 07:39:35 - INFO - __main__ - Global step 2550 Train loss 0.18 Classification-F1 0.5607843137254902 on epoch=637
06/12/2022 07:39:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.18 on epoch=639
06/12/2022 07:39:44 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.20 on epoch=642
06/12/2022 07:39:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.19 on epoch=644
06/12/2022 07:39:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.16 on epoch=647
06/12/2022 07:39:57 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.16 on epoch=649
06/12/2022 07:40:00 - INFO - __main__ - Global step 2600 Train loss 0.18 Classification-F1 0.4458874458874459 on epoch=649
06/12/2022 07:40:04 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.19 on epoch=652
06/12/2022 07:40:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.16 on epoch=654
06/12/2022 07:40:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.18 on epoch=657
06/12/2022 07:40:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.18 on epoch=659
06/12/2022 07:40:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.15 on epoch=662
06/12/2022 07:40:25 - INFO - __main__ - Global step 2650 Train loss 0.17 Classification-F1 0.46867924528301885 on epoch=662
06/12/2022 07:40:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.17 on epoch=664
06/12/2022 07:40:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.17 on epoch=667
06/12/2022 07:40:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.16 on epoch=669
06/12/2022 07:40:42 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.16 on epoch=672
06/12/2022 07:40:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.18 on epoch=674
06/12/2022 07:40:50 - INFO - __main__ - Global step 2700 Train loss 0.17 Classification-F1 0.5273745861981156 on epoch=674
06/12/2022 07:40:54 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.17 on epoch=677
06/12/2022 07:40:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.15 on epoch=679
06/12/2022 07:41:03 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.16 on epoch=682
06/12/2022 07:41:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.14 on epoch=684
06/12/2022 07:41:12 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.17 on epoch=687
06/12/2022 07:41:14 - INFO - __main__ - Global step 2750 Train loss 0.16 Classification-F1 0.5405128205128205 on epoch=687
06/12/2022 07:41:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.19 on epoch=689
06/12/2022 07:41:23 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.18 on epoch=692
06/12/2022 07:41:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.20 on epoch=694
06/12/2022 07:41:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.14 on epoch=697
06/12/2022 07:41:37 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.15 on epoch=699
06/12/2022 07:41:39 - INFO - __main__ - Global step 2800 Train loss 0.17 Classification-F1 0.537733499377335 on epoch=699
06/12/2022 07:41:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.14 on epoch=702
06/12/2022 07:41:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.17 on epoch=704
06/12/2022 07:41:52 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.15 on epoch=707
06/12/2022 07:41:57 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.17 on epoch=709
06/12/2022 07:42:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.14 on epoch=712
06/12/2022 07:42:04 - INFO - __main__ - Global step 2850 Train loss 0.15 Classification-F1 0.5866701110824076 on epoch=712
06/12/2022 07:42:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5780219780219781 -> 0.5866701110824076 on epoch=712, global_step=2850
06/12/2022 07:42:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.14 on epoch=714
06/12/2022 07:42:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.13 on epoch=717
06/12/2022 07:42:17 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.21 on epoch=719
06/12/2022 07:42:22 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.13 on epoch=722
06/12/2022 07:42:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.13 on epoch=724
06/12/2022 07:42:29 - INFO - __main__ - Global step 2900 Train loss 0.15 Classification-F1 0.3818181818181818 on epoch=724
06/12/2022 07:42:34 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.12 on epoch=727
06/12/2022 07:42:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.12 on epoch=729
06/12/2022 07:42:42 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.15 on epoch=732
06/12/2022 07:42:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.13 on epoch=734
06/12/2022 07:42:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.13 on epoch=737
06/12/2022 07:42:54 - INFO - __main__ - Global step 2950 Train loss 0.13 Classification-F1 0.5835835835835835 on epoch=737
06/12/2022 07:42:58 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.11 on epoch=739
06/12/2022 07:43:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.12 on epoch=742
06/12/2022 07:43:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.17 on epoch=744
06/12/2022 07:43:11 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.13 on epoch=747
06/12/2022 07:43:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.14 on epoch=749
06/12/2022 07:43:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 07:43:17 - INFO - __main__ - Printing 3 examples
06/12/2022 07:43:17 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/12/2022 07:43:17 - INFO - __main__ - ['entailed']
06/12/2022 07:43:17 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/12/2022 07:43:17 - INFO - __main__ - ['entailed']
06/12/2022 07:43:17 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/12/2022 07:43:17 - INFO - __main__ - ['entailed']
06/12/2022 07:43:17 - INFO - __main__ - Tokenizing Input ...
06/12/2022 07:43:17 - INFO - __main__ - Tokenizing Output ...
06/12/2022 07:43:17 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 07:43:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 07:43:17 - INFO - __main__ - Printing 3 examples
06/12/2022 07:43:17 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/12/2022 07:43:17 - INFO - __main__ - ['entailed']
06/12/2022 07:43:17 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/12/2022 07:43:17 - INFO - __main__ - ['entailed']
06/12/2022 07:43:17 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/12/2022 07:43:17 - INFO - __main__ - ['entailed']
06/12/2022 07:43:17 - INFO - __main__ - Tokenizing Input ...
06/12/2022 07:43:17 - INFO - __main__ - Tokenizing Output ...
06/12/2022 07:43:18 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 07:43:18 - INFO - __main__ - Global step 3000 Train loss 0.13 Classification-F1 0.5866701110824076 on epoch=749
06/12/2022 07:43:18 - INFO - __main__ - save last model!
06/12/2022 07:43:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 07:43:18 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 07:43:18 - INFO - __main__ - Printing 3 examples
06/12/2022 07:43:18 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 07:43:18 - INFO - __main__ - ['entailed']
06/12/2022 07:43:18 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 07:43:18 - INFO - __main__ - ['entailed']
06/12/2022 07:43:18 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 07:43:18 - INFO - __main__ - ['entailed']
06/12/2022 07:43:18 - INFO - __main__ - Tokenizing Input ...
06/12/2022 07:43:33 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 07:43:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 07:43:34 - INFO - __main__ - Starting training!
06/12/2022 07:43:43 - INFO - __main__ - Tokenizing Output ...
06/12/2022 07:43:56 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 07:52:04 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_87_0.4_8_predictions.txt
06/12/2022 07:52:04 - INFO - __main__ - Classification-F1 on test data: 0.4761
06/12/2022 07:52:04 - INFO - __main__ - prefix=tab_fact_32_87, lr=0.4, bsz=8, dev_performance=0.5866701110824076, test_performance=0.4760887805630837
06/12/2022 07:52:04 - INFO - __main__ - Running ... prefix=tab_fact_32_87, lr=0.3, bsz=8 ...
06/12/2022 07:52:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 07:52:05 - INFO - __main__ - Printing 3 examples
06/12/2022 07:52:05 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/12/2022 07:52:05 - INFO - __main__ - ['entailed']
06/12/2022 07:52:05 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/12/2022 07:52:05 - INFO - __main__ - ['entailed']
06/12/2022 07:52:05 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/12/2022 07:52:05 - INFO - __main__ - ['entailed']
06/12/2022 07:52:05 - INFO - __main__ - Tokenizing Input ...
06/12/2022 07:52:06 - INFO - __main__ - Tokenizing Output ...
06/12/2022 07:52:06 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 07:52:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 07:52:06 - INFO - __main__ - Printing 3 examples
06/12/2022 07:52:06 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/12/2022 07:52:06 - INFO - __main__ - ['entailed']
06/12/2022 07:52:06 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/12/2022 07:52:06 - INFO - __main__ - ['entailed']
06/12/2022 07:52:06 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/12/2022 07:52:06 - INFO - __main__ - ['entailed']
06/12/2022 07:52:06 - INFO - __main__ - Tokenizing Input ...
06/12/2022 07:52:06 - INFO - __main__ - Tokenizing Output ...
06/12/2022 07:52:06 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 07:52:22 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 07:52:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 07:52:23 - INFO - __main__ - Starting training!
06/12/2022 07:52:28 - INFO - __main__ - Step 10 Global step 10 Train loss 3.48 on epoch=2
06/12/2022 07:52:33 - INFO - __main__ - Step 20 Global step 20 Train loss 0.83 on epoch=4
06/12/2022 07:52:37 - INFO - __main__ - Step 30 Global step 30 Train loss 0.45 on epoch=7
06/12/2022 07:52:42 - INFO - __main__ - Step 40 Global step 40 Train loss 0.38 on epoch=9
06/12/2022 07:52:46 - INFO - __main__ - Step 50 Global step 50 Train loss 0.31 on epoch=12
06/12/2022 07:52:48 - INFO - __main__ - Global step 50 Train loss 1.09 Classification-F1 0.3333333333333333 on epoch=12
06/12/2022 07:52:49 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/12/2022 07:52:53 - INFO - __main__ - Step 60 Global step 60 Train loss 0.30 on epoch=14
06/12/2022 07:52:57 - INFO - __main__ - Step 70 Global step 70 Train loss 0.35 on epoch=17
06/12/2022 07:53:02 - INFO - __main__ - Step 80 Global step 80 Train loss 0.31 on epoch=19
06/12/2022 07:53:06 - INFO - __main__ - Step 90 Global step 90 Train loss 0.28 on epoch=22
06/12/2022 07:53:11 - INFO - __main__ - Step 100 Global step 100 Train loss 0.28 on epoch=24
06/12/2022 07:53:13 - INFO - __main__ - Global step 100 Train loss 0.30 Classification-F1 0.3333333333333333 on epoch=24
06/12/2022 07:53:18 - INFO - __main__ - Step 110 Global step 110 Train loss 0.25 on epoch=27
06/12/2022 07:53:22 - INFO - __main__ - Step 120 Global step 120 Train loss 0.25 on epoch=29
06/12/2022 07:53:26 - INFO - __main__ - Step 130 Global step 130 Train loss 0.21 on epoch=32
06/12/2022 07:53:31 - INFO - __main__ - Step 140 Global step 140 Train loss 0.25 on epoch=34
06/12/2022 07:53:35 - INFO - __main__ - Step 150 Global step 150 Train loss 0.25 on epoch=37
06/12/2022 07:53:38 - INFO - __main__ - Global step 150 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=37
06/12/2022 07:53:42 - INFO - __main__ - Step 160 Global step 160 Train loss 0.26 on epoch=39
06/12/2022 07:53:47 - INFO - __main__ - Step 170 Global step 170 Train loss 0.26 on epoch=42
06/12/2022 07:53:51 - INFO - __main__ - Step 180 Global step 180 Train loss 0.23 on epoch=44
06/12/2022 07:53:56 - INFO - __main__ - Step 190 Global step 190 Train loss 0.26 on epoch=47
06/12/2022 07:54:00 - INFO - __main__ - Step 200 Global step 200 Train loss 0.21 on epoch=49
06/12/2022 07:54:03 - INFO - __main__ - Global step 200 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=49
06/12/2022 07:54:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.21 on epoch=52
06/12/2022 07:54:11 - INFO - __main__ - Step 220 Global step 220 Train loss 0.22 on epoch=54
06/12/2022 07:54:16 - INFO - __main__ - Step 230 Global step 230 Train loss 0.21 on epoch=57
06/12/2022 07:54:21 - INFO - __main__ - Step 240 Global step 240 Train loss 0.26 on epoch=59
06/12/2022 07:54:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.23 on epoch=62
06/12/2022 07:54:28 - INFO - __main__ - Global step 250 Train loss 0.23 Classification-F1 0.2074074074074074 on epoch=62
06/12/2022 07:54:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.21 on epoch=64
06/12/2022 07:54:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.23 on epoch=67
06/12/2022 07:54:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.21 on epoch=69
06/12/2022 07:54:46 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=72
06/12/2022 07:54:50 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=74
06/12/2022 07:54:53 - INFO - __main__ - Global step 300 Train loss 0.22 Classification-F1 0.21276595744680848 on epoch=74
06/12/2022 07:54:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=77
06/12/2022 07:55:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.20 on epoch=79
06/12/2022 07:55:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/12/2022 07:55:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=84
06/12/2022 07:55:16 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=87
06/12/2022 07:55:18 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=87
06/12/2022 07:55:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=89
06/12/2022 07:55:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.20 on epoch=92
06/12/2022 07:55:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=94
06/12/2022 07:55:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=97
06/12/2022 07:55:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/12/2022 07:55:44 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=99
06/12/2022 07:55:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=102
06/12/2022 07:55:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.18 on epoch=104
06/12/2022 07:55:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=107
06/12/2022 07:56:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=109
06/12/2022 07:56:06 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/12/2022 07:56:09 - INFO - __main__ - Global step 450 Train loss 0.19 Classification-F1 0.5273745861981156 on epoch=112
06/12/2022 07:56:09 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.5273745861981156 on epoch=112, global_step=450
06/12/2022 07:56:14 - INFO - __main__ - Step 460 Global step 460 Train loss 0.19 on epoch=114
06/12/2022 07:56:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=117
06/12/2022 07:56:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=119
06/12/2022 07:56:27 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=122
06/12/2022 07:56:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=124
06/12/2022 07:56:35 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.42216142270861834 on epoch=124
06/12/2022 07:56:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=127
06/12/2022 07:56:44 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=129
06/12/2022 07:56:48 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=132
06/12/2022 07:56:53 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/12/2022 07:56:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
06/12/2022 07:57:00 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.21481481481481482 on epoch=137
06/12/2022 07:57:05 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=139
06/12/2022 07:57:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=142
06/12/2022 07:57:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=144
06/12/2022 07:57:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=147
06/12/2022 07:57:23 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=149
06/12/2022 07:57:25 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.5195195195195195 on epoch=149
06/12/2022 07:57:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=152
06/12/2022 07:57:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=154
06/12/2022 07:57:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=157
06/12/2022 07:57:43 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=159
06/12/2022 07:57:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=162
06/12/2022 07:57:50 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.3591989987484355 on epoch=162
06/12/2022 07:57:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=164
06/12/2022 07:58:00 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=167
06/12/2022 07:58:04 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=169
06/12/2022 07:58:09 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=172
06/12/2022 07:58:13 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=174
06/12/2022 07:58:16 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.3816425120772947 on epoch=174
06/12/2022 07:58:20 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=177
06/12/2022 07:58:25 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=179
06/12/2022 07:58:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=182
06/12/2022 07:58:34 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=184
06/12/2022 07:58:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=187
06/12/2022 07:58:41 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.5195195195195195 on epoch=187
06/12/2022 07:58:45 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=189
06/12/2022 07:58:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=192
06/12/2022 07:58:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=194
06/12/2022 07:58:59 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=197
06/12/2022 07:59:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=199
06/12/2022 07:59:06 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.5270935960591133 on epoch=199
06/12/2022 07:59:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=202
06/12/2022 07:59:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=204
06/12/2022 07:59:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=207
06/12/2022 07:59:24 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=209
06/12/2022 07:59:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=212
06/12/2022 07:59:31 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.5155067155067155 on epoch=212
06/12/2022 07:59:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=214
06/12/2022 07:59:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=217
06/12/2022 07:59:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=219
06/12/2022 07:59:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=222
06/12/2022 07:59:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=224
06/12/2022 07:59:57 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.5440923605993613 on epoch=224
06/12/2022 07:59:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5273745861981156 -> 0.5440923605993613 on epoch=224, global_step=900
06/12/2022 08:00:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=227
06/12/2022 08:00:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=229
06/12/2022 08:00:10 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=232
06/12/2022 08:00:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=234
06/12/2022 08:00:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=237
06/12/2022 08:00:22 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.4817813765182186 on epoch=237
06/12/2022 08:00:27 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=239
06/12/2022 08:00:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=242
06/12/2022 08:00:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=244
06/12/2022 08:00:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=247
06/12/2022 08:00:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=249
06/12/2022 08:00:48 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.5 on epoch=249
06/12/2022 08:00:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=252
06/12/2022 08:00:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=254
06/12/2022 08:01:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=257
06/12/2022 08:01:06 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=259
06/12/2022 08:01:11 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/12/2022 08:01:13 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.4682306940371457 on epoch=262
06/12/2022 08:01:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=264
06/12/2022 08:01:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
06/12/2022 08:01:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=269
06/12/2022 08:01:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=272
06/12/2022 08:01:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=274
06/12/2022 08:01:39 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.43647798742138366 on epoch=274
06/12/2022 08:01:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
06/12/2022 08:01:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=279
06/12/2022 08:01:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/12/2022 08:01:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=284
06/12/2022 08:02:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/12/2022 08:02:04 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.4102117061021171 on epoch=287
06/12/2022 08:02:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=289
06/12/2022 08:02:14 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=292
06/12/2022 08:02:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=294
06/12/2022 08:02:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=297
06/12/2022 08:02:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=299
06/12/2022 08:02:30 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.48424908424908425 on epoch=299
06/12/2022 08:02:35 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=302
06/12/2022 08:02:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
06/12/2022 08:02:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/12/2022 08:02:48 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=309
06/12/2022 08:02:53 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=312
06/12/2022 08:02:56 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.43529411764705883 on epoch=312
06/12/2022 08:03:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
06/12/2022 08:03:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
06/12/2022 08:03:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=319
06/12/2022 08:03:14 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/12/2022 08:03:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=324
06/12/2022 08:03:21 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.46666666666666656 on epoch=324
06/12/2022 08:03:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/12/2022 08:03:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/12/2022 08:03:35 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/12/2022 08:03:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/12/2022 08:03:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=337
06/12/2022 08:03:47 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.45299145299145294 on epoch=337
06/12/2022 08:03:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=339
06/12/2022 08:03:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/12/2022 08:04:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/12/2022 08:04:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=347
06/12/2022 08:04:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/12/2022 08:04:12 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.4832395400048935 on epoch=349
06/12/2022 08:04:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/12/2022 08:04:21 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/12/2022 08:04:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/12/2022 08:04:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/12/2022 08:04:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/12/2022 08:04:38 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.4325123152709359 on epoch=362
06/12/2022 08:04:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/12/2022 08:04:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/12/2022 08:04:51 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/12/2022 08:04:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/12/2022 08:05:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/12/2022 08:05:03 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.4812085482682388 on epoch=374
06/12/2022 08:05:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/12/2022 08:05:12 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/12/2022 08:05:17 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/12/2022 08:05:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/12/2022 08:05:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/12/2022 08:05:29 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.5145583557621727 on epoch=387
06/12/2022 08:05:33 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/12/2022 08:05:38 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/12/2022 08:05:43 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/12/2022 08:05:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=397
06/12/2022 08:05:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/12/2022 08:05:55 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.43529411764705883 on epoch=399
06/12/2022 08:05:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/12/2022 08:06:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/12/2022 08:06:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/12/2022 08:06:13 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/12/2022 08:06:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/12/2022 08:06:21 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.48424908424908425 on epoch=412
06/12/2022 08:06:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/12/2022 08:06:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=417
06/12/2022 08:06:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/12/2022 08:06:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/12/2022 08:06:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/12/2022 08:06:46 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.4995112414467253 on epoch=424
06/12/2022 08:06:51 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/12/2022 08:06:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/12/2022 08:07:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/12/2022 08:07:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/12/2022 08:07:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/12/2022 08:07:12 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.4285714285714286 on epoch=437
06/12/2022 08:07:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/12/2022 08:07:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/12/2022 08:07:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/12/2022 08:07:30 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/12/2022 08:07:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/12/2022 08:07:38 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.403921568627451 on epoch=449
06/12/2022 08:07:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/12/2022 08:07:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/12/2022 08:07:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/12/2022 08:07:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/12/2022 08:08:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/12/2022 08:08:03 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.4682306940371457 on epoch=462
06/12/2022 08:08:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/12/2022 08:08:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/12/2022 08:08:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/12/2022 08:08:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/12/2022 08:08:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/12/2022 08:08:29 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.4009852216748768 on epoch=474
06/12/2022 08:08:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/12/2022 08:08:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/12/2022 08:08:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/12/2022 08:08:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/12/2022 08:08:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/12/2022 08:08:54 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.4519207242476144 on epoch=487
06/12/2022 08:08:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/12/2022 08:09:03 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/12/2022 08:09:08 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/12/2022 08:09:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/12/2022 08:09:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/12/2022 08:09:20 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.46666666666666656 on epoch=499
06/12/2022 08:09:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/12/2022 08:09:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/12/2022 08:09:34 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/12/2022 08:09:38 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/12/2022 08:09:43 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/12/2022 08:09:46 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.4812085482682388 on epoch=512
06/12/2022 08:09:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/12/2022 08:09:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/12/2022 08:09:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/12/2022 08:10:04 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/12/2022 08:10:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/12/2022 08:10:11 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.5058530510585305 on epoch=524
06/12/2022 08:10:16 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/12/2022 08:10:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/12/2022 08:10:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/12/2022 08:10:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/12/2022 08:10:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/12/2022 08:10:37 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.464039408866995 on epoch=537
06/12/2022 08:10:41 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/12/2022 08:10:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/12/2022 08:10:50 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/12/2022 08:10:55 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/12/2022 08:10:59 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/12/2022 08:11:02 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.46875 on epoch=549
06/12/2022 08:11:07 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/12/2022 08:11:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=554
06/12/2022 08:11:16 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/12/2022 08:11:20 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/12/2022 08:11:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/12/2022 08:11:28 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.4682306940371457 on epoch=562
06/12/2022 08:11:32 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/12/2022 08:11:37 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/12/2022 08:11:41 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/12/2022 08:11:46 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/12/2022 08:11:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/12/2022 08:11:53 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.4682306940371457 on epoch=574
06/12/2022 08:11:58 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/12/2022 08:12:02 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/12/2022 08:12:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/12/2022 08:12:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=584
06/12/2022 08:12:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/12/2022 08:12:19 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.41487521620953793 on epoch=587
06/12/2022 08:12:23 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=589
06/12/2022 08:12:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/12/2022 08:12:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/12/2022 08:12:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/12/2022 08:12:41 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/12/2022 08:12:44 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.4832395400048935 on epoch=599
06/12/2022 08:12:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/12/2022 08:12:53 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/12/2022 08:12:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/12/2022 08:13:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/12/2022 08:13:06 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/12/2022 08:13:09 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.464039408866995 on epoch=612
06/12/2022 08:13:14 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/12/2022 08:13:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/12/2022 08:13:23 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/12/2022 08:13:27 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=622
06/12/2022 08:13:32 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/12/2022 08:13:35 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.4325123152709359 on epoch=624
06/12/2022 08:13:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/12/2022 08:13:44 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/12/2022 08:13:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/12/2022 08:13:53 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/12/2022 08:13:57 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/12/2022 08:14:00 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.4285714285714286 on epoch=637
06/12/2022 08:14:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/12/2022 08:14:09 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/12/2022 08:14:14 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/12/2022 08:14:19 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/12/2022 08:14:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=649
06/12/2022 08:14:26 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.44976664210267747 on epoch=649
06/12/2022 08:14:30 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/12/2022 08:14:35 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/12/2022 08:14:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/12/2022 08:14:44 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/12/2022 08:14:49 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=662
06/12/2022 08:14:51 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.5155067155067155 on epoch=662
06/12/2022 08:14:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/12/2022 08:15:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/12/2022 08:15:05 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/12/2022 08:15:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/12/2022 08:15:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/12/2022 08:15:17 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.49556650246305417 on epoch=674
06/12/2022 08:15:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/12/2022 08:15:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/12/2022 08:15:31 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/12/2022 08:15:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/12/2022 08:15:40 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/12/2022 08:15:42 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.46666666666666656 on epoch=687
06/12/2022 08:15:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/12/2022 08:15:51 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/12/2022 08:15:56 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/12/2022 08:16:01 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/12/2022 08:16:05 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/12/2022 08:16:08 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.48424908424908425 on epoch=699
06/12/2022 08:16:12 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/12/2022 08:16:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/12/2022 08:16:21 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/12/2022 08:16:26 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/12/2022 08:16:30 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/12/2022 08:16:33 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.48424908424908425 on epoch=712
06/12/2022 08:16:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/12/2022 08:16:42 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/12/2022 08:16:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/12/2022 08:16:51 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/12/2022 08:16:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/12/2022 08:16:59 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.48424908424908425 on epoch=724
06/12/2022 08:17:03 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/12/2022 08:17:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/12/2022 08:17:12 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/12/2022 08:17:17 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/12/2022 08:17:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/12/2022 08:17:24 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.48424908424908425 on epoch=737
06/12/2022 08:17:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/12/2022 08:17:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/12/2022 08:17:38 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/12/2022 08:17:42 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/12/2022 08:17:47 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/12/2022 08:17:48 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 08:17:48 - INFO - __main__ - Printing 3 examples
06/12/2022 08:17:48 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/12/2022 08:17:48 - INFO - __main__ - ['entailed']
06/12/2022 08:17:48 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/12/2022 08:17:48 - INFO - __main__ - ['entailed']
06/12/2022 08:17:48 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/12/2022 08:17:48 - INFO - __main__ - ['entailed']
06/12/2022 08:17:48 - INFO - __main__ - Tokenizing Input ...
06/12/2022 08:17:49 - INFO - __main__ - Tokenizing Output ...
06/12/2022 08:17:49 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 08:17:49 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 08:17:49 - INFO - __main__ - Printing 3 examples
06/12/2022 08:17:49 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/12/2022 08:17:49 - INFO - __main__ - ['entailed']
06/12/2022 08:17:49 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/12/2022 08:17:49 - INFO - __main__ - ['entailed']
06/12/2022 08:17:49 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/12/2022 08:17:49 - INFO - __main__ - ['entailed']
06/12/2022 08:17:49 - INFO - __main__ - Tokenizing Input ...
06/12/2022 08:17:49 - INFO - __main__ - Tokenizing Output ...
06/12/2022 08:17:49 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 08:17:50 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.4554554554554554 on epoch=749
06/12/2022 08:17:50 - INFO - __main__ - save last model!
06/12/2022 08:17:50 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 08:17:50 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 08:17:50 - INFO - __main__ - Printing 3 examples
06/12/2022 08:17:50 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 08:17:50 - INFO - __main__ - ['entailed']
06/12/2022 08:17:50 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 08:17:50 - INFO - __main__ - ['entailed']
06/12/2022 08:17:50 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 08:17:50 - INFO - __main__ - ['entailed']
06/12/2022 08:17:50 - INFO - __main__ - Tokenizing Input ...
06/12/2022 08:18:08 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 08:18:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 08:18:09 - INFO - __main__ - Starting training!
06/12/2022 08:18:15 - INFO - __main__ - Tokenizing Output ...
06/12/2022 08:18:27 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 08:27:28 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_87_0.3_8_predictions.txt
06/12/2022 08:27:28 - INFO - __main__ - Classification-F1 on test data: 0.3326
06/12/2022 08:27:29 - INFO - __main__ - prefix=tab_fact_32_87, lr=0.3, bsz=8, dev_performance=0.5440923605993613, test_performance=0.3325522544796032
06/12/2022 08:27:29 - INFO - __main__ - Running ... prefix=tab_fact_32_87, lr=0.2, bsz=8 ...
06/12/2022 08:27:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 08:27:30 - INFO - __main__ - Printing 3 examples
06/12/2022 08:27:30 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/12/2022 08:27:30 - INFO - __main__ - ['entailed']
06/12/2022 08:27:30 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/12/2022 08:27:30 - INFO - __main__ - ['entailed']
06/12/2022 08:27:30 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/12/2022 08:27:30 - INFO - __main__ - ['entailed']
06/12/2022 08:27:30 - INFO - __main__ - Tokenizing Input ...
06/12/2022 08:27:30 - INFO - __main__ - Tokenizing Output ...
06/12/2022 08:27:30 - INFO - __main__ - Loaded 64 examples from train data
06/12/2022 08:27:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/12/2022 08:27:30 - INFO - __main__ - Printing 3 examples
06/12/2022 08:27:30 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/12/2022 08:27:30 - INFO - __main__ - ['entailed']
06/12/2022 08:27:30 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/12/2022 08:27:30 - INFO - __main__ - ['entailed']
06/12/2022 08:27:30 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/12/2022 08:27:30 - INFO - __main__ - ['entailed']
06/12/2022 08:27:30 - INFO - __main__ - Tokenizing Input ...
06/12/2022 08:27:30 - INFO - __main__ - Tokenizing Output ...
06/12/2022 08:27:30 - INFO - __main__ - Loaded 64 examples from dev data
06/12/2022 08:27:46 - INFO - __main__ - load prompt embedding from ckpt
06/12/2022 08:27:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/12/2022 08:27:47 - INFO - __main__ - Starting training!
06/12/2022 08:27:52 - INFO - __main__ - Step 10 Global step 10 Train loss 3.79 on epoch=2
06/12/2022 08:27:56 - INFO - __main__ - Step 20 Global step 20 Train loss 1.21 on epoch=4
06/12/2022 08:28:01 - INFO - __main__ - Step 30 Global step 30 Train loss 0.65 on epoch=7
06/12/2022 08:28:05 - INFO - __main__ - Step 40 Global step 40 Train loss 0.42 on epoch=9
06/12/2022 08:28:10 - INFO - __main__ - Step 50 Global step 50 Train loss 0.39 on epoch=12
06/12/2022 08:28:13 - INFO - __main__ - Global step 50 Train loss 1.29 Classification-F1 0.3333333333333333 on epoch=12
06/12/2022 08:28:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/12/2022 08:28:17 - INFO - __main__ - Step 60 Global step 60 Train loss 0.36 on epoch=14
06/12/2022 08:28:22 - INFO - __main__ - Step 70 Global step 70 Train loss 0.35 on epoch=17
06/12/2022 08:28:26 - INFO - __main__ - Step 80 Global step 80 Train loss 0.37 on epoch=19
06/12/2022 08:28:31 - INFO - __main__ - Step 90 Global step 90 Train loss 0.30 on epoch=22
06/12/2022 08:28:36 - INFO - __main__ - Step 100 Global step 100 Train loss 0.29 on epoch=24
06/12/2022 08:28:39 - INFO - __main__ - Global step 100 Train loss 0.33 Classification-F1 0.3333333333333333 on epoch=24
06/12/2022 08:28:43 - INFO - __main__ - Step 110 Global step 110 Train loss 0.31 on epoch=27
06/12/2022 08:28:48 - INFO - __main__ - Step 120 Global step 120 Train loss 0.30 on epoch=29
06/12/2022 08:28:52 - INFO - __main__ - Step 130 Global step 130 Train loss 0.27 on epoch=32
06/12/2022 08:28:57 - INFO - __main__ - Step 140 Global step 140 Train loss 0.24 on epoch=34
06/12/2022 08:29:01 - INFO - __main__ - Step 150 Global step 150 Train loss 0.24 on epoch=37
06/12/2022 08:29:04 - INFO - __main__ - Global step 150 Train loss 0.27 Classification-F1 0.3671451355661882 on epoch=37
06/12/2022 08:29:04 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.3671451355661882 on epoch=37, global_step=150
06/12/2022 08:29:09 - INFO - __main__ - Step 160 Global step 160 Train loss 0.26 on epoch=39
06/12/2022 08:29:13 - INFO - __main__ - Step 170 Global step 170 Train loss 0.27 on epoch=42
06/12/2022 08:29:18 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=44
06/12/2022 08:29:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.24 on epoch=47
06/12/2022 08:29:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.23 on epoch=49
06/12/2022 08:29:30 - INFO - __main__ - Global step 200 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=49
06/12/2022 08:29:34 - INFO - __main__ - Step 210 Global step 210 Train loss 0.23 on epoch=52
06/12/2022 08:29:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.19 on epoch=54
06/12/2022 08:29:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.26 on epoch=57
06/12/2022 08:29:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.24 on epoch=59
06/12/2022 08:29:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.27 on epoch=62
06/12/2022 08:29:55 - INFO - __main__ - Global step 250 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=62
06/12/2022 08:30:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.24 on epoch=64
06/12/2022 08:30:04 - INFO - __main__ - Step 270 Global step 270 Train loss 0.19 on epoch=67
06/12/2022 08:30:09 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=69
06/12/2022 08:30:13 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=72
06/12/2022 08:30:18 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=74
06/12/2022 08:30:21 - INFO - __main__ - Global step 300 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=74
06/12/2022 08:30:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=77
06/12/2022 08:30:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.23 on epoch=79
06/12/2022 08:30:34 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=82
06/12/2022 08:30:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.21 on epoch=84
06/12/2022 08:30:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.19 on epoch=87
06/12/2022 08:30:46 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=87
06/12/2022 08:30:51 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=89
06/12/2022 08:30:55 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=92
06/12/2022 08:31:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=94
06/12/2022 08:31:04 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=97
06/12/2022 08:31:09 - INFO - __main__ - Step 400 Global step 400 Train loss 0.24 on epoch=99
06/12/2022 08:31:12 - INFO - __main__ - Global step 400 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=99
06/12/2022 08:31:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=102
06/12/2022 08:31:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=104
06/12/2022 08:31:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=107
06/12/2022 08:31:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=109
06/12/2022 08:31:34 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=112
06/12/2022 08:31:37 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=112
06/12/2022 08:31:42 - INFO - __main__ - Step 460 Global step 460 Train loss 0.19 on epoch=114
06/12/2022 08:31:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=117
06/12/2022 08:31:51 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=119
06/12/2022 08:31:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=122
06/12/2022 08:32:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
06/12/2022 08:32:03 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=124
06/12/2022 08:32:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=127
06/12/2022 08:32:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/12/2022 08:32:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=132
06/12/2022 08:32:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/12/2022 08:32:25 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=137
06/12/2022 08:32:29 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.3816425120772947 on epoch=137
06/12/2022 08:32:29 - INFO - __main__ - Saving model with best Classification-F1: 0.3671451355661882 -> 0.3816425120772947 on epoch=137, global_step=550
06/12/2022 08:32:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=139
06/12/2022 08:32:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=142
06/12/2022 08:32:42 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/12/2022 08:32:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=147
06/12/2022 08:32:51 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=149
06/12/2022 08:32:54 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=149
06/12/2022 08:32:59 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=152
06/12/2022 08:33:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=154
06/12/2022 08:33:08 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=157
06/12/2022 08:33:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=159
06/12/2022 08:33:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=162
06/12/2022 08:33:19 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.2032520325203252 on epoch=162
06/12/2022 08:33:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=164
06/12/2022 08:33:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=167
06/12/2022 08:33:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=169
06/12/2022 08:33:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=172
06/12/2022 08:33:42 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=174
06/12/2022 08:33:45 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.4748717948717949 on epoch=174
06/12/2022 08:33:45 - INFO - __main__ - Saving model with best Classification-F1: 0.3816425120772947 -> 0.4748717948717949 on epoch=174, global_step=700
06/12/2022 08:33:50 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=177
06/12/2022 08:33:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=179
06/12/2022 08:33:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=182
06/12/2022 08:34:03 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=184
06/12/2022 08:34:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=187
06/12/2022 08:34:11 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.3264069264069264 on epoch=187
06/12/2022 08:34:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=189
06/12/2022 08:34:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=192
06/12/2022 08:34:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=194
06/12/2022 08:34:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=197
06/12/2022 08:34:33 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=199
06/12/2022 08:34:36 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.2584717607973422 on epoch=199
06/12/2022 08:34:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/12/2022 08:34:45 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=204
06/12/2022 08:34:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=207
06/12/2022 08:34:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=209
06/12/2022 08:34:59 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=212
06/12/2022 08:35:02 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.2978927203065134 on epoch=212
06/12/2022 08:35:07 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=214
06/12/2022 08:35:11 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=217
06/12/2022 08:35:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=219
06/12/2022 08:35:20 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=222
06/12/2022 08:35:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=224
06/12/2022 08:35:28 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.49556650246305417 on epoch=224
06/12/2022 08:35:28 - INFO - __main__ - Saving model with best Classification-F1: 0.4748717948717949 -> 0.49556650246305417 on epoch=224, global_step=900
06/12/2022 08:35:33 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=227
06/12/2022 08:35:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=229
06/12/2022 08:35:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=232
06/12/2022 08:35:46 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=234
06/12/2022 08:35:51 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=237
06/12/2022 08:35:54 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.4285714285714286 on epoch=237
06/12/2022 08:35:58 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=239
06/12/2022 08:36:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=242
06/12/2022 08:36:08 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=244
06/12/2022 08:36:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=247
06/12/2022 08:36:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=249
06/12/2022 08:36:20 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.500880503144654 on epoch=249
06/12/2022 08:36:20 - INFO - __main__ - Saving model with best Classification-F1: 0.49556650246305417 -> 0.500880503144654 on epoch=249, global_step=1000
06/12/2022 08:36:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=252
06/12/2022 08:36:29 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=254
06/12/2022 08:36:33 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=257
06/12/2022 08:36:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=259
06/12/2022 08:36:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=262
06/12/2022 08:36:45 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.4493927125506073 on epoch=262
06/12/2022 08:36:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=264
06/12/2022 08:36:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=267
06/12/2022 08:36:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=269
06/12/2022 08:37:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=272
06/12/2022 08:37:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=274
06/12/2022 08:37:10 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.4874874874874875 on epoch=274
06/12/2022 08:37:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=277
06/12/2022 08:37:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=279
06/12/2022 08:37:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=282
06/12/2022 08:37:28 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=284
06/12/2022 08:37:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=287
06/12/2022 08:37:36 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.4295900178253119 on epoch=287
06/12/2022 08:37:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=289
06/12/2022 08:37:45 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=292
06/12/2022 08:37:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=294
06/12/2022 08:37:54 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=297
06/12/2022 08:37:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=299
06/12/2022 08:38:01 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.40427672955974847 on epoch=299
06/12/2022 08:38:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=302
06/12/2022 08:38:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=304
06/12/2022 08:38:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=307
06/12/2022 08:38:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=309
06/12/2022 08:38:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=312
06/12/2022 08:38:27 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.40427672955974847 on epoch=312
06/12/2022 08:38:32 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=314
06/12/2022 08:38:36 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/12/2022 08:38:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=319
06/12/2022 08:38:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=322
06/12/2022 08:38:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=324
06/12/2022 08:38:53 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.4102117061021171 on epoch=324
06/12/2022 08:38:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=327
06/12/2022 08:39:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=329
06/12/2022 08:39:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=332
06/12/2022 08:39:11 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=334
06/12/2022 08:39:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=337
06/12/2022 08:39:18 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.40427672955974847 on epoch=337
06/12/2022 08:39:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=339
06/12/2022 08:39:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=342
06/12/2022 08:39:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=344
06/12/2022 08:39:36 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=347
06/12/2022 08:39:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=349
06/12/2022 08:39:44 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.43333333333333335 on epoch=349
06/12/2022 08:39:48 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=352
06/12/2022 08:39:53 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=354
06/12/2022 08:39:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=357
06/12/2022 08:40:02 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/12/2022 08:40:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
06/12/2022 08:40:09 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.473972602739726 on epoch=362
06/12/2022 08:40:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=364
06/12/2022 08:40:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
06/12/2022 08:40:23 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=369
06/12/2022 08:40:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=372
06/12/2022 08:40:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=374
06/12/2022 08:40:35 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.39999999999999997 on epoch=374
06/12/2022 08:40:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=377
06/12/2022 08:40:44 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
06/12/2022 08:40:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
06/12/2022 08:40:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=384
06/12/2022 08:40:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/12/2022 08:41:00 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.39999999999999997 on epoch=387
06/12/2022 08:41:05 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/12/2022 08:41:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/12/2022 08:41:14 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
06/12/2022 08:41:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
06/12/2022 08:41:23 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/12/2022 08:41:26 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.39139139139139134 on epoch=399
06/12/2022 08:41:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=402
06/12/2022 08:41:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
06/12/2022 08:41:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=407
06/12/2022 08:41:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=409
06/12/2022 08:41:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=412
06/12/2022 08:41:52 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.403921568627451 on epoch=412
06/12/2022 08:41:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/12/2022 08:42:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=417
06/12/2022 08:42:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/12/2022 08:42:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/12/2022 08:42:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/12/2022 08:42:17 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.41832473593711617 on epoch=424
06/12/2022 08:42:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=427
06/12/2022 08:42:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=429
06/12/2022 08:42:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=432
06/12/2022 08:42:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/12/2022 08:42:40 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/12/2022 08:42:43 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.3882717644019633 on epoch=437
06/12/2022 08:42:48 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/12/2022 08:42:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/12/2022 08:42:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=444
06/12/2022 08:43:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/12/2022 08:43:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/12/2022 08:43:09 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.46031746031746035 on epoch=449
06/12/2022 08:43:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/12/2022 08:43:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=454
06/12/2022 08:43:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=457
06/12/2022 08:43:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/12/2022 08:43:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=462
06/12/2022 08:43:35 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.4325123152709359 on epoch=462
06/12/2022 08:43:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/12/2022 08:43:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/12/2022 08:43:48 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/12/2022 08:43:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=472
06/12/2022 08:43:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/12/2022 08:44:00 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.40566959921798634 on epoch=474
06/12/2022 08:44:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/12/2022 08:44:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/12/2022 08:44:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=482
06/12/2022 08:44:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/12/2022 08:44:23 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/12/2022 08:44:26 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.339874213836478 on epoch=487
06/12/2022 08:44:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=489
06/12/2022 08:44:35 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/12/2022 08:44:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/12/2022 08:44:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/12/2022 08:44:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=499
06/12/2022 08:44:51 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.45299145299145294 on epoch=499
06/12/2022 08:44:56 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=502
06/12/2022 08:45:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/12/2022 08:45:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/12/2022 08:45:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/12/2022 08:45:14 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=512
06/12/2022 08:45:17 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.3969951617010441 on epoch=512
06/12/2022 08:45:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/12/2022 08:45:26 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/12/2022 08:45:31 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/12/2022 08:45:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=522
06/12/2022 08:45:40 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/12/2022 08:45:43 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.37833125778331256 on epoch=524
06/12/2022 08:45:47 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/12/2022 08:45:52 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/12/2022 08:45:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/12/2022 08:46:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/12/2022 08:46:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/12/2022 08:46:08 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.3666666666666667 on epoch=537
06/12/2022 08:46:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/12/2022 08:46:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/12/2022 08:46:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/12/2022 08:46:26 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/12/2022 08:46:31 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/12/2022 08:46:34 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.34358974358974353 on epoch=549
06/12/2022 08:46:38 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/12/2022 08:46:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/12/2022 08:46:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/12/2022 08:46:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=559
06/12/2022 08:46:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/12/2022 08:46:59 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.4682306940371457 on epoch=562
06/12/2022 08:47:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=564
06/12/2022 08:47:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/12/2022 08:47:13 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/12/2022 08:47:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/12/2022 08:47:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=574
06/12/2022 08:47:25 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.3846153846153846 on epoch=574
06/12/2022 08:47:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/12/2022 08:47:34 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/12/2022 08:47:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=582
06/12/2022 08:47:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/12/2022 08:47:47 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/12/2022 08:47:50 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.43529411764705883 on epoch=587
06/12/2022 08:47:55 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/12/2022 08:47:59 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/12/2022 08:48:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/12/2022 08:48:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/12/2022 08:48:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/12/2022 08:48:16 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.35520537328855595 on epoch=599
06/12/2022 08:48:20 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/12/2022 08:48:25 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/12/2022 08:48:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/12/2022 08:48:34 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/12/2022 08:48:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/12/2022 08:48:42 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.4375 on epoch=612
06/12/2022 08:48:46 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/12/2022 08:48:51 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/12/2022 08:48:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/12/2022 08:49:00 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/12/2022 08:49:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/12/2022 08:49:07 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.34358974358974353 on epoch=624
06/12/2022 08:49:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/12/2022 08:49:16 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/12/2022 08:49:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/12/2022 08:49:25 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/12/2022 08:49:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/12/2022 08:49:33 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.34358974358974353 on epoch=637
06/12/2022 08:49:37 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=639
06/12/2022 08:49:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/12/2022 08:49:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/12/2022 08:49:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/12/2022 08:49:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/12/2022 08:49:58 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.35520537328855595 on epoch=649
06/12/2022 08:50:03 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/12/2022 08:50:07 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/12/2022 08:50:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.08 on epoch=657
06/12/2022 08:50:17 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/12/2022 08:50:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/12/2022 08:50:24 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.46666666666666656 on epoch=662
06/12/2022 08:50:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/12/2022 08:50:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/12/2022 08:50:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/12/2022 08:50:42 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/12/2022 08:50:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/12/2022 08:50:50 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.46666666666666656 on epoch=674
06/12/2022 08:50:54 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/12/2022 08:50:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/12/2022 08:51:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/12/2022 08:51:08 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/12/2022 08:51:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/12/2022 08:51:16 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.46666666666666656 on epoch=687
06/12/2022 08:51:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=689
06/12/2022 08:51:25 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/12/2022 08:51:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/12/2022 08:51:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/12/2022 08:51:39 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/12/2022 08:51:42 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.4285714285714286 on epoch=699
06/12/2022 08:51:46 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/12/2022 08:51:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/12/2022 08:51:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/12/2022 08:52:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/12/2022 08:52:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/12/2022 08:52:08 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.41700404858299595 on epoch=712
06/12/2022 08:52:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/12/2022 08:52:17 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=717
06/12/2022 08:52:22 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/12/2022 08:52:26 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/12/2022 08:52:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=724
06/12/2022 08:52:34 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.46875 on epoch=724
06/12/2022 08:52:38 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
06/12/2022 08:52:43 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/12/2022 08:52:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/12/2022 08:52:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/12/2022 08:52:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/12/2022 08:52:59 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.39139139139139134 on epoch=737
06/12/2022 08:53:04 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
06/12/2022 08:53:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=742
06/12/2022 08:53:13 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/12/2022 08:53:17 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=747
06/12/2022 08:53:22 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/12/2022 08:53:25 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.339874213836478 on epoch=749
06/12/2022 08:53:25 - INFO - __main__ - save last model!
06/12/2022 08:53:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/12/2022 08:53:25 - INFO - __main__ - Start tokenizing ... 12792 instances
06/12/2022 08:53:25 - INFO - __main__ - Printing 3 examples
06/12/2022 08:53:25 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 08:53:25 - INFO - __main__ - ['entailed']
06/12/2022 08:53:25 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 08:53:25 - INFO - __main__ - ['entailed']
06/12/2022 08:53:25 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/12/2022 08:53:25 - INFO - __main__ - ['entailed']
06/12/2022 08:53:25 - INFO - __main__ - Tokenizing Input ...
06/12/2022 08:53:50 - INFO - __main__ - Tokenizing Output ...
06/12/2022 08:54:03 - INFO - __main__ - Loaded 12792 examples from test data
06/12/2022 09:02:56 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down32shot/singletask-tab_fact/tab_fact_32_87_0.2_8_predictions.txt
06/12/2022 09:02:56 - INFO - __main__ - Classification-F1 on test data: 0.4905
06/12/2022 09:02:56 - INFO - __main__ - prefix=tab_fact_32_87, lr=0.2, bsz=8, dev_performance=0.500880503144654, test_performance=0.4904576142985208
