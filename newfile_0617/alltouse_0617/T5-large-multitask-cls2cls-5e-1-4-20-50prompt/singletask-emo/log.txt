06/02/2022 20:17:06 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-20-50prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-50prompt-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=50, cuda='4,5')
06/02/2022 20:17:06 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo
06/02/2022 20:17:06 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-20-50prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-50prompt-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=50, cuda='4,5')
06/02/2022 20:17:06 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo
06/02/2022 20:17:07 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/02/2022 20:17:07 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/02/2022 20:17:07 - INFO - __main__ - args.device: cuda:0
06/02/2022 20:17:07 - INFO - __main__ - Using 2 gpus
06/02/2022 20:17:07 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/02/2022 20:17:07 - INFO - __main__ - args.device: cuda:1
06/02/2022 20:17:07 - INFO - __main__ - Using 2 gpus
06/02/2022 20:17:07 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/02/2022 20:17:12 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
06/02/2022 20:17:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 20:17:13 - INFO - __main__ - Printing 3 examples
06/02/2022 20:17:13 - INFO - __main__ -  [emo] how cause yes am listening
06/02/2022 20:17:13 - INFO - __main__ - ['others']
06/02/2022 20:17:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 20:17:13 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/02/2022 20:17:13 - INFO - __main__ - ['others']
06/02/2022 20:17:13 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/02/2022 20:17:13 - INFO - __main__ - Printing 3 examples
06/02/2022 20:17:13 - INFO - __main__ - ['others']
06/02/2022 20:17:13 - INFO - __main__ -  [emo] how cause yes am listening
06/02/2022 20:17:13 - INFO - __main__ - ['others']
06/02/2022 20:17:13 - INFO - __main__ - Tokenizing Input ...
06/02/2022 20:17:13 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/02/2022 20:17:13 - INFO - __main__ - ['others']
06/02/2022 20:17:13 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/02/2022 20:17:13 - INFO - __main__ - ['others']
06/02/2022 20:17:13 - INFO - __main__ - Tokenizing Input ...
06/02/2022 20:17:13 - INFO - __main__ - Tokenizing Output ...
06/02/2022 20:17:13 - INFO - __main__ - Tokenizing Output ...
06/02/2022 20:17:13 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 20:17:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 20:17:13 - INFO - __main__ - Printing 3 examples
06/02/2022 20:17:13 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/02/2022 20:17:13 - INFO - __main__ - ['others']
06/02/2022 20:17:13 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/02/2022 20:17:13 - INFO - __main__ - ['others']
06/02/2022 20:17:13 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/02/2022 20:17:13 - INFO - __main__ - ['others']
06/02/2022 20:17:13 - INFO - __main__ - Tokenizing Input ...
06/02/2022 20:17:13 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 20:17:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 20:17:13 - INFO - __main__ - Printing 3 examples
06/02/2022 20:17:13 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/02/2022 20:17:13 - INFO - __main__ - ['others']
06/02/2022 20:17:13 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/02/2022 20:17:13 - INFO - __main__ - ['others']
06/02/2022 20:17:13 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/02/2022 20:17:13 - INFO - __main__ - ['others']
06/02/2022 20:17:13 - INFO - __main__ - Tokenizing Input ...
06/02/2022 20:17:13 - INFO - __main__ - Tokenizing Output ...
06/02/2022 20:17:13 - INFO - __main__ - Tokenizing Output ...
06/02/2022 20:17:13 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 20:17:13 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 20:17:31 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 20:17:31 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 20:17:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 20:17:32 - INFO - __main__ - Starting training!
06/02/2022 20:17:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 20:17:37 - INFO - __main__ - Starting training!
06/02/2022 20:17:40 - INFO - __main__ - Step 10 Global step 10 Train loss 4.42 on epoch=2
06/02/2022 20:17:42 - INFO - __main__ - Step 20 Global step 20 Train loss 3.07 on epoch=4
06/02/2022 20:17:44 - INFO - __main__ - Step 30 Global step 30 Train loss 2.37 on epoch=7
06/02/2022 20:17:47 - INFO - __main__ - Step 40 Global step 40 Train loss 1.75 on epoch=9
06/02/2022 20:17:49 - INFO - __main__ - Step 50 Global step 50 Train loss 1.53 on epoch=12
06/02/2022 20:17:50 - INFO - __main__ - Global step 50 Train loss 2.63 Classification-F1 0.14876964369864976 on epoch=12
06/02/2022 20:17:50 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.14876964369864976 on epoch=12, global_step=50
06/02/2022 20:17:52 - INFO - __main__ - Step 60 Global step 60 Train loss 1.25 on epoch=14
06/02/2022 20:17:55 - INFO - __main__ - Step 70 Global step 70 Train loss 1.18 on epoch=17
06/02/2022 20:17:57 - INFO - __main__ - Step 80 Global step 80 Train loss 0.90 on epoch=19
06/02/2022 20:17:59 - INFO - __main__ - Step 90 Global step 90 Train loss 0.91 on epoch=22
06/02/2022 20:18:02 - INFO - __main__ - Step 100 Global step 100 Train loss 0.88 on epoch=24
06/02/2022 20:18:02 - INFO - __main__ - Global step 100 Train loss 1.02 Classification-F1 0.5830853543619501 on epoch=24
06/02/2022 20:18:03 - INFO - __main__ - Saving model with best Classification-F1: 0.14876964369864976 -> 0.5830853543619501 on epoch=24, global_step=100
06/02/2022 20:18:05 - INFO - __main__ - Step 110 Global step 110 Train loss 0.89 on epoch=27
06/02/2022 20:18:07 - INFO - __main__ - Step 120 Global step 120 Train loss 0.87 on epoch=29
06/02/2022 20:18:10 - INFO - __main__ - Step 130 Global step 130 Train loss 0.76 on epoch=32
06/02/2022 20:18:12 - INFO - __main__ - Step 140 Global step 140 Train loss 0.71 on epoch=34
06/02/2022 20:18:14 - INFO - __main__ - Step 150 Global step 150 Train loss 0.75 on epoch=37
06/02/2022 20:18:15 - INFO - __main__ - Global step 150 Train loss 0.80 Classification-F1 0.6516840607210627 on epoch=37
06/02/2022 20:18:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5830853543619501 -> 0.6516840607210627 on epoch=37, global_step=150
06/02/2022 20:18:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.68 on epoch=39
06/02/2022 20:18:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.62 on epoch=42
06/02/2022 20:18:22 - INFO - __main__ - Step 180 Global step 180 Train loss 0.68 on epoch=44
06/02/2022 20:18:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.72 on epoch=47
06/02/2022 20:18:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.58 on epoch=49
06/02/2022 20:18:28 - INFO - __main__ - Global step 200 Train loss 0.66 Classification-F1 0.6003264133698916 on epoch=49
06/02/2022 20:18:30 - INFO - __main__ - Step 210 Global step 210 Train loss 0.74 on epoch=52
06/02/2022 20:18:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.62 on epoch=54
06/02/2022 20:18:35 - INFO - __main__ - Step 230 Global step 230 Train loss 0.60 on epoch=57
06/02/2022 20:18:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.74 on epoch=59
06/02/2022 20:18:40 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=62
06/02/2022 20:18:41 - INFO - __main__ - Global step 250 Train loss 0.66 Classification-F1 0.6087693141772839 on epoch=62
06/02/2022 20:18:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.58 on epoch=64
06/02/2022 20:18:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.61 on epoch=67
06/02/2022 20:18:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=69
06/02/2022 20:18:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.58 on epoch=72
06/02/2022 20:18:52 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=74
06/02/2022 20:18:53 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.6717836257309941 on epoch=74
06/02/2022 20:18:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6516840607210627 -> 0.6717836257309941 on epoch=74, global_step=300
06/02/2022 20:18:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.55 on epoch=77
06/02/2022 20:18:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.51 on epoch=79
06/02/2022 20:19:00 - INFO - __main__ - Step 330 Global step 330 Train loss 0.47 on epoch=82
06/02/2022 20:19:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.44 on epoch=84
06/02/2022 20:19:05 - INFO - __main__ - Step 350 Global step 350 Train loss 0.45 on epoch=87
06/02/2022 20:19:06 - INFO - __main__ - Global step 350 Train loss 0.49 Classification-F1 0.6845238095238095 on epoch=87
06/02/2022 20:19:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6717836257309941 -> 0.6845238095238095 on epoch=87, global_step=350
06/02/2022 20:19:08 - INFO - __main__ - Step 360 Global step 360 Train loss 0.41 on epoch=89
06/02/2022 20:19:11 - INFO - __main__ - Step 370 Global step 370 Train loss 0.55 on epoch=92
06/02/2022 20:19:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.41 on epoch=94
06/02/2022 20:19:15 - INFO - __main__ - Step 390 Global step 390 Train loss 0.48 on epoch=97
06/02/2022 20:19:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=99
06/02/2022 20:19:18 - INFO - __main__ - Global step 400 Train loss 0.44 Classification-F1 0.6852444386400244 on epoch=99
06/02/2022 20:19:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6845238095238095 -> 0.6852444386400244 on epoch=99, global_step=400
06/02/2022 20:19:21 - INFO - __main__ - Step 410 Global step 410 Train loss 0.43 on epoch=102
06/02/2022 20:19:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=104
06/02/2022 20:19:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.40 on epoch=107
06/02/2022 20:19:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.40 on epoch=109
06/02/2022 20:19:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.31 on epoch=112
06/02/2022 20:19:31 - INFO - __main__ - Global step 450 Train loss 0.38 Classification-F1 0.7350298183789645 on epoch=112
06/02/2022 20:19:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6852444386400244 -> 0.7350298183789645 on epoch=112, global_step=450
06/02/2022 20:19:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.33 on epoch=114
06/02/2022 20:19:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.36 on epoch=117
06/02/2022 20:19:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=119
06/02/2022 20:19:40 - INFO - __main__ - Step 490 Global step 490 Train loss 0.40 on epoch=122
06/02/2022 20:19:43 - INFO - __main__ - Step 500 Global step 500 Train loss 0.30 on epoch=124
06/02/2022 20:19:44 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.7470588235294118 on epoch=124
06/02/2022 20:19:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7350298183789645 -> 0.7470588235294118 on epoch=124, global_step=500
06/02/2022 20:19:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.31 on epoch=127
06/02/2022 20:19:48 - INFO - __main__ - Step 520 Global step 520 Train loss 0.48 on epoch=129
06/02/2022 20:19:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.42 on epoch=132
06/02/2022 20:19:53 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=134
06/02/2022 20:19:55 - INFO - __main__ - Step 550 Global step 550 Train loss 0.33 on epoch=137
06/02/2022 20:19:56 - INFO - __main__ - Global step 550 Train loss 0.37 Classification-F1 0.7301213196877497 on epoch=137
06/02/2022 20:19:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.37 on epoch=139
06/02/2022 20:20:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=142
06/02/2022 20:20:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.32 on epoch=144
06/02/2022 20:20:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=147
06/02/2022 20:20:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.31 on epoch=149
06/02/2022 20:20:09 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.7267864783910997 on epoch=149
06/02/2022 20:20:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=152
06/02/2022 20:20:13 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=154
06/02/2022 20:20:16 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=157
06/02/2022 20:20:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/02/2022 20:20:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.33 on epoch=162
06/02/2022 20:20:21 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.7491392552571641 on epoch=162
06/02/2022 20:20:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7470588235294118 -> 0.7491392552571641 on epoch=162, global_step=650
06/02/2022 20:20:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.29 on epoch=164
06/02/2022 20:20:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=167
06/02/2022 20:20:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=169
06/02/2022 20:20:30 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=172
06/02/2022 20:20:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=174
06/02/2022 20:20:34 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.7644649257552483 on epoch=174
06/02/2022 20:20:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7491392552571641 -> 0.7644649257552483 on epoch=174, global_step=700
06/02/2022 20:20:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=177
06/02/2022 20:20:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=179
06/02/2022 20:20:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=182
06/02/2022 20:20:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=184
06/02/2022 20:20:45 - INFO - __main__ - Step 750 Global step 750 Train loss 0.26 on epoch=187
06/02/2022 20:20:46 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.7817003047553333 on epoch=187
06/02/2022 20:20:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7644649257552483 -> 0.7817003047553333 on epoch=187, global_step=750
06/02/2022 20:20:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=189
06/02/2022 20:20:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=192
06/02/2022 20:20:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=194
06/02/2022 20:20:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.24 on epoch=197
06/02/2022 20:20:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
06/02/2022 20:20:59 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.7349537037037037 on epoch=199
06/02/2022 20:21:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=202
06/02/2022 20:21:04 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=204
06/02/2022 20:21:07 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=207
06/02/2022 20:21:09 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=209
06/02/2022 20:21:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.35 on epoch=212
06/02/2022 20:21:12 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.7447993499907801 on epoch=212
06/02/2022 20:21:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=214
06/02/2022 20:21:17 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=217
06/02/2022 20:21:20 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=219
06/02/2022 20:21:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=222
06/02/2022 20:21:24 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=224
06/02/2022 20:21:25 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.7644649257552483 on epoch=224
06/02/2022 20:21:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=227
06/02/2022 20:21:30 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=229
06/02/2022 20:21:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=232
06/02/2022 20:21:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=234
06/02/2022 20:21:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=237
06/02/2022 20:21:38 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.7293114543114544 on epoch=237
06/02/2022 20:21:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=239
06/02/2022 20:21:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=242
06/02/2022 20:21:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=244
06/02/2022 20:21:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=247
06/02/2022 20:21:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=249
06/02/2022 20:21:51 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.7630571748218807 on epoch=249
06/02/2022 20:21:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=252
06/02/2022 20:21:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=254
06/02/2022 20:21:58 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=257
06/02/2022 20:22:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=259
06/02/2022 20:22:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
06/02/2022 20:22:04 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.7806663488532232 on epoch=262
06/02/2022 20:22:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=264
06/02/2022 20:22:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=267
06/02/2022 20:22:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=269
06/02/2022 20:22:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=272
06/02/2022 20:22:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=274
06/02/2022 20:22:17 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.7468892141496097 on epoch=274
06/02/2022 20:22:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=277
06/02/2022 20:22:22 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=279
06/02/2022 20:22:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=282
06/02/2022 20:22:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=284
06/02/2022 20:22:29 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/02/2022 20:22:30 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.7649358863780117 on epoch=287
06/02/2022 20:22:32 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=289
06/02/2022 20:22:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
06/02/2022 20:22:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=294
06/02/2022 20:22:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=297
06/02/2022 20:22:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/02/2022 20:22:42 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.7796451914098973 on epoch=299
06/02/2022 20:22:45 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=302
06/02/2022 20:22:47 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=304
06/02/2022 20:22:50 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=307
06/02/2022 20:22:52 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=309
06/02/2022 20:22:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=312
06/02/2022 20:22:55 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.7459287163141118 on epoch=312
06/02/2022 20:22:58 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
06/02/2022 20:23:00 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/02/2022 20:23:02 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/02/2022 20:23:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.14 on epoch=322
06/02/2022 20:23:07 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=324
06/02/2022 20:23:08 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7490196078431373 on epoch=324
06/02/2022 20:23:11 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=327
06/02/2022 20:23:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/02/2022 20:23:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=332
06/02/2022 20:23:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/02/2022 20:23:20 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=337
06/02/2022 20:23:21 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7459287163141118 on epoch=337
06/02/2022 20:23:24 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=339
06/02/2022 20:23:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.13 on epoch=342
06/02/2022 20:23:28 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/02/2022 20:23:31 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=347
06/02/2022 20:23:33 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
06/02/2022 20:23:34 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7963203463203463 on epoch=349
06/02/2022 20:23:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7817003047553333 -> 0.7963203463203463 on epoch=349, global_step=1400
06/02/2022 20:23:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=352
06/02/2022 20:23:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/02/2022 20:23:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=357
06/02/2022 20:23:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=359
06/02/2022 20:23:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=362
06/02/2022 20:23:47 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7473626989980946 on epoch=362
06/02/2022 20:23:49 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/02/2022 20:23:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=367
06/02/2022 20:23:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/02/2022 20:23:57 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/02/2022 20:23:59 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=374
06/02/2022 20:24:00 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7478991596638656 on epoch=374
06/02/2022 20:24:02 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/02/2022 20:24:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/02/2022 20:24:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/02/2022 20:24:10 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/02/2022 20:24:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.14 on epoch=387
06/02/2022 20:24:13 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7645021645021646 on epoch=387
06/02/2022 20:24:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/02/2022 20:24:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/02/2022 20:24:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=394
06/02/2022 20:24:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/02/2022 20:24:25 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/02/2022 20:24:26 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7783068783068783 on epoch=399
06/02/2022 20:24:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/02/2022 20:24:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/02/2022 20:24:33 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=407
06/02/2022 20:24:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/02/2022 20:24:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/02/2022 20:24:39 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7783068783068783 on epoch=412
06/02/2022 20:24:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/02/2022 20:24:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/02/2022 20:24:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=419
06/02/2022 20:24:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/02/2022 20:24:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=424
06/02/2022 20:24:52 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.7783068783068783 on epoch=424
06/02/2022 20:24:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/02/2022 20:24:57 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/02/2022 20:24:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/02/2022 20:25:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
06/02/2022 20:25:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
06/02/2022 20:25:05 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.766022372140281 on epoch=437
06/02/2022 20:25:07 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/02/2022 20:25:10 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/02/2022 20:25:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=444
06/02/2022 20:25:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/02/2022 20:25:17 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/02/2022 20:25:18 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.742953342953343 on epoch=449
06/02/2022 20:25:20 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=452
06/02/2022 20:25:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=454
06/02/2022 20:25:25 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=457
06/02/2022 20:25:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/02/2022 20:25:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/02/2022 20:25:31 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.7448275862068966 on epoch=462
06/02/2022 20:25:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/02/2022 20:25:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/02/2022 20:25:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/02/2022 20:25:40 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.13 on epoch=472
06/02/2022 20:25:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/02/2022 20:25:44 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7293114543114544 on epoch=474
06/02/2022 20:25:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/02/2022 20:25:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/02/2022 20:25:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/02/2022 20:25:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/02/2022 20:25:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/02/2022 20:25:57 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7952380952380952 on epoch=487
06/02/2022 20:25:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/02/2022 20:26:02 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/02/2022 20:26:04 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/02/2022 20:26:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/02/2022 20:26:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/02/2022 20:26:10 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7571428571428571 on epoch=499
06/02/2022 20:26:12 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=502
06/02/2022 20:26:15 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/02/2022 20:26:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/02/2022 20:26:19 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/02/2022 20:26:22 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/02/2022 20:26:23 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7952380952380952 on epoch=512
06/02/2022 20:26:25 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=514
06/02/2022 20:26:28 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=517
06/02/2022 20:26:30 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/02/2022 20:26:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/02/2022 20:26:35 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=524
06/02/2022 20:26:36 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7420294506691566 on epoch=524
06/02/2022 20:26:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/02/2022 20:26:41 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/02/2022 20:26:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/02/2022 20:26:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/02/2022 20:26:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/02/2022 20:26:49 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7952380952380952 on epoch=537
06/02/2022 20:26:51 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/02/2022 20:26:54 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/02/2022 20:26:56 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/02/2022 20:26:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=547
06/02/2022 20:27:01 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=549
06/02/2022 20:27:02 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7991477272727273 on epoch=549
06/02/2022 20:27:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7963203463203463 -> 0.7991477272727273 on epoch=549, global_step=2200
06/02/2022 20:27:04 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/02/2022 20:27:07 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/02/2022 20:27:09 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/02/2022 20:27:11 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/02/2022 20:27:14 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/02/2022 20:27:15 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7916666666666666 on epoch=562
06/02/2022 20:27:17 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/02/2022 20:27:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/02/2022 20:27:22 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/02/2022 20:27:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/02/2022 20:27:26 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=574
06/02/2022 20:27:27 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7565183779605033 on epoch=574
06/02/2022 20:27:30 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/02/2022 20:27:32 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.16 on epoch=579
06/02/2022 20:27:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/02/2022 20:27:37 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/02/2022 20:27:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/02/2022 20:27:40 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7952380952380952 on epoch=587
06/02/2022 20:27:42 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/02/2022 20:27:45 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/02/2022 20:27:47 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/02/2022 20:27:49 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=597
06/02/2022 20:27:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=599
06/02/2022 20:27:53 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7645021645021646 on epoch=599
06/02/2022 20:27:55 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/02/2022 20:27:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/02/2022 20:28:00 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/02/2022 20:28:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/02/2022 20:28:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/02/2022 20:28:05 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7490196078431373 on epoch=612
06/02/2022 20:28:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/02/2022 20:28:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=617
06/02/2022 20:28:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/02/2022 20:28:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.12 on epoch=622
06/02/2022 20:28:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/02/2022 20:28:18 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.779865739399208 on epoch=624
06/02/2022 20:28:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=627
06/02/2022 20:28:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.12 on epoch=629
06/02/2022 20:28:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=632
06/02/2022 20:28:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/02/2022 20:28:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/02/2022 20:28:31 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.7645021645021646 on epoch=637
06/02/2022 20:28:33 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/02/2022 20:28:35 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/02/2022 20:28:38 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/02/2022 20:28:40 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/02/2022 20:28:42 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=649
06/02/2022 20:28:43 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7818836405529954 on epoch=649
06/02/2022 20:28:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/02/2022 20:28:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/02/2022 20:28:50 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/02/2022 20:28:53 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/02/2022 20:28:55 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.10 on epoch=662
06/02/2022 20:28:56 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7973029195498607 on epoch=662
06/02/2022 20:28:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=664
06/02/2022 20:29:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=667
06/02/2022 20:29:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=669
06/02/2022 20:29:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/02/2022 20:29:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=674
06/02/2022 20:29:09 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7952380952380952 on epoch=674
06/02/2022 20:29:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/02/2022 20:29:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=679
06/02/2022 20:29:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/02/2022 20:29:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=684
06/02/2022 20:29:20 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/02/2022 20:29:21 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8127134724857685 on epoch=687
06/02/2022 20:29:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7991477272727273 -> 0.8127134724857685 on epoch=687, global_step=2750
06/02/2022 20:29:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/02/2022 20:29:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=692
06/02/2022 20:29:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=694
06/02/2022 20:29:31 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/02/2022 20:29:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/02/2022 20:29:34 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7796451914098973 on epoch=699
06/02/2022 20:29:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=702
06/02/2022 20:29:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/02/2022 20:29:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/02/2022 20:29:43 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/02/2022 20:29:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/02/2022 20:29:47 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7788952745849298 on epoch=712
06/02/2022 20:29:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/02/2022 20:29:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/02/2022 20:29:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=719
06/02/2022 20:29:56 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/02/2022 20:29:59 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.08 on epoch=724
06/02/2022 20:29:59 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7952380952380952 on epoch=724
06/02/2022 20:30:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
06/02/2022 20:30:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/02/2022 20:30:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/02/2022 20:30:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/02/2022 20:30:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/02/2022 20:30:12 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8142992424242425 on epoch=737
06/02/2022 20:30:12 - INFO - __main__ - Saving model with best Classification-F1: 0.8127134724857685 -> 0.8142992424242425 on epoch=737, global_step=2950
06/02/2022 20:30:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
06/02/2022 20:30:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/02/2022 20:30:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.08 on epoch=744
06/02/2022 20:30:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/02/2022 20:30:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/02/2022 20:30:25 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7952380952380952 on epoch=749
06/02/2022 20:30:25 - INFO - __main__ - save last model!
06/02/2022 20:30:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 20:30:25 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 20:30:25 - INFO - __main__ - Printing 3 examples
06/02/2022 20:30:25 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 20:30:25 - INFO - __main__ - ['others']
06/02/2022 20:30:25 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 20:30:25 - INFO - __main__ - ['others']
06/02/2022 20:30:25 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 20:30:25 - INFO - __main__ - ['others']
06/02/2022 20:30:25 - INFO - __main__ - Tokenizing Input ...
06/02/2022 20:30:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 20:30:25 - INFO - __main__ - Printing 3 examples
06/02/2022 20:30:25 - INFO - __main__ -  [emo] how cause yes am listening
06/02/2022 20:30:25 - INFO - __main__ - ['others']
06/02/2022 20:30:25 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/02/2022 20:30:25 - INFO - __main__ - ['others']
06/02/2022 20:30:25 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/02/2022 20:30:25 - INFO - __main__ - ['others']
06/02/2022 20:30:25 - INFO - __main__ - Tokenizing Input ...
06/02/2022 20:30:25 - INFO - __main__ - Tokenizing Output ...
06/02/2022 20:30:25 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 20:30:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 20:30:25 - INFO - __main__ - Printing 3 examples
06/02/2022 20:30:25 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/02/2022 20:30:25 - INFO - __main__ - ['others']
06/02/2022 20:30:25 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/02/2022 20:30:25 - INFO - __main__ - ['others']
06/02/2022 20:30:25 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/02/2022 20:30:25 - INFO - __main__ - ['others']
06/02/2022 20:30:25 - INFO - __main__ - Tokenizing Input ...
06/02/2022 20:30:25 - INFO - __main__ - Tokenizing Output ...
06/02/2022 20:30:25 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 20:30:27 - INFO - __main__ - Tokenizing Output ...
06/02/2022 20:30:32 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 20:30:40 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 20:30:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 20:30:41 - INFO - __main__ - Starting training!
06/02/2022 20:32:03 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_100_0.5_8_predictions.txt
06/02/2022 20:32:03 - INFO - __main__ - Classification-F1 on test data: 0.4364
06/02/2022 20:32:03 - INFO - __main__ - prefix=emo_16_100, lr=0.5, bsz=8, dev_performance=0.8142992424242425, test_performance=0.43638430142075685
06/02/2022 20:32:03 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.4, bsz=8 ...
06/02/2022 20:32:04 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 20:32:04 - INFO - __main__ - Printing 3 examples
06/02/2022 20:32:04 - INFO - __main__ -  [emo] how cause yes am listening
06/02/2022 20:32:04 - INFO - __main__ - ['others']
06/02/2022 20:32:04 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/02/2022 20:32:04 - INFO - __main__ - ['others']
06/02/2022 20:32:04 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/02/2022 20:32:04 - INFO - __main__ - ['others']
06/02/2022 20:32:04 - INFO - __main__ - Tokenizing Input ...
06/02/2022 20:32:05 - INFO - __main__ - Tokenizing Output ...
06/02/2022 20:32:05 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 20:32:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 20:32:05 - INFO - __main__ - Printing 3 examples
06/02/2022 20:32:05 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/02/2022 20:32:05 - INFO - __main__ - ['others']
06/02/2022 20:32:05 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/02/2022 20:32:05 - INFO - __main__ - ['others']
06/02/2022 20:32:05 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/02/2022 20:32:05 - INFO - __main__ - ['others']
06/02/2022 20:32:05 - INFO - __main__ - Tokenizing Input ...
06/02/2022 20:32:05 - INFO - __main__ - Tokenizing Output ...
06/02/2022 20:32:05 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 20:32:23 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 20:32:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 20:32:24 - INFO - __main__ - Starting training!
06/02/2022 20:32:27 - INFO - __main__ - Step 10 Global step 10 Train loss 4.80 on epoch=2
06/02/2022 20:32:29 - INFO - __main__ - Step 20 Global step 20 Train loss 3.00 on epoch=4
06/02/2022 20:32:32 - INFO - __main__ - Step 30 Global step 30 Train loss 2.43 on epoch=7
06/02/2022 20:32:34 - INFO - __main__ - Step 40 Global step 40 Train loss 1.95 on epoch=9
06/02/2022 20:32:37 - INFO - __main__ - Step 50 Global step 50 Train loss 1.79 on epoch=12
06/02/2022 20:32:38 - INFO - __main__ - Global step 50 Train loss 2.79 Classification-F1 0.05070746247216836 on epoch=12
06/02/2022 20:32:38 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05070746247216836 on epoch=12, global_step=50
06/02/2022 20:32:40 - INFO - __main__ - Step 60 Global step 60 Train loss 1.43 on epoch=14
06/02/2022 20:32:43 - INFO - __main__ - Step 70 Global step 70 Train loss 1.31 on epoch=17
06/02/2022 20:32:45 - INFO - __main__ - Step 80 Global step 80 Train loss 1.25 on epoch=19
06/02/2022 20:32:48 - INFO - __main__ - Step 90 Global step 90 Train loss 1.07 on epoch=22
06/02/2022 20:32:50 - INFO - __main__ - Step 100 Global step 100 Train loss 0.99 on epoch=24
06/02/2022 20:32:51 - INFO - __main__ - Global step 100 Train loss 1.21 Classification-F1 0.5654735763431415 on epoch=24
06/02/2022 20:32:51 - INFO - __main__ - Saving model with best Classification-F1: 0.05070746247216836 -> 0.5654735763431415 on epoch=24, global_step=100
06/02/2022 20:32:53 - INFO - __main__ - Step 110 Global step 110 Train loss 0.80 on epoch=27
06/02/2022 20:32:56 - INFO - __main__ - Step 120 Global step 120 Train loss 0.84 on epoch=29
06/02/2022 20:32:58 - INFO - __main__ - Step 130 Global step 130 Train loss 0.99 on epoch=32
06/02/2022 20:33:00 - INFO - __main__ - Step 140 Global step 140 Train loss 0.80 on epoch=34
06/02/2022 20:33:03 - INFO - __main__ - Step 150 Global step 150 Train loss 0.87 on epoch=37
06/02/2022 20:33:04 - INFO - __main__ - Global step 150 Train loss 0.86 Classification-F1 0.6176142697881827 on epoch=37
06/02/2022 20:33:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5654735763431415 -> 0.6176142697881827 on epoch=37, global_step=150
06/02/2022 20:33:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.67 on epoch=39
06/02/2022 20:33:08 - INFO - __main__ - Step 170 Global step 170 Train loss 0.71 on epoch=42
06/02/2022 20:33:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.63 on epoch=44
06/02/2022 20:33:13 - INFO - __main__ - Step 190 Global step 190 Train loss 0.78 on epoch=47
06/02/2022 20:33:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=49
06/02/2022 20:33:16 - INFO - __main__ - Global step 200 Train loss 0.68 Classification-F1 0.6079032809295968 on epoch=49
06/02/2022 20:33:19 - INFO - __main__ - Step 210 Global step 210 Train loss 0.73 on epoch=52
06/02/2022 20:33:21 - INFO - __main__ - Step 220 Global step 220 Train loss 0.63 on epoch=54
06/02/2022 20:33:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.59 on epoch=57
06/02/2022 20:33:26 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=59
06/02/2022 20:33:28 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=62
06/02/2022 20:33:29 - INFO - __main__ - Global step 250 Train loss 0.63 Classification-F1 0.6149339876961359 on epoch=62
06/02/2022 20:33:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.64 on epoch=64
06/02/2022 20:33:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.63 on epoch=67
06/02/2022 20:33:36 - INFO - __main__ - Step 280 Global step 280 Train loss 0.64 on epoch=69
06/02/2022 20:33:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.56 on epoch=72
06/02/2022 20:33:41 - INFO - __main__ - Step 300 Global step 300 Train loss 0.61 on epoch=74
06/02/2022 20:33:42 - INFO - __main__ - Global step 300 Train loss 0.62 Classification-F1 0.6450088544577885 on epoch=74
06/02/2022 20:33:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6176142697881827 -> 0.6450088544577885 on epoch=74, global_step=300
06/02/2022 20:33:45 - INFO - __main__ - Step 310 Global step 310 Train loss 0.69 on epoch=77
06/02/2022 20:33:47 - INFO - __main__ - Step 320 Global step 320 Train loss 0.55 on epoch=79
06/02/2022 20:33:49 - INFO - __main__ - Step 330 Global step 330 Train loss 0.54 on epoch=82
06/02/2022 20:33:52 - INFO - __main__ - Step 340 Global step 340 Train loss 0.49 on epoch=84
06/02/2022 20:33:54 - INFO - __main__ - Step 350 Global step 350 Train loss 0.53 on epoch=87
06/02/2022 20:33:55 - INFO - __main__ - Global step 350 Train loss 0.56 Classification-F1 0.6066510695187166 on epoch=87
06/02/2022 20:33:57 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=89
06/02/2022 20:34:00 - INFO - __main__ - Step 370 Global step 370 Train loss 0.51 on epoch=92
06/02/2022 20:34:02 - INFO - __main__ - Step 380 Global step 380 Train loss 0.48 on epoch=94
06/02/2022 20:34:05 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=97
06/02/2022 20:34:07 - INFO - __main__ - Step 400 Global step 400 Train loss 0.50 on epoch=99
06/02/2022 20:34:08 - INFO - __main__ - Global step 400 Train loss 0.51 Classification-F1 0.649009009009009 on epoch=99
06/02/2022 20:34:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6450088544577885 -> 0.649009009009009 on epoch=99, global_step=400
06/02/2022 20:34:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.48 on epoch=102
06/02/2022 20:34:13 - INFO - __main__ - Step 420 Global step 420 Train loss 0.50 on epoch=104
06/02/2022 20:34:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.41 on epoch=107
06/02/2022 20:34:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.40 on epoch=109
06/02/2022 20:34:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.37 on epoch=112
06/02/2022 20:34:21 - INFO - __main__ - Global step 450 Train loss 0.43 Classification-F1 0.6990105719707238 on epoch=112
06/02/2022 20:34:21 - INFO - __main__ - Saving model with best Classification-F1: 0.649009009009009 -> 0.6990105719707238 on epoch=112, global_step=450
06/02/2022 20:34:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.51 on epoch=114
06/02/2022 20:34:25 - INFO - __main__ - Step 470 Global step 470 Train loss 0.43 on epoch=117
06/02/2022 20:34:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.37 on epoch=119
06/02/2022 20:34:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.49 on epoch=122
06/02/2022 20:34:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.45 on epoch=124
06/02/2022 20:34:33 - INFO - __main__ - Global step 500 Train loss 0.45 Classification-F1 0.6664230019493178 on epoch=124
06/02/2022 20:34:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.34 on epoch=127
06/02/2022 20:34:38 - INFO - __main__ - Step 520 Global step 520 Train loss 0.41 on epoch=129
06/02/2022 20:34:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.37 on epoch=132
06/02/2022 20:34:43 - INFO - __main__ - Step 540 Global step 540 Train loss 0.37 on epoch=134
06/02/2022 20:34:45 - INFO - __main__ - Step 550 Global step 550 Train loss 0.34 on epoch=137
06/02/2022 20:34:46 - INFO - __main__ - Global step 550 Train loss 0.37 Classification-F1 0.6858509480213334 on epoch=137
06/02/2022 20:34:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.37 on epoch=139
06/02/2022 20:34:51 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=142
06/02/2022 20:34:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.38 on epoch=144
06/02/2022 20:34:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.38 on epoch=147
06/02/2022 20:34:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.27 on epoch=149
06/02/2022 20:34:59 - INFO - __main__ - Global step 600 Train loss 0.35 Classification-F1 0.7026707234617985 on epoch=149
06/02/2022 20:34:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6990105719707238 -> 0.7026707234617985 on epoch=149, global_step=600
06/02/2022 20:35:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.33 on epoch=152
06/02/2022 20:35:04 - INFO - __main__ - Step 620 Global step 620 Train loss 0.26 on epoch=154
06/02/2022 20:35:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.42 on epoch=157
06/02/2022 20:35:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.30 on epoch=159
06/02/2022 20:35:11 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=162
06/02/2022 20:35:12 - INFO - __main__ - Global step 650 Train loss 0.31 Classification-F1 0.7072325732295142 on epoch=162
06/02/2022 20:35:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7026707234617985 -> 0.7072325732295142 on epoch=162, global_step=650
06/02/2022 20:35:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=164
06/02/2022 20:35:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=167
06/02/2022 20:35:19 - INFO - __main__ - Step 680 Global step 680 Train loss 0.35 on epoch=169
06/02/2022 20:35:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=172
06/02/2022 20:35:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.28 on epoch=174
06/02/2022 20:35:25 - INFO - __main__ - Global step 700 Train loss 0.27 Classification-F1 0.7657563025210085 on epoch=174
06/02/2022 20:35:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7072325732295142 -> 0.7657563025210085 on epoch=174, global_step=700
06/02/2022 20:35:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.32 on epoch=177
06/02/2022 20:35:30 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=179
06/02/2022 20:35:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=182
06/02/2022 20:35:34 - INFO - __main__ - Step 740 Global step 740 Train loss 0.31 on epoch=184
06/02/2022 20:35:37 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=187
06/02/2022 20:35:38 - INFO - __main__ - Global step 750 Train loss 0.26 Classification-F1 0.7552357552357553 on epoch=187
06/02/2022 20:35:40 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=189
06/02/2022 20:35:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.26 on epoch=192
06/02/2022 20:35:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.26 on epoch=194
06/02/2022 20:35:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.30 on epoch=197
06/02/2022 20:35:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=199
06/02/2022 20:35:50 - INFO - __main__ - Global step 800 Train loss 0.24 Classification-F1 0.7552357552357553 on epoch=199
06/02/2022 20:35:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=202
06/02/2022 20:35:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.26 on epoch=204
06/02/2022 20:35:58 - INFO - __main__ - Step 830 Global step 830 Train loss 0.23 on epoch=207
06/02/2022 20:36:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.27 on epoch=209
06/02/2022 20:36:02 - INFO - __main__ - Step 850 Global step 850 Train loss 0.26 on epoch=212
06/02/2022 20:36:03 - INFO - __main__ - Global step 850 Train loss 0.27 Classification-F1 0.7361682604076113 on epoch=212
06/02/2022 20:36:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=214
06/02/2022 20:36:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.30 on epoch=217
06/02/2022 20:36:11 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=219
06/02/2022 20:36:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=222
06/02/2022 20:36:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=224
06/02/2022 20:36:16 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.7388503805529667 on epoch=224
06/02/2022 20:36:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=227
06/02/2022 20:36:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=229
06/02/2022 20:36:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=232
06/02/2022 20:36:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=234
06/02/2022 20:36:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=237
06/02/2022 20:36:29 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.7523510971786833 on epoch=237
06/02/2022 20:36:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=239
06/02/2022 20:36:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=242
06/02/2022 20:36:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=244
06/02/2022 20:36:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=247
06/02/2022 20:36:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=249
06/02/2022 20:36:42 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.7546692091742149 on epoch=249
06/02/2022 20:36:44 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=252
06/02/2022 20:36:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.22 on epoch=254
06/02/2022 20:36:49 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=257
06/02/2022 20:36:52 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=259
06/02/2022 20:36:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=262
06/02/2022 20:36:55 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.7695441813088872 on epoch=262
06/02/2022 20:36:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7657563025210085 -> 0.7695441813088872 on epoch=262, global_step=1050
06/02/2022 20:36:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=264
06/02/2022 20:37:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=267
06/02/2022 20:37:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=269
06/02/2022 20:37:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=272
06/02/2022 20:37:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=274
06/02/2022 20:37:08 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.7528869612361073 on epoch=274
06/02/2022 20:37:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=277
06/02/2022 20:37:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=279
06/02/2022 20:37:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=282
06/02/2022 20:37:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=284
06/02/2022 20:37:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=287
06/02/2022 20:37:21 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.7510504201680672 on epoch=287
06/02/2022 20:37:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=289
06/02/2022 20:37:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=292
06/02/2022 20:37:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=294
06/02/2022 20:37:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
06/02/2022 20:37:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=299
06/02/2022 20:37:33 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.7510504201680672 on epoch=299
06/02/2022 20:37:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=302
06/02/2022 20:37:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
06/02/2022 20:37:40 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=307
06/02/2022 20:37:43 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=309
06/02/2022 20:37:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=312
06/02/2022 20:37:46 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.7501322751322751 on epoch=312
06/02/2022 20:37:48 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=314
06/02/2022 20:37:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=317
06/02/2022 20:37:53 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=319
06/02/2022 20:37:56 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=322
06/02/2022 20:37:58 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=324
06/02/2022 20:37:59 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.7368655123339659 on epoch=324
06/02/2022 20:38:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=327
06/02/2022 20:38:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=329
06/02/2022 20:38:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=332
06/02/2022 20:38:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=334
06/02/2022 20:38:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=337
06/02/2022 20:38:12 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.7694361615613987 on epoch=337
06/02/2022 20:38:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/02/2022 20:38:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=342
06/02/2022 20:38:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.14 on epoch=344
06/02/2022 20:38:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=347
06/02/2022 20:38:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=349
06/02/2022 20:38:25 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.7854166666666667 on epoch=349
06/02/2022 20:38:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7695441813088872 -> 0.7854166666666667 on epoch=349, global_step=1400
06/02/2022 20:38:27 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=352
06/02/2022 20:38:29 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=354
06/02/2022 20:38:32 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=357
06/02/2022 20:38:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/02/2022 20:38:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=362
06/02/2022 20:38:37 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7040854978354979 on epoch=362
06/02/2022 20:38:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=364
06/02/2022 20:38:42 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=367
06/02/2022 20:38:45 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/02/2022 20:38:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=372
06/02/2022 20:38:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=374
06/02/2022 20:38:50 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.7596059113300493 on epoch=374
06/02/2022 20:38:53 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=377
06/02/2022 20:38:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=379
06/02/2022 20:38:58 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=382
06/02/2022 20:39:00 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/02/2022 20:39:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=387
06/02/2022 20:39:03 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.7991477272727273 on epoch=387
06/02/2022 20:39:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7854166666666667 -> 0.7991477272727273 on epoch=387, global_step=1550
06/02/2022 20:39:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=389
06/02/2022 20:39:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=392
06/02/2022 20:39:10 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=394
06/02/2022 20:39:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=397
06/02/2022 20:39:15 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
06/02/2022 20:39:16 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7510504201680672 on epoch=399
06/02/2022 20:39:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=402
06/02/2022 20:39:21 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=404
06/02/2022 20:39:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/02/2022 20:39:26 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/02/2022 20:39:28 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=412
06/02/2022 20:39:29 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7548382989559461 on epoch=412
06/02/2022 20:39:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/02/2022 20:39:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=417
06/02/2022 20:39:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/02/2022 20:39:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=422
06/02/2022 20:39:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=424
06/02/2022 20:39:42 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.7553619431643626 on epoch=424
06/02/2022 20:39:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/02/2022 20:39:46 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=429
06/02/2022 20:39:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=432
06/02/2022 20:39:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/02/2022 20:39:54 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=437
06/02/2022 20:39:54 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7370370370370369 on epoch=437
06/02/2022 20:39:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/02/2022 20:39:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=442
06/02/2022 20:40:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=444
06/02/2022 20:40:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=447
06/02/2022 20:40:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=449
06/02/2022 20:40:07 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.7510504201680672 on epoch=449
06/02/2022 20:40:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/02/2022 20:40:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/02/2022 20:40:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=457
06/02/2022 20:40:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=459
06/02/2022 20:40:19 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=462
06/02/2022 20:40:20 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.718721677342367 on epoch=462
06/02/2022 20:40:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/02/2022 20:40:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=467
06/02/2022 20:40:27 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/02/2022 20:40:30 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=472
06/02/2022 20:40:32 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/02/2022 20:40:33 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.7412202380952381 on epoch=474
06/02/2022 20:40:36 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=477
06/02/2022 20:40:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/02/2022 20:40:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/02/2022 20:40:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/02/2022 20:40:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/02/2022 20:40:46 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7180092444317916 on epoch=487
06/02/2022 20:40:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=489
06/02/2022 20:40:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=492
06/02/2022 20:40:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/02/2022 20:40:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/02/2022 20:40:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/02/2022 20:40:59 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7332149818991924 on epoch=499
06/02/2022 20:41:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/02/2022 20:41:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=504
06/02/2022 20:41:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/02/2022 20:41:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=509
06/02/2022 20:41:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=512
06/02/2022 20:41:12 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.7516264570344267 on epoch=512
06/02/2022 20:41:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=514
06/02/2022 20:41:17 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/02/2022 20:41:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/02/2022 20:41:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/02/2022 20:41:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/02/2022 20:41:25 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7307060755336617 on epoch=524
06/02/2022 20:41:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/02/2022 20:41:30 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/02/2022 20:41:32 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=532
06/02/2022 20:41:35 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/02/2022 20:41:37 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/02/2022 20:41:38 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7412202380952381 on epoch=537
06/02/2022 20:41:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=539
06/02/2022 20:41:43 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/02/2022 20:41:45 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=544
06/02/2022 20:41:48 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/02/2022 20:41:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=549
06/02/2022 20:41:51 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7357142857142858 on epoch=549
06/02/2022 20:41:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/02/2022 20:41:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=554
06/02/2022 20:41:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=557
06/02/2022 20:42:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=559
06/02/2022 20:42:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=562
06/02/2022 20:42:04 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.7526574697277031 on epoch=562
06/02/2022 20:42:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/02/2022 20:42:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/02/2022 20:42:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=569
06/02/2022 20:42:14 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/02/2022 20:42:16 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/02/2022 20:42:17 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7564881990285216 on epoch=574
06/02/2022 20:42:20 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/02/2022 20:42:22 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
06/02/2022 20:42:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=582
06/02/2022 20:42:27 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=584
06/02/2022 20:42:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/02/2022 20:42:30 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7264384920634921 on epoch=587
06/02/2022 20:42:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/02/2022 20:42:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/02/2022 20:42:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=594
06/02/2022 20:42:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/02/2022 20:42:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/02/2022 20:42:43 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7412202380952381 on epoch=599
06/02/2022 20:42:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/02/2022 20:42:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/02/2022 20:42:51 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/02/2022 20:42:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/02/2022 20:42:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=612
06/02/2022 20:42:57 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.726234243697479 on epoch=612
06/02/2022 20:42:59 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/02/2022 20:43:01 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/02/2022 20:43:04 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/02/2022 20:43:06 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=622
06/02/2022 20:43:09 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/02/2022 20:43:10 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7246482683982685 on epoch=624
06/02/2022 20:43:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=627
06/02/2022 20:43:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=629
06/02/2022 20:43:17 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/02/2022 20:43:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/02/2022 20:43:22 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/02/2022 20:43:23 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7576248741988454 on epoch=637
06/02/2022 20:43:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/02/2022 20:43:28 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/02/2022 20:43:30 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/02/2022 20:43:33 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/02/2022 20:43:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/02/2022 20:43:36 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7264384920634921 on epoch=649
06/02/2022 20:43:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/02/2022 20:43:41 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/02/2022 20:43:43 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=657
06/02/2022 20:43:46 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/02/2022 20:43:48 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/02/2022 20:43:49 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7349343185550082 on epoch=662
06/02/2022 20:43:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=664
06/02/2022 20:43:54 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=667
06/02/2022 20:43:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/02/2022 20:43:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/02/2022 20:44:01 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=674
06/02/2022 20:44:02 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7547754585705251 on epoch=674
06/02/2022 20:44:05 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/02/2022 20:44:07 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/02/2022 20:44:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=682
06/02/2022 20:44:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=684
06/02/2022 20:44:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/02/2022 20:44:15 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7373695445920304 on epoch=687
06/02/2022 20:44:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=689
06/02/2022 20:44:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/02/2022 20:44:22 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/02/2022 20:44:25 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/02/2022 20:44:27 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/02/2022 20:44:28 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7199872286079183 on epoch=699
06/02/2022 20:44:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=702
06/02/2022 20:44:33 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/02/2022 20:44:35 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/02/2022 20:44:38 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/02/2022 20:44:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/02/2022 20:44:41 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7199452764976959 on epoch=712
06/02/2022 20:44:44 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/02/2022 20:44:46 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=717
06/02/2022 20:44:48 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/02/2022 20:44:51 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/02/2022 20:44:53 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/02/2022 20:44:54 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7547754585705251 on epoch=724
06/02/2022 20:44:56 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
06/02/2022 20:44:59 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=729
06/02/2022 20:45:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=732
06/02/2022 20:45:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/02/2022 20:45:06 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=737
06/02/2022 20:45:07 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7679719395089414 on epoch=737
06/02/2022 20:45:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/02/2022 20:45:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/02/2022 20:45:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/02/2022 20:45:17 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=747
06/02/2022 20:45:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=749
06/02/2022 20:45:20 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.737505954576188 on epoch=749
06/02/2022 20:45:20 - INFO - __main__ - save last model!
06/02/2022 20:45:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 20:45:20 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 20:45:20 - INFO - __main__ - Printing 3 examples
06/02/2022 20:45:20 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 20:45:20 - INFO - __main__ - ['others']
06/02/2022 20:45:20 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 20:45:20 - INFO - __main__ - ['others']
06/02/2022 20:45:20 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 20:45:20 - INFO - __main__ - ['others']
06/02/2022 20:45:20 - INFO - __main__ - Tokenizing Input ...
06/02/2022 20:45:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 20:45:20 - INFO - __main__ - Printing 3 examples
06/02/2022 20:45:20 - INFO - __main__ -  [emo] how cause yes am listening
06/02/2022 20:45:20 - INFO - __main__ - ['others']
06/02/2022 20:45:20 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/02/2022 20:45:20 - INFO - __main__ - ['others']
06/02/2022 20:45:20 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/02/2022 20:45:20 - INFO - __main__ - ['others']
06/02/2022 20:45:20 - INFO - __main__ - Tokenizing Input ...
06/02/2022 20:45:20 - INFO - __main__ - Tokenizing Output ...
06/02/2022 20:45:20 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 20:45:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 20:45:20 - INFO - __main__ - Printing 3 examples
06/02/2022 20:45:20 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/02/2022 20:45:20 - INFO - __main__ - ['others']
06/02/2022 20:45:20 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/02/2022 20:45:20 - INFO - __main__ - ['others']
06/02/2022 20:45:20 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/02/2022 20:45:20 - INFO - __main__ - ['others']
06/02/2022 20:45:20 - INFO - __main__ - Tokenizing Input ...
06/02/2022 20:45:20 - INFO - __main__ - Tokenizing Output ...
06/02/2022 20:45:20 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 20:45:22 - INFO - __main__ - Tokenizing Output ...
06/02/2022 20:45:27 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 20:45:39 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 20:45:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 20:45:40 - INFO - __main__ - Starting training!
06/02/2022 20:46:51 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_100_0.4_8_predictions.txt
06/02/2022 20:46:51 - INFO - __main__ - Classification-F1 on test data: 0.3486
06/02/2022 20:46:51 - INFO - __main__ - prefix=emo_16_100, lr=0.4, bsz=8, dev_performance=0.7991477272727273, test_performance=0.3486237377271283
06/02/2022 20:46:51 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.3, bsz=8 ...
06/02/2022 20:46:52 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 20:46:52 - INFO - __main__ - Printing 3 examples
06/02/2022 20:46:52 - INFO - __main__ -  [emo] how cause yes am listening
06/02/2022 20:46:52 - INFO - __main__ - ['others']
06/02/2022 20:46:52 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/02/2022 20:46:52 - INFO - __main__ - ['others']
06/02/2022 20:46:52 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/02/2022 20:46:52 - INFO - __main__ - ['others']
06/02/2022 20:46:52 - INFO - __main__ - Tokenizing Input ...
06/02/2022 20:46:52 - INFO - __main__ - Tokenizing Output ...
06/02/2022 20:46:52 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 20:46:52 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 20:46:52 - INFO - __main__ - Printing 3 examples
06/02/2022 20:46:52 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/02/2022 20:46:52 - INFO - __main__ - ['others']
06/02/2022 20:46:52 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/02/2022 20:46:52 - INFO - __main__ - ['others']
06/02/2022 20:46:52 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/02/2022 20:46:52 - INFO - __main__ - ['others']
06/02/2022 20:46:52 - INFO - __main__ - Tokenizing Input ...
06/02/2022 20:46:52 - INFO - __main__ - Tokenizing Output ...
06/02/2022 20:46:52 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 20:47:11 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 20:47:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 20:47:12 - INFO - __main__ - Starting training!
06/02/2022 20:47:14 - INFO - __main__ - Step 10 Global step 10 Train loss 4.50 on epoch=2
06/02/2022 20:47:17 - INFO - __main__ - Step 20 Global step 20 Train loss 3.12 on epoch=4
06/02/2022 20:47:19 - INFO - __main__ - Step 30 Global step 30 Train loss 2.97 on epoch=7
06/02/2022 20:47:22 - INFO - __main__ - Step 40 Global step 40 Train loss 2.37 on epoch=9
06/02/2022 20:47:24 - INFO - __main__ - Step 50 Global step 50 Train loss 2.06 on epoch=12
06/02/2022 20:47:25 - INFO - __main__ - Global step 50 Train loss 3.00 Classification-F1 0.0 on epoch=12
06/02/2022 20:47:25 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/02/2022 20:47:28 - INFO - __main__ - Step 60 Global step 60 Train loss 1.86 on epoch=14
06/02/2022 20:47:30 - INFO - __main__ - Step 70 Global step 70 Train loss 1.72 on epoch=17
06/02/2022 20:47:33 - INFO - __main__ - Step 80 Global step 80 Train loss 1.39 on epoch=19
06/02/2022 20:47:35 - INFO - __main__ - Step 90 Global step 90 Train loss 1.45 on epoch=22
06/02/2022 20:47:38 - INFO - __main__ - Step 100 Global step 100 Train loss 1.19 on epoch=24
06/02/2022 20:47:38 - INFO - __main__ - Global step 100 Train loss 1.52 Classification-F1 0.31295546558704446 on epoch=24
06/02/2022 20:47:38 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.31295546558704446 on epoch=24, global_step=100
06/02/2022 20:47:41 - INFO - __main__ - Step 110 Global step 110 Train loss 1.10 on epoch=27
06/02/2022 20:47:43 - INFO - __main__ - Step 120 Global step 120 Train loss 0.97 on epoch=29
06/02/2022 20:47:46 - INFO - __main__ - Step 130 Global step 130 Train loss 0.99 on epoch=32
06/02/2022 20:47:48 - INFO - __main__ - Step 140 Global step 140 Train loss 0.83 on epoch=34
06/02/2022 20:47:51 - INFO - __main__ - Step 150 Global step 150 Train loss 0.97 on epoch=37
06/02/2022 20:47:52 - INFO - __main__ - Global step 150 Train loss 0.97 Classification-F1 0.5068677792041079 on epoch=37
06/02/2022 20:47:52 - INFO - __main__ - Saving model with best Classification-F1: 0.31295546558704446 -> 0.5068677792041079 on epoch=37, global_step=150
06/02/2022 20:47:54 - INFO - __main__ - Step 160 Global step 160 Train loss 0.76 on epoch=39
06/02/2022 20:47:57 - INFO - __main__ - Step 170 Global step 170 Train loss 0.82 on epoch=42
06/02/2022 20:47:59 - INFO - __main__ - Step 180 Global step 180 Train loss 0.86 on epoch=44
06/02/2022 20:48:02 - INFO - __main__ - Step 190 Global step 190 Train loss 0.78 on epoch=47
06/02/2022 20:48:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.83 on epoch=49
06/02/2022 20:48:05 - INFO - __main__ - Global step 200 Train loss 0.81 Classification-F1 0.6076633698916307 on epoch=49
06/02/2022 20:48:05 - INFO - __main__ - Saving model with best Classification-F1: 0.5068677792041079 -> 0.6076633698916307 on epoch=49, global_step=200
06/02/2022 20:48:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.73 on epoch=52
06/02/2022 20:48:10 - INFO - __main__ - Step 220 Global step 220 Train loss 0.75 on epoch=54
06/02/2022 20:48:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.66 on epoch=57
06/02/2022 20:48:15 - INFO - __main__ - Step 240 Global step 240 Train loss 0.69 on epoch=59
06/02/2022 20:48:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.76 on epoch=62
06/02/2022 20:48:18 - INFO - __main__ - Global step 250 Train loss 0.72 Classification-F1 0.5722222222222222 on epoch=62
06/02/2022 20:48:20 - INFO - __main__ - Step 260 Global step 260 Train loss 0.55 on epoch=64
06/02/2022 20:48:23 - INFO - __main__ - Step 270 Global step 270 Train loss 0.68 on epoch=67
06/02/2022 20:48:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.59 on epoch=69
06/02/2022 20:48:28 - INFO - __main__ - Step 290 Global step 290 Train loss 0.65 on epoch=72
06/02/2022 20:48:30 - INFO - __main__ - Step 300 Global step 300 Train loss 0.72 on epoch=74
06/02/2022 20:48:31 - INFO - __main__ - Global step 300 Train loss 0.64 Classification-F1 0.5660952786911866 on epoch=74
06/02/2022 20:48:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.57 on epoch=77
06/02/2022 20:48:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.58 on epoch=79
06/02/2022 20:48:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.61 on epoch=82
06/02/2022 20:48:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.66 on epoch=84
06/02/2022 20:48:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.64 on epoch=87
06/02/2022 20:48:44 - INFO - __main__ - Global step 350 Train loss 0.61 Classification-F1 0.5851924651924651 on epoch=87
06/02/2022 20:48:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.60 on epoch=89
06/02/2022 20:48:49 - INFO - __main__ - Step 370 Global step 370 Train loss 0.57 on epoch=92
06/02/2022 20:48:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.66 on epoch=94
06/02/2022 20:48:54 - INFO - __main__ - Step 390 Global step 390 Train loss 0.60 on epoch=97
06/02/2022 20:48:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.63 on epoch=99
06/02/2022 20:48:57 - INFO - __main__ - Global step 400 Train loss 0.61 Classification-F1 0.5920439209912894 on epoch=99
06/02/2022 20:49:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.71 on epoch=102
06/02/2022 20:49:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.47 on epoch=104
06/02/2022 20:49:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.57 on epoch=107
06/02/2022 20:49:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.52 on epoch=109
06/02/2022 20:49:10 - INFO - __main__ - Step 450 Global step 450 Train loss 0.61 on epoch=112
06/02/2022 20:49:10 - INFO - __main__ - Global step 450 Train loss 0.58 Classification-F1 0.5969586976846506 on epoch=112
06/02/2022 20:49:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.56 on epoch=114
06/02/2022 20:49:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.51 on epoch=117
06/02/2022 20:49:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.52 on epoch=119
06/02/2022 20:49:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.42 on epoch=122
06/02/2022 20:49:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.47 on epoch=124
06/02/2022 20:49:24 - INFO - __main__ - Global step 500 Train loss 0.50 Classification-F1 0.6389794608472401 on epoch=124
06/02/2022 20:49:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6076633698916307 -> 0.6389794608472401 on epoch=124, global_step=500
06/02/2022 20:49:26 - INFO - __main__ - Step 510 Global step 510 Train loss 0.42 on epoch=127
06/02/2022 20:49:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.58 on epoch=129
06/02/2022 20:49:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.54 on epoch=132
06/02/2022 20:49:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.54 on epoch=134
06/02/2022 20:49:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.44 on epoch=137
06/02/2022 20:49:37 - INFO - __main__ - Global step 550 Train loss 0.50 Classification-F1 0.6369653011332171 on epoch=137
06/02/2022 20:49:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.48 on epoch=139
06/02/2022 20:49:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.53 on epoch=142
06/02/2022 20:49:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.49 on epoch=144
06/02/2022 20:49:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.39 on epoch=147
06/02/2022 20:49:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.49 on epoch=149
06/02/2022 20:49:50 - INFO - __main__ - Global step 600 Train loss 0.48 Classification-F1 0.6936062378167642 on epoch=149
06/02/2022 20:49:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6389794608472401 -> 0.6936062378167642 on epoch=149, global_step=600
06/02/2022 20:49:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.41 on epoch=152
06/02/2022 20:49:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.47 on epoch=154
06/02/2022 20:49:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.47 on epoch=157
06/02/2022 20:49:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=159
06/02/2022 20:50:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.41 on epoch=162
06/02/2022 20:50:03 - INFO - __main__ - Global step 650 Train loss 0.41 Classification-F1 0.6725517725517726 on epoch=162
06/02/2022 20:50:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.39 on epoch=164
06/02/2022 20:50:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.35 on epoch=167
06/02/2022 20:50:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.41 on epoch=169
06/02/2022 20:50:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.48 on epoch=172
06/02/2022 20:50:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.39 on epoch=174
06/02/2022 20:50:16 - INFO - __main__ - Global step 700 Train loss 0.40 Classification-F1 0.6526526526526526 on epoch=174
06/02/2022 20:50:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.45 on epoch=177
06/02/2022 20:50:21 - INFO - __main__ - Step 720 Global step 720 Train loss 0.45 on epoch=179
06/02/2022 20:50:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.39 on epoch=182
06/02/2022 20:50:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.36 on epoch=184
06/02/2022 20:50:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.39 on epoch=187
06/02/2022 20:50:29 - INFO - __main__ - Global step 750 Train loss 0.41 Classification-F1 0.6880632159831269 on epoch=187
06/02/2022 20:50:31 - INFO - __main__ - Step 760 Global step 760 Train loss 0.31 on epoch=189
06/02/2022 20:50:34 - INFO - __main__ - Step 770 Global step 770 Train loss 0.41 on epoch=192
06/02/2022 20:50:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=194
06/02/2022 20:50:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.32 on epoch=197
06/02/2022 20:50:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.35 on epoch=199
06/02/2022 20:50:42 - INFO - __main__ - Global step 800 Train loss 0.34 Classification-F1 0.714021164021164 on epoch=199
06/02/2022 20:50:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6936062378167642 -> 0.714021164021164 on epoch=199, global_step=800
06/02/2022 20:50:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=202
06/02/2022 20:50:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.28 on epoch=204
06/02/2022 20:50:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.39 on epoch=207
06/02/2022 20:50:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.34 on epoch=209
06/02/2022 20:50:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.40 on epoch=212
06/02/2022 20:50:55 - INFO - __main__ - Global step 850 Train loss 0.34 Classification-F1 0.714021164021164 on epoch=212
06/02/2022 20:50:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.30 on epoch=214
06/02/2022 20:51:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.29 on epoch=217
06/02/2022 20:51:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.28 on epoch=219
06/02/2022 20:51:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.29 on epoch=222
06/02/2022 20:51:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=224
06/02/2022 20:51:08 - INFO - __main__ - Global step 900 Train loss 0.27 Classification-F1 0.7312741312741313 on epoch=224
06/02/2022 20:51:08 - INFO - __main__ - Saving model with best Classification-F1: 0.714021164021164 -> 0.7312741312741313 on epoch=224, global_step=900
06/02/2022 20:51:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=227
06/02/2022 20:51:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.29 on epoch=229
06/02/2022 20:51:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.25 on epoch=232
06/02/2022 20:51:18 - INFO - __main__ - Step 940 Global step 940 Train loss 0.26 on epoch=234
06/02/2022 20:51:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.29 on epoch=237
06/02/2022 20:51:21 - INFO - __main__ - Global step 950 Train loss 0.27 Classification-F1 0.7321428571428571 on epoch=237
06/02/2022 20:51:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7312741312741313 -> 0.7321428571428571 on epoch=237, global_step=950
06/02/2022 20:51:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.30 on epoch=239
06/02/2022 20:51:26 - INFO - __main__ - Step 970 Global step 970 Train loss 0.26 on epoch=242
06/02/2022 20:51:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.19 on epoch=244
06/02/2022 20:51:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.24 on epoch=247
06/02/2022 20:51:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.26 on epoch=249
06/02/2022 20:51:34 - INFO - __main__ - Global step 1000 Train loss 0.25 Classification-F1 0.7363523398006157 on epoch=249
06/02/2022 20:51:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7321428571428571 -> 0.7363523398006157 on epoch=249, global_step=1000
06/02/2022 20:51:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.23 on epoch=252
06/02/2022 20:51:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.24 on epoch=254
06/02/2022 20:51:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.28 on epoch=257
06/02/2022 20:51:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.28 on epoch=259
06/02/2022 20:51:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.24 on epoch=262
06/02/2022 20:51:47 - INFO - __main__ - Global step 1050 Train loss 0.26 Classification-F1 0.7332633053221288 on epoch=262
06/02/2022 20:51:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.25 on epoch=264
06/02/2022 20:51:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.32 on epoch=267
06/02/2022 20:51:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=269
06/02/2022 20:51:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=272
06/02/2022 20:52:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.24 on epoch=274
06/02/2022 20:52:00 - INFO - __main__ - Global step 1100 Train loss 0.23 Classification-F1 0.7523510971786833 on epoch=274
06/02/2022 20:52:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7363523398006157 -> 0.7523510971786833 on epoch=274, global_step=1100
06/02/2022 20:52:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.26 on epoch=277
06/02/2022 20:52:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=279
06/02/2022 20:52:08 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.29 on epoch=282
06/02/2022 20:52:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.24 on epoch=284
06/02/2022 20:52:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.19 on epoch=287
06/02/2022 20:52:14 - INFO - __main__ - Global step 1150 Train loss 0.24 Classification-F1 0.7505398154812537 on epoch=287
06/02/2022 20:52:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.25 on epoch=289
06/02/2022 20:52:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.17 on epoch=292
06/02/2022 20:52:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.25 on epoch=294
06/02/2022 20:52:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=297
06/02/2022 20:52:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.19 on epoch=299
06/02/2022 20:52:27 - INFO - __main__ - Global step 1200 Train loss 0.21 Classification-F1 0.745006089833676 on epoch=299
06/02/2022 20:52:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=302
06/02/2022 20:52:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=304
06/02/2022 20:52:34 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.21 on epoch=307
06/02/2022 20:52:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=309
06/02/2022 20:52:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.19 on epoch=312
06/02/2022 20:52:40 - INFO - __main__ - Global step 1250 Train loss 0.19 Classification-F1 0.7607142857142858 on epoch=312
06/02/2022 20:52:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7523510971786833 -> 0.7607142857142858 on epoch=312, global_step=1250
06/02/2022 20:52:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.21 on epoch=314
06/02/2022 20:52:45 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=317
06/02/2022 20:52:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=319
06/02/2022 20:52:50 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.14 on epoch=322
06/02/2022 20:52:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=324
06/02/2022 20:52:53 - INFO - __main__ - Global step 1300 Train loss 0.16 Classification-F1 0.7793103448275863 on epoch=324
06/02/2022 20:52:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7607142857142858 -> 0.7793103448275863 on epoch=324, global_step=1300
06/02/2022 20:52:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.22 on epoch=327
06/02/2022 20:52:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.20 on epoch=329
06/02/2022 20:53:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.23 on epoch=332
06/02/2022 20:53:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.25 on epoch=334
06/02/2022 20:53:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.17 on epoch=337
06/02/2022 20:53:06 - INFO - __main__ - Global step 1350 Train loss 0.21 Classification-F1 0.721880954576188 on epoch=337
06/02/2022 20:53:09 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=339
06/02/2022 20:53:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.19 on epoch=342
06/02/2022 20:53:14 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.17 on epoch=344
06/02/2022 20:53:16 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=347
06/02/2022 20:53:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.18 on epoch=349
06/02/2022 20:53:19 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.7485632183908046 on epoch=349
06/02/2022 20:53:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.15 on epoch=352
06/02/2022 20:53:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=354
06/02/2022 20:53:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=357
06/02/2022 20:53:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=359
06/02/2022 20:53:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=362
06/02/2022 20:53:33 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.7455182072829132 on epoch=362
06/02/2022 20:53:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.20 on epoch=364
06/02/2022 20:53:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=367
06/02/2022 20:53:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=369
06/02/2022 20:53:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=372
06/02/2022 20:53:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.24 on epoch=374
06/02/2022 20:53:46 - INFO - __main__ - Global step 1500 Train loss 0.14 Classification-F1 0.727910052910053 on epoch=374
06/02/2022 20:53:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=377
06/02/2022 20:53:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=379
06/02/2022 20:53:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=382
06/02/2022 20:53:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.12 on epoch=384
06/02/2022 20:53:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.16 on epoch=387
06/02/2022 20:53:59 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.7523510971786835 on epoch=387
06/02/2022 20:54:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.15 on epoch=389
06/02/2022 20:54:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=392
06/02/2022 20:54:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=394
06/02/2022 20:54:09 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.13 on epoch=397
06/02/2022 20:54:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=399
06/02/2022 20:54:12 - INFO - __main__ - Global step 1600 Train loss 0.12 Classification-F1 0.7687838066260988 on epoch=399
06/02/2022 20:54:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=402
06/02/2022 20:54:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.11 on epoch=404
06/02/2022 20:54:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=407
06/02/2022 20:54:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=409
06/02/2022 20:54:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=412
06/02/2022 20:54:25 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.7687838066260988 on epoch=412
06/02/2022 20:54:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=414
06/02/2022 20:54:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=417
06/02/2022 20:54:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=419
06/02/2022 20:54:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=422
06/02/2022 20:54:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=424
06/02/2022 20:54:38 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.7804541356772594 on epoch=424
06/02/2022 20:54:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7793103448275863 -> 0.7804541356772594 on epoch=424, global_step=1700
06/02/2022 20:54:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=427
06/02/2022 20:54:43 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/02/2022 20:54:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=432
06/02/2022 20:54:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=434
06/02/2022 20:54:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.13 on epoch=437
06/02/2022 20:54:51 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.7228484497247174 on epoch=437
06/02/2022 20:54:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.13 on epoch=439
06/02/2022 20:54:56 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=442
06/02/2022 20:54:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=444
06/02/2022 20:55:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=447
06/02/2022 20:55:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=449
06/02/2022 20:55:05 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.7493238674780256 on epoch=449
06/02/2022 20:55:07 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=452
06/02/2022 20:55:09 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/02/2022 20:55:12 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=457
06/02/2022 20:55:14 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=459
06/02/2022 20:55:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.15 on epoch=462
06/02/2022 20:55:18 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.7691129764065336 on epoch=462
06/02/2022 20:55:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=464
06/02/2022 20:55:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.14 on epoch=467
06/02/2022 20:55:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=469
06/02/2022 20:55:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=472
06/02/2022 20:55:30 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=474
06/02/2022 20:55:31 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.7980581678857541 on epoch=474
06/02/2022 20:55:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7804541356772594 -> 0.7980581678857541 on epoch=474, global_step=1900
06/02/2022 20:55:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=477
06/02/2022 20:55:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/02/2022 20:55:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=482
06/02/2022 20:55:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=484
06/02/2022 20:55:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=487
06/02/2022 20:55:44 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.7691129764065336 on epoch=487
06/02/2022 20:55:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=489
06/02/2022 20:55:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=492
06/02/2022 20:55:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
06/02/2022 20:55:54 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=497
06/02/2022 20:55:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/02/2022 20:55:57 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7520162082321793 on epoch=499
06/02/2022 20:56:00 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=502
06/02/2022 20:56:02 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=504
06/02/2022 20:56:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=507
06/02/2022 20:56:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/02/2022 20:56:10 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/02/2022 20:56:11 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7491688660552758 on epoch=512
06/02/2022 20:56:13 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=514
06/02/2022 20:56:16 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=517
06/02/2022 20:56:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=519
06/02/2022 20:56:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.10 on epoch=522
06/02/2022 20:56:23 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=524
06/02/2022 20:56:24 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.7965324060658746 on epoch=524
06/02/2022 20:56:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=527
06/02/2022 20:56:29 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.10 on epoch=529
06/02/2022 20:56:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=532
06/02/2022 20:56:34 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=534
06/02/2022 20:56:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/02/2022 20:56:37 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.782906652734239 on epoch=537
06/02/2022 20:56:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=539
06/02/2022 20:56:42 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=542
06/02/2022 20:56:44 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/02/2022 20:56:47 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=547
06/02/2022 20:56:49 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=549
06/02/2022 20:56:50 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.7675587925587926 on epoch=549
06/02/2022 20:56:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=552
06/02/2022 20:56:55 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=554
06/02/2022 20:56:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=557
06/02/2022 20:57:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=559
06/02/2022 20:57:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=562
06/02/2022 20:57:03 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.7544472273998135 on epoch=562
06/02/2022 20:57:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.11 on epoch=564
06/02/2022 20:57:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=567
06/02/2022 20:57:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=569
06/02/2022 20:57:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/02/2022 20:57:16 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/02/2022 20:57:17 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7526486019429567 on epoch=574
06/02/2022 20:57:19 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=577
06/02/2022 20:57:22 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
06/02/2022 20:57:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=582
06/02/2022 20:57:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/02/2022 20:57:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=587
06/02/2022 20:57:30 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7526486019429567 on epoch=587
06/02/2022 20:57:32 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=589
06/02/2022 20:57:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=592
06/02/2022 20:57:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=594
06/02/2022 20:57:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/02/2022 20:57:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/02/2022 20:57:43 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7328185328185327 on epoch=599
06/02/2022 20:57:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=602
06/02/2022 20:57:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/02/2022 20:57:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=607
06/02/2022 20:57:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/02/2022 20:57:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=612
06/02/2022 20:57:56 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.7504003931488719 on epoch=612
06/02/2022 20:57:59 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/02/2022 20:58:01 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/02/2022 20:58:04 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
06/02/2022 20:58:06 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=622
06/02/2022 20:58:09 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/02/2022 20:58:09 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7793103448275863 on epoch=624
06/02/2022 20:58:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=627
06/02/2022 20:58:14 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=629
06/02/2022 20:58:17 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=632
06/02/2022 20:58:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=634
06/02/2022 20:58:22 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=637
06/02/2022 20:58:23 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.7371995820271684 on epoch=637
06/02/2022 20:58:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=639
06/02/2022 20:58:28 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/02/2022 20:58:30 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=644
06/02/2022 20:58:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=647
06/02/2022 20:58:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=649
06/02/2022 20:58:36 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7364529682840878 on epoch=649
06/02/2022 20:58:38 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/02/2022 20:58:41 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/02/2022 20:58:43 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=657
06/02/2022 20:58:46 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.10 on epoch=659
06/02/2022 20:58:48 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/02/2022 20:58:49 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7209383753501399 on epoch=662
06/02/2022 20:58:51 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=664
06/02/2022 20:58:54 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/02/2022 20:58:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=669
06/02/2022 20:58:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=672
06/02/2022 20:59:01 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/02/2022 20:59:02 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7208945696848922 on epoch=674
06/02/2022 20:59:05 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/02/2022 20:59:07 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/02/2022 20:59:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.12 on epoch=682
06/02/2022 20:59:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/02/2022 20:59:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/02/2022 20:59:15 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7328185328185327 on epoch=687
06/02/2022 20:59:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/02/2022 20:59:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.08 on epoch=692
06/02/2022 20:59:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=694
06/02/2022 20:59:25 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/02/2022 20:59:28 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/02/2022 20:59:29 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7367018398268399 on epoch=699
06/02/2022 20:59:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/02/2022 20:59:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/02/2022 20:59:36 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=707
06/02/2022 20:59:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.08 on epoch=709
06/02/2022 20:59:41 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.09 on epoch=712
06/02/2022 20:59:42 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7328185328185327 on epoch=712
06/02/2022 20:59:44 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/02/2022 20:59:47 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=717
06/02/2022 20:59:49 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=719
06/02/2022 20:59:52 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/02/2022 20:59:54 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/02/2022 20:59:55 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7209383753501399 on epoch=724
06/02/2022 20:59:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
06/02/2022 21:00:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.06 on epoch=729
06/02/2022 21:00:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/02/2022 21:00:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/02/2022 21:00:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
06/02/2022 21:00:08 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7513731787925336 on epoch=737
06/02/2022 21:00:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
06/02/2022 21:00:13 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.08 on epoch=742
06/02/2022 21:00:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=744
06/02/2022 21:00:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=747
06/02/2022 21:00:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/02/2022 21:00:21 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7355090311986863 on epoch=749
06/02/2022 21:00:21 - INFO - __main__ - save last model!
06/02/2022 21:00:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 21:00:21 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 21:00:21 - INFO - __main__ - Printing 3 examples
06/02/2022 21:00:21 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 21:00:21 - INFO - __main__ - ['others']
06/02/2022 21:00:21 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 21:00:21 - INFO - __main__ - ['others']
06/02/2022 21:00:21 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 21:00:21 - INFO - __main__ - ['others']
06/02/2022 21:00:21 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:00:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:00:21 - INFO - __main__ - Printing 3 examples
06/02/2022 21:00:21 - INFO - __main__ -  [emo] how cause yes am listening
06/02/2022 21:00:21 - INFO - __main__ - ['others']
06/02/2022 21:00:21 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/02/2022 21:00:21 - INFO - __main__ - ['others']
06/02/2022 21:00:21 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/02/2022 21:00:21 - INFO - __main__ - ['others']
06/02/2022 21:00:21 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:00:22 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:00:22 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 21:00:22 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:00:22 - INFO - __main__ - Printing 3 examples
06/02/2022 21:00:22 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/02/2022 21:00:22 - INFO - __main__ - ['others']
06/02/2022 21:00:22 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/02/2022 21:00:22 - INFO - __main__ - ['others']
06/02/2022 21:00:22 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/02/2022 21:00:22 - INFO - __main__ - ['others']
06/02/2022 21:00:22 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:00:22 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:00:22 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 21:00:23 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:00:29 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 21:00:37 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 21:00:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 21:00:38 - INFO - __main__ - Starting training!
06/02/2022 21:01:59 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_100_0.3_8_predictions.txt
06/02/2022 21:01:59 - INFO - __main__ - Classification-F1 on test data: 0.4302
06/02/2022 21:02:00 - INFO - __main__ - prefix=emo_16_100, lr=0.3, bsz=8, dev_performance=0.7980581678857541, test_performance=0.43018636636954927
06/02/2022 21:02:00 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.2, bsz=8 ...
06/02/2022 21:02:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:02:00 - INFO - __main__ - Printing 3 examples
06/02/2022 21:02:00 - INFO - __main__ -  [emo] how cause yes am listening
06/02/2022 21:02:00 - INFO - __main__ - ['others']
06/02/2022 21:02:00 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/02/2022 21:02:00 - INFO - __main__ - ['others']
06/02/2022 21:02:00 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/02/2022 21:02:00 - INFO - __main__ - ['others']
06/02/2022 21:02:00 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:02:00 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:02:01 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 21:02:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:02:01 - INFO - __main__ - Printing 3 examples
06/02/2022 21:02:01 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/02/2022 21:02:01 - INFO - __main__ - ['others']
06/02/2022 21:02:01 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/02/2022 21:02:01 - INFO - __main__ - ['others']
06/02/2022 21:02:01 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/02/2022 21:02:01 - INFO - __main__ - ['others']
06/02/2022 21:02:01 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:02:01 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:02:01 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 21:02:16 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 21:02:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 21:02:16 - INFO - __main__ - Starting training!
06/02/2022 21:02:19 - INFO - __main__ - Step 10 Global step 10 Train loss 4.60 on epoch=2
06/02/2022 21:02:22 - INFO - __main__ - Step 20 Global step 20 Train loss 3.54 on epoch=4
06/02/2022 21:02:24 - INFO - __main__ - Step 30 Global step 30 Train loss 3.22 on epoch=7
06/02/2022 21:02:26 - INFO - __main__ - Step 40 Global step 40 Train loss 2.69 on epoch=9
06/02/2022 21:02:29 - INFO - __main__ - Step 50 Global step 50 Train loss 2.47 on epoch=12
06/02/2022 21:02:30 - INFO - __main__ - Global step 50 Train loss 3.31 Classification-F1 0.0 on epoch=12
06/02/2022 21:02:30 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/02/2022 21:02:32 - INFO - __main__ - Step 60 Global step 60 Train loss 2.19 on epoch=14
06/02/2022 21:02:35 - INFO - __main__ - Step 70 Global step 70 Train loss 2.20 on epoch=17
06/02/2022 21:02:37 - INFO - __main__ - Step 80 Global step 80 Train loss 1.81 on epoch=19
06/02/2022 21:02:39 - INFO - __main__ - Step 90 Global step 90 Train loss 1.80 on epoch=22
06/02/2022 21:02:42 - INFO - __main__ - Step 100 Global step 100 Train loss 1.47 on epoch=24
06/02/2022 21:02:43 - INFO - __main__ - Global step 100 Train loss 1.90 Classification-F1 0.0557207498383969 on epoch=24
06/02/2022 21:02:43 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0557207498383969 on epoch=24, global_step=100
06/02/2022 21:02:45 - INFO - __main__ - Step 110 Global step 110 Train loss 1.53 on epoch=27
06/02/2022 21:02:48 - INFO - __main__ - Step 120 Global step 120 Train loss 1.35 on epoch=29
06/02/2022 21:02:50 - INFO - __main__ - Step 130 Global step 130 Train loss 1.30 on epoch=32
06/02/2022 21:02:52 - INFO - __main__ - Step 140 Global step 140 Train loss 1.13 on epoch=34
06/02/2022 21:02:55 - INFO - __main__ - Step 150 Global step 150 Train loss 1.27 on epoch=37
06/02/2022 21:02:56 - INFO - __main__ - Global step 150 Train loss 1.32 Classification-F1 0.2698834965460952 on epoch=37
06/02/2022 21:02:56 - INFO - __main__ - Saving model with best Classification-F1: 0.0557207498383969 -> 0.2698834965460952 on epoch=37, global_step=150
06/02/2022 21:02:58 - INFO - __main__ - Step 160 Global step 160 Train loss 1.09 on epoch=39
06/02/2022 21:03:00 - INFO - __main__ - Step 170 Global step 170 Train loss 1.04 on epoch=42
06/02/2022 21:03:03 - INFO - __main__ - Step 180 Global step 180 Train loss 0.96 on epoch=44
06/02/2022 21:03:05 - INFO - __main__ - Step 190 Global step 190 Train loss 0.87 on epoch=47
06/02/2022 21:03:08 - INFO - __main__ - Step 200 Global step 200 Train loss 0.86 on epoch=49
06/02/2022 21:03:09 - INFO - __main__ - Global step 200 Train loss 0.96 Classification-F1 0.5559440559440559 on epoch=49
06/02/2022 21:03:09 - INFO - __main__ - Saving model with best Classification-F1: 0.2698834965460952 -> 0.5559440559440559 on epoch=49, global_step=200
06/02/2022 21:03:11 - INFO - __main__ - Step 210 Global step 210 Train loss 0.90 on epoch=52
06/02/2022 21:03:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.76 on epoch=54
06/02/2022 21:03:16 - INFO - __main__ - Step 230 Global step 230 Train loss 0.86 on epoch=57
06/02/2022 21:03:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.89 on epoch=59
06/02/2022 21:03:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.68 on epoch=62
06/02/2022 21:03:21 - INFO - __main__ - Global step 250 Train loss 0.82 Classification-F1 0.5866113053613053 on epoch=62
06/02/2022 21:03:21 - INFO - __main__ - Saving model with best Classification-F1: 0.5559440559440559 -> 0.5866113053613053 on epoch=62, global_step=250
06/02/2022 21:03:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.82 on epoch=64
06/02/2022 21:03:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.80 on epoch=67
06/02/2022 21:03:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=69
06/02/2022 21:03:31 - INFO - __main__ - Step 290 Global step 290 Train loss 0.63 on epoch=72
06/02/2022 21:03:33 - INFO - __main__ - Step 300 Global step 300 Train loss 0.74 on epoch=74
06/02/2022 21:03:34 - INFO - __main__ - Global step 300 Train loss 0.73 Classification-F1 0.6180653815580286 on epoch=74
06/02/2022 21:03:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5866113053613053 -> 0.6180653815580286 on epoch=74, global_step=300
06/02/2022 21:03:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.87 on epoch=77
06/02/2022 21:03:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.67 on epoch=79
06/02/2022 21:03:42 - INFO - __main__ - Step 330 Global step 330 Train loss 0.80 on epoch=82
06/02/2022 21:03:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.64 on epoch=84
06/02/2022 21:03:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.80 on epoch=87
06/02/2022 21:03:47 - INFO - __main__ - Global step 350 Train loss 0.76 Classification-F1 0.6298203432845789 on epoch=87
06/02/2022 21:03:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6180653815580286 -> 0.6298203432845789 on epoch=87, global_step=350
06/02/2022 21:03:50 - INFO - __main__ - Step 360 Global step 360 Train loss 0.67 on epoch=89
06/02/2022 21:03:52 - INFO - __main__ - Step 370 Global step 370 Train loss 0.76 on epoch=92
06/02/2022 21:03:54 - INFO - __main__ - Step 380 Global step 380 Train loss 0.73 on epoch=94
06/02/2022 21:03:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.74 on epoch=97
06/02/2022 21:03:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.70 on epoch=99
06/02/2022 21:04:00 - INFO - __main__ - Global step 400 Train loss 0.72 Classification-F1 0.6585410138399268 on epoch=99
06/02/2022 21:04:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6298203432845789 -> 0.6585410138399268 on epoch=99, global_step=400
06/02/2022 21:04:02 - INFO - __main__ - Step 410 Global step 410 Train loss 0.70 on epoch=102
06/02/2022 21:04:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.69 on epoch=104
06/02/2022 21:04:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.70 on epoch=107
06/02/2022 21:04:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.64 on epoch=109
06/02/2022 21:04:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.68 on epoch=112
06/02/2022 21:04:13 - INFO - __main__ - Global step 450 Train loss 0.68 Classification-F1 0.6314616755793226 on epoch=112
06/02/2022 21:04:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.59 on epoch=114
06/02/2022 21:04:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.65 on epoch=117
06/02/2022 21:04:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.64 on epoch=119
06/02/2022 21:04:23 - INFO - __main__ - Step 490 Global step 490 Train loss 0.68 on epoch=122
06/02/2022 21:04:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.56 on epoch=124
06/02/2022 21:04:26 - INFO - __main__ - Global step 500 Train loss 0.62 Classification-F1 0.6521739130434783 on epoch=124
06/02/2022 21:04:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.63 on epoch=127
06/02/2022 21:04:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.57 on epoch=129
06/02/2022 21:04:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.51 on epoch=132
06/02/2022 21:04:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.50 on epoch=134
06/02/2022 21:04:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.62 on epoch=137
06/02/2022 21:04:39 - INFO - __main__ - Global step 550 Train loss 0.57 Classification-F1 0.6802801442747095 on epoch=137
06/02/2022 21:04:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6585410138399268 -> 0.6802801442747095 on epoch=137, global_step=550
06/02/2022 21:04:41 - INFO - __main__ - Step 560 Global step 560 Train loss 0.56 on epoch=139
06/02/2022 21:04:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.63 on epoch=142
06/02/2022 21:04:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.52 on epoch=144
06/02/2022 21:04:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.61 on epoch=147
06/02/2022 21:04:51 - INFO - __main__ - Step 600 Global step 600 Train loss 0.68 on epoch=149
06/02/2022 21:04:52 - INFO - __main__ - Global step 600 Train loss 0.60 Classification-F1 0.6738257262450811 on epoch=149
06/02/2022 21:04:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.58 on epoch=152
06/02/2022 21:04:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.49 on epoch=154
06/02/2022 21:04:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.55 on epoch=157
06/02/2022 21:05:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.42 on epoch=159
06/02/2022 21:05:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.67 on epoch=162
06/02/2022 21:05:05 - INFO - __main__ - Global step 650 Train loss 0.54 Classification-F1 0.6684557969529276 on epoch=162
06/02/2022 21:05:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.50 on epoch=164
06/02/2022 21:05:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.47 on epoch=167
06/02/2022 21:05:12 - INFO - __main__ - Step 680 Global step 680 Train loss 0.51 on epoch=169
06/02/2022 21:05:14 - INFO - __main__ - Step 690 Global step 690 Train loss 0.51 on epoch=172
06/02/2022 21:05:17 - INFO - __main__ - Step 700 Global step 700 Train loss 0.48 on epoch=174
06/02/2022 21:05:18 - INFO - __main__ - Global step 700 Train loss 0.49 Classification-F1 0.6404761904761904 on epoch=174
06/02/2022 21:05:20 - INFO - __main__ - Step 710 Global step 710 Train loss 0.50 on epoch=177
06/02/2022 21:05:23 - INFO - __main__ - Step 720 Global step 720 Train loss 0.49 on epoch=179
06/02/2022 21:05:25 - INFO - __main__ - Step 730 Global step 730 Train loss 0.54 on epoch=182
06/02/2022 21:05:27 - INFO - __main__ - Step 740 Global step 740 Train loss 0.49 on epoch=184
06/02/2022 21:05:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.50 on epoch=187
06/02/2022 21:05:31 - INFO - __main__ - Global step 750 Train loss 0.50 Classification-F1 0.6796484570058924 on epoch=187
06/02/2022 21:05:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.50 on epoch=189
06/02/2022 21:05:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.58 on epoch=192
06/02/2022 21:05:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.52 on epoch=194
06/02/2022 21:05:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.40 on epoch=197
06/02/2022 21:05:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.45 on epoch=199
06/02/2022 21:05:44 - INFO - __main__ - Global step 800 Train loss 0.49 Classification-F1 0.6418247439986571 on epoch=199
06/02/2022 21:05:46 - INFO - __main__ - Step 810 Global step 810 Train loss 0.42 on epoch=202
06/02/2022 21:05:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.44 on epoch=204
06/02/2022 21:05:51 - INFO - __main__ - Step 830 Global step 830 Train loss 0.50 on epoch=207
06/02/2022 21:05:53 - INFO - __main__ - Step 840 Global step 840 Train loss 0.46 on epoch=209
06/02/2022 21:05:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.41 on epoch=212
06/02/2022 21:05:56 - INFO - __main__ - Global step 850 Train loss 0.45 Classification-F1 0.6855090311986863 on epoch=212
06/02/2022 21:05:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6802801442747095 -> 0.6855090311986863 on epoch=212, global_step=850
06/02/2022 21:05:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.44 on epoch=214
06/02/2022 21:06:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.44 on epoch=217
06/02/2022 21:06:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.44 on epoch=219
06/02/2022 21:06:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.45 on epoch=222
06/02/2022 21:06:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.44 on epoch=224
06/02/2022 21:06:09 - INFO - __main__ - Global step 900 Train loss 0.44 Classification-F1 0.6989144316730522 on epoch=224
06/02/2022 21:06:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6855090311986863 -> 0.6989144316730522 on epoch=224, global_step=900
06/02/2022 21:06:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.41 on epoch=227
06/02/2022 21:06:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.34 on epoch=229
06/02/2022 21:06:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.38 on epoch=232
06/02/2022 21:06:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.35 on epoch=234
06/02/2022 21:06:21 - INFO - __main__ - Step 950 Global step 950 Train loss 0.39 on epoch=237
06/02/2022 21:06:22 - INFO - __main__ - Global step 950 Train loss 0.38 Classification-F1 0.7162424740010946 on epoch=237
06/02/2022 21:06:22 - INFO - __main__ - Saving model with best Classification-F1: 0.6989144316730522 -> 0.7162424740010946 on epoch=237, global_step=950
06/02/2022 21:06:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.32 on epoch=239
06/02/2022 21:06:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.43 on epoch=242
06/02/2022 21:06:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.31 on epoch=244
06/02/2022 21:06:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.42 on epoch=247
06/02/2022 21:06:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.38 on epoch=249
06/02/2022 21:06:35 - INFO - __main__ - Global step 1000 Train loss 0.37 Classification-F1 0.7004105090311986 on epoch=249
06/02/2022 21:06:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.47 on epoch=252
06/02/2022 21:06:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.43 on epoch=254
06/02/2022 21:06:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.41 on epoch=257
06/02/2022 21:06:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.35 on epoch=259
06/02/2022 21:06:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.38 on epoch=262
06/02/2022 21:06:48 - INFO - __main__ - Global step 1050 Train loss 0.41 Classification-F1 0.7162561576354679 on epoch=262
06/02/2022 21:06:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7162424740010946 -> 0.7162561576354679 on epoch=262, global_step=1050
06/02/2022 21:06:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.31 on epoch=264
06/02/2022 21:06:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.38 on epoch=267
06/02/2022 21:06:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.35 on epoch=269
06/02/2022 21:06:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.29 on epoch=272
06/02/2022 21:07:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.35 on epoch=274
06/02/2022 21:07:01 - INFO - __main__ - Global step 1100 Train loss 0.33 Classification-F1 0.7144888731095628 on epoch=274
06/02/2022 21:07:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.40 on epoch=277
06/02/2022 21:07:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.36 on epoch=279
06/02/2022 21:07:08 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.36 on epoch=282
06/02/2022 21:07:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.33 on epoch=284
06/02/2022 21:07:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.32 on epoch=287
06/02/2022 21:07:14 - INFO - __main__ - Global step 1150 Train loss 0.35 Classification-F1 0.6837486577197367 on epoch=287
06/02/2022 21:07:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.37 on epoch=289
06/02/2022 21:07:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.32 on epoch=292
06/02/2022 21:07:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.35 on epoch=294
06/02/2022 21:07:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.37 on epoch=297
06/02/2022 21:07:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.35 on epoch=299
06/02/2022 21:07:27 - INFO - __main__ - Global step 1200 Train loss 0.35 Classification-F1 0.7006906210760167 on epoch=299
06/02/2022 21:07:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.33 on epoch=302
06/02/2022 21:07:31 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.34 on epoch=304
06/02/2022 21:07:34 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.34 on epoch=307
06/02/2022 21:07:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.31 on epoch=309
06/02/2022 21:07:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.38 on epoch=312
06/02/2022 21:07:39 - INFO - __main__ - Global step 1250 Train loss 0.34 Classification-F1 0.7017316017316018 on epoch=312
06/02/2022 21:07:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.23 on epoch=314
06/02/2022 21:07:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.31 on epoch=317
06/02/2022 21:07:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.23 on epoch=319
06/02/2022 21:07:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.29 on epoch=322
06/02/2022 21:07:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.31 on epoch=324
06/02/2022 21:07:52 - INFO - __main__ - Global step 1300 Train loss 0.27 Classification-F1 0.7152688402688402 on epoch=324
06/02/2022 21:07:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.31 on epoch=327
06/02/2022 21:07:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.23 on epoch=329
06/02/2022 21:07:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.40 on epoch=332
06/02/2022 21:08:02 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.26 on epoch=334
06/02/2022 21:08:04 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.31 on epoch=337
06/02/2022 21:08:05 - INFO - __main__ - Global step 1350 Train loss 0.30 Classification-F1 0.7169660967835411 on epoch=337
06/02/2022 21:08:05 - INFO - __main__ - Saving model with best Classification-F1: 0.7162561576354679 -> 0.7169660967835411 on epoch=337, global_step=1350
06/02/2022 21:08:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.25 on epoch=339
06/02/2022 21:08:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.28 on epoch=342
06/02/2022 21:08:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.26 on epoch=344
06/02/2022 21:08:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.29 on epoch=347
06/02/2022 21:08:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.30 on epoch=349
06/02/2022 21:08:18 - INFO - __main__ - Global step 1400 Train loss 0.28 Classification-F1 0.701890756302521 on epoch=349
06/02/2022 21:08:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.20 on epoch=352
06/02/2022 21:08:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.26 on epoch=354
06/02/2022 21:08:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.26 on epoch=357
06/02/2022 21:08:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.32 on epoch=359
06/02/2022 21:08:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.31 on epoch=362
06/02/2022 21:08:31 - INFO - __main__ - Global step 1450 Train loss 0.27 Classification-F1 0.7173766058147397 on epoch=362
06/02/2022 21:08:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7169660967835411 -> 0.7173766058147397 on epoch=362, global_step=1450
06/02/2022 21:08:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.24 on epoch=364
06/02/2022 21:08:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.29 on epoch=367
06/02/2022 21:08:38 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.20 on epoch=369
06/02/2022 21:08:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.26 on epoch=372
06/02/2022 21:08:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.21 on epoch=374
06/02/2022 21:08:44 - INFO - __main__ - Global step 1500 Train loss 0.24 Classification-F1 0.7339602925809822 on epoch=374
06/02/2022 21:08:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7173766058147397 -> 0.7339602925809822 on epoch=374, global_step=1500
06/02/2022 21:08:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.27 on epoch=377
06/02/2022 21:08:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.30 on epoch=379
06/02/2022 21:08:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.26 on epoch=382
06/02/2022 21:08:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.25 on epoch=384
06/02/2022 21:08:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.26 on epoch=387
06/02/2022 21:08:57 - INFO - __main__ - Global step 1550 Train loss 0.27 Classification-F1 0.6841654373348085 on epoch=387
06/02/2022 21:08:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.20 on epoch=389
06/02/2022 21:09:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.22 on epoch=392
06/02/2022 21:09:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.21 on epoch=394
06/02/2022 21:09:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.28 on epoch=397
06/02/2022 21:09:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.28 on epoch=399
06/02/2022 21:09:09 - INFO - __main__ - Global step 1600 Train loss 0.24 Classification-F1 0.6844696969696971 on epoch=399
06/02/2022 21:09:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.22 on epoch=402
06/02/2022 21:09:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.25 on epoch=404
06/02/2022 21:09:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.26 on epoch=407
06/02/2022 21:09:19 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.17 on epoch=409
06/02/2022 21:09:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.24 on epoch=412
06/02/2022 21:09:22 - INFO - __main__ - Global step 1650 Train loss 0.23 Classification-F1 0.7339602925809822 on epoch=412
06/02/2022 21:09:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.22 on epoch=414
06/02/2022 21:09:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.17 on epoch=417
06/02/2022 21:09:30 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.16 on epoch=419
06/02/2022 21:09:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.26 on epoch=422
06/02/2022 21:09:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.19 on epoch=424
06/02/2022 21:09:35 - INFO - __main__ - Global step 1700 Train loss 0.20 Classification-F1 0.7016926921160792 on epoch=424
06/02/2022 21:09:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.20 on epoch=427
06/02/2022 21:09:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.15 on epoch=429
06/02/2022 21:09:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.21 on epoch=432
06/02/2022 21:09:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.18 on epoch=434
06/02/2022 21:09:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.27 on epoch=437
06/02/2022 21:09:48 - INFO - __main__ - Global step 1750 Train loss 0.20 Classification-F1 0.7329469718922051 on epoch=437
06/02/2022 21:09:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.20 on epoch=439
06/02/2022 21:09:53 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.15 on epoch=442
06/02/2022 21:09:55 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.29 on epoch=444
06/02/2022 21:09:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.17 on epoch=447
06/02/2022 21:10:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.20 on epoch=449
06/02/2022 21:10:01 - INFO - __main__ - Global step 1800 Train loss 0.20 Classification-F1 0.7356844305120167 on epoch=449
06/02/2022 21:10:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7339602925809822 -> 0.7356844305120167 on epoch=449, global_step=1800
06/02/2022 21:10:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.15 on epoch=452
06/02/2022 21:10:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.19 on epoch=454
06/02/2022 21:10:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.20 on epoch=457
06/02/2022 21:10:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.15 on epoch=459
06/02/2022 21:10:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.14 on epoch=462
06/02/2022 21:10:14 - INFO - __main__ - Global step 1850 Train loss 0.17 Classification-F1 0.7150292051293163 on epoch=462
06/02/2022 21:10:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.20 on epoch=464
06/02/2022 21:10:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=467
06/02/2022 21:10:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.17 on epoch=469
06/02/2022 21:10:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.23 on epoch=472
06/02/2022 21:10:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.15 on epoch=474
06/02/2022 21:10:27 - INFO - __main__ - Global step 1900 Train loss 0.18 Classification-F1 0.7335497835497836 on epoch=474
06/02/2022 21:10:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.20 on epoch=477
06/02/2022 21:10:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.15 on epoch=479
06/02/2022 21:10:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.16 on epoch=482
06/02/2022 21:10:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.19 on epoch=484
06/02/2022 21:10:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.16 on epoch=487
06/02/2022 21:10:39 - INFO - __main__ - Global step 1950 Train loss 0.17 Classification-F1 0.7150292051293163 on epoch=487
06/02/2022 21:10:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.15 on epoch=489
06/02/2022 21:10:44 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.21 on epoch=492
06/02/2022 21:10:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.11 on epoch=494
06/02/2022 21:10:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=497
06/02/2022 21:10:51 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=499
06/02/2022 21:10:52 - INFO - __main__ - Global step 2000 Train loss 0.13 Classification-F1 0.7124559501219844 on epoch=499
06/02/2022 21:10:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.20 on epoch=502
06/02/2022 21:10:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=504
06/02/2022 21:10:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.20 on epoch=507
06/02/2022 21:11:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.17 on epoch=509
06/02/2022 21:11:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=512
06/02/2022 21:11:05 - INFO - __main__ - Global step 2050 Train loss 0.16 Classification-F1 0.7124318025319138 on epoch=512
06/02/2022 21:11:08 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.16 on epoch=514
06/02/2022 21:11:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.12 on epoch=517
06/02/2022 21:11:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.18 on epoch=519
06/02/2022 21:11:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.13 on epoch=522
06/02/2022 21:11:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.11 on epoch=524
06/02/2022 21:11:18 - INFO - __main__ - Global step 2100 Train loss 0.14 Classification-F1 0.730952380952381 on epoch=524
06/02/2022 21:11:20 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.16 on epoch=527
06/02/2022 21:11:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.13 on epoch=529
06/02/2022 21:11:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.14 on epoch=532
06/02/2022 21:11:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.14 on epoch=534
06/02/2022 21:11:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.15 on epoch=537
06/02/2022 21:11:31 - INFO - __main__ - Global step 2150 Train loss 0.14 Classification-F1 0.7470588235294118 on epoch=537
06/02/2022 21:11:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7356844305120167 -> 0.7470588235294118 on epoch=537, global_step=2150
06/02/2022 21:11:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.12 on epoch=539
06/02/2022 21:11:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=542
06/02/2022 21:11:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=544
06/02/2022 21:11:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.12 on epoch=547
06/02/2022 21:11:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.11 on epoch=549
06/02/2022 21:11:44 - INFO - __main__ - Global step 2200 Train loss 0.11 Classification-F1 0.7652456978341948 on epoch=549
06/02/2022 21:11:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7470588235294118 -> 0.7652456978341948 on epoch=549, global_step=2200
06/02/2022 21:11:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.17 on epoch=552
06/02/2022 21:11:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=554
06/02/2022 21:11:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.21 on epoch=557
06/02/2022 21:11:53 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=559
06/02/2022 21:11:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.22 on epoch=562
06/02/2022 21:11:57 - INFO - __main__ - Global step 2250 Train loss 0.16 Classification-F1 0.7470588235294118 on epoch=562
06/02/2022 21:11:59 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.12 on epoch=564
06/02/2022 21:12:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.11 on epoch=567
06/02/2022 21:12:04 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=569
06/02/2022 21:12:06 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.11 on epoch=572
06/02/2022 21:12:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.28 on epoch=574
06/02/2022 21:12:10 - INFO - __main__ - Global step 2300 Train loss 0.15 Classification-F1 0.7301120448179271 on epoch=574
06/02/2022 21:12:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=577
06/02/2022 21:12:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.14 on epoch=579
06/02/2022 21:12:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.10 on epoch=582
06/02/2022 21:12:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.10 on epoch=584
06/02/2022 21:12:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=587
06/02/2022 21:12:22 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.7470588235294118 on epoch=587
06/02/2022 21:12:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.13 on epoch=589
06/02/2022 21:12:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=592
06/02/2022 21:12:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.16 on epoch=594
06/02/2022 21:12:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.10 on epoch=597
06/02/2022 21:12:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=599
06/02/2022 21:12:35 - INFO - __main__ - Global step 2400 Train loss 0.11 Classification-F1 0.7142857142857143 on epoch=599
06/02/2022 21:12:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.10 on epoch=602
06/02/2022 21:12:40 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=604
06/02/2022 21:12:42 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.27 on epoch=607
06/02/2022 21:12:45 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.14 on epoch=609
06/02/2022 21:12:47 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.12 on epoch=612
06/02/2022 21:12:48 - INFO - __main__ - Global step 2450 Train loss 0.13 Classification-F1 0.730952380952381 on epoch=612
06/02/2022 21:12:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=614
06/02/2022 21:12:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=617
06/02/2022 21:12:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.11 on epoch=619
06/02/2022 21:12:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.11 on epoch=622
06/02/2022 21:13:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.08 on epoch=624
06/02/2022 21:13:01 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.730952380952381 on epoch=624
06/02/2022 21:13:03 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=627
06/02/2022 21:13:06 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=629
06/02/2022 21:13:08 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=632
06/02/2022 21:13:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.10 on epoch=634
06/02/2022 21:13:13 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.12 on epoch=637
06/02/2022 21:13:14 - INFO - __main__ - Global step 2550 Train loss 0.10 Classification-F1 0.730952380952381 on epoch=637
06/02/2022 21:13:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.09 on epoch=639
06/02/2022 21:13:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.13 on epoch=642
06/02/2022 21:13:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.10 on epoch=644
06/02/2022 21:13:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=647
06/02/2022 21:13:26 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=649
06/02/2022 21:13:26 - INFO - __main__ - Global step 2600 Train loss 0.09 Classification-F1 0.730952380952381 on epoch=649
06/02/2022 21:13:29 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.15 on epoch=652
06/02/2022 21:13:31 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.23 on epoch=654
06/02/2022 21:13:34 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.09 on epoch=657
06/02/2022 21:13:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=659
06/02/2022 21:13:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.13 on epoch=662
06/02/2022 21:13:39 - INFO - __main__ - Global step 2650 Train loss 0.13 Classification-F1 0.7176470588235294 on epoch=662
06/02/2022 21:13:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.15 on epoch=664
06/02/2022 21:13:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.13 on epoch=667
06/02/2022 21:13:47 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.11 on epoch=669
06/02/2022 21:13:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=672
06/02/2022 21:13:51 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.12 on epoch=674
06/02/2022 21:13:52 - INFO - __main__ - Global step 2700 Train loss 0.11 Classification-F1 0.7167189132706373 on epoch=674
06/02/2022 21:13:55 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=677
06/02/2022 21:13:57 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=679
06/02/2022 21:13:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
06/02/2022 21:14:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=684
06/02/2022 21:14:04 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=687
06/02/2022 21:14:05 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.730952380952381 on epoch=687
06/02/2022 21:14:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/02/2022 21:14:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.10 on epoch=692
06/02/2022 21:14:12 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=694
06/02/2022 21:14:15 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=697
06/02/2022 21:14:17 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=699
06/02/2022 21:14:18 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7176470588235294 on epoch=699
06/02/2022 21:14:20 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.09 on epoch=702
06/02/2022 21:14:23 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=704
06/02/2022 21:14:25 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=707
06/02/2022 21:14:27 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.10 on epoch=709
06/02/2022 21:14:30 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=712
06/02/2022 21:14:31 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.7176470588235294 on epoch=712
06/02/2022 21:14:33 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=714
06/02/2022 21:14:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.13 on epoch=717
06/02/2022 21:14:38 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.08 on epoch=719
06/02/2022 21:14:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=722
06/02/2022 21:14:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=724
06/02/2022 21:14:44 - INFO - __main__ - Global step 2900 Train loss 0.07 Classification-F1 0.7517366578545667 on epoch=724
06/02/2022 21:14:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=727
06/02/2022 21:14:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.08 on epoch=729
06/02/2022 21:14:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.12 on epoch=732
06/02/2022 21:14:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/02/2022 21:14:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.13 on epoch=737
06/02/2022 21:14:56 - INFO - __main__ - Global step 2950 Train loss 0.08 Classification-F1 0.7176470588235294 on epoch=737
06/02/2022 21:14:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.09 on epoch=739
06/02/2022 21:15:01 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=742
06/02/2022 21:15:04 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/02/2022 21:15:06 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.10 on epoch=747
06/02/2022 21:15:08 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/02/2022 21:15:09 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.7508741427605525 on epoch=749
06/02/2022 21:15:09 - INFO - __main__ - save last model!
06/02/2022 21:15:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 21:15:09 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 21:15:09 - INFO - __main__ - Printing 3 examples
06/02/2022 21:15:09 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 21:15:09 - INFO - __main__ - ['others']
06/02/2022 21:15:09 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 21:15:09 - INFO - __main__ - ['others']
06/02/2022 21:15:09 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 21:15:09 - INFO - __main__ - ['others']
06/02/2022 21:15:09 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:15:10 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:15:10 - INFO - __main__ - Printing 3 examples
06/02/2022 21:15:10 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/02/2022 21:15:10 - INFO - __main__ - ['others']
06/02/2022 21:15:10 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/02/2022 21:15:10 - INFO - __main__ - ['others']
06/02/2022 21:15:10 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/02/2022 21:15:10 - INFO - __main__ - ['others']
06/02/2022 21:15:10 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:15:10 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:15:10 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 21:15:10 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:15:10 - INFO - __main__ - Printing 3 examples
06/02/2022 21:15:10 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/02/2022 21:15:10 - INFO - __main__ - ['others']
06/02/2022 21:15:10 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/02/2022 21:15:10 - INFO - __main__ - ['others']
06/02/2022 21:15:10 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/02/2022 21:15:10 - INFO - __main__ - ['others']
06/02/2022 21:15:10 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:15:10 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:15:10 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 21:15:11 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:15:17 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 21:15:25 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 21:15:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 21:15:26 - INFO - __main__ - Starting training!
06/02/2022 21:16:32 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_100_0.2_8_predictions.txt
06/02/2022 21:16:33 - INFO - __main__ - Classification-F1 on test data: 0.2473
06/02/2022 21:16:33 - INFO - __main__ - prefix=emo_16_100, lr=0.2, bsz=8, dev_performance=0.7652456978341948, test_performance=0.24730440180142838
06/02/2022 21:16:33 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.5, bsz=8 ...
06/02/2022 21:16:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:16:34 - INFO - __main__ - Printing 3 examples
06/02/2022 21:16:34 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/02/2022 21:16:34 - INFO - __main__ - ['others']
06/02/2022 21:16:34 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/02/2022 21:16:34 - INFO - __main__ - ['others']
06/02/2022 21:16:34 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/02/2022 21:16:34 - INFO - __main__ - ['others']
06/02/2022 21:16:34 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:16:34 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:16:34 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 21:16:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:16:34 - INFO - __main__ - Printing 3 examples
06/02/2022 21:16:34 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/02/2022 21:16:34 - INFO - __main__ - ['others']
06/02/2022 21:16:34 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/02/2022 21:16:34 - INFO - __main__ - ['others']
06/02/2022 21:16:34 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/02/2022 21:16:34 - INFO - __main__ - ['others']
06/02/2022 21:16:34 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:16:34 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:16:34 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 21:16:52 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 21:16:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 21:16:53 - INFO - __main__ - Starting training!
06/02/2022 21:16:56 - INFO - __main__ - Step 10 Global step 10 Train loss 3.78 on epoch=2
06/02/2022 21:16:58 - INFO - __main__ - Step 20 Global step 20 Train loss 2.67 on epoch=4
06/02/2022 21:17:01 - INFO - __main__ - Step 30 Global step 30 Train loss 2.15 on epoch=7
06/02/2022 21:17:03 - INFO - __main__ - Step 40 Global step 40 Train loss 1.74 on epoch=9
06/02/2022 21:17:06 - INFO - __main__ - Step 50 Global step 50 Train loss 1.50 on epoch=12
06/02/2022 21:17:07 - INFO - __main__ - Global step 50 Train loss 2.37 Classification-F1 0.11260755705200148 on epoch=12
06/02/2022 21:17:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11260755705200148 on epoch=12, global_step=50
06/02/2022 21:17:09 - INFO - __main__ - Step 60 Global step 60 Train loss 1.09 on epoch=14
06/02/2022 21:17:11 - INFO - __main__ - Step 70 Global step 70 Train loss 0.95 on epoch=17
06/02/2022 21:17:14 - INFO - __main__ - Step 80 Global step 80 Train loss 0.91 on epoch=19
06/02/2022 21:17:16 - INFO - __main__ - Step 90 Global step 90 Train loss 0.77 on epoch=22
06/02/2022 21:17:18 - INFO - __main__ - Step 100 Global step 100 Train loss 0.79 on epoch=24
06/02/2022 21:17:19 - INFO - __main__ - Global step 100 Train loss 0.90 Classification-F1 0.4873737373737373 on epoch=24
06/02/2022 21:17:19 - INFO - __main__ - Saving model with best Classification-F1: 0.11260755705200148 -> 0.4873737373737373 on epoch=24, global_step=100
06/02/2022 21:17:22 - INFO - __main__ - Step 110 Global step 110 Train loss 0.87 on epoch=27
06/02/2022 21:17:24 - INFO - __main__ - Step 120 Global step 120 Train loss 0.75 on epoch=29
06/02/2022 21:17:26 - INFO - __main__ - Step 130 Global step 130 Train loss 0.81 on epoch=32
06/02/2022 21:17:29 - INFO - __main__ - Step 140 Global step 140 Train loss 0.67 on epoch=34
06/02/2022 21:17:31 - INFO - __main__ - Step 150 Global step 150 Train loss 0.64 on epoch=37
06/02/2022 21:17:32 - INFO - __main__ - Global step 150 Train loss 0.75 Classification-F1 0.693345562191063 on epoch=37
06/02/2022 21:17:32 - INFO - __main__ - Saving model with best Classification-F1: 0.4873737373737373 -> 0.693345562191063 on epoch=37, global_step=150
06/02/2022 21:17:34 - INFO - __main__ - Step 160 Global step 160 Train loss 0.65 on epoch=39
06/02/2022 21:17:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.66 on epoch=42
06/02/2022 21:17:39 - INFO - __main__ - Step 180 Global step 180 Train loss 0.59 on epoch=44
06/02/2022 21:17:41 - INFO - __main__ - Step 190 Global step 190 Train loss 0.65 on epoch=47
06/02/2022 21:17:44 - INFO - __main__ - Step 200 Global step 200 Train loss 0.55 on epoch=49
06/02/2022 21:17:45 - INFO - __main__ - Global step 200 Train loss 0.62 Classification-F1 0.7325532363483027 on epoch=49
06/02/2022 21:17:45 - INFO - __main__ - Saving model with best Classification-F1: 0.693345562191063 -> 0.7325532363483027 on epoch=49, global_step=200
06/02/2022 21:17:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.51 on epoch=52
06/02/2022 21:17:50 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=54
06/02/2022 21:17:52 - INFO - __main__ - Step 230 Global step 230 Train loss 0.48 on epoch=57
06/02/2022 21:17:54 - INFO - __main__ - Step 240 Global step 240 Train loss 0.43 on epoch=59
06/02/2022 21:17:57 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=62
06/02/2022 21:17:57 - INFO - __main__ - Global step 250 Train loss 0.47 Classification-F1 0.7500135538086202 on epoch=62
06/02/2022 21:17:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7325532363483027 -> 0.7500135538086202 on epoch=62, global_step=250
06/02/2022 21:18:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=64
06/02/2022 21:18:02 - INFO - __main__ - Step 270 Global step 270 Train loss 0.41 on epoch=67
06/02/2022 21:18:05 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=69
06/02/2022 21:18:07 - INFO - __main__ - Step 290 Global step 290 Train loss 0.50 on epoch=72
06/02/2022 21:18:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.38 on epoch=74
06/02/2022 21:18:10 - INFO - __main__ - Global step 300 Train loss 0.43 Classification-F1 0.7307885304659499 on epoch=74
06/02/2022 21:18:13 - INFO - __main__ - Step 310 Global step 310 Train loss 0.36 on epoch=77
06/02/2022 21:18:15 - INFO - __main__ - Step 320 Global step 320 Train loss 0.37 on epoch=79
06/02/2022 21:18:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.36 on epoch=82
06/02/2022 21:18:20 - INFO - __main__ - Step 340 Global step 340 Train loss 0.27 on epoch=84
06/02/2022 21:18:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.39 on epoch=87
06/02/2022 21:18:23 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.752750410509031 on epoch=87
06/02/2022 21:18:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7500135538086202 -> 0.752750410509031 on epoch=87, global_step=350
06/02/2022 21:18:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=89
06/02/2022 21:18:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=92
06/02/2022 21:18:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=94
06/02/2022 21:18:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=97
06/02/2022 21:18:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=99
06/02/2022 21:18:36 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.7280555555555556 on epoch=99
06/02/2022 21:18:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=102
06/02/2022 21:18:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=104
06/02/2022 21:18:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=107
06/02/2022 21:18:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.26 on epoch=109
06/02/2022 21:18:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=112
06/02/2022 21:18:49 - INFO - __main__ - Global step 450 Train loss 0.26 Classification-F1 0.7970588235294117 on epoch=112
06/02/2022 21:18:49 - INFO - __main__ - Saving model with best Classification-F1: 0.752750410509031 -> 0.7970588235294117 on epoch=112, global_step=450
06/02/2022 21:18:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.19 on epoch=114
06/02/2022 21:18:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=117
06/02/2022 21:18:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=119
06/02/2022 21:18:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=122
06/02/2022 21:19:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=124
06/02/2022 21:19:02 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.7786854722338594 on epoch=124
06/02/2022 21:19:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=127
06/02/2022 21:19:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/02/2022 21:19:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=132
06/02/2022 21:19:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=134
06/02/2022 21:19:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=137
06/02/2022 21:19:14 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.7514550264550264 on epoch=137
06/02/2022 21:19:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=139
06/02/2022 21:19:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=142
06/02/2022 21:19:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=144
06/02/2022 21:19:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=147
06/02/2022 21:19:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=149
06/02/2022 21:19:27 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.7575225225225225 on epoch=149
06/02/2022 21:19:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=152
06/02/2022 21:19:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/02/2022 21:19:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=157
06/02/2022 21:19:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=159
06/02/2022 21:19:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=162
06/02/2022 21:19:40 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.7790603696675803 on epoch=162
06/02/2022 21:19:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=164
06/02/2022 21:19:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=167
06/02/2022 21:19:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=169
06/02/2022 21:19:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=172
06/02/2022 21:19:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=174
06/02/2022 21:19:53 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.7598792426378633 on epoch=174
06/02/2022 21:19:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=177
06/02/2022 21:19:58 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=179
06/02/2022 21:20:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=182
06/02/2022 21:20:03 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=184
06/02/2022 21:20:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/02/2022 21:20:06 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.796250318309142 on epoch=187
06/02/2022 21:20:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=189
06/02/2022 21:20:11 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=192
06/02/2022 21:20:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=194
06/02/2022 21:20:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=197
06/02/2022 21:20:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
06/02/2022 21:20:19 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7452991452991453 on epoch=199
06/02/2022 21:20:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
06/02/2022 21:20:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=204
06/02/2022 21:20:26 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/02/2022 21:20:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
06/02/2022 21:20:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=212
06/02/2022 21:20:32 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.7614607614607616 on epoch=212
06/02/2022 21:20:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=214
06/02/2022 21:20:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=217
06/02/2022 21:20:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
06/02/2022 21:20:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
06/02/2022 21:20:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=224
06/02/2022 21:20:45 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.7414680379108691 on epoch=224
06/02/2022 21:20:47 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/02/2022 21:20:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=229
06/02/2022 21:20:52 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=232
06/02/2022 21:20:55 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=234
06/02/2022 21:20:57 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=237
06/02/2022 21:20:58 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.7638616557734204 on epoch=237
06/02/2022 21:21:01 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=239
06/02/2022 21:21:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=242
06/02/2022 21:21:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=244
06/02/2022 21:21:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/02/2022 21:21:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=249
06/02/2022 21:21:11 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.7314102564102565 on epoch=249
06/02/2022 21:21:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/02/2022 21:21:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/02/2022 21:21:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/02/2022 21:21:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=259
06/02/2022 21:21:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
06/02/2022 21:21:24 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7610697546181417 on epoch=262
06/02/2022 21:21:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/02/2022 21:21:29 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/02/2022 21:21:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
06/02/2022 21:21:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/02/2022 21:21:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=274
06/02/2022 21:21:37 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7455994455994456 on epoch=274
06/02/2022 21:21:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/02/2022 21:21:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=279
06/02/2022 21:21:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=282
06/02/2022 21:21:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/02/2022 21:21:50 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/02/2022 21:21:51 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7455994455994456 on epoch=287
06/02/2022 21:21:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=289
06/02/2022 21:21:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
06/02/2022 21:21:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/02/2022 21:22:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
06/02/2022 21:22:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/02/2022 21:22:04 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.7313137313137312 on epoch=299
06/02/2022 21:22:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=302
06/02/2022 21:22:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/02/2022 21:22:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/02/2022 21:22:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=309
06/02/2022 21:22:16 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=312
06/02/2022 21:22:17 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7320543065324849 on epoch=312
06/02/2022 21:22:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/02/2022 21:22:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
06/02/2022 21:22:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
06/02/2022 21:22:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/02/2022 21:22:29 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=324
06/02/2022 21:22:30 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7310518334711883 on epoch=324
06/02/2022 21:22:32 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=327
06/02/2022 21:22:35 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/02/2022 21:22:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/02/2022 21:22:40 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=334
06/02/2022 21:22:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/02/2022 21:22:43 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7473169601118785 on epoch=337
06/02/2022 21:22:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=339
06/02/2022 21:22:48 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/02/2022 21:22:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/02/2022 21:22:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/02/2022 21:22:55 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/02/2022 21:22:56 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7426065162907267 on epoch=349
06/02/2022 21:22:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=352
06/02/2022 21:23:01 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/02/2022 21:23:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/02/2022 21:23:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/02/2022 21:23:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
06/02/2022 21:23:10 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7490424485206268 on epoch=362
06/02/2022 21:23:12 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/02/2022 21:23:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=367
06/02/2022 21:23:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/02/2022 21:23:19 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/02/2022 21:23:22 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/02/2022 21:23:23 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7487821565407773 on epoch=374
06/02/2022 21:23:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=377
06/02/2022 21:23:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/02/2022 21:23:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=382
06/02/2022 21:23:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/02/2022 21:23:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/02/2022 21:23:36 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7504014278207826 on epoch=387
06/02/2022 21:23:39 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=389
06/02/2022 21:23:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/02/2022 21:23:43 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/02/2022 21:23:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/02/2022 21:23:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/02/2022 21:23:49 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7316760037348273 on epoch=399
06/02/2022 21:23:52 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/02/2022 21:23:54 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/02/2022 21:23:57 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/02/2022 21:23:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=409
06/02/2022 21:24:02 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/02/2022 21:24:03 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7616432587020823 on epoch=412
06/02/2022 21:24:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/02/2022 21:24:08 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/02/2022 21:24:10 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/02/2022 21:24:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=422
06/02/2022 21:24:15 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/02/2022 21:24:16 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7627233877233878 on epoch=424
06/02/2022 21:24:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/02/2022 21:24:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/02/2022 21:24:23 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/02/2022 21:24:26 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=434
06/02/2022 21:24:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/02/2022 21:24:29 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7275438596491228 on epoch=437
06/02/2022 21:24:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/02/2022 21:24:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/02/2022 21:24:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/02/2022 21:24:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/02/2022 21:24:41 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/02/2022 21:24:42 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7280555555555556 on epoch=449
06/02/2022 21:24:45 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/02/2022 21:24:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=454
06/02/2022 21:24:50 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/02/2022 21:24:52 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/02/2022 21:24:55 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/02/2022 21:24:56 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7276587301587302 on epoch=462
06/02/2022 21:24:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/02/2022 21:25:01 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/02/2022 21:25:03 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/02/2022 21:25:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/02/2022 21:25:08 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/02/2022 21:25:09 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7614607614607616 on epoch=474
06/02/2022 21:25:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/02/2022 21:25:14 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/02/2022 21:25:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/02/2022 21:25:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=484
06/02/2022 21:25:21 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/02/2022 21:25:23 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7276587301587302 on epoch=487
06/02/2022 21:25:25 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/02/2022 21:25:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/02/2022 21:25:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=494
06/02/2022 21:25:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/02/2022 21:25:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/02/2022 21:25:36 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7139839346735898 on epoch=499
06/02/2022 21:25:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/02/2022 21:25:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/02/2022 21:25:43 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=507
06/02/2022 21:25:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/02/2022 21:25:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/02/2022 21:25:49 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7130950305143853 on epoch=512
06/02/2022 21:25:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/02/2022 21:25:54 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/02/2022 21:25:56 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/02/2022 21:25:59 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/02/2022 21:26:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/02/2022 21:26:02 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7124193548387097 on epoch=524
06/02/2022 21:26:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/02/2022 21:26:07 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/02/2022 21:26:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=532
06/02/2022 21:26:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/02/2022 21:26:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/02/2022 21:26:16 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7124193548387097 on epoch=537
06/02/2022 21:26:18 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/02/2022 21:26:21 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/02/2022 21:26:23 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/02/2022 21:26:25 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/02/2022 21:26:28 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/02/2022 21:26:29 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7500765471353706 on epoch=549
06/02/2022 21:26:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/02/2022 21:26:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/02/2022 21:26:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/02/2022 21:26:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/02/2022 21:26:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/02/2022 21:26:43 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7315407772304324 on epoch=562
06/02/2022 21:26:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/02/2022 21:26:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/02/2022 21:26:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=569
06/02/2022 21:26:52 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/02/2022 21:26:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/02/2022 21:26:56 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7124193548387097 on epoch=574
06/02/2022 21:26:58 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/02/2022 21:27:01 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/02/2022 21:27:03 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/02/2022 21:27:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/02/2022 21:27:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/02/2022 21:27:10 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7332723789620342 on epoch=587
06/02/2022 21:27:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.16 on epoch=589
06/02/2022 21:27:14 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/02/2022 21:27:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/02/2022 21:27:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/02/2022 21:27:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/02/2022 21:27:23 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7165596123506874 on epoch=599
06/02/2022 21:27:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/02/2022 21:27:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/02/2022 21:27:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/02/2022 21:27:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/02/2022 21:27:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/02/2022 21:27:37 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7460715754833401 on epoch=612
06/02/2022 21:27:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.07 on epoch=614
06/02/2022 21:27:41 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/02/2022 21:27:44 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/02/2022 21:27:46 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/02/2022 21:27:49 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/02/2022 21:27:50 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.749074074074074 on epoch=624
06/02/2022 21:27:52 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/02/2022 21:27:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/02/2022 21:27:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/02/2022 21:28:00 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/02/2022 21:28:02 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=637
06/02/2022 21:28:03 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7326378827393026 on epoch=637
06/02/2022 21:28:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/02/2022 21:28:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/02/2022 21:28:11 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/02/2022 21:28:13 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/02/2022 21:28:16 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/02/2022 21:28:17 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7320859320859321 on epoch=649
06/02/2022 21:28:19 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/02/2022 21:28:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/02/2022 21:28:24 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/02/2022 21:28:27 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/02/2022 21:28:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/02/2022 21:28:30 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7469426218065057 on epoch=662
06/02/2022 21:28:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/02/2022 21:28:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/02/2022 21:28:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/02/2022 21:28:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/02/2022 21:28:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/02/2022 21:28:44 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7275438596491228 on epoch=674
06/02/2022 21:28:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=677
06/02/2022 21:28:49 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/02/2022 21:28:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/02/2022 21:28:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/02/2022 21:28:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/02/2022 21:28:57 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7120829620829621 on epoch=687
06/02/2022 21:29:00 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/02/2022 21:29:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/02/2022 21:29:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/02/2022 21:29:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/02/2022 21:29:10 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=699
06/02/2022 21:29:11 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7130781799899447 on epoch=699
06/02/2022 21:29:13 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/02/2022 21:29:16 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/02/2022 21:29:18 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/02/2022 21:29:21 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/02/2022 21:29:23 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/02/2022 21:29:24 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7275438596491228 on epoch=712
06/02/2022 21:29:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/02/2022 21:29:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/02/2022 21:29:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/02/2022 21:29:34 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/02/2022 21:29:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/02/2022 21:29:38 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7427375762859634 on epoch=724
06/02/2022 21:29:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/02/2022 21:29:43 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/02/2022 21:29:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/02/2022 21:29:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/02/2022 21:29:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/02/2022 21:29:51 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7120829620829621 on epoch=737
06/02/2022 21:29:54 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/02/2022 21:29:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/02/2022 21:29:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/02/2022 21:30:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=747
06/02/2022 21:30:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=749
06/02/2022 21:30:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:30:05 - INFO - __main__ - Printing 3 examples
06/02/2022 21:30:05 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/02/2022 21:30:05 - INFO - __main__ - ['others']
06/02/2022 21:30:05 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/02/2022 21:30:05 - INFO - __main__ - ['others']
06/02/2022 21:30:05 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/02/2022 21:30:05 - INFO - __main__ - ['others']
06/02/2022 21:30:05 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:30:05 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:30:05 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 21:30:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:30:05 - INFO - __main__ - Printing 3 examples
06/02/2022 21:30:05 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/02/2022 21:30:05 - INFO - __main__ - ['others']
06/02/2022 21:30:05 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/02/2022 21:30:05 - INFO - __main__ - ['others']
06/02/2022 21:30:05 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/02/2022 21:30:05 - INFO - __main__ - ['others']
06/02/2022 21:30:05 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:30:05 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:30:05 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.6983722976370036 on epoch=749
06/02/2022 21:30:05 - INFO - __main__ - save last model!
06/02/2022 21:30:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 21:30:05 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 21:30:05 - INFO - __main__ - Printing 3 examples
06/02/2022 21:30:05 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 21:30:05 - INFO - __main__ - ['others']
06/02/2022 21:30:05 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 21:30:05 - INFO - __main__ - ['others']
06/02/2022 21:30:05 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 21:30:05 - INFO - __main__ - ['others']
06/02/2022 21:30:05 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 21:30:05 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:30:07 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:30:13 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 21:30:24 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 21:30:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 21:30:25 - INFO - __main__ - Starting training!
06/02/2022 21:31:55 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_13_0.5_8_predictions.txt
06/02/2022 21:31:55 - INFO - __main__ - Classification-F1 on test data: 0.3203
06/02/2022 21:31:55 - INFO - __main__ - prefix=emo_16_13, lr=0.5, bsz=8, dev_performance=0.7970588235294117, test_performance=0.3202853234732213
06/02/2022 21:31:55 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.4, bsz=8 ...
06/02/2022 21:31:56 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:31:56 - INFO - __main__ - Printing 3 examples
06/02/2022 21:31:56 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/02/2022 21:31:56 - INFO - __main__ - ['others']
06/02/2022 21:31:56 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/02/2022 21:31:56 - INFO - __main__ - ['others']
06/02/2022 21:31:56 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/02/2022 21:31:56 - INFO - __main__ - ['others']
06/02/2022 21:31:56 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:31:56 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:31:56 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 21:31:56 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:31:56 - INFO - __main__ - Printing 3 examples
06/02/2022 21:31:56 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/02/2022 21:31:56 - INFO - __main__ - ['others']
06/02/2022 21:31:56 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/02/2022 21:31:56 - INFO - __main__ - ['others']
06/02/2022 21:31:56 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/02/2022 21:31:56 - INFO - __main__ - ['others']
06/02/2022 21:31:56 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:31:56 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:31:56 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 21:32:11 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 21:32:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 21:32:12 - INFO - __main__ - Starting training!
06/02/2022 21:32:15 - INFO - __main__ - Step 10 Global step 10 Train loss 4.41 on epoch=2
06/02/2022 21:32:17 - INFO - __main__ - Step 20 Global step 20 Train loss 2.95 on epoch=4
06/02/2022 21:32:20 - INFO - __main__ - Step 30 Global step 30 Train loss 2.34 on epoch=7
06/02/2022 21:32:22 - INFO - __main__ - Step 40 Global step 40 Train loss 2.06 on epoch=9
06/02/2022 21:32:24 - INFO - __main__ - Step 50 Global step 50 Train loss 1.83 on epoch=12
06/02/2022 21:32:25 - INFO - __main__ - Global step 50 Train loss 2.72 Classification-F1 0.12027777777777779 on epoch=12
06/02/2022 21:32:25 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.12027777777777779 on epoch=12, global_step=50
06/02/2022 21:32:28 - INFO - __main__ - Step 60 Global step 60 Train loss 1.43 on epoch=14
06/02/2022 21:32:30 - INFO - __main__ - Step 70 Global step 70 Train loss 1.31 on epoch=17
06/02/2022 21:32:33 - INFO - __main__ - Step 80 Global step 80 Train loss 1.04 on epoch=19
06/02/2022 21:32:35 - INFO - __main__ - Step 90 Global step 90 Train loss 0.95 on epoch=22
06/02/2022 21:32:38 - INFO - __main__ - Step 100 Global step 100 Train loss 0.86 on epoch=24
06/02/2022 21:32:38 - INFO - __main__ - Global step 100 Train loss 1.12 Classification-F1 0.5830830177179923 on epoch=24
06/02/2022 21:32:38 - INFO - __main__ - Saving model with best Classification-F1: 0.12027777777777779 -> 0.5830830177179923 on epoch=24, global_step=100
06/02/2022 21:32:41 - INFO - __main__ - Step 110 Global step 110 Train loss 0.78 on epoch=27
06/02/2022 21:32:43 - INFO - __main__ - Step 120 Global step 120 Train loss 0.85 on epoch=29
06/02/2022 21:32:46 - INFO - __main__ - Step 130 Global step 130 Train loss 0.72 on epoch=32
06/02/2022 21:32:48 - INFO - __main__ - Step 140 Global step 140 Train loss 0.75 on epoch=34
06/02/2022 21:32:51 - INFO - __main__ - Step 150 Global step 150 Train loss 0.71 on epoch=37
06/02/2022 21:32:51 - INFO - __main__ - Global step 150 Train loss 0.76 Classification-F1 0.6863523573200992 on epoch=37
06/02/2022 21:32:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5830830177179923 -> 0.6863523573200992 on epoch=37, global_step=150
06/02/2022 21:32:54 - INFO - __main__ - Step 160 Global step 160 Train loss 0.64 on epoch=39
06/02/2022 21:32:56 - INFO - __main__ - Step 170 Global step 170 Train loss 0.69 on epoch=42
06/02/2022 21:32:59 - INFO - __main__ - Step 180 Global step 180 Train loss 0.55 on epoch=44
06/02/2022 21:33:01 - INFO - __main__ - Step 190 Global step 190 Train loss 0.65 on epoch=47
06/02/2022 21:33:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.51 on epoch=49
06/02/2022 21:33:05 - INFO - __main__ - Global step 200 Train loss 0.61 Classification-F1 0.6585260001578158 on epoch=49
06/02/2022 21:33:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.62 on epoch=52
06/02/2022 21:33:10 - INFO - __main__ - Step 220 Global step 220 Train loss 0.54 on epoch=54
06/02/2022 21:33:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.55 on epoch=57
06/02/2022 21:33:14 - INFO - __main__ - Step 240 Global step 240 Train loss 0.48 on epoch=59
06/02/2022 21:33:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.53 on epoch=62
06/02/2022 21:33:18 - INFO - __main__ - Global step 250 Train loss 0.54 Classification-F1 0.7656520362130763 on epoch=62
06/02/2022 21:33:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6863523573200992 -> 0.7656520362130763 on epoch=62, global_step=250
06/02/2022 21:33:20 - INFO - __main__ - Step 260 Global step 260 Train loss 0.44 on epoch=64
06/02/2022 21:33:23 - INFO - __main__ - Step 270 Global step 270 Train loss 0.53 on epoch=67
06/02/2022 21:33:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.51 on epoch=69
06/02/2022 21:33:28 - INFO - __main__ - Step 290 Global step 290 Train loss 0.43 on epoch=72
06/02/2022 21:33:30 - INFO - __main__ - Step 300 Global step 300 Train loss 0.45 on epoch=74
06/02/2022 21:33:31 - INFO - __main__ - Global step 300 Train loss 0.47 Classification-F1 0.7805443548387097 on epoch=74
06/02/2022 21:33:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7656520362130763 -> 0.7805443548387097 on epoch=74, global_step=300
06/02/2022 21:33:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.50 on epoch=77
06/02/2022 21:33:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.53 on epoch=79
06/02/2022 21:33:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.42 on epoch=82
06/02/2022 21:33:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.46 on epoch=84
06/02/2022 21:33:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=87
06/02/2022 21:33:44 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.7815524193548387 on epoch=87
06/02/2022 21:33:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7805443548387097 -> 0.7815524193548387 on epoch=87, global_step=350
06/02/2022 21:33:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.41 on epoch=89
06/02/2022 21:33:49 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=92
06/02/2022 21:33:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.31 on epoch=94
06/02/2022 21:33:54 - INFO - __main__ - Step 390 Global step 390 Train loss 0.37 on epoch=97
06/02/2022 21:33:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=99
06/02/2022 21:33:58 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.7954364878725279 on epoch=99
06/02/2022 21:33:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7815524193548387 -> 0.7954364878725279 on epoch=99, global_step=400
06/02/2022 21:34:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=102
06/02/2022 21:34:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=104
06/02/2022 21:34:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=107
06/02/2022 21:34:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=109
06/02/2022 21:34:10 - INFO - __main__ - Step 450 Global step 450 Train loss 0.37 on epoch=112
06/02/2022 21:34:11 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.7795409251019652 on epoch=112
06/02/2022 21:34:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=114
06/02/2022 21:34:16 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=117
06/02/2022 21:34:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=119
06/02/2022 21:34:21 - INFO - __main__ - Step 490 Global step 490 Train loss 0.36 on epoch=122
06/02/2022 21:34:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.27 on epoch=124
06/02/2022 21:34:24 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.7971680896041298 on epoch=124
06/02/2022 21:34:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7954364878725279 -> 0.7971680896041298 on epoch=124, global_step=500
06/02/2022 21:34:26 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=127
06/02/2022 21:34:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=129
06/02/2022 21:34:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=132
06/02/2022 21:34:34 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=134
06/02/2022 21:34:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=137
06/02/2022 21:34:37 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.7662815126050421 on epoch=137
06/02/2022 21:34:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=139
06/02/2022 21:34:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=142
06/02/2022 21:34:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=144
06/02/2022 21:34:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=147
06/02/2022 21:34:50 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=149
06/02/2022 21:34:51 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.7964285714285715 on epoch=149
06/02/2022 21:34:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
06/02/2022 21:34:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=154
06/02/2022 21:34:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.14 on epoch=157
06/02/2022 21:35:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=159
06/02/2022 21:35:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=162
06/02/2022 21:35:04 - INFO - __main__ - Global step 650 Train loss 0.16 Classification-F1 0.7812518110692553 on epoch=162
06/02/2022 21:35:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=164
06/02/2022 21:35:09 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
06/02/2022 21:35:11 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=169
06/02/2022 21:35:14 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=172
06/02/2022 21:35:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=174
06/02/2022 21:35:17 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.7801344896933132 on epoch=174
06/02/2022 21:35:20 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=177
06/02/2022 21:35:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=179
06/02/2022 21:35:25 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=182
06/02/2022 21:35:27 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=184
06/02/2022 21:35:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=187
06/02/2022 21:35:31 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.7655400155400155 on epoch=187
06/02/2022 21:35:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=189
06/02/2022 21:35:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=192
06/02/2022 21:35:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=194
06/02/2022 21:35:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=197
06/02/2022 21:35:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=199
06/02/2022 21:35:44 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.812055281882868 on epoch=199
06/02/2022 21:35:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7971680896041298 -> 0.812055281882868 on epoch=199, global_step=800
06/02/2022 21:35:46 - INFO - __main__ - Step 810 Global step 810 Train loss 0.09 on epoch=202
06/02/2022 21:35:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=204
06/02/2022 21:35:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=207
06/02/2022 21:35:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=209
06/02/2022 21:35:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=212
06/02/2022 21:35:57 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.812055281882868 on epoch=212
06/02/2022 21:36:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=214
06/02/2022 21:36:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=217
06/02/2022 21:36:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=219
06/02/2022 21:36:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
06/02/2022 21:36:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=224
06/02/2022 21:36:11 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.8116584564860427 on epoch=224
06/02/2022 21:36:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=227
06/02/2022 21:36:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=229
06/02/2022 21:36:18 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
06/02/2022 21:36:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=234
06/02/2022 21:36:23 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
06/02/2022 21:36:24 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.7653023447141094 on epoch=237
06/02/2022 21:36:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=239
06/02/2022 21:36:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=242
06/02/2022 21:36:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=244
06/02/2022 21:36:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=247
06/02/2022 21:36:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=249
06/02/2022 21:36:37 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.7607017543859649 on epoch=249
06/02/2022 21:36:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
06/02/2022 21:36:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=254
06/02/2022 21:36:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=257
06/02/2022 21:36:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
06/02/2022 21:36:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
06/02/2022 21:36:51 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.7475324675324675 on epoch=262
06/02/2022 21:36:53 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=264
06/02/2022 21:36:56 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.15 on epoch=267
06/02/2022 21:36:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
06/02/2022 21:37:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=272
06/02/2022 21:37:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=274
06/02/2022 21:37:04 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.7447214854111406 on epoch=274
06/02/2022 21:37:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=277
06/02/2022 21:37:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=279
06/02/2022 21:37:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=282
06/02/2022 21:37:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=284
06/02/2022 21:37:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
06/02/2022 21:37:17 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.7317858611976258 on epoch=287
06/02/2022 21:37:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
06/02/2022 21:37:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=292
06/02/2022 21:37:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/02/2022 21:37:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=297
06/02/2022 21:37:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=299
06/02/2022 21:37:30 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.751984126984127 on epoch=299
06/02/2022 21:37:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=302
06/02/2022 21:37:35 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=304
06/02/2022 21:37:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/02/2022 21:37:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
06/02/2022 21:37:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/02/2022 21:37:44 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7485922607626461 on epoch=312
06/02/2022 21:37:46 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/02/2022 21:37:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=317
06/02/2022 21:37:51 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=319
06/02/2022 21:37:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/02/2022 21:37:56 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/02/2022 21:37:57 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.746606334841629 on epoch=324
06/02/2022 21:37:59 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/02/2022 21:38:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=329
06/02/2022 21:38:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=332
06/02/2022 21:38:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=334
06/02/2022 21:38:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=337
06/02/2022 21:38:10 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.7662395847879718 on epoch=337
06/02/2022 21:38:13 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/02/2022 21:38:15 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=342
06/02/2022 21:38:18 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/02/2022 21:38:20 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/02/2022 21:38:23 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
06/02/2022 21:38:23 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7523268398268399 on epoch=349
06/02/2022 21:38:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/02/2022 21:38:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/02/2022 21:38:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=357
06/02/2022 21:38:33 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/02/2022 21:38:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/02/2022 21:38:37 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7158180476491671 on epoch=362
06/02/2022 21:38:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/02/2022 21:38:42 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
06/02/2022 21:38:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=369
06/02/2022 21:38:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=372
06/02/2022 21:38:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=374
06/02/2022 21:38:50 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7452731092436975 on epoch=374
06/02/2022 21:38:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/02/2022 21:38:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/02/2022 21:38:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=382
06/02/2022 21:39:00 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/02/2022 21:39:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=387
06/02/2022 21:39:03 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7151305866476144 on epoch=387
06/02/2022 21:39:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/02/2022 21:39:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/02/2022 21:39:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/02/2022 21:39:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/02/2022 21:39:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/02/2022 21:39:17 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.71505499005499 on epoch=399
06/02/2022 21:39:19 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=402
06/02/2022 21:39:21 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/02/2022 21:39:24 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/02/2022 21:39:26 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/02/2022 21:39:29 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/02/2022 21:39:30 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7001854795972442 on epoch=412
06/02/2022 21:39:32 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/02/2022 21:39:35 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/02/2022 21:39:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/02/2022 21:39:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/02/2022 21:39:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/02/2022 21:39:43 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7036462861006472 on epoch=424
06/02/2022 21:39:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/02/2022 21:39:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/02/2022 21:39:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/02/2022 21:39:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=434
06/02/2022 21:39:56 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/02/2022 21:39:57 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.719607843137255 on epoch=437
06/02/2022 21:39:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/02/2022 21:40:02 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/02/2022 21:40:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/02/2022 21:40:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/02/2022 21:40:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/02/2022 21:40:10 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7472407766525413 on epoch=449
06/02/2022 21:40:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=452
06/02/2022 21:40:15 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/02/2022 21:40:18 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/02/2022 21:40:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/02/2022 21:40:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=462
06/02/2022 21:40:24 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7339669738863287 on epoch=462
06/02/2022 21:40:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/02/2022 21:40:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/02/2022 21:40:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/02/2022 21:40:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/02/2022 21:40:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=474
06/02/2022 21:40:37 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7495098039215686 on epoch=474
06/02/2022 21:40:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/02/2022 21:40:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/02/2022 21:40:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/02/2022 21:40:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/02/2022 21:40:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/02/2022 21:40:50 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7178887034977135 on epoch=487
06/02/2022 21:40:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/02/2022 21:40:55 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/02/2022 21:40:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/02/2022 21:41:00 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/02/2022 21:41:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=499
06/02/2022 21:41:04 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7307929139825692 on epoch=499
06/02/2022 21:41:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/02/2022 21:41:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/02/2022 21:41:11 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/02/2022 21:41:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.13 on epoch=509
06/02/2022 21:41:16 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/02/2022 21:41:17 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7144674566741397 on epoch=512
06/02/2022 21:41:20 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=514
06/02/2022 21:41:22 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/02/2022 21:41:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/02/2022 21:41:27 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=522
06/02/2022 21:41:30 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/02/2022 21:41:31 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7022561354457906 on epoch=524
06/02/2022 21:41:33 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=527
06/02/2022 21:41:35 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/02/2022 21:41:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=532
06/02/2022 21:41:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/02/2022 21:41:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=537
06/02/2022 21:41:44 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7321654449603634 on epoch=537
06/02/2022 21:41:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=539
06/02/2022 21:41:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/02/2022 21:41:51 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/02/2022 21:41:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=547
06/02/2022 21:41:56 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/02/2022 21:41:57 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7321654449603634 on epoch=549
06/02/2022 21:42:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/02/2022 21:42:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=554
06/02/2022 21:42:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/02/2022 21:42:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/02/2022 21:42:09 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=562
06/02/2022 21:42:10 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7144674566741397 on epoch=562
06/02/2022 21:42:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=564
06/02/2022 21:42:15 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/02/2022 21:42:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.12 on epoch=569
06/02/2022 21:42:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=572
06/02/2022 21:42:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=574
06/02/2022 21:42:24 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.7647303147303147 on epoch=574
06/02/2022 21:42:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=577
06/02/2022 21:42:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/02/2022 21:42:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/02/2022 21:42:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/02/2022 21:42:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/02/2022 21:42:37 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7499390456287008 on epoch=587
06/02/2022 21:42:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/02/2022 21:42:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/02/2022 21:42:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=594
06/02/2022 21:42:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/02/2022 21:42:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/02/2022 21:42:50 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7499390456287008 on epoch=599
06/02/2022 21:42:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/02/2022 21:42:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/02/2022 21:42:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=607
06/02/2022 21:43:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/02/2022 21:43:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=612
06/02/2022 21:43:03 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7478468899521531 on epoch=612
06/02/2022 21:43:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/02/2022 21:43:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/02/2022 21:43:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
06/02/2022 21:43:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/02/2022 21:43:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=624
06/02/2022 21:43:16 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.766017316017316 on epoch=624
06/02/2022 21:43:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/02/2022 21:43:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/02/2022 21:43:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/02/2022 21:43:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/02/2022 21:43:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/02/2022 21:43:29 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7485922607626461 on epoch=637
06/02/2022 21:43:32 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/02/2022 21:43:34 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/02/2022 21:43:37 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/02/2022 21:43:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/02/2022 21:43:42 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/02/2022 21:43:43 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7647303147303147 on epoch=649
06/02/2022 21:43:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/02/2022 21:43:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=654
06/02/2022 21:43:50 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=657
06/02/2022 21:43:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/02/2022 21:43:55 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/02/2022 21:43:56 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7805642633228841 on epoch=662
06/02/2022 21:43:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/02/2022 21:44:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=667
06/02/2022 21:44:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/02/2022 21:44:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=672
06/02/2022 21:44:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.09 on epoch=674
06/02/2022 21:44:09 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7321654449603634 on epoch=674
06/02/2022 21:44:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=677
06/02/2022 21:44:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/02/2022 21:44:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/02/2022 21:44:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/02/2022 21:44:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/02/2022 21:44:22 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7335160359353908 on epoch=687
06/02/2022 21:44:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/02/2022 21:44:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/02/2022 21:44:29 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.10 on epoch=694
06/02/2022 21:44:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/02/2022 21:44:34 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/02/2022 21:44:35 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7490105719707238 on epoch=699
06/02/2022 21:44:38 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/02/2022 21:44:40 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/02/2022 21:44:42 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/02/2022 21:44:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/02/2022 21:44:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/02/2022 21:44:48 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7167313941507489 on epoch=712
06/02/2022 21:44:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/02/2022 21:44:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/02/2022 21:44:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=719
06/02/2022 21:44:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=722
06/02/2022 21:45:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/02/2022 21:45:01 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7487554112554113 on epoch=724
06/02/2022 21:45:04 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/02/2022 21:45:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.06 on epoch=729
06/02/2022 21:45:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/02/2022 21:45:11 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/02/2022 21:45:14 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
06/02/2022 21:45:15 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7155373362269914 on epoch=737
06/02/2022 21:45:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/02/2022 21:45:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/02/2022 21:45:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/02/2022 21:45:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/02/2022 21:45:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/02/2022 21:45:28 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7308602486087274 on epoch=749
06/02/2022 21:45:28 - INFO - __main__ - save last model!
06/02/2022 21:45:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 21:45:28 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 21:45:28 - INFO - __main__ - Printing 3 examples
06/02/2022 21:45:28 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 21:45:28 - INFO - __main__ - ['others']
06/02/2022 21:45:28 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 21:45:28 - INFO - __main__ - ['others']
06/02/2022 21:45:28 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 21:45:28 - INFO - __main__ - ['others']
06/02/2022 21:45:28 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:45:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:45:28 - INFO - __main__ - Printing 3 examples
06/02/2022 21:45:28 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/02/2022 21:45:28 - INFO - __main__ - ['others']
06/02/2022 21:45:28 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/02/2022 21:45:28 - INFO - __main__ - ['others']
06/02/2022 21:45:28 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/02/2022 21:45:28 - INFO - __main__ - ['others']
06/02/2022 21:45:28 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:45:28 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:45:28 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 21:45:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:45:28 - INFO - __main__ - Printing 3 examples
06/02/2022 21:45:28 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/02/2022 21:45:28 - INFO - __main__ - ['others']
06/02/2022 21:45:28 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/02/2022 21:45:28 - INFO - __main__ - ['others']
06/02/2022 21:45:28 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/02/2022 21:45:28 - INFO - __main__ - ['others']
06/02/2022 21:45:28 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:45:28 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:45:28 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 21:45:30 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:45:35 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 21:45:47 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 21:45:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 21:45:48 - INFO - __main__ - Starting training!
06/02/2022 21:47:00 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_13_0.4_8_predictions.txt
06/02/2022 21:47:00 - INFO - __main__ - Classification-F1 on test data: 0.2467
06/02/2022 21:47:00 - INFO - __main__ - prefix=emo_16_13, lr=0.4, bsz=8, dev_performance=0.812055281882868, test_performance=0.24669737026140603
06/02/2022 21:47:00 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.3, bsz=8 ...
06/02/2022 21:47:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:47:01 - INFO - __main__ - Printing 3 examples
06/02/2022 21:47:01 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/02/2022 21:47:01 - INFO - __main__ - ['others']
06/02/2022 21:47:01 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/02/2022 21:47:01 - INFO - __main__ - ['others']
06/02/2022 21:47:01 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/02/2022 21:47:01 - INFO - __main__ - ['others']
06/02/2022 21:47:01 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:47:01 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:47:01 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 21:47:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 21:47:01 - INFO - __main__ - Printing 3 examples
06/02/2022 21:47:01 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/02/2022 21:47:01 - INFO - __main__ - ['others']
06/02/2022 21:47:01 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/02/2022 21:47:01 - INFO - __main__ - ['others']
06/02/2022 21:47:01 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/02/2022 21:47:01 - INFO - __main__ - ['others']
06/02/2022 21:47:01 - INFO - __main__ - Tokenizing Input ...
06/02/2022 21:47:01 - INFO - __main__ - Tokenizing Output ...
06/02/2022 21:47:01 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 21:47:20 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 21:47:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 21:47:21 - INFO - __main__ - Starting training!
06/02/2022 21:47:24 - INFO - __main__ - Step 10 Global step 10 Train loss 4.52 on epoch=2
06/02/2022 21:47:26 - INFO - __main__ - Step 20 Global step 20 Train loss 3.23 on epoch=4
06/02/2022 21:47:29 - INFO - __main__ - Step 30 Global step 30 Train loss 2.72 on epoch=7
06/02/2022 21:47:31 - INFO - __main__ - Step 40 Global step 40 Train loss 2.36 on epoch=9
06/02/2022 21:47:34 - INFO - __main__ - Step 50 Global step 50 Train loss 2.12 on epoch=12
06/02/2022 21:47:34 - INFO - __main__ - Global step 50 Train loss 2.99 Classification-F1 0.0 on epoch=12
06/02/2022 21:47:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/02/2022 21:47:37 - INFO - __main__ - Step 60 Global step 60 Train loss 1.88 on epoch=14
06/02/2022 21:47:39 - INFO - __main__ - Step 70 Global step 70 Train loss 1.64 on epoch=17
06/02/2022 21:47:42 - INFO - __main__ - Step 80 Global step 80 Train loss 1.43 on epoch=19
06/02/2022 21:47:44 - INFO - __main__ - Step 90 Global step 90 Train loss 1.23 on epoch=22
06/02/2022 21:47:47 - INFO - __main__ - Step 100 Global step 100 Train loss 1.18 on epoch=24
06/02/2022 21:47:48 - INFO - __main__ - Global step 100 Train loss 1.47 Classification-F1 0.2808317089018843 on epoch=24
06/02/2022 21:47:48 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.2808317089018843 on epoch=24, global_step=100
06/02/2022 21:47:50 - INFO - __main__ - Step 110 Global step 110 Train loss 1.10 on epoch=27
06/02/2022 21:47:53 - INFO - __main__ - Step 120 Global step 120 Train loss 0.94 on epoch=29
06/02/2022 21:47:55 - INFO - __main__ - Step 130 Global step 130 Train loss 0.87 on epoch=32
06/02/2022 21:47:58 - INFO - __main__ - Step 140 Global step 140 Train loss 0.82 on epoch=34
06/02/2022 21:48:00 - INFO - __main__ - Step 150 Global step 150 Train loss 0.82 on epoch=37
06/02/2022 21:48:01 - INFO - __main__ - Global step 150 Train loss 0.91 Classification-F1 0.49797979797979797 on epoch=37
06/02/2022 21:48:01 - INFO - __main__ - Saving model with best Classification-F1: 0.2808317089018843 -> 0.49797979797979797 on epoch=37, global_step=150
06/02/2022 21:48:03 - INFO - __main__ - Step 160 Global step 160 Train loss 0.80 on epoch=39
06/02/2022 21:48:06 - INFO - __main__ - Step 170 Global step 170 Train loss 0.70 on epoch=42
06/02/2022 21:48:08 - INFO - __main__ - Step 180 Global step 180 Train loss 0.70 on epoch=44
06/02/2022 21:48:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.77 on epoch=47
06/02/2022 21:48:13 - INFO - __main__ - Step 200 Global step 200 Train loss 0.65 on epoch=49
06/02/2022 21:48:14 - INFO - __main__ - Global step 200 Train loss 0.72 Classification-F1 0.5395299145299146 on epoch=49
06/02/2022 21:48:14 - INFO - __main__ - Saving model with best Classification-F1: 0.49797979797979797 -> 0.5395299145299146 on epoch=49, global_step=200
06/02/2022 21:48:17 - INFO - __main__ - Step 210 Global step 210 Train loss 0.70 on epoch=52
06/02/2022 21:48:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.69 on epoch=54
06/02/2022 21:48:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.74 on epoch=57
06/02/2022 21:48:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.52 on epoch=59
06/02/2022 21:48:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.46 on epoch=62
06/02/2022 21:48:28 - INFO - __main__ - Global step 250 Train loss 0.62 Classification-F1 0.725 on epoch=62
06/02/2022 21:48:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5395299145299146 -> 0.725 on epoch=62, global_step=250
06/02/2022 21:48:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=64
06/02/2022 21:48:32 - INFO - __main__ - Step 270 Global step 270 Train loss 0.56 on epoch=67
06/02/2022 21:48:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.58 on epoch=69
06/02/2022 21:48:37 - INFO - __main__ - Step 290 Global step 290 Train loss 0.57 on epoch=72
06/02/2022 21:48:40 - INFO - __main__ - Step 300 Global step 300 Train loss 0.62 on epoch=74
06/02/2022 21:48:41 - INFO - __main__ - Global step 300 Train loss 0.59 Classification-F1 0.6804976273726274 on epoch=74
06/02/2022 21:48:43 - INFO - __main__ - Step 310 Global step 310 Train loss 0.56 on epoch=77
06/02/2022 21:48:46 - INFO - __main__ - Step 320 Global step 320 Train loss 0.50 on epoch=79
06/02/2022 21:48:48 - INFO - __main__ - Step 330 Global step 330 Train loss 0.59 on epoch=82
06/02/2022 21:48:51 - INFO - __main__ - Step 340 Global step 340 Train loss 0.54 on epoch=84
06/02/2022 21:48:53 - INFO - __main__ - Step 350 Global step 350 Train loss 0.59 on epoch=87
06/02/2022 21:48:54 - INFO - __main__ - Global step 350 Train loss 0.55 Classification-F1 0.7325396825396825 on epoch=87
06/02/2022 21:48:54 - INFO - __main__ - Saving model with best Classification-F1: 0.725 -> 0.7325396825396825 on epoch=87, global_step=350
06/02/2022 21:48:57 - INFO - __main__ - Step 360 Global step 360 Train loss 0.51 on epoch=89
06/02/2022 21:48:59 - INFO - __main__ - Step 370 Global step 370 Train loss 0.52 on epoch=92
06/02/2022 21:49:01 - INFO - __main__ - Step 380 Global step 380 Train loss 0.46 on epoch=94
06/02/2022 21:49:04 - INFO - __main__ - Step 390 Global step 390 Train loss 0.51 on epoch=97
06/02/2022 21:49:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=99
06/02/2022 21:49:07 - INFO - __main__ - Global step 400 Train loss 0.50 Classification-F1 0.7252554974329168 on epoch=99
06/02/2022 21:49:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=102
06/02/2022 21:49:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.50 on epoch=104
06/02/2022 21:49:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=107
06/02/2022 21:49:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.42 on epoch=109
06/02/2022 21:49:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.44 on epoch=112
06/02/2022 21:49:20 - INFO - __main__ - Global step 450 Train loss 0.45 Classification-F1 0.7974264705882352 on epoch=112
06/02/2022 21:49:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7325396825396825 -> 0.7974264705882352 on epoch=112, global_step=450
06/02/2022 21:49:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.35 on epoch=114
06/02/2022 21:49:25 - INFO - __main__ - Step 470 Global step 470 Train loss 0.40 on epoch=117
06/02/2022 21:49:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.48 on epoch=119
06/02/2022 21:49:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=122
06/02/2022 21:49:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.34 on epoch=124
06/02/2022 21:49:34 - INFO - __main__ - Global step 500 Train loss 0.37 Classification-F1 0.7961730058504252 on epoch=124
06/02/2022 21:49:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.36 on epoch=127
06/02/2022 21:49:39 - INFO - __main__ - Step 520 Global step 520 Train loss 0.33 on epoch=129
06/02/2022 21:49:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=132
06/02/2022 21:49:44 - INFO - __main__ - Step 540 Global step 540 Train loss 0.39 on epoch=134
06/02/2022 21:49:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.35 on epoch=137
06/02/2022 21:49:47 - INFO - __main__ - Global step 550 Train loss 0.36 Classification-F1 0.7809869528619529 on epoch=137
06/02/2022 21:49:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=139
06/02/2022 21:49:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=142
06/02/2022 21:49:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=144
06/02/2022 21:49:57 - INFO - __main__ - Step 590 Global step 590 Train loss 0.40 on epoch=147
06/02/2022 21:49:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.33 on epoch=149
06/02/2022 21:50:00 - INFO - __main__ - Global step 600 Train loss 0.32 Classification-F1 0.7472081972081973 on epoch=149
06/02/2022 21:50:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.34 on epoch=152
06/02/2022 21:50:05 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=154
06/02/2022 21:50:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.32 on epoch=157
06/02/2022 21:50:10 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=159
06/02/2022 21:50:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=162
06/02/2022 21:50:13 - INFO - __main__ - Global step 650 Train loss 0.28 Classification-F1 0.7955566403842266 on epoch=162
06/02/2022 21:50:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.36 on epoch=164
06/02/2022 21:50:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=167
06/02/2022 21:50:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.34 on epoch=169
06/02/2022 21:50:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.32 on epoch=172
06/02/2022 21:50:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=174
06/02/2022 21:50:26 - INFO - __main__ - Global step 700 Train loss 0.28 Classification-F1 0.7925317669150685 on epoch=174
06/02/2022 21:50:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.26 on epoch=177
06/02/2022 21:50:31 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=179
06/02/2022 21:50:34 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=182
06/02/2022 21:50:36 - INFO - __main__ - Step 740 Global step 740 Train loss 0.27 on epoch=184
06/02/2022 21:50:39 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=187
06/02/2022 21:50:40 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.8123587365980874 on epoch=187
06/02/2022 21:50:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7974264705882352 -> 0.8123587365980874 on epoch=187, global_step=750
06/02/2022 21:50:42 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=189
06/02/2022 21:50:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=192
06/02/2022 21:50:47 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=194
06/02/2022 21:50:49 - INFO - __main__ - Step 790 Global step 790 Train loss 0.23 on epoch=197
06/02/2022 21:50:52 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=199
06/02/2022 21:50:53 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.7955566403842266 on epoch=199
06/02/2022 21:50:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=202
06/02/2022 21:50:57 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=204
06/02/2022 21:51:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=207
06/02/2022 21:51:02 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=209
06/02/2022 21:51:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=212
06/02/2022 21:51:06 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.7978621254483323 on epoch=212
06/02/2022 21:51:08 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=214
06/02/2022 21:51:10 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=217
06/02/2022 21:51:13 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=219
06/02/2022 21:51:15 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=222
06/02/2022 21:51:18 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=224
06/02/2022 21:51:19 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.7983966652830751 on epoch=224
06/02/2022 21:51:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=227
06/02/2022 21:51:24 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=229
06/02/2022 21:51:26 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=232
06/02/2022 21:51:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=234
06/02/2022 21:51:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=237
06/02/2022 21:51:32 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.79593837535014 on epoch=237
06/02/2022 21:51:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=239
06/02/2022 21:51:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=242
06/02/2022 21:51:39 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=244
06/02/2022 21:51:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=247
06/02/2022 21:51:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=249
06/02/2022 21:51:45 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.7944170771756979 on epoch=249
06/02/2022 21:51:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=252
06/02/2022 21:51:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=254
06/02/2022 21:51:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=257
06/02/2022 21:51:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=259
06/02/2022 21:51:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=262
06/02/2022 21:51:58 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.7653013399717254 on epoch=262
06/02/2022 21:52:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=264
06/02/2022 21:52:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=267
06/02/2022 21:52:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=269
06/02/2022 21:52:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=272
06/02/2022 21:52:10 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=274
06/02/2022 21:52:11 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.7483188257381805 on epoch=274
06/02/2022 21:52:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
06/02/2022 21:52:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=279
06/02/2022 21:52:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=282
06/02/2022 21:52:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=284
06/02/2022 21:52:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=287
06/02/2022 21:52:24 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.7797619047619047 on epoch=287
06/02/2022 21:52:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=289
06/02/2022 21:52:29 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=292
06/02/2022 21:52:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=294
06/02/2022 21:52:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
06/02/2022 21:52:36 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=299
06/02/2022 21:52:37 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.7641649763353617 on epoch=299
06/02/2022 21:52:39 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=302
06/02/2022 21:52:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
06/02/2022 21:52:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=307
06/02/2022 21:52:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=309
06/02/2022 21:52:49 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/02/2022 21:52:50 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7498763728365246 on epoch=312
06/02/2022 21:52:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/02/2022 21:52:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/02/2022 21:52:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=319
06/02/2022 21:52:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=322
06/02/2022 21:53:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=324
06/02/2022 21:53:03 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.7640295467881674 on epoch=324
06/02/2022 21:53:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=327
06/02/2022 21:53:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/02/2022 21:53:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=332
06/02/2022 21:53:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=334
06/02/2022 21:53:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=337
06/02/2022 21:53:16 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.7346069947849703 on epoch=337
06/02/2022 21:53:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=339
06/02/2022 21:53:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=342
06/02/2022 21:53:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=344
06/02/2022 21:53:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/02/2022 21:53:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
06/02/2022 21:53:29 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7494274684289732 on epoch=349
06/02/2022 21:53:31 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/02/2022 21:53:34 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=354
06/02/2022 21:53:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=357
06/02/2022 21:53:39 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/02/2022 21:53:41 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=362
06/02/2022 21:53:42 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7641649763353617 on epoch=362
06/02/2022 21:53:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=364
06/02/2022 21:53:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
06/02/2022 21:53:49 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=369
06/02/2022 21:53:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/02/2022 21:53:54 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/02/2022 21:53:55 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7313137313137312 on epoch=374
06/02/2022 21:53:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=377
06/02/2022 21:54:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=379
06/02/2022 21:54:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=382
06/02/2022 21:54:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/02/2022 21:54:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/02/2022 21:54:08 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7653828197945844 on epoch=387
06/02/2022 21:54:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=389
06/02/2022 21:54:13 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=392
06/02/2022 21:54:15 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/02/2022 21:54:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=397
06/02/2022 21:54:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=399
06/02/2022 21:54:21 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7335195727036333 on epoch=399
06/02/2022 21:54:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=402
06/02/2022 21:54:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/02/2022 21:54:28 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=407
06/02/2022 21:54:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/02/2022 21:54:33 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=412
06/02/2022 21:54:34 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7498792620496475 on epoch=412
06/02/2022 21:54:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/02/2022 21:54:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=417
06/02/2022 21:54:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=419
06/02/2022 21:54:44 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/02/2022 21:54:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/02/2022 21:54:47 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7977695675971537 on epoch=424
06/02/2022 21:54:50 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/02/2022 21:54:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=429
06/02/2022 21:54:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=432
06/02/2022 21:54:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=434
06/02/2022 21:54:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=437
06/02/2022 21:55:00 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7498792620496475 on epoch=437
06/02/2022 21:55:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/02/2022 21:55:05 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/02/2022 21:55:08 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=444
06/02/2022 21:55:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
06/02/2022 21:55:12 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
06/02/2022 21:55:13 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7498792620496475 on epoch=449
06/02/2022 21:55:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/02/2022 21:55:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=454
06/02/2022 21:55:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=457
06/02/2022 21:55:23 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/02/2022 21:55:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=462
06/02/2022 21:55:27 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.7644026471612679 on epoch=462
06/02/2022 21:55:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/02/2022 21:55:31 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/02/2022 21:55:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/02/2022 21:55:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=472
06/02/2022 21:55:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/02/2022 21:55:40 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7810693138279344 on epoch=474
06/02/2022 21:55:42 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/02/2022 21:55:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=479
06/02/2022 21:55:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/02/2022 21:55:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/02/2022 21:55:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=487
06/02/2022 21:55:53 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7635900606488841 on epoch=487
06/02/2022 21:55:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=489
06/02/2022 21:55:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/02/2022 21:56:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=494
06/02/2022 21:56:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/02/2022 21:56:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/02/2022 21:56:06 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7810693138279344 on epoch=499
06/02/2022 21:56:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/02/2022 21:56:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/02/2022 21:56:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/02/2022 21:56:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/02/2022 21:56:18 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/02/2022 21:56:19 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7810693138279344 on epoch=512
06/02/2022 21:56:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=514
06/02/2022 21:56:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=517
06/02/2022 21:56:26 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/02/2022 21:56:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/02/2022 21:56:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/02/2022 21:56:32 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7822660098522167 on epoch=524
06/02/2022 21:56:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=527
06/02/2022 21:56:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/02/2022 21:56:39 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=532
06/02/2022 21:56:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/02/2022 21:56:44 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/02/2022 21:56:45 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7347215860760321 on epoch=537
06/02/2022 21:56:47 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=539
06/02/2022 21:56:50 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/02/2022 21:56:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/02/2022 21:56:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/02/2022 21:56:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/02/2022 21:56:58 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7780911315927863 on epoch=549
06/02/2022 21:57:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/02/2022 21:57:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/02/2022 21:57:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/02/2022 21:57:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.10 on epoch=559
06/02/2022 21:57:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=562
06/02/2022 21:57:11 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7497585099364854 on epoch=562
06/02/2022 21:57:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/02/2022 21:57:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/02/2022 21:57:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/02/2022 21:57:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/02/2022 21:57:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/02/2022 21:57:24 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7961009711009711 on epoch=574
06/02/2022 21:57:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/02/2022 21:57:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
06/02/2022 21:57:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/02/2022 21:57:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/02/2022 21:57:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/02/2022 21:57:37 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7662395847879718 on epoch=587
06/02/2022 21:57:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/02/2022 21:57:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=592
06/02/2022 21:57:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.09 on epoch=594
06/02/2022 21:57:46 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=597
06/02/2022 21:57:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/02/2022 21:57:50 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7509803921568627 on epoch=599
06/02/2022 21:57:52 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/02/2022 21:57:54 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/02/2022 21:57:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=607
06/02/2022 21:57:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/02/2022 21:58:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/02/2022 21:58:03 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.766017316017316 on epoch=612
06/02/2022 21:58:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=614
06/02/2022 21:58:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=617
06/02/2022 21:58:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/02/2022 21:58:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=622
06/02/2022 21:58:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/02/2022 21:58:16 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7810693138279344 on epoch=624
06/02/2022 21:58:18 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/02/2022 21:58:20 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/02/2022 21:58:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/02/2022 21:58:25 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.07 on epoch=634
06/02/2022 21:58:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/02/2022 21:58:29 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7811552859727301 on epoch=637
06/02/2022 21:58:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=639
06/02/2022 21:58:33 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/02/2022 21:58:36 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=644
06/02/2022 21:58:38 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/02/2022 21:58:41 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
06/02/2022 21:58:42 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7977695675971538 on epoch=649
06/02/2022 21:58:44 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/02/2022 21:58:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/02/2022 21:58:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/02/2022 21:58:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/02/2022 21:58:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/02/2022 21:58:54 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7977695675971538 on epoch=662
06/02/2022 21:58:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/02/2022 21:58:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/02/2022 21:59:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=669
06/02/2022 21:59:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=672
06/02/2022 21:59:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/02/2022 21:59:07 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7310518334711883 on epoch=674
06/02/2022 21:59:10 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/02/2022 21:59:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/02/2022 21:59:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/02/2022 21:59:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=684
06/02/2022 21:59:20 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/02/2022 21:59:21 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7501105525299072 on epoch=687
06/02/2022 21:59:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/02/2022 21:59:25 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/02/2022 21:59:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/02/2022 21:59:30 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=697
06/02/2022 21:59:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/02/2022 21:59:34 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7347215860760321 on epoch=699
06/02/2022 21:59:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/02/2022 21:59:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=704
06/02/2022 21:59:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/02/2022 21:59:43 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/02/2022 21:59:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/02/2022 21:59:47 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7805281882868089 on epoch=712
06/02/2022 21:59:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/02/2022 21:59:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=717
06/02/2022 21:59:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/02/2022 21:59:56 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/02/2022 21:59:59 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=724
06/02/2022 22:00:00 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7822660098522167 on epoch=724
06/02/2022 22:00:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/02/2022 22:00:05 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/02/2022 22:00:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=732
06/02/2022 22:00:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/02/2022 22:00:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/02/2022 22:00:13 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7314102564102565 on epoch=737
06/02/2022 22:00:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/02/2022 22:00:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/02/2022 22:00:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/02/2022 22:00:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/02/2022 22:00:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/02/2022 22:00:26 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7314102564102565 on epoch=749
06/02/2022 22:00:26 - INFO - __main__ - save last model!
06/02/2022 22:00:26 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 22:00:26 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 22:00:26 - INFO - __main__ - Printing 3 examples
06/02/2022 22:00:26 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 22:00:26 - INFO - __main__ - ['others']
06/02/2022 22:00:26 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 22:00:26 - INFO - __main__ - ['others']
06/02/2022 22:00:26 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 22:00:26 - INFO - __main__ - ['others']
06/02/2022 22:00:26 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:00:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:00:26 - INFO - __main__ - Printing 3 examples
06/02/2022 22:00:26 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/02/2022 22:00:26 - INFO - __main__ - ['others']
06/02/2022 22:00:26 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/02/2022 22:00:26 - INFO - __main__ - ['others']
06/02/2022 22:00:26 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/02/2022 22:00:26 - INFO - __main__ - ['others']
06/02/2022 22:00:26 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:00:26 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:00:26 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 22:00:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:00:26 - INFO - __main__ - Printing 3 examples
06/02/2022 22:00:26 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/02/2022 22:00:26 - INFO - __main__ - ['others']
06/02/2022 22:00:26 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/02/2022 22:00:26 - INFO - __main__ - ['others']
06/02/2022 22:00:26 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/02/2022 22:00:26 - INFO - __main__ - ['others']
06/02/2022 22:00:26 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:00:26 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:00:26 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 22:00:28 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:00:34 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 22:00:45 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 22:00:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 22:00:46 - INFO - __main__ - Starting training!
06/02/2022 22:01:57 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_13_0.3_8_predictions.txt
06/02/2022 22:01:57 - INFO - __main__ - Classification-F1 on test data: 0.2549
06/02/2022 22:01:58 - INFO - __main__ - prefix=emo_16_13, lr=0.3, bsz=8, dev_performance=0.8123587365980874, test_performance=0.2549343162910424
06/02/2022 22:01:58 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.2, bsz=8 ...
06/02/2022 22:01:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:01:59 - INFO - __main__ - Printing 3 examples
06/02/2022 22:01:59 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/02/2022 22:01:59 - INFO - __main__ - ['others']
06/02/2022 22:01:59 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/02/2022 22:01:59 - INFO - __main__ - ['others']
06/02/2022 22:01:59 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/02/2022 22:01:59 - INFO - __main__ - ['others']
06/02/2022 22:01:59 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:01:59 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:01:59 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 22:01:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:01:59 - INFO - __main__ - Printing 3 examples
06/02/2022 22:01:59 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/02/2022 22:01:59 - INFO - __main__ - ['others']
06/02/2022 22:01:59 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/02/2022 22:01:59 - INFO - __main__ - ['others']
06/02/2022 22:01:59 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/02/2022 22:01:59 - INFO - __main__ - ['others']
06/02/2022 22:01:59 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:01:59 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:01:59 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 22:02:17 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 22:02:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 22:02:18 - INFO - __main__ - Starting training!
06/02/2022 22:02:21 - INFO - __main__ - Step 10 Global step 10 Train loss 4.20 on epoch=2
06/02/2022 22:02:23 - INFO - __main__ - Step 20 Global step 20 Train loss 3.75 on epoch=4
06/02/2022 22:02:26 - INFO - __main__ - Step 30 Global step 30 Train loss 3.21 on epoch=7
06/02/2022 22:02:28 - INFO - __main__ - Step 40 Global step 40 Train loss 2.89 on epoch=9
06/02/2022 22:02:31 - INFO - __main__ - Step 50 Global step 50 Train loss 2.51 on epoch=12
06/02/2022 22:02:32 - INFO - __main__ - Global step 50 Train loss 3.31 Classification-F1 0.0 on epoch=12
06/02/2022 22:02:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/02/2022 22:02:34 - INFO - __main__ - Step 60 Global step 60 Train loss 2.22 on epoch=14
06/02/2022 22:02:37 - INFO - __main__ - Step 70 Global step 70 Train loss 2.09 on epoch=17
06/02/2022 22:02:39 - INFO - __main__ - Step 80 Global step 80 Train loss 1.85 on epoch=19
06/02/2022 22:02:42 - INFO - __main__ - Step 90 Global step 90 Train loss 1.64 on epoch=22
06/02/2022 22:02:44 - INFO - __main__ - Step 100 Global step 100 Train loss 1.64 on epoch=24
06/02/2022 22:02:45 - INFO - __main__ - Global step 100 Train loss 1.89 Classification-F1 0.09876543209876544 on epoch=24
06/02/2022 22:02:45 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.09876543209876544 on epoch=24, global_step=100
06/02/2022 22:02:48 - INFO - __main__ - Step 110 Global step 110 Train loss 1.48 on epoch=27
06/02/2022 22:02:50 - INFO - __main__ - Step 120 Global step 120 Train loss 1.28 on epoch=29
06/02/2022 22:02:53 - INFO - __main__ - Step 130 Global step 130 Train loss 1.32 on epoch=32
06/02/2022 22:02:55 - INFO - __main__ - Step 140 Global step 140 Train loss 1.00 on epoch=34
06/02/2022 22:02:58 - INFO - __main__ - Step 150 Global step 150 Train loss 1.09 on epoch=37
06/02/2022 22:02:58 - INFO - __main__ - Global step 150 Train loss 1.23 Classification-F1 0.38673688029850595 on epoch=37
06/02/2022 22:02:58 - INFO - __main__ - Saving model with best Classification-F1: 0.09876543209876544 -> 0.38673688029850595 on epoch=37, global_step=150
06/02/2022 22:03:01 - INFO - __main__ - Step 160 Global step 160 Train loss 0.98 on epoch=39
06/02/2022 22:03:03 - INFO - __main__ - Step 170 Global step 170 Train loss 0.91 on epoch=42
06/02/2022 22:03:06 - INFO - __main__ - Step 180 Global step 180 Train loss 0.94 on epoch=44
06/02/2022 22:03:08 - INFO - __main__ - Step 190 Global step 190 Train loss 0.76 on epoch=47
06/02/2022 22:03:11 - INFO - __main__ - Step 200 Global step 200 Train loss 0.76 on epoch=49
06/02/2022 22:03:12 - INFO - __main__ - Global step 200 Train loss 0.87 Classification-F1 0.5347222222222223 on epoch=49
06/02/2022 22:03:12 - INFO - __main__ - Saving model with best Classification-F1: 0.38673688029850595 -> 0.5347222222222223 on epoch=49, global_step=200
06/02/2022 22:03:14 - INFO - __main__ - Step 210 Global step 210 Train loss 0.78 on epoch=52
06/02/2022 22:03:17 - INFO - __main__ - Step 220 Global step 220 Train loss 0.72 on epoch=54
06/02/2022 22:03:19 - INFO - __main__ - Step 230 Global step 230 Train loss 0.74 on epoch=57
06/02/2022 22:03:21 - INFO - __main__ - Step 240 Global step 240 Train loss 0.68 on epoch=59
06/02/2022 22:03:24 - INFO - __main__ - Step 250 Global step 250 Train loss 0.78 on epoch=62
06/02/2022 22:03:25 - INFO - __main__ - Global step 250 Train loss 0.74 Classification-F1 0.6809906597774245 on epoch=62
06/02/2022 22:03:25 - INFO - __main__ - Saving model with best Classification-F1: 0.5347222222222223 -> 0.6809906597774245 on epoch=62, global_step=250
06/02/2022 22:03:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=64
06/02/2022 22:03:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.65 on epoch=67
06/02/2022 22:03:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.76 on epoch=69
06/02/2022 22:03:35 - INFO - __main__ - Step 290 Global step 290 Train loss 0.73 on epoch=72
06/02/2022 22:03:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.53 on epoch=74
06/02/2022 22:03:38 - INFO - __main__ - Global step 300 Train loss 0.65 Classification-F1 0.6585424379542026 on epoch=74
06/02/2022 22:03:40 - INFO - __main__ - Step 310 Global step 310 Train loss 0.76 on epoch=77
06/02/2022 22:03:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.69 on epoch=79
06/02/2022 22:03:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.81 on epoch=82
06/02/2022 22:03:48 - INFO - __main__ - Step 340 Global step 340 Train loss 0.65 on epoch=84
06/02/2022 22:03:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.58 on epoch=87
06/02/2022 22:03:51 - INFO - __main__ - Global step 350 Train loss 0.70 Classification-F1 0.7260436432637571 on epoch=87
06/02/2022 22:03:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6809906597774245 -> 0.7260436432637571 on epoch=87, global_step=350
06/02/2022 22:03:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.57 on epoch=89
06/02/2022 22:03:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.63 on epoch=92
06/02/2022 22:03:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.65 on epoch=94
06/02/2022 22:04:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.63 on epoch=97
06/02/2022 22:04:04 - INFO - __main__ - Step 400 Global step 400 Train loss 0.54 on epoch=99
06/02/2022 22:04:04 - INFO - __main__ - Global step 400 Train loss 0.60 Classification-F1 0.7292717086834734 on epoch=99
06/02/2022 22:04:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7260436432637571 -> 0.7292717086834734 on epoch=99, global_step=400
06/02/2022 22:04:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.61 on epoch=102
06/02/2022 22:04:09 - INFO - __main__ - Step 420 Global step 420 Train loss 0.62 on epoch=104
06/02/2022 22:04:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.61 on epoch=107
06/02/2022 22:04:14 - INFO - __main__ - Step 440 Global step 440 Train loss 0.52 on epoch=109
06/02/2022 22:04:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.52 on epoch=112
06/02/2022 22:04:18 - INFO - __main__ - Global step 450 Train loss 0.58 Classification-F1 0.7471774193548387 on epoch=112
06/02/2022 22:04:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7292717086834734 -> 0.7471774193548387 on epoch=112, global_step=450
06/02/2022 22:04:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.54 on epoch=114
06/02/2022 22:04:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.51 on epoch=117
06/02/2022 22:04:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.53 on epoch=119
06/02/2022 22:04:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.54 on epoch=122
06/02/2022 22:04:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.43 on epoch=124
06/02/2022 22:04:31 - INFO - __main__ - Global step 500 Train loss 0.51 Classification-F1 0.7312834224598931 on epoch=124
06/02/2022 22:04:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.47 on epoch=127
06/02/2022 22:04:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.48 on epoch=129
06/02/2022 22:04:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.54 on epoch=132
06/02/2022 22:04:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.44 on epoch=134
06/02/2022 22:04:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.48 on epoch=137
06/02/2022 22:04:44 - INFO - __main__ - Global step 550 Train loss 0.48 Classification-F1 0.7653291920216363 on epoch=137
06/02/2022 22:04:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7471774193548387 -> 0.7653291920216363 on epoch=137, global_step=550
06/02/2022 22:04:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.48 on epoch=139
06/02/2022 22:04:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.44 on epoch=142
06/02/2022 22:04:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.40 on epoch=144
06/02/2022 22:04:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.47 on epoch=147
06/02/2022 22:04:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.41 on epoch=149
06/02/2022 22:04:57 - INFO - __main__ - Global step 600 Train loss 0.44 Classification-F1 0.7802849727210127 on epoch=149
06/02/2022 22:04:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7653291920216363 -> 0.7802849727210127 on epoch=149, global_step=600
06/02/2022 22:05:00 - INFO - __main__ - Step 610 Global step 610 Train loss 0.53 on epoch=152
06/02/2022 22:05:02 - INFO - __main__ - Step 620 Global step 620 Train loss 0.37 on epoch=154
06/02/2022 22:05:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.42 on epoch=157
06/02/2022 22:05:07 - INFO - __main__ - Step 640 Global step 640 Train loss 0.50 on epoch=159
06/02/2022 22:05:09 - INFO - __main__ - Step 650 Global step 650 Train loss 0.45 on epoch=162
06/02/2022 22:05:10 - INFO - __main__ - Global step 650 Train loss 0.46 Classification-F1 0.7661764705882352 on epoch=162
06/02/2022 22:05:13 - INFO - __main__ - Step 660 Global step 660 Train loss 0.51 on epoch=164
06/02/2022 22:05:15 - INFO - __main__ - Step 670 Global step 670 Train loss 0.47 on epoch=167
06/02/2022 22:05:18 - INFO - __main__ - Step 680 Global step 680 Train loss 0.41 on epoch=169
06/02/2022 22:05:20 - INFO - __main__ - Step 690 Global step 690 Train loss 0.39 on epoch=172
06/02/2022 22:05:23 - INFO - __main__ - Step 700 Global step 700 Train loss 0.40 on epoch=174
06/02/2022 22:05:23 - INFO - __main__ - Global step 700 Train loss 0.44 Classification-F1 0.7661764705882352 on epoch=174
06/02/2022 22:05:26 - INFO - __main__ - Step 710 Global step 710 Train loss 0.35 on epoch=177
06/02/2022 22:05:28 - INFO - __main__ - Step 720 Global step 720 Train loss 0.38 on epoch=179
06/02/2022 22:05:31 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=182
06/02/2022 22:05:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.31 on epoch=184
06/02/2022 22:05:36 - INFO - __main__ - Step 750 Global step 750 Train loss 0.36 on epoch=187
06/02/2022 22:05:37 - INFO - __main__ - Global step 750 Train loss 0.33 Classification-F1 0.7819900687547747 on epoch=187
06/02/2022 22:05:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7802849727210127 -> 0.7819900687547747 on epoch=187, global_step=750
06/02/2022 22:05:39 - INFO - __main__ - Step 760 Global step 760 Train loss 0.35 on epoch=189
06/02/2022 22:05:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=192
06/02/2022 22:05:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.32 on epoch=194
06/02/2022 22:05:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.31 on epoch=197
06/02/2022 22:05:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.32 on epoch=199
06/02/2022 22:05:50 - INFO - __main__ - Global step 800 Train loss 0.31 Classification-F1 0.7984201799725993 on epoch=199
06/02/2022 22:05:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7819900687547747 -> 0.7984201799725993 on epoch=199, global_step=800
06/02/2022 22:05:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.32 on epoch=202
06/02/2022 22:05:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.33 on epoch=204
06/02/2022 22:05:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.36 on epoch=207
06/02/2022 22:06:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.31 on epoch=209
06/02/2022 22:06:02 - INFO - __main__ - Step 850 Global step 850 Train loss 0.29 on epoch=212
06/02/2022 22:06:03 - INFO - __main__ - Global step 850 Train loss 0.32 Classification-F1 0.7983106931382793 on epoch=212
06/02/2022 22:06:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.27 on epoch=214
06/02/2022 22:06:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.30 on epoch=217
06/02/2022 22:06:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.29 on epoch=219
06/02/2022 22:06:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.39 on epoch=222
06/02/2022 22:06:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.31 on epoch=224
06/02/2022 22:06:16 - INFO - __main__ - Global step 900 Train loss 0.31 Classification-F1 0.8287715517241379 on epoch=224
06/02/2022 22:06:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7984201799725993 -> 0.8287715517241379 on epoch=224, global_step=900
06/02/2022 22:06:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=227
06/02/2022 22:06:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.25 on epoch=229
06/02/2022 22:06:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=232
06/02/2022 22:06:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=234
06/02/2022 22:06:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.32 on epoch=237
06/02/2022 22:06:30 - INFO - __main__ - Global step 950 Train loss 0.23 Classification-F1 0.7975201321975516 on epoch=237
06/02/2022 22:06:32 - INFO - __main__ - Step 960 Global step 960 Train loss 0.33 on epoch=239
06/02/2022 22:06:35 - INFO - __main__ - Step 970 Global step 970 Train loss 0.26 on epoch=242
06/02/2022 22:06:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.34 on epoch=244
06/02/2022 22:06:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.28 on epoch=247
06/02/2022 22:06:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.25 on epoch=249
06/02/2022 22:06:43 - INFO - __main__ - Global step 1000 Train loss 0.29 Classification-F1 0.7970480668756531 on epoch=249
06/02/2022 22:06:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.22 on epoch=252
06/02/2022 22:06:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.23 on epoch=254
06/02/2022 22:06:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=257
06/02/2022 22:06:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=259
06/02/2022 22:06:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.20 on epoch=262
06/02/2022 22:06:56 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.7648557071731513 on epoch=262
06/02/2022 22:06:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.26 on epoch=264
06/02/2022 22:07:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=267
06/02/2022 22:07:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.21 on epoch=269
06/02/2022 22:07:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.21 on epoch=272
06/02/2022 22:07:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=274
06/02/2022 22:07:09 - INFO - __main__ - Global step 1100 Train loss 0.21 Classification-F1 0.7939153439153438 on epoch=274
06/02/2022 22:07:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.19 on epoch=277
06/02/2022 22:07:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.38 on epoch=279
06/02/2022 22:07:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.25 on epoch=282
06/02/2022 22:07:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.17 on epoch=284
06/02/2022 22:07:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=287
06/02/2022 22:07:23 - INFO - __main__ - Global step 1150 Train loss 0.23 Classification-F1 0.7958593114665221 on epoch=287
06/02/2022 22:07:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=289
06/02/2022 22:07:28 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.19 on epoch=292
06/02/2022 22:07:30 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.21 on epoch=294
06/02/2022 22:07:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=297
06/02/2022 22:07:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=299
06/02/2022 22:07:36 - INFO - __main__ - Global step 1200 Train loss 0.16 Classification-F1 0.7958593114665221 on epoch=299
06/02/2022 22:07:39 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.19 on epoch=302
06/02/2022 22:07:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=304
06/02/2022 22:07:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.24 on epoch=307
06/02/2022 22:07:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=309
06/02/2022 22:07:48 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=312
06/02/2022 22:07:49 - INFO - __main__ - Global step 1250 Train loss 0.17 Classification-F1 0.7790603696675803 on epoch=312
06/02/2022 22:07:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=314
06/02/2022 22:07:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.19 on epoch=317
06/02/2022 22:07:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.17 on epoch=319
06/02/2022 22:07:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=322
06/02/2022 22:08:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=324
06/02/2022 22:08:03 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.7951173572877427 on epoch=324
06/02/2022 22:08:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=327
06/02/2022 22:08:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.25 on epoch=329
06/02/2022 22:08:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=332
06/02/2022 22:08:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=334
06/02/2022 22:08:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=337
06/02/2022 22:08:16 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.7802623830399792 on epoch=337
06/02/2022 22:08:19 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=339
06/02/2022 22:08:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.20 on epoch=342
06/02/2022 22:08:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=344
06/02/2022 22:08:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=347
06/02/2022 22:08:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=349
06/02/2022 22:08:29 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.7939153439153438 on epoch=349
06/02/2022 22:08:32 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=352
06/02/2022 22:08:34 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=354
06/02/2022 22:08:37 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=357
06/02/2022 22:08:39 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=359
06/02/2022 22:08:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.24 on epoch=362
06/02/2022 22:08:43 - INFO - __main__ - Global step 1450 Train loss 0.14 Classification-F1 0.764434004857392 on epoch=362
06/02/2022 22:08:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=364
06/02/2022 22:08:48 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.13 on epoch=367
06/02/2022 22:08:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=369
06/02/2022 22:08:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.13 on epoch=372
06/02/2022 22:08:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=374
06/02/2022 22:08:56 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.7785714285714286 on epoch=374
06/02/2022 22:08:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=377
06/02/2022 22:09:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=379
06/02/2022 22:09:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=382
06/02/2022 22:09:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=384
06/02/2022 22:09:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.15 on epoch=387
06/02/2022 22:09:09 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.7637164543236651 on epoch=387
06/02/2022 22:09:12 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=389
06/02/2022 22:09:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=392
06/02/2022 22:09:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=394
06/02/2022 22:09:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=397
06/02/2022 22:09:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.14 on epoch=399
06/02/2022 22:09:23 - INFO - __main__ - Global step 1600 Train loss 0.12 Classification-F1 0.7622742200328408 on epoch=399
06/02/2022 22:09:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=402
06/02/2022 22:09:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/02/2022 22:09:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.12 on epoch=407
06/02/2022 22:09:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=409
06/02/2022 22:09:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.14 on epoch=412
06/02/2022 22:09:36 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.7637164543236651 on epoch=412
06/02/2022 22:09:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=414
06/02/2022 22:09:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=417
06/02/2022 22:09:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=419
06/02/2022 22:09:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=422
06/02/2022 22:09:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=424
06/02/2022 22:09:49 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.7776181353767561 on epoch=424
06/02/2022 22:09:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=427
06/02/2022 22:09:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=429
06/02/2022 22:09:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=432
06/02/2022 22:09:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.15 on epoch=434
06/02/2022 22:10:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=437
06/02/2022 22:10:03 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.7776181353767561 on epoch=437
06/02/2022 22:10:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=439
06/02/2022 22:10:08 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=442
06/02/2022 22:10:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=444
06/02/2022 22:10:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=447
06/02/2022 22:10:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/02/2022 22:10:16 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.7469426218065056 on epoch=449
06/02/2022 22:10:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=452
06/02/2022 22:10:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=454
06/02/2022 22:10:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=457
06/02/2022 22:10:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=459
06/02/2022 22:10:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=462
06/02/2022 22:10:29 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.7790603696675803 on epoch=462
06/02/2022 22:10:32 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=464
06/02/2022 22:10:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=467
06/02/2022 22:10:37 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/02/2022 22:10:39 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=472
06/02/2022 22:10:42 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=474
06/02/2022 22:10:42 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.7455994455994455 on epoch=474
06/02/2022 22:10:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=477
06/02/2022 22:10:47 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=479
06/02/2022 22:10:50 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=482
06/02/2022 22:10:52 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=484
06/02/2022 22:10:55 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=487
06/02/2022 22:10:56 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.7790603696675803 on epoch=487
06/02/2022 22:10:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=489
06/02/2022 22:11:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=492
06/02/2022 22:11:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=494
06/02/2022 22:11:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=497
06/02/2022 22:11:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=499
06/02/2022 22:11:09 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7790603696675803 on epoch=499
06/02/2022 22:11:11 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.10 on epoch=502
06/02/2022 22:11:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/02/2022 22:11:16 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/02/2022 22:11:19 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
06/02/2022 22:11:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.11 on epoch=512
06/02/2022 22:11:22 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.7629629629629628 on epoch=512
06/02/2022 22:11:25 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=514
06/02/2022 22:11:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
06/02/2022 22:11:30 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=519
06/02/2022 22:11:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=522
06/02/2022 22:11:35 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=524
06/02/2022 22:11:36 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.7602546180132387 on epoch=524
06/02/2022 22:11:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=527
06/02/2022 22:11:41 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/02/2022 22:11:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=532
06/02/2022 22:11:46 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/02/2022 22:11:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=537
06/02/2022 22:11:49 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7107921714818266 on epoch=537
06/02/2022 22:11:51 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=539
06/02/2022 22:11:54 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=542
06/02/2022 22:11:56 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/02/2022 22:11:59 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/02/2022 22:12:01 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=549
06/02/2022 22:12:02 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7251290388132494 on epoch=549
06/02/2022 22:12:05 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/02/2022 22:12:07 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=554
06/02/2022 22:12:10 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/02/2022 22:12:12 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=559
06/02/2022 22:12:15 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/02/2022 22:12:16 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7019704433497538 on epoch=562
06/02/2022 22:12:18 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=564
06/02/2022 22:12:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=567
06/02/2022 22:12:23 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=569
06/02/2022 22:12:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/02/2022 22:12:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=574
06/02/2022 22:12:29 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7455994455994455 on epoch=574
06/02/2022 22:12:32 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/02/2022 22:12:34 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=579
06/02/2022 22:12:36 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=582
06/02/2022 22:12:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=584
06/02/2022 22:12:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.11 on epoch=587
06/02/2022 22:12:42 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.7145748987854251 on epoch=587
06/02/2022 22:12:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=589
06/02/2022 22:12:47 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=592
06/02/2022 22:12:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=594
06/02/2022 22:12:52 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=597
06/02/2022 22:12:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=599
06/02/2022 22:12:56 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.7497438325024531 on epoch=599
06/02/2022 22:12:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/02/2022 22:13:01 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/02/2022 22:13:03 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=607
06/02/2022 22:13:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/02/2022 22:13:08 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=612
06/02/2022 22:13:09 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.75 on epoch=612
06/02/2022 22:13:11 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/02/2022 22:13:14 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=617
06/02/2022 22:13:16 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=619
06/02/2022 22:13:19 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=622
06/02/2022 22:13:21 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.09 on epoch=624
06/02/2022 22:13:22 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.7665459287163141 on epoch=624
06/02/2022 22:13:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/02/2022 22:13:27 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=629
06/02/2022 22:13:30 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.09 on epoch=632
06/02/2022 22:13:32 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=634
06/02/2022 22:13:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/02/2022 22:13:36 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7485922607626461 on epoch=637
06/02/2022 22:13:38 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=639
06/02/2022 22:13:41 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=642
06/02/2022 22:13:43 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/02/2022 22:13:46 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=647
06/02/2022 22:13:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=649
06/02/2022 22:13:49 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7652473902473901 on epoch=649
06/02/2022 22:13:52 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=652
06/02/2022 22:13:54 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.12 on epoch=654
06/02/2022 22:13:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=657
06/02/2022 22:13:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=659
06/02/2022 22:14:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=662
06/02/2022 22:14:02 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.7490105719707238 on epoch=662
06/02/2022 22:14:05 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/02/2022 22:14:07 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.10 on epoch=667
06/02/2022 22:14:10 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/02/2022 22:14:12 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/02/2022 22:14:15 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=674
06/02/2022 22:14:16 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7643544873146391 on epoch=674
06/02/2022 22:14:18 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/02/2022 22:14:21 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/02/2022 22:14:23 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=682
06/02/2022 22:14:26 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=684
06/02/2022 22:14:28 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=687
06/02/2022 22:14:29 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7303656597774244 on epoch=687
06/02/2022 22:14:32 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/02/2022 22:14:34 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=692
06/02/2022 22:14:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=694
06/02/2022 22:14:39 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=697
06/02/2022 22:14:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=699
06/02/2022 22:14:42 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7490105719707238 on epoch=699
06/02/2022 22:14:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/02/2022 22:14:47 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/02/2022 22:14:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=707
06/02/2022 22:14:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=709
06/02/2022 22:14:55 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=712
06/02/2022 22:14:56 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7280335507921715 on epoch=712
06/02/2022 22:14:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=714
06/02/2022 22:15:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=717
06/02/2022 22:15:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=719
06/02/2022 22:15:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/02/2022 22:15:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=724
06/02/2022 22:15:09 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7338767338767338 on epoch=724
06/02/2022 22:15:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=727
06/02/2022 22:15:14 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/02/2022 22:15:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=732
06/02/2022 22:15:19 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/02/2022 22:15:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=737
06/02/2022 22:15:22 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7131433052485684 on epoch=737
06/02/2022 22:15:25 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
06/02/2022 22:15:27 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=742
06/02/2022 22:15:30 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/02/2022 22:15:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/02/2022 22:15:35 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=749
06/02/2022 22:15:35 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7162698412698413 on epoch=749
06/02/2022 22:15:35 - INFO - __main__ - save last model!
06/02/2022 22:15:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 22:15:36 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 22:15:36 - INFO - __main__ - Printing 3 examples
06/02/2022 22:15:36 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 22:15:36 - INFO - __main__ - ['others']
06/02/2022 22:15:36 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 22:15:36 - INFO - __main__ - ['others']
06/02/2022 22:15:36 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 22:15:36 - INFO - __main__ - ['others']
06/02/2022 22:15:36 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:15:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:15:36 - INFO - __main__ - Printing 3 examples
06/02/2022 22:15:36 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/02/2022 22:15:36 - INFO - __main__ - ['sad']
06/02/2022 22:15:36 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/02/2022 22:15:36 - INFO - __main__ - ['sad']
06/02/2022 22:15:36 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/02/2022 22:15:36 - INFO - __main__ - ['sad']
06/02/2022 22:15:36 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:15:36 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:15:36 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 22:15:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:15:36 - INFO - __main__ - Printing 3 examples
06/02/2022 22:15:36 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/02/2022 22:15:36 - INFO - __main__ - ['sad']
06/02/2022 22:15:36 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/02/2022 22:15:36 - INFO - __main__ - ['sad']
06/02/2022 22:15:36 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/02/2022 22:15:36 - INFO - __main__ - ['sad']
06/02/2022 22:15:36 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:15:36 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:15:36 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 22:15:38 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:15:43 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 22:15:55 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 22:15:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 22:15:55 - INFO - __main__ - Starting training!
06/02/2022 22:17:06 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_13_0.2_8_predictions.txt
06/02/2022 22:17:06 - INFO - __main__ - Classification-F1 on test data: 0.2243
06/02/2022 22:17:06 - INFO - __main__ - prefix=emo_16_13, lr=0.2, bsz=8, dev_performance=0.8287715517241379, test_performance=0.224310819401946
06/02/2022 22:17:06 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.5, bsz=8 ...
06/02/2022 22:17:07 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:17:07 - INFO - __main__ - Printing 3 examples
06/02/2022 22:17:07 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/02/2022 22:17:07 - INFO - __main__ - ['sad']
06/02/2022 22:17:07 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/02/2022 22:17:07 - INFO - __main__ - ['sad']
06/02/2022 22:17:07 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/02/2022 22:17:07 - INFO - __main__ - ['sad']
06/02/2022 22:17:07 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:17:07 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:17:07 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 22:17:07 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:17:07 - INFO - __main__ - Printing 3 examples
06/02/2022 22:17:07 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/02/2022 22:17:07 - INFO - __main__ - ['sad']
06/02/2022 22:17:07 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/02/2022 22:17:07 - INFO - __main__ - ['sad']
06/02/2022 22:17:07 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/02/2022 22:17:07 - INFO - __main__ - ['sad']
06/02/2022 22:17:07 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:17:07 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:17:07 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 22:17:26 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 22:17:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 22:17:27 - INFO - __main__ - Starting training!
06/02/2022 22:17:29 - INFO - __main__ - Step 10 Global step 10 Train loss 4.41 on epoch=2
06/02/2022 22:17:32 - INFO - __main__ - Step 20 Global step 20 Train loss 2.98 on epoch=4
06/02/2022 22:17:34 - INFO - __main__ - Step 30 Global step 30 Train loss 2.49 on epoch=7
06/02/2022 22:17:37 - INFO - __main__ - Step 40 Global step 40 Train loss 1.76 on epoch=9
06/02/2022 22:17:39 - INFO - __main__ - Step 50 Global step 50 Train loss 1.68 on epoch=12
06/02/2022 22:17:40 - INFO - __main__ - Global step 50 Train loss 2.66 Classification-F1 0.1354066985645933 on epoch=12
06/02/2022 22:17:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1354066985645933 on epoch=12, global_step=50
06/02/2022 22:17:43 - INFO - __main__ - Step 60 Global step 60 Train loss 1.07 on epoch=14
06/02/2022 22:17:45 - INFO - __main__ - Step 70 Global step 70 Train loss 1.00 on epoch=17
06/02/2022 22:17:47 - INFO - __main__ - Step 80 Global step 80 Train loss 0.89 on epoch=19
06/02/2022 22:17:50 - INFO - __main__ - Step 90 Global step 90 Train loss 0.86 on epoch=22
06/02/2022 22:17:52 - INFO - __main__ - Step 100 Global step 100 Train loss 0.77 on epoch=24
06/02/2022 22:17:53 - INFO - __main__ - Global step 100 Train loss 0.92 Classification-F1 0.5977053086801112 on epoch=24
06/02/2022 22:17:53 - INFO - __main__ - Saving model with best Classification-F1: 0.1354066985645933 -> 0.5977053086801112 on epoch=24, global_step=100
06/02/2022 22:17:56 - INFO - __main__ - Step 110 Global step 110 Train loss 0.67 on epoch=27
06/02/2022 22:17:58 - INFO - __main__ - Step 120 Global step 120 Train loss 0.69 on epoch=29
06/02/2022 22:18:01 - INFO - __main__ - Step 130 Global step 130 Train loss 0.61 on epoch=32
06/02/2022 22:18:03 - INFO - __main__ - Step 140 Global step 140 Train loss 0.63 on epoch=34
06/02/2022 22:18:06 - INFO - __main__ - Step 150 Global step 150 Train loss 0.67 on epoch=37
06/02/2022 22:18:06 - INFO - __main__ - Global step 150 Train loss 0.66 Classification-F1 0.6690066690066689 on epoch=37
06/02/2022 22:18:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5977053086801112 -> 0.6690066690066689 on epoch=37, global_step=150
06/02/2022 22:18:09 - INFO - __main__ - Step 160 Global step 160 Train loss 0.44 on epoch=39
06/02/2022 22:18:11 - INFO - __main__ - Step 170 Global step 170 Train loss 0.48 on epoch=42
06/02/2022 22:18:14 - INFO - __main__ - Step 180 Global step 180 Train loss 0.50 on epoch=44
06/02/2022 22:18:16 - INFO - __main__ - Step 190 Global step 190 Train loss 0.42 on epoch=47
06/02/2022 22:18:19 - INFO - __main__ - Step 200 Global step 200 Train loss 0.42 on epoch=49
06/02/2022 22:18:20 - INFO - __main__ - Global step 200 Train loss 0.45 Classification-F1 0.6710124127887287 on epoch=49
06/02/2022 22:18:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6690066690066689 -> 0.6710124127887287 on epoch=49, global_step=200
06/02/2022 22:18:22 - INFO - __main__ - Step 210 Global step 210 Train loss 0.50 on epoch=52
06/02/2022 22:18:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.39 on epoch=54
06/02/2022 22:18:27 - INFO - __main__ - Step 230 Global step 230 Train loss 0.54 on epoch=57
06/02/2022 22:18:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=59
06/02/2022 22:18:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.40 on epoch=62
06/02/2022 22:18:33 - INFO - __main__ - Global step 250 Train loss 0.44 Classification-F1 0.6259678713779081 on epoch=62
06/02/2022 22:18:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.36 on epoch=64
06/02/2022 22:18:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.52 on epoch=67
06/02/2022 22:18:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=69
06/02/2022 22:18:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.40 on epoch=72
06/02/2022 22:18:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=74
06/02/2022 22:18:46 - INFO - __main__ - Global step 300 Train loss 0.39 Classification-F1 0.6845259263022421 on epoch=74
06/02/2022 22:18:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6710124127887287 -> 0.6845259263022421 on epoch=74, global_step=300
06/02/2022 22:18:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.43 on epoch=77
06/02/2022 22:18:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.29 on epoch=79
06/02/2022 22:18:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.31 on epoch=82
06/02/2022 22:18:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.27 on epoch=84
06/02/2022 22:18:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=87
06/02/2022 22:18:59 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.6370370370370371 on epoch=87
06/02/2022 22:19:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=89
06/02/2022 22:19:04 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=92
06/02/2022 22:19:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=94
06/02/2022 22:19:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=97
06/02/2022 22:19:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=99
06/02/2022 22:19:13 - INFO - __main__ - Global step 400 Train loss 0.26 Classification-F1 0.6910968234981394 on epoch=99
06/02/2022 22:19:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6845259263022421 -> 0.6910968234981394 on epoch=99, global_step=400
06/02/2022 22:19:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.35 on epoch=102
06/02/2022 22:19:18 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=104
06/02/2022 22:19:20 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=107
06/02/2022 22:19:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=109
06/02/2022 22:19:25 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/02/2022 22:19:26 - INFO - __main__ - Global step 450 Train loss 0.26 Classification-F1 0.696701982228298 on epoch=112
06/02/2022 22:19:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6910968234981394 -> 0.696701982228298 on epoch=112, global_step=450
06/02/2022 22:19:28 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=114
06/02/2022 22:19:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=117
06/02/2022 22:19:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=119
06/02/2022 22:19:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=122
06/02/2022 22:19:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=124
06/02/2022 22:19:39 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.6333333333333333 on epoch=124
06/02/2022 22:19:41 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=127
06/02/2022 22:19:44 - INFO - __main__ - Step 520 Global step 520 Train loss 0.12 on epoch=129
06/02/2022 22:19:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=132
06/02/2022 22:19:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=134
06/02/2022 22:19:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=137
06/02/2022 22:19:52 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.6955312407898615 on epoch=137
06/02/2022 22:19:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.09 on epoch=139
06/02/2022 22:19:57 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=142
06/02/2022 22:19:59 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=144
06/02/2022 22:20:02 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=147
06/02/2022 22:20:04 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=149
06/02/2022 22:20:05 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.6978174603174604 on epoch=149
06/02/2022 22:20:05 - INFO - __main__ - Saving model with best Classification-F1: 0.696701982228298 -> 0.6978174603174604 on epoch=149, global_step=600
06/02/2022 22:20:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=152
06/02/2022 22:20:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=154
06/02/2022 22:20:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=157
06/02/2022 22:20:15 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=159
06/02/2022 22:20:18 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=162
06/02/2022 22:20:18 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.713444170771757 on epoch=162
06/02/2022 22:20:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6978174603174604 -> 0.713444170771757 on epoch=162, global_step=650
06/02/2022 22:20:21 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=164
06/02/2022 22:20:23 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=167
06/02/2022 22:20:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=169
06/02/2022 22:20:28 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=172
06/02/2022 22:20:31 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=174
06/02/2022 22:20:32 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.6340996168582376 on epoch=174
06/02/2022 22:20:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=177
06/02/2022 22:20:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/02/2022 22:20:39 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=182
06/02/2022 22:20:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=184
06/02/2022 22:20:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=187
06/02/2022 22:20:45 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.6645826522828812 on epoch=187
06/02/2022 22:20:47 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=189
06/02/2022 22:20:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=192
06/02/2022 22:20:52 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/02/2022 22:20:55 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=197
06/02/2022 22:20:57 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=199
06/02/2022 22:20:58 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.6962312312312312 on epoch=199
06/02/2022 22:21:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=202
06/02/2022 22:21:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=204
06/02/2022 22:21:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/02/2022 22:21:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=209
06/02/2022 22:21:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=212
06/02/2022 22:21:11 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.7325298540468819 on epoch=212
06/02/2022 22:21:11 - INFO - __main__ - Saving model with best Classification-F1: 0.713444170771757 -> 0.7325298540468819 on epoch=212, global_step=850
06/02/2022 22:21:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/02/2022 22:21:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=217
06/02/2022 22:21:19 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=219
06/02/2022 22:21:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=222
06/02/2022 22:21:24 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=224
06/02/2022 22:21:24 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.6911490683229813 on epoch=224
06/02/2022 22:21:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=227
06/02/2022 22:21:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=229
06/02/2022 22:21:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=232
06/02/2022 22:21:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
06/02/2022 22:21:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=237
06/02/2022 22:21:38 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.7037472491326446 on epoch=237
06/02/2022 22:21:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=239
06/02/2022 22:21:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=242
06/02/2022 22:21:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/02/2022 22:21:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=247
06/02/2022 22:21:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=249
06/02/2022 22:21:51 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.6436175666438825 on epoch=249
06/02/2022 22:21:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
06/02/2022 22:21:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/02/2022 22:21:58 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=257
06/02/2022 22:22:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/02/2022 22:22:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
06/02/2022 22:22:04 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.6764713064713065 on epoch=262
06/02/2022 22:22:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/02/2022 22:22:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=267
06/02/2022 22:22:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=269
06/02/2022 22:22:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=272
06/02/2022 22:22:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/02/2022 22:22:18 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7110673807448001 on epoch=274
06/02/2022 22:22:20 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=277
06/02/2022 22:22:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/02/2022 22:22:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=282
06/02/2022 22:22:27 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/02/2022 22:22:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=287
06/02/2022 22:22:31 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.7458998174168452 on epoch=287
06/02/2022 22:22:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7325298540468819 -> 0.7458998174168452 on epoch=287, global_step=1150
06/02/2022 22:22:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/02/2022 22:22:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=292
06/02/2022 22:22:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=294
06/02/2022 22:22:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/02/2022 22:22:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=299
06/02/2022 22:22:44 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7177350427350427 on epoch=299
06/02/2022 22:22:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/02/2022 22:22:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/02/2022 22:22:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/02/2022 22:22:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/02/2022 22:22:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=312
06/02/2022 22:22:58 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7029100529100529 on epoch=312
06/02/2022 22:23:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/02/2022 22:23:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/02/2022 22:23:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/02/2022 22:23:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/02/2022 22:23:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/02/2022 22:23:11 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.7035849823800487 on epoch=324
06/02/2022 22:23:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/02/2022 22:23:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=329
06/02/2022 22:23:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/02/2022 22:23:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/02/2022 22:23:23 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/02/2022 22:23:25 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.6880849767097645 on epoch=337
06/02/2022 22:23:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/02/2022 22:23:29 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
06/02/2022 22:23:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/02/2022 22:23:34 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/02/2022 22:23:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/02/2022 22:23:38 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.6780818092977803 on epoch=349
06/02/2022 22:23:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=352
06/02/2022 22:23:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/02/2022 22:23:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/02/2022 22:23:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=359
06/02/2022 22:23:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/02/2022 22:23:51 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.6993843843843843 on epoch=362
06/02/2022 22:23:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/02/2022 22:23:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
06/02/2022 22:23:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/02/2022 22:24:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/02/2022 22:24:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/02/2022 22:24:05 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7318019943019942 on epoch=374
06/02/2022 22:24:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/02/2022 22:24:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/02/2022 22:24:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/02/2022 22:24:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/02/2022 22:24:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/02/2022 22:24:18 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7176856282119439 on epoch=387
06/02/2022 22:24:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/02/2022 22:24:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/02/2022 22:24:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/02/2022 22:24:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/02/2022 22:24:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=399
06/02/2022 22:24:31 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6651113454652475 on epoch=399
06/02/2022 22:24:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/02/2022 22:24:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=404
06/02/2022 22:24:39 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/02/2022 22:24:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/02/2022 22:24:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=412
06/02/2022 22:24:45 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7130730223123732 on epoch=412
06/02/2022 22:24:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/02/2022 22:24:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/02/2022 22:24:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/02/2022 22:24:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/02/2022 22:24:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/02/2022 22:24:58 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7170918546630122 on epoch=424
06/02/2022 22:25:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/02/2022 22:25:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/02/2022 22:25:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/02/2022 22:25:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/02/2022 22:25:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/02/2022 22:25:12 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7153701345658051 on epoch=437
06/02/2022 22:25:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/02/2022 22:25:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/02/2022 22:25:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=444
06/02/2022 22:25:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=447
06/02/2022 22:25:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/02/2022 22:25:25 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7165603103103103 on epoch=449
06/02/2022 22:25:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/02/2022 22:25:30 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/02/2022 22:25:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/02/2022 22:25:35 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
06/02/2022 22:25:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/02/2022 22:25:38 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.694047619047619 on epoch=462
06/02/2022 22:25:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/02/2022 22:25:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/02/2022 22:25:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/02/2022 22:25:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/02/2022 22:25:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/02/2022 22:25:51 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6883864449787371 on epoch=474
06/02/2022 22:25:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=477
06/02/2022 22:25:56 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/02/2022 22:25:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/02/2022 22:26:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/02/2022 22:26:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/02/2022 22:26:05 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.70262450797841 on epoch=487
06/02/2022 22:26:07 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/02/2022 22:26:10 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/02/2022 22:26:12 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/02/2022 22:26:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/02/2022 22:26:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=499
06/02/2022 22:26:18 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7145098039215686 on epoch=499
06/02/2022 22:26:20 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/02/2022 22:26:23 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/02/2022 22:26:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/02/2022 22:26:28 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/02/2022 22:26:30 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/02/2022 22:26:31 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7145098039215686 on epoch=512
06/02/2022 22:26:34 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/02/2022 22:26:36 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/02/2022 22:26:39 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/02/2022 22:26:41 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=522
06/02/2022 22:26:44 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=524
06/02/2022 22:26:45 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7073863636363638 on epoch=524
06/02/2022 22:26:47 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/02/2022 22:26:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=529
06/02/2022 22:26:52 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/02/2022 22:26:54 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/02/2022 22:26:57 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=537
06/02/2022 22:26:58 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7176856282119439 on epoch=537
06/02/2022 22:27:00 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/02/2022 22:27:03 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/02/2022 22:27:05 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/02/2022 22:27:08 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=547
06/02/2022 22:27:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/02/2022 22:27:11 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6993843843843843 on epoch=549
06/02/2022 22:27:14 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/02/2022 22:27:16 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=554
06/02/2022 22:27:19 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=557
06/02/2022 22:27:21 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/02/2022 22:27:24 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/02/2022 22:27:25 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.694047619047619 on epoch=562
06/02/2022 22:27:27 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/02/2022 22:27:30 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/02/2022 22:27:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/02/2022 22:27:35 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=572
06/02/2022 22:27:37 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/02/2022 22:27:38 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7267723285486445 on epoch=574
06/02/2022 22:27:41 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/02/2022 22:27:43 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/02/2022 22:27:46 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=582
06/02/2022 22:27:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/02/2022 22:27:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/02/2022 22:27:52 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.678624858978761 on epoch=587
06/02/2022 22:27:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/02/2022 22:27:56 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/02/2022 22:27:59 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/02/2022 22:28:01 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/02/2022 22:28:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=599
06/02/2022 22:28:05 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7319027819027819 on epoch=599
06/02/2022 22:28:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.14 on epoch=602
06/02/2022 22:28:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/02/2022 22:28:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/02/2022 22:28:15 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/02/2022 22:28:17 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/02/2022 22:28:18 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6685875694671461 on epoch=612
06/02/2022 22:28:21 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=614
06/02/2022 22:28:23 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/02/2022 22:28:26 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/02/2022 22:28:28 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/02/2022 22:28:31 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/02/2022 22:28:32 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7278024193548387 on epoch=624
06/02/2022 22:28:34 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/02/2022 22:28:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/02/2022 22:28:39 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/02/2022 22:28:42 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/02/2022 22:28:44 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/02/2022 22:28:45 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7308611340869406 on epoch=637
06/02/2022 22:28:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/02/2022 22:28:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
06/02/2022 22:28:52 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/02/2022 22:28:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/02/2022 22:28:57 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/02/2022 22:28:59 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6944635544635545 on epoch=649
06/02/2022 22:29:01 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=652
06/02/2022 22:29:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/02/2022 22:29:06 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/02/2022 22:29:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/02/2022 22:29:11 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/02/2022 22:29:12 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7119065215220214 on epoch=662
06/02/2022 22:29:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/02/2022 22:29:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/02/2022 22:29:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/02/2022 22:29:22 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/02/2022 22:29:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/02/2022 22:29:26 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.714655325181641 on epoch=674
06/02/2022 22:29:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=677
06/02/2022 22:29:31 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=679
06/02/2022 22:29:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/02/2022 22:29:36 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/02/2022 22:29:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/02/2022 22:29:39 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6545383698916307 on epoch=687
06/02/2022 22:29:42 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/02/2022 22:29:44 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=692
06/02/2022 22:29:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=694
06/02/2022 22:29:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/02/2022 22:29:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/02/2022 22:29:53 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7119065215220214 on epoch=699
06/02/2022 22:29:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/02/2022 22:29:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/02/2022 22:30:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/02/2022 22:30:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/02/2022 22:30:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/02/2022 22:30:06 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6975538672312867 on epoch=712
06/02/2022 22:30:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/02/2022 22:30:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=717
06/02/2022 22:30:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/02/2022 22:30:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/02/2022 22:30:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/02/2022 22:30:20 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7134335839598998 on epoch=724
06/02/2022 22:30:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/02/2022 22:30:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/02/2022 22:30:27 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/02/2022 22:30:29 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.08 on epoch=734
06/02/2022 22:30:32 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/02/2022 22:30:33 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7278024193548387 on epoch=737
06/02/2022 22:30:36 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/02/2022 22:30:38 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/02/2022 22:30:40 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/02/2022 22:30:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/02/2022 22:30:45 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/02/2022 22:30:46 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6975538672312867 on epoch=749
06/02/2022 22:30:46 - INFO - __main__ - save last model!
06/02/2022 22:30:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:30:47 - INFO - __main__ - Printing 3 examples
06/02/2022 22:30:47 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/02/2022 22:30:47 - INFO - __main__ - ['sad']
06/02/2022 22:30:47 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/02/2022 22:30:47 - INFO - __main__ - ['sad']
06/02/2022 22:30:47 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/02/2022 22:30:47 - INFO - __main__ - ['sad']
06/02/2022 22:30:47 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:30:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 22:30:47 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 22:30:47 - INFO - __main__ - Printing 3 examples
06/02/2022 22:30:47 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 22:30:47 - INFO - __main__ - ['others']
06/02/2022 22:30:47 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 22:30:47 - INFO - __main__ - ['others']
06/02/2022 22:30:47 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 22:30:47 - INFO - __main__ - ['others']
06/02/2022 22:30:47 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:30:47 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:30:47 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 22:30:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:30:47 - INFO - __main__ - Printing 3 examples
06/02/2022 22:30:47 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/02/2022 22:30:47 - INFO - __main__ - ['sad']
06/02/2022 22:30:47 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/02/2022 22:30:47 - INFO - __main__ - ['sad']
06/02/2022 22:30:47 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/02/2022 22:30:47 - INFO - __main__ - ['sad']
06/02/2022 22:30:47 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:30:47 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:30:47 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 22:30:49 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:30:54 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 22:31:02 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 22:31:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 22:31:03 - INFO - __main__ - Starting training!
06/02/2022 22:32:25 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_21_0.5_8_predictions.txt
06/02/2022 22:32:25 - INFO - __main__ - Classification-F1 on test data: 0.2621
06/02/2022 22:32:25 - INFO - __main__ - prefix=emo_16_21, lr=0.5, bsz=8, dev_performance=0.7458998174168452, test_performance=0.2621200907477584
06/02/2022 22:32:25 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.4, bsz=8 ...
06/02/2022 22:32:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:32:26 - INFO - __main__ - Printing 3 examples
06/02/2022 22:32:26 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/02/2022 22:32:26 - INFO - __main__ - ['sad']
06/02/2022 22:32:26 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/02/2022 22:32:26 - INFO - __main__ - ['sad']
06/02/2022 22:32:26 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/02/2022 22:32:26 - INFO - __main__ - ['sad']
06/02/2022 22:32:26 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:32:26 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:32:26 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 22:32:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:32:26 - INFO - __main__ - Printing 3 examples
06/02/2022 22:32:26 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/02/2022 22:32:26 - INFO - __main__ - ['sad']
06/02/2022 22:32:26 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/02/2022 22:32:26 - INFO - __main__ - ['sad']
06/02/2022 22:32:26 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/02/2022 22:32:26 - INFO - __main__ - ['sad']
06/02/2022 22:32:26 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:32:26 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:32:26 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 22:32:45 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 22:32:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 22:32:46 - INFO - __main__ - Starting training!
06/02/2022 22:32:49 - INFO - __main__ - Step 10 Global step 10 Train loss 4.50 on epoch=2
06/02/2022 22:32:51 - INFO - __main__ - Step 20 Global step 20 Train loss 3.13 on epoch=4
06/02/2022 22:32:54 - INFO - __main__ - Step 30 Global step 30 Train loss 2.65 on epoch=7
06/02/2022 22:32:56 - INFO - __main__ - Step 40 Global step 40 Train loss 2.06 on epoch=9
06/02/2022 22:32:59 - INFO - __main__ - Step 50 Global step 50 Train loss 1.93 on epoch=12
06/02/2022 22:33:00 - INFO - __main__ - Global step 50 Train loss 2.85 Classification-F1 0.09338152290427541 on epoch=12
06/02/2022 22:33:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09338152290427541 on epoch=12, global_step=50
06/02/2022 22:33:02 - INFO - __main__ - Step 60 Global step 60 Train loss 1.50 on epoch=14
06/02/2022 22:33:05 - INFO - __main__ - Step 70 Global step 70 Train loss 1.33 on epoch=17
06/02/2022 22:33:07 - INFO - __main__ - Step 80 Global step 80 Train loss 0.98 on epoch=19
06/02/2022 22:33:10 - INFO - __main__ - Step 90 Global step 90 Train loss 1.02 on epoch=22
06/02/2022 22:33:12 - INFO - __main__ - Step 100 Global step 100 Train loss 0.86 on epoch=24
06/02/2022 22:33:13 - INFO - __main__ - Global step 100 Train loss 1.14 Classification-F1 0.5176023913751824 on epoch=24
06/02/2022 22:33:13 - INFO - __main__ - Saving model with best Classification-F1: 0.09338152290427541 -> 0.5176023913751824 on epoch=24, global_step=100
06/02/2022 22:33:15 - INFO - __main__ - Step 110 Global step 110 Train loss 0.92 on epoch=27
06/02/2022 22:33:18 - INFO - __main__ - Step 120 Global step 120 Train loss 0.63 on epoch=29
06/02/2022 22:33:20 - INFO - __main__ - Step 130 Global step 130 Train loss 0.80 on epoch=32
06/02/2022 22:33:23 - INFO - __main__ - Step 140 Global step 140 Train loss 0.57 on epoch=34
06/02/2022 22:33:25 - INFO - __main__ - Step 150 Global step 150 Train loss 0.72 on epoch=37
06/02/2022 22:33:26 - INFO - __main__ - Global step 150 Train loss 0.73 Classification-F1 0.5486443381180224 on epoch=37
06/02/2022 22:33:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5176023913751824 -> 0.5486443381180224 on epoch=37, global_step=150
06/02/2022 22:33:28 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=39
06/02/2022 22:33:31 - INFO - __main__ - Step 170 Global step 170 Train loss 0.67 on epoch=42
06/02/2022 22:33:33 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=44
06/02/2022 22:33:36 - INFO - __main__ - Step 190 Global step 190 Train loss 0.50 on epoch=47
06/02/2022 22:33:38 - INFO - __main__ - Step 200 Global step 200 Train loss 0.55 on epoch=49
06/02/2022 22:33:39 - INFO - __main__ - Global step 200 Train loss 0.60 Classification-F1 0.6479166666666666 on epoch=49
06/02/2022 22:33:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5486443381180224 -> 0.6479166666666666 on epoch=49, global_step=200
06/02/2022 22:33:42 - INFO - __main__ - Step 210 Global step 210 Train loss 0.58 on epoch=52
06/02/2022 22:33:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.41 on epoch=54
06/02/2022 22:33:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.51 on epoch=57
06/02/2022 22:33:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.52 on epoch=59
06/02/2022 22:33:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.44 on epoch=62
06/02/2022 22:33:52 - INFO - __main__ - Global step 250 Train loss 0.49 Classification-F1 0.6710124127887287 on epoch=62
06/02/2022 22:33:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6479166666666666 -> 0.6710124127887287 on epoch=62, global_step=250
06/02/2022 22:33:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.48 on epoch=64
06/02/2022 22:33:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.46 on epoch=67
06/02/2022 22:34:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.37 on epoch=69
06/02/2022 22:34:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.41 on epoch=72
06/02/2022 22:34:05 - INFO - __main__ - Step 300 Global step 300 Train loss 0.48 on epoch=74
06/02/2022 22:34:06 - INFO - __main__ - Global step 300 Train loss 0.44 Classification-F1 0.6711309523809523 on epoch=74
06/02/2022 22:34:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6710124127887287 -> 0.6711309523809523 on epoch=74, global_step=300
06/02/2022 22:34:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.39 on epoch=77
06/02/2022 22:34:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=79
06/02/2022 22:34:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.37 on epoch=82
06/02/2022 22:34:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=84
06/02/2022 22:34:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.48 on epoch=87
06/02/2022 22:34:19 - INFO - __main__ - Global step 350 Train loss 0.40 Classification-F1 0.6578917050691244 on epoch=87
06/02/2022 22:34:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=89
06/02/2022 22:34:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.37 on epoch=92
06/02/2022 22:34:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=94
06/02/2022 22:34:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.43 on epoch=97
06/02/2022 22:34:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=99
06/02/2022 22:34:32 - INFO - __main__ - Global step 400 Train loss 0.34 Classification-F1 0.6473967176004527 on epoch=99
06/02/2022 22:34:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=102
06/02/2022 22:34:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=104
06/02/2022 22:34:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=107
06/02/2022 22:34:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.34 on epoch=109
06/02/2022 22:34:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.29 on epoch=112
06/02/2022 22:34:45 - INFO - __main__ - Global step 450 Train loss 0.29 Classification-F1 0.6842805939580133 on epoch=112
06/02/2022 22:34:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6711309523809523 -> 0.6842805939580133 on epoch=112, global_step=450
06/02/2022 22:34:48 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=114
06/02/2022 22:34:50 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=117
06/02/2022 22:34:53 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=119
06/02/2022 22:34:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=122
06/02/2022 22:34:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=124
06/02/2022 22:34:58 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.6544676084149769 on epoch=124
06/02/2022 22:35:01 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=127
06/02/2022 22:35:03 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=129
06/02/2022 22:35:06 - INFO - __main__ - Step 530 Global step 530 Train loss 0.25 on epoch=132
06/02/2022 22:35:08 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=134
06/02/2022 22:35:11 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=137
06/02/2022 22:35:12 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.7175324675324675 on epoch=137
06/02/2022 22:35:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6842805939580133 -> 0.7175324675324675 on epoch=137, global_step=550
06/02/2022 22:35:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=139
06/02/2022 22:35:17 - INFO - __main__ - Step 570 Global step 570 Train loss 0.27 on epoch=142
06/02/2022 22:35:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=144
06/02/2022 22:35:21 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=147
06/02/2022 22:35:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=149
06/02/2022 22:35:25 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.6840388775872647 on epoch=149
06/02/2022 22:35:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=152
06/02/2022 22:35:30 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=154
06/02/2022 22:35:32 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=157
06/02/2022 22:35:35 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=159
06/02/2022 22:35:37 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=162
06/02/2022 22:35:38 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.6840388775872647 on epoch=162
06/02/2022 22:35:41 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=164
06/02/2022 22:35:43 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=167
06/02/2022 22:35:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=169
06/02/2022 22:35:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=172
06/02/2022 22:35:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=174
06/02/2022 22:35:51 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.6755913568399727 on epoch=174
06/02/2022 22:35:54 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=177
06/02/2022 22:35:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=179
06/02/2022 22:35:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=182
06/02/2022 22:36:01 - INFO - __main__ - Step 740 Global step 740 Train loss 0.12 on epoch=184
06/02/2022 22:36:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=187
06/02/2022 22:36:04 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.6745413744052582 on epoch=187
06/02/2022 22:36:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=189
06/02/2022 22:36:09 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=192
06/02/2022 22:36:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=194
06/02/2022 22:36:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=197
06/02/2022 22:36:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=199
06/02/2022 22:36:18 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.6735953801810579 on epoch=199
06/02/2022 22:36:20 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=202
06/02/2022 22:36:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=204
06/02/2022 22:36:25 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=207
06/02/2022 22:36:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=209
06/02/2022 22:36:30 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=212
06/02/2022 22:36:31 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.7002944120591179 on epoch=212
06/02/2022 22:36:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=214
06/02/2022 22:36:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=217
06/02/2022 22:36:38 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=219
06/02/2022 22:36:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=222
06/02/2022 22:36:43 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=224
06/02/2022 22:36:44 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.6763513513513513 on epoch=224
06/02/2022 22:36:46 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=227
06/02/2022 22:36:49 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=229
06/02/2022 22:36:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=232
06/02/2022 22:36:54 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=234
06/02/2022 22:36:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
06/02/2022 22:36:57 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.646366919915307 on epoch=237
06/02/2022 22:36:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=239
06/02/2022 22:37:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=242
06/02/2022 22:37:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=244
06/02/2022 22:37:06 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=247
06/02/2022 22:37:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=249
06/02/2022 22:37:10 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.6513347763347763 on epoch=249
06/02/2022 22:37:12 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=252
06/02/2022 22:37:14 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=254
06/02/2022 22:37:17 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=257
06/02/2022 22:37:19 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=259
06/02/2022 22:37:22 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
06/02/2022 22:37:22 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.7281522399169458 on epoch=262
06/02/2022 22:37:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7175324675324675 -> 0.7281522399169458 on epoch=262, global_step=1050
06/02/2022 22:37:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=264
06/02/2022 22:37:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/02/2022 22:37:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=269
06/02/2022 22:37:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/02/2022 22:37:34 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=274
06/02/2022 22:37:35 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.6909722222222222 on epoch=274
06/02/2022 22:37:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/02/2022 22:37:40 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/02/2022 22:37:42 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/02/2022 22:37:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/02/2022 22:37:47 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=287
06/02/2022 22:37:48 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.6581932773109244 on epoch=287
06/02/2022 22:37:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/02/2022 22:37:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/02/2022 22:37:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=294
06/02/2022 22:37:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
06/02/2022 22:38:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
06/02/2022 22:38:01 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.6646945646945648 on epoch=299
06/02/2022 22:38:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/02/2022 22:38:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=304
06/02/2022 22:38:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/02/2022 22:38:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=309
06/02/2022 22:38:12 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/02/2022 22:38:13 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.6667409387997624 on epoch=312
06/02/2022 22:38:16 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/02/2022 22:38:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/02/2022 22:38:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=319
06/02/2022 22:38:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=322
06/02/2022 22:38:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=324
06/02/2022 22:38:26 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.676608187134503 on epoch=324
06/02/2022 22:38:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=327
06/02/2022 22:38:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/02/2022 22:38:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=332
06/02/2022 22:38:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/02/2022 22:38:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=337
06/02/2022 22:38:39 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.6328534064017936 on epoch=337
06/02/2022 22:38:41 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=339
06/02/2022 22:38:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/02/2022 22:38:46 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/02/2022 22:38:48 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=347
06/02/2022 22:38:51 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/02/2022 22:38:52 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.6457985257985259 on epoch=349
06/02/2022 22:38:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/02/2022 22:38:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=354
06/02/2022 22:38:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=357
06/02/2022 22:39:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/02/2022 22:39:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=362
06/02/2022 22:39:04 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.6468817204301075 on epoch=362
06/02/2022 22:39:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/02/2022 22:39:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=367
06/02/2022 22:39:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/02/2022 22:39:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=372
06/02/2022 22:39:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/02/2022 22:39:17 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.6608442982456142 on epoch=374
06/02/2022 22:39:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/02/2022 22:39:22 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/02/2022 22:39:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=382
06/02/2022 22:39:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=384
06/02/2022 22:39:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/02/2022 22:39:30 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.6740196078431373 on epoch=387
06/02/2022 22:39:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=389
06/02/2022 22:39:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/02/2022 22:39:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/02/2022 22:39:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=397
06/02/2022 22:39:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/02/2022 22:39:42 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.6617698046557919 on epoch=399
06/02/2022 22:39:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/02/2022 22:39:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/02/2022 22:39:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=407
06/02/2022 22:39:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/02/2022 22:39:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/02/2022 22:39:55 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.6628378378378378 on epoch=412
06/02/2022 22:39:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/02/2022 22:40:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/02/2022 22:40:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/02/2022 22:40:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=422
06/02/2022 22:40:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=424
06/02/2022 22:40:08 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.6610295901042931 on epoch=424
06/02/2022 22:40:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/02/2022 22:40:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=429
06/02/2022 22:40:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/02/2022 22:40:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=434
06/02/2022 22:40:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/02/2022 22:40:21 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.6244851994851994 on epoch=437
06/02/2022 22:40:23 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=439
06/02/2022 22:40:25 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=442
06/02/2022 22:40:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/02/2022 22:40:30 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/02/2022 22:40:33 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/02/2022 22:40:33 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.6610295901042931 on epoch=449
06/02/2022 22:40:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/02/2022 22:40:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/02/2022 22:40:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
06/02/2022 22:40:43 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/02/2022 22:40:45 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/02/2022 22:40:46 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6449403815580286 on epoch=462
06/02/2022 22:40:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/02/2022 22:40:51 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/02/2022 22:40:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/02/2022 22:40:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/02/2022 22:40:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=474
06/02/2022 22:40:59 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6379673608573864 on epoch=474
06/02/2022 22:41:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=477
06/02/2022 22:41:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/02/2022 22:41:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/02/2022 22:41:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=484
06/02/2022 22:41:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/02/2022 22:41:12 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.6473384442134442 on epoch=487
06/02/2022 22:41:14 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/02/2022 22:41:16 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/02/2022 22:41:19 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/02/2022 22:41:21 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/02/2022 22:41:24 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/02/2022 22:41:25 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6527695962478571 on epoch=499
06/02/2022 22:41:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=502
06/02/2022 22:41:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/02/2022 22:41:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/02/2022 22:41:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/02/2022 22:41:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/02/2022 22:41:38 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6744871794871795 on epoch=512
06/02/2022 22:41:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/02/2022 22:41:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
06/02/2022 22:41:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/02/2022 22:41:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/02/2022 22:41:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/02/2022 22:41:50 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.6386768551814319 on epoch=524
06/02/2022 22:41:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=527
06/02/2022 22:41:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/02/2022 22:41:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/02/2022 22:42:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/02/2022 22:42:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/02/2022 22:42:03 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6531885689578515 on epoch=537
06/02/2022 22:42:06 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/02/2022 22:42:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=542
06/02/2022 22:42:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/02/2022 22:42:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/02/2022 22:42:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/02/2022 22:42:16 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6326482732732732 on epoch=549
06/02/2022 22:42:18 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/02/2022 22:42:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=554
06/02/2022 22:42:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/02/2022 22:42:26 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/02/2022 22:42:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/02/2022 22:42:29 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6448717948717949 on epoch=562
06/02/2022 22:42:31 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/02/2022 22:42:34 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/02/2022 22:42:36 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/02/2022 22:42:38 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/02/2022 22:42:41 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/02/2022 22:42:42 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.6531885689578515 on epoch=574
06/02/2022 22:42:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/02/2022 22:42:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/02/2022 22:42:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/02/2022 22:42:51 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/02/2022 22:42:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/02/2022 22:42:55 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6643251424501425 on epoch=587
06/02/2022 22:42:57 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/02/2022 22:43:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/02/2022 22:43:02 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.08 on epoch=594
06/02/2022 22:43:04 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/02/2022 22:43:07 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/02/2022 22:43:08 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6669555539337323 on epoch=599
06/02/2022 22:43:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/02/2022 22:43:12 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/02/2022 22:43:15 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/02/2022 22:43:17 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=609
06/02/2022 22:43:19 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=612
06/02/2022 22:43:20 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6521534198963866 on epoch=612
06/02/2022 22:43:23 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/02/2022 22:43:25 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=617
06/02/2022 22:43:28 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/02/2022 22:43:30 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/02/2022 22:43:32 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/02/2022 22:43:33 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6378205128205129 on epoch=624
06/02/2022 22:43:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/02/2022 22:43:38 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/02/2022 22:43:41 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/02/2022 22:43:43 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=634
06/02/2022 22:43:45 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/02/2022 22:43:46 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.5982732732732733 on epoch=637
06/02/2022 22:43:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=639
06/02/2022 22:43:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/02/2022 22:43:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/02/2022 22:43:56 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/02/2022 22:43:58 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/02/2022 22:43:59 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6521534198963866 on epoch=649
06/02/2022 22:44:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/02/2022 22:44:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/02/2022 22:44:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/02/2022 22:44:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/02/2022 22:44:11 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/02/2022 22:44:12 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6386768551814319 on epoch=662
06/02/2022 22:44:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/02/2022 22:44:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/02/2022 22:44:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/02/2022 22:44:22 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/02/2022 22:44:24 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/02/2022 22:44:25 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6531597901864381 on epoch=674
06/02/2022 22:44:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/02/2022 22:44:30 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/02/2022 22:44:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/02/2022 22:44:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/02/2022 22:44:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/02/2022 22:44:38 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6531597901864381 on epoch=687
06/02/2022 22:44:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/02/2022 22:44:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=692
06/02/2022 22:44:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/02/2022 22:44:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/02/2022 22:44:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/02/2022 22:44:51 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6250244810027419 on epoch=699
06/02/2022 22:44:53 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=702
06/02/2022 22:44:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/02/2022 22:44:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/02/2022 22:45:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/02/2022 22:45:03 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/02/2022 22:45:04 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.631315987933635 on epoch=712
06/02/2022 22:45:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/02/2022 22:45:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/02/2022 22:45:11 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/02/2022 22:45:13 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/02/2022 22:45:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/02/2022 22:45:17 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6250244810027419 on epoch=724
06/02/2022 22:45:19 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
06/02/2022 22:45:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/02/2022 22:45:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/02/2022 22:45:26 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/02/2022 22:45:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/02/2022 22:45:30 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.610971685971686 on epoch=737
06/02/2022 22:45:32 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=739
06/02/2022 22:45:34 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/02/2022 22:45:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=744
06/02/2022 22:45:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/02/2022 22:45:42 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/02/2022 22:45:43 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6257985257985258 on epoch=749
06/02/2022 22:45:43 - INFO - __main__ - save last model!
06/02/2022 22:45:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 22:45:43 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 22:45:43 - INFO - __main__ - Printing 3 examples
06/02/2022 22:45:43 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 22:45:43 - INFO - __main__ - ['others']
06/02/2022 22:45:43 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 22:45:43 - INFO - __main__ - ['others']
06/02/2022 22:45:43 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 22:45:43 - INFO - __main__ - ['others']
06/02/2022 22:45:43 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:45:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:45:43 - INFO - __main__ - Printing 3 examples
06/02/2022 22:45:43 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/02/2022 22:45:43 - INFO - __main__ - ['sad']
06/02/2022 22:45:43 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/02/2022 22:45:43 - INFO - __main__ - ['sad']
06/02/2022 22:45:43 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/02/2022 22:45:43 - INFO - __main__ - ['sad']
06/02/2022 22:45:43 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:45:43 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:45:43 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 22:45:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:45:43 - INFO - __main__ - Printing 3 examples
06/02/2022 22:45:43 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/02/2022 22:45:43 - INFO - __main__ - ['sad']
06/02/2022 22:45:43 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/02/2022 22:45:43 - INFO - __main__ - ['sad']
06/02/2022 22:45:43 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/02/2022 22:45:43 - INFO - __main__ - ['sad']
06/02/2022 22:45:43 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:45:43 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:45:43 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 22:45:45 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:45:50 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 22:45:58 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 22:45:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 22:45:59 - INFO - __main__ - Starting training!
06/02/2022 22:47:09 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_21_0.4_8_predictions.txt
06/02/2022 22:47:09 - INFO - __main__ - Classification-F1 on test data: 0.3226
06/02/2022 22:47:09 - INFO - __main__ - prefix=emo_16_21, lr=0.4, bsz=8, dev_performance=0.7281522399169458, test_performance=0.32255593160672513
06/02/2022 22:47:09 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.3, bsz=8 ...
06/02/2022 22:47:10 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:47:10 - INFO - __main__ - Printing 3 examples
06/02/2022 22:47:10 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/02/2022 22:47:10 - INFO - __main__ - ['sad']
06/02/2022 22:47:10 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/02/2022 22:47:10 - INFO - __main__ - ['sad']
06/02/2022 22:47:10 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/02/2022 22:47:10 - INFO - __main__ - ['sad']
06/02/2022 22:47:10 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:47:10 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:47:10 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 22:47:10 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 22:47:10 - INFO - __main__ - Printing 3 examples
06/02/2022 22:47:10 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/02/2022 22:47:10 - INFO - __main__ - ['sad']
06/02/2022 22:47:10 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/02/2022 22:47:10 - INFO - __main__ - ['sad']
06/02/2022 22:47:10 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/02/2022 22:47:10 - INFO - __main__ - ['sad']
06/02/2022 22:47:10 - INFO - __main__ - Tokenizing Input ...
06/02/2022 22:47:10 - INFO - __main__ - Tokenizing Output ...
06/02/2022 22:47:11 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 22:47:28 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 22:47:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 22:47:28 - INFO - __main__ - Starting training!
06/02/2022 22:47:31 - INFO - __main__ - Step 10 Global step 10 Train loss 4.37 on epoch=2
06/02/2022 22:47:34 - INFO - __main__ - Step 20 Global step 20 Train loss 3.39 on epoch=4
06/02/2022 22:47:37 - INFO - __main__ - Step 30 Global step 30 Train loss 2.96 on epoch=7
06/02/2022 22:47:39 - INFO - __main__ - Step 40 Global step 40 Train loss 2.37 on epoch=9
06/02/2022 22:47:42 - INFO - __main__ - Step 50 Global step 50 Train loss 2.29 on epoch=12
06/02/2022 22:47:43 - INFO - __main__ - Global step 50 Train loss 3.07 Classification-F1 0.07094723458359821 on epoch=12
06/02/2022 22:47:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07094723458359821 on epoch=12, global_step=50
06/02/2022 22:47:46 - INFO - __main__ - Step 60 Global step 60 Train loss 1.89 on epoch=14
06/02/2022 22:47:49 - INFO - __main__ - Step 70 Global step 70 Train loss 1.64 on epoch=17
06/02/2022 22:47:51 - INFO - __main__ - Step 80 Global step 80 Train loss 1.39 on epoch=19
06/02/2022 22:47:54 - INFO - __main__ - Step 90 Global step 90 Train loss 1.27 on epoch=22
06/02/2022 22:47:57 - INFO - __main__ - Step 100 Global step 100 Train loss 1.06 on epoch=24
06/02/2022 22:47:58 - INFO - __main__ - Global step 100 Train loss 1.45 Classification-F1 0.25485769020251775 on epoch=24
06/02/2022 22:47:58 - INFO - __main__ - Saving model with best Classification-F1: 0.07094723458359821 -> 0.25485769020251775 on epoch=24, global_step=100
06/02/2022 22:48:01 - INFO - __main__ - Step 110 Global step 110 Train loss 1.11 on epoch=27
06/02/2022 22:48:03 - INFO - __main__ - Step 120 Global step 120 Train loss 0.84 on epoch=29
06/02/2022 22:48:06 - INFO - __main__ - Step 130 Global step 130 Train loss 0.94 on epoch=32
06/02/2022 22:48:08 - INFO - __main__ - Step 140 Global step 140 Train loss 0.75 on epoch=34
06/02/2022 22:48:11 - INFO - __main__ - Step 150 Global step 150 Train loss 0.74 on epoch=37
06/02/2022 22:48:12 - INFO - __main__ - Global step 150 Train loss 0.88 Classification-F1 0.6049457282913165 on epoch=37
06/02/2022 22:48:12 - INFO - __main__ - Saving model with best Classification-F1: 0.25485769020251775 -> 0.6049457282913165 on epoch=37, global_step=150
06/02/2022 22:48:15 - INFO - __main__ - Step 160 Global step 160 Train loss 0.69 on epoch=39
06/02/2022 22:48:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.78 on epoch=42
06/02/2022 22:48:20 - INFO - __main__ - Step 180 Global step 180 Train loss 0.75 on epoch=44
06/02/2022 22:48:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.70 on epoch=47
06/02/2022 22:48:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.57 on epoch=49
06/02/2022 22:48:27 - INFO - __main__ - Global step 200 Train loss 0.70 Classification-F1 0.6133955383955383 on epoch=49
06/02/2022 22:48:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6049457282913165 -> 0.6133955383955383 on epoch=49, global_step=200
06/02/2022 22:48:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=52
06/02/2022 22:48:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.57 on epoch=54
06/02/2022 22:48:35 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=57
06/02/2022 22:48:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.57 on epoch=59
06/02/2022 22:48:40 - INFO - __main__ - Step 250 Global step 250 Train loss 0.66 on epoch=62
06/02/2022 22:48:41 - INFO - __main__ - Global step 250 Train loss 0.63 Classification-F1 0.6669240669240669 on epoch=62
06/02/2022 22:48:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6133955383955383 -> 0.6669240669240669 on epoch=62, global_step=250
06/02/2022 22:48:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=64
06/02/2022 22:48:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.59 on epoch=67
06/02/2022 22:48:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.43 on epoch=69
06/02/2022 22:48:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.64 on epoch=72
06/02/2022 22:48:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.49 on epoch=74
06/02/2022 22:48:54 - INFO - __main__ - Global step 300 Train loss 0.51 Classification-F1 0.6816968892820287 on epoch=74
06/02/2022 22:48:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6669240669240669 -> 0.6816968892820287 on epoch=74, global_step=300
06/02/2022 22:48:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=77
06/02/2022 22:48:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.47 on epoch=79
06/02/2022 22:49:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.48 on epoch=82
06/02/2022 22:49:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=84
06/02/2022 22:49:05 - INFO - __main__ - Step 350 Global step 350 Train loss 0.51 on epoch=87
06/02/2022 22:49:06 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.6845259263022421 on epoch=87
06/02/2022 22:49:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6816968892820287 -> 0.6845259263022421 on epoch=87, global_step=350
06/02/2022 22:49:09 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=89
06/02/2022 22:49:11 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=92
06/02/2022 22:49:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.44 on epoch=94
06/02/2022 22:49:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.40 on epoch=97
06/02/2022 22:49:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.44 on epoch=99
06/02/2022 22:49:19 - INFO - __main__ - Global step 400 Train loss 0.45 Classification-F1 0.6690066690066689 on epoch=99
06/02/2022 22:49:21 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=102
06/02/2022 22:49:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.40 on epoch=104
06/02/2022 22:49:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.46 on epoch=107
06/02/2022 22:49:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=109
06/02/2022 22:49:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=112
06/02/2022 22:49:32 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.6978403540903542 on epoch=112
06/02/2022 22:49:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6845259263022421 -> 0.6978403540903542 on epoch=112, global_step=450
06/02/2022 22:49:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=114
06/02/2022 22:49:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=117
06/02/2022 22:49:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.37 on epoch=119
06/02/2022 22:49:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.38 on epoch=122
06/02/2022 22:49:43 - INFO - __main__ - Step 500 Global step 500 Train loss 0.36 on epoch=124
06/02/2022 22:49:44 - INFO - __main__ - Global step 500 Train loss 0.37 Classification-F1 0.6743055555555556 on epoch=124
06/02/2022 22:49:47 - INFO - __main__ - Step 510 Global step 510 Train loss 0.43 on epoch=127
06/02/2022 22:49:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=129
06/02/2022 22:49:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.47 on epoch=132
06/02/2022 22:49:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=134
06/02/2022 22:49:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=137
06/02/2022 22:49:57 - INFO - __main__ - Global step 550 Train loss 0.34 Classification-F1 0.6751959930313589 on epoch=137
06/02/2022 22:49:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=139
06/02/2022 22:50:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.34 on epoch=142
06/02/2022 22:50:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.29 on epoch=144
06/02/2022 22:50:06 - INFO - __main__ - Step 590 Global step 590 Train loss 0.28 on epoch=147
06/02/2022 22:50:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=149
06/02/2022 22:50:09 - INFO - __main__ - Global step 600 Train loss 0.29 Classification-F1 0.6751959930313589 on epoch=149
06/02/2022 22:50:12 - INFO - __main__ - Step 610 Global step 610 Train loss 0.27 on epoch=152
06/02/2022 22:50:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.28 on epoch=154
06/02/2022 22:50:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.28 on epoch=157
06/02/2022 22:50:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.30 on epoch=159
06/02/2022 22:50:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.28 on epoch=162
06/02/2022 22:50:22 - INFO - __main__ - Global step 650 Train loss 0.28 Classification-F1 0.6852219608965109 on epoch=162
06/02/2022 22:50:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=164
06/02/2022 22:50:27 - INFO - __main__ - Step 670 Global step 670 Train loss 0.31 on epoch=167
06/02/2022 22:50:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=169
06/02/2022 22:50:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=172
06/02/2022 22:50:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=174
06/02/2022 22:50:35 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.6914029198635976 on epoch=174
06/02/2022 22:50:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.30 on epoch=177
06/02/2022 22:50:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=179
06/02/2022 22:50:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=182
06/02/2022 22:50:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=184
06/02/2022 22:50:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=187
06/02/2022 22:50:47 - INFO - __main__ - Global step 750 Train loss 0.25 Classification-F1 0.6852219608965109 on epoch=187
06/02/2022 22:50:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=189
06/02/2022 22:50:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=192
06/02/2022 22:50:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=194
06/02/2022 22:50:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=197
06/02/2022 22:50:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=199
06/02/2022 22:51:00 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.6910408432147562 on epoch=199
06/02/2022 22:51:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.27 on epoch=202
06/02/2022 22:51:04 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=204
06/02/2022 22:51:07 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=207
06/02/2022 22:51:09 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=209
06/02/2022 22:51:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=212
06/02/2022 22:51:12 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.6896335817455752 on epoch=212
06/02/2022 22:51:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=214
06/02/2022 22:51:17 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=217
06/02/2022 22:51:19 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=219
06/02/2022 22:51:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=222
06/02/2022 22:51:24 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=224
06/02/2022 22:51:25 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.67228230097293 on epoch=224
06/02/2022 22:51:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=227
06/02/2022 22:51:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=229
06/02/2022 22:51:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=232
06/02/2022 22:51:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=234
06/02/2022 22:51:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=237
06/02/2022 22:51:37 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.6779894338118022 on epoch=237
06/02/2022 22:51:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=239
06/02/2022 22:51:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=242
06/02/2022 22:51:44 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=244
06/02/2022 22:51:46 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=247
06/02/2022 22:51:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=249
06/02/2022 22:51:50 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.6763915243516762 on epoch=249
06/02/2022 22:51:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=252
06/02/2022 22:51:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=254
06/02/2022 22:51:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=257
06/02/2022 22:51:59 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=259
06/02/2022 22:52:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=262
06/02/2022 22:52:02 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.6763915243516762 on epoch=262
06/02/2022 22:52:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=264
06/02/2022 22:52:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.23 on epoch=267
06/02/2022 22:52:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=269
06/02/2022 22:52:11 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=272
06/02/2022 22:52:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=274
06/02/2022 22:52:15 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.6457724301841948 on epoch=274
06/02/2022 22:52:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=277
06/02/2022 22:52:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=279
06/02/2022 22:52:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=282
06/02/2022 22:52:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=284
06/02/2022 22:52:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=287
06/02/2022 22:52:27 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.6761363636363636 on epoch=287
06/02/2022 22:52:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=289
06/02/2022 22:52:32 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=292
06/02/2022 22:52:34 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=294
06/02/2022 22:52:37 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=297
06/02/2022 22:52:39 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
06/02/2022 22:52:40 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.6768341307814992 on epoch=299
06/02/2022 22:52:42 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=302
06/02/2022 22:52:45 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=304
06/02/2022 22:52:47 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=307
06/02/2022 22:52:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=309
06/02/2022 22:52:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=312
06/02/2022 22:52:53 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6753694581280788 on epoch=312
06/02/2022 22:52:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=314
06/02/2022 22:52:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=317
06/02/2022 22:53:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=319
06/02/2022 22:53:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=322
06/02/2022 22:53:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=324
06/02/2022 22:53:05 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6815024044625563 on epoch=324
06/02/2022 22:53:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/02/2022 22:53:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=329
06/02/2022 22:53:12 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=332
06/02/2022 22:53:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/02/2022 22:53:17 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=337
06/02/2022 22:53:18 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.6626195945271148 on epoch=337
06/02/2022 22:53:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/02/2022 22:53:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=342
06/02/2022 22:53:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/02/2022 22:53:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=347
06/02/2022 22:53:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=349
06/02/2022 22:53:30 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6607142857142858 on epoch=349
06/02/2022 22:53:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=352
06/02/2022 22:53:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=354
06/02/2022 22:53:38 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/02/2022 22:53:40 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=359
06/02/2022 22:53:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=362
06/02/2022 22:53:43 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.6591862721319428 on epoch=362
06/02/2022 22:53:46 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/02/2022 22:53:48 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/02/2022 22:53:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=369
06/02/2022 22:53:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=372
06/02/2022 22:53:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=374
06/02/2022 22:53:56 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.6753153043900073 on epoch=374
06/02/2022 22:53:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/02/2022 22:54:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=379
06/02/2022 22:54:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=382
06/02/2022 22:54:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=384
06/02/2022 22:54:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/02/2022 22:54:09 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6667517600366966 on epoch=387
06/02/2022 22:54:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=389
06/02/2022 22:54:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=392
06/02/2022 22:54:16 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/02/2022 22:54:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=397
06/02/2022 22:54:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=399
06/02/2022 22:54:22 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.6460510510510511 on epoch=399
06/02/2022 22:54:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=402
06/02/2022 22:54:27 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=404
06/02/2022 22:54:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/02/2022 22:54:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=409
06/02/2022 22:54:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/02/2022 22:54:35 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6753153043900073 on epoch=412
06/02/2022 22:54:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=414
06/02/2022 22:54:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/02/2022 22:54:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/02/2022 22:54:44 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=422
06/02/2022 22:54:47 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=424
06/02/2022 22:54:48 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6599415204678363 on epoch=424
06/02/2022 22:54:50 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=427
06/02/2022 22:54:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/02/2022 22:54:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=432
06/02/2022 22:54:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/02/2022 22:55:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=437
06/02/2022 22:55:01 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6826195945271147 on epoch=437
06/02/2022 22:55:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/02/2022 22:55:05 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
06/02/2022 22:55:08 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=444
06/02/2022 22:55:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=447
06/02/2022 22:55:13 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=449
06/02/2022 22:55:14 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.6460510510510511 on epoch=449
06/02/2022 22:55:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/02/2022 22:55:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/02/2022 22:55:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/02/2022 22:55:23 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/02/2022 22:55:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/02/2022 22:55:26 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6458333333333334 on epoch=462
06/02/2022 22:55:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/02/2022 22:55:31 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=467
06/02/2022 22:55:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/02/2022 22:55:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=472
06/02/2022 22:55:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/02/2022 22:55:39 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6512820512820513 on epoch=474
06/02/2022 22:55:42 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=477
06/02/2022 22:55:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/02/2022 22:55:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/02/2022 22:55:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/02/2022 22:55:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=487
06/02/2022 22:55:52 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.6481054648114539 on epoch=487
06/02/2022 22:55:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/02/2022 22:55:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/02/2022 22:56:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/02/2022 22:56:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/02/2022 22:56:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/02/2022 22:56:05 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6608386327503974 on epoch=499
06/02/2022 22:56:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
06/02/2022 22:56:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=504
06/02/2022 22:56:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=507
06/02/2022 22:56:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/02/2022 22:56:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/02/2022 22:56:18 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6334855817705183 on epoch=512
06/02/2022 22:56:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/02/2022 22:56:23 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/02/2022 22:56:26 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/02/2022 22:56:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=522
06/02/2022 22:56:30 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/02/2022 22:56:31 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.6636507936507937 on epoch=524
06/02/2022 22:56:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/02/2022 22:56:36 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=529
06/02/2022 22:56:39 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/02/2022 22:56:41 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/02/2022 22:56:44 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/02/2022 22:56:45 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.6496433651696809 on epoch=537
06/02/2022 22:56:47 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=539
06/02/2022 22:56:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/02/2022 22:56:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/02/2022 22:56:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/02/2022 22:56:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=549
06/02/2022 22:56:58 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6631568786831945 on epoch=549
06/02/2022 22:57:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=552
06/02/2022 22:57:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/02/2022 22:57:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=557
06/02/2022 22:57:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=559
06/02/2022 22:57:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/02/2022 22:57:11 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6688817938817938 on epoch=562
06/02/2022 22:57:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/02/2022 22:57:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/02/2022 22:57:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/02/2022 22:57:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.13 on epoch=572
06/02/2022 22:57:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=574
06/02/2022 22:57:24 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.6496433651696809 on epoch=574
06/02/2022 22:57:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=577
06/02/2022 22:57:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=579
06/02/2022 22:57:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/02/2022 22:57:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/02/2022 22:57:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/02/2022 22:57:37 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6496433651696809 on epoch=587
06/02/2022 22:57:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/02/2022 22:57:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=592
06/02/2022 22:57:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
06/02/2022 22:57:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=597
06/02/2022 22:57:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/02/2022 22:57:50 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6334855817705183 on epoch=599
06/02/2022 22:57:52 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/02/2022 22:57:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/02/2022 22:57:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/02/2022 22:58:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=609
06/02/2022 22:58:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=612
06/02/2022 22:58:03 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6496433651696809 on epoch=612
06/02/2022 22:58:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/02/2022 22:58:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/02/2022 22:58:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=619
06/02/2022 22:58:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=622
06/02/2022 22:58:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/02/2022 22:58:16 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6651113454652475 on epoch=624
06/02/2022 22:58:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/02/2022 22:58:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=629
06/02/2022 22:58:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/02/2022 22:58:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/02/2022 22:58:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/02/2022 22:58:29 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6447588705647176 on epoch=637
06/02/2022 22:58:32 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/02/2022 22:58:34 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/02/2022 22:58:37 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/02/2022 22:58:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=647
06/02/2022 22:58:41 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/02/2022 22:58:42 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6502574002574002 on epoch=649
06/02/2022 22:58:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.09 on epoch=652
06/02/2022 22:58:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/02/2022 22:58:50 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/02/2022 22:58:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/02/2022 22:58:55 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/02/2022 22:58:56 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6853468441217988 on epoch=662
06/02/2022 22:58:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/02/2022 22:59:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/02/2022 22:59:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/02/2022 22:59:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=672
06/02/2022 22:59:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/02/2022 22:59:09 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6477525913009785 on epoch=674
06/02/2022 22:59:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/02/2022 22:59:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/02/2022 22:59:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/02/2022 22:59:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=684
06/02/2022 22:59:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/02/2022 22:59:22 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6488095238095237 on epoch=687
06/02/2022 22:59:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=689
06/02/2022 22:59:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/02/2022 22:59:29 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/02/2022 22:59:31 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/02/2022 22:59:34 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=699
06/02/2022 22:59:35 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6297863857646466 on epoch=699
06/02/2022 22:59:37 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=702
06/02/2022 22:59:40 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/02/2022 22:59:42 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/02/2022 22:59:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/02/2022 22:59:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/02/2022 22:59:48 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6846158499697519 on epoch=712
06/02/2022 22:59:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=714
06/02/2022 22:59:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=717
06/02/2022 22:59:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/02/2022 22:59:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=722
06/02/2022 23:00:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/02/2022 23:00:01 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.6651113454652475 on epoch=724
06/02/2022 23:00:04 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/02/2022 23:00:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/02/2022 23:00:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=732
06/02/2022 23:00:11 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=734
06/02/2022 23:00:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/02/2022 23:00:14 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6651113454652475 on epoch=737
06/02/2022 23:00:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/02/2022 23:00:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=742
06/02/2022 23:00:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/02/2022 23:00:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/02/2022 23:00:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/02/2022 23:00:28 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6651113454652475 on epoch=749
06/02/2022 23:00:28 - INFO - __main__ - save last model!
06/02/2022 23:00:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 23:00:28 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 23:00:28 - INFO - __main__ - Printing 3 examples
06/02/2022 23:00:28 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 23:00:28 - INFO - __main__ - ['others']
06/02/2022 23:00:28 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 23:00:28 - INFO - __main__ - ['others']
06/02/2022 23:00:28 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 23:00:28 - INFO - __main__ - ['others']
06/02/2022 23:00:28 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:00:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:00:28 - INFO - __main__ - Printing 3 examples
06/02/2022 23:00:28 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/02/2022 23:00:28 - INFO - __main__ - ['sad']
06/02/2022 23:00:28 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/02/2022 23:00:28 - INFO - __main__ - ['sad']
06/02/2022 23:00:28 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/02/2022 23:00:28 - INFO - __main__ - ['sad']
06/02/2022 23:00:28 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:00:28 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:00:28 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 23:00:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:00:28 - INFO - __main__ - Printing 3 examples
06/02/2022 23:00:28 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/02/2022 23:00:28 - INFO - __main__ - ['sad']
06/02/2022 23:00:28 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/02/2022 23:00:28 - INFO - __main__ - ['sad']
06/02/2022 23:00:28 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/02/2022 23:00:28 - INFO - __main__ - ['sad']
06/02/2022 23:00:28 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:00:28 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:00:28 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 23:00:30 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:00:35 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 23:00:46 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 23:00:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 23:00:47 - INFO - __main__ - Starting training!
06/02/2022 23:01:58 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_21_0.3_8_predictions.txt
06/02/2022 23:01:58 - INFO - __main__ - Classification-F1 on test data: 0.2612
06/02/2022 23:01:58 - INFO - __main__ - prefix=emo_16_21, lr=0.3, bsz=8, dev_performance=0.6978403540903542, test_performance=0.261159144066276
06/02/2022 23:01:58 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.2, bsz=8 ...
06/02/2022 23:01:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:01:59 - INFO - __main__ - Printing 3 examples
06/02/2022 23:01:59 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/02/2022 23:01:59 - INFO - __main__ - ['sad']
06/02/2022 23:01:59 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/02/2022 23:01:59 - INFO - __main__ - ['sad']
06/02/2022 23:01:59 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/02/2022 23:01:59 - INFO - __main__ - ['sad']
06/02/2022 23:01:59 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:01:59 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:01:59 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 23:01:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:01:59 - INFO - __main__ - Printing 3 examples
06/02/2022 23:01:59 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/02/2022 23:01:59 - INFO - __main__ - ['sad']
06/02/2022 23:01:59 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/02/2022 23:01:59 - INFO - __main__ - ['sad']
06/02/2022 23:01:59 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/02/2022 23:01:59 - INFO - __main__ - ['sad']
06/02/2022 23:01:59 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:01:59 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:01:59 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 23:02:14 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 23:02:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 23:02:15 - INFO - __main__ - Starting training!
06/02/2022 23:02:18 - INFO - __main__ - Step 10 Global step 10 Train loss 4.78 on epoch=2
06/02/2022 23:02:20 - INFO - __main__ - Step 20 Global step 20 Train loss 3.87 on epoch=4
06/02/2022 23:02:22 - INFO - __main__ - Step 30 Global step 30 Train loss 3.46 on epoch=7
06/02/2022 23:02:25 - INFO - __main__ - Step 40 Global step 40 Train loss 3.00 on epoch=9
06/02/2022 23:02:27 - INFO - __main__ - Step 50 Global step 50 Train loss 2.70 on epoch=12
06/02/2022 23:02:28 - INFO - __main__ - Global step 50 Train loss 3.56 Classification-F1 0.0 on epoch=12
06/02/2022 23:02:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/02/2022 23:02:31 - INFO - __main__ - Step 60 Global step 60 Train loss 2.42 on epoch=14
06/02/2022 23:02:33 - INFO - __main__ - Step 70 Global step 70 Train loss 2.26 on epoch=17
06/02/2022 23:02:35 - INFO - __main__ - Step 80 Global step 80 Train loss 1.94 on epoch=19
06/02/2022 23:02:38 - INFO - __main__ - Step 90 Global step 90 Train loss 2.00 on epoch=22
06/02/2022 23:02:40 - INFO - __main__ - Step 100 Global step 100 Train loss 1.68 on epoch=24
06/02/2022 23:02:41 - INFO - __main__ - Global step 100 Train loss 2.06 Classification-F1 0.04783068783068783 on epoch=24
06/02/2022 23:02:41 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.04783068783068783 on epoch=24, global_step=100
06/02/2022 23:02:44 - INFO - __main__ - Step 110 Global step 110 Train loss 1.61 on epoch=27
06/02/2022 23:02:46 - INFO - __main__ - Step 120 Global step 120 Train loss 1.37 on epoch=29
06/02/2022 23:02:48 - INFO - __main__ - Step 130 Global step 130 Train loss 1.36 on epoch=32
06/02/2022 23:02:51 - INFO - __main__ - Step 140 Global step 140 Train loss 1.29 on epoch=34
06/02/2022 23:02:53 - INFO - __main__ - Step 150 Global step 150 Train loss 1.24 on epoch=37
06/02/2022 23:02:54 - INFO - __main__ - Global step 150 Train loss 1.37 Classification-F1 0.23244239124456909 on epoch=37
06/02/2022 23:02:54 - INFO - __main__ - Saving model with best Classification-F1: 0.04783068783068783 -> 0.23244239124456909 on epoch=37, global_step=150
06/02/2022 23:02:57 - INFO - __main__ - Step 160 Global step 160 Train loss 1.05 on epoch=39
06/02/2022 23:02:59 - INFO - __main__ - Step 170 Global step 170 Train loss 1.11 on epoch=42
06/02/2022 23:03:01 - INFO - __main__ - Step 180 Global step 180 Train loss 0.89 on epoch=44
06/02/2022 23:03:04 - INFO - __main__ - Step 190 Global step 190 Train loss 0.79 on epoch=47
06/02/2022 23:03:06 - INFO - __main__ - Step 200 Global step 200 Train loss 0.90 on epoch=49
06/02/2022 23:03:07 - INFO - __main__ - Global step 200 Train loss 0.95 Classification-F1 0.5330808080808082 on epoch=49
06/02/2022 23:03:07 - INFO - __main__ - Saving model with best Classification-F1: 0.23244239124456909 -> 0.5330808080808082 on epoch=49, global_step=200
06/02/2022 23:03:09 - INFO - __main__ - Step 210 Global step 210 Train loss 0.86 on epoch=52
06/02/2022 23:03:12 - INFO - __main__ - Step 220 Global step 220 Train loss 0.81 on epoch=54
06/02/2022 23:03:14 - INFO - __main__ - Step 230 Global step 230 Train loss 0.79 on epoch=57
06/02/2022 23:03:16 - INFO - __main__ - Step 240 Global step 240 Train loss 0.77 on epoch=59
06/02/2022 23:03:19 - INFO - __main__ - Step 250 Global step 250 Train loss 0.75 on epoch=62
06/02/2022 23:03:20 - INFO - __main__ - Global step 250 Train loss 0.79 Classification-F1 0.5858585858585859 on epoch=62
06/02/2022 23:03:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5330808080808082 -> 0.5858585858585859 on epoch=62, global_step=250
06/02/2022 23:03:22 - INFO - __main__ - Step 260 Global step 260 Train loss 0.72 on epoch=64
06/02/2022 23:03:24 - INFO - __main__ - Step 270 Global step 270 Train loss 0.67 on epoch=67
06/02/2022 23:03:27 - INFO - __main__ - Step 280 Global step 280 Train loss 0.62 on epoch=69
06/02/2022 23:03:29 - INFO - __main__ - Step 290 Global step 290 Train loss 0.65 on epoch=72
06/02/2022 23:03:32 - INFO - __main__ - Step 300 Global step 300 Train loss 0.53 on epoch=74
06/02/2022 23:03:32 - INFO - __main__ - Global step 300 Train loss 0.64 Classification-F1 0.5354482323232324 on epoch=74
06/02/2022 23:03:35 - INFO - __main__ - Step 310 Global step 310 Train loss 0.61 on epoch=77
06/02/2022 23:03:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.58 on epoch=79
06/02/2022 23:03:40 - INFO - __main__ - Step 330 Global step 330 Train loss 0.73 on epoch=82
06/02/2022 23:03:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=84
06/02/2022 23:03:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.57 on epoch=87
06/02/2022 23:03:45 - INFO - __main__ - Global step 350 Train loss 0.61 Classification-F1 0.6315656565656567 on epoch=87
06/02/2022 23:03:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5858585858585859 -> 0.6315656565656567 on epoch=87, global_step=350
06/02/2022 23:03:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.74 on epoch=89
06/02/2022 23:03:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.58 on epoch=92
06/02/2022 23:03:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.52 on epoch=94
06/02/2022 23:03:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.53 on epoch=97
06/02/2022 23:03:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.52 on epoch=99
06/02/2022 23:03:58 - INFO - __main__ - Global step 400 Train loss 0.58 Classification-F1 0.653383425442249 on epoch=99
06/02/2022 23:03:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6315656565656567 -> 0.653383425442249 on epoch=99, global_step=400
06/02/2022 23:04:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.42 on epoch=102
06/02/2022 23:04:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.46 on epoch=104
06/02/2022 23:04:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.51 on epoch=107
06/02/2022 23:04:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.45 on epoch=109
06/02/2022 23:04:10 - INFO - __main__ - Step 450 Global step 450 Train loss 0.53 on epoch=112
06/02/2022 23:04:11 - INFO - __main__ - Global step 450 Train loss 0.47 Classification-F1 0.6549992405255565 on epoch=112
06/02/2022 23:04:11 - INFO - __main__ - Saving model with best Classification-F1: 0.653383425442249 -> 0.6549992405255565 on epoch=112, global_step=450
06/02/2022 23:04:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.43 on epoch=114
06/02/2022 23:04:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.49 on epoch=117
06/02/2022 23:04:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.44 on epoch=119
06/02/2022 23:04:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.48 on epoch=122
06/02/2022 23:04:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.49 on epoch=124
06/02/2022 23:04:23 - INFO - __main__ - Global step 500 Train loss 0.47 Classification-F1 0.6711309523809523 on epoch=124
06/02/2022 23:04:23 - INFO - __main__ - Saving model with best Classification-F1: 0.6549992405255565 -> 0.6711309523809523 on epoch=124, global_step=500
06/02/2022 23:04:26 - INFO - __main__ - Step 510 Global step 510 Train loss 0.46 on epoch=127
06/02/2022 23:04:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.40 on epoch=129
06/02/2022 23:04:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=132
06/02/2022 23:04:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.40 on epoch=134
06/02/2022 23:04:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=137
06/02/2022 23:04:36 - INFO - __main__ - Global step 550 Train loss 0.42 Classification-F1 0.6845259263022421 on epoch=137
06/02/2022 23:04:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6711309523809523 -> 0.6845259263022421 on epoch=137, global_step=550
06/02/2022 23:04:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.34 on epoch=139
06/02/2022 23:04:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.47 on epoch=142
06/02/2022 23:04:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=144
06/02/2022 23:04:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=147
06/02/2022 23:04:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.33 on epoch=149
06/02/2022 23:04:50 - INFO - __main__ - Global step 600 Train loss 0.35 Classification-F1 0.6845259263022421 on epoch=149
06/02/2022 23:04:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.52 on epoch=152
06/02/2022 23:04:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.28 on epoch=154
06/02/2022 23:04:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.46 on epoch=157
06/02/2022 23:04:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.39 on epoch=159
06/02/2022 23:05:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.41 on epoch=162
06/02/2022 23:05:03 - INFO - __main__ - Global step 650 Train loss 0.41 Classification-F1 0.7067218234981394 on epoch=162
06/02/2022 23:05:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6845259263022421 -> 0.7067218234981394 on epoch=162, global_step=650
06/02/2022 23:05:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=164
06/02/2022 23:05:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.38 on epoch=167
06/02/2022 23:05:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.30 on epoch=169
06/02/2022 23:05:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.29 on epoch=172
06/02/2022 23:05:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.34 on epoch=174
06/02/2022 23:05:16 - INFO - __main__ - Global step 700 Train loss 0.31 Classification-F1 0.6845259263022421 on epoch=174
06/02/2022 23:05:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.43 on epoch=177
06/02/2022 23:05:21 - INFO - __main__ - Step 720 Global step 720 Train loss 0.32 on epoch=179
06/02/2022 23:05:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.32 on epoch=182
06/02/2022 23:05:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.24 on epoch=184
06/02/2022 23:05:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.35 on epoch=187
06/02/2022 23:05:29 - INFO - __main__ - Global step 750 Train loss 0.33 Classification-F1 0.6917203890980372 on epoch=187
06/02/2022 23:05:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=189
06/02/2022 23:05:34 - INFO - __main__ - Step 770 Global step 770 Train loss 0.38 on epoch=192
06/02/2022 23:05:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=194
06/02/2022 23:05:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.42 on epoch=197
06/02/2022 23:05:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.31 on epoch=199
06/02/2022 23:05:43 - INFO - __main__ - Global step 800 Train loss 0.32 Classification-F1 0.6705360052134246 on epoch=199
06/02/2022 23:05:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.37 on epoch=202
06/02/2022 23:05:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.26 on epoch=204
06/02/2022 23:05:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.29 on epoch=207
06/02/2022 23:05:53 - INFO - __main__ - Step 840 Global step 840 Train loss 0.28 on epoch=209
06/02/2022 23:05:55 - INFO - __main__ - Step 850 Global step 850 Train loss 0.30 on epoch=212
06/02/2022 23:05:56 - INFO - __main__ - Global step 850 Train loss 0.30 Classification-F1 0.6771630898633187 on epoch=212
06/02/2022 23:05:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.31 on epoch=214
06/02/2022 23:06:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.38 on epoch=217
06/02/2022 23:06:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.28 on epoch=219
06/02/2022 23:06:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.30 on epoch=222
06/02/2022 23:06:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=224
06/02/2022 23:06:09 - INFO - __main__ - Global step 900 Train loss 0.30 Classification-F1 0.6705360052134246 on epoch=224
06/02/2022 23:06:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.29 on epoch=227
06/02/2022 23:06:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.26 on epoch=229
06/02/2022 23:06:16 - INFO - __main__ - Step 930 Global step 930 Train loss 0.26 on epoch=232
06/02/2022 23:06:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.26 on epoch=234
06/02/2022 23:06:21 - INFO - __main__ - Step 950 Global step 950 Train loss 0.42 on epoch=237
06/02/2022 23:06:22 - INFO - __main__ - Global step 950 Train loss 0.30 Classification-F1 0.6805555555555556 on epoch=237
06/02/2022 23:06:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.25 on epoch=239
06/02/2022 23:06:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.31 on epoch=242
06/02/2022 23:06:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.34 on epoch=244
06/02/2022 23:06:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.41 on epoch=247
06/02/2022 23:06:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.34 on epoch=249
06/02/2022 23:06:35 - INFO - __main__ - Global step 1000 Train loss 0.33 Classification-F1 0.6410108342957708 on epoch=249
06/02/2022 23:06:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.22 on epoch=252
06/02/2022 23:06:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.20 on epoch=254
06/02/2022 23:06:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.32 on epoch=257
06/02/2022 23:06:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.23 on epoch=259
06/02/2022 23:06:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.26 on epoch=262
06/02/2022 23:06:49 - INFO - __main__ - Global step 1050 Train loss 0.25 Classification-F1 0.6904775176514306 on epoch=262
06/02/2022 23:06:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=264
06/02/2022 23:06:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.22 on epoch=267
06/02/2022 23:06:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=269
06/02/2022 23:06:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=272
06/02/2022 23:07:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.21 on epoch=274
06/02/2022 23:07:02 - INFO - __main__ - Global step 1100 Train loss 0.20 Classification-F1 0.6747016999019287 on epoch=274
06/02/2022 23:07:05 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=277
06/02/2022 23:07:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.20 on epoch=279
06/02/2022 23:07:10 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.23 on epoch=282
06/02/2022 23:07:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=284
06/02/2022 23:07:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.22 on epoch=287
06/02/2022 23:07:15 - INFO - __main__ - Global step 1150 Train loss 0.20 Classification-F1 0.6771630898633187 on epoch=287
06/02/2022 23:07:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=289
06/02/2022 23:07:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.17 on epoch=292
06/02/2022 23:07:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.25 on epoch=294
06/02/2022 23:07:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.23 on epoch=297
06/02/2022 23:07:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=299
06/02/2022 23:07:29 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.6901596402937051 on epoch=299
06/02/2022 23:07:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=302
06/02/2022 23:07:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=304
06/02/2022 23:07:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.28 on epoch=307
06/02/2022 23:07:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=309
06/02/2022 23:07:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=312
06/02/2022 23:07:42 - INFO - __main__ - Global step 1250 Train loss 0.19 Classification-F1 0.6753083297200944 on epoch=312
06/02/2022 23:07:44 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=314
06/02/2022 23:07:47 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=317
06/02/2022 23:07:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=319
06/02/2022 23:07:52 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=322
06/02/2022 23:07:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.15 on epoch=324
06/02/2022 23:07:55 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.6615438051650866 on epoch=324
06/02/2022 23:07:58 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=327
06/02/2022 23:08:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=329
06/02/2022 23:08:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=332
06/02/2022 23:08:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=334
06/02/2022 23:08:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=337
06/02/2022 23:08:08 - INFO - __main__ - Global step 1350 Train loss 0.14 Classification-F1 0.6763915243516762 on epoch=337
06/02/2022 23:08:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=339
06/02/2022 23:08:13 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=342
06/02/2022 23:08:16 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=344
06/02/2022 23:08:18 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.16 on epoch=347
06/02/2022 23:08:21 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=349
06/02/2022 23:08:22 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.6654489573607221 on epoch=349
06/02/2022 23:08:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=352
06/02/2022 23:08:27 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.15 on epoch=354
06/02/2022 23:08:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=357
06/02/2022 23:08:32 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=359
06/02/2022 23:08:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=362
06/02/2022 23:08:35 - INFO - __main__ - Global step 1450 Train loss 0.12 Classification-F1 0.6490373234435414 on epoch=362
06/02/2022 23:08:38 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=364
06/02/2022 23:08:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=367
06/02/2022 23:08:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.14 on epoch=369
06/02/2022 23:08:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=372
06/02/2022 23:08:48 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=374
06/02/2022 23:08:48 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.6618773946360154 on epoch=374
06/02/2022 23:08:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.13 on epoch=377
06/02/2022 23:08:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.19 on epoch=379
06/02/2022 23:08:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=382
06/02/2022 23:08:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=384
06/02/2022 23:09:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=387
06/02/2022 23:09:02 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.6602350898283578 on epoch=387
06/02/2022 23:09:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.15 on epoch=389
06/02/2022 23:09:07 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.21 on epoch=392
06/02/2022 23:09:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.11 on epoch=394
06/02/2022 23:09:12 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=397
06/02/2022 23:09:14 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/02/2022 23:09:15 - INFO - __main__ - Global step 1600 Train loss 0.12 Classification-F1 0.6768341307814992 on epoch=399
06/02/2022 23:09:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.12 on epoch=402
06/02/2022 23:09:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/02/2022 23:09:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=407
06/02/2022 23:09:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=409
06/02/2022 23:09:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=412
06/02/2022 23:09:28 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.6812633595482961 on epoch=412
06/02/2022 23:09:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=414
06/02/2022 23:09:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=417
06/02/2022 23:09:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=419
06/02/2022 23:09:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=422
06/02/2022 23:09:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=424
06/02/2022 23:09:41 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.6326576576576577 on epoch=424
06/02/2022 23:09:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.13 on epoch=427
06/02/2022 23:09:46 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=429
06/02/2022 23:09:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.12 on epoch=432
06/02/2022 23:09:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=434
06/02/2022 23:09:54 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=437
06/02/2022 23:09:55 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.6612633595482961 on epoch=437
06/02/2022 23:09:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=439
06/02/2022 23:10:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=442
06/02/2022 23:10:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=444
06/02/2022 23:10:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=447
06/02/2022 23:10:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=449
06/02/2022 23:10:08 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.6317867867867868 on epoch=449
06/02/2022 23:10:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.15 on epoch=452
06/02/2022 23:10:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=454
06/02/2022 23:10:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
06/02/2022 23:10:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=459
06/02/2022 23:10:20 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=462
06/02/2022 23:10:21 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.6317867867867868 on epoch=462
06/02/2022 23:10:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=464
06/02/2022 23:10:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=467
06/02/2022 23:10:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=469
06/02/2022 23:10:31 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=472
06/02/2022 23:10:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=474
06/02/2022 23:10:34 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.6468817204301076 on epoch=474
06/02/2022 23:10:37 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=477
06/02/2022 23:10:39 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=479
06/02/2022 23:10:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.12 on epoch=482
06/02/2022 23:10:44 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/02/2022 23:10:47 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=487
06/02/2022 23:10:48 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.6320812056295927 on epoch=487
06/02/2022 23:10:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/02/2022 23:10:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/02/2022 23:10:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=494
06/02/2022 23:10:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=497
06/02/2022 23:11:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=499
06/02/2022 23:11:01 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6614248349732221 on epoch=499
06/02/2022 23:11:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
06/02/2022 23:11:06 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=504
06/02/2022 23:11:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=507
06/02/2022 23:11:11 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=509
06/02/2022 23:11:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=512
06/02/2022 23:11:14 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.6468817204301076 on epoch=512
06/02/2022 23:11:17 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=514
06/02/2022 23:11:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=517
06/02/2022 23:11:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=519
06/02/2022 23:11:24 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=522
06/02/2022 23:11:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.11 on epoch=524
06/02/2022 23:11:27 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.6960053460053459 on epoch=524
06/02/2022 23:11:30 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/02/2022 23:11:32 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/02/2022 23:11:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=532
06/02/2022 23:11:37 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=534
06/02/2022 23:11:40 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/02/2022 23:11:41 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6658621844105715 on epoch=537
06/02/2022 23:11:43 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=539
06/02/2022 23:11:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=542
06/02/2022 23:11:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.10 on epoch=544
06/02/2022 23:11:51 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=547
06/02/2022 23:11:53 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/02/2022 23:11:54 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.6767669172932331 on epoch=549
06/02/2022 23:11:56 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/02/2022 23:11:59 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=554
06/02/2022 23:12:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=557
06/02/2022 23:12:04 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=559
06/02/2022 23:12:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=562
06/02/2022 23:12:07 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.6818376068376067 on epoch=562
06/02/2022 23:12:10 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=564
06/02/2022 23:12:12 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=567
06/02/2022 23:12:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/02/2022 23:12:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=572
06/02/2022 23:12:20 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.09 on epoch=574
06/02/2022 23:12:21 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.6614248349732221 on epoch=574
06/02/2022 23:12:23 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=577
06/02/2022 23:12:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=579
06/02/2022 23:12:28 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=582
06/02/2022 23:12:30 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=584
06/02/2022 23:12:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/02/2022 23:12:34 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.6614248349732221 on epoch=587
06/02/2022 23:12:36 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/02/2022 23:12:39 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=592
06/02/2022 23:12:41 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/02/2022 23:12:44 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=597
06/02/2022 23:12:46 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/02/2022 23:12:47 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.6468817204301076 on epoch=599
06/02/2022 23:12:50 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=602
06/02/2022 23:12:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/02/2022 23:12:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/02/2022 23:12:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=609
06/02/2022 23:13:00 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/02/2022 23:13:00 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6468817204301076 on epoch=612
06/02/2022 23:13:03 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=614
06/02/2022 23:13:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=617
06/02/2022 23:13:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
06/02/2022 23:13:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/02/2022 23:13:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/02/2022 23:13:14 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6468817204301076 on epoch=624
06/02/2022 23:13:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=627
06/02/2022 23:13:19 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=629
06/02/2022 23:13:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=632
06/02/2022 23:13:24 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=634
06/02/2022 23:13:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=637
06/02/2022 23:13:27 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.6627639868128998 on epoch=637
06/02/2022 23:13:30 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=639
06/02/2022 23:13:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=642
06/02/2022 23:13:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=644
06/02/2022 23:13:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=647
06/02/2022 23:13:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/02/2022 23:13:40 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.6468817204301076 on epoch=649
06/02/2022 23:13:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=652
06/02/2022 23:13:45 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=654
06/02/2022 23:13:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=657
06/02/2022 23:13:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=659
06/02/2022 23:13:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=662
06/02/2022 23:13:54 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.6658621844105715 on epoch=662
06/02/2022 23:13:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=664
06/02/2022 23:13:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/02/2022 23:14:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=669
06/02/2022 23:14:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/02/2022 23:14:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=674
06/02/2022 23:14:07 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.6658621844105715 on epoch=674
06/02/2022 23:14:10 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.07 on epoch=677
06/02/2022 23:14:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.15 on epoch=679
06/02/2022 23:14:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
06/02/2022 23:14:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.11 on epoch=684
06/02/2022 23:14:20 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/02/2022 23:14:21 - INFO - __main__ - Global step 2750 Train loss 0.08 Classification-F1 0.6658621844105715 on epoch=687
06/02/2022 23:14:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.08 on epoch=689
06/02/2022 23:14:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=692
06/02/2022 23:14:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=694
06/02/2022 23:14:30 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=697
06/02/2022 23:14:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/02/2022 23:14:34 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.6658621844105715 on epoch=699
06/02/2022 23:14:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=702
06/02/2022 23:14:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/02/2022 23:14:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=707
06/02/2022 23:14:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=709
06/02/2022 23:14:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=712
06/02/2022 23:14:47 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.6658621844105715 on epoch=712
06/02/2022 23:14:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=714
06/02/2022 23:14:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=717
06/02/2022 23:14:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=719
06/02/2022 23:14:57 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=722
06/02/2022 23:15:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=724
06/02/2022 23:15:01 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.6658621844105715 on epoch=724
06/02/2022 23:15:03 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=727
06/02/2022 23:15:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=729
06/02/2022 23:15:08 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=732
06/02/2022 23:15:11 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/02/2022 23:15:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/02/2022 23:15:14 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.6468817204301076 on epoch=737
06/02/2022 23:15:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=739
06/02/2022 23:15:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=742
06/02/2022 23:15:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/02/2022 23:15:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=747
06/02/2022 23:15:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/02/2022 23:15:27 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.6815024044625563 on epoch=749
06/02/2022 23:15:27 - INFO - __main__ - save last model!
06/02/2022 23:15:27 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 23:15:28 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 23:15:28 - INFO - __main__ - Printing 3 examples
06/02/2022 23:15:28 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 23:15:28 - INFO - __main__ - ['others']
06/02/2022 23:15:28 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 23:15:28 - INFO - __main__ - ['others']
06/02/2022 23:15:28 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 23:15:28 - INFO - __main__ - ['others']
06/02/2022 23:15:28 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:15:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:15:28 - INFO - __main__ - Printing 3 examples
06/02/2022 23:15:28 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/02/2022 23:15:28 - INFO - __main__ - ['happy']
06/02/2022 23:15:28 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/02/2022 23:15:28 - INFO - __main__ - ['happy']
06/02/2022 23:15:28 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/02/2022 23:15:28 - INFO - __main__ - ['happy']
06/02/2022 23:15:28 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:15:28 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:15:28 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 23:15:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:15:28 - INFO - __main__ - Printing 3 examples
06/02/2022 23:15:28 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/02/2022 23:15:28 - INFO - __main__ - ['happy']
06/02/2022 23:15:28 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/02/2022 23:15:28 - INFO - __main__ - ['happy']
06/02/2022 23:15:28 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/02/2022 23:15:28 - INFO - __main__ - ['happy']
06/02/2022 23:15:28 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:15:28 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:15:28 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 23:15:30 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:15:35 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 23:15:47 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 23:15:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 23:15:47 - INFO - __main__ - Starting training!
06/02/2022 23:16:52 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_21_0.2_8_predictions.txt
06/02/2022 23:16:52 - INFO - __main__ - Classification-F1 on test data: 0.2295
06/02/2022 23:16:52 - INFO - __main__ - prefix=emo_16_21, lr=0.2, bsz=8, dev_performance=0.7067218234981394, test_performance=0.22945249872639448
06/02/2022 23:16:52 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.5, bsz=8 ...
06/02/2022 23:16:53 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:16:53 - INFO - __main__ - Printing 3 examples
06/02/2022 23:16:53 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/02/2022 23:16:53 - INFO - __main__ - ['happy']
06/02/2022 23:16:53 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/02/2022 23:16:53 - INFO - __main__ - ['happy']
06/02/2022 23:16:53 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/02/2022 23:16:53 - INFO - __main__ - ['happy']
06/02/2022 23:16:53 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:16:53 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:16:53 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 23:16:53 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:16:53 - INFO - __main__ - Printing 3 examples
06/02/2022 23:16:53 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/02/2022 23:16:53 - INFO - __main__ - ['happy']
06/02/2022 23:16:53 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/02/2022 23:16:53 - INFO - __main__ - ['happy']
06/02/2022 23:16:53 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/02/2022 23:16:53 - INFO - __main__ - ['happy']
06/02/2022 23:16:53 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:16:53 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:16:53 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 23:17:12 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 23:17:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 23:17:13 - INFO - __main__ - Starting training!
06/02/2022 23:17:16 - INFO - __main__ - Step 10 Global step 10 Train loss 4.02 on epoch=2
06/02/2022 23:17:18 - INFO - __main__ - Step 20 Global step 20 Train loss 2.97 on epoch=4
06/02/2022 23:17:21 - INFO - __main__ - Step 30 Global step 30 Train loss 2.17 on epoch=7
06/02/2022 23:17:23 - INFO - __main__ - Step 40 Global step 40 Train loss 1.87 on epoch=9
06/02/2022 23:17:26 - INFO - __main__ - Step 50 Global step 50 Train loss 1.44 on epoch=12
06/02/2022 23:17:27 - INFO - __main__ - Global step 50 Train loss 2.49 Classification-F1 0.18092252575011195 on epoch=12
06/02/2022 23:17:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.18092252575011195 on epoch=12, global_step=50
06/02/2022 23:17:29 - INFO - __main__ - Step 60 Global step 60 Train loss 1.26 on epoch=14
06/02/2022 23:17:31 - INFO - __main__ - Step 70 Global step 70 Train loss 1.03 on epoch=17
06/02/2022 23:17:34 - INFO - __main__ - Step 80 Global step 80 Train loss 0.91 on epoch=19
06/02/2022 23:17:36 - INFO - __main__ - Step 90 Global step 90 Train loss 0.87 on epoch=22
06/02/2022 23:17:39 - INFO - __main__ - Step 100 Global step 100 Train loss 0.85 on epoch=24
06/02/2022 23:17:40 - INFO - __main__ - Global step 100 Train loss 0.99 Classification-F1 0.5442645547145127 on epoch=24
06/02/2022 23:17:40 - INFO - __main__ - Saving model with best Classification-F1: 0.18092252575011195 -> 0.5442645547145127 on epoch=24, global_step=100
06/02/2022 23:17:42 - INFO - __main__ - Step 110 Global step 110 Train loss 0.79 on epoch=27
06/02/2022 23:17:44 - INFO - __main__ - Step 120 Global step 120 Train loss 0.79 on epoch=29
06/02/2022 23:17:47 - INFO - __main__ - Step 130 Global step 130 Train loss 0.78 on epoch=32
06/02/2022 23:17:49 - INFO - __main__ - Step 140 Global step 140 Train loss 0.77 on epoch=34
06/02/2022 23:17:52 - INFO - __main__ - Step 150 Global step 150 Train loss 0.79 on epoch=37
06/02/2022 23:17:53 - INFO - __main__ - Global step 150 Train loss 0.78 Classification-F1 0.6373511904761906 on epoch=37
06/02/2022 23:17:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5442645547145127 -> 0.6373511904761906 on epoch=37, global_step=150
06/02/2022 23:17:55 - INFO - __main__ - Step 160 Global step 160 Train loss 0.70 on epoch=39
06/02/2022 23:17:58 - INFO - __main__ - Step 170 Global step 170 Train loss 0.65 on epoch=42
06/02/2022 23:18:00 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=44
06/02/2022 23:18:03 - INFO - __main__ - Step 190 Global step 190 Train loss 0.57 on epoch=47
06/02/2022 23:18:05 - INFO - __main__ - Step 200 Global step 200 Train loss 0.66 on epoch=49
06/02/2022 23:18:06 - INFO - __main__ - Global step 200 Train loss 0.65 Classification-F1 0.6617647058823529 on epoch=49
06/02/2022 23:18:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6373511904761906 -> 0.6617647058823529 on epoch=49, global_step=200
06/02/2022 23:18:08 - INFO - __main__ - Step 210 Global step 210 Train loss 0.50 on epoch=52
06/02/2022 23:18:11 - INFO - __main__ - Step 220 Global step 220 Train loss 0.61 on epoch=54
06/02/2022 23:18:13 - INFO - __main__ - Step 230 Global step 230 Train loss 0.62 on epoch=57
06/02/2022 23:18:15 - INFO - __main__ - Step 240 Global step 240 Train loss 0.61 on epoch=59
06/02/2022 23:18:18 - INFO - __main__ - Step 250 Global step 250 Train loss 0.50 on epoch=62
06/02/2022 23:18:19 - INFO - __main__ - Global step 250 Train loss 0.57 Classification-F1 0.6801489016659296 on epoch=62
06/02/2022 23:18:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6617647058823529 -> 0.6801489016659296 on epoch=62, global_step=250
06/02/2022 23:18:21 - INFO - __main__ - Step 260 Global step 260 Train loss 0.55 on epoch=64
06/02/2022 23:18:24 - INFO - __main__ - Step 270 Global step 270 Train loss 0.50 on epoch=67
06/02/2022 23:18:26 - INFO - __main__ - Step 280 Global step 280 Train loss 0.43 on epoch=69
06/02/2022 23:18:29 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=72
06/02/2022 23:18:31 - INFO - __main__ - Step 300 Global step 300 Train loss 0.50 on epoch=74
06/02/2022 23:18:32 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.7770588235294118 on epoch=74
06/02/2022 23:18:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6801489016659296 -> 0.7770588235294118 on epoch=74, global_step=300
06/02/2022 23:18:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.51 on epoch=77
06/02/2022 23:18:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.41 on epoch=79
06/02/2022 23:18:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.34 on epoch=82
06/02/2022 23:18:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=84
06/02/2022 23:18:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.37 on epoch=87
06/02/2022 23:18:45 - INFO - __main__ - Global step 350 Train loss 0.40 Classification-F1 0.7770588235294118 on epoch=87
06/02/2022 23:18:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=89
06/02/2022 23:18:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=92
06/02/2022 23:18:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.46 on epoch=94
06/02/2022 23:18:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=97
06/02/2022 23:18:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=99
06/02/2022 23:18:58 - INFO - __main__ - Global step 400 Train loss 0.35 Classification-F1 0.758080808080808 on epoch=99
06/02/2022 23:19:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=102
06/02/2022 23:19:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=104
06/02/2022 23:19:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.36 on epoch=107
06/02/2022 23:19:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.26 on epoch=109
06/02/2022 23:19:10 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/02/2022 23:19:11 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.7440020234137881 on epoch=112
06/02/2022 23:19:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=114
06/02/2022 23:19:16 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=117
06/02/2022 23:19:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=119
06/02/2022 23:19:21 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=122
06/02/2022 23:19:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.30 on epoch=124
06/02/2022 23:19:24 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.7631302521008404 on epoch=124
06/02/2022 23:19:26 - INFO - __main__ - Step 510 Global step 510 Train loss 0.32 on epoch=127
06/02/2022 23:19:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=129
06/02/2022 23:19:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=132
06/02/2022 23:19:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=134
06/02/2022 23:19:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=137
06/02/2022 23:19:37 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.729296141060847 on epoch=137
06/02/2022 23:19:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=139
06/02/2022 23:19:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=142
06/02/2022 23:19:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=144
06/02/2022 23:19:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=147
06/02/2022 23:19:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=149
06/02/2022 23:19:50 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.7659411357965307 on epoch=149
06/02/2022 23:19:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=152
06/02/2022 23:19:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=154
06/02/2022 23:19:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=157
06/02/2022 23:19:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.09 on epoch=159
06/02/2022 23:20:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=162
06/02/2022 23:20:03 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.7325024531921084 on epoch=162
06/02/2022 23:20:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=164
06/02/2022 23:20:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=167
06/02/2022 23:20:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=169
06/02/2022 23:20:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=172
06/02/2022 23:20:14 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=174
06/02/2022 23:20:15 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.7160195910195909 on epoch=174
06/02/2022 23:20:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=177
06/02/2022 23:20:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=179
06/02/2022 23:20:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=182
06/02/2022 23:20:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=184
06/02/2022 23:20:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=187
06/02/2022 23:20:28 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.7316769487822119 on epoch=187
06/02/2022 23:20:31 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=189
06/02/2022 23:20:33 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=192
06/02/2022 23:20:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=194
06/02/2022 23:20:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=197
06/02/2022 23:20:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=199
06/02/2022 23:20:42 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.7345854377104377 on epoch=199
06/02/2022 23:20:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/02/2022 23:20:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=204
06/02/2022 23:20:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=207
06/02/2022 23:20:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=209
06/02/2022 23:20:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=212
06/02/2022 23:20:55 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.7340331114524663 on epoch=212
06/02/2022 23:20:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=214
06/02/2022 23:21:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=217
06/02/2022 23:21:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=219
06/02/2022 23:21:04 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/02/2022 23:21:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=224
06/02/2022 23:21:08 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.749074074074074 on epoch=224
06/02/2022 23:21:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/02/2022 23:21:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=229
06/02/2022 23:21:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=232
06/02/2022 23:21:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=234
06/02/2022 23:21:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
06/02/2022 23:21:21 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.7493563081798374 on epoch=237
06/02/2022 23:21:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=239
06/02/2022 23:21:26 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=242
06/02/2022 23:21:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=244
06/02/2022 23:21:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=247
06/02/2022 23:21:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=249
06/02/2022 23:21:34 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.7505137582723791 on epoch=249
06/02/2022 23:21:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=252
06/02/2022 23:21:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=254
06/02/2022 23:21:41 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=257
06/02/2022 23:21:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/02/2022 23:21:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=262
06/02/2022 23:21:47 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.7509204913438785 on epoch=262
06/02/2022 23:21:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=264
06/02/2022 23:21:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/02/2022 23:21:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=269
06/02/2022 23:21:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/02/2022 23:21:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/02/2022 23:22:00 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7507474191596901 on epoch=274
06/02/2022 23:22:02 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/02/2022 23:22:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/02/2022 23:22:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/02/2022 23:22:09 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=284
06/02/2022 23:22:12 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
06/02/2022 23:22:13 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7303033224085856 on epoch=287
06/02/2022 23:22:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=289
06/02/2022 23:22:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/02/2022 23:22:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/02/2022 23:22:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=297
06/02/2022 23:22:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/02/2022 23:22:25 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7480636480636481 on epoch=299
06/02/2022 23:22:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=302
06/02/2022 23:22:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=304
06/02/2022 23:22:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/02/2022 23:22:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/02/2022 23:22:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/02/2022 23:22:38 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7645728114478113 on epoch=312
06/02/2022 23:22:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/02/2022 23:22:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/02/2022 23:22:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/02/2022 23:22:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=322
06/02/2022 23:22:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/02/2022 23:22:51 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.7191240132416603 on epoch=324
06/02/2022 23:22:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/02/2022 23:22:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/02/2022 23:22:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/02/2022 23:23:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/02/2022 23:23:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=337
06/02/2022 23:23:04 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7346504258268963 on epoch=337
06/02/2022 23:23:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=339
06/02/2022 23:23:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/02/2022 23:23:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=344
06/02/2022 23:23:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/02/2022 23:23:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/02/2022 23:23:17 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7157796451914099 on epoch=349
06/02/2022 23:23:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/02/2022 23:23:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/02/2022 23:23:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/02/2022 23:23:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/02/2022 23:23:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=362
06/02/2022 23:23:30 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7501498248202101 on epoch=362
06/02/2022 23:23:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/02/2022 23:23:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/02/2022 23:23:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/02/2022 23:23:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/02/2022 23:23:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=374
06/02/2022 23:23:43 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7808316430020283 on epoch=374
06/02/2022 23:23:43 - INFO - __main__ - Saving model with best Classification-F1: 0.7770588235294118 -> 0.7808316430020283 on epoch=374, global_step=1500
06/02/2022 23:23:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=377
06/02/2022 23:23:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
06/02/2022 23:23:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/02/2022 23:23:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=384
06/02/2022 23:23:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=387
06/02/2022 23:23:56 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7185925538179676 on epoch=387
06/02/2022 23:23:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/02/2022 23:24:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/02/2022 23:24:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=394
06/02/2022 23:24:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=397
06/02/2022 23:24:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
06/02/2022 23:24:09 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7312834224598931 on epoch=399
06/02/2022 23:24:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/02/2022 23:24:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/02/2022 23:24:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/02/2022 23:24:19 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/02/2022 23:24:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/02/2022 23:24:22 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7336294776784209 on epoch=412
06/02/2022 23:24:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/02/2022 23:24:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/02/2022 23:24:29 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/02/2022 23:24:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=422
06/02/2022 23:24:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/02/2022 23:24:35 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7175054112554113 on epoch=424
06/02/2022 23:24:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/02/2022 23:24:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/02/2022 23:24:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=432
06/02/2022 23:24:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
06/02/2022 23:24:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=437
06/02/2022 23:24:48 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7471808657292529 on epoch=437
06/02/2022 23:24:50 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/02/2022 23:24:53 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/02/2022 23:24:55 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/02/2022 23:24:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=447
06/02/2022 23:25:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/02/2022 23:25:01 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7123809523809524 on epoch=449
06/02/2022 23:25:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/02/2022 23:25:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/02/2022 23:25:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/02/2022 23:25:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/02/2022 23:25:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/02/2022 23:25:14 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7504289215686275 on epoch=462
06/02/2022 23:25:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/02/2022 23:25:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/02/2022 23:25:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/02/2022 23:25:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/02/2022 23:25:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/02/2022 23:25:27 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7485149394388826 on epoch=474
06/02/2022 23:25:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/02/2022 23:25:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/02/2022 23:25:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/02/2022 23:25:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/02/2022 23:25:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=487
06/02/2022 23:25:40 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7332125953829807 on epoch=487
06/02/2022 23:25:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=489
06/02/2022 23:25:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/02/2022 23:25:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/02/2022 23:25:50 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/02/2022 23:25:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=499
06/02/2022 23:25:53 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7340102707749766 on epoch=499
06/02/2022 23:25:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/02/2022 23:25:58 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=504
06/02/2022 23:26:00 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/02/2022 23:26:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/02/2022 23:26:05 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/02/2022 23:26:06 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7033264473753906 on epoch=512
06/02/2022 23:26:08 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/02/2022 23:26:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/02/2022 23:26:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/02/2022 23:26:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/02/2022 23:26:18 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/02/2022 23:26:19 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7641923436041083 on epoch=524
06/02/2022 23:26:21 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=527
06/02/2022 23:26:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/02/2022 23:26:26 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/02/2022 23:26:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=534
06/02/2022 23:26:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/02/2022 23:26:32 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.794890873015873 on epoch=537
06/02/2022 23:26:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7808316430020283 -> 0.794890873015873 on epoch=537, global_step=2150
06/02/2022 23:26:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/02/2022 23:26:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/02/2022 23:26:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/02/2022 23:26:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/02/2022 23:26:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/02/2022 23:26:45 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.732189793480116 on epoch=549
06/02/2022 23:26:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/02/2022 23:26:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/02/2022 23:26:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/02/2022 23:26:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/02/2022 23:26:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/02/2022 23:26:59 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7185925538179676 on epoch=562
06/02/2022 23:27:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/02/2022 23:27:04 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=567
06/02/2022 23:27:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/02/2022 23:27:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/02/2022 23:27:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/02/2022 23:27:12 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7325171306261407 on epoch=574
06/02/2022 23:27:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/02/2022 23:27:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/02/2022 23:27:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/02/2022 23:27:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/02/2022 23:27:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/02/2022 23:27:25 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7509875541125541 on epoch=587
06/02/2022 23:27:27 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=589
06/02/2022 23:27:30 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/02/2022 23:27:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/02/2022 23:27:35 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/02/2022 23:27:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=599
06/02/2022 23:27:38 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7326839826839827 on epoch=599
06/02/2022 23:27:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/02/2022 23:27:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/02/2022 23:27:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/02/2022 23:27:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/02/2022 23:27:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/02/2022 23:27:51 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7172550629447182 on epoch=612
06/02/2022 23:27:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/02/2022 23:27:56 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/02/2022 23:27:58 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/02/2022 23:28:01 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/02/2022 23:28:03 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/02/2022 23:28:04 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7489814107461167 on epoch=624
06/02/2022 23:28:07 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/02/2022 23:28:09 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/02/2022 23:28:11 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/02/2022 23:28:14 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/02/2022 23:28:16 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/02/2022 23:28:17 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7023809523809524 on epoch=637
06/02/2022 23:28:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=639
06/02/2022 23:28:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/02/2022 23:28:24 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/02/2022 23:28:27 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/02/2022 23:28:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/02/2022 23:28:30 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7312758925662152 on epoch=649
06/02/2022 23:28:33 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/02/2022 23:28:35 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/02/2022 23:28:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/02/2022 23:28:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/02/2022 23:28:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/02/2022 23:28:43 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7496450681934554 on epoch=662
06/02/2022 23:28:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/02/2022 23:28:48 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/02/2022 23:28:51 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/02/2022 23:28:53 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.10 on epoch=672
06/02/2022 23:28:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/02/2022 23:28:56 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7182327476445123 on epoch=674
06/02/2022 23:28:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/02/2022 23:29:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=679
06/02/2022 23:29:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
06/02/2022 23:29:06 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/02/2022 23:29:08 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/02/2022 23:29:10 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7175054112554113 on epoch=687
06/02/2022 23:29:12 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/02/2022 23:29:14 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/02/2022 23:29:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=694
06/02/2022 23:29:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/02/2022 23:29:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/02/2022 23:29:23 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7314919557566617 on epoch=699
06/02/2022 23:29:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/02/2022 23:29:27 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/02/2022 23:29:30 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/02/2022 23:29:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/02/2022 23:29:35 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/02/2022 23:29:36 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.702468487394958 on epoch=712
06/02/2022 23:29:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=714
06/02/2022 23:29:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/02/2022 23:29:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/02/2022 23:29:45 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/02/2022 23:29:48 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/02/2022 23:29:49 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.733718487394958 on epoch=724
06/02/2022 23:29:51 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/02/2022 23:29:54 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/02/2022 23:29:56 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=732
06/02/2022 23:29:59 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/02/2022 23:30:01 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/02/2022 23:30:02 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7028273809523811 on epoch=737
06/02/2022 23:30:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
06/02/2022 23:30:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=742
06/02/2022 23:30:09 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/02/2022 23:30:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/02/2022 23:30:14 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/02/2022 23:30:15 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:30:15 - INFO - __main__ - Printing 3 examples
06/02/2022 23:30:15 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/02/2022 23:30:15 - INFO - __main__ - ['happy']
06/02/2022 23:30:15 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/02/2022 23:30:15 - INFO - __main__ - ['happy']
06/02/2022 23:30:15 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/02/2022 23:30:15 - INFO - __main__ - ['happy']
06/02/2022 23:30:15 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:30:16 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:30:16 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 23:30:16 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:30:16 - INFO - __main__ - Printing 3 examples
06/02/2022 23:30:16 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/02/2022 23:30:16 - INFO - __main__ - ['happy']
06/02/2022 23:30:16 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/02/2022 23:30:16 - INFO - __main__ - ['happy']
06/02/2022 23:30:16 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/02/2022 23:30:16 - INFO - __main__ - ['happy']
06/02/2022 23:30:16 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:30:16 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7028273809523811 on epoch=749
06/02/2022 23:30:16 - INFO - __main__ - save last model!
06/02/2022 23:30:16 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:30:16 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 23:30:16 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 23:30:16 - INFO - __main__ - Printing 3 examples
06/02/2022 23:30:16 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 23:30:16 - INFO - __main__ - ['others']
06/02/2022 23:30:16 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 23:30:16 - INFO - __main__ - ['others']
06/02/2022 23:30:16 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 23:30:16 - INFO - __main__ - ['others']
06/02/2022 23:30:16 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:30:16 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 23:30:18 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:30:23 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 23:30:34 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 23:30:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 23:30:35 - INFO - __main__ - Starting training!
06/02/2022 23:31:59 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_42_0.5_8_predictions.txt
06/02/2022 23:31:59 - INFO - __main__ - Classification-F1 on test data: 0.3584
06/02/2022 23:31:59 - INFO - __main__ - prefix=emo_16_42, lr=0.5, bsz=8, dev_performance=0.794890873015873, test_performance=0.3583924656625216
06/02/2022 23:31:59 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.4, bsz=8 ...
06/02/2022 23:32:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:32:00 - INFO - __main__ - Printing 3 examples
06/02/2022 23:32:00 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/02/2022 23:32:00 - INFO - __main__ - ['happy']
06/02/2022 23:32:00 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/02/2022 23:32:00 - INFO - __main__ - ['happy']
06/02/2022 23:32:00 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/02/2022 23:32:00 - INFO - __main__ - ['happy']
06/02/2022 23:32:00 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:32:00 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:32:00 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 23:32:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:32:00 - INFO - __main__ - Printing 3 examples
06/02/2022 23:32:00 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/02/2022 23:32:00 - INFO - __main__ - ['happy']
06/02/2022 23:32:00 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/02/2022 23:32:00 - INFO - __main__ - ['happy']
06/02/2022 23:32:00 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/02/2022 23:32:00 - INFO - __main__ - ['happy']
06/02/2022 23:32:00 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:32:00 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:32:00 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 23:32:15 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 23:32:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 23:32:16 - INFO - __main__ - Starting training!
06/02/2022 23:32:19 - INFO - __main__ - Step 10 Global step 10 Train loss 4.29 on epoch=2
06/02/2022 23:32:21 - INFO - __main__ - Step 20 Global step 20 Train loss 3.38 on epoch=4
06/02/2022 23:32:23 - INFO - __main__ - Step 30 Global step 30 Train loss 2.37 on epoch=7
06/02/2022 23:32:26 - INFO - __main__ - Step 40 Global step 40 Train loss 2.26 on epoch=9
06/02/2022 23:32:28 - INFO - __main__ - Step 50 Global step 50 Train loss 1.65 on epoch=12
06/02/2022 23:32:29 - INFO - __main__ - Global step 50 Train loss 2.79 Classification-F1 0.1289483463396507 on epoch=12
06/02/2022 23:32:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1289483463396507 on epoch=12, global_step=50
06/02/2022 23:32:32 - INFO - __main__ - Step 60 Global step 60 Train loss 1.86 on epoch=14
06/02/2022 23:32:34 - INFO - __main__ - Step 70 Global step 70 Train loss 1.34 on epoch=17
06/02/2022 23:32:36 - INFO - __main__ - Step 80 Global step 80 Train loss 1.21 on epoch=19
06/02/2022 23:32:39 - INFO - __main__ - Step 90 Global step 90 Train loss 0.98 on epoch=22
06/02/2022 23:32:41 - INFO - __main__ - Step 100 Global step 100 Train loss 0.93 on epoch=24
06/02/2022 23:32:42 - INFO - __main__ - Global step 100 Train loss 1.26 Classification-F1 0.3083333333333333 on epoch=24
06/02/2022 23:32:42 - INFO - __main__ - Saving model with best Classification-F1: 0.1289483463396507 -> 0.3083333333333333 on epoch=24, global_step=100
06/02/2022 23:32:44 - INFO - __main__ - Step 110 Global step 110 Train loss 0.90 on epoch=27
06/02/2022 23:32:47 - INFO - __main__ - Step 120 Global step 120 Train loss 0.95 on epoch=29
06/02/2022 23:32:49 - INFO - __main__ - Step 130 Global step 130 Train loss 0.87 on epoch=32
06/02/2022 23:32:52 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=34
06/02/2022 23:32:54 - INFO - __main__ - Step 150 Global step 150 Train loss 0.74 on epoch=37
06/02/2022 23:32:55 - INFO - __main__ - Global step 150 Train loss 0.85 Classification-F1 0.37364481833403945 on epoch=37
06/02/2022 23:32:55 - INFO - __main__ - Saving model with best Classification-F1: 0.3083333333333333 -> 0.37364481833403945 on epoch=37, global_step=150
06/02/2022 23:32:57 - INFO - __main__ - Step 160 Global step 160 Train loss 0.83 on epoch=39
06/02/2022 23:33:00 - INFO - __main__ - Step 170 Global step 170 Train loss 0.74 on epoch=42
06/02/2022 23:33:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=44
06/02/2022 23:33:04 - INFO - __main__ - Step 190 Global step 190 Train loss 0.72 on epoch=47
06/02/2022 23:33:07 - INFO - __main__ - Step 200 Global step 200 Train loss 0.66 on epoch=49
06/02/2022 23:33:08 - INFO - __main__ - Global step 200 Train loss 0.72 Classification-F1 0.6106738417951232 on epoch=49
06/02/2022 23:33:08 - INFO - __main__ - Saving model with best Classification-F1: 0.37364481833403945 -> 0.6106738417951232 on epoch=49, global_step=200
06/02/2022 23:33:10 - INFO - __main__ - Step 210 Global step 210 Train loss 0.77 on epoch=52
06/02/2022 23:33:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.65 on epoch=54
06/02/2022 23:33:15 - INFO - __main__ - Step 230 Global step 230 Train loss 0.50 on epoch=57
06/02/2022 23:33:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.69 on epoch=59
06/02/2022 23:33:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.56 on epoch=62
06/02/2022 23:33:21 - INFO - __main__ - Global step 250 Train loss 0.63 Classification-F1 0.6809257984130107 on epoch=62
06/02/2022 23:33:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6106738417951232 -> 0.6809257984130107 on epoch=62, global_step=250
06/02/2022 23:33:23 - INFO - __main__ - Step 260 Global step 260 Train loss 0.55 on epoch=64
06/02/2022 23:33:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.57 on epoch=67
06/02/2022 23:33:28 - INFO - __main__ - Step 280 Global step 280 Train loss 0.58 on epoch=69
06/02/2022 23:33:30 - INFO - __main__ - Step 290 Global step 290 Train loss 0.55 on epoch=72
06/02/2022 23:33:33 - INFO - __main__ - Step 300 Global step 300 Train loss 0.52 on epoch=74
06/02/2022 23:33:34 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.709418657788223 on epoch=74
06/02/2022 23:33:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6809257984130107 -> 0.709418657788223 on epoch=74, global_step=300
06/02/2022 23:33:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.69 on epoch=77
06/02/2022 23:33:38 - INFO - __main__ - Step 320 Global step 320 Train loss 0.46 on epoch=79
06/02/2022 23:33:41 - INFO - __main__ - Step 330 Global step 330 Train loss 0.40 on epoch=82
06/02/2022 23:33:43 - INFO - __main__ - Step 340 Global step 340 Train loss 0.40 on epoch=84
06/02/2022 23:33:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=87
06/02/2022 23:33:46 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.7377948280761579 on epoch=87
06/02/2022 23:33:47 - INFO - __main__ - Saving model with best Classification-F1: 0.709418657788223 -> 0.7377948280761579 on epoch=87, global_step=350
06/02/2022 23:33:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.45 on epoch=89
06/02/2022 23:33:51 - INFO - __main__ - Step 370 Global step 370 Train loss 0.47 on epoch=92
06/02/2022 23:33:54 - INFO - __main__ - Step 380 Global step 380 Train loss 0.50 on epoch=94
06/02/2022 23:33:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.43 on epoch=97
06/02/2022 23:33:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.42 on epoch=99
06/02/2022 23:34:00 - INFO - __main__ - Global step 400 Train loss 0.46 Classification-F1 0.7295751633986929 on epoch=99
06/02/2022 23:34:02 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=102
06/02/2022 23:34:04 - INFO - __main__ - Step 420 Global step 420 Train loss 0.46 on epoch=104
06/02/2022 23:34:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=107
06/02/2022 23:34:09 - INFO - __main__ - Step 440 Global step 440 Train loss 0.51 on epoch=109
06/02/2022 23:34:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.39 on epoch=112
06/02/2022 23:34:12 - INFO - __main__ - Global step 450 Train loss 0.44 Classification-F1 0.709200056834328 on epoch=112
06/02/2022 23:34:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=114
06/02/2022 23:34:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.34 on epoch=117
06/02/2022 23:34:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.37 on epoch=119
06/02/2022 23:34:22 - INFO - __main__ - Step 490 Global step 490 Train loss 0.32 on epoch=122
06/02/2022 23:34:24 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=124
06/02/2022 23:34:25 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.7012709137709138 on epoch=124
06/02/2022 23:34:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=127
06/02/2022 23:34:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=129
06/02/2022 23:34:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.31 on epoch=132
06/02/2022 23:34:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.42 on epoch=134
06/02/2022 23:34:37 - INFO - __main__ - Step 550 Global step 550 Train loss 0.31 on epoch=137
06/02/2022 23:34:38 - INFO - __main__ - Global step 550 Train loss 0.34 Classification-F1 0.6950310559006212 on epoch=137
06/02/2022 23:34:41 - INFO - __main__ - Step 560 Global step 560 Train loss 0.31 on epoch=139
06/02/2022 23:34:43 - INFO - __main__ - Step 570 Global step 570 Train loss 0.37 on epoch=142
06/02/2022 23:34:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=144
06/02/2022 23:34:48 - INFO - __main__ - Step 590 Global step 590 Train loss 0.30 on epoch=147
06/02/2022 23:34:50 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=149
06/02/2022 23:34:51 - INFO - __main__ - Global step 600 Train loss 0.29 Classification-F1 0.7009803921568627 on epoch=149
06/02/2022 23:34:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.30 on epoch=152
06/02/2022 23:34:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/02/2022 23:34:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=157
06/02/2022 23:35:00 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/02/2022 23:35:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=162
06/02/2022 23:35:04 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.7154061624649859 on epoch=162
06/02/2022 23:35:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=164
06/02/2022 23:35:09 - INFO - __main__ - Step 670 Global step 670 Train loss 0.26 on epoch=167
06/02/2022 23:35:11 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=169
06/02/2022 23:35:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=172
06/02/2022 23:35:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=174
06/02/2022 23:35:17 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.6848484848484847 on epoch=174
06/02/2022 23:35:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=177
06/02/2022 23:35:21 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=179
06/02/2022 23:35:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=182
06/02/2022 23:35:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=184
06/02/2022 23:35:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=187
06/02/2022 23:35:29 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.6715288220551379 on epoch=187
06/02/2022 23:35:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=189
06/02/2022 23:35:34 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=192
06/02/2022 23:35:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=194
06/02/2022 23:35:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=197
06/02/2022 23:35:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=199
06/02/2022 23:35:42 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.7196652272019919 on epoch=199
06/02/2022 23:35:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=202
06/02/2022 23:35:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=204
06/02/2022 23:35:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=207
06/02/2022 23:35:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=209
06/02/2022 23:35:55 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=212
06/02/2022 23:35:55 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.7193843193843193 on epoch=212
06/02/2022 23:35:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=214
06/02/2022 23:36:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=217
06/02/2022 23:36:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=219
06/02/2022 23:36:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
06/02/2022 23:36:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=224
06/02/2022 23:36:08 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.7339509414877061 on epoch=224
06/02/2022 23:36:11 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=227
06/02/2022 23:36:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=229
06/02/2022 23:36:16 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=232
06/02/2022 23:36:18 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=234
06/02/2022 23:36:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=237
06/02/2022 23:36:21 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.7148692810457516 on epoch=237
06/02/2022 23:36:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=239
06/02/2022 23:36:26 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=242
06/02/2022 23:36:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=244
06/02/2022 23:36:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=247
06/02/2022 23:36:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=249
06/02/2022 23:36:34 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.7484743265993266 on epoch=249
06/02/2022 23:36:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7377948280761579 -> 0.7484743265993266 on epoch=249, global_step=1000
06/02/2022 23:36:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=252
06/02/2022 23:36:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=254
06/02/2022 23:36:41 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=257
06/02/2022 23:36:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=259
06/02/2022 23:36:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
06/02/2022 23:36:47 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.7203918426344896 on epoch=262
06/02/2022 23:36:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=264
06/02/2022 23:36:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=267
06/02/2022 23:36:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
06/02/2022 23:36:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=272
06/02/2022 23:36:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=274
06/02/2022 23:37:00 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.7194957983193278 on epoch=274
06/02/2022 23:37:02 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=277
06/02/2022 23:37:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=279
06/02/2022 23:37:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/02/2022 23:37:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=284
06/02/2022 23:37:12 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=287
06/02/2022 23:37:13 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7034697750067769 on epoch=287
06/02/2022 23:37:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=289
06/02/2022 23:37:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=292
06/02/2022 23:37:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=294
06/02/2022 23:37:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=297
06/02/2022 23:37:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/02/2022 23:37:26 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.7182327476445123 on epoch=299
06/02/2022 23:37:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=302
06/02/2022 23:37:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=304
06/02/2022 23:37:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=307
06/02/2022 23:37:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/02/2022 23:37:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=312
06/02/2022 23:37:38 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.6869431643625191 on epoch=312
06/02/2022 23:37:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=314
06/02/2022 23:37:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=317
06/02/2022 23:37:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/02/2022 23:37:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/02/2022 23:37:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/02/2022 23:37:51 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.6849206349206349 on epoch=324
06/02/2022 23:37:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=327
06/02/2022 23:37:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=329
06/02/2022 23:37:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/02/2022 23:38:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/02/2022 23:38:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=337
06/02/2022 23:38:04 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.6547420634920635 on epoch=337
06/02/2022 23:38:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=339
06/02/2022 23:38:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=342
06/02/2022 23:38:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=344
06/02/2022 23:38:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=347
06/02/2022 23:38:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/02/2022 23:38:17 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7184523809523811 on epoch=349
06/02/2022 23:38:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/02/2022 23:38:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=354
06/02/2022 23:38:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/02/2022 23:38:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/02/2022 23:38:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=362
06/02/2022 23:38:30 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7179040791944018 on epoch=362
06/02/2022 23:38:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=364
06/02/2022 23:38:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
06/02/2022 23:38:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/02/2022 23:38:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/02/2022 23:38:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/02/2022 23:38:43 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6553781512605042 on epoch=374
06/02/2022 23:38:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=377
06/02/2022 23:38:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=379
06/02/2022 23:38:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/02/2022 23:38:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/02/2022 23:38:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/02/2022 23:38:56 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.6878090659340659 on epoch=387
06/02/2022 23:38:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/02/2022 23:39:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=392
06/02/2022 23:39:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/02/2022 23:39:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/02/2022 23:39:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
06/02/2022 23:39:09 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7045391767818239 on epoch=399
06/02/2022 23:39:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/02/2022 23:39:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/02/2022 23:39:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/02/2022 23:39:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/02/2022 23:39:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=412
06/02/2022 23:39:22 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.6847899159663866 on epoch=412
06/02/2022 23:39:24 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/02/2022 23:39:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/02/2022 23:39:29 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/02/2022 23:39:31 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=422
06/02/2022 23:39:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/02/2022 23:39:35 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7003959537915395 on epoch=424
06/02/2022 23:39:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/02/2022 23:39:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/02/2022 23:39:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/02/2022 23:39:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/02/2022 23:39:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/02/2022 23:39:48 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7023538961038961 on epoch=437
06/02/2022 23:39:50 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/02/2022 23:39:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/02/2022 23:39:55 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/02/2022 23:39:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
06/02/2022 23:40:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=449
06/02/2022 23:40:01 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7006370869274094 on epoch=449
06/02/2022 23:40:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=452
06/02/2022 23:40:05 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/02/2022 23:40:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/02/2022 23:40:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/02/2022 23:40:12 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/02/2022 23:40:13 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7006370869274094 on epoch=462
06/02/2022 23:40:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/02/2022 23:40:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=467
06/02/2022 23:40:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/02/2022 23:40:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/02/2022 23:40:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=474
06/02/2022 23:40:26 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6863530668677729 on epoch=474
06/02/2022 23:40:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=477
06/02/2022 23:40:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/02/2022 23:40:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/02/2022 23:40:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/02/2022 23:40:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=487
06/02/2022 23:40:39 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7021173271173271 on epoch=487
06/02/2022 23:40:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/02/2022 23:40:44 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/02/2022 23:40:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=494
06/02/2022 23:40:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/02/2022 23:40:51 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/02/2022 23:40:52 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6977017339920566 on epoch=499
06/02/2022 23:40:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/02/2022 23:40:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
06/02/2022 23:41:00 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=507
06/02/2022 23:41:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/02/2022 23:41:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=512
06/02/2022 23:41:05 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.6847899159663866 on epoch=512
06/02/2022 23:41:08 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/02/2022 23:41:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/02/2022 23:41:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/02/2022 23:41:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/02/2022 23:41:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/02/2022 23:41:18 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6864697802197803 on epoch=524
06/02/2022 23:41:20 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/02/2022 23:41:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/02/2022 23:41:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=532
06/02/2022 23:41:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/02/2022 23:41:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/02/2022 23:41:31 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6864697802197803 on epoch=537
06/02/2022 23:41:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/02/2022 23:41:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/02/2022 23:41:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/02/2022 23:41:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/02/2022 23:41:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=549
06/02/2022 23:41:44 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7024457805707804 on epoch=549
06/02/2022 23:41:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/02/2022 23:41:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/02/2022 23:41:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/02/2022 23:41:54 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/02/2022 23:41:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/02/2022 23:41:57 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7027942645589704 on epoch=562
06/02/2022 23:41:59 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/02/2022 23:42:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=567
06/02/2022 23:42:04 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=569
06/02/2022 23:42:07 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/02/2022 23:42:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=574
06/02/2022 23:42:10 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7027942645589704 on epoch=574
06/02/2022 23:42:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/02/2022 23:42:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
06/02/2022 23:42:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=582
06/02/2022 23:42:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/02/2022 23:42:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/02/2022 23:42:23 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7027942645589704 on epoch=587
06/02/2022 23:42:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/02/2022 23:42:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/02/2022 23:42:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
06/02/2022 23:42:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/02/2022 23:42:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/02/2022 23:42:36 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7181756573597181 on epoch=599
06/02/2022 23:42:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/02/2022 23:42:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/02/2022 23:42:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=607
06/02/2022 23:42:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/02/2022 23:42:48 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/02/2022 23:42:49 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7156204906204906 on epoch=612
06/02/2022 23:42:51 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=614
06/02/2022 23:42:54 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/02/2022 23:42:56 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/02/2022 23:42:59 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/02/2022 23:43:01 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=624
06/02/2022 23:43:02 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6685520361990951 on epoch=624
06/02/2022 23:43:04 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/02/2022 23:43:07 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=629
06/02/2022 23:43:09 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/02/2022 23:43:12 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/02/2022 23:43:14 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/02/2022 23:43:15 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.6862745098039216 on epoch=637
06/02/2022 23:43:17 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/02/2022 23:43:20 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/02/2022 23:43:22 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/02/2022 23:43:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/02/2022 23:43:27 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/02/2022 23:43:28 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.685763888888889 on epoch=649
06/02/2022 23:43:30 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/02/2022 23:43:33 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/02/2022 23:43:35 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/02/2022 23:43:37 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/02/2022 23:43:40 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/02/2022 23:43:41 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7022141003231104 on epoch=662
06/02/2022 23:43:43 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=664
06/02/2022 23:43:45 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/02/2022 23:43:48 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/02/2022 23:43:50 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=672
06/02/2022 23:43:53 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=674
06/02/2022 23:43:54 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7175816993464053 on epoch=674
06/02/2022 23:43:56 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=677
06/02/2022 23:43:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/02/2022 23:44:01 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/02/2022 23:44:03 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/02/2022 23:44:05 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/02/2022 23:44:06 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7184523809523811 on epoch=687
06/02/2022 23:44:09 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/02/2022 23:44:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/02/2022 23:44:14 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/02/2022 23:44:16 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/02/2022 23:44:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=699
06/02/2022 23:44:19 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7032130056323604 on epoch=699
06/02/2022 23:44:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=702
06/02/2022 23:44:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/02/2022 23:44:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/02/2022 23:44:29 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/02/2022 23:44:31 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/02/2022 23:44:32 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7184523809523811 on epoch=712
06/02/2022 23:44:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/02/2022 23:44:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/02/2022 23:44:40 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=719
06/02/2022 23:44:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/02/2022 23:44:44 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/02/2022 23:44:45 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7130781799899447 on epoch=724
06/02/2022 23:44:48 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=727
06/02/2022 23:44:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=729
06/02/2022 23:44:53 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/02/2022 23:44:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/02/2022 23:44:57 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/02/2022 23:44:58 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.716006216006216 on epoch=737
06/02/2022 23:45:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=739
06/02/2022 23:45:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/02/2022 23:45:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/02/2022 23:45:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=747
06/02/2022 23:45:10 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=749
06/02/2022 23:45:11 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6946098554794207 on epoch=749
06/02/2022 23:45:11 - INFO - __main__ - save last model!
06/02/2022 23:45:11 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 23:45:11 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 23:45:11 - INFO - __main__ - Printing 3 examples
06/02/2022 23:45:11 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 23:45:11 - INFO - __main__ - ['others']
06/02/2022 23:45:11 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 23:45:11 - INFO - __main__ - ['others']
06/02/2022 23:45:11 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 23:45:11 - INFO - __main__ - ['others']
06/02/2022 23:45:11 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:45:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:45:11 - INFO - __main__ - Printing 3 examples
06/02/2022 23:45:11 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/02/2022 23:45:11 - INFO - __main__ - ['happy']
06/02/2022 23:45:11 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/02/2022 23:45:11 - INFO - __main__ - ['happy']
06/02/2022 23:45:11 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/02/2022 23:45:11 - INFO - __main__ - ['happy']
06/02/2022 23:45:11 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:45:11 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:45:11 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 23:45:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:45:11 - INFO - __main__ - Printing 3 examples
06/02/2022 23:45:11 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/02/2022 23:45:11 - INFO - __main__ - ['happy']
06/02/2022 23:45:11 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/02/2022 23:45:11 - INFO - __main__ - ['happy']
06/02/2022 23:45:11 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/02/2022 23:45:11 - INFO - __main__ - ['happy']
06/02/2022 23:45:11 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:45:11 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:45:11 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 23:45:13 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:45:19 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 23:45:27 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 23:45:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 23:45:28 - INFO - __main__ - Starting training!
06/02/2022 23:46:45 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_42_0.4_8_predictions.txt
06/02/2022 23:46:46 - INFO - __main__ - Classification-F1 on test data: 0.4090
06/02/2022 23:46:46 - INFO - __main__ - prefix=emo_16_42, lr=0.4, bsz=8, dev_performance=0.7484743265993266, test_performance=0.4090455057354468
06/02/2022 23:46:46 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.3, bsz=8 ...
06/02/2022 23:46:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:46:47 - INFO - __main__ - Printing 3 examples
06/02/2022 23:46:47 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/02/2022 23:46:47 - INFO - __main__ - ['happy']
06/02/2022 23:46:47 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/02/2022 23:46:47 - INFO - __main__ - ['happy']
06/02/2022 23:46:47 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/02/2022 23:46:47 - INFO - __main__ - ['happy']
06/02/2022 23:46:47 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:46:47 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:46:47 - INFO - __main__ - Loaded 64 examples from train data
06/02/2022 23:46:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/02/2022 23:46:47 - INFO - __main__ - Printing 3 examples
06/02/2022 23:46:47 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/02/2022 23:46:47 - INFO - __main__ - ['happy']
06/02/2022 23:46:47 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/02/2022 23:46:47 - INFO - __main__ - ['happy']
06/02/2022 23:46:47 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/02/2022 23:46:47 - INFO - __main__ - ['happy']
06/02/2022 23:46:47 - INFO - __main__ - Tokenizing Input ...
06/02/2022 23:46:47 - INFO - __main__ - Tokenizing Output ...
06/02/2022 23:46:47 - INFO - __main__ - Loaded 64 examples from dev data
06/02/2022 23:47:02 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 23:47:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 23:47:02 - INFO - __main__ - Starting training!
06/02/2022 23:47:05 - INFO - __main__ - Step 10 Global step 10 Train loss 4.50 on epoch=2
06/02/2022 23:47:07 - INFO - __main__ - Step 20 Global step 20 Train loss 3.34 on epoch=4
06/02/2022 23:47:10 - INFO - __main__ - Step 30 Global step 30 Train loss 2.69 on epoch=7
06/02/2022 23:47:12 - INFO - __main__ - Step 40 Global step 40 Train loss 2.46 on epoch=9
06/02/2022 23:47:15 - INFO - __main__ - Step 50 Global step 50 Train loss 1.99 on epoch=12
06/02/2022 23:47:16 - INFO - __main__ - Global step 50 Train loss 2.99 Classification-F1 0.06984126984126984 on epoch=12
06/02/2022 23:47:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06984126984126984 on epoch=12, global_step=50
06/02/2022 23:47:18 - INFO - __main__ - Step 60 Global step 60 Train loss 2.08 on epoch=14
06/02/2022 23:47:20 - INFO - __main__ - Step 70 Global step 70 Train loss 1.72 on epoch=17
06/02/2022 23:47:23 - INFO - __main__ - Step 80 Global step 80 Train loss 1.62 on epoch=19
06/02/2022 23:47:25 - INFO - __main__ - Step 90 Global step 90 Train loss 1.52 on epoch=22
06/02/2022 23:47:27 - INFO - __main__ - Step 100 Global step 100 Train loss 1.25 on epoch=24
06/02/2022 23:47:28 - INFO - __main__ - Global step 100 Train loss 1.64 Classification-F1 0.2417063492063492 on epoch=24
06/02/2022 23:47:29 - INFO - __main__ - Saving model with best Classification-F1: 0.06984126984126984 -> 0.2417063492063492 on epoch=24, global_step=100
06/02/2022 23:47:31 - INFO - __main__ - Step 110 Global step 110 Train loss 1.02 on epoch=27
06/02/2022 23:47:33 - INFO - __main__ - Step 120 Global step 120 Train loss 1.03 on epoch=29
06/02/2022 23:47:36 - INFO - __main__ - Step 130 Global step 130 Train loss 1.01 on epoch=32
06/02/2022 23:47:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.90 on epoch=34
06/02/2022 23:47:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.89 on epoch=37
06/02/2022 23:47:41 - INFO - __main__ - Global step 150 Train loss 0.97 Classification-F1 0.4523809523809524 on epoch=37
06/02/2022 23:47:41 - INFO - __main__ - Saving model with best Classification-F1: 0.2417063492063492 -> 0.4523809523809524 on epoch=37, global_step=150
06/02/2022 23:47:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.84 on epoch=39
06/02/2022 23:47:46 - INFO - __main__ - Step 170 Global step 170 Train loss 0.81 on epoch=42
06/02/2022 23:47:48 - INFO - __main__ - Step 180 Global step 180 Train loss 0.82 on epoch=44
06/02/2022 23:47:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.74 on epoch=47
06/02/2022 23:47:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.93 on epoch=49
06/02/2022 23:47:54 - INFO - __main__ - Global step 200 Train loss 0.83 Classification-F1 0.4542188178623603 on epoch=49
06/02/2022 23:47:54 - INFO - __main__ - Saving model with best Classification-F1: 0.4523809523809524 -> 0.4542188178623603 on epoch=49, global_step=200
06/02/2022 23:47:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.67 on epoch=52
06/02/2022 23:47:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.77 on epoch=54
06/02/2022 23:48:01 - INFO - __main__ - Step 230 Global step 230 Train loss 0.66 on epoch=57
06/02/2022 23:48:04 - INFO - __main__ - Step 240 Global step 240 Train loss 0.75 on epoch=59
06/02/2022 23:48:06 - INFO - __main__ - Step 250 Global step 250 Train loss 0.63 on epoch=62
06/02/2022 23:48:07 - INFO - __main__ - Global step 250 Train loss 0.70 Classification-F1 0.4541930937279774 on epoch=62
06/02/2022 23:48:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=64
06/02/2022 23:48:11 - INFO - __main__ - Step 270 Global step 270 Train loss 0.68 on epoch=67
06/02/2022 23:48:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.71 on epoch=69
06/02/2022 23:48:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.69 on epoch=72
06/02/2022 23:48:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.59 on epoch=74
06/02/2022 23:48:19 - INFO - __main__ - Global step 300 Train loss 0.65 Classification-F1 0.5171481680860951 on epoch=74
06/02/2022 23:48:19 - INFO - __main__ - Saving model with best Classification-F1: 0.4542188178623603 -> 0.5171481680860951 on epoch=74, global_step=300
06/02/2022 23:48:22 - INFO - __main__ - Step 310 Global step 310 Train loss 0.57 on epoch=77
06/02/2022 23:48:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.59 on epoch=79
06/02/2022 23:48:27 - INFO - __main__ - Step 330 Global step 330 Train loss 0.57 on epoch=82
06/02/2022 23:48:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.50 on epoch=84
06/02/2022 23:48:31 - INFO - __main__ - Step 350 Global step 350 Train loss 0.59 on epoch=87
06/02/2022 23:48:32 - INFO - __main__ - Global step 350 Train loss 0.57 Classification-F1 0.6385850991114149 on epoch=87
06/02/2022 23:48:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5171481680860951 -> 0.6385850991114149 on epoch=87, global_step=350
06/02/2022 23:48:35 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=89
06/02/2022 23:48:37 - INFO - __main__ - Step 370 Global step 370 Train loss 0.49 on epoch=92
06/02/2022 23:48:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.54 on epoch=94
06/02/2022 23:48:42 - INFO - __main__ - Step 390 Global step 390 Train loss 0.48 on epoch=97
06/02/2022 23:48:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.51 on epoch=99
06/02/2022 23:48:45 - INFO - __main__ - Global step 400 Train loss 0.51 Classification-F1 0.6944581327470527 on epoch=99
06/02/2022 23:48:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6385850991114149 -> 0.6944581327470527 on epoch=99, global_step=400
06/02/2022 23:48:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.53 on epoch=102
06/02/2022 23:48:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.51 on epoch=104
06/02/2022 23:48:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.52 on epoch=107
06/02/2022 23:48:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.45 on epoch=109
06/02/2022 23:48:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.51 on epoch=112
06/02/2022 23:48:58 - INFO - __main__ - Global step 450 Train loss 0.50 Classification-F1 0.6734519852166911 on epoch=112
06/02/2022 23:49:00 - INFO - __main__ - Step 460 Global step 460 Train loss 0.50 on epoch=114
06/02/2022 23:49:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.51 on epoch=117
06/02/2022 23:49:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.45 on epoch=119
06/02/2022 23:49:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.41 on epoch=122
06/02/2022 23:49:10 - INFO - __main__ - Step 500 Global step 500 Train loss 0.47 on epoch=124
06/02/2022 23:49:11 - INFO - __main__ - Global step 500 Train loss 0.47 Classification-F1 0.70899209486166 on epoch=124
06/02/2022 23:49:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6944581327470527 -> 0.70899209486166 on epoch=124, global_step=500
06/02/2022 23:49:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.50 on epoch=127
06/02/2022 23:49:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.52 on epoch=129
06/02/2022 23:49:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.37 on epoch=132
06/02/2022 23:49:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.44 on epoch=134
06/02/2022 23:49:23 - INFO - __main__ - Step 550 Global step 550 Train loss 0.39 on epoch=137
06/02/2022 23:49:24 - INFO - __main__ - Global step 550 Train loss 0.44 Classification-F1 0.7096202249015549 on epoch=137
06/02/2022 23:49:24 - INFO - __main__ - Saving model with best Classification-F1: 0.70899209486166 -> 0.7096202249015549 on epoch=137, global_step=550
06/02/2022 23:49:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.35 on epoch=139
06/02/2022 23:49:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.33 on epoch=142
06/02/2022 23:49:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.39 on epoch=144
06/02/2022 23:49:33 - INFO - __main__ - Step 590 Global step 590 Train loss 0.29 on epoch=147
06/02/2022 23:49:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.46 on epoch=149
06/02/2022 23:49:37 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.7090101610561969 on epoch=149
06/02/2022 23:49:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.31 on epoch=152
06/02/2022 23:49:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.42 on epoch=154
06/02/2022 23:49:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=157
06/02/2022 23:49:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.38 on epoch=159
06/02/2022 23:49:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.34 on epoch=162
06/02/2022 23:49:50 - INFO - __main__ - Global step 650 Train loss 0.35 Classification-F1 0.729906204906205 on epoch=162
06/02/2022 23:49:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7096202249015549 -> 0.729906204906205 on epoch=162, global_step=650
06/02/2022 23:49:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.43 on epoch=164
06/02/2022 23:49:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.32 on epoch=167
06/02/2022 23:49:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.36 on epoch=169
06/02/2022 23:49:59 - INFO - __main__ - Step 690 Global step 690 Train loss 0.32 on epoch=172
06/02/2022 23:50:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.31 on epoch=174
06/02/2022 23:50:03 - INFO - __main__ - Global step 700 Train loss 0.35 Classification-F1 0.7156204906204906 on epoch=174
06/02/2022 23:50:05 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=177
06/02/2022 23:50:08 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=179
06/02/2022 23:50:10 - INFO - __main__ - Step 730 Global step 730 Train loss 0.39 on epoch=182
06/02/2022 23:50:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.37 on epoch=184
06/02/2022 23:50:15 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=187
06/02/2022 23:50:16 - INFO - __main__ - Global step 750 Train loss 0.30 Classification-F1 0.7440020234137881 on epoch=187
06/02/2022 23:50:16 - INFO - __main__ - Saving model with best Classification-F1: 0.729906204906205 -> 0.7440020234137881 on epoch=187, global_step=750
06/02/2022 23:50:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=189
06/02/2022 23:50:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=192
06/02/2022 23:50:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=194
06/02/2022 23:50:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.28 on epoch=197
06/02/2022 23:50:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=199
06/02/2022 23:50:29 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.7480672268907562 on epoch=199
06/02/2022 23:50:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7440020234137881 -> 0.7480672268907562 on epoch=199, global_step=800
06/02/2022 23:50:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=202
06/02/2022 23:50:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=204
06/02/2022 23:50:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=207
06/02/2022 23:50:38 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=209
06/02/2022 23:50:41 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=212
06/02/2022 23:50:42 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.7136989931107578 on epoch=212
06/02/2022 23:50:44 - INFO - __main__ - Step 860 Global step 860 Train loss 0.25 on epoch=214
06/02/2022 23:50:46 - INFO - __main__ - Step 870 Global step 870 Train loss 0.22 on epoch=217
06/02/2022 23:50:49 - INFO - __main__ - Step 880 Global step 880 Train loss 0.23 on epoch=219
06/02/2022 23:50:51 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=222
06/02/2022 23:50:53 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=224
06/02/2022 23:50:54 - INFO - __main__ - Global step 900 Train loss 0.23 Classification-F1 0.7508150633150632 on epoch=224
06/02/2022 23:50:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7480672268907562 -> 0.7508150633150632 on epoch=224, global_step=900
06/02/2022 23:50:57 - INFO - __main__ - Step 910 Global step 910 Train loss 0.30 on epoch=227
06/02/2022 23:50:59 - INFO - __main__ - Step 920 Global step 920 Train loss 0.28 on epoch=229
06/02/2022 23:51:02 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=232
06/02/2022 23:51:04 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=234
06/02/2022 23:51:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=237
06/02/2022 23:51:07 - INFO - __main__ - Global step 950 Train loss 0.21 Classification-F1 0.7508150633150632 on epoch=237
06/02/2022 23:51:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.22 on epoch=239
06/02/2022 23:51:12 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=242
06/02/2022 23:51:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=244
06/02/2022 23:51:17 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=247
06/02/2022 23:51:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=249
06/02/2022 23:51:20 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.7510166304283951 on epoch=249
06/02/2022 23:51:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7508150633150632 -> 0.7510166304283951 on epoch=249, global_step=1000
06/02/2022 23:51:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=252
06/02/2022 23:51:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.19 on epoch=254
06/02/2022 23:51:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=257
06/02/2022 23:51:30 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=259
06/02/2022 23:51:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=262
06/02/2022 23:51:33 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.7047458133971292 on epoch=262
06/02/2022 23:51:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=264
06/02/2022 23:51:38 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=267
06/02/2022 23:51:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=269
06/02/2022 23:51:43 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=272
06/02/2022 23:51:45 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=274
06/02/2022 23:51:46 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.7502826027019575 on epoch=274
06/02/2022 23:51:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=277
06/02/2022 23:51:51 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=279
06/02/2022 23:51:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=282
06/02/2022 23:51:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=284
06/02/2022 23:51:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=287
06/02/2022 23:51:59 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.7320337301587301 on epoch=287
06/02/2022 23:52:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=289
06/02/2022 23:52:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=292
06/02/2022 23:52:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=294
06/02/2022 23:52:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=297
06/02/2022 23:52:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.19 on epoch=299
06/02/2022 23:52:12 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.7482254550565745 on epoch=299
06/02/2022 23:52:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=302
06/02/2022 23:52:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=304
06/02/2022 23:52:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=307
06/02/2022 23:52:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=309
06/02/2022 23:52:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=312
06/02/2022 23:52:25 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.7180952380952381 on epoch=312
06/02/2022 23:52:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/02/2022 23:52:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=317
06/02/2022 23:52:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=319
06/02/2022 23:52:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=322
06/02/2022 23:52:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=324
06/02/2022 23:52:38 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.7489478114478113 on epoch=324
06/02/2022 23:52:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=327
06/02/2022 23:52:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=329
06/02/2022 23:52:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=332
06/02/2022 23:52:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=334
06/02/2022 23:52:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=337
06/02/2022 23:52:51 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.7010767451943922 on epoch=337
06/02/2022 23:52:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=339
06/02/2022 23:52:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=342
06/02/2022 23:52:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=344
06/02/2022 23:53:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=347
06/02/2022 23:53:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/02/2022 23:53:04 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.7356112637362637 on epoch=349
06/02/2022 23:53:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=352
06/02/2022 23:53:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=354
06/02/2022 23:53:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=357
06/02/2022 23:53:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/02/2022 23:53:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=362
06/02/2022 23:53:16 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7185416666666666 on epoch=362
06/02/2022 23:53:19 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=364
06/02/2022 23:53:21 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=367
06/02/2022 23:53:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=369
06/02/2022 23:53:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=372
06/02/2022 23:53:28 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=374
06/02/2022 23:53:29 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6846753246753248 on epoch=374
06/02/2022 23:53:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=377
06/02/2022 23:53:34 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=379
06/02/2022 23:53:37 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=382
06/02/2022 23:53:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/02/2022 23:53:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/02/2022 23:53:42 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6882284382284383 on epoch=387
06/02/2022 23:53:45 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=389
06/02/2022 23:53:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=392
06/02/2022 23:53:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
06/02/2022 23:53:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=397
06/02/2022 23:53:54 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=399
06/02/2022 23:53:55 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7183986928104575 on epoch=399
06/02/2022 23:53:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=402
06/02/2022 23:54:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/02/2022 23:54:03 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=407
06/02/2022 23:54:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/02/2022 23:54:07 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=412
06/02/2022 23:54:08 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7339958407605467 on epoch=412
06/02/2022 23:54:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/02/2022 23:54:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=417
06/02/2022 23:54:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/02/2022 23:54:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/02/2022 23:54:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=424
06/02/2022 23:54:21 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7176030668677729 on epoch=424
06/02/2022 23:54:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/02/2022 23:54:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=429
06/02/2022 23:54:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=432
06/02/2022 23:54:31 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/02/2022 23:54:34 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=437
06/02/2022 23:54:34 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7198268398268399 on epoch=437
06/02/2022 23:54:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=439
06/02/2022 23:54:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/02/2022 23:54:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/02/2022 23:54:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
06/02/2022 23:54:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=449
06/02/2022 23:54:48 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7198268398268399 on epoch=449
06/02/2022 23:54:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/02/2022 23:54:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=454
06/02/2022 23:54:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=457
06/02/2022 23:54:57 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
06/02/2022 23:55:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=462
06/02/2022 23:55:00 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.6986206393227266 on epoch=462
06/02/2022 23:55:03 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/02/2022 23:55:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/02/2022 23:55:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/02/2022 23:55:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=472
06/02/2022 23:55:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/02/2022 23:55:13 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6893582887700535 on epoch=474
06/02/2022 23:55:16 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/02/2022 23:55:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/02/2022 23:55:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=482
06/02/2022 23:55:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/02/2022 23:55:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=487
06/02/2022 23:55:27 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6862745098039215 on epoch=487
06/02/2022 23:55:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/02/2022 23:55:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=492
06/02/2022 23:55:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/02/2022 23:55:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/02/2022 23:55:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=499
06/02/2022 23:55:40 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7176030668677729 on epoch=499
06/02/2022 23:55:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/02/2022 23:55:45 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=504
06/02/2022 23:55:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=507
06/02/2022 23:55:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=509
06/02/2022 23:55:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/02/2022 23:55:53 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.685595238095238 on epoch=512
06/02/2022 23:55:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=514
06/02/2022 23:55:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/02/2022 23:56:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/02/2022 23:56:02 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/02/2022 23:56:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/02/2022 23:56:06 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.6878795546558705 on epoch=524
06/02/2022 23:56:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/02/2022 23:56:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=529
06/02/2022 23:56:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/02/2022 23:56:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/02/2022 23:56:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/02/2022 23:56:19 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6879734848484849 on epoch=537
06/02/2022 23:56:21 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=539
06/02/2022 23:56:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=542
06/02/2022 23:56:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.12 on epoch=544
06/02/2022 23:56:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/02/2022 23:56:31 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=549
06/02/2022 23:56:32 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.6875632316808787 on epoch=549
06/02/2022 23:56:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=552
06/02/2022 23:56:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=554
06/02/2022 23:56:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/02/2022 23:56:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/02/2022 23:56:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=562
06/02/2022 23:56:45 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.6880883822060293 on epoch=562
06/02/2022 23:56:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/02/2022 23:56:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/02/2022 23:56:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/02/2022 23:56:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/02/2022 23:56:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/02/2022 23:56:58 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7170799788446847 on epoch=574
06/02/2022 23:57:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/02/2022 23:57:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/02/2022 23:57:05 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/02/2022 23:57:08 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/02/2022 23:57:10 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=587
06/02/2022 23:57:11 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7333613445378151 on epoch=587
06/02/2022 23:57:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=589
06/02/2022 23:57:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=592
06/02/2022 23:57:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
06/02/2022 23:57:21 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/02/2022 23:57:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/02/2022 23:57:25 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7027942645589704 on epoch=599
06/02/2022 23:57:27 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/02/2022 23:57:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/02/2022 23:57:32 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/02/2022 23:57:34 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/02/2022 23:57:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/02/2022 23:57:38 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.71667731948467 on epoch=612
06/02/2022 23:57:40 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=614
06/02/2022 23:57:43 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/02/2022 23:57:45 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/02/2022 23:57:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=622
06/02/2022 23:57:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=624
06/02/2022 23:57:51 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7008658008658009 on epoch=624
06/02/2022 23:57:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/02/2022 23:57:56 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/02/2022 23:57:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/02/2022 23:58:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/02/2022 23:58:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/02/2022 23:58:04 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.71619379748412 on epoch=637
06/02/2022 23:58:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/02/2022 23:58:09 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=642
06/02/2022 23:58:11 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/02/2022 23:58:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=647
06/02/2022 23:58:16 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/02/2022 23:58:17 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.71667731948467 on epoch=649
06/02/2022 23:58:19 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=652
06/02/2022 23:58:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=654
06/02/2022 23:58:24 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/02/2022 23:58:27 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=659
06/02/2022 23:58:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=662
06/02/2022 23:58:30 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.71667731948467 on epoch=662
06/02/2022 23:58:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/02/2022 23:58:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/02/2022 23:58:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/02/2022 23:58:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=672
06/02/2022 23:58:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/02/2022 23:58:43 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7001854795972443 on epoch=674
06/02/2022 23:58:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=677
06/02/2022 23:58:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/02/2022 23:58:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/02/2022 23:58:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/02/2022 23:58:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/02/2022 23:58:57 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7017316017316017 on epoch=687
06/02/2022 23:58:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=689
06/02/2022 23:59:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/02/2022 23:59:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/02/2022 23:59:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/02/2022 23:59:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/02/2022 23:59:10 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6710942441492725 on epoch=699
06/02/2022 23:59:12 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/02/2022 23:59:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.08 on epoch=704
06/02/2022 23:59:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/02/2022 23:59:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/02/2022 23:59:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/02/2022 23:59:23 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7036931818181819 on epoch=712
06/02/2022 23:59:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.11 on epoch=714
06/02/2022 23:59:28 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/02/2022 23:59:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/02/2022 23:59:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=722
06/02/2022 23:59:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=724
06/02/2022 23:59:36 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7017316017316017 on epoch=724
06/02/2022 23:59:38 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
06/02/2022 23:59:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/02/2022 23:59:43 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/02/2022 23:59:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/02/2022 23:59:48 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/02/2022 23:59:49 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7020947802197803 on epoch=737
06/02/2022 23:59:51 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=739
06/02/2022 23:59:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/02/2022 23:59:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=744
06/02/2022 23:59:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=747
06/03/2022 00:00:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/03/2022 00:00:02 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7035268652915713 on epoch=749
06/03/2022 00:00:02 - INFO - __main__ - save last model!
06/03/2022 00:00:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/03/2022 00:00:02 - INFO - __main__ - Start tokenizing ... 5509 instances
06/03/2022 00:00:02 - INFO - __main__ - Printing 3 examples
06/03/2022 00:00:02 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/03/2022 00:00:02 - INFO - __main__ - ['others']
06/03/2022 00:00:02 - INFO - __main__ -  [emo] what you like very little things ok
06/03/2022 00:00:02 - INFO - __main__ - ['others']
06/03/2022 00:00:02 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/03/2022 00:00:02 - INFO - __main__ - ['others']
06/03/2022 00:00:02 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:00:02 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:00:02 - INFO - __main__ - Printing 3 examples
06/03/2022 00:00:02 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/03/2022 00:00:02 - INFO - __main__ - ['happy']
06/03/2022 00:00:02 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/03/2022 00:00:02 - INFO - __main__ - ['happy']
06/03/2022 00:00:02 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/03/2022 00:00:02 - INFO - __main__ - ['happy']
06/03/2022 00:00:02 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:00:02 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:00:02 - INFO - __main__ - Loaded 64 examples from train data
06/03/2022 00:00:02 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:00:02 - INFO - __main__ - Printing 3 examples
06/03/2022 00:00:02 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/03/2022 00:00:02 - INFO - __main__ - ['happy']
06/03/2022 00:00:02 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/03/2022 00:00:02 - INFO - __main__ - ['happy']
06/03/2022 00:00:02 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/03/2022 00:00:02 - INFO - __main__ - ['happy']
06/03/2022 00:00:02 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:00:02 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:00:02 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 00:00:04 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:00:09 - INFO - __main__ - Loaded 5509 examples from test data
06/03/2022 00:00:18 - INFO - __main__ - load prompt embedding from ckpt
06/03/2022 00:00:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/03/2022 00:00:19 - INFO - __main__ - Starting training!
06/03/2022 00:01:41 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_42_0.3_8_predictions.txt
06/03/2022 00:01:41 - INFO - __main__ - Classification-F1 on test data: 0.3445
06/03/2022 00:01:41 - INFO - __main__ - prefix=emo_16_42, lr=0.3, bsz=8, dev_performance=0.7510166304283951, test_performance=0.34450026881853174
06/03/2022 00:01:41 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.2, bsz=8 ...
06/03/2022 00:01:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:01:42 - INFO - __main__ - Printing 3 examples
06/03/2022 00:01:42 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/03/2022 00:01:42 - INFO - __main__ - ['happy']
06/03/2022 00:01:42 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/03/2022 00:01:42 - INFO - __main__ - ['happy']
06/03/2022 00:01:42 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/03/2022 00:01:42 - INFO - __main__ - ['happy']
06/03/2022 00:01:42 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:01:42 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:01:42 - INFO - __main__ - Loaded 64 examples from train data
06/03/2022 00:01:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:01:42 - INFO - __main__ - Printing 3 examples
06/03/2022 00:01:42 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/03/2022 00:01:42 - INFO - __main__ - ['happy']
06/03/2022 00:01:42 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/03/2022 00:01:42 - INFO - __main__ - ['happy']
06/03/2022 00:01:42 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/03/2022 00:01:42 - INFO - __main__ - ['happy']
06/03/2022 00:01:42 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:01:42 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:01:42 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 00:01:57 - INFO - __main__ - load prompt embedding from ckpt
06/03/2022 00:01:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/03/2022 00:01:58 - INFO - __main__ - Starting training!
06/03/2022 00:02:01 - INFO - __main__ - Step 10 Global step 10 Train loss 4.33 on epoch=2
06/03/2022 00:02:03 - INFO - __main__ - Step 20 Global step 20 Train loss 3.66 on epoch=4
06/03/2022 00:02:05 - INFO - __main__ - Step 30 Global step 30 Train loss 3.15 on epoch=7
06/03/2022 00:02:08 - INFO - __main__ - Step 40 Global step 40 Train loss 2.91 on epoch=9
06/03/2022 00:02:10 - INFO - __main__ - Step 50 Global step 50 Train loss 2.39 on epoch=12
06/03/2022 00:02:11 - INFO - __main__ - Global step 50 Train loss 3.29 Classification-F1 0.04832535885167464 on epoch=12
06/03/2022 00:02:11 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04832535885167464 on epoch=12, global_step=50
06/03/2022 00:02:14 - INFO - __main__ - Step 60 Global step 60 Train loss 2.29 on epoch=14
06/03/2022 00:02:16 - INFO - __main__ - Step 70 Global step 70 Train loss 2.04 on epoch=17
06/03/2022 00:02:19 - INFO - __main__ - Step 80 Global step 80 Train loss 1.96 on epoch=19
06/03/2022 00:02:21 - INFO - __main__ - Step 90 Global step 90 Train loss 1.75 on epoch=22
06/03/2022 00:02:23 - INFO - __main__ - Step 100 Global step 100 Train loss 1.70 on epoch=24
06/03/2022 00:02:25 - INFO - __main__ - Global step 100 Train loss 1.95 Classification-F1 0.15919117647058822 on epoch=24
06/03/2022 00:02:25 - INFO - __main__ - Saving model with best Classification-F1: 0.04832535885167464 -> 0.15919117647058822 on epoch=24, global_step=100
06/03/2022 00:02:27 - INFO - __main__ - Step 110 Global step 110 Train loss 1.61 on epoch=27
06/03/2022 00:02:30 - INFO - __main__ - Step 120 Global step 120 Train loss 1.48 on epoch=29
06/03/2022 00:02:32 - INFO - __main__ - Step 130 Global step 130 Train loss 1.33 on epoch=32
06/03/2022 00:02:35 - INFO - __main__ - Step 140 Global step 140 Train loss 1.25 on epoch=34
06/03/2022 00:02:37 - INFO - __main__ - Step 150 Global step 150 Train loss 1.08 on epoch=37
06/03/2022 00:02:38 - INFO - __main__ - Global step 150 Train loss 1.35 Classification-F1 0.3250436540759122 on epoch=37
06/03/2022 00:02:38 - INFO - __main__ - Saving model with best Classification-F1: 0.15919117647058822 -> 0.3250436540759122 on epoch=37, global_step=150
06/03/2022 00:02:40 - INFO - __main__ - Step 160 Global step 160 Train loss 1.12 on epoch=39
06/03/2022 00:02:43 - INFO - __main__ - Step 170 Global step 170 Train loss 0.99 on epoch=42
06/03/2022 00:02:45 - INFO - __main__ - Step 180 Global step 180 Train loss 1.00 on epoch=44
06/03/2022 00:02:47 - INFO - __main__ - Step 190 Global step 190 Train loss 0.95 on epoch=47
06/03/2022 00:02:50 - INFO - __main__ - Step 200 Global step 200 Train loss 0.89 on epoch=49
06/03/2022 00:02:51 - INFO - __main__ - Global step 200 Train loss 0.99 Classification-F1 0.3674656736079444 on epoch=49
06/03/2022 00:02:51 - INFO - __main__ - Saving model with best Classification-F1: 0.3250436540759122 -> 0.3674656736079444 on epoch=49, global_step=200
06/03/2022 00:02:53 - INFO - __main__ - Step 210 Global step 210 Train loss 0.84 on epoch=52
06/03/2022 00:02:55 - INFO - __main__ - Step 220 Global step 220 Train loss 0.81 on epoch=54
06/03/2022 00:02:58 - INFO - __main__ - Step 230 Global step 230 Train loss 0.88 on epoch=57
06/03/2022 00:03:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.82 on epoch=59
06/03/2022 00:03:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.67 on epoch=62
06/03/2022 00:03:04 - INFO - __main__ - Global step 250 Train loss 0.80 Classification-F1 0.36380952380952386 on epoch=62
06/03/2022 00:03:06 - INFO - __main__ - Step 260 Global step 260 Train loss 0.88 on epoch=64
06/03/2022 00:03:08 - INFO - __main__ - Step 270 Global step 270 Train loss 0.75 on epoch=67
06/03/2022 00:03:11 - INFO - __main__ - Step 280 Global step 280 Train loss 0.80 on epoch=69
06/03/2022 00:03:13 - INFO - __main__ - Step 290 Global step 290 Train loss 0.72 on epoch=72
06/03/2022 00:03:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.74 on epoch=74
06/03/2022 00:03:16 - INFO - __main__ - Global step 300 Train loss 0.78 Classification-F1 0.4869393044855641 on epoch=74
06/03/2022 00:03:16 - INFO - __main__ - Saving model with best Classification-F1: 0.3674656736079444 -> 0.4869393044855641 on epoch=74, global_step=300
06/03/2022 00:03:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.78 on epoch=77
06/03/2022 00:03:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.70 on epoch=79
06/03/2022 00:03:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.72 on epoch=82
06/03/2022 00:03:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.72 on epoch=84
06/03/2022 00:03:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.68 on epoch=87
06/03/2022 00:03:29 - INFO - __main__ - Global step 350 Train loss 0.72 Classification-F1 0.5313700918964077 on epoch=87
06/03/2022 00:03:29 - INFO - __main__ - Saving model with best Classification-F1: 0.4869393044855641 -> 0.5313700918964077 on epoch=87, global_step=350
06/03/2022 00:03:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.70 on epoch=89
06/03/2022 00:03:34 - INFO - __main__ - Step 370 Global step 370 Train loss 0.61 on epoch=92
06/03/2022 00:03:37 - INFO - __main__ - Step 380 Global step 380 Train loss 0.77 on epoch=94
06/03/2022 00:03:39 - INFO - __main__ - Step 390 Global step 390 Train loss 0.62 on epoch=97
06/03/2022 00:03:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.58 on epoch=99
06/03/2022 00:03:42 - INFO - __main__ - Global step 400 Train loss 0.66 Classification-F1 0.6498511904761906 on epoch=99
06/03/2022 00:03:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5313700918964077 -> 0.6498511904761906 on epoch=99, global_step=400
06/03/2022 00:03:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.75 on epoch=102
06/03/2022 00:03:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.60 on epoch=104
06/03/2022 00:03:49 - INFO - __main__ - Step 430 Global step 430 Train loss 0.62 on epoch=107
06/03/2022 00:03:52 - INFO - __main__ - Step 440 Global step 440 Train loss 0.68 on epoch=109
06/03/2022 00:03:54 - INFO - __main__ - Step 450 Global step 450 Train loss 0.60 on epoch=112
06/03/2022 00:03:55 - INFO - __main__ - Global step 450 Train loss 0.65 Classification-F1 0.6503200365512058 on epoch=112
06/03/2022 00:03:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6498511904761906 -> 0.6503200365512058 on epoch=112, global_step=450
06/03/2022 00:03:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.65 on epoch=114
06/03/2022 00:04:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.61 on epoch=117
06/03/2022 00:04:02 - INFO - __main__ - Step 480 Global step 480 Train loss 0.64 on epoch=119
06/03/2022 00:04:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.58 on epoch=122
06/03/2022 00:04:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.65 on epoch=124
06/03/2022 00:04:08 - INFO - __main__ - Global step 500 Train loss 0.63 Classification-F1 0.6498511904761906 on epoch=124
06/03/2022 00:04:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.56 on epoch=127
06/03/2022 00:04:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.60 on epoch=129
06/03/2022 00:04:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.64 on epoch=132
06/03/2022 00:04:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.66 on epoch=134
06/03/2022 00:04:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.49 on epoch=137
06/03/2022 00:04:21 - INFO - __main__ - Global step 550 Train loss 0.59 Classification-F1 0.6719749000999 on epoch=137
06/03/2022 00:04:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6503200365512058 -> 0.6719749000999 on epoch=137, global_step=550
06/03/2022 00:04:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.49 on epoch=139
06/03/2022 00:04:26 - INFO - __main__ - Step 570 Global step 570 Train loss 0.46 on epoch=142
06/03/2022 00:04:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.43 on epoch=144
06/03/2022 00:04:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.52 on epoch=147
06/03/2022 00:04:33 - INFO - __main__ - Step 600 Global step 600 Train loss 0.44 on epoch=149
06/03/2022 00:04:34 - INFO - __main__ - Global step 600 Train loss 0.47 Classification-F1 0.680470460864644 on epoch=149
06/03/2022 00:04:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6719749000999 -> 0.680470460864644 on epoch=149, global_step=600
06/03/2022 00:04:36 - INFO - __main__ - Step 610 Global step 610 Train loss 0.57 on epoch=152
06/03/2022 00:04:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.52 on epoch=154
06/03/2022 00:04:41 - INFO - __main__ - Step 630 Global step 630 Train loss 0.40 on epoch=157
06/03/2022 00:04:43 - INFO - __main__ - Step 640 Global step 640 Train loss 0.59 on epoch=159
06/03/2022 00:04:46 - INFO - __main__ - Step 650 Global step 650 Train loss 0.43 on epoch=162
06/03/2022 00:04:46 - INFO - __main__ - Global step 650 Train loss 0.50 Classification-F1 0.7164289958407605 on epoch=162
06/03/2022 00:04:46 - INFO - __main__ - Saving model with best Classification-F1: 0.680470460864644 -> 0.7164289958407605 on epoch=162, global_step=650
06/03/2022 00:04:49 - INFO - __main__ - Step 660 Global step 660 Train loss 0.54 on epoch=164
06/03/2022 00:04:51 - INFO - __main__ - Step 670 Global step 670 Train loss 0.57 on epoch=167
06/03/2022 00:04:54 - INFO - __main__ - Step 680 Global step 680 Train loss 0.50 on epoch=169
06/03/2022 00:04:56 - INFO - __main__ - Step 690 Global step 690 Train loss 0.44 on epoch=172
06/03/2022 00:04:59 - INFO - __main__ - Step 700 Global step 700 Train loss 0.55 on epoch=174
06/03/2022 00:04:59 - INFO - __main__ - Global step 700 Train loss 0.52 Classification-F1 0.7093790917656848 on epoch=174
06/03/2022 00:05:02 - INFO - __main__ - Step 710 Global step 710 Train loss 0.38 on epoch=177
06/03/2022 00:05:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.41 on epoch=179
06/03/2022 00:05:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.44 on epoch=182
06/03/2022 00:05:09 - INFO - __main__ - Step 740 Global step 740 Train loss 0.38 on epoch=184
06/03/2022 00:05:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.52 on epoch=187
06/03/2022 00:05:12 - INFO - __main__ - Global step 750 Train loss 0.43 Classification-F1 0.7370423340961099 on epoch=187
06/03/2022 00:05:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7164289958407605 -> 0.7370423340961099 on epoch=187, global_step=750
06/03/2022 00:05:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.40 on epoch=189
06/03/2022 00:05:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.42 on epoch=192
06/03/2022 00:05:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.41 on epoch=194
06/03/2022 00:05:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.37 on epoch=197
06/03/2022 00:05:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.39 on epoch=199
06/03/2022 00:05:25 - INFO - __main__ - Global step 800 Train loss 0.40 Classification-F1 0.7574174406604747 on epoch=199
06/03/2022 00:05:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7370423340961099 -> 0.7574174406604747 on epoch=199, global_step=800
06/03/2022 00:05:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.41 on epoch=202
06/03/2022 00:05:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.34 on epoch=204
06/03/2022 00:05:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.31 on epoch=207
06/03/2022 00:05:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.31 on epoch=209
06/03/2022 00:05:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.43 on epoch=212
06/03/2022 00:05:38 - INFO - __main__ - Global step 850 Train loss 0.36 Classification-F1 0.7377948280761579 on epoch=212
06/03/2022 00:05:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.36 on epoch=214
06/03/2022 00:05:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.39 on epoch=217
06/03/2022 00:05:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.33 on epoch=219
06/03/2022 00:05:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.38 on epoch=222
06/03/2022 00:05:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.33 on epoch=224
06/03/2022 00:05:51 - INFO - __main__ - Global step 900 Train loss 0.36 Classification-F1 0.7770588235294118 on epoch=224
06/03/2022 00:05:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7574174406604747 -> 0.7770588235294118 on epoch=224, global_step=900
06/03/2022 00:05:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.34 on epoch=227
06/03/2022 00:05:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.36 on epoch=229
06/03/2022 00:05:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.34 on epoch=232
06/03/2022 00:06:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.34 on epoch=234
06/03/2022 00:06:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.41 on epoch=237
06/03/2022 00:06:04 - INFO - __main__ - Global step 950 Train loss 0.36 Classification-F1 0.7625715421303656 on epoch=237
06/03/2022 00:06:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.37 on epoch=239
06/03/2022 00:06:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.26 on epoch=242
06/03/2022 00:06:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=244
06/03/2022 00:06:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.29 on epoch=247
06/03/2022 00:06:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.28 on epoch=249
06/03/2022 00:06:17 - INFO - __main__ - Global step 1000 Train loss 0.29 Classification-F1 0.7759289729877965 on epoch=249
06/03/2022 00:06:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.30 on epoch=252
06/03/2022 00:06:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.34 on epoch=254
06/03/2022 00:06:24 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.32 on epoch=257
06/03/2022 00:06:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.26 on epoch=259
06/03/2022 00:06:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.45 on epoch=262
06/03/2022 00:06:30 - INFO - __main__ - Global step 1050 Train loss 0.33 Classification-F1 0.756969696969697 on epoch=262
06/03/2022 00:06:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.31 on epoch=264
06/03/2022 00:06:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.31 on epoch=267
06/03/2022 00:06:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=269
06/03/2022 00:06:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.35 on epoch=272
06/03/2022 00:06:42 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.23 on epoch=274
06/03/2022 00:06:43 - INFO - __main__ - Global step 1100 Train loss 0.29 Classification-F1 0.7467358092358093 on epoch=274
06/03/2022 00:06:45 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.29 on epoch=277
06/03/2022 00:06:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.25 on epoch=279
06/03/2022 00:06:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.22 on epoch=282
06/03/2022 00:06:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.31 on epoch=284
06/03/2022 00:06:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.28 on epoch=287
06/03/2022 00:06:56 - INFO - __main__ - Global step 1150 Train loss 0.27 Classification-F1 0.7613122171945701 on epoch=287
06/03/2022 00:06:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.23 on epoch=289
06/03/2022 00:07:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.21 on epoch=292
06/03/2022 00:07:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.27 on epoch=294
06/03/2022 00:07:05 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.24 on epoch=297
06/03/2022 00:07:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=299
06/03/2022 00:07:09 - INFO - __main__ - Global step 1200 Train loss 0.23 Classification-F1 0.7792137056842939 on epoch=299
06/03/2022 00:07:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7770588235294118 -> 0.7792137056842939 on epoch=299, global_step=1200
06/03/2022 00:07:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.25 on epoch=302
06/03/2022 00:07:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.20 on epoch=304
06/03/2022 00:07:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.22 on epoch=307
06/03/2022 00:07:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.19 on epoch=309
06/03/2022 00:07:21 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=312
06/03/2022 00:07:22 - INFO - __main__ - Global step 1250 Train loss 0.21 Classification-F1 0.7796593384828678 on epoch=312
06/03/2022 00:07:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7792137056842939 -> 0.7796593384828678 on epoch=312, global_step=1250
06/03/2022 00:07:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.21 on epoch=314
06/03/2022 00:07:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.22 on epoch=317
06/03/2022 00:07:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=319
06/03/2022 00:07:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.23 on epoch=322
06/03/2022 00:07:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=324
06/03/2022 00:07:35 - INFO - __main__ - Global step 1300 Train loss 0.19 Classification-F1 0.7792137056842939 on epoch=324
06/03/2022 00:07:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.22 on epoch=327
06/03/2022 00:07:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.23 on epoch=329
06/03/2022 00:07:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=332
06/03/2022 00:07:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.17 on epoch=334
06/03/2022 00:07:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.19 on epoch=337
06/03/2022 00:07:48 - INFO - __main__ - Global step 1350 Train loss 0.20 Classification-F1 0.7935574871058743 on epoch=337
06/03/2022 00:07:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7796593384828678 -> 0.7935574871058743 on epoch=337, global_step=1350
06/03/2022 00:07:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.19 on epoch=339
06/03/2022 00:07:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.23 on epoch=342
06/03/2022 00:07:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=344
06/03/2022 00:07:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.16 on epoch=347
06/03/2022 00:08:00 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.19 on epoch=349
06/03/2022 00:08:01 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.7796593384828678 on epoch=349
06/03/2022 00:08:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.20 on epoch=352
06/03/2022 00:08:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.23 on epoch=354
06/03/2022 00:08:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.15 on epoch=357
06/03/2022 00:08:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=359
06/03/2022 00:08:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=362
06/03/2022 00:08:13 - INFO - __main__ - Global step 1450 Train loss 0.17 Classification-F1 0.7332280668677729 on epoch=362
06/03/2022 00:08:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.19 on epoch=364
06/03/2022 00:08:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.19 on epoch=367
06/03/2022 00:08:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.18 on epoch=369
06/03/2022 00:08:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.21 on epoch=372
06/03/2022 00:08:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=374
06/03/2022 00:08:26 - INFO - __main__ - Global step 1500 Train loss 0.18 Classification-F1 0.7790603696675803 on epoch=374
06/03/2022 00:08:29 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=377
06/03/2022 00:08:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=379
06/03/2022 00:08:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=382
06/03/2022 00:08:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.13 on epoch=384
06/03/2022 00:08:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.14 on epoch=387
06/03/2022 00:08:39 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.746606334841629 on epoch=387
06/03/2022 00:08:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.21 on epoch=389
06/03/2022 00:08:44 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=392
06/03/2022 00:08:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=394
06/03/2022 00:08:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.17 on epoch=397
06/03/2022 00:08:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=399
06/03/2022 00:08:52 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.7475718725718726 on epoch=399
06/03/2022 00:08:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=402
06/03/2022 00:08:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=404
06/03/2022 00:09:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=407
06/03/2022 00:09:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=409
06/03/2022 00:09:05 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.13 on epoch=412
06/03/2022 00:09:05 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.764447857996245 on epoch=412
06/03/2022 00:09:08 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=414
06/03/2022 00:09:10 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=417
06/03/2022 00:09:13 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=419
06/03/2022 00:09:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.14 on epoch=422
06/03/2022 00:09:18 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=424
06/03/2022 00:09:19 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.7476304945054946 on epoch=424
06/03/2022 00:09:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=427
06/03/2022 00:09:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.19 on epoch=429
06/03/2022 00:09:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.13 on epoch=432
06/03/2022 00:09:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=434
06/03/2022 00:09:31 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=437
06/03/2022 00:09:32 - INFO - __main__ - Global step 1750 Train loss 0.11 Classification-F1 0.7151515151515151 on epoch=437
06/03/2022 00:09:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=439
06/03/2022 00:09:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.14 on epoch=442
06/03/2022 00:09:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=444
06/03/2022 00:09:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=447
06/03/2022 00:09:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.14 on epoch=449
06/03/2022 00:09:45 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.7308377896613191 on epoch=449
06/03/2022 00:09:47 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=452
06/03/2022 00:09:50 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.12 on epoch=454
06/03/2022 00:09:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=457
06/03/2022 00:09:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=459
06/03/2022 00:09:57 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.18 on epoch=462
06/03/2022 00:09:58 - INFO - __main__ - Global step 1850 Train loss 0.10 Classification-F1 0.7460542929292928 on epoch=462
06/03/2022 00:10:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=464
06/03/2022 00:10:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=467
06/03/2022 00:10:05 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=469
06/03/2022 00:10:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=472
06/03/2022 00:10:10 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.14 on epoch=474
06/03/2022 00:10:11 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.7455678200459984 on epoch=474
06/03/2022 00:10:13 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=477
06/03/2022 00:10:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=479
06/03/2022 00:10:18 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=482
06/03/2022 00:10:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.12 on epoch=484
06/03/2022 00:10:23 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=487
06/03/2022 00:10:24 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.7464349376114082 on epoch=487
06/03/2022 00:10:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.12 on epoch=489
06/03/2022 00:10:28 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=492
06/03/2022 00:10:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=494
06/03/2022 00:10:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=497
06/03/2022 00:10:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=499
06/03/2022 00:10:37 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.7176908263305323 on epoch=499
06/03/2022 00:10:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=502
06/03/2022 00:10:42 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=504
06/03/2022 00:10:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=507
06/03/2022 00:10:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=509
06/03/2022 00:10:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=512
06/03/2022 00:10:50 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.7320346320346319 on epoch=512
06/03/2022 00:10:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.14 on epoch=514
06/03/2022 00:10:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=517
06/03/2022 00:10:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=519
06/03/2022 00:11:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=522
06/03/2022 00:11:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=524
06/03/2022 00:11:03 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.7303921568627451 on epoch=524
06/03/2022 00:11:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/03/2022 00:11:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=529
06/03/2022 00:11:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=532
06/03/2022 00:11:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.11 on epoch=534
06/03/2022 00:11:16 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/03/2022 00:11:17 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7299558080808081 on epoch=537
06/03/2022 00:11:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=539
06/03/2022 00:11:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=542
06/03/2022 00:11:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=544
06/03/2022 00:11:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=547
06/03/2022 00:11:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=549
06/03/2022 00:11:30 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.7320346320346319 on epoch=549
06/03/2022 00:11:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=552
06/03/2022 00:11:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=554
06/03/2022 00:11:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=557
06/03/2022 00:11:40 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=559
06/03/2022 00:11:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=562
06/03/2022 00:11:43 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.7464349376114082 on epoch=562
06/03/2022 00:11:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=564
06/03/2022 00:11:48 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=567
06/03/2022 00:11:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.10 on epoch=569
06/03/2022 00:11:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=572
06/03/2022 00:11:56 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=574
06/03/2022 00:11:57 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.7444240196078431 on epoch=574
06/03/2022 00:11:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/03/2022 00:12:02 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=579
06/03/2022 00:12:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=582
06/03/2022 00:12:07 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/03/2022 00:12:09 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=587
06/03/2022 00:12:10 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7297181372549019 on epoch=587
06/03/2022 00:12:13 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=589
06/03/2022 00:12:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/03/2022 00:12:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/03/2022 00:12:20 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.12 on epoch=597
06/03/2022 00:12:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=599
06/03/2022 00:12:24 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.7351352948127141 on epoch=599
06/03/2022 00:12:26 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=602
06/03/2022 00:12:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/03/2022 00:12:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=607
06/03/2022 00:12:34 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=609
06/03/2022 00:12:36 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=612
06/03/2022 00:12:37 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.7172706582633053 on epoch=612
06/03/2022 00:12:40 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=614
06/03/2022 00:12:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=617
06/03/2022 00:12:44 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=619
06/03/2022 00:12:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=622
06/03/2022 00:12:49 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/03/2022 00:12:50 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7460542929292928 on epoch=624
06/03/2022 00:12:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=627
06/03/2022 00:12:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=629
06/03/2022 00:12:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/03/2022 00:13:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=634
06/03/2022 00:13:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=637
06/03/2022 00:13:04 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7333447802197802 on epoch=637
06/03/2022 00:13:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=639
06/03/2022 00:13:09 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
06/03/2022 00:13:11 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=644
06/03/2022 00:13:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/03/2022 00:13:16 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/03/2022 00:13:17 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7480217086834734 on epoch=649
06/03/2022 00:13:20 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/03/2022 00:13:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=654
06/03/2022 00:13:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=657
06/03/2022 00:13:27 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/03/2022 00:13:30 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=662
06/03/2022 00:13:31 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7606060606060605 on epoch=662
06/03/2022 00:13:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=664
06/03/2022 00:13:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=667
06/03/2022 00:13:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=669
06/03/2022 00:13:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/03/2022 00:13:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=674
06/03/2022 00:13:44 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.7178571428571429 on epoch=674
06/03/2022 00:13:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/03/2022 00:13:49 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=679
06/03/2022 00:13:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/03/2022 00:13:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=684
06/03/2022 00:13:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=687
06/03/2022 00:13:57 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7178571428571429 on epoch=687
06/03/2022 00:13:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=689
06/03/2022 00:14:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=692
06/03/2022 00:14:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/03/2022 00:14:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/03/2022 00:14:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/03/2022 00:14:10 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7329967470859311 on epoch=699
06/03/2022 00:14:13 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=702
06/03/2022 00:14:15 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/03/2022 00:14:18 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=707
06/03/2022 00:14:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=709
06/03/2022 00:14:23 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/03/2022 00:14:24 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7606060606060605 on epoch=712
06/03/2022 00:14:26 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=714
06/03/2022 00:14:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/03/2022 00:14:31 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=719
06/03/2022 00:14:33 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.09 on epoch=722
06/03/2022 00:14:36 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=724
06/03/2022 00:14:37 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7496700603318249 on epoch=724
06/03/2022 00:14:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=727
06/03/2022 00:14:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/03/2022 00:14:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=732
06/03/2022 00:14:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=734
06/03/2022 00:14:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=737
06/03/2022 00:14:50 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.7335174629292276 on epoch=737
06/03/2022 00:14:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
06/03/2022 00:14:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=742
06/03/2022 00:14:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/03/2022 00:15:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=747
06/03/2022 00:15:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=749
06/03/2022 00:15:03 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7444240196078431 on epoch=749
06/03/2022 00:15:03 - INFO - __main__ - save last model!
06/03/2022 00:15:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/03/2022 00:15:03 - INFO - __main__ - Start tokenizing ... 5509 instances
06/03/2022 00:15:03 - INFO - __main__ - Printing 3 examples
06/03/2022 00:15:03 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/03/2022 00:15:03 - INFO - __main__ - ['others']
06/03/2022 00:15:03 - INFO - __main__ -  [emo] what you like very little things ok
06/03/2022 00:15:03 - INFO - __main__ - ['others']
06/03/2022 00:15:03 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/03/2022 00:15:03 - INFO - __main__ - ['others']
06/03/2022 00:15:03 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:15:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:15:03 - INFO - __main__ - Printing 3 examples
06/03/2022 00:15:03 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/03/2022 00:15:03 - INFO - __main__ - ['others']
06/03/2022 00:15:03 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/03/2022 00:15:03 - INFO - __main__ - ['others']
06/03/2022 00:15:03 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/03/2022 00:15:03 - INFO - __main__ - ['others']
06/03/2022 00:15:03 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:15:04 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:15:04 - INFO - __main__ - Loaded 64 examples from train data
06/03/2022 00:15:04 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:15:04 - INFO - __main__ - Printing 3 examples
06/03/2022 00:15:04 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/03/2022 00:15:04 - INFO - __main__ - ['others']
06/03/2022 00:15:04 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/03/2022 00:15:04 - INFO - __main__ - ['others']
06/03/2022 00:15:04 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/03/2022 00:15:04 - INFO - __main__ - ['others']
06/03/2022 00:15:04 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:15:04 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:15:04 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 00:15:06 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:15:11 - INFO - __main__ - Loaded 5509 examples from test data
06/03/2022 00:15:19 - INFO - __main__ - load prompt embedding from ckpt
06/03/2022 00:15:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/03/2022 00:15:20 - INFO - __main__ - Starting training!
06/03/2022 00:16:46 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_42_0.2_8_predictions.txt
06/03/2022 00:16:46 - INFO - __main__ - Classification-F1 on test data: 0.2479
06/03/2022 00:16:46 - INFO - __main__ - prefix=emo_16_42, lr=0.2, bsz=8, dev_performance=0.7935574871058743, test_performance=0.2479149340304996
06/03/2022 00:16:46 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.5, bsz=8 ...
06/03/2022 00:16:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:16:47 - INFO - __main__ - Printing 3 examples
06/03/2022 00:16:47 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/03/2022 00:16:47 - INFO - __main__ - ['others']
06/03/2022 00:16:47 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/03/2022 00:16:47 - INFO - __main__ - ['others']
06/03/2022 00:16:47 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/03/2022 00:16:47 - INFO - __main__ - ['others']
06/03/2022 00:16:47 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:16:47 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:16:47 - INFO - __main__ - Loaded 64 examples from train data
06/03/2022 00:16:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:16:47 - INFO - __main__ - Printing 3 examples
06/03/2022 00:16:47 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/03/2022 00:16:47 - INFO - __main__ - ['others']
06/03/2022 00:16:47 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/03/2022 00:16:47 - INFO - __main__ - ['others']
06/03/2022 00:16:47 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/03/2022 00:16:47 - INFO - __main__ - ['others']
06/03/2022 00:16:47 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:16:47 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:16:47 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 00:17:02 - INFO - __main__ - load prompt embedding from ckpt
06/03/2022 00:17:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/03/2022 00:17:03 - INFO - __main__ - Starting training!
06/03/2022 00:17:05 - INFO - __main__ - Step 10 Global step 10 Train loss 3.63 on epoch=2
06/03/2022 00:17:08 - INFO - __main__ - Step 20 Global step 20 Train loss 2.55 on epoch=4
06/03/2022 00:17:10 - INFO - __main__ - Step 30 Global step 30 Train loss 1.93 on epoch=7
06/03/2022 00:17:13 - INFO - __main__ - Step 40 Global step 40 Train loss 1.59 on epoch=9
06/03/2022 00:17:15 - INFO - __main__ - Step 50 Global step 50 Train loss 1.42 on epoch=12
06/03/2022 00:17:16 - INFO - __main__ - Global step 50 Train loss 2.22 Classification-F1 0.14623285211520504 on epoch=12
06/03/2022 00:17:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.14623285211520504 on epoch=12, global_step=50
06/03/2022 00:17:19 - INFO - __main__ - Step 60 Global step 60 Train loss 0.98 on epoch=14
06/03/2022 00:17:21 - INFO - __main__ - Step 70 Global step 70 Train loss 1.01 on epoch=17
06/03/2022 00:17:23 - INFO - __main__ - Step 80 Global step 80 Train loss 0.82 on epoch=19
06/03/2022 00:17:26 - INFO - __main__ - Step 90 Global step 90 Train loss 0.82 on epoch=22
06/03/2022 00:17:28 - INFO - __main__ - Step 100 Global step 100 Train loss 0.72 on epoch=24
06/03/2022 00:17:29 - INFO - __main__ - Global step 100 Train loss 0.87 Classification-F1 0.49094120406783404 on epoch=24
06/03/2022 00:17:29 - INFO - __main__ - Saving model with best Classification-F1: 0.14623285211520504 -> 0.49094120406783404 on epoch=24, global_step=100
06/03/2022 00:17:31 - INFO - __main__ - Step 110 Global step 110 Train loss 0.80 on epoch=27
06/03/2022 00:17:34 - INFO - __main__ - Step 120 Global step 120 Train loss 0.72 on epoch=29
06/03/2022 00:17:36 - INFO - __main__ - Step 130 Global step 130 Train loss 0.61 on epoch=32
06/03/2022 00:17:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.62 on epoch=34
06/03/2022 00:17:41 - INFO - __main__ - Step 150 Global step 150 Train loss 0.67 on epoch=37
06/03/2022 00:17:42 - INFO - __main__ - Global step 150 Train loss 0.68 Classification-F1 0.6031497035573122 on epoch=37
06/03/2022 00:17:42 - INFO - __main__ - Saving model with best Classification-F1: 0.49094120406783404 -> 0.6031497035573122 on epoch=37, global_step=150
06/03/2022 00:17:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.56 on epoch=39
06/03/2022 00:17:47 - INFO - __main__ - Step 170 Global step 170 Train loss 0.58 on epoch=42
06/03/2022 00:17:49 - INFO - __main__ - Step 180 Global step 180 Train loss 0.57 on epoch=44
06/03/2022 00:17:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.51 on epoch=47
06/03/2022 00:17:54 - INFO - __main__ - Step 200 Global step 200 Train loss 0.58 on epoch=49
06/03/2022 00:17:55 - INFO - __main__ - Global step 200 Train loss 0.56 Classification-F1 0.5444240196078431 on epoch=49
06/03/2022 00:17:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.51 on epoch=52
06/03/2022 00:17:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=54
06/03/2022 00:18:02 - INFO - __main__ - Step 230 Global step 230 Train loss 0.54 on epoch=57
06/03/2022 00:18:04 - INFO - __main__ - Step 240 Global step 240 Train loss 0.43 on epoch=59
06/03/2022 00:18:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=62
06/03/2022 00:18:07 - INFO - __main__ - Global step 250 Train loss 0.49 Classification-F1 0.6408386327503974 on epoch=62
06/03/2022 00:18:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6031497035573122 -> 0.6408386327503974 on epoch=62, global_step=250
06/03/2022 00:18:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.52 on epoch=64
06/03/2022 00:18:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.37 on epoch=67
06/03/2022 00:18:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.40 on epoch=69
06/03/2022 00:18:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.40 on epoch=72
06/03/2022 00:18:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.39 on epoch=74
06/03/2022 00:18:20 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.65566534914361 on epoch=74
06/03/2022 00:18:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6408386327503974 -> 0.65566534914361 on epoch=74, global_step=300
06/03/2022 00:18:23 - INFO - __main__ - Step 310 Global step 310 Train loss 0.35 on epoch=77
06/03/2022 00:18:25 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=79
06/03/2022 00:18:27 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=82
06/03/2022 00:18:30 - INFO - __main__ - Step 340 Global step 340 Train loss 0.33 on epoch=84
06/03/2022 00:18:32 - INFO - __main__ - Step 350 Global step 350 Train loss 0.43 on epoch=87
06/03/2022 00:18:33 - INFO - __main__ - Global step 350 Train loss 0.37 Classification-F1 0.6463744588744589 on epoch=87
06/03/2022 00:18:35 - INFO - __main__ - Step 360 Global step 360 Train loss 0.38 on epoch=89
06/03/2022 00:18:38 - INFO - __main__ - Step 370 Global step 370 Train loss 0.32 on epoch=92
06/03/2022 00:18:40 - INFO - __main__ - Step 380 Global step 380 Train loss 0.30 on epoch=94
06/03/2022 00:18:42 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=97
06/03/2022 00:18:45 - INFO - __main__ - Step 400 Global step 400 Train loss 0.31 on epoch=99
06/03/2022 00:18:46 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.6184932953225637 on epoch=99
06/03/2022 00:18:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=102
06/03/2022 00:18:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=104
06/03/2022 00:18:53 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=107
06/03/2022 00:18:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.26 on epoch=109
06/03/2022 00:18:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/03/2022 00:18:58 - INFO - __main__ - Global step 450 Train loss 0.26 Classification-F1 0.6194646516070129 on epoch=112
06/03/2022 00:19:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=114
06/03/2022 00:19:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=117
06/03/2022 00:19:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=119
06/03/2022 00:19:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=122
06/03/2022 00:19:10 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=124
06/03/2022 00:19:11 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.6291034431081638 on epoch=124
06/03/2022 00:19:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=127
06/03/2022 00:19:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=129
06/03/2022 00:19:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=132
06/03/2022 00:19:20 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=134
06/03/2022 00:19:23 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
06/03/2022 00:19:24 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.638645071403692 on epoch=137
06/03/2022 00:19:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=139
06/03/2022 00:19:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.15 on epoch=142
06/03/2022 00:19:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/03/2022 00:19:33 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=147
06/03/2022 00:19:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=149
06/03/2022 00:19:37 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.6550438596491228 on epoch=149
06/03/2022 00:19:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
06/03/2022 00:19:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=154
06/03/2022 00:19:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=157
06/03/2022 00:19:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=159
06/03/2022 00:19:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=162
06/03/2022 00:19:49 - INFO - __main__ - Global step 650 Train loss 0.16 Classification-F1 0.6427606177606178 on epoch=162
06/03/2022 00:19:51 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=164
06/03/2022 00:19:54 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
06/03/2022 00:19:56 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=169
06/03/2022 00:19:59 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=172
06/03/2022 00:20:01 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=174
06/03/2022 00:20:02 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.6377231941471256 on epoch=174
06/03/2022 00:20:04 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=177
06/03/2022 00:20:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=179
06/03/2022 00:20:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=182
06/03/2022 00:20:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=184
06/03/2022 00:20:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=187
06/03/2022 00:20:15 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.6417050691244239 on epoch=187
06/03/2022 00:20:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=189
06/03/2022 00:20:19 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=192
06/03/2022 00:20:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=194
06/03/2022 00:20:24 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=197
06/03/2022 00:20:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
06/03/2022 00:20:27 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.6685703185703185 on epoch=199
06/03/2022 00:20:27 - INFO - __main__ - Saving model with best Classification-F1: 0.65566534914361 -> 0.6685703185703185 on epoch=199, global_step=800
06/03/2022 00:20:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=202
06/03/2022 00:20:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=204
06/03/2022 00:20:34 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=207
06/03/2022 00:20:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=209
06/03/2022 00:20:39 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
06/03/2022 00:20:40 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.6685703185703185 on epoch=212
06/03/2022 00:20:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/03/2022 00:20:45 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=217
06/03/2022 00:20:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=219
06/03/2022 00:20:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=222
06/03/2022 00:20:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=224
06/03/2022 00:20:53 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.6996670029444813 on epoch=224
06/03/2022 00:20:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6685703185703185 -> 0.6996670029444813 on epoch=224, global_step=900
06/03/2022 00:20:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=227
06/03/2022 00:20:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=229
06/03/2022 00:21:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=232
06/03/2022 00:21:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=234
06/03/2022 00:21:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=237
06/03/2022 00:21:05 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.6532242769084875 on epoch=237
06/03/2022 00:21:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=239
06/03/2022 00:21:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/03/2022 00:21:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=244
06/03/2022 00:21:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=247
06/03/2022 00:21:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=249
06/03/2022 00:21:18 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.6533718814968815 on epoch=249
06/03/2022 00:21:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=252
06/03/2022 00:21:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/03/2022 00:21:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/03/2022 00:21:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=259
06/03/2022 00:21:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
06/03/2022 00:21:30 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.6666118421052631 on epoch=262
06/03/2022 00:21:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=264
06/03/2022 00:21:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/03/2022 00:21:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
06/03/2022 00:21:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/03/2022 00:21:42 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/03/2022 00:21:43 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.6398809523809523 on epoch=274
06/03/2022 00:21:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
06/03/2022 00:21:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=279
06/03/2022 00:21:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/03/2022 00:21:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=284
06/03/2022 00:21:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=287
06/03/2022 00:21:56 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.6504010695187166 on epoch=287
06/03/2022 00:21:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=289
06/03/2022 00:22:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/03/2022 00:22:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=294
06/03/2022 00:22:05 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/03/2022 00:22:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/03/2022 00:22:08 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.6721014492753623 on epoch=299
06/03/2022 00:22:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/03/2022 00:22:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=304
06/03/2022 00:22:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/03/2022 00:22:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/03/2022 00:22:20 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=312
06/03/2022 00:22:21 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.6652236652236652 on epoch=312
06/03/2022 00:22:23 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/03/2022 00:22:26 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/03/2022 00:22:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
06/03/2022 00:22:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/03/2022 00:22:33 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=324
06/03/2022 00:22:34 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7206211092246746 on epoch=324
06/03/2022 00:22:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6996670029444813 -> 0.7206211092246746 on epoch=324, global_step=1300
06/03/2022 00:22:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/03/2022 00:22:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/03/2022 00:22:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=332
06/03/2022 00:22:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/03/2022 00:22:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/03/2022 00:22:47 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.6545112781954887 on epoch=337
06/03/2022 00:22:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=339
06/03/2022 00:22:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/03/2022 00:22:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/03/2022 00:22:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=347
06/03/2022 00:22:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/03/2022 00:22:59 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.654862278546489 on epoch=349
06/03/2022 00:23:02 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/03/2022 00:23:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/03/2022 00:23:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/03/2022 00:23:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/03/2022 00:23:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
06/03/2022 00:23:12 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.6926653544300604 on epoch=362
06/03/2022 00:23:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/03/2022 00:23:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/03/2022 00:23:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/03/2022 00:23:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/03/2022 00:23:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=374
06/03/2022 00:23:25 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7126503126503126 on epoch=374
06/03/2022 00:23:27 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/03/2022 00:23:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/03/2022 00:23:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=382
06/03/2022 00:23:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/03/2022 00:23:37 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/03/2022 00:23:37 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.6926653544300604 on epoch=387
06/03/2022 00:23:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/03/2022 00:23:42 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/03/2022 00:23:44 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/03/2022 00:23:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/03/2022 00:23:49 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/03/2022 00:23:50 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.6909937428029533 on epoch=399
06/03/2022 00:23:52 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/03/2022 00:23:55 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/03/2022 00:23:57 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/03/2022 00:24:00 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/03/2022 00:24:02 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/03/2022 00:24:03 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7021668087524864 on epoch=412
06/03/2022 00:24:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/03/2022 00:24:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/03/2022 00:24:10 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/03/2022 00:24:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/03/2022 00:24:15 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/03/2022 00:24:15 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.6789958407605466 on epoch=424
06/03/2022 00:24:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/03/2022 00:24:20 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/03/2022 00:24:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/03/2022 00:24:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/03/2022 00:24:27 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=437
06/03/2022 00:24:28 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.6803508053508054 on epoch=437
06/03/2022 00:24:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/03/2022 00:24:33 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/03/2022 00:24:35 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/03/2022 00:24:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/03/2022 00:24:40 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/03/2022 00:24:41 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6773242291334396 on epoch=449
06/03/2022 00:24:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/03/2022 00:24:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/03/2022 00:24:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/03/2022 00:24:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/03/2022 00:24:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/03/2022 00:24:53 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6773242291334396 on epoch=462
06/03/2022 00:24:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/03/2022 00:24:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/03/2022 00:25:00 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/03/2022 00:25:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/03/2022 00:25:05 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=474
06/03/2022 00:25:06 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6909937428029533 on epoch=474
06/03/2022 00:25:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/03/2022 00:25:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=479
06/03/2022 00:25:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/03/2022 00:25:15 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/03/2022 00:25:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/03/2022 00:25:19 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.6859434162423292 on epoch=487
06/03/2022 00:25:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/03/2022 00:25:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/03/2022 00:25:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/03/2022 00:25:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/03/2022 00:25:30 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/03/2022 00:25:31 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7591129591129591 on epoch=499
06/03/2022 00:25:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7206211092246746 -> 0.7591129591129591 on epoch=499, global_step=2000
06/03/2022 00:25:34 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/03/2022 00:25:36 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=504
06/03/2022 00:25:39 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/03/2022 00:25:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/03/2022 00:25:43 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/03/2022 00:25:44 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7003257261838498 on epoch=512
06/03/2022 00:25:47 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=514
06/03/2022 00:25:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=517
06/03/2022 00:25:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/03/2022 00:25:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/03/2022 00:25:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=524
06/03/2022 00:25:57 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.6909937428029533 on epoch=524
06/03/2022 00:25:59 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/03/2022 00:26:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/03/2022 00:26:04 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/03/2022 00:26:06 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/03/2022 00:26:09 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/03/2022 00:26:10 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6776133287168941 on epoch=537
06/03/2022 00:26:12 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/03/2022 00:26:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.12 on epoch=542
06/03/2022 00:26:17 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/03/2022 00:26:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/03/2022 00:26:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/03/2022 00:26:22 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6997460293392971 on epoch=549
06/03/2022 00:26:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/03/2022 00:26:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=554
06/03/2022 00:26:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/03/2022 00:26:32 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/03/2022 00:26:34 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=562
06/03/2022 00:26:35 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7014421536160665 on epoch=562
06/03/2022 00:26:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=564
06/03/2022 00:26:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/03/2022 00:26:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=569
06/03/2022 00:26:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/03/2022 00:26:47 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/03/2022 00:26:48 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.74585326953748 on epoch=574
06/03/2022 00:26:50 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=577
06/03/2022 00:26:53 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/03/2022 00:26:55 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/03/2022 00:26:57 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/03/2022 00:27:00 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/03/2022 00:27:01 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.679088179088179 on epoch=587
06/03/2022 00:27:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/03/2022 00:27:06 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/03/2022 00:27:08 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
06/03/2022 00:27:10 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/03/2022 00:27:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/03/2022 00:27:14 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6776133287168941 on epoch=599
06/03/2022 00:27:16 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/03/2022 00:27:19 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/03/2022 00:27:21 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/03/2022 00:27:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/03/2022 00:27:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/03/2022 00:27:27 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6931734931734931 on epoch=612
06/03/2022 00:27:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=614
06/03/2022 00:27:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/03/2022 00:27:34 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/03/2022 00:27:36 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=622
06/03/2022 00:27:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/03/2022 00:27:40 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7269854891558745 on epoch=624
06/03/2022 00:27:42 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/03/2022 00:27:44 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/03/2022 00:27:47 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=632
06/03/2022 00:27:49 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/03/2022 00:27:52 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=637
06/03/2022 00:27:53 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7087302292894397 on epoch=637
06/03/2022 00:27:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/03/2022 00:27:57 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/03/2022 00:28:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/03/2022 00:28:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/03/2022 00:28:04 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/03/2022 00:28:05 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.6774032555282555 on epoch=649
06/03/2022 00:28:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/03/2022 00:28:10 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/03/2022 00:28:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/03/2022 00:28:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=659
06/03/2022 00:28:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/03/2022 00:28:19 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6997460293392971 on epoch=662
06/03/2022 00:28:21 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/03/2022 00:28:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/03/2022 00:28:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/03/2022 00:28:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/03/2022 00:28:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/03/2022 00:28:32 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7014421536160665 on epoch=674
06/03/2022 00:28:34 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/03/2022 00:28:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/03/2022 00:28:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/03/2022 00:28:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=684
06/03/2022 00:28:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/03/2022 00:28:45 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6997460293392971 on epoch=687
06/03/2022 00:28:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/03/2022 00:28:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/03/2022 00:28:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/03/2022 00:28:54 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/03/2022 00:28:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=699
06/03/2022 00:28:58 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7000515018607123 on epoch=699
06/03/2022 00:29:00 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/03/2022 00:29:02 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/03/2022 00:29:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=707
06/03/2022 00:29:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.09 on epoch=709
06/03/2022 00:29:09 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/03/2022 00:29:11 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7355783701321459 on epoch=712
06/03/2022 00:29:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/03/2022 00:29:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/03/2022 00:29:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/03/2022 00:29:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/03/2022 00:29:22 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/03/2022 00:29:24 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7020343994669331 on epoch=724
06/03/2022 00:29:26 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/03/2022 00:29:28 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=729
06/03/2022 00:29:31 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/03/2022 00:29:33 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/03/2022 00:29:35 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/03/2022 00:29:36 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7212601256718904 on epoch=737
06/03/2022 00:29:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/03/2022 00:29:41 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/03/2022 00:29:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/03/2022 00:29:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/03/2022 00:29:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/03/2022 00:29:49 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7456319956319957 on epoch=749
06/03/2022 00:29:49 - INFO - __main__ - save last model!
06/03/2022 00:29:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/03/2022 00:29:49 - INFO - __main__ - Start tokenizing ... 5509 instances
06/03/2022 00:29:49 - INFO - __main__ - Printing 3 examples
06/03/2022 00:29:49 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/03/2022 00:29:49 - INFO - __main__ - ['others']
06/03/2022 00:29:49 - INFO - __main__ -  [emo] what you like very little things ok
06/03/2022 00:29:49 - INFO - __main__ - ['others']
06/03/2022 00:29:49 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/03/2022 00:29:49 - INFO - __main__ - ['others']
06/03/2022 00:29:49 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:29:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:29:50 - INFO - __main__ - Printing 3 examples
06/03/2022 00:29:50 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/03/2022 00:29:50 - INFO - __main__ - ['others']
06/03/2022 00:29:50 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/03/2022 00:29:50 - INFO - __main__ - ['others']
06/03/2022 00:29:50 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/03/2022 00:29:50 - INFO - __main__ - ['others']
06/03/2022 00:29:50 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:29:50 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:29:50 - INFO - __main__ - Loaded 64 examples from train data
06/03/2022 00:29:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:29:50 - INFO - __main__ - Printing 3 examples
06/03/2022 00:29:50 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/03/2022 00:29:50 - INFO - __main__ - ['others']
06/03/2022 00:29:50 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/03/2022 00:29:50 - INFO - __main__ - ['others']
06/03/2022 00:29:50 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/03/2022 00:29:50 - INFO - __main__ - ['others']
06/03/2022 00:29:50 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:29:50 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:29:50 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 00:29:52 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:29:57 - INFO - __main__ - Loaded 5509 examples from test data
06/03/2022 00:30:08 - INFO - __main__ - load prompt embedding from ckpt
06/03/2022 00:30:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/03/2022 00:30:09 - INFO - __main__ - Starting training!
06/03/2022 00:31:29 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_87_0.5_8_predictions.txt
06/03/2022 00:31:29 - INFO - __main__ - Classification-F1 on test data: 0.3300
06/03/2022 00:31:29 - INFO - __main__ - prefix=emo_16_87, lr=0.5, bsz=8, dev_performance=0.7591129591129591, test_performance=0.33000044904336323
06/03/2022 00:31:29 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.4, bsz=8 ...
06/03/2022 00:31:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:31:30 - INFO - __main__ - Printing 3 examples
06/03/2022 00:31:30 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/03/2022 00:31:30 - INFO - __main__ - ['others']
06/03/2022 00:31:30 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/03/2022 00:31:30 - INFO - __main__ - ['others']
06/03/2022 00:31:30 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/03/2022 00:31:30 - INFO - __main__ - ['others']
06/03/2022 00:31:30 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:31:30 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:31:30 - INFO - __main__ - Loaded 64 examples from train data
06/03/2022 00:31:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:31:30 - INFO - __main__ - Printing 3 examples
06/03/2022 00:31:30 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/03/2022 00:31:30 - INFO - __main__ - ['others']
06/03/2022 00:31:30 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/03/2022 00:31:30 - INFO - __main__ - ['others']
06/03/2022 00:31:30 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/03/2022 00:31:30 - INFO - __main__ - ['others']
06/03/2022 00:31:30 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:31:30 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:31:30 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 00:31:49 - INFO - __main__ - load prompt embedding from ckpt
06/03/2022 00:31:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/03/2022 00:31:50 - INFO - __main__ - Starting training!
06/03/2022 00:31:52 - INFO - __main__ - Step 10 Global step 10 Train loss 4.06 on epoch=2
06/03/2022 00:31:55 - INFO - __main__ - Step 20 Global step 20 Train loss 3.00 on epoch=4
06/03/2022 00:31:57 - INFO - __main__ - Step 30 Global step 30 Train loss 2.34 on epoch=7
06/03/2022 00:32:00 - INFO - __main__ - Step 40 Global step 40 Train loss 1.94 on epoch=9
06/03/2022 00:32:02 - INFO - __main__ - Step 50 Global step 50 Train loss 1.56 on epoch=12
06/03/2022 00:32:03 - INFO - __main__ - Global step 50 Train loss 2.58 Classification-F1 0.07127659574468086 on epoch=12
06/03/2022 00:32:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07127659574468086 on epoch=12, global_step=50
06/03/2022 00:32:06 - INFO - __main__ - Step 60 Global step 60 Train loss 1.28 on epoch=14
06/03/2022 00:32:08 - INFO - __main__ - Step 70 Global step 70 Train loss 1.27 on epoch=17
06/03/2022 00:32:10 - INFO - __main__ - Step 80 Global step 80 Train loss 1.02 on epoch=19
06/03/2022 00:32:13 - INFO - __main__ - Step 90 Global step 90 Train loss 1.09 on epoch=22
06/03/2022 00:32:15 - INFO - __main__ - Step 100 Global step 100 Train loss 0.92 on epoch=24
06/03/2022 00:32:16 - INFO - __main__ - Global step 100 Train loss 1.12 Classification-F1 0.469080459770115 on epoch=24
06/03/2022 00:32:16 - INFO - __main__ - Saving model with best Classification-F1: 0.07127659574468086 -> 0.469080459770115 on epoch=24, global_step=100
06/03/2022 00:32:19 - INFO - __main__ - Step 110 Global step 110 Train loss 0.87 on epoch=27
06/03/2022 00:32:21 - INFO - __main__ - Step 120 Global step 120 Train loss 0.77 on epoch=29
06/03/2022 00:32:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.79 on epoch=32
06/03/2022 00:32:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.69 on epoch=34
06/03/2022 00:32:28 - INFO - __main__ - Step 150 Global step 150 Train loss 0.54 on epoch=37
06/03/2022 00:32:29 - INFO - __main__ - Global step 150 Train loss 0.73 Classification-F1 0.6172077650405823 on epoch=37
06/03/2022 00:32:29 - INFO - __main__ - Saving model with best Classification-F1: 0.469080459770115 -> 0.6172077650405823 on epoch=37, global_step=150
06/03/2022 00:32:32 - INFO - __main__ - Step 160 Global step 160 Train loss 0.60 on epoch=39
06/03/2022 00:32:34 - INFO - __main__ - Step 170 Global step 170 Train loss 0.67 on epoch=42
06/03/2022 00:32:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=44
06/03/2022 00:32:39 - INFO - __main__ - Step 190 Global step 190 Train loss 0.55 on epoch=47
06/03/2022 00:32:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=49
06/03/2022 00:32:42 - INFO - __main__ - Global step 200 Train loss 0.59 Classification-F1 0.5766350232834501 on epoch=49
06/03/2022 00:32:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.62 on epoch=52
06/03/2022 00:32:47 - INFO - __main__ - Step 220 Global step 220 Train loss 0.57 on epoch=54
06/03/2022 00:32:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.50 on epoch=57
06/03/2022 00:32:52 - INFO - __main__ - Step 240 Global step 240 Train loss 0.63 on epoch=59
06/03/2022 00:32:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.52 on epoch=62
06/03/2022 00:32:56 - INFO - __main__ - Global step 250 Train loss 0.57 Classification-F1 0.6051313628899836 on epoch=62
06/03/2022 00:32:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.57 on epoch=64
06/03/2022 00:33:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.57 on epoch=67
06/03/2022 00:33:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.56 on epoch=69
06/03/2022 00:33:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.46 on epoch=72
06/03/2022 00:33:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=74
06/03/2022 00:33:09 - INFO - __main__ - Global step 300 Train loss 0.52 Classification-F1 0.5253957396912252 on epoch=74
06/03/2022 00:33:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.42 on epoch=77
06/03/2022 00:33:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=79
06/03/2022 00:33:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.46 on epoch=82
06/03/2022 00:33:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.47 on epoch=84
06/03/2022 00:33:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=87
06/03/2022 00:33:22 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.5611145271116578 on epoch=87
06/03/2022 00:33:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.46 on epoch=89
06/03/2022 00:33:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=92
06/03/2022 00:33:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=94
06/03/2022 00:33:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=97
06/03/2022 00:33:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=99
06/03/2022 00:33:35 - INFO - __main__ - Global step 400 Train loss 0.38 Classification-F1 0.6060472689484243 on epoch=99
06/03/2022 00:33:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.39 on epoch=102
06/03/2022 00:33:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=104
06/03/2022 00:33:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.36 on epoch=107
06/03/2022 00:33:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=109
06/03/2022 00:33:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=112
06/03/2022 00:33:48 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.6081375313283208 on epoch=112
06/03/2022 00:33:50 - INFO - __main__ - Step 460 Global step 460 Train loss 0.33 on epoch=114
06/03/2022 00:33:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=117
06/03/2022 00:33:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=119
06/03/2022 00:33:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=122
06/03/2022 00:34:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=124
06/03/2022 00:34:01 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.6326839826839827 on epoch=124
06/03/2022 00:34:01 - INFO - __main__ - Saving model with best Classification-F1: 0.6172077650405823 -> 0.6326839826839827 on epoch=124, global_step=500
06/03/2022 00:34:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=127
06/03/2022 00:34:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=129
06/03/2022 00:34:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=132
06/03/2022 00:34:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=134
06/03/2022 00:34:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=137
06/03/2022 00:34:14 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.6464150432900433 on epoch=137
06/03/2022 00:34:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6326839826839827 -> 0.6464150432900433 on epoch=137, global_step=550
06/03/2022 00:34:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=139
06/03/2022 00:34:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=142
06/03/2022 00:34:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=144
06/03/2022 00:34:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=147
06/03/2022 00:34:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=149
06/03/2022 00:34:27 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.6432327476445123 on epoch=149
06/03/2022 00:34:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=152
06/03/2022 00:34:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/03/2022 00:34:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=157
06/03/2022 00:34:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=159
06/03/2022 00:34:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=162
06/03/2022 00:34:40 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.603320993031359 on epoch=162
06/03/2022 00:34:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=164
06/03/2022 00:34:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=167
06/03/2022 00:34:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=169
06/03/2022 00:34:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=172
06/03/2022 00:34:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=174
06/03/2022 00:34:54 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.603320993031359 on epoch=174
06/03/2022 00:34:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=177
06/03/2022 00:34:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=179
06/03/2022 00:35:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=182
06/03/2022 00:35:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=184
06/03/2022 00:35:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=187
06/03/2022 00:35:07 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.6456649645504134 on epoch=187
06/03/2022 00:35:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=189
06/03/2022 00:35:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=192
06/03/2022 00:35:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=194
06/03/2022 00:35:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=197
06/03/2022 00:35:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=199
06/03/2022 00:35:20 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.6165278060014903 on epoch=199
06/03/2022 00:35:23 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=202
06/03/2022 00:35:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=204
06/03/2022 00:35:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=207
06/03/2022 00:35:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=209
06/03/2022 00:35:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=212
06/03/2022 00:35:33 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.6305134493988983 on epoch=212
06/03/2022 00:35:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=214
06/03/2022 00:35:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=217
06/03/2022 00:35:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=219
06/03/2022 00:35:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=222
06/03/2022 00:35:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
06/03/2022 00:35:47 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.6661181955299602 on epoch=224
06/03/2022 00:35:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6464150432900433 -> 0.6661181955299602 on epoch=224, global_step=900
06/03/2022 00:35:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=227
06/03/2022 00:35:52 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=229
06/03/2022 00:35:54 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=232
06/03/2022 00:35:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
06/03/2022 00:35:59 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=237
06/03/2022 00:36:00 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.6135416666666667 on epoch=237
06/03/2022 00:36:02 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=239
06/03/2022 00:36:05 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=242
06/03/2022 00:36:07 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=244
06/03/2022 00:36:10 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=247
06/03/2022 00:36:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=249
06/03/2022 00:36:13 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.6135416666666667 on epoch=249
06/03/2022 00:36:16 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=252
06/03/2022 00:36:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=254
06/03/2022 00:36:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/03/2022 00:36:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
06/03/2022 00:36:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=262
06/03/2022 00:36:26 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.6286850404497464 on epoch=262
06/03/2022 00:36:29 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=264
06/03/2022 00:36:31 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=267
06/03/2022 00:36:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=269
06/03/2022 00:36:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=272
06/03/2022 00:36:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.20 on epoch=274
06/03/2022 00:36:40 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.6578962703962704 on epoch=274
06/03/2022 00:36:42 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=277
06/03/2022 00:36:44 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=279
06/03/2022 00:36:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/03/2022 00:36:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=284
06/03/2022 00:36:52 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=287
06/03/2022 00:36:53 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.643452380952381 on epoch=287
06/03/2022 00:36:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/03/2022 00:36:58 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/03/2022 00:37:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=294
06/03/2022 00:37:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/03/2022 00:37:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/03/2022 00:37:06 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.6661204642039883 on epoch=299
06/03/2022 00:37:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6661181955299602 -> 0.6661204642039883 on epoch=299, global_step=1200
06/03/2022 00:37:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=302
06/03/2022 00:37:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/03/2022 00:37:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/03/2022 00:37:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=309
06/03/2022 00:37:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/03/2022 00:37:19 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.6659008308961196 on epoch=312
06/03/2022 00:37:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/03/2022 00:37:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=317
06/03/2022 00:37:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=319
06/03/2022 00:37:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/03/2022 00:37:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=324
06/03/2022 00:37:32 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.6795422714540361 on epoch=324
06/03/2022 00:37:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6661204642039883 -> 0.6795422714540361 on epoch=324, global_step=1300
06/03/2022 00:37:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=327
06/03/2022 00:37:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=329
06/03/2022 00:37:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=332
06/03/2022 00:37:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/03/2022 00:37:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=337
06/03/2022 00:37:45 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.6405161149825784 on epoch=337
06/03/2022 00:37:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/03/2022 00:37:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/03/2022 00:37:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/03/2022 00:37:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=347
06/03/2022 00:37:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/03/2022 00:37:59 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6541543315736864 on epoch=349
06/03/2022 00:38:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=352
06/03/2022 00:38:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=354
06/03/2022 00:38:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/03/2022 00:38:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/03/2022 00:38:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/03/2022 00:38:12 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.6504954642039882 on epoch=362
06/03/2022 00:38:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/03/2022 00:38:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/03/2022 00:38:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/03/2022 00:38:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/03/2022 00:38:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=374
06/03/2022 00:38:25 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.6635333416583418 on epoch=374
06/03/2022 00:38:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/03/2022 00:38:30 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=379
06/03/2022 00:38:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/03/2022 00:38:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/03/2022 00:38:37 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/03/2022 00:38:38 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.6433909228026875 on epoch=387
06/03/2022 00:38:41 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/03/2022 00:38:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/03/2022 00:38:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/03/2022 00:38:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/03/2022 00:38:50 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
06/03/2022 00:38:51 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.6710729968262249 on epoch=399
06/03/2022 00:38:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/03/2022 00:38:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/03/2022 00:38:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/03/2022 00:39:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/03/2022 00:39:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/03/2022 00:39:04 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.6659008308961196 on epoch=412
06/03/2022 00:39:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/03/2022 00:39:09 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=417
06/03/2022 00:39:12 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/03/2022 00:39:14 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=422
06/03/2022 00:39:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/03/2022 00:39:17 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6709196608095113 on epoch=424
06/03/2022 00:39:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/03/2022 00:39:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/03/2022 00:39:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=432
06/03/2022 00:39:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/03/2022 00:39:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/03/2022 00:39:31 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.6570855614973262 on epoch=437
06/03/2022 00:39:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/03/2022 00:39:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/03/2022 00:39:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/03/2022 00:39:40 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/03/2022 00:39:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
06/03/2022 00:39:44 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.6708842627960275 on epoch=449
06/03/2022 00:39:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=452
06/03/2022 00:39:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=454
06/03/2022 00:39:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/03/2022 00:39:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/03/2022 00:39:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/03/2022 00:39:57 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6585424379542026 on epoch=462
06/03/2022 00:39:59 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/03/2022 00:40:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/03/2022 00:40:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/03/2022 00:40:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/03/2022 00:40:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/03/2022 00:40:10 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.640327380952381 on epoch=474
06/03/2022 00:40:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/03/2022 00:40:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/03/2022 00:40:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/03/2022 00:40:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/03/2022 00:40:22 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/03/2022 00:40:23 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.6376633986928105 on epoch=487
06/03/2022 00:40:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/03/2022 00:40:28 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=492
06/03/2022 00:40:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/03/2022 00:40:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/03/2022 00:40:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/03/2022 00:40:36 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.6947742241859889 on epoch=499
06/03/2022 00:40:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6795422714540361 -> 0.6947742241859889 on epoch=499, global_step=2000
06/03/2022 00:40:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/03/2022 00:40:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=504
06/03/2022 00:40:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/03/2022 00:40:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/03/2022 00:40:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=512
06/03/2022 00:40:50 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6552115583075335 on epoch=512
06/03/2022 00:40:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/03/2022 00:40:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/03/2022 00:40:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/03/2022 00:41:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/03/2022 00:41:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/03/2022 00:41:03 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6701317688159794 on epoch=524
06/03/2022 00:41:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/03/2022 00:41:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/03/2022 00:41:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/03/2022 00:41:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=534
06/03/2022 00:41:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/03/2022 00:41:16 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6564934295197453 on epoch=537
06/03/2022 00:41:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/03/2022 00:41:21 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/03/2022 00:41:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/03/2022 00:41:26 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/03/2022 00:41:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=549
06/03/2022 00:41:30 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6701317688159794 on epoch=549
06/03/2022 00:41:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/03/2022 00:41:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/03/2022 00:41:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/03/2022 00:41:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/03/2022 00:41:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/03/2022 00:41:43 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.6701317688159794 on epoch=562
06/03/2022 00:41:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/03/2022 00:41:48 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/03/2022 00:41:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/03/2022 00:41:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/03/2022 00:41:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/03/2022 00:41:56 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.6701317688159794 on epoch=574
06/03/2022 00:41:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/03/2022 00:42:01 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/03/2022 00:42:03 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/03/2022 00:42:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/03/2022 00:42:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/03/2022 00:42:09 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6701839826839827 on epoch=587
06/03/2022 00:42:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=589
06/03/2022 00:42:14 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/03/2022 00:42:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=594
06/03/2022 00:42:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/03/2022 00:42:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=599
06/03/2022 00:42:22 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6938643188643189 on epoch=599
06/03/2022 00:42:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/03/2022 00:42:27 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=604
06/03/2022 00:42:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=607
06/03/2022 00:42:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/03/2022 00:42:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/03/2022 00:42:36 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.6705861705861706 on epoch=612
06/03/2022 00:42:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/03/2022 00:42:41 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/03/2022 00:42:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/03/2022 00:42:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/03/2022 00:42:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/03/2022 00:42:49 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6556013431013431 on epoch=624
06/03/2022 00:42:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/03/2022 00:42:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=629
06/03/2022 00:42:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/03/2022 00:42:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/03/2022 00:43:01 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/03/2022 00:43:02 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6798128342245989 on epoch=637
06/03/2022 00:43:04 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/03/2022 00:43:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/03/2022 00:43:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/03/2022 00:43:12 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/03/2022 00:43:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/03/2022 00:43:15 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6663157722940332 on epoch=649
06/03/2022 00:43:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/03/2022 00:43:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/03/2022 00:43:22 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/03/2022 00:43:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/03/2022 00:43:27 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=662
06/03/2022 00:43:28 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6701317688159794 on epoch=662
06/03/2022 00:43:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=664
06/03/2022 00:43:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/03/2022 00:43:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/03/2022 00:43:38 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/03/2022 00:43:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/03/2022 00:43:42 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6938643188643189 on epoch=674
06/03/2022 00:43:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/03/2022 00:43:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/03/2022 00:43:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/03/2022 00:43:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/03/2022 00:43:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/03/2022 00:43:55 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7079357049945285 on epoch=687
06/03/2022 00:43:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6947742241859889 -> 0.7079357049945285 on epoch=687, global_step=2750
06/03/2022 00:43:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=689
06/03/2022 00:44:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/03/2022 00:44:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/03/2022 00:44:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/03/2022 00:44:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/03/2022 00:44:08 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6928847296494356 on epoch=699
06/03/2022 00:44:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/03/2022 00:44:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/03/2022 00:44:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/03/2022 00:44:18 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/03/2022 00:44:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=712
06/03/2022 00:44:21 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6721043184457819 on epoch=712
06/03/2022 00:44:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/03/2022 00:44:26 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/03/2022 00:44:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/03/2022 00:44:31 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=722
06/03/2022 00:44:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/03/2022 00:44:35 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6701317688159794 on epoch=724
06/03/2022 00:44:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
06/03/2022 00:44:40 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/03/2022 00:44:42 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/03/2022 00:44:45 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/03/2022 00:44:47 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/03/2022 00:44:48 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6701317688159794 on epoch=737
06/03/2022 00:44:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/03/2022 00:44:53 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/03/2022 00:44:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/03/2022 00:44:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/03/2022 00:45:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.09 on epoch=749
06/03/2022 00:45:01 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7076839826839827 on epoch=749
06/03/2022 00:45:01 - INFO - __main__ - save last model!
06/03/2022 00:45:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/03/2022 00:45:01 - INFO - __main__ - Start tokenizing ... 5509 instances
06/03/2022 00:45:01 - INFO - __main__ - Printing 3 examples
06/03/2022 00:45:01 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/03/2022 00:45:01 - INFO - __main__ - ['others']
06/03/2022 00:45:01 - INFO - __main__ -  [emo] what you like very little things ok
06/03/2022 00:45:01 - INFO - __main__ - ['others']
06/03/2022 00:45:01 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/03/2022 00:45:01 - INFO - __main__ - ['others']
06/03/2022 00:45:01 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:45:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:45:01 - INFO - __main__ - Printing 3 examples
06/03/2022 00:45:01 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/03/2022 00:45:01 - INFO - __main__ - ['others']
06/03/2022 00:45:01 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/03/2022 00:45:01 - INFO - __main__ - ['others']
06/03/2022 00:45:01 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/03/2022 00:45:01 - INFO - __main__ - ['others']
06/03/2022 00:45:01 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:45:01 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:45:01 - INFO - __main__ - Loaded 64 examples from train data
06/03/2022 00:45:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:45:01 - INFO - __main__ - Printing 3 examples
06/03/2022 00:45:01 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/03/2022 00:45:01 - INFO - __main__ - ['others']
06/03/2022 00:45:01 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/03/2022 00:45:01 - INFO - __main__ - ['others']
06/03/2022 00:45:01 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/03/2022 00:45:01 - INFO - __main__ - ['others']
06/03/2022 00:45:01 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:45:01 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:45:02 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 00:45:03 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:45:09 - INFO - __main__ - Loaded 5509 examples from test data
06/03/2022 00:45:17 - INFO - __main__ - load prompt embedding from ckpt
06/03/2022 00:45:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/03/2022 00:45:18 - INFO - __main__ - Starting training!
06/03/2022 00:46:46 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_87_0.4_8_predictions.txt
06/03/2022 00:46:46 - INFO - __main__ - Classification-F1 on test data: 0.2666
06/03/2022 00:46:46 - INFO - __main__ - prefix=emo_16_87, lr=0.4, bsz=8, dev_performance=0.7079357049945285, test_performance=0.26661101471890475
06/03/2022 00:46:46 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.3, bsz=8 ...
06/03/2022 00:46:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:46:47 - INFO - __main__ - Printing 3 examples
06/03/2022 00:46:47 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/03/2022 00:46:47 - INFO - __main__ - ['others']
06/03/2022 00:46:47 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/03/2022 00:46:47 - INFO - __main__ - ['others']
06/03/2022 00:46:47 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/03/2022 00:46:47 - INFO - __main__ - ['others']
06/03/2022 00:46:47 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:46:47 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:46:47 - INFO - __main__ - Loaded 64 examples from train data
06/03/2022 00:46:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 00:46:47 - INFO - __main__ - Printing 3 examples
06/03/2022 00:46:47 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/03/2022 00:46:47 - INFO - __main__ - ['others']
06/03/2022 00:46:47 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/03/2022 00:46:47 - INFO - __main__ - ['others']
06/03/2022 00:46:47 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/03/2022 00:46:47 - INFO - __main__ - ['others']
06/03/2022 00:46:47 - INFO - __main__ - Tokenizing Input ...
06/03/2022 00:46:47 - INFO - __main__ - Tokenizing Output ...
06/03/2022 00:46:47 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 00:47:02 - INFO - __main__ - load prompt embedding from ckpt
06/03/2022 00:47:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/03/2022 00:47:03 - INFO - __main__ - Starting training!
06/03/2022 00:47:06 - INFO - __main__ - Step 10 Global step 10 Train loss 4.07 on epoch=2
06/03/2022 00:47:08 - INFO - __main__ - Step 20 Global step 20 Train loss 2.97 on epoch=4
06/03/2022 00:47:10 - INFO - __main__ - Step 30 Global step 30 Train loss 2.61 on epoch=7
06/03/2022 00:47:13 - INFO - __main__ - Step 40 Global step 40 Train loss 2.00 on epoch=9
06/03/2022 00:47:15 - INFO - __main__ - Step 50 Global step 50 Train loss 1.83 on epoch=12
06/03/2022 00:47:16 - INFO - __main__ - Global step 50 Train loss 2.69 Classification-F1 0.01976470588235294 on epoch=12
06/03/2022 00:47:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.01976470588235294 on epoch=12, global_step=50
06/03/2022 00:47:18 - INFO - __main__ - Step 60 Global step 60 Train loss 1.54 on epoch=14
06/03/2022 00:47:21 - INFO - __main__ - Step 70 Global step 70 Train loss 1.40 on epoch=17
06/03/2022 00:47:23 - INFO - __main__ - Step 80 Global step 80 Train loss 1.21 on epoch=19
06/03/2022 00:47:25 - INFO - __main__ - Step 90 Global step 90 Train loss 1.06 on epoch=22
06/03/2022 00:47:28 - INFO - __main__ - Step 100 Global step 100 Train loss 0.97 on epoch=24
06/03/2022 00:47:29 - INFO - __main__ - Global step 100 Train loss 1.24 Classification-F1 0.24135354078856905 on epoch=24
06/03/2022 00:47:29 - INFO - __main__ - Saving model with best Classification-F1: 0.01976470588235294 -> 0.24135354078856905 on epoch=24, global_step=100
06/03/2022 00:47:31 - INFO - __main__ - Step 110 Global step 110 Train loss 0.99 on epoch=27
06/03/2022 00:47:33 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=29
06/03/2022 00:47:36 - INFO - __main__ - Step 130 Global step 130 Train loss 0.75 on epoch=32
06/03/2022 00:47:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.74 on epoch=34
06/03/2022 00:47:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.75 on epoch=37
06/03/2022 00:47:41 - INFO - __main__ - Global step 150 Train loss 0.83 Classification-F1 0.4925582080754495 on epoch=37
06/03/2022 00:47:41 - INFO - __main__ - Saving model with best Classification-F1: 0.24135354078856905 -> 0.4925582080754495 on epoch=37, global_step=150
06/03/2022 00:47:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.77 on epoch=39
06/03/2022 00:47:46 - INFO - __main__ - Step 170 Global step 170 Train loss 0.63 on epoch=42
06/03/2022 00:47:48 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=44
06/03/2022 00:47:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.61 on epoch=47
06/03/2022 00:47:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.61 on epoch=49
06/03/2022 00:47:54 - INFO - __main__ - Global step 200 Train loss 0.66 Classification-F1 0.5525326797385621 on epoch=49
06/03/2022 00:47:54 - INFO - __main__ - Saving model with best Classification-F1: 0.4925582080754495 -> 0.5525326797385621 on epoch=49, global_step=200
06/03/2022 00:47:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.75 on epoch=52
06/03/2022 00:47:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.65 on epoch=54
06/03/2022 00:48:01 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=57
06/03/2022 00:48:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.63 on epoch=59
06/03/2022 00:48:06 - INFO - __main__ - Step 250 Global step 250 Train loss 0.60 on epoch=62
06/03/2022 00:48:06 - INFO - __main__ - Global step 250 Train loss 0.64 Classification-F1 0.6215347152847153 on epoch=62
06/03/2022 00:48:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5525326797385621 -> 0.6215347152847153 on epoch=62, global_step=250
06/03/2022 00:48:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=64
06/03/2022 00:48:11 - INFO - __main__ - Step 270 Global step 270 Train loss 0.66 on epoch=67
06/03/2022 00:48:13 - INFO - __main__ - Step 280 Global step 280 Train loss 0.57 on epoch=69
06/03/2022 00:48:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=72
06/03/2022 00:48:18 - INFO - __main__ - Step 300 Global step 300 Train loss 0.52 on epoch=74
06/03/2022 00:48:19 - INFO - __main__ - Global step 300 Train loss 0.56 Classification-F1 0.5364927470190628 on epoch=74
06/03/2022 00:48:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.53 on epoch=77
06/03/2022 00:48:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=79
06/03/2022 00:48:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.55 on epoch=82
06/03/2022 00:48:28 - INFO - __main__ - Step 340 Global step 340 Train loss 0.44 on epoch=84
06/03/2022 00:48:31 - INFO - __main__ - Step 350 Global step 350 Train loss 0.47 on epoch=87
06/03/2022 00:48:32 - INFO - __main__ - Global step 350 Train loss 0.49 Classification-F1 0.6447534525120733 on epoch=87
06/03/2022 00:48:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6215347152847153 -> 0.6447534525120733 on epoch=87, global_step=350
06/03/2022 00:48:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.42 on epoch=89
06/03/2022 00:48:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.53 on epoch=92
06/03/2022 00:48:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.49 on epoch=94
06/03/2022 00:48:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.43 on epoch=97
06/03/2022 00:48:43 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=99
06/03/2022 00:48:44 - INFO - __main__ - Global step 400 Train loss 0.45 Classification-F1 0.5882629302601943 on epoch=99
06/03/2022 00:48:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.51 on epoch=102
06/03/2022 00:48:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.41 on epoch=104
06/03/2022 00:48:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.46 on epoch=107
06/03/2022 00:48:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.36 on epoch=109
06/03/2022 00:48:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.41 on epoch=112
06/03/2022 00:48:57 - INFO - __main__ - Global step 450 Train loss 0.43 Classification-F1 0.6194754970711988 on epoch=112
06/03/2022 00:48:59 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=114
06/03/2022 00:49:01 - INFO - __main__ - Step 470 Global step 470 Train loss 0.41 on epoch=117
06/03/2022 00:49:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.37 on epoch=119
06/03/2022 00:49:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.38 on epoch=122
06/03/2022 00:49:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.34 on epoch=124
06/03/2022 00:49:09 - INFO - __main__ - Global step 500 Train loss 0.36 Classification-F1 0.6178459109876527 on epoch=124
06/03/2022 00:49:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.46 on epoch=127
06/03/2022 00:49:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=129
06/03/2022 00:49:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.35 on epoch=132
06/03/2022 00:49:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=134
06/03/2022 00:49:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=137
06/03/2022 00:49:22 - INFO - __main__ - Global step 550 Train loss 0.37 Classification-F1 0.618945993031359 on epoch=137
06/03/2022 00:49:24 - INFO - __main__ - Step 560 Global step 560 Train loss 0.35 on epoch=139
06/03/2022 00:49:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.33 on epoch=142
06/03/2022 00:49:29 - INFO - __main__ - Step 580 Global step 580 Train loss 0.29 on epoch=144
06/03/2022 00:49:31 - INFO - __main__ - Step 590 Global step 590 Train loss 0.33 on epoch=147
06/03/2022 00:49:34 - INFO - __main__ - Step 600 Global step 600 Train loss 0.34 on epoch=149
06/03/2022 00:49:34 - INFO - __main__ - Global step 600 Train loss 0.33 Classification-F1 0.630733082706767 on epoch=149
06/03/2022 00:49:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=152
06/03/2022 00:49:39 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=154
06/03/2022 00:49:41 - INFO - __main__ - Step 630 Global step 630 Train loss 0.28 on epoch=157
06/03/2022 00:49:44 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=159
06/03/2022 00:49:46 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=162
06/03/2022 00:49:47 - INFO - __main__ - Global step 650 Train loss 0.27 Classification-F1 0.6604142469996128 on epoch=162
06/03/2022 00:49:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6447534525120733 -> 0.6604142469996128 on epoch=162, global_step=650
06/03/2022 00:49:49 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=164
06/03/2022 00:49:52 - INFO - __main__ - Step 670 Global step 670 Train loss 0.38 on epoch=167
06/03/2022 00:49:54 - INFO - __main__ - Step 680 Global step 680 Train loss 0.29 on epoch=169
06/03/2022 00:49:56 - INFO - __main__ - Step 690 Global step 690 Train loss 0.30 on epoch=172
06/03/2022 00:49:59 - INFO - __main__ - Step 700 Global step 700 Train loss 0.25 on epoch=174
06/03/2022 00:50:00 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.616504329004329 on epoch=174
06/03/2022 00:50:02 - INFO - __main__ - Step 710 Global step 710 Train loss 0.30 on epoch=177
06/03/2022 00:50:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=179
06/03/2022 00:50:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=182
06/03/2022 00:50:09 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=184
06/03/2022 00:50:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.24 on epoch=187
06/03/2022 00:50:12 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.6413240763198319 on epoch=187
06/03/2022 00:50:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.27 on epoch=189
06/03/2022 00:50:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=192
06/03/2022 00:50:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.25 on epoch=194
06/03/2022 00:50:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=197
06/03/2022 00:50:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=199
06/03/2022 00:50:25 - INFO - __main__ - Global step 800 Train loss 0.25 Classification-F1 0.629606166191532 on epoch=199
06/03/2022 00:50:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=202
06/03/2022 00:50:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=204
06/03/2022 00:50:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.23 on epoch=207
06/03/2022 00:50:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=209
06/03/2022 00:50:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=212
06/03/2022 00:50:37 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.6320855614973262 on epoch=212
06/03/2022 00:50:40 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=214
06/03/2022 00:50:42 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=217
06/03/2022 00:50:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=219
06/03/2022 00:50:47 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=222
06/03/2022 00:50:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=224
06/03/2022 00:50:50 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.629606166191532 on epoch=224
06/03/2022 00:50:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=227
06/03/2022 00:50:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=229
06/03/2022 00:50:57 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=232
06/03/2022 00:50:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=234
06/03/2022 00:51:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=237
06/03/2022 00:51:03 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.6389986824769434 on epoch=237
06/03/2022 00:51:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=239
06/03/2022 00:51:08 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=242
06/03/2022 00:51:10 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=244
06/03/2022 00:51:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=247
06/03/2022 00:51:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=249
06/03/2022 00:51:16 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.6412155993217685 on epoch=249
06/03/2022 00:51:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=252
06/03/2022 00:51:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=254
06/03/2022 00:51:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=257
06/03/2022 00:51:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=259
06/03/2022 00:51:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=262
06/03/2022 00:51:28 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.6412155993217685 on epoch=262
06/03/2022 00:51:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=264
06/03/2022 00:51:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=267
06/03/2022 00:51:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=269
06/03/2022 00:51:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=272
06/03/2022 00:51:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=274
06/03/2022 00:51:42 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.6412155993217685 on epoch=274
06/03/2022 00:51:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=277
06/03/2022 00:51:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=279
06/03/2022 00:51:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=282
06/03/2022 00:51:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=284
06/03/2022 00:51:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=287
06/03/2022 00:51:55 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.6262304006968641 on epoch=287
06/03/2022 00:51:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=289
06/03/2022 00:52:00 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=292
06/03/2022 00:52:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=294
06/03/2022 00:52:05 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=297
06/03/2022 00:52:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/03/2022 00:52:08 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.6262304006968641 on epoch=299
06/03/2022 00:52:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/03/2022 00:52:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=304
06/03/2022 00:52:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.10 on epoch=307
06/03/2022 00:52:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=309
06/03/2022 00:52:20 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/03/2022 00:52:21 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6559214816747098 on epoch=312
06/03/2022 00:52:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=314
06/03/2022 00:52:26 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=317
06/03/2022 00:52:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=319
06/03/2022 00:52:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=322
06/03/2022 00:52:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=324
06/03/2022 00:52:34 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.6790701415701416 on epoch=324
06/03/2022 00:52:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6604142469996128 -> 0.6790701415701416 on epoch=324, global_step=1300
06/03/2022 00:52:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/03/2022 00:52:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=329
06/03/2022 00:52:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=332
06/03/2022 00:52:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=334
06/03/2022 00:52:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=337
06/03/2022 00:52:48 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.6591862721319428 on epoch=337
06/03/2022 00:52:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=339
06/03/2022 00:52:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=342
06/03/2022 00:52:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=344
06/03/2022 00:52:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=347
06/03/2022 00:53:00 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=349
06/03/2022 00:53:01 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.6417050691244239 on epoch=349
06/03/2022 00:53:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=352
06/03/2022 00:53:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/03/2022 00:53:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/03/2022 00:53:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=359
06/03/2022 00:53:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=362
06/03/2022 00:53:14 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6641369047619048 on epoch=362
06/03/2022 00:53:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=364
06/03/2022 00:53:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=367
06/03/2022 00:53:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=369
06/03/2022 00:53:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/03/2022 00:53:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/03/2022 00:53:27 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.6417050691244239 on epoch=374
06/03/2022 00:53:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=377
06/03/2022 00:53:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
06/03/2022 00:53:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=382
06/03/2022 00:53:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=384
06/03/2022 00:53:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/03/2022 00:53:40 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.6651080888689072 on epoch=387
06/03/2022 00:53:43 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/03/2022 00:53:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=392
06/03/2022 00:53:48 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
06/03/2022 00:53:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=397
06/03/2022 00:53:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/03/2022 00:53:54 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.680650918904147 on epoch=399
06/03/2022 00:53:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6790701415701416 -> 0.680650918904147 on epoch=399, global_step=1600
06/03/2022 00:53:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/03/2022 00:53:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/03/2022 00:54:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/03/2022 00:54:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=409
06/03/2022 00:54:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/03/2022 00:54:07 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.6725108225108226 on epoch=412
06/03/2022 00:54:09 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=414
06/03/2022 00:54:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=417
06/03/2022 00:54:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=419
06/03/2022 00:54:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=422
06/03/2022 00:54:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/03/2022 00:54:20 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6790701415701416 on epoch=424
06/03/2022 00:54:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/03/2022 00:54:25 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=429
06/03/2022 00:54:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=432
06/03/2022 00:54:30 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
06/03/2022 00:54:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/03/2022 00:54:33 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6730880230880231 on epoch=437
06/03/2022 00:54:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/03/2022 00:54:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=442
06/03/2022 00:54:41 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/03/2022 00:54:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/03/2022 00:54:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
06/03/2022 00:54:46 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.654038789428815 on epoch=449
06/03/2022 00:54:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=452
06/03/2022 00:54:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
06/03/2022 00:54:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/03/2022 00:54:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
06/03/2022 00:54:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=462
06/03/2022 00:55:00 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7093996689584926 on epoch=462
06/03/2022 00:55:00 - INFO - __main__ - Saving model with best Classification-F1: 0.680650918904147 -> 0.7093996689584926 on epoch=462, global_step=1850
06/03/2022 00:55:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=464
06/03/2022 00:55:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/03/2022 00:55:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=469
06/03/2022 00:55:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=472
06/03/2022 00:55:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/03/2022 00:55:13 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.6791583416583418 on epoch=474
06/03/2022 00:55:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/03/2022 00:55:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=479
06/03/2022 00:55:20 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/03/2022 00:55:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=484
06/03/2022 00:55:25 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.09 on epoch=487
06/03/2022 00:55:26 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.6388513513513514 on epoch=487
06/03/2022 00:55:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/03/2022 00:55:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/03/2022 00:55:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/03/2022 00:55:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/03/2022 00:55:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/03/2022 00:55:39 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6779638553832101 on epoch=499
06/03/2022 00:55:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=502
06/03/2022 00:55:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=504
06/03/2022 00:55:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=507
06/03/2022 00:55:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/03/2022 00:55:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/03/2022 00:55:52 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.6932997557997558 on epoch=512
06/03/2022 00:55:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/03/2022 00:55:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=517
06/03/2022 00:56:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/03/2022 00:56:02 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/03/2022 00:56:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=524
06/03/2022 00:56:06 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6779638553832101 on epoch=524
06/03/2022 00:56:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=527
06/03/2022 00:56:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.12 on epoch=529
06/03/2022 00:56:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/03/2022 00:56:15 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=534
06/03/2022 00:56:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/03/2022 00:56:19 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.6779638553832101 on epoch=537
06/03/2022 00:56:21 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/03/2022 00:56:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=542
06/03/2022 00:56:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/03/2022 00:56:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/03/2022 00:56:31 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=549
06/03/2022 00:56:32 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6784114183307731 on epoch=549
06/03/2022 00:56:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=552
06/03/2022 00:56:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/03/2022 00:56:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/03/2022 00:56:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/03/2022 00:56:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/03/2022 00:56:45 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6797913343965976 on epoch=562
06/03/2022 00:56:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/03/2022 00:56:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/03/2022 00:56:53 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/03/2022 00:56:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/03/2022 00:56:58 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/03/2022 00:56:59 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6862325158257836 on epoch=574
06/03/2022 00:57:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/03/2022 00:57:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/03/2022 00:57:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/03/2022 00:57:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/03/2022 00:57:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/03/2022 00:57:12 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.6797913343965976 on epoch=587
06/03/2022 00:57:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=589
06/03/2022 00:57:17 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/03/2022 00:57:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=594
06/03/2022 00:57:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=597
06/03/2022 00:57:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/03/2022 00:57:25 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6779638553832101 on epoch=599
06/03/2022 00:57:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/03/2022 00:57:30 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/03/2022 00:57:33 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/03/2022 00:57:35 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/03/2022 00:57:38 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/03/2022 00:57:39 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6932997557997558 on epoch=612
06/03/2022 00:57:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/03/2022 00:57:44 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/03/2022 00:57:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/03/2022 00:57:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=622
06/03/2022 00:57:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/03/2022 00:57:52 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6644554339800519 on epoch=624
06/03/2022 00:57:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/03/2022 00:57:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/03/2022 00:57:59 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/03/2022 00:58:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=634
06/03/2022 00:58:04 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/03/2022 00:58:05 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7075925106884859 on epoch=637
06/03/2022 00:58:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/03/2022 00:58:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/03/2022 00:58:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/03/2022 00:58:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=647
06/03/2022 00:58:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=649
06/03/2022 00:58:18 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6948165869218501 on epoch=649
06/03/2022 00:58:21 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=652
06/03/2022 00:58:23 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/03/2022 00:58:26 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/03/2022 00:58:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/03/2022 00:58:31 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/03/2022 00:58:31 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6797913343965976 on epoch=662
06/03/2022 00:58:34 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/03/2022 00:58:36 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/03/2022 00:58:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/03/2022 00:58:41 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=672
06/03/2022 00:58:44 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/03/2022 00:58:45 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6937950937950937 on epoch=674
06/03/2022 00:58:47 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/03/2022 00:58:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/03/2022 00:58:52 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/03/2022 00:58:55 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/03/2022 00:58:57 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/03/2022 00:58:58 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.679088179088179 on epoch=687
06/03/2022 00:59:00 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/03/2022 00:59:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=692
06/03/2022 00:59:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=694
06/03/2022 00:59:08 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/03/2022 00:59:10 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/03/2022 00:59:11 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.679088179088179 on epoch=699
06/03/2022 00:59:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=702
06/03/2022 00:59:16 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/03/2022 00:59:18 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/03/2022 00:59:21 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/03/2022 00:59:23 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/03/2022 00:59:24 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7075925106884859 on epoch=712
06/03/2022 00:59:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=714
06/03/2022 00:59:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/03/2022 00:59:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/03/2022 00:59:34 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/03/2022 00:59:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/03/2022 00:59:38 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6797913343965976 on epoch=724
06/03/2022 00:59:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/03/2022 00:59:43 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=729
06/03/2022 00:59:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/03/2022 00:59:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/03/2022 00:59:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/03/2022 00:59:51 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6797913343965976 on epoch=737
06/03/2022 00:59:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=739
06/03/2022 00:59:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/03/2022 00:59:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/03/2022 01:00:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/03/2022 01:00:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/03/2022 01:00:04 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6926786663628768 on epoch=749
06/03/2022 01:00:04 - INFO - __main__ - save last model!
06/03/2022 01:00:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/03/2022 01:00:04 - INFO - __main__ - Start tokenizing ... 5509 instances
06/03/2022 01:00:04 - INFO - __main__ - Printing 3 examples
06/03/2022 01:00:04 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/03/2022 01:00:04 - INFO - __main__ - ['others']
06/03/2022 01:00:04 - INFO - __main__ -  [emo] what you like very little things ok
06/03/2022 01:00:04 - INFO - __main__ - ['others']
06/03/2022 01:00:04 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/03/2022 01:00:04 - INFO - __main__ - ['others']
06/03/2022 01:00:04 - INFO - __main__ - Tokenizing Input ...
06/03/2022 01:00:04 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 01:00:04 - INFO - __main__ - Printing 3 examples
06/03/2022 01:00:04 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/03/2022 01:00:04 - INFO - __main__ - ['others']
06/03/2022 01:00:04 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/03/2022 01:00:04 - INFO - __main__ - ['others']
06/03/2022 01:00:04 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/03/2022 01:00:04 - INFO - __main__ - ['others']
06/03/2022 01:00:04 - INFO - __main__ - Tokenizing Input ...
06/03/2022 01:00:04 - INFO - __main__ - Tokenizing Output ...
06/03/2022 01:00:04 - INFO - __main__ - Loaded 64 examples from train data
06/03/2022 01:00:04 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 01:00:04 - INFO - __main__ - Printing 3 examples
06/03/2022 01:00:04 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/03/2022 01:00:04 - INFO - __main__ - ['others']
06/03/2022 01:00:04 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/03/2022 01:00:04 - INFO - __main__ - ['others']
06/03/2022 01:00:04 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/03/2022 01:00:04 - INFO - __main__ - ['others']
06/03/2022 01:00:04 - INFO - __main__ - Tokenizing Input ...
06/03/2022 01:00:04 - INFO - __main__ - Tokenizing Output ...
06/03/2022 01:00:04 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 01:00:06 - INFO - __main__ - Tokenizing Output ...
06/03/2022 01:00:12 - INFO - __main__ - Loaded 5509 examples from test data
06/03/2022 01:00:23 - INFO - __main__ - load prompt embedding from ckpt
06/03/2022 01:00:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/03/2022 01:00:24 - INFO - __main__ - Starting training!
06/03/2022 01:01:36 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_87_0.3_8_predictions.txt
06/03/2022 01:01:36 - INFO - __main__ - Classification-F1 on test data: 0.3028
06/03/2022 01:01:36 - INFO - __main__ - prefix=emo_16_87, lr=0.3, bsz=8, dev_performance=0.7093996689584926, test_performance=0.3028052104863316
06/03/2022 01:01:37 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.2, bsz=8 ...
06/03/2022 01:01:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 01:01:37 - INFO - __main__ - Printing 3 examples
06/03/2022 01:01:37 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/03/2022 01:01:37 - INFO - __main__ - ['others']
06/03/2022 01:01:37 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/03/2022 01:01:37 - INFO - __main__ - ['others']
06/03/2022 01:01:37 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/03/2022 01:01:37 - INFO - __main__ - ['others']
06/03/2022 01:01:37 - INFO - __main__ - Tokenizing Input ...
06/03/2022 01:01:37 - INFO - __main__ - Tokenizing Output ...
06/03/2022 01:01:37 - INFO - __main__ - Loaded 64 examples from train data
06/03/2022 01:01:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/03/2022 01:01:37 - INFO - __main__ - Printing 3 examples
06/03/2022 01:01:37 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/03/2022 01:01:37 - INFO - __main__ - ['others']
06/03/2022 01:01:37 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/03/2022 01:01:37 - INFO - __main__ - ['others']
06/03/2022 01:01:37 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/03/2022 01:01:37 - INFO - __main__ - ['others']
06/03/2022 01:01:37 - INFO - __main__ - Tokenizing Input ...
06/03/2022 01:01:37 - INFO - __main__ - Tokenizing Output ...
06/03/2022 01:01:38 - INFO - __main__ - Loaded 64 examples from dev data
06/03/2022 01:01:54 - INFO - __main__ - load prompt embedding from ckpt
06/03/2022 01:01:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/03/2022 01:01:55 - INFO - __main__ - Starting training!
06/03/2022 01:01:58 - INFO - __main__ - Step 10 Global step 10 Train loss 4.69 on epoch=2
06/03/2022 01:02:00 - INFO - __main__ - Step 20 Global step 20 Train loss 3.28 on epoch=4
06/03/2022 01:02:03 - INFO - __main__ - Step 30 Global step 30 Train loss 3.02 on epoch=7
06/03/2022 01:02:05 - INFO - __main__ - Step 40 Global step 40 Train loss 2.42 on epoch=9
06/03/2022 01:02:08 - INFO - __main__ - Step 50 Global step 50 Train loss 2.19 on epoch=12
06/03/2022 01:02:09 - INFO - __main__ - Global step 50 Train loss 3.12 Classification-F1 0.0 on epoch=12
06/03/2022 01:02:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
06/03/2022 01:02:11 - INFO - __main__ - Step 60 Global step 60 Train loss 2.06 on epoch=14
06/03/2022 01:02:14 - INFO - __main__ - Step 70 Global step 70 Train loss 1.84 on epoch=17
06/03/2022 01:02:16 - INFO - __main__ - Step 80 Global step 80 Train loss 1.65 on epoch=19
06/03/2022 01:02:19 - INFO - __main__ - Step 90 Global step 90 Train loss 1.49 on epoch=22
06/03/2022 01:02:21 - INFO - __main__ - Step 100 Global step 100 Train loss 1.37 on epoch=24
06/03/2022 01:02:22 - INFO - __main__ - Global step 100 Train loss 1.68 Classification-F1 0.05128851540616246 on epoch=24
06/03/2022 01:02:22 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.05128851540616246 on epoch=24, global_step=100
06/03/2022 01:02:25 - INFO - __main__ - Step 110 Global step 110 Train loss 1.30 on epoch=27
06/03/2022 01:02:27 - INFO - __main__ - Step 120 Global step 120 Train loss 1.24 on epoch=29
06/03/2022 01:02:30 - INFO - __main__ - Step 130 Global step 130 Train loss 1.17 on epoch=32
06/03/2022 01:02:32 - INFO - __main__ - Step 140 Global step 140 Train loss 1.02 on epoch=34
06/03/2022 01:02:34 - INFO - __main__ - Step 150 Global step 150 Train loss 0.96 on epoch=37
06/03/2022 01:02:35 - INFO - __main__ - Global step 150 Train loss 1.14 Classification-F1 0.18965986394557824 on epoch=37
06/03/2022 01:02:35 - INFO - __main__ - Saving model with best Classification-F1: 0.05128851540616246 -> 0.18965986394557824 on epoch=37, global_step=150
06/03/2022 01:02:38 - INFO - __main__ - Step 160 Global step 160 Train loss 0.95 on epoch=39
06/03/2022 01:02:40 - INFO - __main__ - Step 170 Global step 170 Train loss 0.81 on epoch=42
06/03/2022 01:02:43 - INFO - __main__ - Step 180 Global step 180 Train loss 0.83 on epoch=44
06/03/2022 01:02:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.83 on epoch=47
06/03/2022 01:02:48 - INFO - __main__ - Step 200 Global step 200 Train loss 0.69 on epoch=49
06/03/2022 01:02:48 - INFO - __main__ - Global step 200 Train loss 0.82 Classification-F1 0.3686647173489279 on epoch=49
06/03/2022 01:02:48 - INFO - __main__ - Saving model with best Classification-F1: 0.18965986394557824 -> 0.3686647173489279 on epoch=49, global_step=200
06/03/2022 01:02:51 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=52
06/03/2022 01:02:53 - INFO - __main__ - Step 220 Global step 220 Train loss 0.72 on epoch=54
06/03/2022 01:02:56 - INFO - __main__ - Step 230 Global step 230 Train loss 0.74 on epoch=57
06/03/2022 01:02:58 - INFO - __main__ - Step 240 Global step 240 Train loss 0.70 on epoch=59
06/03/2022 01:03:01 - INFO - __main__ - Step 250 Global step 250 Train loss 0.71 on epoch=62
06/03/2022 01:03:01 - INFO - __main__ - Global step 250 Train loss 0.71 Classification-F1 0.4946560846560847 on epoch=62
06/03/2022 01:03:01 - INFO - __main__ - Saving model with best Classification-F1: 0.3686647173489279 -> 0.4946560846560847 on epoch=62, global_step=250
06/03/2022 01:03:04 - INFO - __main__ - Step 260 Global step 260 Train loss 0.63 on epoch=64
06/03/2022 01:03:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.69 on epoch=67
06/03/2022 01:03:09 - INFO - __main__ - Step 280 Global step 280 Train loss 0.74 on epoch=69
06/03/2022 01:03:11 - INFO - __main__ - Step 290 Global step 290 Train loss 0.62 on epoch=72
06/03/2022 01:03:14 - INFO - __main__ - Step 300 Global step 300 Train loss 0.64 on epoch=74
06/03/2022 01:03:15 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.5148845433742459 on epoch=74
06/03/2022 01:03:15 - INFO - __main__ - Saving model with best Classification-F1: 0.4946560846560847 -> 0.5148845433742459 on epoch=74, global_step=300
06/03/2022 01:03:17 - INFO - __main__ - Step 310 Global step 310 Train loss 0.67 on epoch=77
06/03/2022 01:03:19 - INFO - __main__ - Step 320 Global step 320 Train loss 0.70 on epoch=79
06/03/2022 01:03:22 - INFO - __main__ - Step 330 Global step 330 Train loss 0.69 on epoch=82
06/03/2022 01:03:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.69 on epoch=84
06/03/2022 01:03:27 - INFO - __main__ - Step 350 Global step 350 Train loss 0.70 on epoch=87
06/03/2022 01:03:28 - INFO - __main__ - Global step 350 Train loss 0.69 Classification-F1 0.6086645540687206 on epoch=87
06/03/2022 01:03:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5148845433742459 -> 0.6086645540687206 on epoch=87, global_step=350
06/03/2022 01:03:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.51 on epoch=89
06/03/2022 01:03:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.65 on epoch=92
06/03/2022 01:03:35 - INFO - __main__ - Step 380 Global step 380 Train loss 0.62 on epoch=94
06/03/2022 01:03:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.54 on epoch=97
06/03/2022 01:03:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.63 on epoch=99
06/03/2022 01:03:41 - INFO - __main__ - Global step 400 Train loss 0.59 Classification-F1 0.5588989441930619 on epoch=99
06/03/2022 01:03:43 - INFO - __main__ - Step 410 Global step 410 Train loss 0.51 on epoch=102
06/03/2022 01:03:46 - INFO - __main__ - Step 420 Global step 420 Train loss 0.57 on epoch=104
06/03/2022 01:03:48 - INFO - __main__ - Step 430 Global step 430 Train loss 0.57 on epoch=107
06/03/2022 01:03:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.51 on epoch=109
06/03/2022 01:03:53 - INFO - __main__ - Step 450 Global step 450 Train loss 0.51 on epoch=112
06/03/2022 01:03:54 - INFO - __main__ - Global step 450 Train loss 0.53 Classification-F1 0.6395431145431146 on epoch=112
06/03/2022 01:03:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6086645540687206 -> 0.6395431145431146 on epoch=112, global_step=450
06/03/2022 01:03:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.52 on epoch=114
06/03/2022 01:03:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.51 on epoch=117
06/03/2022 01:04:01 - INFO - __main__ - Step 480 Global step 480 Train loss 0.54 on epoch=119
06/03/2022 01:04:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.52 on epoch=122
06/03/2022 01:04:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.49 on epoch=124
06/03/2022 01:04:07 - INFO - __main__ - Global step 500 Train loss 0.51 Classification-F1 0.6401515151515151 on epoch=124
06/03/2022 01:04:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6395431145431146 -> 0.6401515151515151 on epoch=124, global_step=500
06/03/2022 01:04:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.48 on epoch=127
06/03/2022 01:04:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.45 on epoch=129
06/03/2022 01:04:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.53 on epoch=132
06/03/2022 01:04:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.43 on epoch=134
06/03/2022 01:04:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.57 on epoch=137
06/03/2022 01:04:20 - INFO - __main__ - Global step 550 Train loss 0.49 Classification-F1 0.6401515151515151 on epoch=137
06/03/2022 01:04:22 - INFO - __main__ - Step 560 Global step 560 Train loss 0.42 on epoch=139
06/03/2022 01:04:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.54 on epoch=142
06/03/2022 01:04:27 - INFO - __main__ - Step 580 Global step 580 Train loss 0.44 on epoch=144
06/03/2022 01:04:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.37 on epoch=147
06/03/2022 01:04:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.53 on epoch=149
06/03/2022 01:04:33 - INFO - __main__ - Global step 600 Train loss 0.46 Classification-F1 0.5433612440191387 on epoch=149
06/03/2022 01:04:35 - INFO - __main__ - Step 610 Global step 610 Train loss 0.46 on epoch=152
06/03/2022 01:04:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.44 on epoch=154
06/03/2022 01:04:40 - INFO - __main__ - Step 630 Global step 630 Train loss 0.41 on epoch=157
06/03/2022 01:04:43 - INFO - __main__ - Step 640 Global step 640 Train loss 0.40 on epoch=159
06/03/2022 01:04:45 - INFO - __main__ - Step 650 Global step 650 Train loss 0.40 on epoch=162
06/03/2022 01:04:46 - INFO - __main__ - Global step 650 Train loss 0.42 Classification-F1 0.6538957688338494 on epoch=162
06/03/2022 01:04:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6401515151515151 -> 0.6538957688338494 on epoch=162, global_step=650
06/03/2022 01:04:48 - INFO - __main__ - Step 660 Global step 660 Train loss 0.40 on epoch=164
06/03/2022 01:04:51 - INFO - __main__ - Step 670 Global step 670 Train loss 0.36 on epoch=167
06/03/2022 01:04:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.31 on epoch=169
06/03/2022 01:04:56 - INFO - __main__ - Step 690 Global step 690 Train loss 0.47 on epoch=172
06/03/2022 01:04:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.37 on epoch=174
06/03/2022 01:04:59 - INFO - __main__ - Global step 700 Train loss 0.38 Classification-F1 0.6328858612168571 on epoch=174
06/03/2022 01:05:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.36 on epoch=177
06/03/2022 01:05:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.43 on epoch=179
06/03/2022 01:05:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.33 on epoch=182
06/03/2022 01:05:09 - INFO - __main__ - Step 740 Global step 740 Train loss 0.41 on epoch=184
06/03/2022 01:05:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.35 on epoch=187
06/03/2022 01:05:12 - INFO - __main__ - Global step 750 Train loss 0.38 Classification-F1 0.6551681145431146 on epoch=187
06/03/2022 01:05:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6538957688338494 -> 0.6551681145431146 on epoch=187, global_step=750
06/03/2022 01:05:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.42 on epoch=189
06/03/2022 01:05:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.33 on epoch=192
06/03/2022 01:05:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.42 on epoch=194
06/03/2022 01:05:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.37 on epoch=197
06/03/2022 01:05:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.30 on epoch=199
06/03/2022 01:05:25 - INFO - __main__ - Global step 800 Train loss 0.37 Classification-F1 0.6321969696969697 on epoch=199
06/03/2022 01:05:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=202
06/03/2022 01:05:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.31 on epoch=204
06/03/2022 01:05:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.29 on epoch=207
06/03/2022 01:05:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=209
06/03/2022 01:05:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.31 on epoch=212
06/03/2022 01:05:38 - INFO - __main__ - Global step 850 Train loss 0.29 Classification-F1 0.6339153732446415 on epoch=212
06/03/2022 01:05:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.34 on epoch=214
06/03/2022 01:05:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.24 on epoch=217
06/03/2022 01:05:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.32 on epoch=219
06/03/2022 01:05:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.28 on epoch=222
06/03/2022 01:05:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.35 on epoch=224
06/03/2022 01:05:51 - INFO - __main__ - Global step 900 Train loss 0.31 Classification-F1 0.5994781783681215 on epoch=224
06/03/2022 01:05:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.34 on epoch=227
06/03/2022 01:05:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.27 on epoch=229
06/03/2022 01:05:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.26 on epoch=232
06/03/2022 01:06:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.26 on epoch=234
06/03/2022 01:06:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.29 on epoch=237
06/03/2022 01:06:04 - INFO - __main__ - Global step 950 Train loss 0.28 Classification-F1 0.6464150432900433 on epoch=237
06/03/2022 01:06:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.26 on epoch=239
06/03/2022 01:06:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.24 on epoch=242
06/03/2022 01:06:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.25 on epoch=244
06/03/2022 01:06:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.24 on epoch=247
06/03/2022 01:06:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.25 on epoch=249
06/03/2022 01:06:17 - INFO - __main__ - Global step 1000 Train loss 0.25 Classification-F1 0.6343888580931264 on epoch=249
06/03/2022 01:06:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.27 on epoch=252
06/03/2022 01:06:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.20 on epoch=254
06/03/2022 01:06:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.29 on epoch=257
06/03/2022 01:06:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=259
06/03/2022 01:06:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.26 on epoch=262
06/03/2022 01:06:30 - INFO - __main__ - Global step 1050 Train loss 0.24 Classification-F1 0.6183860494344366 on epoch=262
06/03/2022 01:06:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.24 on epoch=264
06/03/2022 01:06:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=267
06/03/2022 01:06:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.36 on epoch=269
06/03/2022 01:06:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=272
06/03/2022 01:06:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.24 on epoch=274
06/03/2022 01:06:44 - INFO - __main__ - Global step 1100 Train loss 0.26 Classification-F1 0.6457219251336899 on epoch=274
06/03/2022 01:06:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.25 on epoch=277
06/03/2022 01:06:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.25 on epoch=279
06/03/2022 01:06:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.22 on epoch=282
06/03/2022 01:06:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.20 on epoch=284
06/03/2022 01:06:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.23 on epoch=287
06/03/2022 01:06:57 - INFO - __main__ - Global step 1150 Train loss 0.23 Classification-F1 0.6310425432445068 on epoch=287
06/03/2022 01:06:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.19 on epoch=289
06/03/2022 01:07:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.24 on epoch=292
06/03/2022 01:07:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.19 on epoch=294
06/03/2022 01:07:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=297
06/03/2022 01:07:09 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.27 on epoch=299
06/03/2022 01:07:10 - INFO - __main__ - Global step 1200 Train loss 0.22 Classification-F1 0.614520202020202 on epoch=299
06/03/2022 01:07:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.22 on epoch=302
06/03/2022 01:07:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.25 on epoch=304
06/03/2022 01:07:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.26 on epoch=307
06/03/2022 01:07:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.20 on epoch=309
06/03/2022 01:07:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.22 on epoch=312
06/03/2022 01:07:23 - INFO - __main__ - Global step 1250 Train loss 0.23 Classification-F1 0.6305704099821746 on epoch=312
06/03/2022 01:07:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=314
06/03/2022 01:07:28 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.17 on epoch=317
06/03/2022 01:07:30 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=319
06/03/2022 01:07:33 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.19 on epoch=322
06/03/2022 01:07:35 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=324
06/03/2022 01:07:36 - INFO - __main__ - Global step 1300 Train loss 0.17 Classification-F1 0.6577380952380952 on epoch=324
06/03/2022 01:07:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6551681145431146 -> 0.6577380952380952 on epoch=324, global_step=1300
06/03/2022 01:07:39 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.19 on epoch=327
06/03/2022 01:07:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.19 on epoch=329
06/03/2022 01:07:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.23 on epoch=332
06/03/2022 01:07:46 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.17 on epoch=334
06/03/2022 01:07:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=337
06/03/2022 01:07:49 - INFO - __main__ - Global step 1350 Train loss 0.19 Classification-F1 0.6577380952380952 on epoch=337
06/03/2022 01:07:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.17 on epoch=339
06/03/2022 01:07:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.14 on epoch=342
06/03/2022 01:07:57 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=344
06/03/2022 01:07:59 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=347
06/03/2022 01:08:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=349
06/03/2022 01:08:03 - INFO - __main__ - Global step 1400 Train loss 0.15 Classification-F1 0.6413338187531735 on epoch=349
06/03/2022 01:08:05 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.16 on epoch=352
06/03/2022 01:08:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.18 on epoch=354
06/03/2022 01:08:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=357
06/03/2022 01:08:12 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=359
06/03/2022 01:08:15 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=362
06/03/2022 01:08:16 - INFO - __main__ - Global step 1450 Train loss 0.15 Classification-F1 0.6559214816747098 on epoch=362
06/03/2022 01:08:18 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.18 on epoch=364
06/03/2022 01:08:21 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=367
06/03/2022 01:08:23 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.14 on epoch=369
06/03/2022 01:08:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=372
06/03/2022 01:08:28 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.15 on epoch=374
06/03/2022 01:08:29 - INFO - __main__ - Global step 1500 Train loss 0.14 Classification-F1 0.6547906285514468 on epoch=374
06/03/2022 01:08:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=377
06/03/2022 01:08:34 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=379
06/03/2022 01:08:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=382
06/03/2022 01:08:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.13 on epoch=384
06/03/2022 01:08:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=387
06/03/2022 01:08:42 - INFO - __main__ - Global step 1550 Train loss 0.11 Classification-F1 0.6547906285514468 on epoch=387
06/03/2022 01:08:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=389
06/03/2022 01:08:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.12 on epoch=392
06/03/2022 01:08:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.15 on epoch=394
06/03/2022 01:08:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=397
06/03/2022 01:08:54 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=399
06/03/2022 01:08:55 - INFO - __main__ - Global step 1600 Train loss 0.13 Classification-F1 0.627827380952381 on epoch=399
06/03/2022 01:08:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=402
06/03/2022 01:09:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.11 on epoch=404
06/03/2022 01:09:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.14 on epoch=407
06/03/2022 01:09:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.15 on epoch=409
06/03/2022 01:09:07 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.14 on epoch=412
06/03/2022 01:09:08 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.6432327476445123 on epoch=412
06/03/2022 01:09:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=414
06/03/2022 01:09:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=417
06/03/2022 01:09:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=419
06/03/2022 01:09:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=422
06/03/2022 01:09:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=424
06/03/2022 01:09:21 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.6432327476445123 on epoch=424
06/03/2022 01:09:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=427
06/03/2022 01:09:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=429
06/03/2022 01:09:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=432
06/03/2022 01:09:31 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.14 on epoch=434
06/03/2022 01:09:33 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=437
06/03/2022 01:09:34 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.6282130056323605 on epoch=437
06/03/2022 01:09:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.15 on epoch=439
06/03/2022 01:09:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.14 on epoch=442
06/03/2022 01:09:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.13 on epoch=444
06/03/2022 01:09:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=447
06/03/2022 01:09:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=449
06/03/2022 01:09:47 - INFO - __main__ - Global step 1800 Train loss 0.12 Classification-F1 0.6570307719206224 on epoch=449
06/03/2022 01:09:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=452
06/03/2022 01:09:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=454
06/03/2022 01:09:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=457
06/03/2022 01:09:57 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=459
06/03/2022 01:10:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=462
06/03/2022 01:10:01 - INFO - __main__ - Global step 1850 Train loss 0.10 Classification-F1 0.6427606177606178 on epoch=462
06/03/2022 01:10:03 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.14 on epoch=464
06/03/2022 01:10:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=467
06/03/2022 01:10:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=469
06/03/2022 01:10:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=472
06/03/2022 01:10:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=474
06/03/2022 01:10:14 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.6559214816747098 on epoch=474
06/03/2022 01:10:16 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=477
06/03/2022 01:10:19 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=479
06/03/2022 01:10:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.11 on epoch=482
06/03/2022 01:10:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=484
06/03/2022 01:10:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=487
06/03/2022 01:10:27 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.6432327476445123 on epoch=487
06/03/2022 01:10:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.13 on epoch=489
06/03/2022 01:10:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=492
06/03/2022 01:10:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=494
06/03/2022 01:10:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=497
06/03/2022 01:10:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=499
06/03/2022 01:10:40 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.6405161149825784 on epoch=499
06/03/2022 01:10:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=502
06/03/2022 01:10:45 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=504
06/03/2022 01:10:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=507
06/03/2022 01:10:50 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
06/03/2022 01:10:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=512
06/03/2022 01:10:53 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.627827380952381 on epoch=512
06/03/2022 01:10:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=514
06/03/2022 01:10:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
06/03/2022 01:11:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=519
06/03/2022 01:11:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=522
06/03/2022 01:11:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=524
06/03/2022 01:11:06 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.6641663343965976 on epoch=524
06/03/2022 01:11:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6577380952380952 -> 0.6641663343965976 on epoch=524, global_step=2100
06/03/2022 01:11:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=527
06/03/2022 01:11:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/03/2022 01:11:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=532
06/03/2022 01:11:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=534
06/03/2022 01:11:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/03/2022 01:11:19 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.6507128288378289 on epoch=537
06/03/2022 01:11:22 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=539
06/03/2022 01:11:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=542
06/03/2022 01:11:27 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/03/2022 01:11:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=547
06/03/2022 01:11:32 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=549
06/03/2022 01:11:33 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.627827380952381 on epoch=549
06/03/2022 01:11:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=552
06/03/2022 01:11:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=554
06/03/2022 01:11:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/03/2022 01:11:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.10 on epoch=559
06/03/2022 01:11:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=562
06/03/2022 01:11:46 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.6285268652915712 on epoch=562
06/03/2022 01:11:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=564
06/03/2022 01:11:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=567
06/03/2022 01:11:53 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=569
06/03/2022 01:11:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/03/2022 01:11:58 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/03/2022 01:11:59 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.651770004189359 on epoch=574
06/03/2022 01:12:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=577
06/03/2022 01:12:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=579
06/03/2022 01:12:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=582
06/03/2022 01:12:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=584
06/03/2022 01:12:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=587
06/03/2022 01:12:12 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.6641663343965976 on epoch=587
06/03/2022 01:12:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.10 on epoch=589
06/03/2022 01:12:17 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=592
06/03/2022 01:12:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=594
06/03/2022 01:12:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=597
06/03/2022 01:12:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=599
06/03/2022 01:12:25 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.6641663343965976 on epoch=599
06/03/2022 01:12:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.11 on epoch=602
06/03/2022 01:12:30 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=604
06/03/2022 01:12:33 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=607
06/03/2022 01:12:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.13 on epoch=609
06/03/2022 01:12:38 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=612
06/03/2022 01:12:39 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.6641663343965976 on epoch=612
06/03/2022 01:12:42 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.10 on epoch=614
06/03/2022 01:12:44 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=617
06/03/2022 01:12:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=619
06/03/2022 01:12:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=622
06/03/2022 01:12:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=624
06/03/2022 01:12:52 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.6931734931734931 on epoch=624
06/03/2022 01:12:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6641663343965976 -> 0.6931734931734931 on epoch=624, global_step=2500
06/03/2022 01:12:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=627
06/03/2022 01:12:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=629
06/03/2022 01:13:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=632
06/03/2022 01:13:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=634
06/03/2022 01:13:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=637
06/03/2022 01:13:06 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.6641663343965976 on epoch=637
06/03/2022 01:13:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/03/2022 01:13:11 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/03/2022 01:13:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=644
06/03/2022 01:13:16 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=647
06/03/2022 01:13:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/03/2022 01:13:19 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.6538194444444444 on epoch=649
06/03/2022 01:13:21 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/03/2022 01:13:24 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=654
06/03/2022 01:13:26 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=657
06/03/2022 01:13:29 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/03/2022 01:13:31 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/03/2022 01:13:32 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.6641663343965976 on epoch=662
06/03/2022 01:13:35 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=664
06/03/2022 01:13:37 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=667
06/03/2022 01:13:40 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=669
06/03/2022 01:13:42 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=672
06/03/2022 01:13:45 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=674
06/03/2022 01:13:45 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.6641663343965976 on epoch=674
06/03/2022 01:13:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=677
06/03/2022 01:13:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=679
06/03/2022 01:13:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
06/03/2022 01:13:55 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=684
06/03/2022 01:13:58 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/03/2022 01:13:59 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6538194444444444 on epoch=687
06/03/2022 01:14:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=689
06/03/2022 01:14:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/03/2022 01:14:06 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=694
06/03/2022 01:14:09 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/03/2022 01:14:11 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=699
06/03/2022 01:14:12 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6776747557997558 on epoch=699
06/03/2022 01:14:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=702
06/03/2022 01:14:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=704
06/03/2022 01:14:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=707
06/03/2022 01:14:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=709
06/03/2022 01:14:24 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.07 on epoch=712
06/03/2022 01:14:25 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.6641663343965976 on epoch=712
06/03/2022 01:14:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/03/2022 01:14:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=717
06/03/2022 01:14:33 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/03/2022 01:14:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=722
06/03/2022 01:14:38 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=724
06/03/2022 01:14:39 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.6693181818181817 on epoch=724
06/03/2022 01:14:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/03/2022 01:14:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=729
06/03/2022 01:14:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/03/2022 01:14:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=734
06/03/2022 01:14:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=737
06/03/2022 01:14:52 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6776747557997558 on epoch=737
06/03/2022 01:14:54 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=739
06/03/2022 01:14:57 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=742
06/03/2022 01:14:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=744
06/03/2022 01:15:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=747
06/03/2022 01:15:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/03/2022 01:15:05 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.663889742014742 on epoch=749
06/03/2022 01:15:05 - INFO - __main__ - save last model!
06/03/2022 01:15:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/03/2022 01:15:05 - INFO - __main__ - Start tokenizing ... 5509 instances
06/03/2022 01:15:05 - INFO - __main__ - Printing 3 examples
06/03/2022 01:15:05 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/03/2022 01:15:05 - INFO - __main__ - ['others']
06/03/2022 01:15:05 - INFO - __main__ -  [emo] what you like very little things ok
06/03/2022 01:15:05 - INFO - __main__ - ['others']
06/03/2022 01:15:05 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/03/2022 01:15:05 - INFO - __main__ - ['others']
06/03/2022 01:15:05 - INFO - __main__ - Tokenizing Input ...
06/03/2022 01:15:07 - INFO - __main__ - Tokenizing Output ...
06/03/2022 01:15:13 - INFO - __main__ - Loaded 5509 examples from test data
06/03/2022 01:16:33 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-emo/emo_16_87_0.2_8_predictions.txt
06/03/2022 01:16:33 - INFO - __main__ - Classification-F1 on test data: 0.3253
06/03/2022 01:16:33 - INFO - __main__ - prefix=emo_16_87, lr=0.2, bsz=8, dev_performance=0.6931734931734931, test_performance=0.32532180118413095
