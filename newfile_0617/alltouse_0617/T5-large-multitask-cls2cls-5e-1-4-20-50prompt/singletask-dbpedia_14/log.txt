06/02/2022 09:15:44 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-50prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-50prompt-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=50, cuda='4,5')
06/02/2022 09:15:44 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14
06/02/2022 09:15:44 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-50prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-50prompt-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=50, cuda='4,5')
06/02/2022 09:15:44 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14
06/02/2022 09:15:45 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/02/2022 09:15:45 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/02/2022 09:15:45 - INFO - __main__ - args.device: cuda:0
06/02/2022 09:15:45 - INFO - __main__ - Using 2 gpus
06/02/2022 09:15:45 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/02/2022 09:15:45 - INFO - __main__ - args.device: cuda:1
06/02/2022 09:15:45 - INFO - __main__ - Using 2 gpus
06/02/2022 09:15:45 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/02/2022 09:15:50 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
06/02/2022 09:15:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:15:51 - INFO - __main__ - Printing 3 examples
06/02/2022 09:15:51 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 09:15:51 - INFO - __main__ - ['Animal']
06/02/2022 09:15:51 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 09:15:51 - INFO - __main__ - ['Animal']
06/02/2022 09:15:51 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 09:15:51 - INFO - __main__ - ['Animal']
06/02/2022 09:15:51 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:15:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:15:51 - INFO - __main__ - Printing 3 examples
06/02/2022 09:15:51 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 09:15:51 - INFO - __main__ - ['Animal']
06/02/2022 09:15:51 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 09:15:51 - INFO - __main__ - ['Animal']
06/02/2022 09:15:51 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 09:15:51 - INFO - __main__ - ['Animal']
06/02/2022 09:15:51 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:15:51 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:15:51 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:15:51 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 09:15:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:15:51 - INFO - __main__ - Printing 3 examples
06/02/2022 09:15:51 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 09:15:51 - INFO - __main__ - ['Animal']
06/02/2022 09:15:51 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 09:15:51 - INFO - __main__ - ['Animal']
06/02/2022 09:15:51 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 09:15:51 - INFO - __main__ - ['Animal']
06/02/2022 09:15:51 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:15:51 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 09:15:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:15:51 - INFO - __main__ - Printing 3 examples
06/02/2022 09:15:51 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 09:15:51 - INFO - __main__ - ['Animal']
06/02/2022 09:15:51 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 09:15:51 - INFO - __main__ - ['Animal']
06/02/2022 09:15:51 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 09:15:51 - INFO - __main__ - ['Animal']
06/02/2022 09:15:51 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:15:51 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:15:52 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:15:52 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 09:15:52 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 09:16:10 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 09:16:11 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 09:16:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 09:16:11 - INFO - __main__ - Starting training!
06/02/2022 09:16:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 09:16:15 - INFO - __main__ - Starting training!
06/02/2022 09:16:18 - INFO - __main__ - Step 10 Global step 10 Train loss 5.84 on epoch=0
06/02/2022 09:16:21 - INFO - __main__ - Step 20 Global step 20 Train loss 4.00 on epoch=1
06/02/2022 09:16:23 - INFO - __main__ - Step 30 Global step 30 Train loss 3.24 on epoch=2
06/02/2022 09:16:26 - INFO - __main__ - Step 40 Global step 40 Train loss 2.92 on epoch=2
06/02/2022 09:16:28 - INFO - __main__ - Step 50 Global step 50 Train loss 2.55 on epoch=3
06/02/2022 09:16:33 - INFO - __main__ - Global step 50 Train loss 3.71 Classification-F1 0.12253708280136111 on epoch=3
06/02/2022 09:16:33 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.12253708280136111 on epoch=3, global_step=50
06/02/2022 09:16:35 - INFO - __main__ - Step 60 Global step 60 Train loss 2.66 on epoch=4
06/02/2022 09:16:38 - INFO - __main__ - Step 70 Global step 70 Train loss 1.97 on epoch=4
06/02/2022 09:16:40 - INFO - __main__ - Step 80 Global step 80 Train loss 2.07 on epoch=5
06/02/2022 09:16:43 - INFO - __main__ - Step 90 Global step 90 Train loss 1.93 on epoch=6
06/02/2022 09:16:45 - INFO - __main__ - Step 100 Global step 100 Train loss 1.83 on epoch=7
06/02/2022 09:16:50 - INFO - __main__ - Global step 100 Train loss 2.09 Classification-F1 0.16206775723838324 on epoch=7
06/02/2022 09:16:50 - INFO - __main__ - Saving model with best Classification-F1: 0.12253708280136111 -> 0.16206775723838324 on epoch=7, global_step=100
06/02/2022 09:16:52 - INFO - __main__ - Step 110 Global step 110 Train loss 1.71 on epoch=7
06/02/2022 09:16:55 - INFO - __main__ - Step 120 Global step 120 Train loss 1.58 on epoch=8
06/02/2022 09:16:57 - INFO - __main__ - Step 130 Global step 130 Train loss 1.64 on epoch=9
06/02/2022 09:17:00 - INFO - __main__ - Step 140 Global step 140 Train loss 1.26 on epoch=9
06/02/2022 09:17:02 - INFO - __main__ - Step 150 Global step 150 Train loss 1.47 on epoch=10
06/02/2022 09:17:08 - INFO - __main__ - Global step 150 Train loss 1.53 Classification-F1 0.25272171504095864 on epoch=10
06/02/2022 09:17:08 - INFO - __main__ - Saving model with best Classification-F1: 0.16206775723838324 -> 0.25272171504095864 on epoch=10, global_step=150
06/02/2022 09:17:10 - INFO - __main__ - Step 160 Global step 160 Train loss 1.17 on epoch=11
06/02/2022 09:17:13 - INFO - __main__ - Step 170 Global step 170 Train loss 1.17 on epoch=12
06/02/2022 09:17:15 - INFO - __main__ - Step 180 Global step 180 Train loss 0.98 on epoch=12
06/02/2022 09:17:18 - INFO - __main__ - Step 190 Global step 190 Train loss 1.02 on epoch=13
06/02/2022 09:17:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.91 on epoch=14
06/02/2022 09:17:26 - INFO - __main__ - Global step 200 Train loss 1.05 Classification-F1 0.39556243752784187 on epoch=14
06/02/2022 09:17:26 - INFO - __main__ - Saving model with best Classification-F1: 0.25272171504095864 -> 0.39556243752784187 on epoch=14, global_step=200
06/02/2022 09:17:28 - INFO - __main__ - Step 210 Global step 210 Train loss 0.76 on epoch=14
06/02/2022 09:17:31 - INFO - __main__ - Step 220 Global step 220 Train loss 0.76 on epoch=15
06/02/2022 09:17:33 - INFO - __main__ - Step 230 Global step 230 Train loss 0.72 on epoch=16
06/02/2022 09:17:36 - INFO - __main__ - Step 240 Global step 240 Train loss 0.69 on epoch=17
06/02/2022 09:17:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.73 on epoch=17
06/02/2022 09:17:45 - INFO - __main__ - Global step 250 Train loss 0.73 Classification-F1 0.4882765830346476 on epoch=17
06/02/2022 09:17:45 - INFO - __main__ - Saving model with best Classification-F1: 0.39556243752784187 -> 0.4882765830346476 on epoch=17, global_step=250
06/02/2022 09:17:47 - INFO - __main__ - Step 260 Global step 260 Train loss 0.65 on epoch=18
06/02/2022 09:17:50 - INFO - __main__ - Step 270 Global step 270 Train loss 0.63 on epoch=19
06/02/2022 09:17:52 - INFO - __main__ - Step 280 Global step 280 Train loss 0.45 on epoch=19
06/02/2022 09:17:55 - INFO - __main__ - Step 290 Global step 290 Train loss 0.51 on epoch=20
06/02/2022 09:17:57 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=21
06/02/2022 09:18:04 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.5376423848702075 on epoch=21
06/02/2022 09:18:04 - INFO - __main__ - Saving model with best Classification-F1: 0.4882765830346476 -> 0.5376423848702075 on epoch=21, global_step=300
06/02/2022 09:18:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.52 on epoch=22
06/02/2022 09:18:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.41 on epoch=22
06/02/2022 09:18:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.46 on epoch=23
06/02/2022 09:18:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.44 on epoch=24
06/02/2022 09:18:16 - INFO - __main__ - Step 350 Global step 350 Train loss 0.43 on epoch=24
06/02/2022 09:18:23 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.6453822499185403 on epoch=24
06/02/2022 09:18:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5376423848702075 -> 0.6453822499185403 on epoch=24, global_step=350
06/02/2022 09:18:26 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=25
06/02/2022 09:18:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.34 on epoch=26
06/02/2022 09:18:31 - INFO - __main__ - Step 380 Global step 380 Train loss 0.39 on epoch=27
06/02/2022 09:18:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.30 on epoch=27
06/02/2022 09:18:36 - INFO - __main__ - Step 400 Global step 400 Train loss 0.43 on epoch=28
06/02/2022 09:18:42 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.6951433753004211 on epoch=28
06/02/2022 09:18:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6453822499185403 -> 0.6951433753004211 on epoch=28, global_step=400
06/02/2022 09:18:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.39 on epoch=29
06/02/2022 09:18:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.32 on epoch=29
06/02/2022 09:18:50 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=30
06/02/2022 09:18:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.34 on epoch=31
06/02/2022 09:18:55 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=32
06/02/2022 09:19:02 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.7114716504066599 on epoch=32
06/02/2022 09:19:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6951433753004211 -> 0.7114716504066599 on epoch=32, global_step=450
06/02/2022 09:19:04 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=32
06/02/2022 09:19:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=33
06/02/2022 09:19:09 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=34
06/02/2022 09:19:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
06/02/2022 09:19:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=35
06/02/2022 09:19:21 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.695464335804448 on epoch=35
06/02/2022 09:19:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=36
06/02/2022 09:19:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=37
06/02/2022 09:19:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=37
06/02/2022 09:19:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=38
06/02/2022 09:19:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=39
06/02/2022 09:19:40 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.7323515169617321 on epoch=39
06/02/2022 09:19:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7114716504066599 -> 0.7323515169617321 on epoch=39, global_step=550
06/02/2022 09:19:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.32 on epoch=39
06/02/2022 09:19:45 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=40
06/02/2022 09:19:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=41
06/02/2022 09:19:50 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=42
06/02/2022 09:19:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=42
06/02/2022 09:20:00 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.6302197565243106 on epoch=42
06/02/2022 09:20:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=43
06/02/2022 09:20:05 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=44
06/02/2022 09:20:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=44
06/02/2022 09:20:10 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=45
06/02/2022 09:20:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
06/02/2022 09:20:19 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.7029664121095803 on epoch=46
06/02/2022 09:20:22 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=47
06/02/2022 09:20:24 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=47
06/02/2022 09:20:27 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=48
06/02/2022 09:20:29 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
06/02/2022 09:20:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=49
06/02/2022 09:20:38 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.6235460264262107 on epoch=49
06/02/2022 09:20:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=50
06/02/2022 09:20:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=51
06/02/2022 09:20:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=52
06/02/2022 09:20:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=52
06/02/2022 09:20:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=53
06/02/2022 09:20:58 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.8064076196764478 on epoch=53
06/02/2022 09:20:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7323515169617321 -> 0.8064076196764478 on epoch=53, global_step=750
06/02/2022 09:21:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=54
06/02/2022 09:21:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=54
06/02/2022 09:21:06 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=55
06/02/2022 09:21:08 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=56
06/02/2022 09:21:11 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
06/02/2022 09:21:17 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.8009348768446247 on epoch=57
06/02/2022 09:21:20 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=57
06/02/2022 09:21:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=58
06/02/2022 09:21:25 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=59
06/02/2022 09:21:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=59
06/02/2022 09:21:30 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=60
06/02/2022 09:21:37 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.8530094356796718 on epoch=60
06/02/2022 09:21:37 - INFO - __main__ - Saving model with best Classification-F1: 0.8064076196764478 -> 0.8530094356796718 on epoch=60, global_step=850
06/02/2022 09:21:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=61
06/02/2022 09:21:42 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=62
06/02/2022 09:21:44 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=62
06/02/2022 09:21:47 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=63
06/02/2022 09:21:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=64
06/02/2022 09:21:56 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.9052292715717762 on epoch=64
06/02/2022 09:21:56 - INFO - __main__ - Saving model with best Classification-F1: 0.8530094356796718 -> 0.9052292715717762 on epoch=64, global_step=900
06/02/2022 09:21:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=64
06/02/2022 09:22:01 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=65
06/02/2022 09:22:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=66
06/02/2022 09:22:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=67
06/02/2022 09:22:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=67
06/02/2022 09:22:15 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.9822570890526298 on epoch=67
06/02/2022 09:22:16 - INFO - __main__ - Saving model with best Classification-F1: 0.9052292715717762 -> 0.9822570890526298 on epoch=67, global_step=950
06/02/2022 09:22:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=68
06/02/2022 09:22:21 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=69
06/02/2022 09:22:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=69
06/02/2022 09:22:26 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=70
06/02/2022 09:22:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=71
06/02/2022 09:22:35 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.9777621532483962 on epoch=71
06/02/2022 09:22:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=72
06/02/2022 09:22:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
06/02/2022 09:22:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=73
06/02/2022 09:22:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
06/02/2022 09:22:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
06/02/2022 09:22:55 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.9822570890526298 on epoch=74
06/02/2022 09:22:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=75
06/02/2022 09:23:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
06/02/2022 09:23:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=77
06/02/2022 09:23:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=77
06/02/2022 09:23:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/02/2022 09:23:14 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.9146227454813792 on epoch=78
06/02/2022 09:23:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=79
06/02/2022 09:23:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=79
06/02/2022 09:23:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
06/02/2022 09:23:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
06/02/2022 09:23:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=82
06/02/2022 09:23:34 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.9146227454813792 on epoch=82
06/02/2022 09:23:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/02/2022 09:23:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
06/02/2022 09:23:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/02/2022 09:23:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/02/2022 09:23:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
06/02/2022 09:23:54 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.9146227454813792 on epoch=85
06/02/2022 09:23:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
06/02/2022 09:23:59 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/02/2022 09:24:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
06/02/2022 09:24:04 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=88
06/02/2022 09:24:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/02/2022 09:24:14 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.9104274720640945 on epoch=89
06/02/2022 09:24:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
06/02/2022 09:24:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
06/02/2022 09:24:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/02/2022 09:24:24 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
06/02/2022 09:24:27 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=92
06/02/2022 09:24:35 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.9777621532483962 on epoch=92
06/02/2022 09:24:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=93
06/02/2022 09:24:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/02/2022 09:24:43 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
06/02/2022 09:24:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
06/02/2022 09:24:48 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=96
06/02/2022 09:24:55 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.9146227454813792 on epoch=96
06/02/2022 09:24:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
06/02/2022 09:25:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
06/02/2022 09:25:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/02/2022 09:25:06 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
06/02/2022 09:25:08 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/02/2022 09:25:16 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.9867213747669157 on epoch=99
06/02/2022 09:25:16 - INFO - __main__ - Saving model with best Classification-F1: 0.9822570890526298 -> 0.9867213747669157 on epoch=99, global_step=1400
06/02/2022 09:25:19 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=100
06/02/2022 09:25:21 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=101
06/02/2022 09:25:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=102
06/02/2022 09:25:26 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/02/2022 09:25:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/02/2022 09:25:36 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.9104274720640945 on epoch=103
06/02/2022 09:25:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/02/2022 09:25:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/02/2022 09:25:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/02/2022 09:25:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/02/2022 09:25:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=107
06/02/2022 09:25:56 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.9104274720640945 on epoch=107
06/02/2022 09:25:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
06/02/2022 09:26:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
06/02/2022 09:26:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
06/02/2022 09:26:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/02/2022 09:26:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/02/2022 09:26:17 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.9187894121480459 on epoch=110
06/02/2022 09:26:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
06/02/2022 09:26:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
06/02/2022 09:26:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/02/2022 09:26:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/02/2022 09:26:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/02/2022 09:26:38 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.9146227454813792 on epoch=114
06/02/2022 09:26:40 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/02/2022 09:26:43 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=115
06/02/2022 09:26:45 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/02/2022 09:26:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
06/02/2022 09:26:51 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/02/2022 09:26:59 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.9187894121480459 on epoch=117
06/02/2022 09:27:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
06/02/2022 09:27:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
06/02/2022 09:27:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
06/02/2022 09:27:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=120
06/02/2022 09:27:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/02/2022 09:27:20 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.9187894121480459 on epoch=121
06/02/2022 09:27:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
06/02/2022 09:27:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/02/2022 09:27:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/02/2022 09:27:31 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/02/2022 09:27:34 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/02/2022 09:27:42 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.9822570890526298 on epoch=124
06/02/2022 09:27:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/02/2022 09:27:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/02/2022 09:27:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/02/2022 09:27:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/02/2022 09:27:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/02/2022 09:28:03 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.9822570890526298 on epoch=128
06/02/2022 09:28:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
06/02/2022 09:28:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/02/2022 09:28:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/02/2022 09:28:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
06/02/2022 09:28:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/02/2022 09:28:25 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.9867213747669157 on epoch=132
06/02/2022 09:28:27 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
06/02/2022 09:28:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/02/2022 09:28:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
06/02/2022 09:28:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=134
06/02/2022 09:28:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/02/2022 09:28:46 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.9820991153059465 on epoch=135
06/02/2022 09:28:48 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/02/2022 09:28:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/02/2022 09:28:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/02/2022 09:28:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/02/2022 09:28:58 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/02/2022 09:29:07 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=139
06/02/2022 09:29:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/02/2022 09:29:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=140
06/02/2022 09:29:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/02/2022 09:29:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/02/2022 09:29:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/02/2022 09:29:28 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=142
06/02/2022 09:29:31 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/02/2022 09:29:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/02/2022 09:29:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/02/2022 09:29:39 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/02/2022 09:29:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/02/2022 09:29:49 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9820991153059465 on epoch=146
06/02/2022 09:29:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/02/2022 09:29:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/02/2022 09:29:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=148
06/02/2022 09:30:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/02/2022 09:30:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/02/2022 09:30:10 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9867213747669157 on epoch=149
06/02/2022 09:30:13 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=150
06/02/2022 09:30:15 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/02/2022 09:30:18 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/02/2022 09:30:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/02/2022 09:30:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
06/02/2022 09:30:31 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.9187894121480459 on epoch=153
06/02/2022 09:30:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/02/2022 09:30:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/02/2022 09:30:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/02/2022 09:30:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
06/02/2022 09:30:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
06/02/2022 09:30:51 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.98225708905263 on epoch=157
06/02/2022 09:30:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/02/2022 09:30:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/02/2022 09:30:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/02/2022 09:31:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/02/2022 09:31:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/02/2022 09:31:12 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9867213747669157 on epoch=160
06/02/2022 09:31:15 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/02/2022 09:31:17 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/02/2022 09:31:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/02/2022 09:31:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/02/2022 09:31:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/02/2022 09:31:33 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9146186724934353 on epoch=164
06/02/2022 09:31:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=164
06/02/2022 09:31:38 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/02/2022 09:31:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/02/2022 09:31:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/02/2022 09:31:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/02/2022 09:31:53 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9146186724934353 on epoch=167
06/02/2022 09:31:56 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/02/2022 09:31:58 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/02/2022 09:32:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/02/2022 09:32:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/02/2022 09:32:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/02/2022 09:32:13 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9164955053380103 on epoch=171
06/02/2022 09:32:16 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/02/2022 09:32:18 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/02/2022 09:32:21 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/02/2022 09:32:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/02/2022 09:32:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/02/2022 09:32:33 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9123247656833996 on epoch=174
06/02/2022 09:32:36 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/02/2022 09:32:38 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/02/2022 09:32:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=177
06/02/2022 09:32:43 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/02/2022 09:32:46 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/02/2022 09:32:53 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9103086366511415 on epoch=178
06/02/2022 09:32:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/02/2022 09:32:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/02/2022 09:33:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/02/2022 09:33:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/02/2022 09:33:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/02/2022 09:33:14 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9822527251369758 on epoch=182
06/02/2022 09:33:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/02/2022 09:33:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=183
06/02/2022 09:33:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/02/2022 09:33:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/02/2022 09:33:26 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/02/2022 09:33:34 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.982226438962682 on epoch=185
06/02/2022 09:33:36 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/02/2022 09:33:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/02/2022 09:33:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/02/2022 09:33:44 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/02/2022 09:33:46 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/02/2022 09:33:54 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=189
06/02/2022 09:33:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/02/2022 09:33:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=190
06/02/2022 09:34:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/02/2022 09:34:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/02/2022 09:34:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/02/2022 09:34:14 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9867213747669157 on epoch=192
06/02/2022 09:34:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/02/2022 09:34:19 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/02/2022 09:34:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/02/2022 09:34:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/02/2022 09:34:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/02/2022 09:34:34 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9822570890526298 on epoch=196
06/02/2022 09:34:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/02/2022 09:34:39 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/02/2022 09:34:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/02/2022 09:34:44 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/02/2022 09:34:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/02/2022 09:34:54 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9822570890526298 on epoch=199
06/02/2022 09:34:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/02/2022 09:34:59 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/02/2022 09:35:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/02/2022 09:35:04 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/02/2022 09:35:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/02/2022 09:35:14 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9822570890526298 on epoch=203
06/02/2022 09:35:17 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/02/2022 09:35:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/02/2022 09:35:22 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/02/2022 09:35:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/02/2022 09:35:27 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/02/2022 09:35:35 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9867213747669157 on epoch=207
06/02/2022 09:35:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/02/2022 09:35:40 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/02/2022 09:35:43 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/02/2022 09:35:45 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/02/2022 09:35:48 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/02/2022 09:35:56 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9822527251369758 on epoch=210
06/02/2022 09:35:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/02/2022 09:36:01 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/02/2022 09:36:04 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/02/2022 09:36:06 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/02/2022 09:36:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/02/2022 09:36:10 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:36:10 - INFO - __main__ - Printing 3 examples
06/02/2022 09:36:10 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 09:36:10 - INFO - __main__ - ['Animal']
06/02/2022 09:36:10 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 09:36:10 - INFO - __main__ - ['Animal']
06/02/2022 09:36:10 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 09:36:10 - INFO - __main__ - ['Animal']
06/02/2022 09:36:10 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:36:11 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:36:11 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 09:36:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:36:11 - INFO - __main__ - Printing 3 examples
06/02/2022 09:36:11 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 09:36:11 - INFO - __main__ - ['Animal']
06/02/2022 09:36:11 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 09:36:11 - INFO - __main__ - ['Animal']
06/02/2022 09:36:11 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 09:36:11 - INFO - __main__ - ['Animal']
06/02/2022 09:36:11 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:36:11 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:36:11 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 09:36:16 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9777621532483962 on epoch=214
06/02/2022 09:36:16 - INFO - __main__ - save last model!
06/02/2022 09:36:16 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 09:36:16 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 09:36:16 - INFO - __main__ - Printing 3 examples
06/02/2022 09:36:16 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 09:36:16 - INFO - __main__ - ['Animal']
06/02/2022 09:36:16 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 09:36:16 - INFO - __main__ - ['Animal']
06/02/2022 09:36:16 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 09:36:16 - INFO - __main__ - ['Village']
06/02/2022 09:36:16 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:36:18 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:36:22 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 09:36:27 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 09:36:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 09:36:27 - INFO - __main__ - Starting training!
06/02/2022 09:38:50 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
06/02/2022 09:38:50 - INFO - __main__ - Classification-F1 on test data: 0.6168
06/02/2022 09:38:51 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.9867213747669157, test_performance=0.6167724513726328
06/02/2022 09:38:51 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
06/02/2022 09:38:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:38:52 - INFO - __main__ - Printing 3 examples
06/02/2022 09:38:52 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 09:38:52 - INFO - __main__ - ['Animal']
06/02/2022 09:38:52 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 09:38:52 - INFO - __main__ - ['Animal']
06/02/2022 09:38:52 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 09:38:52 - INFO - __main__ - ['Animal']
06/02/2022 09:38:52 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:38:52 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:38:52 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 09:38:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:38:52 - INFO - __main__ - Printing 3 examples
06/02/2022 09:38:52 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 09:38:52 - INFO - __main__ - ['Animal']
06/02/2022 09:38:52 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 09:38:52 - INFO - __main__ - ['Animal']
06/02/2022 09:38:52 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 09:38:52 - INFO - __main__ - ['Animal']
06/02/2022 09:38:52 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:38:52 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:38:52 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 09:39:10 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 09:39:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 09:39:11 - INFO - __main__ - Starting training!
06/02/2022 09:39:14 - INFO - __main__ - Step 10 Global step 10 Train loss 6.12 on epoch=0
06/02/2022 09:39:17 - INFO - __main__ - Step 20 Global step 20 Train loss 4.36 on epoch=1
06/02/2022 09:39:19 - INFO - __main__ - Step 30 Global step 30 Train loss 3.60 on epoch=2
06/02/2022 09:39:21 - INFO - __main__ - Step 40 Global step 40 Train loss 3.25 on epoch=2
06/02/2022 09:39:24 - INFO - __main__ - Step 50 Global step 50 Train loss 2.79 on epoch=3
06/02/2022 09:39:28 - INFO - __main__ - Global step 50 Train loss 4.02 Classification-F1 0.10502775749458097 on epoch=3
06/02/2022 09:39:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10502775749458097 on epoch=3, global_step=50
06/02/2022 09:39:31 - INFO - __main__ - Step 60 Global step 60 Train loss 2.89 on epoch=4
06/02/2022 09:39:33 - INFO - __main__ - Step 70 Global step 70 Train loss 2.26 on epoch=4
06/02/2022 09:39:35 - INFO - __main__ - Step 80 Global step 80 Train loss 2.43 on epoch=5
06/02/2022 09:39:38 - INFO - __main__ - Step 90 Global step 90 Train loss 2.14 on epoch=6
06/02/2022 09:39:40 - INFO - __main__ - Step 100 Global step 100 Train loss 1.97 on epoch=7
06/02/2022 09:39:45 - INFO - __main__ - Global step 100 Train loss 2.34 Classification-F1 0.14351699092529926 on epoch=7
06/02/2022 09:39:45 - INFO - __main__ - Saving model with best Classification-F1: 0.10502775749458097 -> 0.14351699092529926 on epoch=7, global_step=100
06/02/2022 09:39:47 - INFO - __main__ - Step 110 Global step 110 Train loss 1.94 on epoch=7
06/02/2022 09:39:50 - INFO - __main__ - Step 120 Global step 120 Train loss 1.89 on epoch=8
06/02/2022 09:39:52 - INFO - __main__ - Step 130 Global step 130 Train loss 1.96 on epoch=9
06/02/2022 09:39:55 - INFO - __main__ - Step 140 Global step 140 Train loss 1.51 on epoch=9
06/02/2022 09:39:57 - INFO - __main__ - Step 150 Global step 150 Train loss 1.69 on epoch=10
06/02/2022 09:40:02 - INFO - __main__ - Global step 150 Train loss 1.80 Classification-F1 0.2081017617425652 on epoch=10
06/02/2022 09:40:02 - INFO - __main__ - Saving model with best Classification-F1: 0.14351699092529926 -> 0.2081017617425652 on epoch=10, global_step=150
06/02/2022 09:40:05 - INFO - __main__ - Step 160 Global step 160 Train loss 1.53 on epoch=11
06/02/2022 09:40:07 - INFO - __main__ - Step 170 Global step 170 Train loss 1.33 on epoch=12
06/02/2022 09:40:10 - INFO - __main__ - Step 180 Global step 180 Train loss 1.37 on epoch=12
06/02/2022 09:40:12 - INFO - __main__ - Step 190 Global step 190 Train loss 1.40 on epoch=13
06/02/2022 09:40:15 - INFO - __main__ - Step 200 Global step 200 Train loss 1.29 on epoch=14
06/02/2022 09:40:20 - INFO - __main__ - Global step 200 Train loss 1.39 Classification-F1 0.29825105220065257 on epoch=14
06/02/2022 09:40:20 - INFO - __main__ - Saving model with best Classification-F1: 0.2081017617425652 -> 0.29825105220065257 on epoch=14, global_step=200
06/02/2022 09:40:22 - INFO - __main__ - Step 210 Global step 210 Train loss 1.03 on epoch=14
06/02/2022 09:40:25 - INFO - __main__ - Step 220 Global step 220 Train loss 1.09 on epoch=15
06/02/2022 09:40:27 - INFO - __main__ - Step 230 Global step 230 Train loss 0.96 on epoch=16
06/02/2022 09:40:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.85 on epoch=17
06/02/2022 09:40:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.80 on epoch=17
06/02/2022 09:40:37 - INFO - __main__ - Global step 250 Train loss 0.95 Classification-F1 0.43265254292269906 on epoch=17
06/02/2022 09:40:37 - INFO - __main__ - Saving model with best Classification-F1: 0.29825105220065257 -> 0.43265254292269906 on epoch=17, global_step=250
06/02/2022 09:40:40 - INFO - __main__ - Step 260 Global step 260 Train loss 0.92 on epoch=18
06/02/2022 09:40:42 - INFO - __main__ - Step 270 Global step 270 Train loss 0.77 on epoch=19
06/02/2022 09:40:45 - INFO - __main__ - Step 280 Global step 280 Train loss 0.63 on epoch=19
06/02/2022 09:40:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.84 on epoch=20
06/02/2022 09:40:50 - INFO - __main__ - Step 300 Global step 300 Train loss 0.78 on epoch=21
06/02/2022 09:40:56 - INFO - __main__ - Global step 300 Train loss 0.79 Classification-F1 0.4935548900392395 on epoch=21
06/02/2022 09:40:56 - INFO - __main__ - Saving model with best Classification-F1: 0.43265254292269906 -> 0.4935548900392395 on epoch=21, global_step=300
06/02/2022 09:40:58 - INFO - __main__ - Step 310 Global step 310 Train loss 0.71 on epoch=22
06/02/2022 09:41:01 - INFO - __main__ - Step 320 Global step 320 Train loss 0.57 on epoch=22
06/02/2022 09:41:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.63 on epoch=23
06/02/2022 09:41:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.52 on epoch=24
06/02/2022 09:41:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.61 on epoch=24
06/02/2022 09:41:14 - INFO - __main__ - Global step 350 Train loss 0.61 Classification-F1 0.580600790883049 on epoch=24
06/02/2022 09:41:14 - INFO - __main__ - Saving model with best Classification-F1: 0.4935548900392395 -> 0.580600790883049 on epoch=24, global_step=350
06/02/2022 09:41:17 - INFO - __main__ - Step 360 Global step 360 Train loss 0.49 on epoch=25
06/02/2022 09:41:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.55 on epoch=26
06/02/2022 09:41:22 - INFO - __main__ - Step 380 Global step 380 Train loss 0.39 on epoch=27
06/02/2022 09:41:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.47 on epoch=27
06/02/2022 09:41:27 - INFO - __main__ - Step 400 Global step 400 Train loss 0.56 on epoch=28
06/02/2022 09:41:33 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.6522843814945333 on epoch=28
06/02/2022 09:41:33 - INFO - __main__ - Saving model with best Classification-F1: 0.580600790883049 -> 0.6522843814945333 on epoch=28, global_step=400
06/02/2022 09:41:36 - INFO - __main__ - Step 410 Global step 410 Train loss 0.42 on epoch=29
06/02/2022 09:41:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=29
06/02/2022 09:41:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.39 on epoch=30
06/02/2022 09:41:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.39 on epoch=31
06/02/2022 09:41:46 - INFO - __main__ - Step 450 Global step 450 Train loss 0.38 on epoch=32
06/02/2022 09:41:53 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.6302046282833759 on epoch=32
06/02/2022 09:41:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.36 on epoch=32
06/02/2022 09:41:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.45 on epoch=33
06/02/2022 09:42:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.36 on epoch=34
06/02/2022 09:42:03 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=34
06/02/2022 09:42:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.36 on epoch=35
06/02/2022 09:42:12 - INFO - __main__ - Global step 500 Train loss 0.36 Classification-F1 0.6888403192732566 on epoch=35
06/02/2022 09:42:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6522843814945333 -> 0.6888403192732566 on epoch=35, global_step=500
06/02/2022 09:42:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=36
06/02/2022 09:42:17 - INFO - __main__ - Step 520 Global step 520 Train loss 0.31 on epoch=37
06/02/2022 09:42:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.33 on epoch=37
06/02/2022 09:42:22 - INFO - __main__ - Step 540 Global step 540 Train loss 0.33 on epoch=38
06/02/2022 09:42:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.31 on epoch=39
06/02/2022 09:42:31 - INFO - __main__ - Global step 550 Train loss 0.32 Classification-F1 0.5709078748163807 on epoch=39
06/02/2022 09:42:34 - INFO - __main__ - Step 560 Global step 560 Train loss 0.28 on epoch=39
06/02/2022 09:42:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.31 on epoch=40
06/02/2022 09:42:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=41
06/02/2022 09:42:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=42
06/02/2022 09:42:44 - INFO - __main__ - Step 600 Global step 600 Train loss 0.27 on epoch=42
06/02/2022 09:42:51 - INFO - __main__ - Global step 600 Train loss 0.27 Classification-F1 0.7952164399019518 on epoch=42
06/02/2022 09:42:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6888403192732566 -> 0.7952164399019518 on epoch=42, global_step=600
06/02/2022 09:42:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=43
06/02/2022 09:42:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=44
06/02/2022 09:42:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=44
06/02/2022 09:43:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.35 on epoch=45
06/02/2022 09:43:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=46
06/02/2022 09:43:10 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.7240795218380608 on epoch=46
06/02/2022 09:43:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=47
06/02/2022 09:43:15 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=47
06/02/2022 09:43:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.28 on epoch=48
06/02/2022 09:43:20 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
06/02/2022 09:43:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=49
06/02/2022 09:43:29 - INFO - __main__ - Global step 700 Train loss 0.24 Classification-F1 0.6582516562343412 on epoch=49
06/02/2022 09:43:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=50
06/02/2022 09:43:34 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=51
06/02/2022 09:43:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.35 on epoch=52
06/02/2022 09:43:39 - INFO - __main__ - Step 740 Global step 740 Train loss 0.24 on epoch=52
06/02/2022 09:43:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=53
06/02/2022 09:43:48 - INFO - __main__ - Global step 750 Train loss 0.25 Classification-F1 0.8069415544199108 on epoch=53
06/02/2022 09:43:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7952164399019518 -> 0.8069415544199108 on epoch=53, global_step=750
06/02/2022 09:43:51 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=54
06/02/2022 09:43:53 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=54
06/02/2022 09:43:56 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=55
06/02/2022 09:43:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
06/02/2022 09:44:01 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=57
06/02/2022 09:44:07 - INFO - __main__ - Global step 800 Train loss 0.22 Classification-F1 0.726489642998182 on epoch=57
06/02/2022 09:44:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=57
06/02/2022 09:44:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=58
06/02/2022 09:44:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=59
06/02/2022 09:44:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=59
06/02/2022 09:44:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=60
06/02/2022 09:44:26 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.8438528549249612 on epoch=60
06/02/2022 09:44:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8069415544199108 -> 0.8438528549249612 on epoch=60, global_step=850
06/02/2022 09:44:29 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=61
06/02/2022 09:44:31 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=62
06/02/2022 09:44:34 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=62
06/02/2022 09:44:36 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=63
06/02/2022 09:44:39 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=64
06/02/2022 09:44:45 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.7439078517207385 on epoch=64
06/02/2022 09:44:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=64
06/02/2022 09:44:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=65
06/02/2022 09:44:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/02/2022 09:44:55 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=67
06/02/2022 09:44:58 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=67
06/02/2022 09:45:04 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.794214451694081 on epoch=67
06/02/2022 09:45:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=68
06/02/2022 09:45:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=69
06/02/2022 09:45:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=69
06/02/2022 09:45:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=70
06/02/2022 09:45:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=71
06/02/2022 09:45:23 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.7432426175096953 on epoch=71
06/02/2022 09:45:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=72
06/02/2022 09:45:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=72
06/02/2022 09:45:31 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=73
06/02/2022 09:45:33 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=74
06/02/2022 09:45:36 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
06/02/2022 09:45:43 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.9056814579743652 on epoch=74
06/02/2022 09:45:43 - INFO - __main__ - Saving model with best Classification-F1: 0.8438528549249612 -> 0.9056814579743652 on epoch=74, global_step=1050
06/02/2022 09:45:46 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
06/02/2022 09:45:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=76
06/02/2022 09:45:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=77
06/02/2022 09:45:53 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=77
06/02/2022 09:45:56 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=78
06/02/2022 09:46:02 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.9010339981544916 on epoch=78
06/02/2022 09:46:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
06/02/2022 09:46:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
06/02/2022 09:46:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=80
06/02/2022 09:46:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
06/02/2022 09:46:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=82
06/02/2022 09:46:21 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.9061133632338566 on epoch=82
06/02/2022 09:46:21 - INFO - __main__ - Saving model with best Classification-F1: 0.9056814579743652 -> 0.9061133632338566 on epoch=82, global_step=1150
06/02/2022 09:46:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/02/2022 09:46:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=83
06/02/2022 09:46:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
06/02/2022 09:46:31 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/02/2022 09:46:33 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
06/02/2022 09:46:41 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.9777621532483962 on epoch=85
06/02/2022 09:46:41 - INFO - __main__ - Saving model with best Classification-F1: 0.9061133632338566 -> 0.9777621532483962 on epoch=85, global_step=1200
06/02/2022 09:46:44 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=86
06/02/2022 09:46:46 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=87
06/02/2022 09:46:49 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
06/02/2022 09:46:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=88
06/02/2022 09:46:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/02/2022 09:47:02 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.973139893787427 on epoch=89
06/02/2022 09:47:04 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=89
06/02/2022 09:47:07 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=90
06/02/2022 09:47:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=91
06/02/2022 09:47:12 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
06/02/2022 09:47:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
06/02/2022 09:47:22 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.9776041795017127 on epoch=92
06/02/2022 09:47:24 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=93
06/02/2022 09:47:27 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=94
06/02/2022 09:47:29 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=94
06/02/2022 09:47:32 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/02/2022 09:47:34 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/02/2022 09:47:42 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.973139893787427 on epoch=96
06/02/2022 09:47:44 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=97
06/02/2022 09:47:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
06/02/2022 09:47:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=98
06/02/2022 09:47:52 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/02/2022 09:47:55 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/02/2022 09:48:03 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.9776348295916607 on epoch=99
06/02/2022 09:48:05 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
06/02/2022 09:48:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=101
06/02/2022 09:48:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
06/02/2022 09:48:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=102
06/02/2022 09:48:15 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=103
06/02/2022 09:48:23 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.973139893787427 on epoch=103
06/02/2022 09:48:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/02/2022 09:48:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=104
06/02/2022 09:48:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/02/2022 09:48:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=106
06/02/2022 09:48:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
06/02/2022 09:48:44 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.982226438962682 on epoch=107
06/02/2022 09:48:44 - INFO - __main__ - Saving model with best Classification-F1: 0.9777621532483962 -> 0.982226438962682 on epoch=107, global_step=1500
06/02/2022 09:48:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=107
06/02/2022 09:48:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
06/02/2022 09:48:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
06/02/2022 09:48:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/02/2022 09:48:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/02/2022 09:49:05 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.9822570890526298 on epoch=110
06/02/2022 09:49:05 - INFO - __main__ - Saving model with best Classification-F1: 0.982226438962682 -> 0.9822570890526298 on epoch=110, global_step=1550
06/02/2022 09:49:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/02/2022 09:49:10 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/02/2022 09:49:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
06/02/2022 09:49:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
06/02/2022 09:49:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/02/2022 09:49:26 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.9822570890526298 on epoch=114
06/02/2022 09:49:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=114
06/02/2022 09:49:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=115
06/02/2022 09:49:33 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/02/2022 09:49:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=117
06/02/2022 09:49:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/02/2022 09:49:46 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.9822570890526298 on epoch=117
06/02/2022 09:49:49 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.15 on epoch=118
06/02/2022 09:49:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/02/2022 09:49:54 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/02/2022 09:49:56 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/02/2022 09:49:59 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
06/02/2022 09:50:07 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.9822570890526298 on epoch=121
06/02/2022 09:50:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
06/02/2022 09:50:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
06/02/2022 09:50:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/02/2022 09:50:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
06/02/2022 09:50:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=124
06/02/2022 09:50:29 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.9822570890526298 on epoch=124
06/02/2022 09:50:31 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
06/02/2022 09:50:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
06/02/2022 09:50:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=127
06/02/2022 09:50:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/02/2022 09:50:41 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=128
06/02/2022 09:50:50 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.9822570890526298 on epoch=128
06/02/2022 09:50:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
06/02/2022 09:50:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/02/2022 09:50:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=130
06/02/2022 09:51:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/02/2022 09:51:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
06/02/2022 09:51:11 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.9146227454813792 on epoch=132
06/02/2022 09:51:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
06/02/2022 09:51:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
06/02/2022 09:51:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=134
06/02/2022 09:51:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/02/2022 09:51:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/02/2022 09:51:32 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.9062567324094838 on epoch=135
06/02/2022 09:51:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/02/2022 09:51:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/02/2022 09:51:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/02/2022 09:51:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=138
06/02/2022 09:51:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/02/2022 09:51:52 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.9104520058267686 on epoch=139
06/02/2022 09:51:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.12 on epoch=139
06/02/2022 09:51:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=140
06/02/2022 09:52:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/02/2022 09:52:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/02/2022 09:52:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/02/2022 09:52:13 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.9104233990761508 on epoch=142
06/02/2022 09:52:16 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/02/2022 09:52:19 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/02/2022 09:52:21 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/02/2022 09:52:24 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/02/2022 09:52:26 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/02/2022 09:52:35 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.9104233990761508 on epoch=146
06/02/2022 09:52:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/02/2022 09:52:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
06/02/2022 09:52:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
06/02/2022 09:52:45 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=149
06/02/2022 09:52:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/02/2022 09:52:56 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9104233990761508 on epoch=149
06/02/2022 09:52:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/02/2022 09:53:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/02/2022 09:53:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/02/2022 09:53:06 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/02/2022 09:53:08 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
06/02/2022 09:53:17 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.9104233990761508 on epoch=153
06/02/2022 09:53:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/02/2022 09:53:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/02/2022 09:53:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=155
06/02/2022 09:53:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/02/2022 09:53:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
06/02/2022 09:53:39 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.9146186724934353 on epoch=157
06/02/2022 09:53:41 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/02/2022 09:53:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/02/2022 09:53:46 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/02/2022 09:53:49 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
06/02/2022 09:53:51 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
06/02/2022 09:54:00 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.9146227454813792 on epoch=160
06/02/2022 09:54:03 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=161
06/02/2022 09:54:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/02/2022 09:54:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/02/2022 09:54:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/02/2022 09:54:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/02/2022 09:54:21 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9186746497230369 on epoch=164
06/02/2022 09:54:24 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/02/2022 09:54:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.13 on epoch=165
06/02/2022 09:54:29 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/02/2022 09:54:31 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=167
06/02/2022 09:54:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/02/2022 09:54:43 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.9186746497230369 on epoch=167
06/02/2022 09:54:46 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/02/2022 09:54:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/02/2022 09:54:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/02/2022 09:54:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/02/2022 09:54:56 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
06/02/2022 09:55:04 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9821034792216007 on epoch=171
06/02/2022 09:55:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/02/2022 09:55:09 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/02/2022 09:55:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/02/2022 09:55:14 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/02/2022 09:55:17 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/02/2022 09:55:26 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9186746497230369 on epoch=174
06/02/2022 09:55:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
06/02/2022 09:55:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/02/2022 09:55:34 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=177
06/02/2022 09:55:36 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/02/2022 09:55:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=178
06/02/2022 09:55:47 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9228413163897036 on epoch=178
06/02/2022 09:55:50 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/02/2022 09:55:52 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/02/2022 09:55:55 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/02/2022 09:55:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/02/2022 09:56:00 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/02/2022 09:56:09 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9186746497230369 on epoch=182
06/02/2022 09:56:11 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/02/2022 09:56:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
06/02/2022 09:56:16 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/02/2022 09:56:19 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/02/2022 09:56:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/02/2022 09:56:31 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9228413163897036 on epoch=185
06/02/2022 09:56:33 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
06/02/2022 09:56:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/02/2022 09:56:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/02/2022 09:56:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=188
06/02/2022 09:56:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/02/2022 09:56:53 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.9104520058267686 on epoch=189
06/02/2022 09:56:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/02/2022 09:56:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/02/2022 09:57:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
06/02/2022 09:57:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/02/2022 09:57:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=192
06/02/2022 09:57:14 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.9146186724934353 on epoch=192
06/02/2022 09:57:17 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/02/2022 09:57:19 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=194
06/02/2022 09:57:22 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/02/2022 09:57:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/02/2022 09:57:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/02/2022 09:57:35 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9146186724934353 on epoch=196
06/02/2022 09:57:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/02/2022 09:57:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/02/2022 09:57:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/02/2022 09:57:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/02/2022 09:57:48 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
06/02/2022 09:57:56 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9822527251369758 on epoch=199
06/02/2022 09:57:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/02/2022 09:58:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/02/2022 09:58:04 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/02/2022 09:58:06 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.12 on epoch=202
06/02/2022 09:58:09 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
06/02/2022 09:58:17 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.9146227454813792 on epoch=203
06/02/2022 09:58:20 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/02/2022 09:58:22 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/02/2022 09:58:25 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/02/2022 09:58:27 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/02/2022 09:58:30 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/02/2022 09:58:39 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9104520058267686 on epoch=207
06/02/2022 09:58:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/02/2022 09:58:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/02/2022 09:58:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/02/2022 09:58:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/02/2022 09:58:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/02/2022 09:59:00 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9104520058267686 on epoch=210
06/02/2022 09:59:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/02/2022 09:59:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/02/2022 09:59:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/02/2022 09:59:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/02/2022 09:59:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/02/2022 09:59:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:59:14 - INFO - __main__ - Printing 3 examples
06/02/2022 09:59:14 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 09:59:14 - INFO - __main__ - ['Animal']
06/02/2022 09:59:14 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 09:59:14 - INFO - __main__ - ['Animal']
06/02/2022 09:59:14 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 09:59:14 - INFO - __main__ - ['Animal']
06/02/2022 09:59:14 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:59:14 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:59:14 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 09:59:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:59:14 - INFO - __main__ - Printing 3 examples
06/02/2022 09:59:14 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 09:59:14 - INFO - __main__ - ['Animal']
06/02/2022 09:59:14 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 09:59:14 - INFO - __main__ - ['Animal']
06/02/2022 09:59:14 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 09:59:14 - INFO - __main__ - ['Animal']
06/02/2022 09:59:14 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:59:14 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:59:14 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 09:59:21 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9081580990167327 on epoch=214
06/02/2022 09:59:21 - INFO - __main__ - save last model!
06/02/2022 09:59:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 09:59:21 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 09:59:21 - INFO - __main__ - Printing 3 examples
06/02/2022 09:59:21 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 09:59:21 - INFO - __main__ - ['Animal']
06/02/2022 09:59:21 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 09:59:21 - INFO - __main__ - ['Animal']
06/02/2022 09:59:21 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 09:59:21 - INFO - __main__ - ['Village']
06/02/2022 09:59:21 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:59:23 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:59:26 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 09:59:30 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 09:59:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 09:59:30 - INFO - __main__ - Starting training!
06/02/2022 10:02:23 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
06/02/2022 10:02:23 - INFO - __main__ - Classification-F1 on test data: 0.5430
06/02/2022 10:02:23 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.9822570890526298, test_performance=0.543025415250526
06/02/2022 10:02:23 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
06/02/2022 10:02:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 10:02:24 - INFO - __main__ - Printing 3 examples
06/02/2022 10:02:24 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 10:02:24 - INFO - __main__ - ['Animal']
06/02/2022 10:02:24 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 10:02:24 - INFO - __main__ - ['Animal']
06/02/2022 10:02:24 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 10:02:24 - INFO - __main__ - ['Animal']
06/02/2022 10:02:24 - INFO - __main__ - Tokenizing Input ...
06/02/2022 10:02:24 - INFO - __main__ - Tokenizing Output ...
06/02/2022 10:02:24 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 10:02:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 10:02:24 - INFO - __main__ - Printing 3 examples
06/02/2022 10:02:24 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 10:02:24 - INFO - __main__ - ['Animal']
06/02/2022 10:02:24 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 10:02:24 - INFO - __main__ - ['Animal']
06/02/2022 10:02:24 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 10:02:24 - INFO - __main__ - ['Animal']
06/02/2022 10:02:24 - INFO - __main__ - Tokenizing Input ...
06/02/2022 10:02:25 - INFO - __main__ - Tokenizing Output ...
06/02/2022 10:02:25 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 10:02:41 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 10:02:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 10:02:42 - INFO - __main__ - Starting training!
06/02/2022 10:02:46 - INFO - __main__ - Step 10 Global step 10 Train loss 6.51 on epoch=0
06/02/2022 10:02:48 - INFO - __main__ - Step 20 Global step 20 Train loss 4.74 on epoch=1
06/02/2022 10:02:51 - INFO - __main__ - Step 30 Global step 30 Train loss 4.13 on epoch=2
06/02/2022 10:02:53 - INFO - __main__ - Step 40 Global step 40 Train loss 3.60 on epoch=2
06/02/2022 10:02:55 - INFO - __main__ - Step 50 Global step 50 Train loss 3.34 on epoch=3
06/02/2022 10:03:00 - INFO - __main__ - Global step 50 Train loss 4.46 Classification-F1 0.08160034926759924 on epoch=3
06/02/2022 10:03:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08160034926759924 on epoch=3, global_step=50
06/02/2022 10:03:02 - INFO - __main__ - Step 60 Global step 60 Train loss 3.31 on epoch=4
06/02/2022 10:03:05 - INFO - __main__ - Step 70 Global step 70 Train loss 2.60 on epoch=4
06/02/2022 10:03:07 - INFO - __main__ - Step 80 Global step 80 Train loss 2.60 on epoch=5
06/02/2022 10:03:10 - INFO - __main__ - Step 90 Global step 90 Train loss 2.32 on epoch=6
06/02/2022 10:03:12 - INFO - __main__ - Step 100 Global step 100 Train loss 2.31 on epoch=7
06/02/2022 10:03:17 - INFO - __main__ - Global step 100 Train loss 2.63 Classification-F1 0.12547860721349471 on epoch=7
06/02/2022 10:03:17 - INFO - __main__ - Saving model with best Classification-F1: 0.08160034926759924 -> 0.12547860721349471 on epoch=7, global_step=100
06/02/2022 10:03:19 - INFO - __main__ - Step 110 Global step 110 Train loss 2.28 on epoch=7
06/02/2022 10:03:22 - INFO - __main__ - Step 120 Global step 120 Train loss 2.12 on epoch=8
06/02/2022 10:03:24 - INFO - __main__ - Step 130 Global step 130 Train loss 2.20 on epoch=9
06/02/2022 10:03:27 - INFO - __main__ - Step 140 Global step 140 Train loss 1.72 on epoch=9
06/02/2022 10:03:29 - INFO - __main__ - Step 150 Global step 150 Train loss 1.98 on epoch=10
06/02/2022 10:03:34 - INFO - __main__ - Global step 150 Train loss 2.06 Classification-F1 0.1576797713729906 on epoch=10
06/02/2022 10:03:34 - INFO - __main__ - Saving model with best Classification-F1: 0.12547860721349471 -> 0.1576797713729906 on epoch=10, global_step=150
06/02/2022 10:03:36 - INFO - __main__ - Step 160 Global step 160 Train loss 1.75 on epoch=11
06/02/2022 10:03:39 - INFO - __main__ - Step 170 Global step 170 Train loss 1.81 on epoch=12
06/02/2022 10:03:41 - INFO - __main__ - Step 180 Global step 180 Train loss 1.59 on epoch=12
06/02/2022 10:03:44 - INFO - __main__ - Step 190 Global step 190 Train loss 1.50 on epoch=13
06/02/2022 10:03:46 - INFO - __main__ - Step 200 Global step 200 Train loss 1.70 on epoch=14
06/02/2022 10:03:51 - INFO - __main__ - Global step 200 Train loss 1.67 Classification-F1 0.2000516649803972 on epoch=14
06/02/2022 10:03:51 - INFO - __main__ - Saving model with best Classification-F1: 0.1576797713729906 -> 0.2000516649803972 on epoch=14, global_step=200
06/02/2022 10:03:54 - INFO - __main__ - Step 210 Global step 210 Train loss 1.39 on epoch=14
06/02/2022 10:03:56 - INFO - __main__ - Step 220 Global step 220 Train loss 1.46 on epoch=15
06/02/2022 10:03:59 - INFO - __main__ - Step 230 Global step 230 Train loss 1.44 on epoch=16
06/02/2022 10:04:01 - INFO - __main__ - Step 240 Global step 240 Train loss 1.38 on epoch=17
06/02/2022 10:04:04 - INFO - __main__ - Step 250 Global step 250 Train loss 1.19 on epoch=17
06/02/2022 10:04:09 - INFO - __main__ - Global step 250 Train loss 1.37 Classification-F1 0.26693205602798137 on epoch=17
06/02/2022 10:04:09 - INFO - __main__ - Saving model with best Classification-F1: 0.2000516649803972 -> 0.26693205602798137 on epoch=17, global_step=250
06/02/2022 10:04:12 - INFO - __main__ - Step 260 Global step 260 Train loss 1.26 on epoch=18
06/02/2022 10:04:14 - INFO - __main__ - Step 270 Global step 270 Train loss 1.27 on epoch=19
06/02/2022 10:04:17 - INFO - __main__ - Step 280 Global step 280 Train loss 1.06 on epoch=19
06/02/2022 10:04:19 - INFO - __main__ - Step 290 Global step 290 Train loss 1.12 on epoch=20
06/02/2022 10:04:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.88 on epoch=21
06/02/2022 10:04:27 - INFO - __main__ - Global step 300 Train loss 1.12 Classification-F1 0.3374698877033988 on epoch=21
06/02/2022 10:04:27 - INFO - __main__ - Saving model with best Classification-F1: 0.26693205602798137 -> 0.3374698877033988 on epoch=21, global_step=300
06/02/2022 10:04:29 - INFO - __main__ - Step 310 Global step 310 Train loss 0.92 on epoch=22
06/02/2022 10:04:32 - INFO - __main__ - Step 320 Global step 320 Train loss 0.93 on epoch=22
06/02/2022 10:04:34 - INFO - __main__ - Step 330 Global step 330 Train loss 0.88 on epoch=23
06/02/2022 10:04:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.87 on epoch=24
06/02/2022 10:04:39 - INFO - __main__ - Step 350 Global step 350 Train loss 0.79 on epoch=24
06/02/2022 10:04:45 - INFO - __main__ - Global step 350 Train loss 0.88 Classification-F1 0.3959204013205586 on epoch=24
06/02/2022 10:04:45 - INFO - __main__ - Saving model with best Classification-F1: 0.3374698877033988 -> 0.3959204013205586 on epoch=24, global_step=350
06/02/2022 10:04:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.80 on epoch=25
06/02/2022 10:04:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.69 on epoch=26
06/02/2022 10:04:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.72 on epoch=27
06/02/2022 10:04:54 - INFO - __main__ - Step 390 Global step 390 Train loss 0.68 on epoch=27
06/02/2022 10:04:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.67 on epoch=28
06/02/2022 10:05:03 - INFO - __main__ - Global step 400 Train loss 0.71 Classification-F1 0.518774234799109 on epoch=28
06/02/2022 10:05:03 - INFO - __main__ - Saving model with best Classification-F1: 0.3959204013205586 -> 0.518774234799109 on epoch=28, global_step=400
06/02/2022 10:05:05 - INFO - __main__ - Step 410 Global step 410 Train loss 0.66 on epoch=29
06/02/2022 10:05:07 - INFO - __main__ - Step 420 Global step 420 Train loss 0.54 on epoch=29
06/02/2022 10:05:10 - INFO - __main__ - Step 430 Global step 430 Train loss 0.58 on epoch=30
06/02/2022 10:05:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.53 on epoch=31
06/02/2022 10:05:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.59 on epoch=32
06/02/2022 10:05:21 - INFO - __main__ - Global step 450 Train loss 0.58 Classification-F1 0.6273494241968199 on epoch=32
06/02/2022 10:05:21 - INFO - __main__ - Saving model with best Classification-F1: 0.518774234799109 -> 0.6273494241968199 on epoch=32, global_step=450
06/02/2022 10:05:24 - INFO - __main__ - Step 460 Global step 460 Train loss 0.50 on epoch=32
06/02/2022 10:05:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.54 on epoch=33
06/02/2022 10:05:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.51 on epoch=34
06/02/2022 10:05:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.47 on epoch=34
06/02/2022 10:05:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.52 on epoch=35
06/02/2022 10:05:40 - INFO - __main__ - Global step 500 Train loss 0.51 Classification-F1 0.5923416036425375 on epoch=35
06/02/2022 10:05:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.43 on epoch=36
06/02/2022 10:05:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.44 on epoch=37
06/02/2022 10:05:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.44 on epoch=37
06/02/2022 10:05:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.46 on epoch=38
06/02/2022 10:05:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.56 on epoch=39
06/02/2022 10:05:59 - INFO - __main__ - Global step 550 Train loss 0.47 Classification-F1 0.642336062235256 on epoch=39
06/02/2022 10:05:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6273494241968199 -> 0.642336062235256 on epoch=39, global_step=550
06/02/2022 10:06:01 - INFO - __main__ - Step 560 Global step 560 Train loss 0.39 on epoch=39
06/02/2022 10:06:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.41 on epoch=40
06/02/2022 10:06:06 - INFO - __main__ - Step 580 Global step 580 Train loss 0.36 on epoch=41
06/02/2022 10:06:09 - INFO - __main__ - Step 590 Global step 590 Train loss 0.40 on epoch=42
06/02/2022 10:06:11 - INFO - __main__ - Step 600 Global step 600 Train loss 0.30 on epoch=42
06/02/2022 10:06:18 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.7130561225793675 on epoch=42
06/02/2022 10:06:18 - INFO - __main__ - Saving model with best Classification-F1: 0.642336062235256 -> 0.7130561225793675 on epoch=42, global_step=600
06/02/2022 10:06:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.50 on epoch=43
06/02/2022 10:06:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.33 on epoch=44
06/02/2022 10:06:25 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=44
06/02/2022 10:06:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.37 on epoch=45
06/02/2022 10:06:30 - INFO - __main__ - Step 650 Global step 650 Train loss 0.28 on epoch=46
06/02/2022 10:06:36 - INFO - __main__ - Global step 650 Train loss 0.36 Classification-F1 0.6098532765990072 on epoch=46
06/02/2022 10:06:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.37 on epoch=47
06/02/2022 10:06:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=47
06/02/2022 10:06:44 - INFO - __main__ - Step 680 Global step 680 Train loss 0.38 on epoch=48
06/02/2022 10:06:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.32 on epoch=49
06/02/2022 10:06:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.31 on epoch=49
06/02/2022 10:06:55 - INFO - __main__ - Global step 700 Train loss 0.33 Classification-F1 0.6501201531443467 on epoch=49
06/02/2022 10:06:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.34 on epoch=50
06/02/2022 10:07:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.39 on epoch=51
06/02/2022 10:07:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.31 on epoch=52
06/02/2022 10:07:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=52
06/02/2022 10:07:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.27 on epoch=53
06/02/2022 10:07:14 - INFO - __main__ - Global step 750 Train loss 0.32 Classification-F1 0.506282991202346 on epoch=53
06/02/2022 10:07:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.28 on epoch=54
06/02/2022 10:07:19 - INFO - __main__ - Step 770 Global step 770 Train loss 0.29 on epoch=54
06/02/2022 10:07:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.31 on epoch=55
06/02/2022 10:07:24 - INFO - __main__ - Step 790 Global step 790 Train loss 0.23 on epoch=56
06/02/2022 10:07:27 - INFO - __main__ - Step 800 Global step 800 Train loss 0.30 on epoch=57
06/02/2022 10:07:33 - INFO - __main__ - Global step 800 Train loss 0.28 Classification-F1 0.6938872269080498 on epoch=57
06/02/2022 10:07:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=57
06/02/2022 10:07:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.28 on epoch=58
06/02/2022 10:07:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.26 on epoch=59
06/02/2022 10:07:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.28 on epoch=59
06/02/2022 10:07:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.33 on epoch=60
06/02/2022 10:07:52 - INFO - __main__ - Global step 850 Train loss 0.27 Classification-F1 0.5602147102423916 on epoch=60
06/02/2022 10:07:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=61
06/02/2022 10:07:57 - INFO - __main__ - Step 870 Global step 870 Train loss 0.26 on epoch=62
06/02/2022 10:08:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.23 on epoch=62
06/02/2022 10:08:02 - INFO - __main__ - Step 890 Global step 890 Train loss 0.24 on epoch=63
06/02/2022 10:08:05 - INFO - __main__ - Step 900 Global step 900 Train loss 0.24 on epoch=64
06/02/2022 10:08:11 - INFO - __main__ - Global step 900 Train loss 0.24 Classification-F1 0.6044832791376569 on epoch=64
06/02/2022 10:08:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.21 on epoch=64
06/02/2022 10:08:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.27 on epoch=65
06/02/2022 10:08:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=66
06/02/2022 10:08:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=67
06/02/2022 10:08:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=67
06/02/2022 10:08:31 - INFO - __main__ - Global step 950 Train loss 0.22 Classification-F1 0.6900797794036584 on epoch=67
06/02/2022 10:08:33 - INFO - __main__ - Step 960 Global step 960 Train loss 0.22 on epoch=68
06/02/2022 10:08:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=69
06/02/2022 10:08:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=69
06/02/2022 10:08:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=70
06/02/2022 10:08:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=71
06/02/2022 10:08:50 - INFO - __main__ - Global step 1000 Train loss 0.20 Classification-F1 0.7046551258725976 on epoch=71
06/02/2022 10:08:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=72
06/02/2022 10:08:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.23 on epoch=72
06/02/2022 10:08:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.30 on epoch=73
06/02/2022 10:09:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=74
06/02/2022 10:09:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.20 on epoch=74
06/02/2022 10:09:09 - INFO - __main__ - Global step 1050 Train loss 0.22 Classification-F1 0.7210908502928876 on epoch=74
06/02/2022 10:09:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7130561225793675 -> 0.7210908502928876 on epoch=74, global_step=1050
06/02/2022 10:09:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=75
06/02/2022 10:09:14 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=76
06/02/2022 10:09:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=77
06/02/2022 10:09:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=77
06/02/2022 10:09:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=78
06/02/2022 10:09:28 - INFO - __main__ - Global step 1100 Train loss 0.16 Classification-F1 0.7066277242847702 on epoch=78
06/02/2022 10:09:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.19 on epoch=79
06/02/2022 10:09:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=79
06/02/2022 10:09:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.18 on epoch=80
06/02/2022 10:09:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=81
06/02/2022 10:09:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.19 on epoch=82
06/02/2022 10:09:47 - INFO - __main__ - Global step 1150 Train loss 0.18 Classification-F1 0.7916664715275051 on epoch=82
06/02/2022 10:09:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7210908502928876 -> 0.7916664715275051 on epoch=82, global_step=1150
06/02/2022 10:09:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=82
06/02/2022 10:09:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=83
06/02/2022 10:09:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.20 on epoch=84
06/02/2022 10:09:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=84
06/02/2022 10:10:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
06/02/2022 10:10:07 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.9002609374367755 on epoch=85
06/02/2022 10:10:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7916664715275051 -> 0.9002609374367755 on epoch=85, global_step=1200
06/02/2022 10:10:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=86
06/02/2022 10:10:12 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=87
06/02/2022 10:10:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
06/02/2022 10:10:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=88
06/02/2022 10:10:20 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=89
06/02/2022 10:10:27 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.9777621532483962 on epoch=89
06/02/2022 10:10:27 - INFO - __main__ - Saving model with best Classification-F1: 0.9002609374367755 -> 0.9777621532483962 on epoch=89, global_step=1250
06/02/2022 10:10:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=89
06/02/2022 10:10:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=90
06/02/2022 10:10:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=91
06/02/2022 10:10:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.21 on epoch=92
06/02/2022 10:10:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=92
06/02/2022 10:10:46 - INFO - __main__ - Global step 1300 Train loss 0.14 Classification-F1 0.9062682326107373 on epoch=92
06/02/2022 10:10:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=93
06/02/2022 10:10:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.21 on epoch=94
06/02/2022 10:10:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=94
06/02/2022 10:10:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=95
06/02/2022 10:10:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=96
06/02/2022 10:11:05 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.9104274720640945 on epoch=96
06/02/2022 10:11:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=97
06/02/2022 10:11:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=97
06/02/2022 10:11:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=98
06/02/2022 10:11:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=99
06/02/2022 10:11:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=99
06/02/2022 10:11:24 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.9777928033383442 on epoch=99
06/02/2022 10:11:24 - INFO - __main__ - Saving model with best Classification-F1: 0.9777621532483962 -> 0.9777928033383442 on epoch=99, global_step=1400
06/02/2022 10:11:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=100
06/02/2022 10:11:29 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
06/02/2022 10:11:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.16 on epoch=102
06/02/2022 10:11:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=102
06/02/2022 10:11:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/02/2022 10:11:43 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.910438972265348 on epoch=103
06/02/2022 10:11:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=104
06/02/2022 10:11:48 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=104
06/02/2022 10:11:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=105
06/02/2022 10:11:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=106
06/02/2022 10:11:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=107
06/02/2022 10:12:03 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.982226438962682 on epoch=107
06/02/2022 10:12:03 - INFO - __main__ - Saving model with best Classification-F1: 0.9777928033383442 -> 0.982226438962682 on epoch=107, global_step=1500
06/02/2022 10:12:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=107
06/02/2022 10:12:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=108
06/02/2022 10:12:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
06/02/2022 10:12:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
06/02/2022 10:12:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=110
06/02/2022 10:12:22 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.982226438962682 on epoch=110
06/02/2022 10:12:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=111
06/02/2022 10:12:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=112
06/02/2022 10:12:30 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
06/02/2022 10:12:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.18 on epoch=113
06/02/2022 10:12:35 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=114
06/02/2022 10:12:42 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.982226438962682 on epoch=114
06/02/2022 10:12:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=114
06/02/2022 10:12:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=115
06/02/2022 10:12:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=116
06/02/2022 10:12:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=117
06/02/2022 10:12:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=117
06/02/2022 10:13:02 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.977757789332742 on epoch=117
06/02/2022 10:13:04 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=118
06/02/2022 10:13:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=119
06/02/2022 10:13:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/02/2022 10:13:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
06/02/2022 10:13:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=121
06/02/2022 10:13:22 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.9777621532483962 on epoch=121
06/02/2022 10:13:25 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=122
06/02/2022 10:13:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
06/02/2022 10:13:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=123
06/02/2022 10:13:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=124
06/02/2022 10:13:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=124
06/02/2022 10:13:42 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.9017598893469142 on epoch=124
06/02/2022 10:13:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=125
06/02/2022 10:13:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=126
06/02/2022 10:13:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.13 on epoch=127
06/02/2022 10:13:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=127
06/02/2022 10:13:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=128
06/02/2022 10:14:02 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.9104233990761508 on epoch=128
06/02/2022 10:14:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=129
06/02/2022 10:14:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
06/02/2022 10:14:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=130
06/02/2022 10:14:12 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=131
06/02/2022 10:14:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.11 on epoch=132
06/02/2022 10:14:22 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.982226438962682 on epoch=132
06/02/2022 10:14:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
06/02/2022 10:14:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=133
06/02/2022 10:14:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=134
06/02/2022 10:14:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/02/2022 10:14:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
06/02/2022 10:14:42 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.9104274720640945 on epoch=135
06/02/2022 10:14:44 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.10 on epoch=136
06/02/2022 10:14:47 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=137
06/02/2022 10:14:49 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
06/02/2022 10:14:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
06/02/2022 10:14:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=139
06/02/2022 10:15:01 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.9777621532483962 on epoch=139
06/02/2022 10:15:04 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
06/02/2022 10:15:06 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/02/2022 10:15:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=141
06/02/2022 10:15:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.10 on epoch=142
06/02/2022 10:15:14 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/02/2022 10:15:21 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.9145941387307611 on epoch=142
06/02/2022 10:15:24 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.10 on epoch=143
06/02/2022 10:15:27 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=144
06/02/2022 10:15:30 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
06/02/2022 10:15:32 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=145
06/02/2022 10:15:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/02/2022 10:15:42 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.9104274720640945 on epoch=146
06/02/2022 10:15:45 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=147
06/02/2022 10:15:47 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
06/02/2022 10:15:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=148
06/02/2022 10:15:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.16 on epoch=149
06/02/2022 10:15:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
06/02/2022 10:16:03 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.9104274720640945 on epoch=149
06/02/2022 10:16:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
06/02/2022 10:16:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/02/2022 10:16:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=152
06/02/2022 10:16:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=152
06/02/2022 10:16:17 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/02/2022 10:16:25 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.9123002319207252 on epoch=153
06/02/2022 10:16:27 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=154
06/02/2022 10:16:30 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=154
06/02/2022 10:16:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.10 on epoch=155
06/02/2022 10:16:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=156
06/02/2022 10:16:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=157
06/02/2022 10:16:46 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.9081294922661148 on epoch=157
06/02/2022 10:16:49 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/02/2022 10:16:52 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.17 on epoch=158
06/02/2022 10:16:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=159
06/02/2022 10:16:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
06/02/2022 10:16:59 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.09 on epoch=160
06/02/2022 10:17:07 - INFO - __main__ - Global step 2250 Train loss 0.09 Classification-F1 0.9019426235792461 on epoch=160
06/02/2022 10:17:10 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=161
06/02/2022 10:17:12 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/02/2022 10:17:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/02/2022 10:17:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/02/2022 10:17:20 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=164
06/02/2022 10:17:27 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.903962825599448 on epoch=164
06/02/2022 10:17:30 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/02/2022 10:17:32 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
06/02/2022 10:17:35 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/02/2022 10:17:37 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/02/2022 10:17:40 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
06/02/2022 10:17:48 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.9104233990761508 on epoch=167
06/02/2022 10:17:50 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/02/2022 10:17:53 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/02/2022 10:17:55 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/02/2022 10:17:58 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/02/2022 10:18:00 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/02/2022 10:18:08 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.9146186724934355 on epoch=171
06/02/2022 10:18:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/02/2022 10:18:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/02/2022 10:18:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
06/02/2022 10:18:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=174
06/02/2022 10:18:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=174
06/02/2022 10:18:29 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.9104233990761508 on epoch=174
06/02/2022 10:18:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=175
06/02/2022 10:18:34 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/02/2022 10:18:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/02/2022 10:18:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=177
06/02/2022 10:18:42 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/02/2022 10:18:50 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.9103045636631976 on epoch=178
06/02/2022 10:18:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/02/2022 10:18:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/02/2022 10:18:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/02/2022 10:19:00 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=181
06/02/2022 10:19:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/02/2022 10:19:11 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.9104233990761508 on epoch=182
06/02/2022 10:19:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=182
06/02/2022 10:19:16 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/02/2022 10:19:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
06/02/2022 10:19:21 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/02/2022 10:19:24 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=185
06/02/2022 10:19:32 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.9145941387307611 on epoch=185
06/02/2022 10:19:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=186
06/02/2022 10:19:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/02/2022 10:19:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=187
06/02/2022 10:19:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/02/2022 10:19:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/02/2022 10:19:52 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.9104233990761508 on epoch=189
06/02/2022 10:19:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/02/2022 10:19:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=190
06/02/2022 10:20:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=191
06/02/2022 10:20:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/02/2022 10:20:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=192
06/02/2022 10:20:13 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.9104233990761508 on epoch=192
06/02/2022 10:20:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=193
06/02/2022 10:20:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.14 on epoch=194
06/02/2022 10:20:20 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=194
06/02/2022 10:20:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.07 on epoch=195
06/02/2022 10:20:25 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/02/2022 10:20:32 - INFO - __main__ - Global step 2750 Train loss 0.08 Classification-F1 0.8515165890403082 on epoch=196
06/02/2022 10:20:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=197
06/02/2022 10:20:37 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/02/2022 10:20:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
06/02/2022 10:20:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=199
06/02/2022 10:20:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
06/02/2022 10:20:53 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.9104233990761508 on epoch=199
06/02/2022 10:20:56 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
06/02/2022 10:20:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=201
06/02/2022 10:21:01 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/02/2022 10:21:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=202
06/02/2022 10:21:06 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=203
06/02/2022 10:21:13 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.8554266574665057 on epoch=203
06/02/2022 10:21:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/02/2022 10:21:18 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=204
06/02/2022 10:21:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/02/2022 10:21:23 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/02/2022 10:21:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/02/2022 10:21:34 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.8493660514058996 on epoch=207
06/02/2022 10:21:36 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/02/2022 10:21:39 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/02/2022 10:21:41 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=209
06/02/2022 10:21:44 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=209
06/02/2022 10:21:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/02/2022 10:21:54 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.9081294922661148 on epoch=210
06/02/2022 10:21:57 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/02/2022 10:21:59 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/02/2022 10:22:02 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=212
06/02/2022 10:22:04 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/02/2022 10:22:07 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/02/2022 10:22:08 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 10:22:08 - INFO - __main__ - Printing 3 examples
06/02/2022 10:22:08 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 10:22:08 - INFO - __main__ - ['Animal']
06/02/2022 10:22:08 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 10:22:08 - INFO - __main__ - ['Animal']
06/02/2022 10:22:08 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 10:22:08 - INFO - __main__ - ['Animal']
06/02/2022 10:22:08 - INFO - __main__ - Tokenizing Input ...
06/02/2022 10:22:08 - INFO - __main__ - Tokenizing Output ...
06/02/2022 10:22:08 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 10:22:08 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 10:22:08 - INFO - __main__ - Printing 3 examples
06/02/2022 10:22:08 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 10:22:08 - INFO - __main__ - ['Animal']
06/02/2022 10:22:08 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 10:22:08 - INFO - __main__ - ['Animal']
06/02/2022 10:22:08 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 10:22:08 - INFO - __main__ - ['Animal']
06/02/2022 10:22:08 - INFO - __main__ - Tokenizing Input ...
06/02/2022 10:22:09 - INFO - __main__ - Tokenizing Output ...
06/02/2022 10:22:09 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 10:22:15 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9145941387307611 on epoch=214
06/02/2022 10:22:15 - INFO - __main__ - save last model!
06/02/2022 10:22:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 10:22:15 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 10:22:15 - INFO - __main__ - Printing 3 examples
06/02/2022 10:22:15 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 10:22:15 - INFO - __main__ - ['Animal']
06/02/2022 10:22:15 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 10:22:15 - INFO - __main__ - ['Animal']
06/02/2022 10:22:15 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 10:22:15 - INFO - __main__ - ['Village']
06/02/2022 10:22:15 - INFO - __main__ - Tokenizing Input ...
06/02/2022 10:22:17 - INFO - __main__ - Tokenizing Output ...
06/02/2022 10:22:20 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 10:22:27 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 10:22:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 10:22:28 - INFO - __main__ - Starting training!
06/02/2022 10:25:10 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
06/02/2022 10:25:10 - INFO - __main__ - Classification-F1 on test data: 0.6170
06/02/2022 10:25:11 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.982226438962682, test_performance=0.6169977956583246
06/02/2022 10:25:11 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
06/02/2022 10:25:12 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 10:25:12 - INFO - __main__ - Printing 3 examples
06/02/2022 10:25:12 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 10:25:12 - INFO - __main__ - ['Animal']
06/02/2022 10:25:12 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 10:25:12 - INFO - __main__ - ['Animal']
06/02/2022 10:25:12 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 10:25:12 - INFO - __main__ - ['Animal']
06/02/2022 10:25:12 - INFO - __main__ - Tokenizing Input ...
06/02/2022 10:25:12 - INFO - __main__ - Tokenizing Output ...
06/02/2022 10:25:12 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 10:25:12 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 10:25:12 - INFO - __main__ - Printing 3 examples
06/02/2022 10:25:12 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 10:25:12 - INFO - __main__ - ['Animal']
06/02/2022 10:25:12 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 10:25:12 - INFO - __main__ - ['Animal']
06/02/2022 10:25:12 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 10:25:12 - INFO - __main__ - ['Animal']
06/02/2022 10:25:12 - INFO - __main__ - Tokenizing Input ...
06/02/2022 10:25:12 - INFO - __main__ - Tokenizing Output ...
06/02/2022 10:25:12 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 10:25:29 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 10:25:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 10:25:30 - INFO - __main__ - Starting training!
06/02/2022 10:25:33 - INFO - __main__ - Step 10 Global step 10 Train loss 6.38 on epoch=0
06/02/2022 10:25:36 - INFO - __main__ - Step 20 Global step 20 Train loss 5.34 on epoch=1
06/02/2022 10:25:38 - INFO - __main__ - Step 30 Global step 30 Train loss 4.37 on epoch=2
06/02/2022 10:25:41 - INFO - __main__ - Step 40 Global step 40 Train loss 3.87 on epoch=2
06/02/2022 10:25:43 - INFO - __main__ - Step 50 Global step 50 Train loss 3.70 on epoch=3
06/02/2022 10:25:48 - INFO - __main__ - Global step 50 Train loss 4.73 Classification-F1 0.052936626846929 on epoch=3
06/02/2022 10:25:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.052936626846929 on epoch=3, global_step=50
06/02/2022 10:25:50 - INFO - __main__ - Step 60 Global step 60 Train loss 3.84 on epoch=4
06/02/2022 10:25:53 - INFO - __main__ - Step 70 Global step 70 Train loss 3.07 on epoch=4
06/02/2022 10:25:55 - INFO - __main__ - Step 80 Global step 80 Train loss 3.28 on epoch=5
06/02/2022 10:25:58 - INFO - __main__ - Step 90 Global step 90 Train loss 3.06 on epoch=6
06/02/2022 10:26:00 - INFO - __main__ - Step 100 Global step 100 Train loss 2.81 on epoch=7
06/02/2022 10:26:05 - INFO - __main__ - Global step 100 Train loss 3.21 Classification-F1 0.10369739057239057 on epoch=7
06/02/2022 10:26:05 - INFO - __main__ - Saving model with best Classification-F1: 0.052936626846929 -> 0.10369739057239057 on epoch=7, global_step=100
06/02/2022 10:26:07 - INFO - __main__ - Step 110 Global step 110 Train loss 2.55 on epoch=7
06/02/2022 10:26:10 - INFO - __main__ - Step 120 Global step 120 Train loss 2.47 on epoch=8
06/02/2022 10:26:12 - INFO - __main__ - Step 130 Global step 130 Train loss 2.64 on epoch=9
06/02/2022 10:26:15 - INFO - __main__ - Step 140 Global step 140 Train loss 2.18 on epoch=9
06/02/2022 10:26:17 - INFO - __main__ - Step 150 Global step 150 Train loss 2.32 on epoch=10
06/02/2022 10:26:22 - INFO - __main__ - Global step 150 Train loss 2.43 Classification-F1 0.12218162490342306 on epoch=10
06/02/2022 10:26:22 - INFO - __main__ - Saving model with best Classification-F1: 0.10369739057239057 -> 0.12218162490342306 on epoch=10, global_step=150
06/02/2022 10:26:24 - INFO - __main__ - Step 160 Global step 160 Train loss 2.19 on epoch=11
06/02/2022 10:26:27 - INFO - __main__ - Step 170 Global step 170 Train loss 2.17 on epoch=12
06/02/2022 10:26:29 - INFO - __main__ - Step 180 Global step 180 Train loss 2.11 on epoch=12
06/02/2022 10:26:32 - INFO - __main__ - Step 190 Global step 190 Train loss 1.90 on epoch=13
06/02/2022 10:26:34 - INFO - __main__ - Step 200 Global step 200 Train loss 2.13 on epoch=14
06/02/2022 10:26:39 - INFO - __main__ - Global step 200 Train loss 2.10 Classification-F1 0.15231378479244922 on epoch=14
06/02/2022 10:26:39 - INFO - __main__ - Saving model with best Classification-F1: 0.12218162490342306 -> 0.15231378479244922 on epoch=14, global_step=200
06/02/2022 10:26:41 - INFO - __main__ - Step 210 Global step 210 Train loss 1.81 on epoch=14
06/02/2022 10:26:44 - INFO - __main__ - Step 220 Global step 220 Train loss 2.00 on epoch=15
06/02/2022 10:26:46 - INFO - __main__ - Step 230 Global step 230 Train loss 1.77 on epoch=16
06/02/2022 10:26:49 - INFO - __main__ - Step 240 Global step 240 Train loss 1.79 on epoch=17
06/02/2022 10:26:51 - INFO - __main__ - Step 250 Global step 250 Train loss 1.62 on epoch=17
06/02/2022 10:26:56 - INFO - __main__ - Global step 250 Train loss 1.80 Classification-F1 0.17122345474379133 on epoch=17
06/02/2022 10:26:56 - INFO - __main__ - Saving model with best Classification-F1: 0.15231378479244922 -> 0.17122345474379133 on epoch=17, global_step=250
06/02/2022 10:26:59 - INFO - __main__ - Step 260 Global step 260 Train loss 1.65 on epoch=18
06/02/2022 10:27:01 - INFO - __main__ - Step 270 Global step 270 Train loss 1.78 on epoch=19
06/02/2022 10:27:04 - INFO - __main__ - Step 280 Global step 280 Train loss 1.46 on epoch=19
06/02/2022 10:27:06 - INFO - __main__ - Step 290 Global step 290 Train loss 1.56 on epoch=20
06/02/2022 10:27:09 - INFO - __main__ - Step 300 Global step 300 Train loss 1.45 on epoch=21
06/02/2022 10:27:14 - INFO - __main__ - Global step 300 Train loss 1.58 Classification-F1 0.20452744058818373 on epoch=21
06/02/2022 10:27:14 - INFO - __main__ - Saving model with best Classification-F1: 0.17122345474379133 -> 0.20452744058818373 on epoch=21, global_step=300
06/02/2022 10:27:17 - INFO - __main__ - Step 310 Global step 310 Train loss 1.47 on epoch=22
06/02/2022 10:27:19 - INFO - __main__ - Step 320 Global step 320 Train loss 1.48 on epoch=22
06/02/2022 10:27:22 - INFO - __main__ - Step 330 Global step 330 Train loss 1.43 on epoch=23
06/02/2022 10:27:24 - INFO - __main__ - Step 340 Global step 340 Train loss 1.54 on epoch=24
06/02/2022 10:27:27 - INFO - __main__ - Step 350 Global step 350 Train loss 1.20 on epoch=24
06/02/2022 10:27:32 - INFO - __main__ - Global step 350 Train loss 1.42 Classification-F1 0.25392229249402426 on epoch=24
06/02/2022 10:27:32 - INFO - __main__ - Saving model with best Classification-F1: 0.20452744058818373 -> 0.25392229249402426 on epoch=24, global_step=350
06/02/2022 10:27:35 - INFO - __main__ - Step 360 Global step 360 Train loss 1.33 on epoch=25
06/02/2022 10:27:37 - INFO - __main__ - Step 370 Global step 370 Train loss 1.33 on epoch=26
06/02/2022 10:27:40 - INFO - __main__ - Step 380 Global step 380 Train loss 1.28 on epoch=27
06/02/2022 10:27:42 - INFO - __main__ - Step 390 Global step 390 Train loss 1.13 on epoch=27
06/02/2022 10:27:45 - INFO - __main__ - Step 400 Global step 400 Train loss 1.18 on epoch=28
06/02/2022 10:27:50 - INFO - __main__ - Global step 400 Train loss 1.25 Classification-F1 0.306873098133981 on epoch=28
06/02/2022 10:27:50 - INFO - __main__ - Saving model with best Classification-F1: 0.25392229249402426 -> 0.306873098133981 on epoch=28, global_step=400
06/02/2022 10:27:53 - INFO - __main__ - Step 410 Global step 410 Train loss 1.20 on epoch=29
06/02/2022 10:27:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.99 on epoch=29
06/02/2022 10:27:58 - INFO - __main__ - Step 430 Global step 430 Train loss 1.18 on epoch=30
06/02/2022 10:28:00 - INFO - __main__ - Step 440 Global step 440 Train loss 1.01 on epoch=31
06/02/2022 10:28:03 - INFO - __main__ - Step 450 Global step 450 Train loss 1.05 on epoch=32
06/02/2022 10:28:08 - INFO - __main__ - Global step 450 Train loss 1.09 Classification-F1 0.364567302004298 on epoch=32
06/02/2022 10:28:08 - INFO - __main__ - Saving model with best Classification-F1: 0.306873098133981 -> 0.364567302004298 on epoch=32, global_step=450
06/02/2022 10:28:11 - INFO - __main__ - Step 460 Global step 460 Train loss 1.08 on epoch=32
06/02/2022 10:28:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.94 on epoch=33
06/02/2022 10:28:16 - INFO - __main__ - Step 480 Global step 480 Train loss 0.92 on epoch=34
06/02/2022 10:28:18 - INFO - __main__ - Step 490 Global step 490 Train loss 0.79 on epoch=34
06/02/2022 10:28:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.88 on epoch=35
06/02/2022 10:28:26 - INFO - __main__ - Global step 500 Train loss 0.92 Classification-F1 0.4197016379163209 on epoch=35
06/02/2022 10:28:26 - INFO - __main__ - Saving model with best Classification-F1: 0.364567302004298 -> 0.4197016379163209 on epoch=35, global_step=500
06/02/2022 10:28:29 - INFO - __main__ - Step 510 Global step 510 Train loss 0.74 on epoch=36
06/02/2022 10:28:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.89 on epoch=37
06/02/2022 10:28:34 - INFO - __main__ - Step 530 Global step 530 Train loss 0.80 on epoch=37
06/02/2022 10:28:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.88 on epoch=38
06/02/2022 10:28:39 - INFO - __main__ - Step 550 Global step 550 Train loss 0.74 on epoch=39
06/02/2022 10:28:45 - INFO - __main__ - Global step 550 Train loss 0.81 Classification-F1 0.4314905544329169 on epoch=39
06/02/2022 10:28:45 - INFO - __main__ - Saving model with best Classification-F1: 0.4197016379163209 -> 0.4314905544329169 on epoch=39, global_step=550
06/02/2022 10:28:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.67 on epoch=39
06/02/2022 10:28:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.77 on epoch=40
06/02/2022 10:28:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.75 on epoch=41
06/02/2022 10:28:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.72 on epoch=42
06/02/2022 10:28:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.59 on epoch=42
06/02/2022 10:29:04 - INFO - __main__ - Global step 600 Train loss 0.70 Classification-F1 0.5502004076612766 on epoch=42
06/02/2022 10:29:04 - INFO - __main__ - Saving model with best Classification-F1: 0.4314905544329169 -> 0.5502004076612766 on epoch=42, global_step=600
06/02/2022 10:29:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.66 on epoch=43
06/02/2022 10:29:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.58 on epoch=44
06/02/2022 10:29:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.53 on epoch=44
06/02/2022 10:29:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.63 on epoch=45
06/02/2022 10:29:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.66 on epoch=46
06/02/2022 10:29:23 - INFO - __main__ - Global step 650 Train loss 0.61 Classification-F1 0.583250917728749 on epoch=46
06/02/2022 10:29:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5502004076612766 -> 0.583250917728749 on epoch=46, global_step=650
06/02/2022 10:29:25 - INFO - __main__ - Step 660 Global step 660 Train loss 0.59 on epoch=47
06/02/2022 10:29:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.54 on epoch=47
06/02/2022 10:29:30 - INFO - __main__ - Step 680 Global step 680 Train loss 0.60 on epoch=48
06/02/2022 10:29:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.53 on epoch=49
06/02/2022 10:29:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.51 on epoch=49
06/02/2022 10:29:42 - INFO - __main__ - Global step 700 Train loss 0.55 Classification-F1 0.6250583209739217 on epoch=49
06/02/2022 10:29:42 - INFO - __main__ - Saving model with best Classification-F1: 0.583250917728749 -> 0.6250583209739217 on epoch=49, global_step=700
06/02/2022 10:29:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.56 on epoch=50
06/02/2022 10:29:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.49 on epoch=51
06/02/2022 10:29:49 - INFO - __main__ - Step 730 Global step 730 Train loss 0.53 on epoch=52
06/02/2022 10:29:52 - INFO - __main__ - Step 740 Global step 740 Train loss 0.45 on epoch=52
06/02/2022 10:29:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.52 on epoch=53
06/02/2022 10:30:01 - INFO - __main__ - Global step 750 Train loss 0.51 Classification-F1 0.611951877782548 on epoch=53
06/02/2022 10:30:03 - INFO - __main__ - Step 760 Global step 760 Train loss 0.39 on epoch=54
06/02/2022 10:30:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.48 on epoch=54
06/02/2022 10:30:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.45 on epoch=55
06/02/2022 10:30:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.42 on epoch=56
06/02/2022 10:30:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.45 on epoch=57
06/02/2022 10:30:20 - INFO - __main__ - Global step 800 Train loss 0.44 Classification-F1 0.5881746349121716 on epoch=57
06/02/2022 10:30:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.58 on epoch=57
06/02/2022 10:30:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.47 on epoch=58
06/02/2022 10:30:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.47 on epoch=59
06/02/2022 10:30:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.38 on epoch=59
06/02/2022 10:30:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.43 on epoch=60
06/02/2022 10:30:39 - INFO - __main__ - Global step 850 Train loss 0.47 Classification-F1 0.6538810201499956 on epoch=60
06/02/2022 10:30:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6250583209739217 -> 0.6538810201499956 on epoch=60, global_step=850
06/02/2022 10:30:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.40 on epoch=61
06/02/2022 10:30:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.41 on epoch=62
06/02/2022 10:30:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.40 on epoch=62
06/02/2022 10:30:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.37 on epoch=63
06/02/2022 10:30:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.34 on epoch=64
06/02/2022 10:30:58 - INFO - __main__ - Global step 900 Train loss 0.39 Classification-F1 0.5679221082797521 on epoch=64
06/02/2022 10:31:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.37 on epoch=64
06/02/2022 10:31:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.40 on epoch=65
06/02/2022 10:31:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.26 on epoch=66
06/02/2022 10:31:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.39 on epoch=67
06/02/2022 10:31:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.35 on epoch=67
06/02/2022 10:31:18 - INFO - __main__ - Global step 950 Train loss 0.35 Classification-F1 0.5837462110944085 on epoch=67
06/02/2022 10:31:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.42 on epoch=68
06/02/2022 10:31:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.39 on epoch=69
06/02/2022 10:31:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.38 on epoch=69
06/02/2022 10:31:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.32 on epoch=70
06/02/2022 10:31:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.35 on epoch=71
06/02/2022 10:31:37 - INFO - __main__ - Global step 1000 Train loss 0.37 Classification-F1 0.579439371723096 on epoch=71
06/02/2022 10:31:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.30 on epoch=72
06/02/2022 10:31:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.33 on epoch=72
06/02/2022 10:31:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.37 on epoch=73
06/02/2022 10:31:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.28 on epoch=74
06/02/2022 10:31:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.25 on epoch=74
06/02/2022 10:31:56 - INFO - __main__ - Global step 1050 Train loss 0.30 Classification-F1 0.6085523310008265 on epoch=74
06/02/2022 10:31:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.32 on epoch=75
06/02/2022 10:32:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.30 on epoch=76
06/02/2022 10:32:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.36 on epoch=77
06/02/2022 10:32:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.29 on epoch=77
06/02/2022 10:32:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.26 on epoch=78
06/02/2022 10:32:16 - INFO - __main__ - Global step 1100 Train loss 0.31 Classification-F1 0.5754525497215682 on epoch=78
06/02/2022 10:32:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.32 on epoch=79
06/02/2022 10:32:21 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.31 on epoch=79
06/02/2022 10:32:23 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.25 on epoch=80
06/02/2022 10:32:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=81
06/02/2022 10:32:28 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.36 on epoch=82
06/02/2022 10:32:35 - INFO - __main__ - Global step 1150 Train loss 0.30 Classification-F1 0.6291058302135152 on epoch=82
06/02/2022 10:32:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.26 on epoch=82
06/02/2022 10:32:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.27 on epoch=83
06/02/2022 10:32:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.32 on epoch=84
06/02/2022 10:32:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.24 on epoch=84
06/02/2022 10:32:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.28 on epoch=85
06/02/2022 10:32:54 - INFO - __main__ - Global step 1200 Train loss 0.27 Classification-F1 0.6051302949023413 on epoch=85
06/02/2022 10:32:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=86
06/02/2022 10:32:59 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.31 on epoch=87
06/02/2022 10:33:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.21 on epoch=87
06/02/2022 10:33:04 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=88
06/02/2022 10:33:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.27 on epoch=89
06/02/2022 10:33:13 - INFO - __main__ - Global step 1250 Train loss 0.23 Classification-F1 0.6041893616608986 on epoch=89
06/02/2022 10:33:16 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.24 on epoch=89
06/02/2022 10:33:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.27 on epoch=90
06/02/2022 10:33:21 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.23 on epoch=91
06/02/2022 10:33:24 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.30 on epoch=92
06/02/2022 10:33:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.27 on epoch=92
06/02/2022 10:33:33 - INFO - __main__ - Global step 1300 Train loss 0.26 Classification-F1 0.5936898489219495 on epoch=92
06/02/2022 10:33:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.25 on epoch=93
06/02/2022 10:33:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.30 on epoch=94
06/02/2022 10:33:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=94
06/02/2022 10:33:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.21 on epoch=95
06/02/2022 10:33:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.24 on epoch=96
06/02/2022 10:33:52 - INFO - __main__ - Global step 1350 Train loss 0.23 Classification-F1 0.5958412904717622 on epoch=96
06/02/2022 10:33:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.20 on epoch=97
06/02/2022 10:33:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.20 on epoch=97
06/02/2022 10:33:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=98
06/02/2022 10:34:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.19 on epoch=99
06/02/2022 10:34:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.17 on epoch=99
06/02/2022 10:34:11 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.6504913463687683 on epoch=99
06/02/2022 10:34:14 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.25 on epoch=100
06/02/2022 10:34:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.21 on epoch=101
06/02/2022 10:34:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=102
06/02/2022 10:34:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.18 on epoch=102
06/02/2022 10:34:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.22 on epoch=103
06/02/2022 10:34:30 - INFO - __main__ - Global step 1450 Train loss 0.21 Classification-F1 0.6113607270865336 on epoch=103
06/02/2022 10:34:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.22 on epoch=104
06/02/2022 10:34:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.25 on epoch=104
06/02/2022 10:34:38 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.22 on epoch=105
06/02/2022 10:34:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=106
06/02/2022 10:34:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.26 on epoch=107
06/02/2022 10:34:49 - INFO - __main__ - Global step 1500 Train loss 0.22 Classification-F1 0.5913608334352276 on epoch=107
06/02/2022 10:34:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.14 on epoch=107
06/02/2022 10:34:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.24 on epoch=108
06/02/2022 10:34:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.24 on epoch=109
06/02/2022 10:35:00 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.18 on epoch=109
06/02/2022 10:35:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.19 on epoch=110
06/02/2022 10:35:09 - INFO - __main__ - Global step 1550 Train loss 0.20 Classification-F1 0.6359766340553816 on epoch=110
06/02/2022 10:35:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.18 on epoch=111
06/02/2022 10:35:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.25 on epoch=112
06/02/2022 10:35:16 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.19 on epoch=112
06/02/2022 10:35:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.20 on epoch=113
06/02/2022 10:35:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.17 on epoch=114
06/02/2022 10:35:28 - INFO - __main__ - Global step 1600 Train loss 0.20 Classification-F1 0.6000954647388148 on epoch=114
06/02/2022 10:35:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.23 on epoch=114
06/02/2022 10:35:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=115
06/02/2022 10:35:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.18 on epoch=116
06/02/2022 10:35:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.22 on epoch=117
06/02/2022 10:35:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.19 on epoch=117
06/02/2022 10:35:47 - INFO - __main__ - Global step 1650 Train loss 0.19 Classification-F1 0.6723209203036052 on epoch=117
06/02/2022 10:35:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6538810201499956 -> 0.6723209203036052 on epoch=117, global_step=1650
06/02/2022 10:35:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=118
06/02/2022 10:35:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.21 on epoch=119
06/02/2022 10:35:55 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.17 on epoch=119
06/02/2022 10:35:57 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=120
06/02/2022 10:36:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.14 on epoch=121
06/02/2022 10:36:07 - INFO - __main__ - Global step 1700 Train loss 0.15 Classification-F1 0.7954607810479483 on epoch=121
06/02/2022 10:36:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6723209203036052 -> 0.7954607810479483 on epoch=121, global_step=1700
06/02/2022 10:36:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.22 on epoch=122
06/02/2022 10:36:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.14 on epoch=122
06/02/2022 10:36:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.14 on epoch=123
06/02/2022 10:36:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.18 on epoch=124
06/02/2022 10:36:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=124
06/02/2022 10:36:26 - INFO - __main__ - Global step 1750 Train loss 0.15 Classification-F1 0.7971384574661091 on epoch=124
06/02/2022 10:36:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7954607810479483 -> 0.7971384574661091 on epoch=124, global_step=1750
06/02/2022 10:36:28 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.23 on epoch=125
06/02/2022 10:36:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.16 on epoch=126
06/02/2022 10:36:33 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.13 on epoch=127
06/02/2022 10:36:36 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=127
06/02/2022 10:36:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.19 on epoch=128
06/02/2022 10:36:45 - INFO - __main__ - Global step 1800 Train loss 0.16 Classification-F1 0.9062682326107373 on epoch=128
06/02/2022 10:36:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7971384574661091 -> 0.9062682326107373 on epoch=128, global_step=1800
06/02/2022 10:36:48 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=129
06/02/2022 10:36:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.15 on epoch=129
06/02/2022 10:36:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.21 on epoch=130
06/02/2022 10:36:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.18 on epoch=131
06/02/2022 10:36:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.21 on epoch=132
06/02/2022 10:37:05 - INFO - __main__ - Global step 1850 Train loss 0.18 Classification-F1 0.849083329863445 on epoch=132
06/02/2022 10:37:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=132
06/02/2022 10:37:10 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.19 on epoch=133
06/02/2022 10:37:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=134
06/02/2022 10:37:15 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.18 on epoch=134
06/02/2022 10:37:18 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.15 on epoch=135
06/02/2022 10:37:25 - INFO - __main__ - Global step 1900 Train loss 0.14 Classification-F1 0.9777621532483962 on epoch=135
06/02/2022 10:37:25 - INFO - __main__ - Saving model with best Classification-F1: 0.9062682326107373 -> 0.9777621532483962 on epoch=135, global_step=1900
06/02/2022 10:37:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=136
06/02/2022 10:37:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.14 on epoch=137
06/02/2022 10:37:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.14 on epoch=137
06/02/2022 10:37:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.18 on epoch=138
06/02/2022 10:37:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=139
06/02/2022 10:37:44 - INFO - __main__ - Global step 1950 Train loss 0.13 Classification-F1 0.982226438962682 on epoch=139
06/02/2022 10:37:44 - INFO - __main__ - Saving model with best Classification-F1: 0.9777621532483962 -> 0.982226438962682 on epoch=139, global_step=1950
06/02/2022 10:37:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.14 on epoch=139
06/02/2022 10:37:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.16 on epoch=140
06/02/2022 10:37:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.13 on epoch=141
06/02/2022 10:37:54 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.16 on epoch=142
06/02/2022 10:37:57 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.15 on epoch=142
06/02/2022 10:38:03 - INFO - __main__ - Global step 2000 Train loss 0.15 Classification-F1 0.9104274720640945 on epoch=142
06/02/2022 10:38:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.10 on epoch=143
06/02/2022 10:38:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.17 on epoch=144
06/02/2022 10:38:10 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.15 on epoch=144
06/02/2022 10:38:13 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=145
06/02/2022 10:38:15 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.13 on epoch=146
06/02/2022 10:38:22 - INFO - __main__ - Global step 2050 Train loss 0.13 Classification-F1 0.9104274720640945 on epoch=146
06/02/2022 10:38:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.11 on epoch=147
06/02/2022 10:38:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=147
06/02/2022 10:38:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=148
06/02/2022 10:38:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.12 on epoch=149
06/02/2022 10:38:34 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.11 on epoch=149
06/02/2022 10:38:41 - INFO - __main__ - Global step 2100 Train loss 0.11 Classification-F1 0.9777621532483962 on epoch=149
06/02/2022 10:38:43 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=150
06/02/2022 10:38:46 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.14 on epoch=151
06/02/2022 10:38:48 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.15 on epoch=152
06/02/2022 10:38:51 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.14 on epoch=152
06/02/2022 10:38:54 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.15 on epoch=153
06/02/2022 10:39:00 - INFO - __main__ - Global step 2150 Train loss 0.13 Classification-F1 0.9145941387307611 on epoch=153
06/02/2022 10:39:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.15 on epoch=154
06/02/2022 10:39:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.17 on epoch=154
06/02/2022 10:39:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.18 on epoch=155
06/02/2022 10:39:10 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=156
06/02/2022 10:39:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.17 on epoch=157
06/02/2022 10:39:20 - INFO - __main__ - Global step 2200 Train loss 0.15 Classification-F1 0.982226438962682 on epoch=157
06/02/2022 10:39:22 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.10 on epoch=157
06/02/2022 10:39:25 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=158
06/02/2022 10:39:27 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=159
06/02/2022 10:39:30 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=159
06/02/2022 10:39:32 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.10 on epoch=160
06/02/2022 10:39:39 - INFO - __main__ - Global step 2250 Train loss 0.09 Classification-F1 0.9777621532483962 on epoch=160
06/02/2022 10:39:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=161
06/02/2022 10:39:45 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.16 on epoch=162
06/02/2022 10:39:47 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.13 on epoch=162
06/02/2022 10:39:50 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=163
06/02/2022 10:39:52 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=164
06/02/2022 10:39:59 - INFO - __main__ - Global step 2300 Train loss 0.10 Classification-F1 0.9777621532483962 on epoch=164
06/02/2022 10:40:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=164
06/02/2022 10:40:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.10 on epoch=165
06/02/2022 10:40:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.11 on epoch=166
06/02/2022 10:40:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=167
06/02/2022 10:40:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.10 on epoch=167
06/02/2022 10:40:19 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.9777621532483962 on epoch=167
06/02/2022 10:40:21 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.16 on epoch=168
06/02/2022 10:40:24 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=169
06/02/2022 10:40:26 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=169
06/02/2022 10:40:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.10 on epoch=170
06/02/2022 10:40:31 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=171
06/02/2022 10:40:38 - INFO - __main__ - Global step 2400 Train loss 0.10 Classification-F1 0.9777621532483962 on epoch=171
06/02/2022 10:40:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.18 on epoch=172
06/02/2022 10:40:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.10 on epoch=172
06/02/2022 10:40:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=173
06/02/2022 10:40:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.09 on epoch=174
06/02/2022 10:40:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=174
06/02/2022 10:40:56 - INFO - __main__ - Global step 2450 Train loss 0.10 Classification-F1 0.9777621532483962 on epoch=174
06/02/2022 10:40:59 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.12 on epoch=175
06/02/2022 10:41:01 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=176
06/02/2022 10:41:04 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.09 on epoch=177
06/02/2022 10:41:06 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=177
06/02/2022 10:41:09 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=178
06/02/2022 10:41:16 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.9777621532483962 on epoch=178
06/02/2022 10:41:18 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.13 on epoch=179
06/02/2022 10:41:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.11 on epoch=179
06/02/2022 10:41:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=180
06/02/2022 10:41:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.10 on epoch=181
06/02/2022 10:41:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.15 on epoch=182
06/02/2022 10:41:35 - INFO - __main__ - Global step 2550 Train loss 0.11 Classification-F1 0.9777621532483962 on epoch=182
06/02/2022 10:41:38 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.10 on epoch=182
06/02/2022 10:41:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.09 on epoch=183
06/02/2022 10:41:43 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=184
06/02/2022 10:41:45 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.10 on epoch=184
06/02/2022 10:41:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.11 on epoch=185
06/02/2022 10:41:55 - INFO - __main__ - Global step 2600 Train loss 0.09 Classification-F1 0.9777621532483962 on epoch=185
06/02/2022 10:41:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=186
06/02/2022 10:42:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.11 on epoch=187
06/02/2022 10:42:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=187
06/02/2022 10:42:05 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.08 on epoch=188
06/02/2022 10:42:07 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=189
06/02/2022 10:42:14 - INFO - __main__ - Global step 2650 Train loss 0.08 Classification-F1 0.9777621532483962 on epoch=189
06/02/2022 10:42:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=189
06/02/2022 10:42:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=190
06/02/2022 10:42:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
06/02/2022 10:42:24 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=192
06/02/2022 10:42:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=192
06/02/2022 10:42:33 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.9777621532483962 on epoch=192
06/02/2022 10:42:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/02/2022 10:42:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=194
06/02/2022 10:42:41 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.12 on epoch=194
06/02/2022 10:42:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.08 on epoch=195
06/02/2022 10:42:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.13 on epoch=196
06/02/2022 10:42:53 - INFO - __main__ - Global step 2750 Train loss 0.09 Classification-F1 0.9777621532483962 on epoch=196
06/02/2022 10:42:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=197
06/02/2022 10:42:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.08 on epoch=197
06/02/2022 10:43:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.12 on epoch=198
06/02/2022 10:43:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.09 on epoch=199
06/02/2022 10:43:05 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.10 on epoch=199
06/02/2022 10:43:12 - INFO - __main__ - Global step 2800 Train loss 0.09 Classification-F1 0.9777621532483962 on epoch=199
06/02/2022 10:43:15 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=200
06/02/2022 10:43:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=201
06/02/2022 10:43:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.12 on epoch=202
06/02/2022 10:43:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=202
06/02/2022 10:43:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=203
06/02/2022 10:43:32 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.9777621532483962 on epoch=203
06/02/2022 10:43:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=204
06/02/2022 10:43:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=204
06/02/2022 10:43:40 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.07 on epoch=205
06/02/2022 10:43:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=206
06/02/2022 10:43:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.08 on epoch=207
06/02/2022 10:43:52 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.9777621532483962 on epoch=207
06/02/2022 10:43:54 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.08 on epoch=207
06/02/2022 10:43:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/02/2022 10:44:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=209
06/02/2022 10:44:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=209
06/02/2022 10:44:05 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=210
06/02/2022 10:44:12 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.9777621532483962 on epoch=210
06/02/2022 10:44:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=211
06/02/2022 10:44:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.07 on epoch=212
06/02/2022 10:44:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=212
06/02/2022 10:44:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=213
06/02/2022 10:44:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.07 on epoch=214
06/02/2022 10:44:25 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 10:44:25 - INFO - __main__ - Printing 3 examples
06/02/2022 10:44:25 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 10:44:25 - INFO - __main__ - ['Animal']
06/02/2022 10:44:25 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 10:44:25 - INFO - __main__ - ['Animal']
06/02/2022 10:44:25 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 10:44:25 - INFO - __main__ - ['Animal']
06/02/2022 10:44:25 - INFO - __main__ - Tokenizing Input ...
06/02/2022 10:44:25 - INFO - __main__ - Tokenizing Output ...
06/02/2022 10:44:26 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 10:44:26 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 10:44:26 - INFO - __main__ - Printing 3 examples
06/02/2022 10:44:26 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 10:44:26 - INFO - __main__ - ['Animal']
06/02/2022 10:44:26 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 10:44:26 - INFO - __main__ - ['Animal']
06/02/2022 10:44:26 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 10:44:26 - INFO - __main__ - ['Animal']
06/02/2022 10:44:26 - INFO - __main__ - Tokenizing Input ...
06/02/2022 10:44:26 - INFO - __main__ - Tokenizing Output ...
06/02/2022 10:44:26 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 10:44:31 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.9104274720640945 on epoch=214
06/02/2022 10:44:31 - INFO - __main__ - save last model!
06/02/2022 10:44:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 10:44:32 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 10:44:32 - INFO - __main__ - Printing 3 examples
06/02/2022 10:44:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 10:44:32 - INFO - __main__ - ['Animal']
06/02/2022 10:44:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 10:44:32 - INFO - __main__ - ['Animal']
06/02/2022 10:44:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 10:44:32 - INFO - __main__ - ['Village']
06/02/2022 10:44:32 - INFO - __main__ - Tokenizing Input ...
06/02/2022 10:44:33 - INFO - __main__ - Tokenizing Output ...
06/02/2022 10:44:37 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 10:44:42 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 10:44:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 10:44:42 - INFO - __main__ - Starting training!
06/02/2022 10:46:59 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
06/02/2022 10:46:59 - INFO - __main__ - Classification-F1 on test data: 0.6480
06/02/2022 10:46:59 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.982226438962682, test_performance=0.6479708517521594
06/02/2022 10:46:59 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
06/02/2022 10:47:00 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 10:47:00 - INFO - __main__ - Printing 3 examples
06/02/2022 10:47:00 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 10:47:00 - INFO - __main__ - ['Animal']
06/02/2022 10:47:00 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 10:47:00 - INFO - __main__ - ['Animal']
06/02/2022 10:47:00 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 10:47:00 - INFO - __main__ - ['Animal']
06/02/2022 10:47:00 - INFO - __main__ - Tokenizing Input ...
06/02/2022 10:47:00 - INFO - __main__ - Tokenizing Output ...
06/02/2022 10:47:01 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 10:47:01 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 10:47:01 - INFO - __main__ - Printing 3 examples
06/02/2022 10:47:01 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 10:47:01 - INFO - __main__ - ['Animal']
06/02/2022 10:47:01 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 10:47:01 - INFO - __main__ - ['Animal']
06/02/2022 10:47:01 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 10:47:01 - INFO - __main__ - ['Animal']
06/02/2022 10:47:01 - INFO - __main__ - Tokenizing Input ...
06/02/2022 10:47:01 - INFO - __main__ - Tokenizing Output ...
06/02/2022 10:47:01 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 10:47:18 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 10:47:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 10:47:18 - INFO - __main__ - Starting training!
06/02/2022 10:47:22 - INFO - __main__ - Step 10 Global step 10 Train loss 5.19 on epoch=0
06/02/2022 10:47:24 - INFO - __main__ - Step 20 Global step 20 Train loss 3.87 on epoch=1
06/02/2022 10:47:27 - INFO - __main__ - Step 30 Global step 30 Train loss 3.58 on epoch=2
06/02/2022 10:47:29 - INFO - __main__ - Step 40 Global step 40 Train loss 2.76 on epoch=2
06/02/2022 10:47:32 - INFO - __main__ - Step 50 Global step 50 Train loss 2.61 on epoch=3
06/02/2022 10:47:37 - INFO - __main__ - Global step 50 Train loss 3.60 Classification-F1 0.09915967365967365 on epoch=3
06/02/2022 10:47:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09915967365967365 on epoch=3, global_step=50
06/02/2022 10:47:39 - INFO - __main__ - Step 60 Global step 60 Train loss 2.32 on epoch=4
06/02/2022 10:47:42 - INFO - __main__ - Step 70 Global step 70 Train loss 2.07 on epoch=4
06/02/2022 10:47:44 - INFO - __main__ - Step 80 Global step 80 Train loss 2.09 on epoch=5
06/02/2022 10:47:47 - INFO - __main__ - Step 90 Global step 90 Train loss 1.71 on epoch=6
06/02/2022 10:47:49 - INFO - __main__ - Step 100 Global step 100 Train loss 1.87 on epoch=7
06/02/2022 10:47:54 - INFO - __main__ - Global step 100 Train loss 2.01 Classification-F1 0.1552671624554156 on epoch=7
06/02/2022 10:47:54 - INFO - __main__ - Saving model with best Classification-F1: 0.09915967365967365 -> 0.1552671624554156 on epoch=7, global_step=100
06/02/2022 10:47:56 - INFO - __main__ - Step 110 Global step 110 Train loss 1.60 on epoch=7
06/02/2022 10:47:59 - INFO - __main__ - Step 120 Global step 120 Train loss 1.59 on epoch=8
06/02/2022 10:48:01 - INFO - __main__ - Step 130 Global step 130 Train loss 1.47 on epoch=9
06/02/2022 10:48:04 - INFO - __main__ - Step 140 Global step 140 Train loss 1.19 on epoch=9
06/02/2022 10:48:06 - INFO - __main__ - Step 150 Global step 150 Train loss 1.24 on epoch=10
06/02/2022 10:48:11 - INFO - __main__ - Global step 150 Train loss 1.42 Classification-F1 0.26368411608519665 on epoch=10
06/02/2022 10:48:11 - INFO - __main__ - Saving model with best Classification-F1: 0.1552671624554156 -> 0.26368411608519665 on epoch=10, global_step=150
06/02/2022 10:48:14 - INFO - __main__ - Step 160 Global step 160 Train loss 1.14 on epoch=11
06/02/2022 10:48:16 - INFO - __main__ - Step 170 Global step 170 Train loss 1.17 on epoch=12
06/02/2022 10:48:19 - INFO - __main__ - Step 180 Global step 180 Train loss 0.96 on epoch=12
06/02/2022 10:48:21 - INFO - __main__ - Step 190 Global step 190 Train loss 1.00 on epoch=13
06/02/2022 10:48:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.89 on epoch=14
06/02/2022 10:48:29 - INFO - __main__ - Global step 200 Train loss 1.03 Classification-F1 0.4204313653941781 on epoch=14
06/02/2022 10:48:29 - INFO - __main__ - Saving model with best Classification-F1: 0.26368411608519665 -> 0.4204313653941781 on epoch=14, global_step=200
06/02/2022 10:48:32 - INFO - __main__ - Step 210 Global step 210 Train loss 0.79 on epoch=14
06/02/2022 10:48:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.64 on epoch=15
06/02/2022 10:48:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.73 on epoch=16
06/02/2022 10:48:39 - INFO - __main__ - Step 240 Global step 240 Train loss 0.80 on epoch=17
06/02/2022 10:48:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.53 on epoch=17
06/02/2022 10:48:48 - INFO - __main__ - Global step 250 Train loss 0.70 Classification-F1 0.4242713163736523 on epoch=17
06/02/2022 10:48:48 - INFO - __main__ - Saving model with best Classification-F1: 0.4204313653941781 -> 0.4242713163736523 on epoch=17, global_step=250
06/02/2022 10:48:50 - INFO - __main__ - Step 260 Global step 260 Train loss 0.63 on epoch=18
06/02/2022 10:48:53 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=19
06/02/2022 10:48:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.53 on epoch=19
06/02/2022 10:48:58 - INFO - __main__ - Step 290 Global step 290 Train loss 0.56 on epoch=20
06/02/2022 10:49:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.40 on epoch=21
06/02/2022 10:49:08 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.5662546371347212 on epoch=21
06/02/2022 10:49:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4242713163736523 -> 0.5662546371347212 on epoch=21, global_step=300
06/02/2022 10:49:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.50 on epoch=22
06/02/2022 10:49:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.44 on epoch=22
06/02/2022 10:49:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.48 on epoch=23
06/02/2022 10:49:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.42 on epoch=24
06/02/2022 10:49:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.33 on epoch=24
06/02/2022 10:49:27 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.585156787567347 on epoch=24
06/02/2022 10:49:27 - INFO - __main__ - Saving model with best Classification-F1: 0.5662546371347212 -> 0.585156787567347 on epoch=24, global_step=350
06/02/2022 10:49:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=25
06/02/2022 10:49:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.35 on epoch=26
06/02/2022 10:49:35 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=27
06/02/2022 10:49:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=27
06/02/2022 10:49:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.34 on epoch=28
06/02/2022 10:49:47 - INFO - __main__ - Global step 400 Train loss 0.33 Classification-F1 0.7037176519010135 on epoch=28
06/02/2022 10:49:47 - INFO - __main__ - Saving model with best Classification-F1: 0.585156787567347 -> 0.7037176519010135 on epoch=28, global_step=400
06/02/2022 10:49:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=29
06/02/2022 10:49:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=29
06/02/2022 10:49:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.32 on epoch=30
06/02/2022 10:49:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.30 on epoch=31
06/02/2022 10:49:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=32
06/02/2022 10:50:06 - INFO - __main__ - Global step 450 Train loss 0.29 Classification-F1 0.7345659723648339 on epoch=32
06/02/2022 10:50:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7037176519010135 -> 0.7345659723648339 on epoch=32, global_step=450
06/02/2022 10:50:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=32
06/02/2022 10:50:11 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=33
06/02/2022 10:50:14 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=34
06/02/2022 10:50:16 - INFO - __main__ - Step 490 Global step 490 Train loss 0.32 on epoch=34
06/02/2022 10:50:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=35
06/02/2022 10:50:25 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.7397346739282225 on epoch=35
06/02/2022 10:50:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7345659723648339 -> 0.7397346739282225 on epoch=35, global_step=500
06/02/2022 10:50:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=36
06/02/2022 10:50:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=37
06/02/2022 10:50:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=37
06/02/2022 10:50:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=38
06/02/2022 10:50:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=39
06/02/2022 10:50:45 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.7613534134680174 on epoch=39
06/02/2022 10:50:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7397346739282225 -> 0.7613534134680174 on epoch=39, global_step=550
06/02/2022 10:50:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=39
06/02/2022 10:50:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=40
06/02/2022 10:50:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=41
06/02/2022 10:50:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.17 on epoch=42
06/02/2022 10:50:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=42
06/02/2022 10:51:04 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.7878678113009512 on epoch=42
06/02/2022 10:51:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7613534134680174 -> 0.7878678113009512 on epoch=42, global_step=600
06/02/2022 10:51:07 - INFO - __main__ - Step 610 Global step 610 Train loss 0.13 on epoch=43
06/02/2022 10:51:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=44
06/02/2022 10:51:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=44
06/02/2022 10:51:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=45
06/02/2022 10:51:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=46
06/02/2022 10:51:23 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.7200675107695981 on epoch=46
06/02/2022 10:51:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=47
06/02/2022 10:51:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
06/02/2022 10:51:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=48
06/02/2022 10:51:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=49
06/02/2022 10:51:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=49
06/02/2022 10:51:43 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.7152079977606793 on epoch=49
06/02/2022 10:51:45 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=50
06/02/2022 10:51:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=51
06/02/2022 10:51:50 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=52
06/02/2022 10:51:52 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=52
06/02/2022 10:51:55 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=53
06/02/2022 10:52:02 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.7847251771350443 on epoch=53
06/02/2022 10:52:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=54
06/02/2022 10:52:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=54
06/02/2022 10:52:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=55
06/02/2022 10:52:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
06/02/2022 10:52:14 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
06/02/2022 10:52:21 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.7654765560444209 on epoch=57
06/02/2022 10:52:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=57
06/02/2022 10:52:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=58
06/02/2022 10:52:29 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=59
06/02/2022 10:52:31 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=59
06/02/2022 10:52:34 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=60
06/02/2022 10:52:41 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.7734909671816693 on epoch=60
06/02/2022 10:52:43 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=61
06/02/2022 10:52:46 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=62
06/02/2022 10:52:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=62
06/02/2022 10:52:51 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=63
06/02/2022 10:52:53 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
06/02/2022 10:53:00 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.8164027268865979 on epoch=64
06/02/2022 10:53:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7878678113009512 -> 0.8164027268865979 on epoch=64, global_step=900
06/02/2022 10:53:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=64
06/02/2022 10:53:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=65
06/02/2022 10:53:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/02/2022 10:53:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=67
06/02/2022 10:53:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=67
06/02/2022 10:53:19 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.880435093229211 on epoch=67
06/02/2022 10:53:20 - INFO - __main__ - Saving model with best Classification-F1: 0.8164027268865979 -> 0.880435093229211 on epoch=67, global_step=950
06/02/2022 10:53:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=68
06/02/2022 10:53:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=69
06/02/2022 10:53:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
06/02/2022 10:53:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
06/02/2022 10:53:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/02/2022 10:53:39 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.8933218331320796 on epoch=71
06/02/2022 10:53:39 - INFO - __main__ - Saving model with best Classification-F1: 0.880435093229211 -> 0.8933218331320796 on epoch=71, global_step=1000
06/02/2022 10:53:41 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/02/2022 10:53:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
06/02/2022 10:53:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
06/02/2022 10:53:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=74
06/02/2022 10:53:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
06/02/2022 10:53:58 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.8973793437218485 on epoch=74
06/02/2022 10:53:58 - INFO - __main__ - Saving model with best Classification-F1: 0.8933218331320796 -> 0.8973793437218485 on epoch=74, global_step=1050
06/02/2022 10:54:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
06/02/2022 10:54:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=76
06/02/2022 10:54:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=77
06/02/2022 10:54:08 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=77
06/02/2022 10:54:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/02/2022 10:54:18 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.9015615835777127 on epoch=78
06/02/2022 10:54:18 - INFO - __main__ - Saving model with best Classification-F1: 0.8973793437218485 -> 0.9015615835777127 on epoch=78, global_step=1100
06/02/2022 10:54:20 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
06/02/2022 10:54:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=79
06/02/2022 10:54:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.16 on epoch=80
06/02/2022 10:54:28 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
06/02/2022 10:54:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
06/02/2022 10:54:37 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.9015615835777127 on epoch=82
06/02/2022 10:54:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=82
06/02/2022 10:54:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
06/02/2022 10:54:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=84
06/02/2022 10:54:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=84
06/02/2022 10:54:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
06/02/2022 10:54:57 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.8434704912023461 on epoch=85
06/02/2022 10:55:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
06/02/2022 10:55:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
06/02/2022 10:55:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=87
06/02/2022 10:55:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=88
06/02/2022 10:55:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=89
06/02/2022 10:55:17 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.831645698051948 on epoch=89
06/02/2022 10:55:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
06/02/2022 10:55:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
06/02/2022 10:55:25 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
06/02/2022 10:55:27 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=92
06/02/2022 10:55:30 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=92
06/02/2022 10:55:37 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.8333225518946581 on epoch=92
06/02/2022 10:55:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=93
06/02/2022 10:55:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/02/2022 10:55:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
06/02/2022 10:55:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/02/2022 10:55:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
06/02/2022 10:55:57 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.8933218331320797 on epoch=96
06/02/2022 10:56:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
06/02/2022 10:56:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
06/02/2022 10:56:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/02/2022 10:56:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/02/2022 10:56:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/02/2022 10:56:18 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7844300804675847 on epoch=99
06/02/2022 10:56:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
06/02/2022 10:56:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
06/02/2022 10:56:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
06/02/2022 10:56:28 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
06/02/2022 10:56:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
06/02/2022 10:56:38 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7844300804675847 on epoch=103
06/02/2022 10:56:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/02/2022 10:56:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/02/2022 10:56:45 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=105
06/02/2022 10:56:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/02/2022 10:56:50 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=107
06/02/2022 10:56:58 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.8372556207233627 on epoch=107
06/02/2022 10:57:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
06/02/2022 10:57:03 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
06/02/2022 10:57:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
06/02/2022 10:57:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=109
06/02/2022 10:57:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
06/02/2022 10:57:18 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.8373952852768674 on epoch=110
06/02/2022 10:57:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
06/02/2022 10:57:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=112
06/02/2022 10:57:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/02/2022 10:57:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/02/2022 10:57:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.14 on epoch=114
06/02/2022 10:57:38 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8372556207233627 on epoch=114
06/02/2022 10:57:41 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/02/2022 10:57:43 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/02/2022 10:57:46 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/02/2022 10:57:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
06/02/2022 10:57:51 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
06/02/2022 10:57:59 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7824060450469648 on epoch=117
06/02/2022 10:58:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
06/02/2022 10:58:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/02/2022 10:58:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/02/2022 10:58:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/02/2022 10:58:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/02/2022 10:58:19 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7389424367009756 on epoch=121
06/02/2022 10:58:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
06/02/2022 10:58:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
06/02/2022 10:58:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/02/2022 10:58:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/02/2022 10:58:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/02/2022 10:58:40 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7881317923063653 on epoch=124
06/02/2022 10:58:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/02/2022 10:58:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/02/2022 10:58:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/02/2022 10:58:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
06/02/2022 10:58:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/02/2022 10:59:01 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7861113506986372 on epoch=128
06/02/2022 10:59:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=129
06/02/2022 10:59:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
06/02/2022 10:59:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/02/2022 10:59:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
06/02/2022 10:59:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
06/02/2022 10:59:22 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.8354853084928986 on epoch=132
06/02/2022 10:59:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=132
06/02/2022 10:59:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/02/2022 10:59:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/02/2022 10:59:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/02/2022 10:59:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/02/2022 10:59:42 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.8394061583577713 on epoch=135
06/02/2022 10:59:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/02/2022 10:59:47 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/02/2022 10:59:50 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
06/02/2022 10:59:52 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/02/2022 10:59:55 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/02/2022 11:00:03 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.788135386119257 on epoch=139
06/02/2022 11:00:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/02/2022 11:00:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/02/2022 11:00:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/02/2022 11:00:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
06/02/2022 11:00:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/02/2022 11:00:23 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.833365408113392 on epoch=142
06/02/2022 11:00:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/02/2022 11:00:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=144
06/02/2022 11:00:30 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
06/02/2022 11:00:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/02/2022 11:00:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/02/2022 11:00:44 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.8933348666935004 on epoch=146
06/02/2022 11:00:46 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/02/2022 11:00:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/02/2022 11:00:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/02/2022 11:00:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/02/2022 11:00:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/02/2022 11:01:04 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8975211795373087 on epoch=149
06/02/2022 11:01:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/02/2022 11:01:09 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/02/2022 11:01:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=152
06/02/2022 11:01:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/02/2022 11:01:16 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/02/2022 11:01:24 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.8933348666935004 on epoch=153
06/02/2022 11:01:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/02/2022 11:01:29 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/02/2022 11:01:31 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=155
06/02/2022 11:01:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/02/2022 11:01:36 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/02/2022 11:01:44 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8976530485116823 on epoch=157
06/02/2022 11:01:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/02/2022 11:01:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=158
06/02/2022 11:01:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/02/2022 11:01:54 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/02/2022 11:01:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/02/2022 11:02:04 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.8976660820731029 on epoch=160
06/02/2022 11:02:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
06/02/2022 11:02:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/02/2022 11:02:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/02/2022 11:02:14 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/02/2022 11:02:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/02/2022 11:02:25 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8975211795373087 on epoch=164
06/02/2022 11:02:27 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/02/2022 11:02:30 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/02/2022 11:02:32 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/02/2022 11:02:35 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/02/2022 11:02:37 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/02/2022 11:02:45 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.8975211795373087 on epoch=167
06/02/2022 11:02:48 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/02/2022 11:02:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
06/02/2022 11:02:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/02/2022 11:02:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/02/2022 11:02:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/02/2022 11:03:06 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.901852394916911 on epoch=171
06/02/2022 11:03:06 - INFO - __main__ - Saving model with best Classification-F1: 0.9015615835777127 -> 0.901852394916911 on epoch=171, global_step=2400
06/02/2022 11:03:09 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/02/2022 11:03:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/02/2022 11:03:14 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/02/2022 11:03:16 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
06/02/2022 11:03:19 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/02/2022 11:03:27 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.901852394916911 on epoch=174
06/02/2022 11:03:30 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/02/2022 11:03:33 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/02/2022 11:03:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/02/2022 11:03:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=177
06/02/2022 11:03:40 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/02/2022 11:03:49 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8975211795373087 on epoch=178
06/02/2022 11:03:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/02/2022 11:03:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/02/2022 11:03:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/02/2022 11:03:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/02/2022 11:04:01 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/02/2022 11:04:09 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.901852394916911 on epoch=182
06/02/2022 11:04:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/02/2022 11:04:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/02/2022 11:04:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/02/2022 11:04:19 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/02/2022 11:04:22 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/02/2022 11:04:30 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8975211795373087 on epoch=185
06/02/2022 11:04:33 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/02/2022 11:04:35 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/02/2022 11:04:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/02/2022 11:04:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/02/2022 11:04:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/02/2022 11:04:51 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8975211795373087 on epoch=189
06/02/2022 11:04:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/02/2022 11:04:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/02/2022 11:04:59 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/02/2022 11:05:01 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/02/2022 11:05:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/02/2022 11:05:12 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8933348666935004 on epoch=192
06/02/2022 11:05:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/02/2022 11:05:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/02/2022 11:05:20 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/02/2022 11:05:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/02/2022 11:05:25 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/02/2022 11:05:33 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.8933348666935004 on epoch=196
06/02/2022 11:05:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=197
06/02/2022 11:05:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/02/2022 11:05:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/02/2022 11:05:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/02/2022 11:05:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/02/2022 11:05:54 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8975211795373087 on epoch=199
06/02/2022 11:05:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/02/2022 11:05:59 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/02/2022 11:06:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/02/2022 11:06:04 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/02/2022 11:06:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/02/2022 11:06:15 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8975211795373087 on epoch=203
06/02/2022 11:06:18 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/02/2022 11:06:20 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/02/2022 11:06:23 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/02/2022 11:06:25 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/02/2022 11:06:28 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/02/2022 11:06:36 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8933348666935004 on epoch=207
06/02/2022 11:06:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/02/2022 11:06:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/02/2022 11:06:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/02/2022 11:06:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/02/2022 11:06:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/02/2022 11:06:58 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8975211795373087 on epoch=210
06/02/2022 11:07:00 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/02/2022 11:07:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/02/2022 11:07:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/02/2022 11:07:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/02/2022 11:07:10 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/02/2022 11:07:12 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 11:07:12 - INFO - __main__ - Printing 3 examples
06/02/2022 11:07:12 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 11:07:12 - INFO - __main__ - ['Animal']
06/02/2022 11:07:12 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 11:07:12 - INFO - __main__ - ['Animal']
06/02/2022 11:07:12 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 11:07:12 - INFO - __main__ - ['Animal']
06/02/2022 11:07:12 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:07:12 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:07:12 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 11:07:12 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 11:07:12 - INFO - __main__ - Printing 3 examples
06/02/2022 11:07:12 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 11:07:12 - INFO - __main__ - ['Animal']
06/02/2022 11:07:12 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 11:07:12 - INFO - __main__ - ['Animal']
06/02/2022 11:07:12 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 11:07:12 - INFO - __main__ - ['Animal']
06/02/2022 11:07:12 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:07:12 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:07:13 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 11:07:19 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8933348666935004 on epoch=214
06/02/2022 11:07:19 - INFO - __main__ - save last model!
06/02/2022 11:07:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 11:07:19 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 11:07:19 - INFO - __main__ - Printing 3 examples
06/02/2022 11:07:19 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 11:07:19 - INFO - __main__ - ['Animal']
06/02/2022 11:07:19 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 11:07:19 - INFO - __main__ - ['Animal']
06/02/2022 11:07:19 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 11:07:19 - INFO - __main__ - ['Village']
06/02/2022 11:07:19 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:07:21 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:07:24 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 11:07:28 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 11:07:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 11:07:28 - INFO - __main__ - Starting training!
06/02/2022 11:10:19 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
06/02/2022 11:10:19 - INFO - __main__ - Classification-F1 on test data: 0.6215
06/02/2022 11:10:19 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.901852394916911, test_performance=0.6215326004773374
06/02/2022 11:10:19 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
06/02/2022 11:10:20 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 11:10:20 - INFO - __main__ - Printing 3 examples
06/02/2022 11:10:20 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 11:10:20 - INFO - __main__ - ['Animal']
06/02/2022 11:10:20 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 11:10:20 - INFO - __main__ - ['Animal']
06/02/2022 11:10:20 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 11:10:20 - INFO - __main__ - ['Animal']
06/02/2022 11:10:20 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:10:20 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:10:20 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 11:10:20 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 11:10:20 - INFO - __main__ - Printing 3 examples
06/02/2022 11:10:20 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 11:10:20 - INFO - __main__ - ['Animal']
06/02/2022 11:10:20 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 11:10:20 - INFO - __main__ - ['Animal']
06/02/2022 11:10:20 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 11:10:20 - INFO - __main__ - ['Animal']
06/02/2022 11:10:20 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:10:20 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:10:20 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 11:10:37 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 11:10:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 11:10:38 - INFO - __main__ - Starting training!
06/02/2022 11:10:42 - INFO - __main__ - Step 10 Global step 10 Train loss 5.42 on epoch=0
06/02/2022 11:10:44 - INFO - __main__ - Step 20 Global step 20 Train loss 4.37 on epoch=1
06/02/2022 11:10:47 - INFO - __main__ - Step 30 Global step 30 Train loss 3.65 on epoch=2
06/02/2022 11:10:49 - INFO - __main__ - Step 40 Global step 40 Train loss 3.21 on epoch=2
06/02/2022 11:10:52 - INFO - __main__ - Step 50 Global step 50 Train loss 2.89 on epoch=3
06/02/2022 11:10:57 - INFO - __main__ - Global step 50 Train loss 3.91 Classification-F1 0.10032311567671368 on epoch=3
06/02/2022 11:10:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10032311567671368 on epoch=3, global_step=50
06/02/2022 11:10:59 - INFO - __main__ - Step 60 Global step 60 Train loss 2.61 on epoch=4
06/02/2022 11:11:02 - INFO - __main__ - Step 70 Global step 70 Train loss 2.31 on epoch=4
06/02/2022 11:11:04 - INFO - __main__ - Step 80 Global step 80 Train loss 2.12 on epoch=5
06/02/2022 11:11:07 - INFO - __main__ - Step 90 Global step 90 Train loss 1.95 on epoch=6
06/02/2022 11:11:09 - INFO - __main__ - Step 100 Global step 100 Train loss 2.04 on epoch=7
06/02/2022 11:11:14 - INFO - __main__ - Global step 100 Train loss 2.20 Classification-F1 0.13917340267766318 on epoch=7
06/02/2022 11:11:14 - INFO - __main__ - Saving model with best Classification-F1: 0.10032311567671368 -> 0.13917340267766318 on epoch=7, global_step=100
06/02/2022 11:11:16 - INFO - __main__ - Step 110 Global step 110 Train loss 1.75 on epoch=7
06/02/2022 11:11:19 - INFO - __main__ - Step 120 Global step 120 Train loss 1.79 on epoch=8
06/02/2022 11:11:21 - INFO - __main__ - Step 130 Global step 130 Train loss 1.56 on epoch=9
06/02/2022 11:11:24 - INFO - __main__ - Step 140 Global step 140 Train loss 1.65 on epoch=9
06/02/2022 11:11:26 - INFO - __main__ - Step 150 Global step 150 Train loss 1.61 on epoch=10
06/02/2022 11:11:31 - INFO - __main__ - Global step 150 Train loss 1.67 Classification-F1 0.18214507602441218 on epoch=10
06/02/2022 11:11:31 - INFO - __main__ - Saving model with best Classification-F1: 0.13917340267766318 -> 0.18214507602441218 on epoch=10, global_step=150
06/02/2022 11:11:34 - INFO - __main__ - Step 160 Global step 160 Train loss 1.40 on epoch=11
06/02/2022 11:11:36 - INFO - __main__ - Step 170 Global step 170 Train loss 1.48 on epoch=12
06/02/2022 11:11:39 - INFO - __main__ - Step 180 Global step 180 Train loss 1.28 on epoch=12
06/02/2022 11:11:41 - INFO - __main__ - Step 190 Global step 190 Train loss 1.21 on epoch=13
06/02/2022 11:11:44 - INFO - __main__ - Step 200 Global step 200 Train loss 1.17 on epoch=14
06/02/2022 11:11:49 - INFO - __main__ - Global step 200 Train loss 1.31 Classification-F1 0.33982353179339575 on epoch=14
06/02/2022 11:11:49 - INFO - __main__ - Saving model with best Classification-F1: 0.18214507602441218 -> 0.33982353179339575 on epoch=14, global_step=200
06/02/2022 11:11:51 - INFO - __main__ - Step 210 Global step 210 Train loss 1.03 on epoch=14
06/02/2022 11:11:54 - INFO - __main__ - Step 220 Global step 220 Train loss 0.93 on epoch=15
06/02/2022 11:11:56 - INFO - __main__ - Step 230 Global step 230 Train loss 0.90 on epoch=16
06/02/2022 11:11:59 - INFO - __main__ - Step 240 Global step 240 Train loss 1.01 on epoch=17
06/02/2022 11:12:01 - INFO - __main__ - Step 250 Global step 250 Train loss 0.71 on epoch=17
06/02/2022 11:12:07 - INFO - __main__ - Global step 250 Train loss 0.91 Classification-F1 0.3837512667059385 on epoch=17
06/02/2022 11:12:07 - INFO - __main__ - Saving model with best Classification-F1: 0.33982353179339575 -> 0.3837512667059385 on epoch=17, global_step=250
06/02/2022 11:12:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.77 on epoch=18
06/02/2022 11:12:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.68 on epoch=19
06/02/2022 11:12:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.67 on epoch=19
06/02/2022 11:12:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.59 on epoch=20
06/02/2022 11:12:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.62 on epoch=21
06/02/2022 11:12:25 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.4379168604527028 on epoch=21
06/02/2022 11:12:25 - INFO - __main__ - Saving model with best Classification-F1: 0.3837512667059385 -> 0.4379168604527028 on epoch=21, global_step=300
06/02/2022 11:12:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.55 on epoch=22
06/02/2022 11:12:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.59 on epoch=22
06/02/2022 11:12:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.50 on epoch=23
06/02/2022 11:12:35 - INFO - __main__ - Step 340 Global step 340 Train loss 0.54 on epoch=24
06/02/2022 11:12:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.50 on epoch=24
06/02/2022 11:12:45 - INFO - __main__ - Global step 350 Train loss 0.53 Classification-F1 0.561728596257683 on epoch=24
06/02/2022 11:12:45 - INFO - __main__ - Saving model with best Classification-F1: 0.4379168604527028 -> 0.561728596257683 on epoch=24, global_step=350
06/02/2022 11:12:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.55 on epoch=25
06/02/2022 11:12:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.42 on epoch=26
06/02/2022 11:12:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.52 on epoch=27
06/02/2022 11:12:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.42 on epoch=27
06/02/2022 11:12:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.42 on epoch=28
06/02/2022 11:13:04 - INFO - __main__ - Global step 400 Train loss 0.47 Classification-F1 0.592666076201788 on epoch=28
06/02/2022 11:13:04 - INFO - __main__ - Saving model with best Classification-F1: 0.561728596257683 -> 0.592666076201788 on epoch=28, global_step=400
06/02/2022 11:13:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.39 on epoch=29
06/02/2022 11:13:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.49 on epoch=29
06/02/2022 11:13:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.32 on epoch=30
06/02/2022 11:13:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=31
06/02/2022 11:13:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=32
06/02/2022 11:13:24 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.7412984599364528 on epoch=32
06/02/2022 11:13:24 - INFO - __main__ - Saving model with best Classification-F1: 0.592666076201788 -> 0.7412984599364528 on epoch=32, global_step=450
06/02/2022 11:13:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.40 on epoch=32
06/02/2022 11:13:29 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=33
06/02/2022 11:13:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.42 on epoch=34
06/02/2022 11:13:34 - INFO - __main__ - Step 490 Global step 490 Train loss 0.33 on epoch=34
06/02/2022 11:13:37 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=35
06/02/2022 11:13:44 - INFO - __main__ - Global step 500 Train loss 0.35 Classification-F1 0.6957250120298157 on epoch=35
06/02/2022 11:13:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.34 on epoch=36
06/02/2022 11:13:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=37
06/02/2022 11:13:52 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=37
06/02/2022 11:13:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=38
06/02/2022 11:13:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=39
06/02/2022 11:14:03 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.7192833508253896 on epoch=39
06/02/2022 11:14:06 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=39
06/02/2022 11:14:08 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=40
06/02/2022 11:14:11 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=41
06/02/2022 11:14:13 - INFO - __main__ - Step 590 Global step 590 Train loss 0.33 on epoch=42
06/02/2022 11:14:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=42
06/02/2022 11:14:22 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.7054779538650506 on epoch=42
06/02/2022 11:14:25 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=43
06/02/2022 11:14:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=44
06/02/2022 11:14:30 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=44
06/02/2022 11:14:33 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=45
06/02/2022 11:14:35 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
06/02/2022 11:14:42 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.7575904413660055 on epoch=46
06/02/2022 11:14:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7412984599364528 -> 0.7575904413660055 on epoch=46, global_step=650
06/02/2022 11:14:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.29 on epoch=47
06/02/2022 11:14:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=47
06/02/2022 11:14:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=48
06/02/2022 11:14:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.25 on epoch=49
06/02/2022 11:14:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.25 on epoch=49
06/02/2022 11:15:01 - INFO - __main__ - Global step 700 Train loss 0.24 Classification-F1 0.7230660266713398 on epoch=49
06/02/2022 11:15:04 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=50
06/02/2022 11:15:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=51
06/02/2022 11:15:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=52
06/02/2022 11:15:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=52
06/02/2022 11:15:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=53
06/02/2022 11:15:21 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.7205071406209925 on epoch=53
06/02/2022 11:15:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=54
06/02/2022 11:15:26 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=54
06/02/2022 11:15:28 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=55
06/02/2022 11:15:31 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=56
06/02/2022 11:15:34 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=57
06/02/2022 11:15:40 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.7117323813818371 on epoch=57
06/02/2022 11:15:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=57
06/02/2022 11:15:45 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=58
06/02/2022 11:15:48 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=59
06/02/2022 11:15:50 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=59
06/02/2022 11:15:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=60
06/02/2022 11:15:59 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.735345760576409 on epoch=60
06/02/2022 11:16:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=61
06/02/2022 11:16:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=62
06/02/2022 11:16:07 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=62
06/02/2022 11:16:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=63
06/02/2022 11:16:12 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=64
06/02/2022 11:16:19 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.8368545279687869 on epoch=64
06/02/2022 11:16:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7575904413660055 -> 0.8368545279687869 on epoch=64, global_step=900
06/02/2022 11:16:22 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=64
06/02/2022 11:16:24 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=65
06/02/2022 11:16:27 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=66
06/02/2022 11:16:29 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=67
06/02/2022 11:16:32 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=67
06/02/2022 11:16:38 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.7858315187858587 on epoch=67
06/02/2022 11:16:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/02/2022 11:16:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.24 on epoch=69
06/02/2022 11:16:46 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=69
06/02/2022 11:16:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=70
06/02/2022 11:16:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=71
06/02/2022 11:16:57 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.8870338063428425 on epoch=71
06/02/2022 11:16:57 - INFO - __main__ - Saving model with best Classification-F1: 0.8368545279687869 -> 0.8870338063428425 on epoch=71, global_step=1000
06/02/2022 11:17:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=72
06/02/2022 11:17:02 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=72
06/02/2022 11:17:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=73
06/02/2022 11:17:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=74
06/02/2022 11:17:10 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=74
06/02/2022 11:17:17 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.887101778150165 on epoch=74
06/02/2022 11:17:17 - INFO - __main__ - Saving model with best Classification-F1: 0.8870338063428425 -> 0.887101778150165 on epoch=74, global_step=1050
06/02/2022 11:17:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
06/02/2022 11:17:22 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=76
06/02/2022 11:17:24 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=77
06/02/2022 11:17:27 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
06/02/2022 11:17:29 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=78
06/02/2022 11:17:36 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.893379617394536 on epoch=78
06/02/2022 11:17:36 - INFO - __main__ - Saving model with best Classification-F1: 0.887101778150165 -> 0.893379617394536 on epoch=78, global_step=1100
06/02/2022 11:17:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=79
06/02/2022 11:17:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
06/02/2022 11:17:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=80
06/02/2022 11:17:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=81
06/02/2022 11:17:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=82
06/02/2022 11:17:56 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.893379617394536 on epoch=82
06/02/2022 11:17:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=82
06/02/2022 11:18:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
06/02/2022 11:18:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
06/02/2022 11:18:06 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=84
06/02/2022 11:18:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
06/02/2022 11:18:15 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.905624986368296 on epoch=85
06/02/2022 11:18:15 - INFO - __main__ - Saving model with best Classification-F1: 0.893379617394536 -> 0.905624986368296 on epoch=85, global_step=1200
06/02/2022 11:18:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
06/02/2022 11:18:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/02/2022 11:18:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=87
06/02/2022 11:18:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=88
06/02/2022 11:18:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/02/2022 11:18:34 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.893379617394536 on epoch=89
06/02/2022 11:18:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
06/02/2022 11:18:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=90
06/02/2022 11:18:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=91
06/02/2022 11:18:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=92
06/02/2022 11:18:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
06/02/2022 11:18:54 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.9016893795641424 on epoch=92
06/02/2022 11:18:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
06/02/2022 11:18:59 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
06/02/2022 11:19:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
06/02/2022 11:19:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
06/02/2022 11:19:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/02/2022 11:19:13 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.893351973242865 on epoch=96
06/02/2022 11:19:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=97
06/02/2022 11:19:18 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
06/02/2022 11:19:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/02/2022 11:19:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
06/02/2022 11:19:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/02/2022 11:19:33 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.8890133306499531 on epoch=99
06/02/2022 11:19:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
06/02/2022 11:19:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
06/02/2022 11:19:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=102
06/02/2022 11:19:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
06/02/2022 11:19:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
06/02/2022 11:19:52 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.8890133306499529 on epoch=103
06/02/2022 11:19:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/02/2022 11:19:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=104
06/02/2022 11:20:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
06/02/2022 11:20:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
06/02/2022 11:20:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
06/02/2022 11:20:12 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.8931562054491126 on epoch=107
06/02/2022 11:20:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=107
06/02/2022 11:20:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
06/02/2022 11:20:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/02/2022 11:20:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=109
06/02/2022 11:20:24 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
06/02/2022 11:20:31 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.8393845954804209 on epoch=110
06/02/2022 11:20:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
06/02/2022 11:20:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=112
06/02/2022 11:20:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
06/02/2022 11:20:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/02/2022 11:20:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/02/2022 11:20:51 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8932086040672379 on epoch=114
06/02/2022 11:20:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=114
06/02/2022 11:20:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=115
06/02/2022 11:20:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/02/2022 11:21:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/02/2022 11:21:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=117
06/02/2022 11:21:11 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.905860119218753 on epoch=117
06/02/2022 11:21:11 - INFO - __main__ - Saving model with best Classification-F1: 0.905624986368296 -> 0.905860119218753 on epoch=117, global_step=1650
06/02/2022 11:21:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=118
06/02/2022 11:21:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/02/2022 11:21:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/02/2022 11:21:22 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/02/2022 11:21:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
06/02/2022 11:21:32 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.9016893795641424 on epoch=121
06/02/2022 11:21:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
06/02/2022 11:21:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=122
06/02/2022 11:21:39 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/02/2022 11:21:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/02/2022 11:21:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/02/2022 11:21:52 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.8975186399095316 on epoch=124
06/02/2022 11:21:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/02/2022 11:21:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
06/02/2022 11:21:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/02/2022 11:22:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/02/2022 11:22:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/02/2022 11:22:12 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7841784290048606 on epoch=128
06/02/2022 11:22:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
06/02/2022 11:22:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/02/2022 11:22:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
06/02/2022 11:22:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=131
06/02/2022 11:22:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/02/2022 11:22:31 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.8372608766747168 on epoch=132
06/02/2022 11:22:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
06/02/2022 11:22:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
06/02/2022 11:22:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/02/2022 11:22:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/02/2022 11:22:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/02/2022 11:22:51 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.8890133306499531 on epoch=135
06/02/2022 11:22:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/02/2022 11:22:56 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/02/2022 11:22:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/02/2022 11:23:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/02/2022 11:23:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/02/2022 11:23:11 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7843301724691948 on epoch=139
06/02/2022 11:23:14 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/02/2022 11:23:16 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/02/2022 11:23:19 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/02/2022 11:23:21 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/02/2022 11:23:24 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/02/2022 11:23:31 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.8372608766747168 on epoch=142
06/02/2022 11:23:34 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/02/2022 11:23:36 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/02/2022 11:23:38 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/02/2022 11:23:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/02/2022 11:23:43 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/02/2022 11:23:51 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8394114143091255 on epoch=146
06/02/2022 11:23:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/02/2022 11:23:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
06/02/2022 11:23:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/02/2022 11:24:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/02/2022 11:24:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/02/2022 11:24:10 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.8394114143091255 on epoch=149
06/02/2022 11:24:13 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/02/2022 11:24:15 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/02/2022 11:24:18 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/02/2022 11:24:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/02/2022 11:24:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/02/2022 11:24:30 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8975227128974755 on epoch=153
06/02/2022 11:24:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/02/2022 11:24:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=154
06/02/2022 11:24:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/02/2022 11:24:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=156
06/02/2022 11:24:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/02/2022 11:24:50 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.9017090257412839 on epoch=157
06/02/2022 11:24:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/02/2022 11:24:55 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/02/2022 11:24:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/02/2022 11:25:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
06/02/2022 11:25:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/02/2022 11:25:10 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.9016893795641423 on epoch=160
06/02/2022 11:25:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/02/2022 11:25:15 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/02/2022 11:25:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/02/2022 11:25:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/02/2022 11:25:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/02/2022 11:25:31 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8930652348916105 on epoch=164
06/02/2022 11:25:34 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/02/2022 11:25:36 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=165
06/02/2022 11:25:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/02/2022 11:25:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/02/2022 11:25:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/02/2022 11:25:51 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8888773886876353 on epoch=167
06/02/2022 11:25:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/02/2022 11:25:56 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/02/2022 11:25:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/02/2022 11:26:01 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/02/2022 11:26:03 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/02/2022 11:26:12 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8890133306499531 on epoch=171
06/02/2022 11:26:14 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
06/02/2022 11:26:17 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/02/2022 11:26:19 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/02/2022 11:26:22 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/02/2022 11:26:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/02/2022 11:26:32 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8930652348916105 on epoch=174
06/02/2022 11:26:35 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/02/2022 11:26:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/02/2022 11:26:40 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/02/2022 11:26:42 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/02/2022 11:26:45 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/02/2022 11:26:53 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8888773886876353 on epoch=178
06/02/2022 11:26:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/02/2022 11:26:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
06/02/2022 11:27:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/02/2022 11:27:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/02/2022 11:27:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/02/2022 11:27:12 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8354960899315738 on epoch=182
06/02/2022 11:27:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/02/2022 11:27:17 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/02/2022 11:27:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/02/2022 11:27:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
06/02/2022 11:27:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/02/2022 11:27:33 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.8354853084928986 on epoch=185
06/02/2022 11:27:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/02/2022 11:27:38 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/02/2022 11:27:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/02/2022 11:27:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/02/2022 11:27:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/02/2022 11:27:53 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7841885762412607 on epoch=189
06/02/2022 11:27:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/02/2022 11:27:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/02/2022 11:28:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/02/2022 11:28:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/02/2022 11:28:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/02/2022 11:28:14 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7918088970968756 on epoch=192
06/02/2022 11:28:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=193
06/02/2022 11:28:19 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/02/2022 11:28:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/02/2022 11:28:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/02/2022 11:28:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
06/02/2022 11:28:33 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7459153920610277 on epoch=196
06/02/2022 11:28:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/02/2022 11:28:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/02/2022 11:28:41 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/02/2022 11:28:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/02/2022 11:28:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/02/2022 11:28:53 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7423311626703468 on epoch=199
06/02/2022 11:28:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/02/2022 11:28:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/02/2022 11:29:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/02/2022 11:29:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
06/02/2022 11:29:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
06/02/2022 11:29:13 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.8411587261370824 on epoch=203
06/02/2022 11:29:15 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/02/2022 11:29:18 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/02/2022 11:29:20 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/02/2022 11:29:23 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/02/2022 11:29:25 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/02/2022 11:29:33 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9016804189906656 on epoch=207
06/02/2022 11:29:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/02/2022 11:29:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/02/2022 11:29:40 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=209
06/02/2022 11:29:43 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/02/2022 11:29:45 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/02/2022 11:29:53 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.897509679336055 on epoch=210
06/02/2022 11:29:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/02/2022 11:29:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/02/2022 11:30:00 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/02/2022 11:30:03 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/02/2022 11:30:05 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/02/2022 11:30:07 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 11:30:07 - INFO - __main__ - Printing 3 examples
06/02/2022 11:30:07 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 11:30:07 - INFO - __main__ - ['Animal']
06/02/2022 11:30:07 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 11:30:07 - INFO - __main__ - ['Animal']
06/02/2022 11:30:07 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 11:30:07 - INFO - __main__ - ['Animal']
06/02/2022 11:30:07 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:30:07 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:30:07 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 11:30:07 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 11:30:07 - INFO - __main__ - Printing 3 examples
06/02/2022 11:30:07 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 11:30:07 - INFO - __main__ - ['Animal']
06/02/2022 11:30:07 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 11:30:07 - INFO - __main__ - ['Animal']
06/02/2022 11:30:07 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 11:30:07 - INFO - __main__ - ['Animal']
06/02/2022 11:30:07 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:30:07 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:30:07 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 11:30:13 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8974941061468577 on epoch=214
06/02/2022 11:30:13 - INFO - __main__ - save last model!
06/02/2022 11:30:13 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 11:30:13 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 11:30:13 - INFO - __main__ - Printing 3 examples
06/02/2022 11:30:13 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 11:30:13 - INFO - __main__ - ['Animal']
06/02/2022 11:30:13 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 11:30:13 - INFO - __main__ - ['Animal']
06/02/2022 11:30:13 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 11:30:13 - INFO - __main__ - ['Village']
06/02/2022 11:30:13 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:30:15 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:30:18 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 11:30:23 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 11:30:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 11:30:23 - INFO - __main__ - Starting training!
06/02/2022 11:33:03 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
06/02/2022 11:33:03 - INFO - __main__ - Classification-F1 on test data: 0.5461
06/02/2022 11:33:03 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.905860119218753, test_performance=0.5461435584657114
06/02/2022 11:33:03 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
06/02/2022 11:33:04 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 11:33:04 - INFO - __main__ - Printing 3 examples
06/02/2022 11:33:04 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 11:33:04 - INFO - __main__ - ['Animal']
06/02/2022 11:33:04 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 11:33:04 - INFO - __main__ - ['Animal']
06/02/2022 11:33:04 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 11:33:04 - INFO - __main__ - ['Animal']
06/02/2022 11:33:04 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:33:04 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:33:04 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 11:33:04 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 11:33:04 - INFO - __main__ - Printing 3 examples
06/02/2022 11:33:04 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 11:33:04 - INFO - __main__ - ['Animal']
06/02/2022 11:33:04 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 11:33:04 - INFO - __main__ - ['Animal']
06/02/2022 11:33:04 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 11:33:04 - INFO - __main__ - ['Animal']
06/02/2022 11:33:04 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:33:04 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:33:05 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 11:33:21 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 11:33:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 11:33:22 - INFO - __main__ - Starting training!
06/02/2022 11:33:26 - INFO - __main__ - Step 10 Global step 10 Train loss 5.69 on epoch=0
06/02/2022 11:33:28 - INFO - __main__ - Step 20 Global step 20 Train loss 4.45 on epoch=1
06/02/2022 11:33:31 - INFO - __main__ - Step 30 Global step 30 Train loss 3.91 on epoch=2
06/02/2022 11:33:33 - INFO - __main__ - Step 40 Global step 40 Train loss 3.39 on epoch=2
06/02/2022 11:33:36 - INFO - __main__ - Step 50 Global step 50 Train loss 3.24 on epoch=3
06/02/2022 11:33:40 - INFO - __main__ - Global step 50 Train loss 4.14 Classification-F1 0.07477919794414012 on epoch=3
06/02/2022 11:33:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07477919794414012 on epoch=3, global_step=50
06/02/2022 11:33:43 - INFO - __main__ - Step 60 Global step 60 Train loss 3.05 on epoch=4
06/02/2022 11:33:45 - INFO - __main__ - Step 70 Global step 70 Train loss 2.65 on epoch=4
06/02/2022 11:33:48 - INFO - __main__ - Step 80 Global step 80 Train loss 2.52 on epoch=5
06/02/2022 11:33:50 - INFO - __main__ - Step 90 Global step 90 Train loss 2.17 on epoch=6
06/02/2022 11:33:53 - INFO - __main__ - Step 100 Global step 100 Train loss 2.42 on epoch=7
06/02/2022 11:33:58 - INFO - __main__ - Global step 100 Train loss 2.56 Classification-F1 0.11540480852808759 on epoch=7
06/02/2022 11:33:58 - INFO - __main__ - Saving model with best Classification-F1: 0.07477919794414012 -> 0.11540480852808759 on epoch=7, global_step=100
06/02/2022 11:34:00 - INFO - __main__ - Step 110 Global step 110 Train loss 2.10 on epoch=7
06/02/2022 11:34:03 - INFO - __main__ - Step 120 Global step 120 Train loss 2.16 on epoch=8
06/02/2022 11:34:05 - INFO - __main__ - Step 130 Global step 130 Train loss 1.98 on epoch=9
06/02/2022 11:34:08 - INFO - __main__ - Step 140 Global step 140 Train loss 1.93 on epoch=9
06/02/2022 11:34:10 - INFO - __main__ - Step 150 Global step 150 Train loss 1.81 on epoch=10
06/02/2022 11:34:15 - INFO - __main__ - Global step 150 Train loss 2.00 Classification-F1 0.1472232963115316 on epoch=10
06/02/2022 11:34:15 - INFO - __main__ - Saving model with best Classification-F1: 0.11540480852808759 -> 0.1472232963115316 on epoch=10, global_step=150
06/02/2022 11:34:17 - INFO - __main__ - Step 160 Global step 160 Train loss 1.68 on epoch=11
06/02/2022 11:34:20 - INFO - __main__ - Step 170 Global step 170 Train loss 1.69 on epoch=12
06/02/2022 11:34:22 - INFO - __main__ - Step 180 Global step 180 Train loss 1.64 on epoch=12
06/02/2022 11:34:25 - INFO - __main__ - Step 190 Global step 190 Train loss 1.58 on epoch=13
06/02/2022 11:34:27 - INFO - __main__ - Step 200 Global step 200 Train loss 1.41 on epoch=14
06/02/2022 11:34:32 - INFO - __main__ - Global step 200 Train loss 1.60 Classification-F1 0.17518692922023596 on epoch=14
06/02/2022 11:34:32 - INFO - __main__ - Saving model with best Classification-F1: 0.1472232963115316 -> 0.17518692922023596 on epoch=14, global_step=200
06/02/2022 11:34:35 - INFO - __main__ - Step 210 Global step 210 Train loss 1.48 on epoch=14
06/02/2022 11:34:37 - INFO - __main__ - Step 220 Global step 220 Train loss 1.26 on epoch=15
06/02/2022 11:34:40 - INFO - __main__ - Step 230 Global step 230 Train loss 1.27 on epoch=16
06/02/2022 11:34:42 - INFO - __main__ - Step 240 Global step 240 Train loss 1.33 on epoch=17
06/02/2022 11:34:45 - INFO - __main__ - Step 250 Global step 250 Train loss 1.11 on epoch=17
06/02/2022 11:34:50 - INFO - __main__ - Global step 250 Train loss 1.29 Classification-F1 0.26105795951017496 on epoch=17
06/02/2022 11:34:50 - INFO - __main__ - Saving model with best Classification-F1: 0.17518692922023596 -> 0.26105795951017496 on epoch=17, global_step=250
06/02/2022 11:34:52 - INFO - __main__ - Step 260 Global step 260 Train loss 1.08 on epoch=18
06/02/2022 11:34:55 - INFO - __main__ - Step 270 Global step 270 Train loss 1.03 on epoch=19
06/02/2022 11:34:57 - INFO - __main__ - Step 280 Global step 280 Train loss 1.07 on epoch=19
06/02/2022 11:35:00 - INFO - __main__ - Step 290 Global step 290 Train loss 1.01 on epoch=20
06/02/2022 11:35:02 - INFO - __main__ - Step 300 Global step 300 Train loss 1.00 on epoch=21
06/02/2022 11:35:08 - INFO - __main__ - Global step 300 Train loss 1.04 Classification-F1 0.39418826297050474 on epoch=21
06/02/2022 11:35:08 - INFO - __main__ - Saving model with best Classification-F1: 0.26105795951017496 -> 0.39418826297050474 on epoch=21, global_step=300
06/02/2022 11:35:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.96 on epoch=22
06/02/2022 11:35:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.80 on epoch=22
06/02/2022 11:35:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.79 on epoch=23
06/02/2022 11:35:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.69 on epoch=24
06/02/2022 11:35:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.72 on epoch=24
06/02/2022 11:35:26 - INFO - __main__ - Global step 350 Train loss 0.79 Classification-F1 0.437306708422953 on epoch=24
06/02/2022 11:35:26 - INFO - __main__ - Saving model with best Classification-F1: 0.39418826297050474 -> 0.437306708422953 on epoch=24, global_step=350
06/02/2022 11:35:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.74 on epoch=25
06/02/2022 11:35:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.61 on epoch=26
06/02/2022 11:35:34 - INFO - __main__ - Step 380 Global step 380 Train loss 0.67 on epoch=27
06/02/2022 11:35:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.54 on epoch=27
06/02/2022 11:35:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.58 on epoch=28
06/02/2022 11:35:45 - INFO - __main__ - Global step 400 Train loss 0.63 Classification-F1 0.47422190063687153 on epoch=28
06/02/2022 11:35:45 - INFO - __main__ - Saving model with best Classification-F1: 0.437306708422953 -> 0.47422190063687153 on epoch=28, global_step=400
06/02/2022 11:35:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.67 on epoch=29
06/02/2022 11:35:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.53 on epoch=29
06/02/2022 11:35:53 - INFO - __main__ - Step 430 Global step 430 Train loss 0.46 on epoch=30
06/02/2022 11:35:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.48 on epoch=31
06/02/2022 11:35:58 - INFO - __main__ - Step 450 Global step 450 Train loss 0.43 on epoch=32
06/02/2022 11:36:04 - INFO - __main__ - Global step 450 Train loss 0.52 Classification-F1 0.571142098113853 on epoch=32
06/02/2022 11:36:04 - INFO - __main__ - Saving model with best Classification-F1: 0.47422190063687153 -> 0.571142098113853 on epoch=32, global_step=450
06/02/2022 11:36:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.46 on epoch=32
06/02/2022 11:36:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.44 on epoch=33
06/02/2022 11:36:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.49 on epoch=34
06/02/2022 11:36:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.53 on epoch=34
06/02/2022 11:36:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.38 on epoch=35
06/02/2022 11:36:24 - INFO - __main__ - Global step 500 Train loss 0.46 Classification-F1 0.6490650336380887 on epoch=35
06/02/2022 11:36:24 - INFO - __main__ - Saving model with best Classification-F1: 0.571142098113853 -> 0.6490650336380887 on epoch=35, global_step=500
06/02/2022 11:36:26 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=36
06/02/2022 11:36:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.47 on epoch=37
06/02/2022 11:36:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.42 on epoch=37
06/02/2022 11:36:34 - INFO - __main__ - Step 540 Global step 540 Train loss 0.36 on epoch=38
06/02/2022 11:36:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=39
06/02/2022 11:36:43 - INFO - __main__ - Global step 550 Train loss 0.40 Classification-F1 0.6536531139294939 on epoch=39
06/02/2022 11:36:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6490650336380887 -> 0.6536531139294939 on epoch=39, global_step=550
06/02/2022 11:36:45 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=39
06/02/2022 11:36:48 - INFO - __main__ - Step 570 Global step 570 Train loss 0.37 on epoch=40
06/02/2022 11:36:50 - INFO - __main__ - Step 580 Global step 580 Train loss 0.39 on epoch=41
06/02/2022 11:36:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.42 on epoch=42
06/02/2022 11:36:55 - INFO - __main__ - Step 600 Global step 600 Train loss 0.30 on epoch=42
06/02/2022 11:37:02 - INFO - __main__ - Global step 600 Train loss 0.38 Classification-F1 0.6567655683974469 on epoch=42
06/02/2022 11:37:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6536531139294939 -> 0.6567655683974469 on epoch=42, global_step=600
06/02/2022 11:37:04 - INFO - __main__ - Step 610 Global step 610 Train loss 0.31 on epoch=43
06/02/2022 11:37:07 - INFO - __main__ - Step 620 Global step 620 Train loss 0.33 on epoch=44
06/02/2022 11:37:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.28 on epoch=44
06/02/2022 11:37:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.33 on epoch=45
06/02/2022 11:37:14 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=46
06/02/2022 11:37:21 - INFO - __main__ - Global step 650 Train loss 0.30 Classification-F1 0.6893844928000527 on epoch=46
06/02/2022 11:37:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6567655683974469 -> 0.6893844928000527 on epoch=46, global_step=650
06/02/2022 11:37:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.27 on epoch=47
06/02/2022 11:37:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=47
06/02/2022 11:37:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.30 on epoch=48
06/02/2022 11:37:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=49
06/02/2022 11:37:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.28 on epoch=49
06/02/2022 11:37:40 - INFO - __main__ - Global step 700 Train loss 0.28 Classification-F1 0.6492619608938395 on epoch=49
06/02/2022 11:37:43 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=50
06/02/2022 11:37:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.27 on epoch=51
06/02/2022 11:37:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=52
06/02/2022 11:37:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=52
06/02/2022 11:37:53 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=53
06/02/2022 11:38:00 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.7225520627897537 on epoch=53
06/02/2022 11:38:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6893844928000527 -> 0.7225520627897537 on epoch=53, global_step=750
06/02/2022 11:38:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.32 on epoch=54
06/02/2022 11:38:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=54
06/02/2022 11:38:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.28 on epoch=55
06/02/2022 11:38:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=56
06/02/2022 11:38:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.29 on epoch=57
06/02/2022 11:38:19 - INFO - __main__ - Global step 800 Train loss 0.27 Classification-F1 0.707552001401217 on epoch=57
06/02/2022 11:38:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=57
06/02/2022 11:38:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=58
06/02/2022 11:38:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.28 on epoch=59
06/02/2022 11:38:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=59
06/02/2022 11:38:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=60
06/02/2022 11:38:39 - INFO - __main__ - Global step 850 Train loss 0.24 Classification-F1 0.6679868691863625 on epoch=60
06/02/2022 11:38:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=61
06/02/2022 11:38:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.25 on epoch=62
06/02/2022 11:38:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=62
06/02/2022 11:38:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.20 on epoch=63
06/02/2022 11:38:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.23 on epoch=64
06/02/2022 11:38:59 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.6599776423405705 on epoch=64
06/02/2022 11:39:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.25 on epoch=64
06/02/2022 11:39:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=65
06/02/2022 11:39:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=66
06/02/2022 11:39:08 - INFO - __main__ - Step 940 Global step 940 Train loss 0.22 on epoch=67
06/02/2022 11:39:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=67
06/02/2022 11:39:18 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.7706273378667542 on epoch=67
06/02/2022 11:39:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7225520627897537 -> 0.7706273378667542 on epoch=67, global_step=950
06/02/2022 11:39:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.21 on epoch=68
06/02/2022 11:39:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=69
06/02/2022 11:39:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=69
06/02/2022 11:39:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=70
06/02/2022 11:39:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=71
06/02/2022 11:39:37 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.7613534134680174 on epoch=71
06/02/2022 11:39:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=72
06/02/2022 11:39:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=72
06/02/2022 11:39:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=73
06/02/2022 11:39:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=74
06/02/2022 11:39:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=74
06/02/2022 11:39:56 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.676590814585215 on epoch=74
06/02/2022 11:39:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=75
06/02/2022 11:40:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=76
06/02/2022 11:40:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=77
06/02/2022 11:40:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=77
06/02/2022 11:40:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=78
06/02/2022 11:40:15 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.7623009734560054 on epoch=78
06/02/2022 11:40:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=79
06/02/2022 11:40:20 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=79
06/02/2022 11:40:23 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=80
06/02/2022 11:40:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=81
06/02/2022 11:40:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.22 on epoch=82
06/02/2022 11:40:34 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.7423301623914516 on epoch=82
06/02/2022 11:40:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=82
06/02/2022 11:40:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=83
06/02/2022 11:40:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=84
06/02/2022 11:40:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=84
06/02/2022 11:40:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=85
06/02/2022 11:40:53 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.7216344210586179 on epoch=85
06/02/2022 11:40:56 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=86
06/02/2022 11:40:58 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.18 on epoch=87
06/02/2022 11:41:01 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
06/02/2022 11:41:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=88
06/02/2022 11:41:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=89
06/02/2022 11:41:12 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.7739226791953582 on epoch=89
06/02/2022 11:41:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7706273378667542 -> 0.7739226791953582 on epoch=89, global_step=1250
06/02/2022 11:41:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=89
06/02/2022 11:41:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=90
06/02/2022 11:41:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=91
06/02/2022 11:41:22 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=92
06/02/2022 11:41:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=92
06/02/2022 11:41:32 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.7711147625354492 on epoch=92
06/02/2022 11:41:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
06/02/2022 11:41:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=94
06/02/2022 11:41:39 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.18 on epoch=94
06/02/2022 11:41:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=95
06/02/2022 11:41:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=96
06/02/2022 11:41:51 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.7739226791953582 on epoch=96
06/02/2022 11:41:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.13 on epoch=97
06/02/2022 11:41:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=97
06/02/2022 11:41:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=98
06/02/2022 11:42:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=99
06/02/2022 11:42:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.15 on epoch=99
06/02/2022 11:42:10 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.8329297994857767 on epoch=99
06/02/2022 11:42:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7739226791953582 -> 0.8329297994857767 on epoch=99, global_step=1400
06/02/2022 11:42:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=100
06/02/2022 11:42:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=101
06/02/2022 11:42:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=102
06/02/2022 11:42:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=102
06/02/2022 11:42:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=103
06/02/2022 11:42:29 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.8951723344813707 on epoch=103
06/02/2022 11:42:29 - INFO - __main__ - Saving model with best Classification-F1: 0.8329297994857767 -> 0.8951723344813707 on epoch=103, global_step=1450
06/02/2022 11:42:32 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=104
06/02/2022 11:42:34 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=104
06/02/2022 11:42:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
06/02/2022 11:42:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=106
06/02/2022 11:42:41 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=107
06/02/2022 11:42:48 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.8908622986390766 on epoch=107
06/02/2022 11:42:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=107
06/02/2022 11:42:53 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=108
06/02/2022 11:42:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
06/02/2022 11:42:58 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=109
06/02/2022 11:43:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=110
06/02/2022 11:43:07 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.8993430741359812 on epoch=110
06/02/2022 11:43:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8951723344813707 -> 0.8993430741359812 on epoch=110, global_step=1550
06/02/2022 11:43:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=111
06/02/2022 11:43:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/02/2022 11:43:15 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.11 on epoch=112
06/02/2022 11:43:17 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
06/02/2022 11:43:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/02/2022 11:43:27 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.8993037090792768 on epoch=114
06/02/2022 11:43:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=114
06/02/2022 11:43:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=115
06/02/2022 11:43:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
06/02/2022 11:43:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
06/02/2022 11:43:39 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.11 on epoch=117
06/02/2022 11:43:46 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.8995388419297339 on epoch=117
06/02/2022 11:43:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8993430741359812 -> 0.8995388419297339 on epoch=117, global_step=1650
06/02/2022 11:43:49 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.14 on epoch=118
06/02/2022 11:43:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=119
06/02/2022 11:43:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=119
06/02/2022 11:43:56 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=120
06/02/2022 11:43:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/02/2022 11:44:06 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.8950813639238686 on epoch=121
06/02/2022 11:44:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
06/02/2022 11:44:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
06/02/2022 11:44:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
06/02/2022 11:44:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=124
06/02/2022 11:44:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/02/2022 11:44:26 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.8995388419297338 on epoch=124
06/02/2022 11:44:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
06/02/2022 11:44:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
06/02/2022 11:44:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=127
06/02/2022 11:44:36 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=127
06/02/2022 11:44:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=128
06/02/2022 11:44:46 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.8973793437218484 on epoch=128
06/02/2022 11:44:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=129
06/02/2022 11:44:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=129
06/02/2022 11:44:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
06/02/2022 11:44:57 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
06/02/2022 11:44:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=132
06/02/2022 11:45:07 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.8951723344813707 on epoch=132
06/02/2022 11:45:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=132
06/02/2022 11:45:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
06/02/2022 11:45:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/02/2022 11:45:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=134
06/02/2022 11:45:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
06/02/2022 11:45:28 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.9016893795641424 on epoch=135
06/02/2022 11:45:28 - INFO - __main__ - Saving model with best Classification-F1: 0.8995388419297339 -> 0.9016893795641424 on epoch=135, global_step=1900
06/02/2022 11:45:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=136
06/02/2022 11:45:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=137
06/02/2022 11:45:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=137
06/02/2022 11:45:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=138
06/02/2022 11:45:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/02/2022 11:45:49 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.8950813639238686 on epoch=139
06/02/2022 11:45:52 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/02/2022 11:45:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/02/2022 11:45:57 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/02/2022 11:45:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=142
06/02/2022 11:46:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/02/2022 11:46:10 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8907713280815749 on epoch=142
06/02/2022 11:46:12 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
06/02/2022 11:46:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=144
06/02/2022 11:46:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/02/2022 11:46:19 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/02/2022 11:46:22 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/02/2022 11:46:30 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.8931275986984945 on epoch=146
06/02/2022 11:46:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
06/02/2022 11:46:35 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
06/02/2022 11:46:37 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=148
06/02/2022 11:46:40 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=149
06/02/2022 11:46:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=149
06/02/2022 11:46:50 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.9016893795641423 on epoch=149
06/02/2022 11:46:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=150
06/02/2022 11:46:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/02/2022 11:46:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=152
06/02/2022 11:47:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/02/2022 11:47:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
06/02/2022 11:47:10 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.8888773886876353 on epoch=153
06/02/2022 11:47:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/02/2022 11:47:15 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
06/02/2022 11:47:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=155
06/02/2022 11:47:20 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
06/02/2022 11:47:23 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
06/02/2022 11:47:31 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8975227128974755 on epoch=157
06/02/2022 11:47:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/02/2022 11:47:36 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=158
06/02/2022 11:47:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
06/02/2022 11:47:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=159
06/02/2022 11:47:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
06/02/2022 11:47:52 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.8933348666935004 on epoch=160
06/02/2022 11:47:55 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/02/2022 11:47:57 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=162
06/02/2022 11:48:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=162
06/02/2022 11:48:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/02/2022 11:48:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
06/02/2022 11:48:12 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.8933348666935004 on epoch=164
06/02/2022 11:48:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/02/2022 11:48:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
06/02/2022 11:48:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/02/2022 11:48:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/02/2022 11:48:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=167
06/02/2022 11:48:33 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.8974038774845227 on epoch=167
06/02/2022 11:48:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.14 on epoch=168
06/02/2022 11:48:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=169
06/02/2022 11:48:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/02/2022 11:48:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=170
06/02/2022 11:48:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
06/02/2022 11:48:53 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.8930652348916105 on epoch=171
06/02/2022 11:48:56 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
06/02/2022 11:48:58 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/02/2022 11:49:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=173
06/02/2022 11:49:03 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/02/2022 11:49:06 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=174
06/02/2022 11:49:13 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.8975227128974755 on epoch=174
06/02/2022 11:49:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
06/02/2022 11:49:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/02/2022 11:49:21 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/02/2022 11:49:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/02/2022 11:49:26 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/02/2022 11:49:34 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.8390472262952102 on epoch=178
06/02/2022 11:49:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
06/02/2022 11:49:39 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
06/02/2022 11:49:41 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/02/2022 11:49:44 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
06/02/2022 11:49:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/02/2022 11:49:54 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8975227128974755 on epoch=182
06/02/2022 11:49:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/02/2022 11:49:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/02/2022 11:50:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=184
06/02/2022 11:50:04 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=184
06/02/2022 11:50:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/02/2022 11:50:16 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.8974038774845227 on epoch=185
06/02/2022 11:50:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/02/2022 11:50:21 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/02/2022 11:50:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/02/2022 11:50:26 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/02/2022 11:50:28 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=189
06/02/2022 11:50:36 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.8392731872807775 on epoch=189
06/02/2022 11:50:39 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/02/2022 11:50:41 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=190
06/02/2022 11:50:44 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/02/2022 11:50:46 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=192
06/02/2022 11:50:49 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/02/2022 11:50:57 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.9016893795641424 on epoch=192
06/02/2022 11:50:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/02/2022 11:51:02 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/02/2022 11:51:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/02/2022 11:51:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=195
06/02/2022 11:51:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
06/02/2022 11:51:18 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8432100745356794 on epoch=196
06/02/2022 11:51:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/02/2022 11:51:23 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/02/2022 11:51:25 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=198
06/02/2022 11:51:28 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
06/02/2022 11:51:30 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/02/2022 11:51:38 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7390789616596068 on epoch=199
06/02/2022 11:51:41 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=200
06/02/2022 11:51:43 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=201
06/02/2022 11:51:46 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/02/2022 11:51:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/02/2022 11:51:51 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
06/02/2022 11:51:58 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.799183485711 on epoch=203
06/02/2022 11:52:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/02/2022 11:52:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/02/2022 11:52:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
06/02/2022 11:52:08 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/02/2022 11:52:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/02/2022 11:52:19 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8371264680725663 on epoch=207
06/02/2022 11:52:21 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/02/2022 11:52:24 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/02/2022 11:52:26 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/02/2022 11:52:29 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/02/2022 11:52:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/02/2022 11:52:40 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8392770057069749 on epoch=210
06/02/2022 11:52:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/02/2022 11:52:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=212
06/02/2022 11:52:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/02/2022 11:52:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/02/2022 11:52:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
06/02/2022 11:52:54 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 11:52:54 - INFO - __main__ - Printing 3 examples
06/02/2022 11:52:54 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 11:52:54 - INFO - __main__ - ['Animal']
06/02/2022 11:52:54 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 11:52:54 - INFO - __main__ - ['Animal']
06/02/2022 11:52:54 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 11:52:54 - INFO - __main__ - ['Animal']
06/02/2022 11:52:54 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:52:54 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:52:54 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 11:52:54 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 11:52:54 - INFO - __main__ - Printing 3 examples
06/02/2022 11:52:54 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 11:52:54 - INFO - __main__ - ['Animal']
06/02/2022 11:52:54 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 11:52:54 - INFO - __main__ - ['Animal']
06/02/2022 11:52:54 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 11:52:54 - INFO - __main__ - ['Animal']
06/02/2022 11:52:54 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:52:54 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:52:54 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 11:53:01 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8974662412914066 on epoch=214
06/02/2022 11:53:01 - INFO - __main__ - save last model!
06/02/2022 11:53:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 11:53:01 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 11:53:01 - INFO - __main__ - Printing 3 examples
06/02/2022 11:53:01 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 11:53:01 - INFO - __main__ - ['Animal']
06/02/2022 11:53:01 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 11:53:01 - INFO - __main__ - ['Animal']
06/02/2022 11:53:01 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 11:53:01 - INFO - __main__ - ['Village']
06/02/2022 11:53:01 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:53:03 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:53:06 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 11:53:13 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 11:53:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 11:53:14 - INFO - __main__ - Starting training!
06/02/2022 11:55:49 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
06/02/2022 11:55:49 - INFO - __main__ - Classification-F1 on test data: 0.5460
06/02/2022 11:55:49 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.9016893795641424, test_performance=0.5460011836187034
06/02/2022 11:55:49 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
06/02/2022 11:55:50 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 11:55:50 - INFO - __main__ - Printing 3 examples
06/02/2022 11:55:50 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 11:55:50 - INFO - __main__ - ['Animal']
06/02/2022 11:55:50 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 11:55:50 - INFO - __main__ - ['Animal']
06/02/2022 11:55:50 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 11:55:50 - INFO - __main__ - ['Animal']
06/02/2022 11:55:50 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:55:50 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:55:51 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 11:55:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 11:55:51 - INFO - __main__ - Printing 3 examples
06/02/2022 11:55:51 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 11:55:51 - INFO - __main__ - ['Animal']
06/02/2022 11:55:51 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 11:55:51 - INFO - __main__ - ['Animal']
06/02/2022 11:55:51 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 11:55:51 - INFO - __main__ - ['Animal']
06/02/2022 11:55:51 - INFO - __main__ - Tokenizing Input ...
06/02/2022 11:55:51 - INFO - __main__ - Tokenizing Output ...
06/02/2022 11:55:51 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 11:56:08 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 11:56:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 11:56:09 - INFO - __main__ - Starting training!
06/02/2022 11:56:12 - INFO - __main__ - Step 10 Global step 10 Train loss 6.26 on epoch=0
06/02/2022 11:56:15 - INFO - __main__ - Step 20 Global step 20 Train loss 4.82 on epoch=1
06/02/2022 11:56:17 - INFO - __main__ - Step 30 Global step 30 Train loss 4.54 on epoch=2
06/02/2022 11:56:20 - INFO - __main__ - Step 40 Global step 40 Train loss 3.74 on epoch=2
06/02/2022 11:56:22 - INFO - __main__ - Step 50 Global step 50 Train loss 3.79 on epoch=3
06/02/2022 11:56:27 - INFO - __main__ - Global step 50 Train loss 4.63 Classification-F1 0.05925228698630014 on epoch=3
06/02/2022 11:56:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05925228698630014 on epoch=3, global_step=50
06/02/2022 11:56:29 - INFO - __main__ - Step 60 Global step 60 Train loss 3.39 on epoch=4
06/02/2022 11:56:32 - INFO - __main__ - Step 70 Global step 70 Train loss 3.31 on epoch=4
06/02/2022 11:56:34 - INFO - __main__ - Step 80 Global step 80 Train loss 3.07 on epoch=5
06/02/2022 11:56:37 - INFO - __main__ - Step 90 Global step 90 Train loss 2.84 on epoch=6
06/02/2022 11:56:39 - INFO - __main__ - Step 100 Global step 100 Train loss 2.87 on epoch=7
06/02/2022 11:56:44 - INFO - __main__ - Global step 100 Train loss 3.10 Classification-F1 0.10677112777224011 on epoch=7
06/02/2022 11:56:44 - INFO - __main__ - Saving model with best Classification-F1: 0.05925228698630014 -> 0.10677112777224011 on epoch=7, global_step=100
06/02/2022 11:56:46 - INFO - __main__ - Step 110 Global step 110 Train loss 2.56 on epoch=7
06/02/2022 11:56:49 - INFO - __main__ - Step 120 Global step 120 Train loss 2.55 on epoch=8
06/02/2022 11:56:51 - INFO - __main__ - Step 130 Global step 130 Train loss 2.40 on epoch=9
06/02/2022 11:56:54 - INFO - __main__ - Step 140 Global step 140 Train loss 2.33 on epoch=9
06/02/2022 11:56:56 - INFO - __main__ - Step 150 Global step 150 Train loss 2.09 on epoch=10
06/02/2022 11:57:01 - INFO - __main__ - Global step 150 Train loss 2.38 Classification-F1 0.11418068270527287 on epoch=10
06/02/2022 11:57:01 - INFO - __main__ - Saving model with best Classification-F1: 0.10677112777224011 -> 0.11418068270527287 on epoch=10, global_step=150
06/02/2022 11:57:03 - INFO - __main__ - Step 160 Global step 160 Train loss 2.04 on epoch=11
06/02/2022 11:57:06 - INFO - __main__ - Step 170 Global step 170 Train loss 2.18 on epoch=12
06/02/2022 11:57:08 - INFO - __main__ - Step 180 Global step 180 Train loss 2.03 on epoch=12
06/02/2022 11:57:11 - INFO - __main__ - Step 190 Global step 190 Train loss 1.97 on epoch=13
06/02/2022 11:57:13 - INFO - __main__ - Step 200 Global step 200 Train loss 1.89 on epoch=14
06/02/2022 11:57:18 - INFO - __main__ - Global step 200 Train loss 2.02 Classification-F1 0.13813289213382302 on epoch=14
06/02/2022 11:57:18 - INFO - __main__ - Saving model with best Classification-F1: 0.11418068270527287 -> 0.13813289213382302 on epoch=14, global_step=200
06/02/2022 11:57:20 - INFO - __main__ - Step 210 Global step 210 Train loss 1.82 on epoch=14
06/02/2022 11:57:23 - INFO - __main__ - Step 220 Global step 220 Train loss 1.80 on epoch=15
06/02/2022 11:57:25 - INFO - __main__ - Step 230 Global step 230 Train loss 1.77 on epoch=16
06/02/2022 11:57:28 - INFO - __main__ - Step 240 Global step 240 Train loss 1.92 on epoch=17
06/02/2022 11:57:30 - INFO - __main__ - Step 250 Global step 250 Train loss 1.71 on epoch=17
06/02/2022 11:57:35 - INFO - __main__ - Global step 250 Train loss 1.80 Classification-F1 0.1530361812437042 on epoch=17
06/02/2022 11:57:35 - INFO - __main__ - Saving model with best Classification-F1: 0.13813289213382302 -> 0.1530361812437042 on epoch=17, global_step=250
06/02/2022 11:57:38 - INFO - __main__ - Step 260 Global step 260 Train loss 1.72 on epoch=18
06/02/2022 11:57:40 - INFO - __main__ - Step 270 Global step 270 Train loss 1.55 on epoch=19
06/02/2022 11:57:42 - INFO - __main__ - Step 280 Global step 280 Train loss 1.72 on epoch=19
06/02/2022 11:57:45 - INFO - __main__ - Step 290 Global step 290 Train loss 1.46 on epoch=20
06/02/2022 11:57:47 - INFO - __main__ - Step 300 Global step 300 Train loss 1.46 on epoch=21
06/02/2022 11:57:52 - INFO - __main__ - Global step 300 Train loss 1.58 Classification-F1 0.1749975135843073 on epoch=21
06/02/2022 11:57:52 - INFO - __main__ - Saving model with best Classification-F1: 0.1530361812437042 -> 0.1749975135843073 on epoch=21, global_step=300
06/02/2022 11:57:55 - INFO - __main__ - Step 310 Global step 310 Train loss 1.58 on epoch=22
06/02/2022 11:57:57 - INFO - __main__ - Step 320 Global step 320 Train loss 1.35 on epoch=22
06/02/2022 11:57:59 - INFO - __main__ - Step 330 Global step 330 Train loss 1.39 on epoch=23
06/02/2022 11:58:02 - INFO - __main__ - Step 340 Global step 340 Train loss 1.32 on epoch=24
06/02/2022 11:58:04 - INFO - __main__ - Step 350 Global step 350 Train loss 1.27 on epoch=24
06/02/2022 11:58:09 - INFO - __main__ - Global step 350 Train loss 1.38 Classification-F1 0.26184469206835326 on epoch=24
06/02/2022 11:58:09 - INFO - __main__ - Saving model with best Classification-F1: 0.1749975135843073 -> 0.26184469206835326 on epoch=24, global_step=350
06/02/2022 11:58:12 - INFO - __main__ - Step 360 Global step 360 Train loss 1.08 on epoch=25
06/02/2022 11:58:14 - INFO - __main__ - Step 370 Global step 370 Train loss 1.10 on epoch=26
06/02/2022 11:58:16 - INFO - __main__ - Step 380 Global step 380 Train loss 1.25 on epoch=27
06/02/2022 11:58:19 - INFO - __main__ - Step 390 Global step 390 Train loss 1.10 on epoch=27
06/02/2022 11:58:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.96 on epoch=28
06/02/2022 11:58:26 - INFO - __main__ - Global step 400 Train loss 1.10 Classification-F1 0.27420958155068587 on epoch=28
06/02/2022 11:58:26 - INFO - __main__ - Saving model with best Classification-F1: 0.26184469206835326 -> 0.27420958155068587 on epoch=28, global_step=400
06/02/2022 11:58:29 - INFO - __main__ - Step 410 Global step 410 Train loss 1.12 on epoch=29
06/02/2022 11:58:31 - INFO - __main__ - Step 420 Global step 420 Train loss 1.05 on epoch=29
06/02/2022 11:58:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.92 on epoch=30
06/02/2022 11:58:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.90 on epoch=31
06/02/2022 11:58:38 - INFO - __main__ - Step 450 Global step 450 Train loss 1.03 on epoch=32
06/02/2022 11:58:43 - INFO - __main__ - Global step 450 Train loss 1.01 Classification-F1 0.3667485514726194 on epoch=32
06/02/2022 11:58:44 - INFO - __main__ - Saving model with best Classification-F1: 0.27420958155068587 -> 0.3667485514726194 on epoch=32, global_step=450
06/02/2022 11:58:46 - INFO - __main__ - Step 460 Global step 460 Train loss 0.81 on epoch=32
06/02/2022 11:58:48 - INFO - __main__ - Step 470 Global step 470 Train loss 0.84 on epoch=33
06/02/2022 11:58:51 - INFO - __main__ - Step 480 Global step 480 Train loss 0.87 on epoch=34
06/02/2022 11:58:53 - INFO - __main__ - Step 490 Global step 490 Train loss 0.76 on epoch=34
06/02/2022 11:58:56 - INFO - __main__ - Step 500 Global step 500 Train loss 0.71 on epoch=35
06/02/2022 11:59:01 - INFO - __main__ - Global step 500 Train loss 0.80 Classification-F1 0.3876585767442678 on epoch=35
06/02/2022 11:59:01 - INFO - __main__ - Saving model with best Classification-F1: 0.3667485514726194 -> 0.3876585767442678 on epoch=35, global_step=500
06/02/2022 11:59:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.78 on epoch=36
06/02/2022 11:59:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.88 on epoch=37
06/02/2022 11:59:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.83 on epoch=37
06/02/2022 11:59:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.63 on epoch=38
06/02/2022 11:59:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.60 on epoch=39
06/02/2022 11:59:19 - INFO - __main__ - Global step 550 Train loss 0.74 Classification-F1 0.45517458430522534 on epoch=39
06/02/2022 11:59:19 - INFO - __main__ - Saving model with best Classification-F1: 0.3876585767442678 -> 0.45517458430522534 on epoch=39, global_step=550
06/02/2022 11:59:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.62 on epoch=39
06/02/2022 11:59:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.60 on epoch=40
06/02/2022 11:59:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.62 on epoch=41
06/02/2022 11:59:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.71 on epoch=42
06/02/2022 11:59:31 - INFO - __main__ - Step 600 Global step 600 Train loss 0.46 on epoch=42
06/02/2022 11:59:38 - INFO - __main__ - Global step 600 Train loss 0.60 Classification-F1 0.40403076321076997 on epoch=42
06/02/2022 11:59:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.59 on epoch=43
06/02/2022 11:59:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.59 on epoch=44
06/02/2022 11:59:45 - INFO - __main__ - Step 630 Global step 630 Train loss 0.61 on epoch=44
06/02/2022 11:59:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.56 on epoch=45
06/02/2022 11:59:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.60 on epoch=46
06/02/2022 11:59:56 - INFO - __main__ - Global step 650 Train loss 0.59 Classification-F1 0.4321867037845576 on epoch=46
06/02/2022 11:59:59 - INFO - __main__ - Step 660 Global step 660 Train loss 0.54 on epoch=47
06/02/2022 12:00:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.53 on epoch=47
06/02/2022 12:00:04 - INFO - __main__ - Step 680 Global step 680 Train loss 0.48 on epoch=48
06/02/2022 12:00:06 - INFO - __main__ - Step 690 Global step 690 Train loss 0.54 on epoch=49
06/02/2022 12:00:08 - INFO - __main__ - Step 700 Global step 700 Train loss 0.55 on epoch=49
06/02/2022 12:00:15 - INFO - __main__ - Global step 700 Train loss 0.53 Classification-F1 0.5296391206582957 on epoch=49
06/02/2022 12:00:15 - INFO - __main__ - Saving model with best Classification-F1: 0.45517458430522534 -> 0.5296391206582957 on epoch=49, global_step=700
06/02/2022 12:00:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.50 on epoch=50
06/02/2022 12:00:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.48 on epoch=51
06/02/2022 12:00:22 - INFO - __main__ - Step 730 Global step 730 Train loss 0.49 on epoch=52
06/02/2022 12:00:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.46 on epoch=52
06/02/2022 12:00:27 - INFO - __main__ - Step 750 Global step 750 Train loss 0.47 on epoch=53
06/02/2022 12:00:34 - INFO - __main__ - Global step 750 Train loss 0.48 Classification-F1 0.5896048635396574 on epoch=53
06/02/2022 12:00:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5296391206582957 -> 0.5896048635396574 on epoch=53, global_step=750
06/02/2022 12:00:37 - INFO - __main__ - Step 760 Global step 760 Train loss 0.45 on epoch=54
06/02/2022 12:00:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.41 on epoch=54
06/02/2022 12:00:41 - INFO - __main__ - Step 780 Global step 780 Train loss 0.46 on epoch=55
06/02/2022 12:00:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.35 on epoch=56
06/02/2022 12:00:46 - INFO - __main__ - Step 800 Global step 800 Train loss 0.41 on epoch=57
06/02/2022 12:00:53 - INFO - __main__ - Global step 800 Train loss 0.42 Classification-F1 0.5517537496755817 on epoch=57
06/02/2022 12:00:56 - INFO - __main__ - Step 810 Global step 810 Train loss 0.32 on epoch=57
06/02/2022 12:00:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.39 on epoch=58
06/02/2022 12:01:01 - INFO - __main__ - Step 830 Global step 830 Train loss 0.45 on epoch=59
06/02/2022 12:01:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.34 on epoch=59
06/02/2022 12:01:06 - INFO - __main__ - Step 850 Global step 850 Train loss 0.39 on epoch=60
06/02/2022 12:01:13 - INFO - __main__ - Global step 850 Train loss 0.38 Classification-F1 0.6101412093365411 on epoch=60
06/02/2022 12:01:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5896048635396574 -> 0.6101412093365411 on epoch=60, global_step=850
06/02/2022 12:01:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.36 on epoch=61
06/02/2022 12:01:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.31 on epoch=62
06/02/2022 12:01:20 - INFO - __main__ - Step 880 Global step 880 Train loss 0.29 on epoch=62
06/02/2022 12:01:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.37 on epoch=63
06/02/2022 12:01:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.40 on epoch=64
06/02/2022 12:01:32 - INFO - __main__ - Global step 900 Train loss 0.35 Classification-F1 0.6475743611227482 on epoch=64
06/02/2022 12:01:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6101412093365411 -> 0.6475743611227482 on epoch=64, global_step=900
06/02/2022 12:01:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.34 on epoch=64
06/02/2022 12:01:36 - INFO - __main__ - Step 920 Global step 920 Train loss 0.30 on epoch=65
06/02/2022 12:01:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.32 on epoch=66
06/02/2022 12:01:41 - INFO - __main__ - Step 940 Global step 940 Train loss 0.29 on epoch=67
06/02/2022 12:01:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.36 on epoch=67
06/02/2022 12:01:50 - INFO - __main__ - Global step 950 Train loss 0.32 Classification-F1 0.6472901640643576 on epoch=67
06/02/2022 12:01:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.32 on epoch=68
06/02/2022 12:01:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.30 on epoch=69
06/02/2022 12:01:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.29 on epoch=69
06/02/2022 12:02:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=70
06/02/2022 12:02:03 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.32 on epoch=71
06/02/2022 12:02:09 - INFO - __main__ - Global step 1000 Train loss 0.30 Classification-F1 0.5849879061195259 on epoch=71
06/02/2022 12:02:12 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.33 on epoch=72
06/02/2022 12:02:14 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.26 on epoch=72
06/02/2022 12:02:17 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.29 on epoch=73
06/02/2022 12:02:19 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.29 on epoch=74
06/02/2022 12:02:21 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.27 on epoch=74
06/02/2022 12:02:28 - INFO - __main__ - Global step 1050 Train loss 0.29 Classification-F1 0.641015654260436 on epoch=74
06/02/2022 12:02:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.25 on epoch=75
06/02/2022 12:02:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.29 on epoch=76
06/02/2022 12:02:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.32 on epoch=77
06/02/2022 12:02:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.33 on epoch=77
06/02/2022 12:02:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.31 on epoch=78
06/02/2022 12:02:47 - INFO - __main__ - Global step 1100 Train loss 0.30 Classification-F1 0.6747533202741431 on epoch=78
06/02/2022 12:02:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6475743611227482 -> 0.6747533202741431 on epoch=78, global_step=1100
06/02/2022 12:02:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.28 on epoch=79
06/02/2022 12:02:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.22 on epoch=79
06/02/2022 12:02:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.23 on epoch=80
06/02/2022 12:02:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=81
06/02/2022 12:02:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.28 on epoch=82
06/02/2022 12:03:06 - INFO - __main__ - Global step 1150 Train loss 0.25 Classification-F1 0.6787633453367998 on epoch=82
06/02/2022 12:03:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6747533202741431 -> 0.6787633453367998 on epoch=82, global_step=1150
06/02/2022 12:03:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.31 on epoch=82
06/02/2022 12:03:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.25 on epoch=83
06/02/2022 12:03:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.25 on epoch=84
06/02/2022 12:03:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.27 on epoch=84
06/02/2022 12:03:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.29 on epoch=85
06/02/2022 12:03:25 - INFO - __main__ - Global step 1200 Train loss 0.28 Classification-F1 0.7238338187434796 on epoch=85
06/02/2022 12:03:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6787633453367998 -> 0.7238338187434796 on epoch=85, global_step=1200
06/02/2022 12:03:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.22 on epoch=86
06/02/2022 12:03:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.23 on epoch=87
06/02/2022 12:03:32 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.22 on epoch=87
06/02/2022 12:03:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.21 on epoch=88
06/02/2022 12:03:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.18 on epoch=89
06/02/2022 12:03:44 - INFO - __main__ - Global step 1250 Train loss 0.21 Classification-F1 0.6703211873101542 on epoch=89
06/02/2022 12:03:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.21 on epoch=89
06/02/2022 12:03:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.21 on epoch=90
06/02/2022 12:03:51 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.22 on epoch=91
06/02/2022 12:03:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.35 on epoch=92
06/02/2022 12:03:56 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.21 on epoch=92
06/02/2022 12:04:03 - INFO - __main__ - Global step 1300 Train loss 0.24 Classification-F1 0.7178070880790678 on epoch=92
06/02/2022 12:04:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.20 on epoch=93
06/02/2022 12:04:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.26 on epoch=94
06/02/2022 12:04:11 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.21 on epoch=94
06/02/2022 12:04:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.25 on epoch=95
06/02/2022 12:04:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.23 on epoch=96
06/02/2022 12:04:22 - INFO - __main__ - Global step 1350 Train loss 0.23 Classification-F1 0.6773544176120826 on epoch=96
06/02/2022 12:04:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.20 on epoch=97
06/02/2022 12:04:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.19 on epoch=97
06/02/2022 12:04:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=98
06/02/2022 12:04:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.23 on epoch=99
06/02/2022 12:04:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.17 on epoch=99
06/02/2022 12:04:41 - INFO - __main__ - Global step 1400 Train loss 0.20 Classification-F1 0.6586947653855411 on epoch=99
06/02/2022 12:04:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=100
06/02/2022 12:04:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.19 on epoch=101
06/02/2022 12:04:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.19 on epoch=102
06/02/2022 12:04:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.21 on epoch=102
06/02/2022 12:04:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.17 on epoch=103
06/02/2022 12:05:00 - INFO - __main__ - Global step 1450 Train loss 0.18 Classification-F1 0.732730192154389 on epoch=103
06/02/2022 12:05:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7238338187434796 -> 0.732730192154389 on epoch=103, global_step=1450
06/02/2022 12:05:03 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.17 on epoch=104
06/02/2022 12:05:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.25 on epoch=104
06/02/2022 12:05:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.25 on epoch=105
06/02/2022 12:05:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.16 on epoch=106
06/02/2022 12:05:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.20 on epoch=107
06/02/2022 12:05:20 - INFO - __main__ - Global step 1500 Train loss 0.21 Classification-F1 0.7152079977606793 on epoch=107
06/02/2022 12:05:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.23 on epoch=107
06/02/2022 12:05:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=108
06/02/2022 12:05:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=109
06/02/2022 12:05:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.14 on epoch=109
06/02/2022 12:05:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.14 on epoch=110
06/02/2022 12:05:39 - INFO - __main__ - Global step 1550 Train loss 0.16 Classification-F1 0.6913895053313809 on epoch=110
06/02/2022 12:05:41 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.13 on epoch=111
06/02/2022 12:05:44 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=112
06/02/2022 12:05:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.29 on epoch=112
06/02/2022 12:05:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.20 on epoch=113
06/02/2022 12:05:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.21 on epoch=114
06/02/2022 12:05:58 - INFO - __main__ - Global step 1600 Train loss 0.19 Classification-F1 0.6526516380703329 on epoch=114
06/02/2022 12:06:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.17 on epoch=114
06/02/2022 12:06:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=115
06/02/2022 12:06:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=116
06/02/2022 12:06:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.20 on epoch=117
06/02/2022 12:06:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.15 on epoch=117
06/02/2022 12:06:17 - INFO - __main__ - Global step 1650 Train loss 0.16 Classification-F1 0.6844119527082648 on epoch=117
06/02/2022 12:06:20 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.16 on epoch=118
06/02/2022 12:06:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.18 on epoch=119
06/02/2022 12:06:25 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.13 on epoch=119
06/02/2022 12:06:27 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.16 on epoch=120
06/02/2022 12:06:30 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.19 on epoch=121
06/02/2022 12:06:37 - INFO - __main__ - Global step 1700 Train loss 0.16 Classification-F1 0.6827797456380299 on epoch=121
06/02/2022 12:06:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.18 on epoch=122
06/02/2022 12:06:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=122
06/02/2022 12:06:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.14 on epoch=123
06/02/2022 12:06:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=124
06/02/2022 12:06:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=124
06/02/2022 12:06:56 - INFO - __main__ - Global step 1750 Train loss 0.13 Classification-F1 0.7772339648595851 on epoch=124
06/02/2022 12:06:56 - INFO - __main__ - Saving model with best Classification-F1: 0.732730192154389 -> 0.7772339648595851 on epoch=124, global_step=1750
06/02/2022 12:06:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.13 on epoch=125
06/02/2022 12:07:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.14 on epoch=126
06/02/2022 12:07:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.15 on epoch=127
06/02/2022 12:07:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.14 on epoch=127
06/02/2022 12:07:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=128
06/02/2022 12:07:16 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.8262029150712655 on epoch=128
06/02/2022 12:07:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7772339648595851 -> 0.8262029150712655 on epoch=128, global_step=1800
06/02/2022 12:07:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.15 on epoch=129
06/02/2022 12:07:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.13 on epoch=129
06/02/2022 12:07:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.12 on epoch=130
06/02/2022 12:07:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.17 on epoch=131
06/02/2022 12:07:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=132
06/02/2022 12:07:35 - INFO - __main__ - Global step 1850 Train loss 0.14 Classification-F1 0.8307004033284868 on epoch=132
06/02/2022 12:07:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8262029150712655 -> 0.8307004033284868 on epoch=132, global_step=1850
06/02/2022 12:07:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.12 on epoch=132
06/02/2022 12:07:40 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=133
06/02/2022 12:07:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=134
06/02/2022 12:07:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.16 on epoch=134
06/02/2022 12:07:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.15 on epoch=135
06/02/2022 12:07:55 - INFO - __main__ - Global step 1900 Train loss 0.13 Classification-F1 0.8370366212012159 on epoch=135
06/02/2022 12:07:55 - INFO - __main__ - Saving model with best Classification-F1: 0.8307004033284868 -> 0.8370366212012159 on epoch=135, global_step=1900
06/02/2022 12:07:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.14 on epoch=136
06/02/2022 12:08:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=137
06/02/2022 12:08:02 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.13 on epoch=137
06/02/2022 12:08:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=138
06/02/2022 12:08:07 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.19 on epoch=139
06/02/2022 12:08:14 - INFO - __main__ - Global step 1950 Train loss 0.13 Classification-F1 0.7871586806666537 on epoch=139
06/02/2022 12:08:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.14 on epoch=139
06/02/2022 12:08:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.13 on epoch=140
06/02/2022 12:08:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=141
06/02/2022 12:08:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=142
06/02/2022 12:08:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.18 on epoch=142
06/02/2022 12:08:34 - INFO - __main__ - Global step 2000 Train loss 0.13 Classification-F1 0.7818356737209288 on epoch=142
06/02/2022 12:08:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.16 on epoch=143
06/02/2022 12:08:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.13 on epoch=144
06/02/2022 12:08:41 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.10 on epoch=144
06/02/2022 12:08:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.18 on epoch=145
06/02/2022 12:08:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.11 on epoch=146
06/02/2022 12:08:53 - INFO - __main__ - Global step 2050 Train loss 0.14 Classification-F1 0.8953550687137023 on epoch=146
06/02/2022 12:08:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8370366212012159 -> 0.8953550687137023 on epoch=146, global_step=2050
06/02/2022 12:08:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.14 on epoch=147
06/02/2022 12:08:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=147
06/02/2022 12:09:01 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.15 on epoch=148
06/02/2022 12:09:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.11 on epoch=149
06/02/2022 12:09:06 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=149
06/02/2022 12:09:13 - INFO - __main__ - Global step 2100 Train loss 0.12 Classification-F1 0.899525808368313 on epoch=149
06/02/2022 12:09:13 - INFO - __main__ - Saving model with best Classification-F1: 0.8953550687137023 -> 0.899525808368313 on epoch=149, global_step=2100
06/02/2022 12:09:15 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.11 on epoch=150
06/02/2022 12:09:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.11 on epoch=151
06/02/2022 12:09:20 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.11 on epoch=152
06/02/2022 12:09:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.10 on epoch=152
06/02/2022 12:09:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=153
06/02/2022 12:09:32 - INFO - __main__ - Global step 2150 Train loss 0.11 Classification-F1 0.8331672759418765 on epoch=153
06/02/2022 12:09:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=154
06/02/2022 12:09:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=154
06/02/2022 12:09:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.10 on epoch=155
06/02/2022 12:09:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.12 on epoch=156
06/02/2022 12:09:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.12 on epoch=157
06/02/2022 12:09:52 - INFO - __main__ - Global step 2200 Train loss 0.11 Classification-F1 0.899525808368313 on epoch=157
06/02/2022 12:09:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=157
06/02/2022 12:09:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.13 on epoch=158
06/02/2022 12:09:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.21 on epoch=159
06/02/2022 12:10:02 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.10 on epoch=159
06/02/2022 12:10:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.10 on epoch=160
06/02/2022 12:10:11 - INFO - __main__ - Global step 2250 Train loss 0.12 Classification-F1 0.899347147123925 on epoch=160
06/02/2022 12:10:14 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=161
06/02/2022 12:10:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.11 on epoch=162
06/02/2022 12:10:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.12 on epoch=162
06/02/2022 12:10:21 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.12 on epoch=163
06/02/2022 12:10:24 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.11 on epoch=164
06/02/2022 12:10:31 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.9035907461713913 on epoch=164
06/02/2022 12:10:31 - INFO - __main__ - Saving model with best Classification-F1: 0.899525808368313 -> 0.9035907461713913 on epoch=164, global_step=2300
06/02/2022 12:10:33 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
06/02/2022 12:10:36 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=165
06/02/2022 12:10:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.11 on epoch=166
06/02/2022 12:10:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.11 on epoch=167
06/02/2022 12:10:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=167
06/02/2022 12:10:50 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.895187165775401 on epoch=167
06/02/2022 12:10:53 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=168
06/02/2022 12:10:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=169
06/02/2022 12:10:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=169
06/02/2022 12:11:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.12 on epoch=170
06/02/2022 12:11:03 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.10 on epoch=171
06/02/2022 12:11:10 - INFO - __main__ - Global step 2400 Train loss 0.09 Classification-F1 0.8993824391926858 on epoch=171
06/02/2022 12:11:12 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.14 on epoch=172
06/02/2022 12:11:14 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
06/02/2022 12:11:17 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=173
06/02/2022 12:11:19 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=174
06/02/2022 12:11:22 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=174
06/02/2022 12:11:29 - INFO - __main__ - Global step 2450 Train loss 0.09 Classification-F1 0.8910857105845 on epoch=174
06/02/2022 12:11:31 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.10 on epoch=175
06/02/2022 12:11:34 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=176
06/02/2022 12:11:36 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.14 on epoch=177
06/02/2022 12:11:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.14 on epoch=177
06/02/2022 12:11:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=178
06/02/2022 12:11:48 - INFO - __main__ - Global step 2500 Train loss 0.10 Classification-F1 0.8952157725260191 on epoch=178
06/02/2022 12:11:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.13 on epoch=179
06/02/2022 12:11:53 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.08 on epoch=179
06/02/2022 12:11:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=180
06/02/2022 12:11:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/02/2022 12:12:01 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=182
06/02/2022 12:12:08 - INFO - __main__ - Global step 2550 Train loss 0.08 Classification-F1 0.8952157725260191 on epoch=182
06/02/2022 12:12:10 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=182
06/02/2022 12:12:13 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=183
06/02/2022 12:12:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
06/02/2022 12:12:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
06/02/2022 12:12:20 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/02/2022 12:12:27 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.8975096793360549 on epoch=185
06/02/2022 12:12:29 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/02/2022 12:12:32 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.11 on epoch=187
06/02/2022 12:12:34 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=187
06/02/2022 12:12:37 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.11 on epoch=188
06/02/2022 12:12:39 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.10 on epoch=189
06/02/2022 12:12:46 - INFO - __main__ - Global step 2650 Train loss 0.09 Classification-F1 0.905624986368296 on epoch=189
06/02/2022 12:12:46 - INFO - __main__ - Saving model with best Classification-F1: 0.9035907461713913 -> 0.905624986368296 on epoch=189, global_step=2650
06/02/2022 12:12:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.09 on epoch=189
06/02/2022 12:12:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=190
06/02/2022 12:12:53 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=191
06/02/2022 12:12:56 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
06/02/2022 12:12:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=192
06/02/2022 12:13:05 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.8355272622751194 on epoch=192
06/02/2022 12:13:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.07 on epoch=193
06/02/2022 12:13:10 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=194
06/02/2022 12:13:12 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.14 on epoch=194
06/02/2022 12:13:15 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.09 on epoch=195
06/02/2022 12:13:17 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.09 on epoch=196
06/02/2022 12:13:24 - INFO - __main__ - Global step 2750 Train loss 0.10 Classification-F1 0.899347147123925 on epoch=196
06/02/2022 12:13:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.08 on epoch=197
06/02/2022 12:13:29 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.08 on epoch=197
06/02/2022 12:13:32 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.11 on epoch=198
06/02/2022 12:13:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=199
06/02/2022 12:13:37 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=199
06/02/2022 12:13:44 - INFO - __main__ - Global step 2800 Train loss 0.08 Classification-F1 0.8333436383262476 on epoch=199
06/02/2022 12:13:46 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
06/02/2022 12:13:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=201
06/02/2022 12:13:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.09 on epoch=202
06/02/2022 12:13:54 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.09 on epoch=202
06/02/2022 12:13:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=203
06/02/2022 12:14:03 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.8294704746407108 on epoch=203
06/02/2022 12:14:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=204
06/02/2022 12:14:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=204
06/02/2022 12:14:11 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=205
06/02/2022 12:14:13 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=206
06/02/2022 12:14:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.08 on epoch=207
06/02/2022 12:14:22 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.8270053475935828 on epoch=207
06/02/2022 12:14:25 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/02/2022 12:14:27 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=208
06/02/2022 12:14:30 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=209
06/02/2022 12:14:32 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=209
06/02/2022 12:14:35 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=210
06/02/2022 12:14:41 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.831433868452073 on epoch=210
06/02/2022 12:14:44 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=211
06/02/2022 12:14:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/02/2022 12:14:49 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/02/2022 12:14:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=213
06/02/2022 12:14:54 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
06/02/2022 12:14:55 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 12:14:55 - INFO - __main__ - Printing 3 examples
06/02/2022 12:14:55 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 12:14:55 - INFO - __main__ - ['Plant']
06/02/2022 12:14:55 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 12:14:55 - INFO - __main__ - ['Plant']
06/02/2022 12:14:55 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 12:14:55 - INFO - __main__ - ['Plant']
06/02/2022 12:14:55 - INFO - __main__ - Tokenizing Input ...
06/02/2022 12:14:55 - INFO - __main__ - Tokenizing Output ...
06/02/2022 12:14:55 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 12:14:55 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 12:14:55 - INFO - __main__ - Printing 3 examples
06/02/2022 12:14:55 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 12:14:55 - INFO - __main__ - ['Plant']
06/02/2022 12:14:55 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 12:14:55 - INFO - __main__ - ['Plant']
06/02/2022 12:14:55 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 12:14:55 - INFO - __main__ - ['Plant']
06/02/2022 12:14:55 - INFO - __main__ - Tokenizing Input ...
06/02/2022 12:14:55 - INFO - __main__ - Tokenizing Output ...
06/02/2022 12:14:56 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 12:15:00 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8331564945032013 on epoch=214
06/02/2022 12:15:00 - INFO - __main__ - save last model!
06/02/2022 12:15:00 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 12:15:00 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 12:15:00 - INFO - __main__ - Printing 3 examples
06/02/2022 12:15:00 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 12:15:00 - INFO - __main__ - ['Animal']
06/02/2022 12:15:00 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 12:15:00 - INFO - __main__ - ['Animal']
06/02/2022 12:15:00 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 12:15:00 - INFO - __main__ - ['Village']
06/02/2022 12:15:00 - INFO - __main__ - Tokenizing Input ...
06/02/2022 12:15:02 - INFO - __main__ - Tokenizing Output ...
06/02/2022 12:15:06 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 12:15:11 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 12:15:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 12:15:11 - INFO - __main__ - Starting training!
06/02/2022 12:17:11 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
06/02/2022 12:17:11 - INFO - __main__ - Classification-F1 on test data: 0.6195
06/02/2022 12:17:12 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.905624986368296, test_performance=0.6195206512004611
06/02/2022 12:17:12 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
06/02/2022 12:17:13 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 12:17:13 - INFO - __main__ - Printing 3 examples
06/02/2022 12:17:13 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 12:17:13 - INFO - __main__ - ['Plant']
06/02/2022 12:17:13 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 12:17:13 - INFO - __main__ - ['Plant']
06/02/2022 12:17:13 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 12:17:13 - INFO - __main__ - ['Plant']
06/02/2022 12:17:13 - INFO - __main__ - Tokenizing Input ...
06/02/2022 12:17:13 - INFO - __main__ - Tokenizing Output ...
06/02/2022 12:17:13 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 12:17:13 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 12:17:13 - INFO - __main__ - Printing 3 examples
06/02/2022 12:17:13 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 12:17:13 - INFO - __main__ - ['Plant']
06/02/2022 12:17:13 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 12:17:13 - INFO - __main__ - ['Plant']
06/02/2022 12:17:13 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 12:17:13 - INFO - __main__ - ['Plant']
06/02/2022 12:17:13 - INFO - __main__ - Tokenizing Input ...
06/02/2022 12:17:13 - INFO - __main__ - Tokenizing Output ...
06/02/2022 12:17:13 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 12:17:30 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 12:17:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 12:17:31 - INFO - __main__ - Starting training!
06/02/2022 12:17:34 - INFO - __main__ - Step 10 Global step 10 Train loss 5.36 on epoch=0
06/02/2022 12:17:37 - INFO - __main__ - Step 20 Global step 20 Train loss 4.00 on epoch=1
06/02/2022 12:17:39 - INFO - __main__ - Step 30 Global step 30 Train loss 3.46 on epoch=2
06/02/2022 12:17:42 - INFO - __main__ - Step 40 Global step 40 Train loss 2.62 on epoch=2
06/02/2022 12:17:44 - INFO - __main__ - Step 50 Global step 50 Train loss 2.40 on epoch=3
06/02/2022 12:17:49 - INFO - __main__ - Global step 50 Train loss 3.57 Classification-F1 0.11205354823868148 on epoch=3
06/02/2022 12:17:49 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11205354823868148 on epoch=3, global_step=50
06/02/2022 12:17:52 - INFO - __main__ - Step 60 Global step 60 Train loss 2.10 on epoch=4
06/02/2022 12:17:54 - INFO - __main__ - Step 70 Global step 70 Train loss 2.02 on epoch=4
06/02/2022 12:17:57 - INFO - __main__ - Step 80 Global step 80 Train loss 1.72 on epoch=5
06/02/2022 12:17:59 - INFO - __main__ - Step 90 Global step 90 Train loss 1.80 on epoch=6
06/02/2022 12:18:01 - INFO - __main__ - Step 100 Global step 100 Train loss 1.62 on epoch=7
06/02/2022 12:18:06 - INFO - __main__ - Global step 100 Train loss 1.85 Classification-F1 0.1562979808163532 on epoch=7
06/02/2022 12:18:06 - INFO - __main__ - Saving model with best Classification-F1: 0.11205354823868148 -> 0.1562979808163532 on epoch=7, global_step=100
06/02/2022 12:18:09 - INFO - __main__ - Step 110 Global step 110 Train loss 1.43 on epoch=7
06/02/2022 12:18:11 - INFO - __main__ - Step 120 Global step 120 Train loss 1.43 on epoch=8
06/02/2022 12:18:14 - INFO - __main__ - Step 130 Global step 130 Train loss 1.36 on epoch=9
06/02/2022 12:18:16 - INFO - __main__ - Step 140 Global step 140 Train loss 1.16 on epoch=9
06/02/2022 12:18:19 - INFO - __main__ - Step 150 Global step 150 Train loss 1.13 on epoch=10
06/02/2022 12:18:24 - INFO - __main__ - Global step 150 Train loss 1.30 Classification-F1 0.2779990738468247 on epoch=10
06/02/2022 12:18:24 - INFO - __main__ - Saving model with best Classification-F1: 0.1562979808163532 -> 0.2779990738468247 on epoch=10, global_step=150
06/02/2022 12:18:27 - INFO - __main__ - Step 160 Global step 160 Train loss 1.11 on epoch=11
06/02/2022 12:18:29 - INFO - __main__ - Step 170 Global step 170 Train loss 1.00 on epoch=12
06/02/2022 12:18:32 - INFO - __main__ - Step 180 Global step 180 Train loss 0.97 on epoch=12
06/02/2022 12:18:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.96 on epoch=13
06/02/2022 12:18:37 - INFO - __main__ - Step 200 Global step 200 Train loss 0.87 on epoch=14
06/02/2022 12:18:42 - INFO - __main__ - Global step 200 Train loss 0.98 Classification-F1 0.380155829905932 on epoch=14
06/02/2022 12:18:42 - INFO - __main__ - Saving model with best Classification-F1: 0.2779990738468247 -> 0.380155829905932 on epoch=14, global_step=200
06/02/2022 12:18:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=14
06/02/2022 12:18:47 - INFO - __main__ - Step 220 Global step 220 Train loss 0.71 on epoch=15
06/02/2022 12:18:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.67 on epoch=16
06/02/2022 12:18:52 - INFO - __main__ - Step 240 Global step 240 Train loss 0.51 on epoch=17
06/02/2022 12:18:54 - INFO - __main__ - Step 250 Global step 250 Train loss 0.53 on epoch=17
06/02/2022 12:19:01 - INFO - __main__ - Global step 250 Train loss 0.62 Classification-F1 0.5246448618776608 on epoch=17
06/02/2022 12:19:01 - INFO - __main__ - Saving model with best Classification-F1: 0.380155829905932 -> 0.5246448618776608 on epoch=17, global_step=250
06/02/2022 12:19:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.43 on epoch=18
06/02/2022 12:19:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=19
06/02/2022 12:19:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.52 on epoch=19
06/02/2022 12:19:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.42 on epoch=20
06/02/2022 12:19:13 - INFO - __main__ - Step 300 Global step 300 Train loss 0.51 on epoch=21
06/02/2022 12:19:20 - INFO - __main__ - Global step 300 Train loss 0.48 Classification-F1 0.6422222795987053 on epoch=21
06/02/2022 12:19:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5246448618776608 -> 0.6422222795987053 on epoch=21, global_step=300
06/02/2022 12:19:22 - INFO - __main__ - Step 310 Global step 310 Train loss 0.40 on epoch=22
06/02/2022 12:19:25 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=22
06/02/2022 12:19:27 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=23
06/02/2022 12:19:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=24
06/02/2022 12:19:32 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=24
06/02/2022 12:19:39 - INFO - __main__ - Global step 350 Train loss 0.36 Classification-F1 0.5222338233990614 on epoch=24
06/02/2022 12:19:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=25
06/02/2022 12:19:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.32 on epoch=26
06/02/2022 12:19:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=27
06/02/2022 12:19:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.27 on epoch=27
06/02/2022 12:19:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.37 on epoch=28
06/02/2022 12:19:58 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.5198159670380439 on epoch=28
06/02/2022 12:20:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=29
06/02/2022 12:20:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=29
06/02/2022 12:20:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=30
06/02/2022 12:20:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=31
06/02/2022 12:20:10 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=32
06/02/2022 12:20:16 - INFO - __main__ - Global step 450 Train loss 0.25 Classification-F1 0.633308008341706 on epoch=32
06/02/2022 12:20:19 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=32
06/02/2022 12:20:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=33
06/02/2022 12:20:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=34
06/02/2022 12:20:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=34
06/02/2022 12:20:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=35
06/02/2022 12:20:36 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.6928750880311783 on epoch=35
06/02/2022 12:20:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6422222795987053 -> 0.6928750880311783 on epoch=35, global_step=500
06/02/2022 12:20:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=36
06/02/2022 12:20:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=37
06/02/2022 12:20:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=37
06/02/2022 12:20:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=38
06/02/2022 12:20:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=39
06/02/2022 12:20:55 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.6781299178958083 on epoch=39
06/02/2022 12:20:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=39
06/02/2022 12:21:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=40
06/02/2022 12:21:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=41
06/02/2022 12:21:04 - INFO - __main__ - Step 590 Global step 590 Train loss 0.14 on epoch=42
06/02/2022 12:21:07 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=42
06/02/2022 12:21:13 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.7092753844046128 on epoch=42
06/02/2022 12:21:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6928750880311783 -> 0.7092753844046128 on epoch=42, global_step=600
06/02/2022 12:21:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=43
06/02/2022 12:21:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=44
06/02/2022 12:21:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=44
06/02/2022 12:21:23 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=45
06/02/2022 12:21:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=46
06/02/2022 12:21:33 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.7643668008488372 on epoch=46
06/02/2022 12:21:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7092753844046128 -> 0.7643668008488372 on epoch=46, global_step=650
06/02/2022 12:21:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=47
06/02/2022 12:21:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=47
06/02/2022 12:21:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=48
06/02/2022 12:21:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=49
06/02/2022 12:21:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=49
06/02/2022 12:21:52 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.7676782011027993 on epoch=49
06/02/2022 12:21:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7643668008488372 -> 0.7676782011027993 on epoch=49, global_step=700
06/02/2022 12:21:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=50
06/02/2022 12:21:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=51
06/02/2022 12:22:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
06/02/2022 12:22:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=52
06/02/2022 12:22:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=53
06/02/2022 12:22:12 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.8226146104108546 on epoch=53
06/02/2022 12:22:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7676782011027993 -> 0.8226146104108546 on epoch=53, global_step=750
06/02/2022 12:22:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=54
06/02/2022 12:22:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=54
06/02/2022 12:22:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=55
06/02/2022 12:22:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=56
06/02/2022 12:22:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=57
06/02/2022 12:22:31 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.7913336002939599 on epoch=57
06/02/2022 12:22:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=57
06/02/2022 12:22:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=58
06/02/2022 12:22:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=59
06/02/2022 12:22:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=59
06/02/2022 12:22:43 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=60
06/02/2022 12:22:50 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.8378339311140464 on epoch=60
06/02/2022 12:22:50 - INFO - __main__ - Saving model with best Classification-F1: 0.8226146104108546 -> 0.8378339311140464 on epoch=60, global_step=850
06/02/2022 12:22:53 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=61
06/02/2022 12:22:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=62
06/02/2022 12:22:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=62
06/02/2022 12:23:00 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=63
06/02/2022 12:23:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=64
06/02/2022 12:23:09 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.8508550796190657 on epoch=64
06/02/2022 12:23:09 - INFO - __main__ - Saving model with best Classification-F1: 0.8378339311140464 -> 0.8508550796190657 on epoch=64, global_step=900
06/02/2022 12:23:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/02/2022 12:23:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=65
06/02/2022 12:23:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=66
06/02/2022 12:23:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=67
06/02/2022 12:23:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=67
06/02/2022 12:23:29 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.7949394449088458 on epoch=67
06/02/2022 12:23:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
06/02/2022 12:23:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=69
06/02/2022 12:23:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/02/2022 12:23:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=70
06/02/2022 12:23:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/02/2022 12:23:48 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.8468412398456198 on epoch=71
06/02/2022 12:23:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=72
06/02/2022 12:23:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
06/02/2022 12:23:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
06/02/2022 12:23:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
06/02/2022 12:24:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
06/02/2022 12:24:07 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.9016234408281129 on epoch=74
06/02/2022 12:24:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8508550796190657 -> 0.9016234408281129 on epoch=74, global_step=1050
06/02/2022 12:24:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=75
06/02/2022 12:24:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
06/02/2022 12:24:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
06/02/2022 12:24:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=77
06/02/2022 12:24:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
06/02/2022 12:24:27 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.7453512226454385 on epoch=78
06/02/2022 12:24:29 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=79
06/02/2022 12:24:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
06/02/2022 12:24:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
06/02/2022 12:24:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=81
06/02/2022 12:24:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/02/2022 12:24:47 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.8508588980452633 on epoch=82
06/02/2022 12:24:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
06/02/2022 12:24:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
06/02/2022 12:24:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/02/2022 12:24:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=84
06/02/2022 12:24:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
06/02/2022 12:25:07 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7392053550951511 on epoch=85
06/02/2022 12:25:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
06/02/2022 12:25:12 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/02/2022 12:25:14 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
06/02/2022 12:25:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=88
06/02/2022 12:25:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
06/02/2022 12:25:27 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7906663868012213 on epoch=89
06/02/2022 12:25:30 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
06/02/2022 12:25:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.17 on epoch=90
06/02/2022 12:25:35 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
06/02/2022 12:25:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
06/02/2022 12:25:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=92
06/02/2022 12:25:47 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.8346093615232018 on epoch=92
06/02/2022 12:25:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
06/02/2022 12:25:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=94
06/02/2022 12:25:55 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=94
06/02/2022 12:25:57 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=95
06/02/2022 12:26:00 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/02/2022 12:26:07 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.7306373286211996 on epoch=96
06/02/2022 12:26:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
06/02/2022 12:26:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
06/02/2022 12:26:15 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/02/2022 12:26:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/02/2022 12:26:20 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/02/2022 12:26:29 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7454489743560934 on epoch=99
06/02/2022 12:26:31 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.16 on epoch=100
06/02/2022 12:26:34 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
06/02/2022 12:26:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
06/02/2022 12:26:38 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=102
06/02/2022 12:26:41 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
06/02/2022 12:26:49 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.785701667044499 on epoch=103
06/02/2022 12:26:51 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
06/02/2022 12:26:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
06/02/2022 12:26:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
06/02/2022 12:26:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
06/02/2022 12:27:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
06/02/2022 12:27:09 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8450625270775213 on epoch=107
06/02/2022 12:27:11 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=107
06/02/2022 12:27:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/02/2022 12:27:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
06/02/2022 12:27:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
06/02/2022 12:27:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/02/2022 12:27:30 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.8426783916051505 on epoch=110
06/02/2022 12:27:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=111
06/02/2022 12:27:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
06/02/2022 12:27:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
06/02/2022 12:27:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
06/02/2022 12:27:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/02/2022 12:27:50 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8402358628695183 on epoch=114
06/02/2022 12:27:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
06/02/2022 12:27:55 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/02/2022 12:27:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/02/2022 12:28:00 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/02/2022 12:28:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/02/2022 12:28:11 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7023707672710952 on epoch=117
06/02/2022 12:28:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/02/2022 12:28:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/02/2022 12:28:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/02/2022 12:28:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/02/2022 12:28:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/02/2022 12:28:32 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7888874494198171 on epoch=121
06/02/2022 12:28:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/02/2022 12:28:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
06/02/2022 12:28:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=123
06/02/2022 12:28:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
06/02/2022 12:28:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/02/2022 12:28:54 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7437688668292116 on epoch=124
06/02/2022 12:28:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/02/2022 12:28:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/02/2022 12:29:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/02/2022 12:29:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=127
06/02/2022 12:29:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/02/2022 12:29:15 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7919529049133838 on epoch=128
06/02/2022 12:29:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/02/2022 12:29:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/02/2022 12:29:22 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/02/2022 12:29:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/02/2022 12:29:27 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/02/2022 12:29:36 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7981156665315535 on epoch=132
06/02/2022 12:29:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/02/2022 12:29:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
06/02/2022 12:29:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/02/2022 12:29:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/02/2022 12:29:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/02/2022 12:29:58 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7933656726923756 on epoch=135
06/02/2022 12:30:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
06/02/2022 12:30:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/02/2022 12:30:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/02/2022 12:30:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
06/02/2022 12:30:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/02/2022 12:30:20 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7889162844832543 on epoch=139
06/02/2022 12:30:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/02/2022 12:30:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/02/2022 12:30:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/02/2022 12:30:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/02/2022 12:30:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/02/2022 12:30:42 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7933656726923756 on epoch=142
06/02/2022 12:30:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/02/2022 12:30:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/02/2022 12:30:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/02/2022 12:30:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/02/2022 12:30:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/02/2022 12:31:03 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7974347363578864 on epoch=146
06/02/2022 12:31:05 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
06/02/2022 12:31:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/02/2022 12:31:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/02/2022 12:31:12 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/02/2022 12:31:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/02/2022 12:31:24 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8009767983439711 on epoch=149
06/02/2022 12:31:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/02/2022 12:31:29 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/02/2022 12:31:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/02/2022 12:31:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/02/2022 12:31:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/02/2022 12:31:45 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.791623540911966 on epoch=153
06/02/2022 12:31:47 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/02/2022 12:31:50 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
06/02/2022 12:31:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/02/2022 12:31:55 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
06/02/2022 12:31:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/02/2022 12:32:06 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8529056643324233 on epoch=157
06/02/2022 12:32:08 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/02/2022 12:32:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/02/2022 12:32:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/02/2022 12:32:15 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/02/2022 12:32:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/02/2022 12:32:27 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9077417669464388 on epoch=160
06/02/2022 12:32:27 - INFO - __main__ - Saving model with best Classification-F1: 0.9016234408281129 -> 0.9077417669464388 on epoch=160, global_step=2250
06/02/2022 12:32:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/02/2022 12:32:32 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/02/2022 12:32:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/02/2022 12:32:36 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/02/2022 12:32:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/02/2022 12:32:49 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8529056643324233 on epoch=164
06/02/2022 12:32:51 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/02/2022 12:32:53 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/02/2022 12:32:56 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/02/2022 12:32:58 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/02/2022 12:33:01 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=167
06/02/2022 12:33:10 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8445807315367244 on epoch=167
06/02/2022 12:33:13 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/02/2022 12:33:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=169
06/02/2022 12:33:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/02/2022 12:33:20 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/02/2022 12:33:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
06/02/2022 12:33:33 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8468488766980147 on epoch=171
06/02/2022 12:33:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/02/2022 12:33:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/02/2022 12:33:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/02/2022 12:33:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
06/02/2022 12:33:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=174
06/02/2022 12:33:55 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.8406706631105269 on epoch=174
06/02/2022 12:33:58 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/02/2022 12:34:00 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/02/2022 12:34:02 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/02/2022 12:34:05 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/02/2022 12:34:07 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/02/2022 12:34:17 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8468534588094516 on epoch=178
06/02/2022 12:34:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/02/2022 12:34:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/02/2022 12:34:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=180
06/02/2022 12:34:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/02/2022 12:34:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/02/2022 12:34:39 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8489955959062258 on epoch=182
06/02/2022 12:34:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/02/2022 12:34:44 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/02/2022 12:34:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/02/2022 12:34:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/02/2022 12:34:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/02/2022 12:35:00 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7948880118333106 on epoch=185
06/02/2022 12:35:03 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/02/2022 12:35:05 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
06/02/2022 12:35:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/02/2022 12:35:10 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/02/2022 12:35:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/02/2022 12:35:24 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7925927550714897 on epoch=189
06/02/2022 12:35:26 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/02/2022 12:35:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/02/2022 12:35:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/02/2022 12:35:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/02/2022 12:35:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/02/2022 12:35:47 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9035791732677161 on epoch=192
06/02/2022 12:35:50 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/02/2022 12:35:53 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
06/02/2022 12:35:55 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/02/2022 12:35:58 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/02/2022 12:36:01 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
06/02/2022 12:36:11 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9122140762463343 on epoch=196
06/02/2022 12:36:11 - INFO - __main__ - Saving model with best Classification-F1: 0.9077417669464388 -> 0.9122140762463343 on epoch=196, global_step=2750
06/02/2022 12:36:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/02/2022 12:36:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/02/2022 12:36:19 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/02/2022 12:36:22 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/02/2022 12:36:24 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/02/2022 12:36:34 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8510424303519062 on epoch=199
06/02/2022 12:36:37 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/02/2022 12:36:40 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/02/2022 12:36:42 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/02/2022 12:36:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/02/2022 12:36:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/02/2022 12:36:57 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8358976792696551 on epoch=203
06/02/2022 12:37:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/02/2022 12:37:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/02/2022 12:37:05 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/02/2022 12:37:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=206
06/02/2022 12:37:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/02/2022 12:37:19 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.8514326735092864 on epoch=207
06/02/2022 12:37:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/02/2022 12:37:24 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/02/2022 12:37:27 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/02/2022 12:37:29 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/02/2022 12:37:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/02/2022 12:37:41 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8429510272356491 on epoch=210
06/02/2022 12:37:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/02/2022 12:37:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/02/2022 12:37:48 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=212
06/02/2022 12:37:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/02/2022 12:37:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/02/2022 12:37:54 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 12:37:54 - INFO - __main__ - Printing 3 examples
06/02/2022 12:37:54 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 12:37:54 - INFO - __main__ - ['Plant']
06/02/2022 12:37:54 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 12:37:54 - INFO - __main__ - ['Plant']
06/02/2022 12:37:54 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 12:37:54 - INFO - __main__ - ['Plant']
06/02/2022 12:37:54 - INFO - __main__ - Tokenizing Input ...
06/02/2022 12:37:55 - INFO - __main__ - Tokenizing Output ...
06/02/2022 12:37:55 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 12:37:55 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 12:37:55 - INFO - __main__ - Printing 3 examples
06/02/2022 12:37:55 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 12:37:55 - INFO - __main__ - ['Plant']
06/02/2022 12:37:55 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 12:37:55 - INFO - __main__ - ['Plant']
06/02/2022 12:37:55 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 12:37:55 - INFO - __main__ - ['Plant']
06/02/2022 12:37:55 - INFO - __main__ - Tokenizing Input ...
06/02/2022 12:37:55 - INFO - __main__ - Tokenizing Output ...
06/02/2022 12:37:55 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 12:38:02 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8429510272356491 on epoch=214
06/02/2022 12:38:02 - INFO - __main__ - save last model!
06/02/2022 12:38:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 12:38:02 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 12:38:02 - INFO - __main__ - Printing 3 examples
06/02/2022 12:38:02 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 12:38:02 - INFO - __main__ - ['Animal']
06/02/2022 12:38:02 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 12:38:02 - INFO - __main__ - ['Animal']
06/02/2022 12:38:02 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 12:38:02 - INFO - __main__ - ['Village']
06/02/2022 12:38:02 - INFO - __main__ - Tokenizing Input ...
06/02/2022 12:38:04 - INFO - __main__ - Tokenizing Output ...
06/02/2022 12:38:07 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 12:38:10 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 12:38:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 12:38:11 - INFO - __main__ - Starting training!
06/02/2022 12:40:57 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
06/02/2022 12:40:57 - INFO - __main__ - Classification-F1 on test data: 0.6731
06/02/2022 12:40:57 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.9122140762463343, test_performance=0.6730897079578716
06/02/2022 12:40:57 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
06/02/2022 12:40:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 12:40:58 - INFO - __main__ - Printing 3 examples
06/02/2022 12:40:58 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 12:40:58 - INFO - __main__ - ['Plant']
06/02/2022 12:40:58 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 12:40:58 - INFO - __main__ - ['Plant']
06/02/2022 12:40:58 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 12:40:58 - INFO - __main__ - ['Plant']
06/02/2022 12:40:58 - INFO - __main__ - Tokenizing Input ...
06/02/2022 12:40:58 - INFO - __main__ - Tokenizing Output ...
06/02/2022 12:40:59 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 12:40:59 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 12:40:59 - INFO - __main__ - Printing 3 examples
06/02/2022 12:40:59 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 12:40:59 - INFO - __main__ - ['Plant']
06/02/2022 12:40:59 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 12:40:59 - INFO - __main__ - ['Plant']
06/02/2022 12:40:59 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 12:40:59 - INFO - __main__ - ['Plant']
06/02/2022 12:40:59 - INFO - __main__ - Tokenizing Input ...
06/02/2022 12:40:59 - INFO - __main__ - Tokenizing Output ...
06/02/2022 12:40:59 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 12:41:16 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 12:41:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 12:41:17 - INFO - __main__ - Starting training!
06/02/2022 12:41:20 - INFO - __main__ - Step 10 Global step 10 Train loss 5.65 on epoch=0
06/02/2022 12:41:22 - INFO - __main__ - Step 20 Global step 20 Train loss 4.17 on epoch=1
06/02/2022 12:41:25 - INFO - __main__ - Step 30 Global step 30 Train loss 3.54 on epoch=2
06/02/2022 12:41:27 - INFO - __main__ - Step 40 Global step 40 Train loss 3.00 on epoch=2
06/02/2022 12:41:29 - INFO - __main__ - Step 50 Global step 50 Train loss 2.70 on epoch=3
06/02/2022 12:41:34 - INFO - __main__ - Global step 50 Train loss 3.81 Classification-F1 0.08699280532013047 on epoch=3
06/02/2022 12:41:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08699280532013047 on epoch=3, global_step=50
06/02/2022 12:41:37 - INFO - __main__ - Step 60 Global step 60 Train loss 2.34 on epoch=4
06/02/2022 12:41:39 - INFO - __main__ - Step 70 Global step 70 Train loss 2.17 on epoch=4
06/02/2022 12:41:41 - INFO - __main__ - Step 80 Global step 80 Train loss 1.80 on epoch=5
06/02/2022 12:41:44 - INFO - __main__ - Step 90 Global step 90 Train loss 2.03 on epoch=6
06/02/2022 12:41:46 - INFO - __main__ - Step 100 Global step 100 Train loss 1.82 on epoch=7
06/02/2022 12:41:51 - INFO - __main__ - Global step 100 Train loss 2.03 Classification-F1 0.12868495472154712 on epoch=7
06/02/2022 12:41:51 - INFO - __main__ - Saving model with best Classification-F1: 0.08699280532013047 -> 0.12868495472154712 on epoch=7, global_step=100
06/02/2022 12:41:53 - INFO - __main__ - Step 110 Global step 110 Train loss 1.53 on epoch=7
06/02/2022 12:41:56 - INFO - __main__ - Step 120 Global step 120 Train loss 1.61 on epoch=8
06/02/2022 12:41:58 - INFO - __main__ - Step 130 Global step 130 Train loss 1.49 on epoch=9
06/02/2022 12:42:00 - INFO - __main__ - Step 140 Global step 140 Train loss 1.36 on epoch=9
06/02/2022 12:42:03 - INFO - __main__ - Step 150 Global step 150 Train loss 1.25 on epoch=10
06/02/2022 12:42:08 - INFO - __main__ - Global step 150 Train loss 1.45 Classification-F1 0.1876195947326675 on epoch=10
06/02/2022 12:42:08 - INFO - __main__ - Saving model with best Classification-F1: 0.12868495472154712 -> 0.1876195947326675 on epoch=10, global_step=150
06/02/2022 12:42:10 - INFO - __main__ - Step 160 Global step 160 Train loss 1.40 on epoch=11
06/02/2022 12:42:13 - INFO - __main__ - Step 170 Global step 170 Train loss 1.26 on epoch=12
06/02/2022 12:42:15 - INFO - __main__ - Step 180 Global step 180 Train loss 1.04 on epoch=12
06/02/2022 12:42:17 - INFO - __main__ - Step 190 Global step 190 Train loss 1.20 on epoch=13
06/02/2022 12:42:20 - INFO - __main__ - Step 200 Global step 200 Train loss 1.02 on epoch=14
06/02/2022 12:42:26 - INFO - __main__ - Global step 200 Train loss 1.18 Classification-F1 0.2804457946772937 on epoch=14
06/02/2022 12:42:26 - INFO - __main__ - Saving model with best Classification-F1: 0.1876195947326675 -> 0.2804457946772937 on epoch=14, global_step=200
06/02/2022 12:42:28 - INFO - __main__ - Step 210 Global step 210 Train loss 1.02 on epoch=14
06/02/2022 12:42:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.79 on epoch=15
06/02/2022 12:42:33 - INFO - __main__ - Step 230 Global step 230 Train loss 0.93 on epoch=16
06/02/2022 12:42:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.74 on epoch=17
06/02/2022 12:42:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.67 on epoch=17
06/02/2022 12:42:43 - INFO - __main__ - Global step 250 Train loss 0.83 Classification-F1 0.47853173083517914 on epoch=17
06/02/2022 12:42:43 - INFO - __main__ - Saving model with best Classification-F1: 0.2804457946772937 -> 0.47853173083517914 on epoch=17, global_step=250
06/02/2022 12:42:46 - INFO - __main__ - Step 260 Global step 260 Train loss 0.87 on epoch=18
06/02/2022 12:42:48 - INFO - __main__ - Step 270 Global step 270 Train loss 0.68 on epoch=19
06/02/2022 12:42:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.63 on epoch=19
06/02/2022 12:42:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.62 on epoch=20
06/02/2022 12:42:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.63 on epoch=21
06/02/2022 12:43:01 - INFO - __main__ - Global step 300 Train loss 0.69 Classification-F1 0.5043281299873592 on epoch=21
06/02/2022 12:43:01 - INFO - __main__ - Saving model with best Classification-F1: 0.47853173083517914 -> 0.5043281299873592 on epoch=21, global_step=300
06/02/2022 12:43:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.54 on epoch=22
06/02/2022 12:43:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.44 on epoch=22
06/02/2022 12:43:09 - INFO - __main__ - Step 330 Global step 330 Train loss 0.58 on epoch=23
06/02/2022 12:43:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.58 on epoch=24
06/02/2022 12:43:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.45 on epoch=24
06/02/2022 12:43:20 - INFO - __main__ - Global step 350 Train loss 0.52 Classification-F1 0.5874000488694177 on epoch=24
06/02/2022 12:43:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5043281299873592 -> 0.5874000488694177 on epoch=24, global_step=350
06/02/2022 12:43:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.53 on epoch=25
06/02/2022 12:43:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.44 on epoch=26
06/02/2022 12:43:27 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=27
06/02/2022 12:43:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=27
06/02/2022 12:43:32 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=28
06/02/2022 12:43:39 - INFO - __main__ - Global step 400 Train loss 0.46 Classification-F1 0.6426768502931559 on epoch=28
06/02/2022 12:43:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5874000488694177 -> 0.6426768502931559 on epoch=28, global_step=400
06/02/2022 12:43:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.35 on epoch=29
06/02/2022 12:43:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.38 on epoch=29
06/02/2022 12:43:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=30
06/02/2022 12:43:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=31
06/02/2022 12:43:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=32
06/02/2022 12:43:58 - INFO - __main__ - Global step 450 Train loss 0.36 Classification-F1 0.6069866106688065 on epoch=32
06/02/2022 12:44:00 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=32
06/02/2022 12:44:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.40 on epoch=33
06/02/2022 12:44:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=34
06/02/2022 12:44:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=34
06/02/2022 12:44:10 - INFO - __main__ - Step 500 Global step 500 Train loss 0.33 on epoch=35
06/02/2022 12:44:17 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.7068282944575229 on epoch=35
06/02/2022 12:44:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6426768502931559 -> 0.7068282944575229 on epoch=35, global_step=500
06/02/2022 12:44:19 - INFO - __main__ - Step 510 Global step 510 Train loss 0.35 on epoch=36
06/02/2022 12:44:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.29 on epoch=37
06/02/2022 12:44:24 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=37
06/02/2022 12:44:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=38
06/02/2022 12:44:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=39
06/02/2022 12:44:36 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.6987226070414907 on epoch=39
06/02/2022 12:44:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=39
06/02/2022 12:44:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=40
06/02/2022 12:44:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=41
06/02/2022 12:44:45 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=42
06/02/2022 12:44:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.27 on epoch=42
06/02/2022 12:44:54 - INFO - __main__ - Global step 600 Train loss 0.25 Classification-F1 0.6572973413016241 on epoch=42
06/02/2022 12:44:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=43
06/02/2022 12:44:59 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=44
06/02/2022 12:45:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=44
06/02/2022 12:45:04 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=45
06/02/2022 12:45:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=46
06/02/2022 12:45:13 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.6960652757997675 on epoch=46
06/02/2022 12:45:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=47
06/02/2022 12:45:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=47
06/02/2022 12:45:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.28 on epoch=48
06/02/2022 12:45:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=49
06/02/2022 12:45:25 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=49
06/02/2022 12:45:32 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.691207814983688 on epoch=49
06/02/2022 12:45:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=50
06/02/2022 12:45:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=51
06/02/2022 12:45:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=52
06/02/2022 12:45:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=52
06/02/2022 12:45:45 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=53
06/02/2022 12:45:51 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.6999875992020685 on epoch=53
06/02/2022 12:45:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=54
06/02/2022 12:45:56 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=54
06/02/2022 12:45:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=55
06/02/2022 12:46:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.24 on epoch=56
06/02/2022 12:46:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=57
06/02/2022 12:46:11 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.7309342468669827 on epoch=57
06/02/2022 12:46:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7068282944575229 -> 0.7309342468669827 on epoch=57, global_step=800
06/02/2022 12:46:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=57
06/02/2022 12:46:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=58
06/02/2022 12:46:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=59
06/02/2022 12:46:20 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=59
06/02/2022 12:46:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=60
06/02/2022 12:46:30 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.782350201452549 on epoch=60
06/02/2022 12:46:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7309342468669827 -> 0.782350201452549 on epoch=60, global_step=850
06/02/2022 12:46:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=61
06/02/2022 12:46:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=62
06/02/2022 12:46:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=62
06/02/2022 12:46:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=63
06/02/2022 12:46:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=64
06/02/2022 12:46:49 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.7929521509400248 on epoch=64
06/02/2022 12:46:49 - INFO - __main__ - Saving model with best Classification-F1: 0.782350201452549 -> 0.7929521509400248 on epoch=64, global_step=900
06/02/2022 12:46:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=64
06/02/2022 12:46:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
06/02/2022 12:46:57 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=66
06/02/2022 12:46:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=67
06/02/2022 12:47:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=67
06/02/2022 12:47:08 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.748899253665579 on epoch=67
06/02/2022 12:47:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=68
06/02/2022 12:47:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=69
06/02/2022 12:47:15 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=69
06/02/2022 12:47:18 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=70
06/02/2022 12:47:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.19 on epoch=71
06/02/2022 12:47:27 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.7951157750103427 on epoch=71
06/02/2022 12:47:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7929521509400248 -> 0.7951157750103427 on epoch=71, global_step=1000
06/02/2022 12:47:30 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=72
06/02/2022 12:47:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=72
06/02/2022 12:47:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=73
06/02/2022 12:47:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=74
06/02/2022 12:47:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
06/02/2022 12:47:47 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.7560875390031969 on epoch=74
06/02/2022 12:47:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
06/02/2022 12:47:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=76
06/02/2022 12:47:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
06/02/2022 12:47:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=77
06/02/2022 12:47:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=78
06/02/2022 12:48:06 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.798792245598578 on epoch=78
06/02/2022 12:48:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7951157750103427 -> 0.798792245598578 on epoch=78, global_step=1100
06/02/2022 12:48:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=79
06/02/2022 12:48:11 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
06/02/2022 12:48:14 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=80
06/02/2022 12:48:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=81
06/02/2022 12:48:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=82
06/02/2022 12:48:26 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.8547651480452632 on epoch=82
06/02/2022 12:48:26 - INFO - __main__ - Saving model with best Classification-F1: 0.798792245598578 -> 0.8547651480452632 on epoch=82, global_step=1150
06/02/2022 12:48:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=82
06/02/2022 12:48:31 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
06/02/2022 12:48:34 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=84
06/02/2022 12:48:36 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=84
06/02/2022 12:48:39 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=85
06/02/2022 12:48:46 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.8465540043502486 on epoch=85
06/02/2022 12:48:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/02/2022 12:48:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
06/02/2022 12:48:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
06/02/2022 12:48:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=88
06/02/2022 12:48:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/02/2022 12:49:05 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.9139000288826895 on epoch=89
06/02/2022 12:49:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8547651480452632 -> 0.9139000288826895 on epoch=89, global_step=1250
06/02/2022 12:49:08 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
06/02/2022 12:49:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=90
06/02/2022 12:49:13 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=91
06/02/2022 12:49:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/02/2022 12:49:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=92
06/02/2022 12:49:25 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.7987807453973245 on epoch=92
06/02/2022 12:49:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=93
06/02/2022 12:49:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
06/02/2022 12:49:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
06/02/2022 12:49:35 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
06/02/2022 12:49:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/02/2022 12:49:45 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.9097571540835296 on epoch=96
06/02/2022 12:49:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
06/02/2022 12:49:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.18 on epoch=97
06/02/2022 12:49:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=98
06/02/2022 12:49:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
06/02/2022 12:49:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=99
06/02/2022 12:50:05 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.8547651480452632 on epoch=99
06/02/2022 12:50:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
06/02/2022 12:50:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=101
06/02/2022 12:50:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
06/02/2022 12:50:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=102
06/02/2022 12:50:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
06/02/2022 12:50:25 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.8508812029210512 on epoch=103
06/02/2022 12:50:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=104
06/02/2022 12:50:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/02/2022 12:50:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/02/2022 12:50:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
06/02/2022 12:50:37 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=107
06/02/2022 12:50:45 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.8507597088094516 on epoch=107
06/02/2022 12:50:47 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=107
06/02/2022 12:50:50 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=108
06/02/2022 12:50:52 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=109
06/02/2022 12:50:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/02/2022 12:50:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
06/02/2022 12:51:04 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.8546537398456198 on epoch=110
06/02/2022 12:51:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
06/02/2022 12:51:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
06/02/2022 12:51:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=112
06/02/2022 12:51:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
06/02/2022 12:51:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
06/02/2022 12:51:24 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.8445500942818224 on epoch=114
06/02/2022 12:51:27 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
06/02/2022 12:51:29 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/02/2022 12:51:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/02/2022 12:51:34 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
06/02/2022 12:51:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=117
06/02/2022 12:51:45 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.8022199601855101 on epoch=117
06/02/2022 12:51:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
06/02/2022 12:51:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/02/2022 12:51:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/02/2022 12:51:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
06/02/2022 12:51:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/02/2022 12:52:05 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.8445908174486804 on epoch=121
06/02/2022 12:52:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/02/2022 12:52:10 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
06/02/2022 12:52:13 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/02/2022 12:52:15 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
06/02/2022 12:52:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
06/02/2022 12:52:25 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.80034341980295 on epoch=124
06/02/2022 12:52:28 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=125
06/02/2022 12:52:30 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
06/02/2022 12:52:33 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
06/02/2022 12:52:35 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
06/02/2022 12:52:38 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/02/2022 12:52:46 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.80034341980295 on epoch=128
06/02/2022 12:52:48 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
06/02/2022 12:52:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/02/2022 12:52:53 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=130
06/02/2022 12:52:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=131
06/02/2022 12:52:58 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
06/02/2022 12:53:06 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.7509597270442653 on epoch=132
06/02/2022 12:53:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
06/02/2022 12:53:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
06/02/2022 12:53:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/02/2022 12:53:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/02/2022 12:53:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=135
06/02/2022 12:53:25 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.798941981484676 on epoch=135
06/02/2022 12:53:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=136
06/02/2022 12:53:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/02/2022 12:53:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=137
06/02/2022 12:53:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
06/02/2022 12:53:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=139
06/02/2022 12:53:45 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.8530585593841642 on epoch=139
06/02/2022 12:53:47 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/02/2022 12:53:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
06/02/2022 12:53:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/02/2022 12:53:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
06/02/2022 12:53:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/02/2022 12:54:05 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.9097857608341477 on epoch=142
06/02/2022 12:54:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/02/2022 12:54:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/02/2022 12:54:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
06/02/2022 12:54:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=145
06/02/2022 12:54:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/02/2022 12:54:25 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.9119084336131055 on epoch=146
06/02/2022 12:54:27 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
06/02/2022 12:54:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
06/02/2022 12:54:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/02/2022 12:54:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/02/2022 12:54:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/02/2022 12:54:44 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.8530585593841642 on epoch=149
06/02/2022 12:54:46 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/02/2022 12:54:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
06/02/2022 12:54:51 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=152
06/02/2022 12:54:54 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=152
06/02/2022 12:54:56 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/02/2022 12:55:03 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.8047797711459951 on epoch=153
06/02/2022 12:55:06 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/02/2022 12:55:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/02/2022 12:55:11 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=155
06/02/2022 12:55:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
06/02/2022 12:55:16 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/02/2022 12:55:23 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8609970674486804 on epoch=157
06/02/2022 12:55:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/02/2022 12:55:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/02/2022 12:55:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=159
06/02/2022 12:55:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/02/2022 12:55:35 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/02/2022 12:55:43 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.918095302299974 on epoch=160
06/02/2022 12:55:43 - INFO - __main__ - Saving model with best Classification-F1: 0.9139000288826895 -> 0.918095302299974 on epoch=160, global_step=2250
06/02/2022 12:55:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/02/2022 12:55:48 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/02/2022 12:55:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/02/2022 12:55:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/02/2022 12:55:56 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/02/2022 12:56:03 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7543192632667048 on epoch=164
06/02/2022 12:56:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/02/2022 12:56:08 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/02/2022 12:56:11 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/02/2022 12:56:13 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/02/2022 12:56:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/02/2022 12:56:23 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9119322254806124 on epoch=167
06/02/2022 12:56:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/02/2022 12:56:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/02/2022 12:56:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
06/02/2022 12:56:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/02/2022 12:56:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/02/2022 12:56:42 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9139000288826895 on epoch=171
06/02/2022 12:56:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/02/2022 12:56:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=172
06/02/2022 12:56:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/02/2022 12:56:52 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
06/02/2022 12:56:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/02/2022 12:57:01 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8007150200559545 on epoch=174
06/02/2022 12:57:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/02/2022 12:57:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/02/2022 12:57:09 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=177
06/02/2022 12:57:11 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.10 on epoch=177
06/02/2022 12:57:14 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/02/2022 12:57:21 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.8046532689322063 on epoch=178
06/02/2022 12:57:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=179
06/02/2022 12:57:26 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/02/2022 12:57:28 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/02/2022 12:57:31 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/02/2022 12:57:33 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
06/02/2022 12:57:41 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.9160751002797721 on epoch=182
06/02/2022 12:57:43 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/02/2022 12:57:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/02/2022 12:57:48 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
06/02/2022 12:57:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/02/2022 12:57:53 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
06/02/2022 12:58:01 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.8047876775343569 on epoch=185
06/02/2022 12:58:03 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/02/2022 12:58:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/02/2022 12:58:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/02/2022 12:58:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/02/2022 12:58:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/02/2022 12:58:21 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8027715485020989 on epoch=189
06/02/2022 12:58:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/02/2022 12:58:26 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/02/2022 12:58:29 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/02/2022 12:58:31 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/02/2022 12:58:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/02/2022 12:58:43 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8061871082743949 on epoch=192
06/02/2022 12:58:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/02/2022 12:58:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/02/2022 12:58:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/02/2022 12:58:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/02/2022 12:58:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/02/2022 12:59:05 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7105531043707964 on epoch=196
06/02/2022 12:59:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/02/2022 12:59:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/02/2022 12:59:12 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/02/2022 12:59:15 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/02/2022 12:59:17 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/02/2022 12:59:26 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6799716857113965 on epoch=199
06/02/2022 12:59:29 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/02/2022 12:59:31 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/02/2022 12:59:34 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/02/2022 12:59:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/02/2022 12:59:39 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/02/2022 12:59:48 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7951354148697601 on epoch=203
06/02/2022 12:59:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/02/2022 12:59:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/02/2022 12:59:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/02/2022 12:59:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/02/2022 13:00:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/02/2022 13:00:10 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7522881999453188 on epoch=207
06/02/2022 13:00:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=207
06/02/2022 13:00:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.10 on epoch=208
06/02/2022 13:00:17 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/02/2022 13:00:20 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/02/2022 13:00:22 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/02/2022 13:00:32 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7142811745462351 on epoch=210
06/02/2022 13:00:35 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/02/2022 13:00:37 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/02/2022 13:00:40 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/02/2022 13:00:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/02/2022 13:00:45 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
06/02/2022 13:00:46 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 13:00:46 - INFO - __main__ - Printing 3 examples
06/02/2022 13:00:46 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 13:00:46 - INFO - __main__ - ['Plant']
06/02/2022 13:00:46 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 13:00:46 - INFO - __main__ - ['Plant']
06/02/2022 13:00:46 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 13:00:46 - INFO - __main__ - ['Plant']
06/02/2022 13:00:46 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:00:47 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:00:47 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 13:00:47 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 13:00:47 - INFO - __main__ - Printing 3 examples
06/02/2022 13:00:47 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 13:00:47 - INFO - __main__ - ['Plant']
06/02/2022 13:00:47 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 13:00:47 - INFO - __main__ - ['Plant']
06/02/2022 13:00:47 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 13:00:47 - INFO - __main__ - ['Plant']
06/02/2022 13:00:47 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:00:47 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:00:47 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 13:00:55 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7561420658194851 on epoch=214
06/02/2022 13:00:55 - INFO - __main__ - save last model!
06/02/2022 13:00:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 13:00:55 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 13:00:55 - INFO - __main__ - Printing 3 examples
06/02/2022 13:00:55 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 13:00:55 - INFO - __main__ - ['Animal']
06/02/2022 13:00:55 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 13:00:55 - INFO - __main__ - ['Animal']
06/02/2022 13:00:55 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 13:00:55 - INFO - __main__ - ['Village']
06/02/2022 13:00:55 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:00:57 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:01:00 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 13:01:06 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 13:01:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 13:01:06 - INFO - __main__ - Starting training!
06/02/2022 13:04:08 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
06/02/2022 13:04:08 - INFO - __main__ - Classification-F1 on test data: 0.4649
06/02/2022 13:04:08 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.918095302299974, test_performance=0.4648830496407452
06/02/2022 13:04:08 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
06/02/2022 13:04:09 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 13:04:09 - INFO - __main__ - Printing 3 examples
06/02/2022 13:04:09 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 13:04:09 - INFO - __main__ - ['Plant']
06/02/2022 13:04:09 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 13:04:09 - INFO - __main__ - ['Plant']
06/02/2022 13:04:09 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 13:04:09 - INFO - __main__ - ['Plant']
06/02/2022 13:04:09 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:04:09 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:04:09 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 13:04:09 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 13:04:09 - INFO - __main__ - Printing 3 examples
06/02/2022 13:04:09 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 13:04:09 - INFO - __main__ - ['Plant']
06/02/2022 13:04:09 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 13:04:09 - INFO - __main__ - ['Plant']
06/02/2022 13:04:09 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 13:04:09 - INFO - __main__ - ['Plant']
06/02/2022 13:04:09 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:04:10 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:04:10 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 13:04:27 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 13:04:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 13:04:28 - INFO - __main__ - Starting training!
06/02/2022 13:04:31 - INFO - __main__ - Step 10 Global step 10 Train loss 5.47 on epoch=0
06/02/2022 13:04:33 - INFO - __main__ - Step 20 Global step 20 Train loss 4.40 on epoch=1
06/02/2022 13:04:36 - INFO - __main__ - Step 30 Global step 30 Train loss 3.65 on epoch=2
06/02/2022 13:04:38 - INFO - __main__ - Step 40 Global step 40 Train loss 3.14 on epoch=2
06/02/2022 13:04:41 - INFO - __main__ - Step 50 Global step 50 Train loss 3.20 on epoch=3
06/02/2022 13:04:45 - INFO - __main__ - Global step 50 Train loss 3.97 Classification-F1 0.0816507691587572 on epoch=3
06/02/2022 13:04:45 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0816507691587572 on epoch=3, global_step=50
06/02/2022 13:04:48 - INFO - __main__ - Step 60 Global step 60 Train loss 2.69 on epoch=4
06/02/2022 13:04:50 - INFO - __main__ - Step 70 Global step 70 Train loss 2.61 on epoch=4
06/02/2022 13:04:53 - INFO - __main__ - Step 80 Global step 80 Train loss 2.03 on epoch=5
06/02/2022 13:04:55 - INFO - __main__ - Step 90 Global step 90 Train loss 2.29 on epoch=6
06/02/2022 13:04:57 - INFO - __main__ - Step 100 Global step 100 Train loss 2.13 on epoch=7
06/02/2022 13:05:02 - INFO - __main__ - Global step 100 Train loss 2.35 Classification-F1 0.11878875497316277 on epoch=7
06/02/2022 13:05:02 - INFO - __main__ - Saving model with best Classification-F1: 0.0816507691587572 -> 0.11878875497316277 on epoch=7, global_step=100
06/02/2022 13:05:05 - INFO - __main__ - Step 110 Global step 110 Train loss 1.81 on epoch=7
06/02/2022 13:05:07 - INFO - __main__ - Step 120 Global step 120 Train loss 1.96 on epoch=8
06/02/2022 13:05:10 - INFO - __main__ - Step 130 Global step 130 Train loss 1.77 on epoch=9
06/02/2022 13:05:12 - INFO - __main__ - Step 140 Global step 140 Train loss 1.82 on epoch=9
06/02/2022 13:05:14 - INFO - __main__ - Step 150 Global step 150 Train loss 1.42 on epoch=10
06/02/2022 13:05:19 - INFO - __main__ - Global step 150 Train loss 1.76 Classification-F1 0.14590178364922315 on epoch=10
06/02/2022 13:05:19 - INFO - __main__ - Saving model with best Classification-F1: 0.11878875497316277 -> 0.14590178364922315 on epoch=10, global_step=150
06/02/2022 13:05:22 - INFO - __main__ - Step 160 Global step 160 Train loss 1.69 on epoch=11
06/02/2022 13:05:24 - INFO - __main__ - Step 170 Global step 170 Train loss 1.61 on epoch=12
06/02/2022 13:05:27 - INFO - __main__ - Step 180 Global step 180 Train loss 1.42 on epoch=12
06/02/2022 13:05:29 - INFO - __main__ - Step 190 Global step 190 Train loss 1.41 on epoch=13
06/02/2022 13:05:32 - INFO - __main__ - Step 200 Global step 200 Train loss 1.30 on epoch=14
06/02/2022 13:05:36 - INFO - __main__ - Global step 200 Train loss 1.48 Classification-F1 0.17055756374389433 on epoch=14
06/02/2022 13:05:36 - INFO - __main__ - Saving model with best Classification-F1: 0.14590178364922315 -> 0.17055756374389433 on epoch=14, global_step=200
06/02/2022 13:05:39 - INFO - __main__ - Step 210 Global step 210 Train loss 1.27 on epoch=14
06/02/2022 13:05:41 - INFO - __main__ - Step 220 Global step 220 Train loss 1.11 on epoch=15
06/02/2022 13:05:44 - INFO - __main__ - Step 230 Global step 230 Train loss 1.25 on epoch=16
06/02/2022 13:05:46 - INFO - __main__ - Step 240 Global step 240 Train loss 1.16 on epoch=17
06/02/2022 13:05:49 - INFO - __main__ - Step 250 Global step 250 Train loss 1.01 on epoch=17
06/02/2022 13:05:54 - INFO - __main__ - Global step 250 Train loss 1.16 Classification-F1 0.27017945372351504 on epoch=17
06/02/2022 13:05:54 - INFO - __main__ - Saving model with best Classification-F1: 0.17055756374389433 -> 0.27017945372351504 on epoch=17, global_step=250
06/02/2022 13:05:57 - INFO - __main__ - Step 260 Global step 260 Train loss 1.13 on epoch=18
06/02/2022 13:05:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.95 on epoch=19
06/02/2022 13:06:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.94 on epoch=19
06/02/2022 13:06:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.83 on epoch=20
06/02/2022 13:06:06 - INFO - __main__ - Step 300 Global step 300 Train loss 1.11 on epoch=21
06/02/2022 13:06:12 - INFO - __main__ - Global step 300 Train loss 0.99 Classification-F1 0.3832469655369564 on epoch=21
06/02/2022 13:06:12 - INFO - __main__ - Saving model with best Classification-F1: 0.27017945372351504 -> 0.3832469655369564 on epoch=21, global_step=300
06/02/2022 13:06:14 - INFO - __main__ - Step 310 Global step 310 Train loss 0.83 on epoch=22
06/02/2022 13:06:16 - INFO - __main__ - Step 320 Global step 320 Train loss 0.85 on epoch=22
06/02/2022 13:06:19 - INFO - __main__ - Step 330 Global step 330 Train loss 0.78 on epoch=23
06/02/2022 13:06:21 - INFO - __main__ - Step 340 Global step 340 Train loss 0.75 on epoch=24
06/02/2022 13:06:24 - INFO - __main__ - Step 350 Global step 350 Train loss 0.84 on epoch=24
06/02/2022 13:06:30 - INFO - __main__ - Global step 350 Train loss 0.81 Classification-F1 0.44586068772150017 on epoch=24
06/02/2022 13:06:30 - INFO - __main__ - Saving model with best Classification-F1: 0.3832469655369564 -> 0.44586068772150017 on epoch=24, global_step=350
06/02/2022 13:06:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.61 on epoch=25
06/02/2022 13:06:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.72 on epoch=26
06/02/2022 13:06:37 - INFO - __main__ - Step 380 Global step 380 Train loss 0.64 on epoch=27
06/02/2022 13:06:40 - INFO - __main__ - Step 390 Global step 390 Train loss 0.62 on epoch=27
06/02/2022 13:06:42 - INFO - __main__ - Step 400 Global step 400 Train loss 0.61 on epoch=28
06/02/2022 13:06:48 - INFO - __main__ - Global step 400 Train loss 0.64 Classification-F1 0.45707123712696346 on epoch=28
06/02/2022 13:06:49 - INFO - __main__ - Saving model with best Classification-F1: 0.44586068772150017 -> 0.45707123712696346 on epoch=28, global_step=400
06/02/2022 13:06:51 - INFO - __main__ - Step 410 Global step 410 Train loss 0.56 on epoch=29
06/02/2022 13:06:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.54 on epoch=29
06/02/2022 13:06:56 - INFO - __main__ - Step 430 Global step 430 Train loss 0.63 on epoch=30
06/02/2022 13:06:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.58 on epoch=31
06/02/2022 13:07:01 - INFO - __main__ - Step 450 Global step 450 Train loss 0.55 on epoch=32
06/02/2022 13:07:07 - INFO - __main__ - Global step 450 Train loss 0.57 Classification-F1 0.5808246950174181 on epoch=32
06/02/2022 13:07:07 - INFO - __main__ - Saving model with best Classification-F1: 0.45707123712696346 -> 0.5808246950174181 on epoch=32, global_step=450
06/02/2022 13:07:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.45 on epoch=32
06/02/2022 13:07:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.44 on epoch=33
06/02/2022 13:07:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.56 on epoch=34
06/02/2022 13:07:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.42 on epoch=34
06/02/2022 13:07:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.44 on epoch=35
06/02/2022 13:07:26 - INFO - __main__ - Global step 500 Train loss 0.46 Classification-F1 0.6741523236168558 on epoch=35
06/02/2022 13:07:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5808246950174181 -> 0.6741523236168558 on epoch=35, global_step=500
06/02/2022 13:07:29 - INFO - __main__ - Step 510 Global step 510 Train loss 0.44 on epoch=36
06/02/2022 13:07:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.35 on epoch=37
06/02/2022 13:07:34 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=37
06/02/2022 13:07:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.48 on epoch=38
06/02/2022 13:07:39 - INFO - __main__ - Step 550 Global step 550 Train loss 0.40 on epoch=39
06/02/2022 13:07:46 - INFO - __main__ - Global step 550 Train loss 0.40 Classification-F1 0.6105580392402351 on epoch=39
06/02/2022 13:07:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.38 on epoch=39
06/02/2022 13:07:51 - INFO - __main__ - Step 570 Global step 570 Train loss 0.40 on epoch=40
06/02/2022 13:07:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.33 on epoch=41
06/02/2022 13:07:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.37 on epoch=42
06/02/2022 13:07:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.34 on epoch=42
06/02/2022 13:08:05 - INFO - __main__ - Global step 600 Train loss 0.36 Classification-F1 0.577342950681435 on epoch=42
06/02/2022 13:08:07 - INFO - __main__ - Step 610 Global step 610 Train loss 0.38 on epoch=43
06/02/2022 13:08:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.31 on epoch=44
06/02/2022 13:08:12 - INFO - __main__ - Step 630 Global step 630 Train loss 0.30 on epoch=44
06/02/2022 13:08:15 - INFO - __main__ - Step 640 Global step 640 Train loss 0.30 on epoch=45
06/02/2022 13:08:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.31 on epoch=46
06/02/2022 13:08:24 - INFO - __main__ - Global step 650 Train loss 0.32 Classification-F1 0.5665589573038102 on epoch=46
06/02/2022 13:08:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=47
06/02/2022 13:08:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=47
06/02/2022 13:08:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.31 on epoch=48
06/02/2022 13:08:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.28 on epoch=49
06/02/2022 13:08:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=49
06/02/2022 13:08:43 - INFO - __main__ - Global step 700 Train loss 0.27 Classification-F1 0.6274028492956172 on epoch=49
06/02/2022 13:08:45 - INFO - __main__ - Step 710 Global step 710 Train loss 0.26 on epoch=50
06/02/2022 13:08:48 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=51
06/02/2022 13:08:50 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=52
06/02/2022 13:08:53 - INFO - __main__ - Step 740 Global step 740 Train loss 0.30 on epoch=52
06/02/2022 13:08:55 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=53
06/02/2022 13:09:02 - INFO - __main__ - Global step 750 Train loss 0.26 Classification-F1 0.6449363763346619 on epoch=53
06/02/2022 13:09:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.29 on epoch=54
06/02/2022 13:09:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=54
06/02/2022 13:09:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=55
06/02/2022 13:09:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=56
06/02/2022 13:09:14 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=57
06/02/2022 13:09:21 - INFO - __main__ - Global step 800 Train loss 0.24 Classification-F1 0.7327149498241562 on epoch=57
06/02/2022 13:09:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6741523236168558 -> 0.7327149498241562 on epoch=57, global_step=800
06/02/2022 13:09:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=57
06/02/2022 13:09:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=58
06/02/2022 13:09:29 - INFO - __main__ - Step 830 Global step 830 Train loss 0.23 on epoch=59
06/02/2022 13:09:31 - INFO - __main__ - Step 840 Global step 840 Train loss 0.21 on epoch=59
06/02/2022 13:09:34 - INFO - __main__ - Step 850 Global step 850 Train loss 0.21 on epoch=60
06/02/2022 13:09:40 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.7253954530928947 on epoch=60
06/02/2022 13:09:43 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=61
06/02/2022 13:09:45 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=62
06/02/2022 13:09:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=62
06/02/2022 13:09:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.22 on epoch=63
06/02/2022 13:09:53 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=64
06/02/2022 13:10:00 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.7039578824826966 on epoch=64
06/02/2022 13:10:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=64
06/02/2022 13:10:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=65
06/02/2022 13:10:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=66
06/02/2022 13:10:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=67
06/02/2022 13:10:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=67
06/02/2022 13:10:19 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.716197560403541 on epoch=67
06/02/2022 13:10:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=68
06/02/2022 13:10:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=69
06/02/2022 13:10:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=69
06/02/2022 13:10:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=70
06/02/2022 13:10:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=71
06/02/2022 13:10:39 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.7356458960254026 on epoch=71
06/02/2022 13:10:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7327149498241562 -> 0.7356458960254026 on epoch=71, global_step=1000
06/02/2022 13:10:41 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=72
06/02/2022 13:10:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=72
06/02/2022 13:10:46 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=73
06/02/2022 13:10:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=74
06/02/2022 13:10:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=74
06/02/2022 13:10:58 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.7485867609141835 on epoch=74
06/02/2022 13:10:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7356458960254026 -> 0.7485867609141835 on epoch=74, global_step=1050
06/02/2022 13:11:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=75
06/02/2022 13:11:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=76
06/02/2022 13:11:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=77
06/02/2022 13:11:08 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=77
06/02/2022 13:11:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=78
06/02/2022 13:11:18 - INFO - __main__ - Global step 1100 Train loss 0.16 Classification-F1 0.7365108194264773 on epoch=78
06/02/2022 13:11:20 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=79
06/02/2022 13:11:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=79
06/02/2022 13:11:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=80
06/02/2022 13:11:28 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=81
06/02/2022 13:11:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=82
06/02/2022 13:11:37 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.7987807453973245 on epoch=82
06/02/2022 13:11:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7485867609141835 -> 0.7987807453973245 on epoch=82, global_step=1150
06/02/2022 13:11:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=82
06/02/2022 13:11:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=83
06/02/2022 13:11:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=84
06/02/2022 13:11:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/02/2022 13:11:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=85
06/02/2022 13:11:57 - INFO - __main__ - Global step 1200 Train loss 0.16 Classification-F1 0.8025873120122401 on epoch=85
06/02/2022 13:11:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7987807453973245 -> 0.8025873120122401 on epoch=85, global_step=1200
06/02/2022 13:11:59 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=86
06/02/2022 13:12:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=87
06/02/2022 13:12:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
06/02/2022 13:12:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=88
06/02/2022 13:12:09 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
06/02/2022 13:12:16 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.8025873120122401 on epoch=89
06/02/2022 13:12:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=89
06/02/2022 13:12:21 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=90
06/02/2022 13:12:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=91
06/02/2022 13:12:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
06/02/2022 13:12:29 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
06/02/2022 13:12:36 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.7560875390031969 on epoch=92
06/02/2022 13:12:39 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=93
06/02/2022 13:12:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=94
06/02/2022 13:12:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=94
06/02/2022 13:12:46 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.17 on epoch=95
06/02/2022 13:12:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.19 on epoch=96
06/02/2022 13:12:56 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.8025873120122401 on epoch=96
06/02/2022 13:12:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=97
06/02/2022 13:13:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
06/02/2022 13:13:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=98
06/02/2022 13:13:06 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=99
06/02/2022 13:13:08 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=99
06/02/2022 13:13:15 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.8508550796190657 on epoch=99
06/02/2022 13:13:15 - INFO - __main__ - Saving model with best Classification-F1: 0.8025873120122401 -> 0.8508550796190657 on epoch=99, global_step=1400
06/02/2022 13:13:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=100
06/02/2022 13:13:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=101
06/02/2022 13:13:23 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
06/02/2022 13:13:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=102
06/02/2022 13:13:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=103
06/02/2022 13:13:34 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.9055340158107938 on epoch=103
06/02/2022 13:13:34 - INFO - __main__ - Saving model with best Classification-F1: 0.8508550796190657 -> 0.9055340158107938 on epoch=103, global_step=1450
06/02/2022 13:13:37 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.14 on epoch=104
06/02/2022 13:13:39 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
06/02/2022 13:13:42 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/02/2022 13:13:44 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.16 on epoch=106
06/02/2022 13:13:47 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=107
06/02/2022 13:13:54 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.9097292892280786 on epoch=107
06/02/2022 13:13:54 - INFO - __main__ - Saving model with best Classification-F1: 0.9055340158107938 -> 0.9097292892280786 on epoch=107, global_step=1500
06/02/2022 13:13:56 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=107
06/02/2022 13:13:59 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.17 on epoch=108
06/02/2022 13:14:01 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=109
06/02/2022 13:14:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=109
06/02/2022 13:14:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.20 on epoch=110
06/02/2022 13:14:13 - INFO - __main__ - Global step 1550 Train loss 0.14 Classification-F1 0.9097292892280786 on epoch=110
06/02/2022 13:14:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=111
06/02/2022 13:14:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=112
06/02/2022 13:14:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.14 on epoch=112
06/02/2022 13:14:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=113
06/02/2022 13:14:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
06/02/2022 13:14:33 - INFO - __main__ - Global step 1600 Train loss 0.11 Classification-F1 0.9097292892280786 on epoch=114
06/02/2022 13:14:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=114
06/02/2022 13:14:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=115
06/02/2022 13:14:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/02/2022 13:14:43 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=117
06/02/2022 13:14:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.14 on epoch=117
06/02/2022 13:14:53 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.9097292892280786 on epoch=117
06/02/2022 13:14:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=118
06/02/2022 13:14:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=119
06/02/2022 13:15:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=119
06/02/2022 13:15:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=120
06/02/2022 13:15:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
06/02/2022 13:15:13 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.8547651480452632 on epoch=121
06/02/2022 13:15:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=122
06/02/2022 13:15:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=122
06/02/2022 13:15:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=123
06/02/2022 13:15:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=124
06/02/2022 13:15:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/02/2022 13:15:32 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.8547651480452632 on epoch=124
06/02/2022 13:15:35 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=125
06/02/2022 13:15:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
06/02/2022 13:15:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=127
06/02/2022 13:15:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/02/2022 13:15:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=128
06/02/2022 13:15:52 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.8508588980452632 on epoch=128
06/02/2022 13:15:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
06/02/2022 13:15:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/02/2022 13:16:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
06/02/2022 13:16:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=131
06/02/2022 13:16:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
06/02/2022 13:16:12 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.8547651480452632 on epoch=132
06/02/2022 13:16:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/02/2022 13:16:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
06/02/2022 13:16:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
06/02/2022 13:16:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=134
06/02/2022 13:16:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
06/02/2022 13:16:32 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.8547651480452632 on epoch=135
06/02/2022 13:16:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.13 on epoch=136
06/02/2022 13:16:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=137
06/02/2022 13:16:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=137
06/02/2022 13:16:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=138
06/02/2022 13:16:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/02/2022 13:16:52 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.8508588980452632 on epoch=139
06/02/2022 13:16:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.12 on epoch=139
06/02/2022 13:16:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/02/2022 13:16:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=141
06/02/2022 13:17:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=142
06/02/2022 13:17:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=142
06/02/2022 13:17:11 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.7989108414240048 on epoch=142
06/02/2022 13:17:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/02/2022 13:17:16 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=144
06/02/2022 13:17:18 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=144
06/02/2022 13:17:21 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=145
06/02/2022 13:17:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=146
06/02/2022 13:17:30 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.8508588980452632 on epoch=146
06/02/2022 13:17:33 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
06/02/2022 13:17:35 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=147
06/02/2022 13:17:37 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=148
06/02/2022 13:17:40 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=149
06/02/2022 13:17:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/02/2022 13:17:50 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.9096104538151256 on epoch=149
06/02/2022 13:17:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=150
06/02/2022 13:17:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/02/2022 13:17:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=152
06/02/2022 13:17:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
06/02/2022 13:18:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=153
06/02/2022 13:18:09 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.901408989456166 on epoch=153
06/02/2022 13:18:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/02/2022 13:18:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/02/2022 13:18:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/02/2022 13:18:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
06/02/2022 13:18:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/02/2022 13:18:28 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.905595302299974 on epoch=157
06/02/2022 13:18:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/02/2022 13:18:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=158
06/02/2022 13:18:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=159
06/02/2022 13:18:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/02/2022 13:18:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
06/02/2022 13:18:48 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.9097578959786967 on epoch=160
06/02/2022 13:18:48 - INFO - __main__ - Saving model with best Classification-F1: 0.9097292892280786 -> 0.9097578959786967 on epoch=160, global_step=2250
06/02/2022 13:18:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=161
06/02/2022 13:18:52 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/02/2022 13:18:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/02/2022 13:18:57 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.08 on epoch=163
06/02/2022 13:19:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
06/02/2022 13:19:07 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.8547919668739677 on epoch=164
06/02/2022 13:19:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=164
06/02/2022 13:19:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/02/2022 13:19:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
06/02/2022 13:19:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/02/2022 13:19:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
06/02/2022 13:19:27 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.9097619689666406 on epoch=167
06/02/2022 13:19:27 - INFO - __main__ - Saving model with best Classification-F1: 0.9097578959786967 -> 0.9097619689666406 on epoch=167, global_step=2350
06/02/2022 13:19:29 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=168
06/02/2022 13:19:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=169
06/02/2022 13:19:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/02/2022 13:19:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
06/02/2022 13:19:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=171
06/02/2022 13:19:47 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.9097619689666406 on epoch=171
06/02/2022 13:19:50 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/02/2022 13:19:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=172
06/02/2022 13:19:54 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.09 on epoch=173
06/02/2022 13:19:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.16 on epoch=174
06/02/2022 13:19:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=174
06/02/2022 13:20:07 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.905595302299974 on epoch=174
06/02/2022 13:20:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/02/2022 13:20:12 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/02/2022 13:20:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/02/2022 13:20:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/02/2022 13:20:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/02/2022 13:20:28 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9097333622160229 on epoch=178
06/02/2022 13:20:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
06/02/2022 13:20:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/02/2022 13:20:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/02/2022 13:20:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/02/2022 13:20:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/02/2022 13:20:48 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9055756561228329 on epoch=182
06/02/2022 13:20:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/02/2022 13:20:53 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/02/2022 13:20:55 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=184
06/02/2022 13:20:58 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=184
06/02/2022 13:21:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.08 on epoch=185
06/02/2022 13:21:09 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.9055756561228329 on epoch=185
06/02/2022 13:21:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/02/2022 13:21:14 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/02/2022 13:21:16 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/02/2022 13:21:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
06/02/2022 13:21:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/02/2022 13:21:30 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7952445180721697 on epoch=189
06/02/2022 13:21:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.12 on epoch=189
06/02/2022 13:21:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/02/2022 13:21:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/02/2022 13:21:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/02/2022 13:21:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/02/2022 13:21:50 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.8531577486199758 on epoch=192
06/02/2022 13:21:53 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=193
06/02/2022 13:21:55 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.08 on epoch=194
06/02/2022 13:21:58 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/02/2022 13:22:00 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/02/2022 13:22:03 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
06/02/2022 13:22:11 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.9122140762463343 on epoch=196
06/02/2022 13:22:11 - INFO - __main__ - Saving model with best Classification-F1: 0.9097619689666406 -> 0.9122140762463343 on epoch=196, global_step=2750
06/02/2022 13:22:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
06/02/2022 13:22:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
06/02/2022 13:22:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/02/2022 13:22:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/02/2022 13:22:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
06/02/2022 13:22:31 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8047797711459951 on epoch=199
06/02/2022 13:22:34 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/02/2022 13:22:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=201
06/02/2022 13:22:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/02/2022 13:22:41 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/02/2022 13:22:43 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/02/2022 13:22:52 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.8570946358748779 on epoch=203
06/02/2022 13:22:54 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=204
06/02/2022 13:22:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=204
06/02/2022 13:22:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/02/2022 13:23:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=206
06/02/2022 13:23:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=207
06/02/2022 13:23:12 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.9122140762463343 on epoch=207
06/02/2022 13:23:14 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=207
06/02/2022 13:23:17 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/02/2022 13:23:19 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=209
06/02/2022 13:23:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/02/2022 13:23:24 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/02/2022 13:23:33 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.9122140762463343 on epoch=210
06/02/2022 13:23:35 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
06/02/2022 13:23:38 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/02/2022 13:23:40 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=212
06/02/2022 13:23:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/02/2022 13:23:45 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.07 on epoch=214
06/02/2022 13:23:46 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 13:23:46 - INFO - __main__ - Printing 3 examples
06/02/2022 13:23:46 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 13:23:46 - INFO - __main__ - ['Plant']
06/02/2022 13:23:46 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 13:23:46 - INFO - __main__ - ['Plant']
06/02/2022 13:23:46 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 13:23:46 - INFO - __main__ - ['Plant']
06/02/2022 13:23:46 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:23:47 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:23:47 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 13:23:47 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 13:23:47 - INFO - __main__ - Printing 3 examples
06/02/2022 13:23:47 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 13:23:47 - INFO - __main__ - ['Plant']
06/02/2022 13:23:47 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 13:23:47 - INFO - __main__ - ['Plant']
06/02/2022 13:23:47 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 13:23:47 - INFO - __main__ - ['Plant']
06/02/2022 13:23:47 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:23:47 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:23:47 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 13:23:53 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8492821358748779 on epoch=214
06/02/2022 13:23:53 - INFO - __main__ - save last model!
06/02/2022 13:23:53 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 13:23:53 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 13:23:53 - INFO - __main__ - Printing 3 examples
06/02/2022 13:23:53 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 13:23:53 - INFO - __main__ - ['Animal']
06/02/2022 13:23:53 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 13:23:53 - INFO - __main__ - ['Animal']
06/02/2022 13:23:53 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 13:23:53 - INFO - __main__ - ['Village']
06/02/2022 13:23:53 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:23:55 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:23:58 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 13:24:03 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 13:24:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 13:24:03 - INFO - __main__ - Starting training!
06/02/2022 13:26:32 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
06/02/2022 13:26:32 - INFO - __main__ - Classification-F1 on test data: 0.5431
06/02/2022 13:26:32 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.9122140762463343, test_performance=0.5431132854851769
06/02/2022 13:26:32 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
06/02/2022 13:26:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 13:26:33 - INFO - __main__ - Printing 3 examples
06/02/2022 13:26:33 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 13:26:33 - INFO - __main__ - ['Plant']
06/02/2022 13:26:33 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 13:26:33 - INFO - __main__ - ['Plant']
06/02/2022 13:26:33 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 13:26:33 - INFO - __main__ - ['Plant']
06/02/2022 13:26:33 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:26:34 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:26:34 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 13:26:34 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 13:26:34 - INFO - __main__ - Printing 3 examples
06/02/2022 13:26:34 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 13:26:34 - INFO - __main__ - ['Plant']
06/02/2022 13:26:34 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 13:26:34 - INFO - __main__ - ['Plant']
06/02/2022 13:26:34 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 13:26:34 - INFO - __main__ - ['Plant']
06/02/2022 13:26:34 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:26:34 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:26:34 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 13:26:51 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 13:26:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 13:26:52 - INFO - __main__ - Starting training!
06/02/2022 13:26:55 - INFO - __main__ - Step 10 Global step 10 Train loss 5.88 on epoch=0
06/02/2022 13:26:58 - INFO - __main__ - Step 20 Global step 20 Train loss 4.64 on epoch=1
06/02/2022 13:27:00 - INFO - __main__ - Step 30 Global step 30 Train loss 4.31 on epoch=2
06/02/2022 13:27:02 - INFO - __main__ - Step 40 Global step 40 Train loss 3.70 on epoch=2
06/02/2022 13:27:05 - INFO - __main__ - Step 50 Global step 50 Train loss 3.45 on epoch=3
06/02/2022 13:27:09 - INFO - __main__ - Global step 50 Train loss 4.39 Classification-F1 0.05994427878678353 on epoch=3
06/02/2022 13:27:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05994427878678353 on epoch=3, global_step=50
06/02/2022 13:27:12 - INFO - __main__ - Step 60 Global step 60 Train loss 3.26 on epoch=4
06/02/2022 13:27:14 - INFO - __main__ - Step 70 Global step 70 Train loss 3.05 on epoch=4
06/02/2022 13:27:16 - INFO - __main__ - Step 80 Global step 80 Train loss 2.62 on epoch=5
06/02/2022 13:27:19 - INFO - __main__ - Step 90 Global step 90 Train loss 2.81 on epoch=6
06/02/2022 13:27:21 - INFO - __main__ - Step 100 Global step 100 Train loss 2.64 on epoch=7
06/02/2022 13:27:26 - INFO - __main__ - Global step 100 Train loss 2.88 Classification-F1 0.09962618917842798 on epoch=7
06/02/2022 13:27:26 - INFO - __main__ - Saving model with best Classification-F1: 0.05994427878678353 -> 0.09962618917842798 on epoch=7, global_step=100
06/02/2022 13:27:28 - INFO - __main__ - Step 110 Global step 110 Train loss 2.19 on epoch=7
06/02/2022 13:27:31 - INFO - __main__ - Step 120 Global step 120 Train loss 2.26 on epoch=8
06/02/2022 13:27:33 - INFO - __main__ - Step 130 Global step 130 Train loss 2.17 on epoch=9
06/02/2022 13:27:35 - INFO - __main__ - Step 140 Global step 140 Train loss 2.13 on epoch=9
06/02/2022 13:27:38 - INFO - __main__ - Step 150 Global step 150 Train loss 1.84 on epoch=10
06/02/2022 13:27:42 - INFO - __main__ - Global step 150 Train loss 2.12 Classification-F1 0.12477000671039244 on epoch=10
06/02/2022 13:27:42 - INFO - __main__ - Saving model with best Classification-F1: 0.09962618917842798 -> 0.12477000671039244 on epoch=10, global_step=150
06/02/2022 13:27:45 - INFO - __main__ - Step 160 Global step 160 Train loss 2.01 on epoch=11
06/02/2022 13:27:47 - INFO - __main__ - Step 170 Global step 170 Train loss 1.92 on epoch=12
06/02/2022 13:27:50 - INFO - __main__ - Step 180 Global step 180 Train loss 1.69 on epoch=12
06/02/2022 13:27:52 - INFO - __main__ - Step 190 Global step 190 Train loss 2.03 on epoch=13
06/02/2022 13:27:54 - INFO - __main__ - Step 200 Global step 200 Train loss 1.67 on epoch=14
06/02/2022 13:27:59 - INFO - __main__ - Global step 200 Train loss 1.86 Classification-F1 0.1528304290816192 on epoch=14
06/02/2022 13:27:59 - INFO - __main__ - Saving model with best Classification-F1: 0.12477000671039244 -> 0.1528304290816192 on epoch=14, global_step=200
06/02/2022 13:28:02 - INFO - __main__ - Step 210 Global step 210 Train loss 1.72 on epoch=14
06/02/2022 13:28:04 - INFO - __main__ - Step 220 Global step 220 Train loss 1.57 on epoch=15
06/02/2022 13:28:06 - INFO - __main__ - Step 230 Global step 230 Train loss 1.69 on epoch=16
06/02/2022 13:28:09 - INFO - __main__ - Step 240 Global step 240 Train loss 1.50 on epoch=17
06/02/2022 13:28:11 - INFO - __main__ - Step 250 Global step 250 Train loss 1.42 on epoch=17
06/02/2022 13:28:16 - INFO - __main__ - Global step 250 Train loss 1.58 Classification-F1 0.154241850349971 on epoch=17
06/02/2022 13:28:16 - INFO - __main__ - Saving model with best Classification-F1: 0.1528304290816192 -> 0.154241850349971 on epoch=17, global_step=250
06/02/2022 13:28:19 - INFO - __main__ - Step 260 Global step 260 Train loss 1.54 on epoch=18
06/02/2022 13:28:21 - INFO - __main__ - Step 270 Global step 270 Train loss 1.42 on epoch=19
06/02/2022 13:28:23 - INFO - __main__ - Step 280 Global step 280 Train loss 1.42 on epoch=19
06/02/2022 13:28:26 - INFO - __main__ - Step 290 Global step 290 Train loss 1.24 on epoch=20
06/02/2022 13:28:28 - INFO - __main__ - Step 300 Global step 300 Train loss 1.35 on epoch=21
06/02/2022 13:28:33 - INFO - __main__ - Global step 300 Train loss 1.39 Classification-F1 0.18861572177080196 on epoch=21
06/02/2022 13:28:33 - INFO - __main__ - Saving model with best Classification-F1: 0.154241850349971 -> 0.18861572177080196 on epoch=21, global_step=300
06/02/2022 13:28:36 - INFO - __main__ - Step 310 Global step 310 Train loss 1.40 on epoch=22
06/02/2022 13:28:38 - INFO - __main__ - Step 320 Global step 320 Train loss 1.02 on epoch=22
06/02/2022 13:28:40 - INFO - __main__ - Step 330 Global step 330 Train loss 1.29 on epoch=23
06/02/2022 13:28:43 - INFO - __main__ - Step 340 Global step 340 Train loss 1.15 on epoch=24
06/02/2022 13:28:45 - INFO - __main__ - Step 350 Global step 350 Train loss 1.07 on epoch=24
06/02/2022 13:28:51 - INFO - __main__ - Global step 350 Train loss 1.19 Classification-F1 0.2868168061666514 on epoch=24
06/02/2022 13:28:51 - INFO - __main__ - Saving model with best Classification-F1: 0.18861572177080196 -> 0.2868168061666514 on epoch=24, global_step=350
06/02/2022 13:28:53 - INFO - __main__ - Step 360 Global step 360 Train loss 1.04 on epoch=25
06/02/2022 13:28:55 - INFO - __main__ - Step 370 Global step 370 Train loss 1.07 on epoch=26
06/02/2022 13:28:58 - INFO - __main__ - Step 380 Global step 380 Train loss 1.09 on epoch=27
06/02/2022 13:29:00 - INFO - __main__ - Step 390 Global step 390 Train loss 1.07 on epoch=27
06/02/2022 13:29:03 - INFO - __main__ - Step 400 Global step 400 Train loss 1.00 on epoch=28
06/02/2022 13:29:08 - INFO - __main__ - Global step 400 Train loss 1.05 Classification-F1 0.3138369227872271 on epoch=28
06/02/2022 13:29:08 - INFO - __main__ - Saving model with best Classification-F1: 0.2868168061666514 -> 0.3138369227872271 on epoch=28, global_step=400
06/02/2022 13:29:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.90 on epoch=29
06/02/2022 13:29:13 - INFO - __main__ - Step 420 Global step 420 Train loss 0.88 on epoch=29
06/02/2022 13:29:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.81 on epoch=30
06/02/2022 13:29:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.84 on epoch=31
06/02/2022 13:29:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.76 on epoch=32
06/02/2022 13:29:26 - INFO - __main__ - Global step 450 Train loss 0.84 Classification-F1 0.4048265910334876 on epoch=32
06/02/2022 13:29:26 - INFO - __main__ - Saving model with best Classification-F1: 0.3138369227872271 -> 0.4048265910334876 on epoch=32, global_step=450
06/02/2022 13:29:28 - INFO - __main__ - Step 460 Global step 460 Train loss 0.75 on epoch=32
06/02/2022 13:29:30 - INFO - __main__ - Step 470 Global step 470 Train loss 0.84 on epoch=33
06/02/2022 13:29:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.74 on epoch=34
06/02/2022 13:29:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.68 on epoch=34
06/02/2022 13:29:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.61 on epoch=35
06/02/2022 13:29:43 - INFO - __main__ - Global step 500 Train loss 0.73 Classification-F1 0.48476549886894715 on epoch=35
06/02/2022 13:29:43 - INFO - __main__ - Saving model with best Classification-F1: 0.4048265910334876 -> 0.48476549886894715 on epoch=35, global_step=500
06/02/2022 13:29:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.66 on epoch=36
06/02/2022 13:29:48 - INFO - __main__ - Step 520 Global step 520 Train loss 0.71 on epoch=37
06/02/2022 13:29:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.65 on epoch=37
06/02/2022 13:29:53 - INFO - __main__ - Step 540 Global step 540 Train loss 0.63 on epoch=38
06/02/2022 13:29:55 - INFO - __main__ - Step 550 Global step 550 Train loss 0.69 on epoch=39
06/02/2022 13:30:02 - INFO - __main__ - Global step 550 Train loss 0.67 Classification-F1 0.45973853073603294 on epoch=39
06/02/2022 13:30:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.58 on epoch=39
06/02/2022 13:30:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.66 on epoch=40
06/02/2022 13:30:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.55 on epoch=41
06/02/2022 13:30:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.56 on epoch=42
06/02/2022 13:30:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.54 on epoch=42
06/02/2022 13:30:20 - INFO - __main__ - Global step 600 Train loss 0.58 Classification-F1 0.43090971824286617 on epoch=42
06/02/2022 13:30:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.50 on epoch=43
06/02/2022 13:30:25 - INFO - __main__ - Step 620 Global step 620 Train loss 0.48 on epoch=44
06/02/2022 13:30:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.43 on epoch=44
06/02/2022 13:30:30 - INFO - __main__ - Step 640 Global step 640 Train loss 0.45 on epoch=45
06/02/2022 13:30:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.44 on epoch=46
06/02/2022 13:30:39 - INFO - __main__ - Global step 650 Train loss 0.46 Classification-F1 0.6346555760538617 on epoch=46
06/02/2022 13:30:39 - INFO - __main__ - Saving model with best Classification-F1: 0.48476549886894715 -> 0.6346555760538617 on epoch=46, global_step=650
06/02/2022 13:30:41 - INFO - __main__ - Step 660 Global step 660 Train loss 0.45 on epoch=47
06/02/2022 13:30:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.47 on epoch=47
06/02/2022 13:30:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.41 on epoch=48
06/02/2022 13:30:49 - INFO - __main__ - Step 690 Global step 690 Train loss 0.39 on epoch=49
06/02/2022 13:30:51 - INFO - __main__ - Step 700 Global step 700 Train loss 0.43 on epoch=49
06/02/2022 13:30:58 - INFO - __main__ - Global step 700 Train loss 0.43 Classification-F1 0.6035988210934385 on epoch=49
06/02/2022 13:31:00 - INFO - __main__ - Step 710 Global step 710 Train loss 0.42 on epoch=50
06/02/2022 13:31:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.47 on epoch=51
06/02/2022 13:31:05 - INFO - __main__ - Step 730 Global step 730 Train loss 0.36 on epoch=52
06/02/2022 13:31:07 - INFO - __main__ - Step 740 Global step 740 Train loss 0.34 on epoch=52
06/02/2022 13:31:10 - INFO - __main__ - Step 750 Global step 750 Train loss 0.48 on epoch=53
06/02/2022 13:31:17 - INFO - __main__ - Global step 750 Train loss 0.41 Classification-F1 0.5515840914189178 on epoch=53
06/02/2022 13:31:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.41 on epoch=54
06/02/2022 13:31:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.33 on epoch=54
06/02/2022 13:31:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.31 on epoch=55
06/02/2022 13:31:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.27 on epoch=56
06/02/2022 13:31:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.39 on epoch=57
06/02/2022 13:31:35 - INFO - __main__ - Global step 800 Train loss 0.34 Classification-F1 0.545933562710104 on epoch=57
06/02/2022 13:31:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.37 on epoch=57
06/02/2022 13:31:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.31 on epoch=58
06/02/2022 13:31:42 - INFO - __main__ - Step 830 Global step 830 Train loss 0.34 on epoch=59
06/02/2022 13:31:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.28 on epoch=59
06/02/2022 13:31:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.31 on epoch=60
06/02/2022 13:31:54 - INFO - __main__ - Global step 850 Train loss 0.32 Classification-F1 0.6062714946311099 on epoch=60
06/02/2022 13:31:56 - INFO - __main__ - Step 860 Global step 860 Train loss 0.35 on epoch=61
06/02/2022 13:31:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.27 on epoch=62
06/02/2022 13:32:01 - INFO - __main__ - Step 880 Global step 880 Train loss 0.35 on epoch=62
06/02/2022 13:32:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.39 on epoch=63
06/02/2022 13:32:06 - INFO - __main__ - Step 900 Global step 900 Train loss 0.38 on epoch=64
06/02/2022 13:32:12 - INFO - __main__ - Global step 900 Train loss 0.35 Classification-F1 0.601607794452552 on epoch=64
06/02/2022 13:32:15 - INFO - __main__ - Step 910 Global step 910 Train loss 0.36 on epoch=64
06/02/2022 13:32:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.28 on epoch=65
06/02/2022 13:32:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.33 on epoch=66
06/02/2022 13:32:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.27 on epoch=67
06/02/2022 13:32:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.28 on epoch=67
06/02/2022 13:32:31 - INFO - __main__ - Global step 950 Train loss 0.30 Classification-F1 0.7478312074389467 on epoch=67
06/02/2022 13:32:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6346555760538617 -> 0.7478312074389467 on epoch=67, global_step=950
06/02/2022 13:32:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.24 on epoch=68
06/02/2022 13:32:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.27 on epoch=69
06/02/2022 13:32:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.28 on epoch=69
06/02/2022 13:32:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.23 on epoch=70
06/02/2022 13:32:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.27 on epoch=71
06/02/2022 13:32:50 - INFO - __main__ - Global step 1000 Train loss 0.26 Classification-F1 0.6643779711130087 on epoch=71
06/02/2022 13:32:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.32 on epoch=72
06/02/2022 13:32:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.29 on epoch=72
06/02/2022 13:32:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.26 on epoch=73
06/02/2022 13:33:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.25 on epoch=74
06/02/2022 13:33:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.24 on epoch=74
06/02/2022 13:33:09 - INFO - __main__ - Global step 1050 Train loss 0.27 Classification-F1 0.7111492932584996 on epoch=74
06/02/2022 13:33:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.31 on epoch=75
06/02/2022 13:33:14 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.30 on epoch=76
06/02/2022 13:33:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.20 on epoch=77
06/02/2022 13:33:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=77
06/02/2022 13:33:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.26 on epoch=78
06/02/2022 13:33:28 - INFO - __main__ - Global step 1100 Train loss 0.25 Classification-F1 0.6669024274150541 on epoch=78
06/02/2022 13:33:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.25 on epoch=79
06/02/2022 13:33:32 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.16 on epoch=79
06/02/2022 13:33:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.30 on epoch=80
06/02/2022 13:33:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=81
06/02/2022 13:33:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.24 on epoch=82
06/02/2022 13:33:47 - INFO - __main__ - Global step 1150 Train loss 0.24 Classification-F1 0.742658243057695 on epoch=82
06/02/2022 13:33:49 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.29 on epoch=82
06/02/2022 13:33:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.24 on epoch=83
06/02/2022 13:33:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.22 on epoch=84
06/02/2022 13:33:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=84
06/02/2022 13:33:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.16 on epoch=85
06/02/2022 13:34:06 - INFO - __main__ - Global step 1200 Train loss 0.22 Classification-F1 0.7132175953268016 on epoch=85
06/02/2022 13:34:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.22 on epoch=86
06/02/2022 13:34:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=87
06/02/2022 13:34:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.19 on epoch=87
06/02/2022 13:34:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=88
06/02/2022 13:34:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.24 on epoch=89
06/02/2022 13:34:25 - INFO - __main__ - Global step 1250 Train loss 0.19 Classification-F1 0.7113188071376908 on epoch=89
06/02/2022 13:34:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.19 on epoch=89
06/02/2022 13:34:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.22 on epoch=90
06/02/2022 13:34:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=91
06/02/2022 13:34:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=92
06/02/2022 13:34:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.20 on epoch=92
06/02/2022 13:34:44 - INFO - __main__ - Global step 1300 Train loss 0.18 Classification-F1 0.7113188071376909 on epoch=92
06/02/2022 13:34:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.22 on epoch=93
06/02/2022 13:34:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.21 on epoch=94
06/02/2022 13:34:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=94
06/02/2022 13:34:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.16 on epoch=95
06/02/2022 13:34:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.23 on epoch=96
06/02/2022 13:35:03 - INFO - __main__ - Global step 1350 Train loss 0.19 Classification-F1 0.663591686068817 on epoch=96
06/02/2022 13:35:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=97
06/02/2022 13:35:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.20 on epoch=97
06/02/2022 13:35:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=98
06/02/2022 13:35:13 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.18 on epoch=99
06/02/2022 13:35:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.21 on epoch=99
06/02/2022 13:35:23 - INFO - __main__ - Global step 1400 Train loss 0.18 Classification-F1 0.7176680134868972 on epoch=99
06/02/2022 13:35:25 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.20 on epoch=100
06/02/2022 13:35:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.17 on epoch=101
06/02/2022 13:35:30 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.16 on epoch=102
06/02/2022 13:35:33 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.23 on epoch=102
06/02/2022 13:35:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.22 on epoch=103
06/02/2022 13:35:42 - INFO - __main__ - Global step 1450 Train loss 0.19 Classification-F1 0.7234276063432643 on epoch=103
06/02/2022 13:35:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=104
06/02/2022 13:35:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=104
06/02/2022 13:35:49 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.16 on epoch=105
06/02/2022 13:35:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.20 on epoch=106
06/02/2022 13:35:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=107
06/02/2022 13:36:02 - INFO - __main__ - Global step 1500 Train loss 0.14 Classification-F1 0.7350998846822093 on epoch=107
06/02/2022 13:36:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.19 on epoch=107
06/02/2022 13:36:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.21 on epoch=108
06/02/2022 13:36:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=109
06/02/2022 13:36:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=109
06/02/2022 13:36:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=110
06/02/2022 13:36:21 - INFO - __main__ - Global step 1550 Train loss 0.15 Classification-F1 0.7207192036348616 on epoch=110
06/02/2022 13:36:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.19 on epoch=111
06/02/2022 13:36:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.13 on epoch=112
06/02/2022 13:36:29 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.17 on epoch=112
06/02/2022 13:36:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.17 on epoch=113
06/02/2022 13:36:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.18 on epoch=114
06/02/2022 13:36:40 - INFO - __main__ - Global step 1600 Train loss 0.17 Classification-F1 0.7454073076057793 on epoch=114
06/02/2022 13:36:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.12 on epoch=114
06/02/2022 13:36:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=115
06/02/2022 13:36:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=116
06/02/2022 13:36:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=117
06/02/2022 13:36:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.17 on epoch=117
06/02/2022 13:37:00 - INFO - __main__ - Global step 1650 Train loss 0.13 Classification-F1 0.7402972361161199 on epoch=117
06/02/2022 13:37:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=118
06/02/2022 13:37:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=119
06/02/2022 13:37:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.17 on epoch=119
06/02/2022 13:37:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.20 on epoch=120
06/02/2022 13:37:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=121
06/02/2022 13:37:19 - INFO - __main__ - Global step 1700 Train loss 0.15 Classification-F1 0.7426633330280811 on epoch=121
06/02/2022 13:37:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=122
06/02/2022 13:37:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.14 on epoch=122
06/02/2022 13:37:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.16 on epoch=123
06/02/2022 13:37:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=124
06/02/2022 13:37:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=124
06/02/2022 13:37:38 - INFO - __main__ - Global step 1750 Train loss 0.13 Classification-F1 0.7925410081231045 on epoch=124
06/02/2022 13:37:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7478312074389467 -> 0.7925410081231045 on epoch=124, global_step=1750
06/02/2022 13:37:41 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.13 on epoch=125
06/02/2022 13:37:43 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.17 on epoch=126
06/02/2022 13:37:46 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=127
06/02/2022 13:37:48 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.16 on epoch=127
06/02/2022 13:37:51 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=128
06/02/2022 13:37:58 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.754044116270119 on epoch=128
06/02/2022 13:38:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=129
06/02/2022 13:38:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/02/2022 13:38:05 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.13 on epoch=130
06/02/2022 13:38:08 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.20 on epoch=131
06/02/2022 13:38:10 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=132
06/02/2022 13:38:17 - INFO - __main__ - Global step 1850 Train loss 0.12 Classification-F1 0.7949394449088458 on epoch=132
06/02/2022 13:38:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7925410081231045 -> 0.7949394449088458 on epoch=132, global_step=1850
06/02/2022 13:38:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.13 on epoch=132
06/02/2022 13:38:22 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=133
06/02/2022 13:38:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.14 on epoch=134
06/02/2022 13:38:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.10 on epoch=134
06/02/2022 13:38:30 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=135
06/02/2022 13:38:37 - INFO - __main__ - Global step 1900 Train loss 0.11 Classification-F1 0.7948591767698735 on epoch=135
06/02/2022 13:38:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.10 on epoch=136
06/02/2022 13:38:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.11 on epoch=137
06/02/2022 13:38:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
06/02/2022 13:38:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=138
06/02/2022 13:38:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=139
06/02/2022 13:38:56 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.7988053320344872 on epoch=139
06/02/2022 13:38:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7949394449088458 -> 0.7988053320344872 on epoch=139, global_step=1950
06/02/2022 13:38:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
06/02/2022 13:39:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=140
06/02/2022 13:39:04 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.11 on epoch=141
06/02/2022 13:39:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.10 on epoch=142
06/02/2022 13:39:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.16 on epoch=142
06/02/2022 13:39:16 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.8468367258927032 on epoch=142
06/02/2022 13:39:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7988053320344872 -> 0.8468367258927032 on epoch=142, global_step=2000
06/02/2022 13:39:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.10 on epoch=143
06/02/2022 13:39:21 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=144
06/02/2022 13:39:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.11 on epoch=144
06/02/2022 13:39:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=145
06/02/2022 13:39:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.15 on epoch=146
06/02/2022 13:39:35 - INFO - __main__ - Global step 2050 Train loss 0.11 Classification-F1 0.8468367258927032 on epoch=146
06/02/2022 13:39:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=147
06/02/2022 13:39:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.12 on epoch=147
06/02/2022 13:39:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=148
06/02/2022 13:39:45 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=149
06/02/2022 13:39:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=149
06/02/2022 13:39:55 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.9013911410116345 on epoch=149
06/02/2022 13:39:55 - INFO - __main__ - Saving model with best Classification-F1: 0.8468367258927032 -> 0.9013911410116345 on epoch=149, global_step=2100
06/02/2022 13:39:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.12 on epoch=150
06/02/2022 13:40:00 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.12 on epoch=151
06/02/2022 13:40:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.13 on epoch=152
06/02/2022 13:40:05 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=152
06/02/2022 13:40:08 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=153
06/02/2022 13:40:15 - INFO - __main__ - Global step 2150 Train loss 0.11 Classification-F1 0.9056773849864211 on epoch=153
06/02/2022 13:40:15 - INFO - __main__ - Saving model with best Classification-F1: 0.9013911410116345 -> 0.9056773849864211 on epoch=153, global_step=2150
06/02/2022 13:40:18 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.15 on epoch=154
06/02/2022 13:40:20 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.12 on epoch=154
06/02/2022 13:40:23 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=155
06/02/2022 13:40:25 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=156
06/02/2022 13:40:28 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=157
06/02/2022 13:40:35 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.9097292892280786 on epoch=157
06/02/2022 13:40:35 - INFO - __main__ - Saving model with best Classification-F1: 0.9056773849864211 -> 0.9097292892280786 on epoch=157, global_step=2200
06/02/2022 13:40:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.13 on epoch=157
06/02/2022 13:40:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.12 on epoch=158
06/02/2022 13:40:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.11 on epoch=159
06/02/2022 13:40:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
06/02/2022 13:40:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
06/02/2022 13:40:55 - INFO - __main__ - Global step 2250 Train loss 0.10 Classification-F1 0.8547651480452632 on epoch=160
06/02/2022 13:40:57 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.11 on epoch=161
06/02/2022 13:41:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=162
06/02/2022 13:41:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.10 on epoch=162
06/02/2022 13:41:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.16 on epoch=163
06/02/2022 13:41:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.12 on epoch=164
06/02/2022 13:41:15 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.905590487416863 on epoch=164
06/02/2022 13:41:17 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.10 on epoch=164
06/02/2022 13:41:20 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.10 on epoch=165
06/02/2022 13:41:22 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.13 on epoch=166
06/02/2022 13:41:25 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.12 on epoch=167
06/02/2022 13:41:27 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=167
06/02/2022 13:41:35 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.8469488296190657 on epoch=167
06/02/2022 13:41:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
06/02/2022 13:41:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=169
06/02/2022 13:41:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=169
06/02/2022 13:41:45 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=170
06/02/2022 13:41:47 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=171
06/02/2022 13:41:55 - INFO - __main__ - Global step 2400 Train loss 0.09 Classification-F1 0.8508550796190657 on epoch=171
06/02/2022 13:41:57 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
06/02/2022 13:42:00 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
06/02/2022 13:42:02 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
06/02/2022 13:42:04 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.10 on epoch=174
06/02/2022 13:42:07 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.12 on epoch=174
06/02/2022 13:42:15 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.8508550796190657 on epoch=174
06/02/2022 13:42:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.14 on epoch=175
06/02/2022 13:42:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.09 on epoch=176
06/02/2022 13:42:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=177
06/02/2022 13:42:24 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=177
06/02/2022 13:42:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=178
06/02/2022 13:42:34 - INFO - __main__ - Global step 2500 Train loss 0.08 Classification-F1 0.8508550796190657 on epoch=178
06/02/2022 13:42:37 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
06/02/2022 13:42:39 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/02/2022 13:42:42 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.13 on epoch=180
06/02/2022 13:42:44 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.09 on epoch=181
06/02/2022 13:42:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=182
06/02/2022 13:42:54 - INFO - __main__ - Global step 2550 Train loss 0.08 Classification-F1 0.8508550796190657 on epoch=182
06/02/2022 13:42:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=182
06/02/2022 13:42:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=183
06/02/2022 13:43:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=184
06/02/2022 13:43:04 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.10 on epoch=184
06/02/2022 13:43:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.08 on epoch=185
06/02/2022 13:43:14 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.8508550796190657 on epoch=185
06/02/2022 13:43:17 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.12 on epoch=186
06/02/2022 13:43:19 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/02/2022 13:43:22 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/02/2022 13:43:24 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=188
06/02/2022 13:43:27 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.07 on epoch=189
06/02/2022 13:43:34 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.9055864144289193 on epoch=189
06/02/2022 13:43:37 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=189
06/02/2022 13:43:39 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/02/2022 13:43:42 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.12 on epoch=191
06/02/2022 13:43:44 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.08 on epoch=192
06/02/2022 13:43:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=192
06/02/2022 13:43:54 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.8429510953941693 on epoch=192
06/02/2022 13:43:57 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=193
06/02/2022 13:43:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.08 on epoch=194
06/02/2022 13:44:02 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.14 on epoch=194
06/02/2022 13:44:05 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.08 on epoch=195
06/02/2022 13:44:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/02/2022 13:44:15 - INFO - __main__ - Global step 2750 Train loss 0.09 Classification-F1 0.8430547985828976 on epoch=196
06/02/2022 13:44:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.09 on epoch=197
06/02/2022 13:44:21 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/02/2022 13:44:24 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=198
06/02/2022 13:44:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.09 on epoch=199
06/02/2022 13:44:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
06/02/2022 13:44:37 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.9056150211795372 on epoch=199
06/02/2022 13:44:39 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=200
06/02/2022 13:44:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.10 on epoch=201
06/02/2022 13:44:44 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/02/2022 13:44:46 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=202
06/02/2022 13:44:49 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=203
06/02/2022 13:44:57 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.9055864144289193 on epoch=203
06/02/2022 13:45:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=204
06/02/2022 13:45:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.11 on epoch=204
06/02/2022 13:45:05 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.07 on epoch=205
06/02/2022 13:45:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=206
06/02/2022 13:45:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
06/02/2022 13:45:18 - INFO - __main__ - Global step 2900 Train loss 0.07 Classification-F1 0.8547651480452632 on epoch=207
06/02/2022 13:45:21 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.09 on epoch=207
06/02/2022 13:45:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/02/2022 13:45:25 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=209
06/02/2022 13:45:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/02/2022 13:45:30 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=210
06/02/2022 13:45:39 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.9055864144289193 on epoch=210
06/02/2022 13:45:41 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=211
06/02/2022 13:45:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/02/2022 13:45:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/02/2022 13:45:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=213
06/02/2022 13:45:51 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
06/02/2022 13:45:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 13:45:53 - INFO - __main__ - Printing 3 examples
06/02/2022 13:45:53 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 13:45:53 - INFO - __main__ - ['Company']
06/02/2022 13:45:53 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 13:45:53 - INFO - __main__ - ['Company']
06/02/2022 13:45:53 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 13:45:53 - INFO - __main__ - ['Company']
06/02/2022 13:45:53 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:45:53 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:45:53 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 13:45:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 13:45:53 - INFO - __main__ - Printing 3 examples
06/02/2022 13:45:53 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 13:45:53 - INFO - __main__ - ['Company']
06/02/2022 13:45:53 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 13:45:53 - INFO - __main__ - ['Company']
06/02/2022 13:45:53 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 13:45:53 - INFO - __main__ - ['Company']
06/02/2022 13:45:53 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:45:53 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:45:53 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 13:46:00 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.9096104538151256 on epoch=214
06/02/2022 13:46:00 - INFO - __main__ - save last model!
06/02/2022 13:46:00 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 13:46:00 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 13:46:00 - INFO - __main__ - Printing 3 examples
06/02/2022 13:46:00 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 13:46:00 - INFO - __main__ - ['Animal']
06/02/2022 13:46:00 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 13:46:00 - INFO - __main__ - ['Animal']
06/02/2022 13:46:00 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 13:46:00 - INFO - __main__ - ['Village']
06/02/2022 13:46:00 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:46:02 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:46:05 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 13:46:08 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 13:46:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 13:46:09 - INFO - __main__ - Starting training!
06/02/2022 13:48:45 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
06/02/2022 13:48:45 - INFO - __main__ - Classification-F1 on test data: 0.5677
06/02/2022 13:48:45 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.9097292892280786, test_performance=0.5677060799360176
06/02/2022 13:48:45 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
06/02/2022 13:48:46 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 13:48:46 - INFO - __main__ - Printing 3 examples
06/02/2022 13:48:46 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 13:48:46 - INFO - __main__ - ['Company']
06/02/2022 13:48:46 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 13:48:46 - INFO - __main__ - ['Company']
06/02/2022 13:48:46 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 13:48:46 - INFO - __main__ - ['Company']
06/02/2022 13:48:46 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:48:46 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:48:46 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 13:48:46 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 13:48:46 - INFO - __main__ - Printing 3 examples
06/02/2022 13:48:46 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 13:48:46 - INFO - __main__ - ['Company']
06/02/2022 13:48:46 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 13:48:46 - INFO - __main__ - ['Company']
06/02/2022 13:48:46 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 13:48:46 - INFO - __main__ - ['Company']
06/02/2022 13:48:46 - INFO - __main__ - Tokenizing Input ...
06/02/2022 13:48:46 - INFO - __main__ - Tokenizing Output ...
06/02/2022 13:48:47 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 13:49:04 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 13:49:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 13:49:04 - INFO - __main__ - Starting training!
06/02/2022 13:49:08 - INFO - __main__ - Step 10 Global step 10 Train loss 5.68 on epoch=0
06/02/2022 13:49:10 - INFO - __main__ - Step 20 Global step 20 Train loss 4.28 on epoch=1
06/02/2022 13:49:12 - INFO - __main__ - Step 30 Global step 30 Train loss 3.59 on epoch=2
06/02/2022 13:49:15 - INFO - __main__ - Step 40 Global step 40 Train loss 3.12 on epoch=2
06/02/2022 13:49:17 - INFO - __main__ - Step 50 Global step 50 Train loss 2.64 on epoch=3
06/02/2022 13:49:22 - INFO - __main__ - Global step 50 Train loss 3.86 Classification-F1 0.10188503467837347 on epoch=3
06/02/2022 13:49:22 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10188503467837347 on epoch=3, global_step=50
06/02/2022 13:49:24 - INFO - __main__ - Step 60 Global step 60 Train loss 2.48 on epoch=4
06/02/2022 13:49:27 - INFO - __main__ - Step 70 Global step 70 Train loss 2.29 on epoch=4
06/02/2022 13:49:29 - INFO - __main__ - Step 80 Global step 80 Train loss 2.04 on epoch=5
06/02/2022 13:49:31 - INFO - __main__ - Step 90 Global step 90 Train loss 2.08 on epoch=6
06/02/2022 13:49:34 - INFO - __main__ - Step 100 Global step 100 Train loss 1.99 on epoch=7
06/02/2022 13:49:39 - INFO - __main__ - Global step 100 Train loss 2.18 Classification-F1 0.12282584100790771 on epoch=7
06/02/2022 13:49:39 - INFO - __main__ - Saving model with best Classification-F1: 0.10188503467837347 -> 0.12282584100790771 on epoch=7, global_step=100
06/02/2022 13:49:41 - INFO - __main__ - Step 110 Global step 110 Train loss 1.69 on epoch=7
06/02/2022 13:49:43 - INFO - __main__ - Step 120 Global step 120 Train loss 1.70 on epoch=8
06/02/2022 13:49:46 - INFO - __main__ - Step 130 Global step 130 Train loss 1.56 on epoch=9
06/02/2022 13:49:48 - INFO - __main__ - Step 140 Global step 140 Train loss 1.42 on epoch=9
06/02/2022 13:49:51 - INFO - __main__ - Step 150 Global step 150 Train loss 1.33 on epoch=10
06/02/2022 13:49:56 - INFO - __main__ - Global step 150 Train loss 1.54 Classification-F1 0.20917349299831745 on epoch=10
06/02/2022 13:49:56 - INFO - __main__ - Saving model with best Classification-F1: 0.12282584100790771 -> 0.20917349299831745 on epoch=10, global_step=150
06/02/2022 13:49:59 - INFO - __main__ - Step 160 Global step 160 Train loss 1.20 on epoch=11
06/02/2022 13:50:01 - INFO - __main__ - Step 170 Global step 170 Train loss 1.11 on epoch=12
06/02/2022 13:50:03 - INFO - __main__ - Step 180 Global step 180 Train loss 1.05 on epoch=12
06/02/2022 13:50:06 - INFO - __main__ - Step 190 Global step 190 Train loss 1.01 on epoch=13
06/02/2022 13:50:08 - INFO - __main__ - Step 200 Global step 200 Train loss 1.01 on epoch=14
06/02/2022 13:50:14 - INFO - __main__ - Global step 200 Train loss 1.07 Classification-F1 0.42426968397872894 on epoch=14
06/02/2022 13:50:14 - INFO - __main__ - Saving model with best Classification-F1: 0.20917349299831745 -> 0.42426968397872894 on epoch=14, global_step=200
06/02/2022 13:50:16 - INFO - __main__ - Step 210 Global step 210 Train loss 0.92 on epoch=14
06/02/2022 13:50:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.71 on epoch=15
06/02/2022 13:50:21 - INFO - __main__ - Step 230 Global step 230 Train loss 0.80 on epoch=16
06/02/2022 13:50:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.74 on epoch=17
06/02/2022 13:50:26 - INFO - __main__ - Step 250 Global step 250 Train loss 0.86 on epoch=17
06/02/2022 13:50:32 - INFO - __main__ - Global step 250 Train loss 0.80 Classification-F1 0.5160523195112424 on epoch=17
06/02/2022 13:50:32 - INFO - __main__ - Saving model with best Classification-F1: 0.42426968397872894 -> 0.5160523195112424 on epoch=17, global_step=250
06/02/2022 13:50:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.48 on epoch=18
06/02/2022 13:50:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.68 on epoch=19
06/02/2022 13:50:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.59 on epoch=19
06/02/2022 13:50:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=20
06/02/2022 13:50:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.56 on epoch=21
06/02/2022 13:50:51 - INFO - __main__ - Global step 300 Train loss 0.57 Classification-F1 0.5440730988654371 on epoch=21
06/02/2022 13:50:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5160523195112424 -> 0.5440730988654371 on epoch=21, global_step=300
06/02/2022 13:50:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.44 on epoch=22
06/02/2022 13:50:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.53 on epoch=22
06/02/2022 13:50:58 - INFO - __main__ - Step 330 Global step 330 Train loss 0.42 on epoch=23
06/02/2022 13:51:01 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=24
06/02/2022 13:51:03 - INFO - __main__ - Step 350 Global step 350 Train loss 0.44 on epoch=24
06/02/2022 13:51:10 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.6376787751680391 on epoch=24
06/02/2022 13:51:10 - INFO - __main__ - Saving model with best Classification-F1: 0.5440730988654371 -> 0.6376787751680391 on epoch=24, global_step=350
06/02/2022 13:51:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.45 on epoch=25
06/02/2022 13:51:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.45 on epoch=26
06/02/2022 13:51:17 - INFO - __main__ - Step 380 Global step 380 Train loss 0.41 on epoch=27
06/02/2022 13:51:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=27
06/02/2022 13:51:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=28
06/02/2022 13:51:29 - INFO - __main__ - Global step 400 Train loss 0.42 Classification-F1 0.652661639435833 on epoch=28
06/02/2022 13:51:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6376787751680391 -> 0.652661639435833 on epoch=28, global_step=400
06/02/2022 13:51:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.39 on epoch=29
06/02/2022 13:51:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.39 on epoch=29
06/02/2022 13:51:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.39 on epoch=30
06/02/2022 13:51:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=31
06/02/2022 13:51:41 - INFO - __main__ - Step 450 Global step 450 Train loss 0.38 on epoch=32
06/02/2022 13:51:48 - INFO - __main__ - Global step 450 Train loss 0.38 Classification-F1 0.6917646108148998 on epoch=32
06/02/2022 13:51:48 - INFO - __main__ - Saving model with best Classification-F1: 0.652661639435833 -> 0.6917646108148998 on epoch=32, global_step=450
06/02/2022 13:51:50 - INFO - __main__ - Step 460 Global step 460 Train loss 0.38 on epoch=32
06/02/2022 13:51:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=33
06/02/2022 13:51:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=34
06/02/2022 13:51:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=34
06/02/2022 13:52:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.40 on epoch=35
06/02/2022 13:52:07 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.7234236528354175 on epoch=35
06/02/2022 13:52:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6917646108148998 -> 0.7234236528354175 on epoch=35, global_step=500
06/02/2022 13:52:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=36
06/02/2022 13:52:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=37
06/02/2022 13:52:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.31 on epoch=37
06/02/2022 13:52:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=38
06/02/2022 13:52:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.31 on epoch=39
06/02/2022 13:52:25 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.6673618538324421 on epoch=39
06/02/2022 13:52:28 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=39
06/02/2022 13:52:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=40
06/02/2022 13:52:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=41
06/02/2022 13:52:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=42
06/02/2022 13:52:38 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=42
06/02/2022 13:52:44 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.7079796937382077 on epoch=42
06/02/2022 13:52:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=43
06/02/2022 13:52:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=44
06/02/2022 13:52:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=44
06/02/2022 13:52:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=45
06/02/2022 13:52:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=46
06/02/2022 13:53:03 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.7473118989458859 on epoch=46
06/02/2022 13:53:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7234236528354175 -> 0.7473118989458859 on epoch=46, global_step=650
06/02/2022 13:53:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=47
06/02/2022 13:53:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=47
06/02/2022 13:53:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=48
06/02/2022 13:53:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=49
06/02/2022 13:53:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=49
06/02/2022 13:53:21 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.7449916702223187 on epoch=49
06/02/2022 13:53:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=50
06/02/2022 13:53:26 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=51
06/02/2022 13:53:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=52
06/02/2022 13:53:31 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=52
06/02/2022 13:53:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=53
06/02/2022 13:53:40 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.8045310792938877 on epoch=53
06/02/2022 13:53:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7473118989458859 -> 0.8045310792938877 on epoch=53, global_step=750
06/02/2022 13:53:43 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=54
06/02/2022 13:53:45 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=54
06/02/2022 13:53:48 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=55
06/02/2022 13:53:50 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=56
06/02/2022 13:53:53 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=57
06/02/2022 13:53:59 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.7971493030539799 on epoch=57
06/02/2022 13:54:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=57
06/02/2022 13:54:04 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=58
06/02/2022 13:54:07 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=59
06/02/2022 13:54:09 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=59
06/02/2022 13:54:12 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=60
06/02/2022 13:54:18 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.7540769204840395 on epoch=60
06/02/2022 13:54:20 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=61
06/02/2022 13:54:23 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=62
06/02/2022 13:54:25 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=62
06/02/2022 13:54:27 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=63
06/02/2022 13:54:30 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=64
06/02/2022 13:54:36 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.7951539079581674 on epoch=64
06/02/2022 13:54:38 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=64
06/02/2022 13:54:41 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=65
06/02/2022 13:54:43 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=66
06/02/2022 13:54:46 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=67
06/02/2022 13:54:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=67
06/02/2022 13:54:55 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.8547759294839383 on epoch=67
06/02/2022 13:54:55 - INFO - __main__ - Saving model with best Classification-F1: 0.8045310792938877 -> 0.8547759294839383 on epoch=67, global_step=950
06/02/2022 13:54:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/02/2022 13:55:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
06/02/2022 13:55:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=69
06/02/2022 13:55:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/02/2022 13:55:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=71
06/02/2022 13:55:13 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.7988993412227513 on epoch=71
06/02/2022 13:55:16 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=72
06/02/2022 13:55:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
06/02/2022 13:55:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=73
06/02/2022 13:55:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=74
06/02/2022 13:55:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.21 on epoch=74
06/02/2022 13:55:32 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.8508658610577409 on epoch=74
06/02/2022 13:55:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=75
06/02/2022 13:55:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=76
06/02/2022 13:55:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=77
06/02/2022 13:55:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=77
06/02/2022 13:55:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
06/02/2022 13:55:52 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.8508428606552338 on epoch=78
06/02/2022 13:55:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
06/02/2022 13:55:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=79
06/02/2022 13:55:59 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=80
06/02/2022 13:56:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=81
06/02/2022 13:56:04 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=82
06/02/2022 13:56:11 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.8508428606552338 on epoch=82
06/02/2022 13:56:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
06/02/2022 13:56:16 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
06/02/2022 13:56:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
06/02/2022 13:56:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=84
06/02/2022 13:56:24 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
06/02/2022 13:56:31 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.8586859979101358 on epoch=85
06/02/2022 13:56:31 - INFO - __main__ - Saving model with best Classification-F1: 0.8547759294839383 -> 0.8586859979101358 on epoch=85, global_step=1200
06/02/2022 13:56:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
06/02/2022 13:56:36 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=87
06/02/2022 13:56:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
06/02/2022 13:56:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=88
06/02/2022 13:56:44 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/02/2022 13:56:51 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.84704420042868 on epoch=89
06/02/2022 13:56:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=89
06/02/2022 13:56:56 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=90
06/02/2022 13:56:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/02/2022 13:57:01 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/02/2022 13:57:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
06/02/2022 13:57:11 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.8547759294839383 on epoch=92
06/02/2022 13:57:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/02/2022 13:57:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=94
06/02/2022 13:57:18 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=94
06/02/2022 13:57:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
06/02/2022 13:57:23 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/02/2022 13:57:31 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.8508658610577409 on epoch=96
06/02/2022 13:57:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
06/02/2022 13:57:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
06/02/2022 13:57:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
06/02/2022 13:57:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=99
06/02/2022 13:57:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
06/02/2022 13:57:51 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.8469327922290364 on epoch=99
06/02/2022 13:57:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/02/2022 13:57:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=101
06/02/2022 13:57:58 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=102
06/02/2022 13:58:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
06/02/2022 13:58:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
06/02/2022 13:58:11 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.8547759294839383 on epoch=103
06/02/2022 13:58:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=104
06/02/2022 13:58:16 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=104
06/02/2022 13:58:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
06/02/2022 13:58:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
06/02/2022 13:58:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=107
06/02/2022 13:58:31 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.8508658610577409 on epoch=107
06/02/2022 13:58:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=107
06/02/2022 13:58:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=108
06/02/2022 13:58:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/02/2022 13:58:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
06/02/2022 13:58:43 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
06/02/2022 13:58:51 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.8469327922290364 on epoch=110
06/02/2022 13:58:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
06/02/2022 13:58:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
06/02/2022 13:58:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
06/02/2022 13:59:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
06/02/2022 13:59:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=114
06/02/2022 13:59:11 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.8429532693854163 on epoch=114
06/02/2022 13:59:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=114
06/02/2022 13:59:16 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/02/2022 13:59:18 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/02/2022 13:59:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
06/02/2022 13:59:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
06/02/2022 13:59:31 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.8508428606552338 on epoch=117
06/02/2022 13:59:33 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
06/02/2022 13:59:36 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/02/2022 13:59:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
06/02/2022 13:59:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
06/02/2022 13:59:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
06/02/2022 13:59:51 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.8547759294839383 on epoch=121
06/02/2022 13:59:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
06/02/2022 13:59:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=122
06/02/2022 13:59:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/02/2022 14:00:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
06/02/2022 14:00:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/02/2022 14:00:11 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.8508428606552338 on epoch=124
06/02/2022 14:00:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/02/2022 14:00:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
06/02/2022 14:00:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/02/2022 14:00:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=127
06/02/2022 14:00:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/02/2022 14:00:31 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.8508428606552338 on epoch=128
06/02/2022 14:00:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
06/02/2022 14:00:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
06/02/2022 14:00:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/02/2022 14:00:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
06/02/2022 14:00:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/02/2022 14:00:51 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.9077131601958207 on epoch=132
06/02/2022 14:00:51 - INFO - __main__ - Saving model with best Classification-F1: 0.8586859979101358 -> 0.9077131601958207 on epoch=132, global_step=1850
06/02/2022 14:00:54 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/02/2022 14:00:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/02/2022 14:00:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/02/2022 14:01:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=134
06/02/2022 14:01:04 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/02/2022 14:01:12 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.8547759294839383 on epoch=135
06/02/2022 14:01:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/02/2022 14:01:17 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/02/2022 14:01:19 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
06/02/2022 14:01:22 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/02/2022 14:01:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/02/2022 14:01:33 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.8509542688548775 on epoch=139
06/02/2022 14:01:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/02/2022 14:01:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/02/2022 14:01:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/02/2022 14:01:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/02/2022 14:01:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=142
06/02/2022 14:01:54 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.8586859979101358 on epoch=142
06/02/2022 14:01:57 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/02/2022 14:01:59 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/02/2022 14:02:02 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=144
06/02/2022 14:02:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/02/2022 14:02:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=146
06/02/2022 14:02:15 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.9098596248422853 on epoch=146
06/02/2022 14:02:15 - INFO - __main__ - Saving model with best Classification-F1: 0.9077131601958207 -> 0.9098596248422853 on epoch=146, global_step=2050
06/02/2022 14:02:18 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
06/02/2022 14:02:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=147
06/02/2022 14:02:23 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/02/2022 14:02:26 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/02/2022 14:02:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/02/2022 14:02:36 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.8548873376835819 on epoch=149
06/02/2022 14:02:39 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/02/2022 14:02:41 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
06/02/2022 14:02:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/02/2022 14:02:46 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/02/2022 14:02:49 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/02/2022 14:02:57 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.8547759294839383 on epoch=153
06/02/2022 14:03:00 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/02/2022 14:03:02 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/02/2022 14:03:05 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/02/2022 14:03:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
06/02/2022 14:03:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=157
06/02/2022 14:03:18 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.9140548982595701 on epoch=157
06/02/2022 14:03:18 - INFO - __main__ - Saving model with best Classification-F1: 0.9098596248422853 -> 0.9140548982595701 on epoch=157, global_step=2200
06/02/2022 14:03:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/02/2022 14:03:23 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/02/2022 14:03:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/02/2022 14:03:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
06/02/2022 14:03:30 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/02/2022 14:03:39 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8025974592486403 on epoch=160
06/02/2022 14:03:41 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/02/2022 14:03:44 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/02/2022 14:03:46 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=162
06/02/2022 14:03:49 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=163
06/02/2022 14:03:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/02/2022 14:03:59 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8469327922290364 on epoch=164
06/02/2022 14:04:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
06/02/2022 14:04:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
06/02/2022 14:04:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/02/2022 14:04:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/02/2022 14:04:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/02/2022 14:04:21 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.8567812770775213 on epoch=167
06/02/2022 14:04:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/02/2022 14:04:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
06/02/2022 14:04:29 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
06/02/2022 14:04:31 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/02/2022 14:04:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/02/2022 14:04:43 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9182256379141808 on epoch=171
06/02/2022 14:04:43 - INFO - __main__ - Saving model with best Classification-F1: 0.9140548982595701 -> 0.9182256379141808 on epoch=171, global_step=2400
06/02/2022 14:04:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/02/2022 14:04:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/02/2022 14:04:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/02/2022 14:04:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/02/2022 14:04:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/02/2022 14:05:04 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9183444733271339 on epoch=174
06/02/2022 14:05:04 - INFO - __main__ - Saving model with best Classification-F1: 0.9182256379141808 -> 0.9183444733271339 on epoch=174, global_step=2450
06/02/2022 14:05:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
06/02/2022 14:05:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/02/2022 14:05:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/02/2022 14:05:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/02/2022 14:05:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/02/2022 14:05:26 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8509542688548775 on epoch=178
06/02/2022 14:05:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/02/2022 14:05:31 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/02/2022 14:05:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/02/2022 14:05:36 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/02/2022 14:05:39 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/02/2022 14:05:48 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8586859979101358 on epoch=182
06/02/2022 14:05:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/02/2022 14:05:53 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
06/02/2022 14:05:55 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
06/02/2022 14:05:58 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/02/2022 14:06:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/02/2022 14:06:09 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.8586859979101358 on epoch=185
06/02/2022 14:06:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/02/2022 14:06:14 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/02/2022 14:06:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/02/2022 14:06:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/02/2022 14:06:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/02/2022 14:06:31 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8548873376835819 on epoch=189
06/02/2022 14:06:34 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/02/2022 14:06:36 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/02/2022 14:06:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/02/2022 14:06:41 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/02/2022 14:06:44 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/02/2022 14:06:54 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8508428606552338 on epoch=192
06/02/2022 14:06:57 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/02/2022 14:06:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/02/2022 14:07:02 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/02/2022 14:07:04 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/02/2022 14:07:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/02/2022 14:07:16 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8508428606552338 on epoch=196
06/02/2022 14:07:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/02/2022 14:07:21 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/02/2022 14:07:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/02/2022 14:07:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/02/2022 14:07:28 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/02/2022 14:07:37 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8586859979101358 on epoch=199
06/02/2022 14:07:40 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/02/2022 14:07:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/02/2022 14:07:45 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/02/2022 14:07:47 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
06/02/2022 14:07:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
06/02/2022 14:07:58 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8547759294839383 on epoch=203
06/02/2022 14:08:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/02/2022 14:08:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/02/2022 14:08:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
06/02/2022 14:08:08 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/02/2022 14:08:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
06/02/2022 14:08:19 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7523232688318077 on epoch=207
06/02/2022 14:08:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/02/2022 14:08:24 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/02/2022 14:08:27 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/02/2022 14:08:29 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/02/2022 14:08:32 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/02/2022 14:08:40 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8058568882098293 on epoch=210
06/02/2022 14:08:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/02/2022 14:08:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/02/2022 14:08:48 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/02/2022 14:08:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=213
06/02/2022 14:08:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/02/2022 14:08:54 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 14:08:54 - INFO - __main__ - Printing 3 examples
06/02/2022 14:08:54 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 14:08:54 - INFO - __main__ - ['Company']
06/02/2022 14:08:54 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 14:08:54 - INFO - __main__ - ['Company']
06/02/2022 14:08:54 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 14:08:54 - INFO - __main__ - ['Company']
06/02/2022 14:08:54 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:08:54 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:08:54 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 14:08:54 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 14:08:54 - INFO - __main__ - Printing 3 examples
06/02/2022 14:08:54 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 14:08:54 - INFO - __main__ - ['Company']
06/02/2022 14:08:54 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 14:08:54 - INFO - __main__ - ['Company']
06/02/2022 14:08:54 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 14:08:54 - INFO - __main__ - ['Company']
06/02/2022 14:08:54 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:08:54 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:08:55 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 14:09:01 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8508428606552338 on epoch=214
06/02/2022 14:09:01 - INFO - __main__ - save last model!
06/02/2022 14:09:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 14:09:01 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 14:09:01 - INFO - __main__ - Printing 3 examples
06/02/2022 14:09:01 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 14:09:01 - INFO - __main__ - ['Animal']
06/02/2022 14:09:01 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 14:09:01 - INFO - __main__ - ['Animal']
06/02/2022 14:09:01 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 14:09:01 - INFO - __main__ - ['Village']
06/02/2022 14:09:01 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:09:03 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:09:07 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 14:09:10 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 14:09:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 14:09:10 - INFO - __main__ - Starting training!
06/02/2022 14:12:01 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
06/02/2022 14:12:01 - INFO - __main__ - Classification-F1 on test data: 0.6498
06/02/2022 14:12:02 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.9183444733271339, test_performance=0.6497985225565066
06/02/2022 14:12:02 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
06/02/2022 14:12:02 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 14:12:02 - INFO - __main__ - Printing 3 examples
06/02/2022 14:12:02 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 14:12:02 - INFO - __main__ - ['Company']
06/02/2022 14:12:02 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 14:12:02 - INFO - __main__ - ['Company']
06/02/2022 14:12:02 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 14:12:02 - INFO - __main__ - ['Company']
06/02/2022 14:12:02 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:12:03 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:12:03 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 14:12:03 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 14:12:03 - INFO - __main__ - Printing 3 examples
06/02/2022 14:12:03 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 14:12:03 - INFO - __main__ - ['Company']
06/02/2022 14:12:03 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 14:12:03 - INFO - __main__ - ['Company']
06/02/2022 14:12:03 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 14:12:03 - INFO - __main__ - ['Company']
06/02/2022 14:12:03 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:12:03 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:12:03 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 14:12:20 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 14:12:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 14:12:21 - INFO - __main__ - Starting training!
06/02/2022 14:12:24 - INFO - __main__ - Step 10 Global step 10 Train loss 5.89 on epoch=0
06/02/2022 14:12:27 - INFO - __main__ - Step 20 Global step 20 Train loss 4.45 on epoch=1
06/02/2022 14:12:29 - INFO - __main__ - Step 30 Global step 30 Train loss 3.80 on epoch=2
06/02/2022 14:12:32 - INFO - __main__ - Step 40 Global step 40 Train loss 3.39 on epoch=2
06/02/2022 14:12:34 - INFO - __main__ - Step 50 Global step 50 Train loss 3.19 on epoch=3
06/02/2022 14:12:39 - INFO - __main__ - Global step 50 Train loss 4.15 Classification-F1 0.08876321795258744 on epoch=3
06/02/2022 14:12:39 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08876321795258744 on epoch=3, global_step=50
06/02/2022 14:12:41 - INFO - __main__ - Step 60 Global step 60 Train loss 2.85 on epoch=4
06/02/2022 14:12:43 - INFO - __main__ - Step 70 Global step 70 Train loss 2.59 on epoch=4
06/02/2022 14:12:46 - INFO - __main__ - Step 80 Global step 80 Train loss 2.46 on epoch=5
06/02/2022 14:12:48 - INFO - __main__ - Step 90 Global step 90 Train loss 2.21 on epoch=6
06/02/2022 14:12:51 - INFO - __main__ - Step 100 Global step 100 Train loss 2.03 on epoch=7
06/02/2022 14:12:56 - INFO - __main__ - Global step 100 Train loss 2.43 Classification-F1 0.12116108748028201 on epoch=7
06/02/2022 14:12:56 - INFO - __main__ - Saving model with best Classification-F1: 0.08876321795258744 -> 0.12116108748028201 on epoch=7, global_step=100
06/02/2022 14:12:58 - INFO - __main__ - Step 110 Global step 110 Train loss 2.02 on epoch=7
06/02/2022 14:13:01 - INFO - __main__ - Step 120 Global step 120 Train loss 1.73 on epoch=8
06/02/2022 14:13:03 - INFO - __main__ - Step 130 Global step 130 Train loss 1.79 on epoch=9
06/02/2022 14:13:06 - INFO - __main__ - Step 140 Global step 140 Train loss 1.62 on epoch=9
06/02/2022 14:13:08 - INFO - __main__ - Step 150 Global step 150 Train loss 1.54 on epoch=10
06/02/2022 14:13:14 - INFO - __main__ - Global step 150 Train loss 1.74 Classification-F1 0.1803631350221061 on epoch=10
06/02/2022 14:13:14 - INFO - __main__ - Saving model with best Classification-F1: 0.12116108748028201 -> 0.1803631350221061 on epoch=10, global_step=150
06/02/2022 14:13:16 - INFO - __main__ - Step 160 Global step 160 Train loss 1.49 on epoch=11
06/02/2022 14:13:19 - INFO - __main__ - Step 170 Global step 170 Train loss 1.44 on epoch=12
06/02/2022 14:13:21 - INFO - __main__ - Step 180 Global step 180 Train loss 1.49 on epoch=12
06/02/2022 14:13:24 - INFO - __main__ - Step 190 Global step 190 Train loss 1.19 on epoch=13
06/02/2022 14:13:26 - INFO - __main__ - Step 200 Global step 200 Train loss 1.23 on epoch=14
06/02/2022 14:13:32 - INFO - __main__ - Global step 200 Train loss 1.37 Classification-F1 0.2723542298451167 on epoch=14
06/02/2022 14:13:32 - INFO - __main__ - Saving model with best Classification-F1: 0.1803631350221061 -> 0.2723542298451167 on epoch=14, global_step=200
06/02/2022 14:13:34 - INFO - __main__ - Step 210 Global step 210 Train loss 1.09 on epoch=14
06/02/2022 14:13:37 - INFO - __main__ - Step 220 Global step 220 Train loss 1.02 on epoch=15
06/02/2022 14:13:40 - INFO - __main__ - Step 230 Global step 230 Train loss 1.03 on epoch=16
06/02/2022 14:13:42 - INFO - __main__ - Step 240 Global step 240 Train loss 0.92 on epoch=17
06/02/2022 14:13:44 - INFO - __main__ - Step 250 Global step 250 Train loss 0.97 on epoch=17
06/02/2022 14:13:50 - INFO - __main__ - Global step 250 Train loss 1.00 Classification-F1 0.3926087737147645 on epoch=17
06/02/2022 14:13:50 - INFO - __main__ - Saving model with best Classification-F1: 0.2723542298451167 -> 0.3926087737147645 on epoch=17, global_step=250
06/02/2022 14:13:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.84 on epoch=18
06/02/2022 14:13:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.92 on epoch=19
06/02/2022 14:13:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.77 on epoch=19
06/02/2022 14:14:00 - INFO - __main__ - Step 290 Global step 290 Train loss 0.75 on epoch=20
06/02/2022 14:14:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.69 on epoch=21
06/02/2022 14:14:09 - INFO - __main__ - Global step 300 Train loss 0.80 Classification-F1 0.45873266518427813 on epoch=21
06/02/2022 14:14:09 - INFO - __main__ - Saving model with best Classification-F1: 0.3926087737147645 -> 0.45873266518427813 on epoch=21, global_step=300
06/02/2022 14:14:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.64 on epoch=22
06/02/2022 14:14:14 - INFO - __main__ - Step 320 Global step 320 Train loss 0.72 on epoch=22
06/02/2022 14:14:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.62 on epoch=23
06/02/2022 14:14:19 - INFO - __main__ - Step 340 Global step 340 Train loss 0.66 on epoch=24
06/02/2022 14:14:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.55 on epoch=24
06/02/2022 14:14:28 - INFO - __main__ - Global step 350 Train loss 0.64 Classification-F1 0.47382636760245866 on epoch=24
06/02/2022 14:14:28 - INFO - __main__ - Saving model with best Classification-F1: 0.45873266518427813 -> 0.47382636760245866 on epoch=24, global_step=350
06/02/2022 14:14:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=25
06/02/2022 14:14:33 - INFO - __main__ - Step 370 Global step 370 Train loss 0.50 on epoch=26
06/02/2022 14:14:36 - INFO - __main__ - Step 380 Global step 380 Train loss 0.63 on epoch=27
06/02/2022 14:14:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.50 on epoch=27
06/02/2022 14:14:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=28
06/02/2022 14:14:48 - INFO - __main__ - Global step 400 Train loss 0.54 Classification-F1 0.5846310095987025 on epoch=28
06/02/2022 14:14:48 - INFO - __main__ - Saving model with best Classification-F1: 0.47382636760245866 -> 0.5846310095987025 on epoch=28, global_step=400
06/02/2022 14:14:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.53 on epoch=29
06/02/2022 14:14:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.45 on epoch=29
06/02/2022 14:14:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.43 on epoch=30
06/02/2022 14:14:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.45 on epoch=31
06/02/2022 14:15:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.49 on epoch=32
06/02/2022 14:15:07 - INFO - __main__ - Global step 450 Train loss 0.47 Classification-F1 0.5586593541249042 on epoch=32
06/02/2022 14:15:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.43 on epoch=32
06/02/2022 14:15:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.40 on epoch=33
06/02/2022 14:15:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.39 on epoch=34
06/02/2022 14:15:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.38 on epoch=34
06/02/2022 14:15:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.38 on epoch=35
06/02/2022 14:15:27 - INFO - __main__ - Global step 500 Train loss 0.40 Classification-F1 0.6625979918764958 on epoch=35
06/02/2022 14:15:27 - INFO - __main__ - Saving model with best Classification-F1: 0.5846310095987025 -> 0.6625979918764958 on epoch=35, global_step=500
06/02/2022 14:15:30 - INFO - __main__ - Step 510 Global step 510 Train loss 0.38 on epoch=36
06/02/2022 14:15:32 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=37
06/02/2022 14:15:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.35 on epoch=37
06/02/2022 14:15:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=38
06/02/2022 14:15:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.33 on epoch=39
06/02/2022 14:15:47 - INFO - __main__ - Global step 550 Train loss 0.34 Classification-F1 0.6615512771473501 on epoch=39
06/02/2022 14:15:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.43 on epoch=39
06/02/2022 14:15:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.37 on epoch=40
06/02/2022 14:15:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=41
06/02/2022 14:15:57 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=42
06/02/2022 14:15:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.34 on epoch=42
06/02/2022 14:16:06 - INFO - __main__ - Global step 600 Train loss 0.34 Classification-F1 0.6629453812316715 on epoch=42
06/02/2022 14:16:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6625979918764958 -> 0.6629453812316715 on epoch=42, global_step=600
06/02/2022 14:16:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=43
06/02/2022 14:16:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=44
06/02/2022 14:16:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.35 on epoch=44
06/02/2022 14:16:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.30 on epoch=45
06/02/2022 14:16:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=46
06/02/2022 14:16:26 - INFO - __main__ - Global step 650 Train loss 0.29 Classification-F1 0.7096014342194309 on epoch=46
06/02/2022 14:16:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6629453812316715 -> 0.7096014342194309 on epoch=46, global_step=650
06/02/2022 14:16:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.31 on epoch=47
06/02/2022 14:16:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.33 on epoch=47
06/02/2022 14:16:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=48
06/02/2022 14:16:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.24 on epoch=49
06/02/2022 14:16:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=49
06/02/2022 14:16:45 - INFO - __main__ - Global step 700 Train loss 0.26 Classification-F1 0.7686139543205859 on epoch=49
06/02/2022 14:16:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7096014342194309 -> 0.7686139543205859 on epoch=49, global_step=700
06/02/2022 14:16:48 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=50
06/02/2022 14:16:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=51
06/02/2022 14:16:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=52
06/02/2022 14:16:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=52
06/02/2022 14:16:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.25 on epoch=53
06/02/2022 14:17:05 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.6915668372374654 on epoch=53
06/02/2022 14:17:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.26 on epoch=54
06/02/2022 14:17:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=54
06/02/2022 14:17:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=55
06/02/2022 14:17:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=56
06/02/2022 14:17:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=57
06/02/2022 14:17:24 - INFO - __main__ - Global step 800 Train loss 0.22 Classification-F1 0.6927032815872062 on epoch=57
06/02/2022 14:17:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=57
06/02/2022 14:17:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=58
06/02/2022 14:17:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=59
06/02/2022 14:17:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.27 on epoch=59
06/02/2022 14:17:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=60
06/02/2022 14:17:44 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.7498308740244224 on epoch=60
06/02/2022 14:17:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=61
06/02/2022 14:17:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=62
06/02/2022 14:17:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=62
06/02/2022 14:17:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=63
06/02/2022 14:17:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=64
06/02/2022 14:18:04 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.6962888850554885 on epoch=64
06/02/2022 14:18:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=64
06/02/2022 14:18:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=65
06/02/2022 14:18:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.24 on epoch=66
06/02/2022 14:18:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=67
06/02/2022 14:18:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=67
06/02/2022 14:18:24 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.7521604860245016 on epoch=67
06/02/2022 14:18:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=68
06/02/2022 14:18:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=69
06/02/2022 14:18:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=69
06/02/2022 14:18:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=70
06/02/2022 14:18:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=71
06/02/2022 14:18:44 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.8471893904695056 on epoch=71
06/02/2022 14:18:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7686139543205859 -> 0.8471893904695056 on epoch=71, global_step=1000
06/02/2022 14:18:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=72
06/02/2022 14:18:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=72
06/02/2022 14:18:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
06/02/2022 14:18:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=74
06/02/2022 14:18:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.29 on epoch=74
06/02/2022 14:19:04 - INFO - __main__ - Global step 1050 Train loss 0.18 Classification-F1 0.8008293674551069 on epoch=74
06/02/2022 14:19:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=75
06/02/2022 14:19:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=76
06/02/2022 14:19:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=77
06/02/2022 14:19:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=77
06/02/2022 14:19:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=78
06/02/2022 14:19:24 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.8009515570934257 on epoch=78
06/02/2022 14:19:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=79
06/02/2022 14:19:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=79
06/02/2022 14:19:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
06/02/2022 14:19:34 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=81
06/02/2022 14:19:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=82
06/02/2022 14:19:45 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.8509542688548775 on epoch=82
06/02/2022 14:19:45 - INFO - __main__ - Saving model with best Classification-F1: 0.8471893904695056 -> 0.8509542688548775 on epoch=82, global_step=1150
06/02/2022 14:19:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=82
06/02/2022 14:19:50 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=83
06/02/2022 14:19:53 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=84
06/02/2022 14:19:55 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=84
06/02/2022 14:19:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
06/02/2022 14:20:05 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.8509772692573845 on epoch=85
06/02/2022 14:20:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8509542688548775 -> 0.8509772692573845 on epoch=85, global_step=1200
06/02/2022 14:20:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
06/02/2022 14:20:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=87
06/02/2022 14:20:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
06/02/2022 14:20:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
06/02/2022 14:20:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=89
06/02/2022 14:20:26 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.8509542688548775 on epoch=89
06/02/2022 14:20:28 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=89
06/02/2022 14:20:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=90
06/02/2022 14:20:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=91
06/02/2022 14:20:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=92
06/02/2022 14:20:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.20 on epoch=92
06/02/2022 14:20:46 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.8548873376835819 on epoch=92
06/02/2022 14:20:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8509772692573845 -> 0.8548873376835819 on epoch=92, global_step=1300
06/02/2022 14:20:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
06/02/2022 14:20:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=94
06/02/2022 14:20:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
06/02/2022 14:20:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=95
06/02/2022 14:20:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=96
06/02/2022 14:21:06 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.9099784602552384 on epoch=96
06/02/2022 14:21:06 - INFO - __main__ - Saving model with best Classification-F1: 0.8548873376835819 -> 0.9099784602552384 on epoch=96, global_step=1350
06/02/2022 14:21:09 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=97
06/02/2022 14:21:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=97
06/02/2022 14:21:14 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=98
06/02/2022 14:21:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
06/02/2022 14:21:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/02/2022 14:21:27 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.9099784602552384 on epoch=99
06/02/2022 14:21:29 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
06/02/2022 14:21:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=101
06/02/2022 14:21:34 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=102
06/02/2022 14:21:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=102
06/02/2022 14:21:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
06/02/2022 14:21:48 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.8509542688548775 on epoch=103
06/02/2022 14:21:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=104
06/02/2022 14:21:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
06/02/2022 14:21:55 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/02/2022 14:21:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=106
06/02/2022 14:22:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.14 on epoch=107
06/02/2022 14:22:09 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.8509542688548775 on epoch=107
06/02/2022 14:22:11 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
06/02/2022 14:22:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
06/02/2022 14:22:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=109
06/02/2022 14:22:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.16 on epoch=109
06/02/2022 14:22:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=110
06/02/2022 14:22:29 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.84704420042868 on epoch=110
06/02/2022 14:22:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.13 on epoch=111
06/02/2022 14:22:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=112
06/02/2022 14:22:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=112
06/02/2022 14:22:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
06/02/2022 14:22:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=114
06/02/2022 14:22:50 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.8508428606552338 on epoch=114
06/02/2022 14:22:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=114
06/02/2022 14:22:55 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=115
06/02/2022 14:22:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=116
06/02/2022 14:23:00 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
06/02/2022 14:23:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/02/2022 14:23:11 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.8508428606552338 on epoch=117
06/02/2022 14:23:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
06/02/2022 14:23:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/02/2022 14:23:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=119
06/02/2022 14:23:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.16 on epoch=120
06/02/2022 14:23:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
06/02/2022 14:23:31 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.8550356506238859 on epoch=121
06/02/2022 14:23:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
06/02/2022 14:23:36 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=122
06/02/2022 14:23:39 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/02/2022 14:23:41 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
06/02/2022 14:23:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=124
06/02/2022 14:23:52 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.8508428606552338 on epoch=124
06/02/2022 14:23:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=125
06/02/2022 14:23:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=126
06/02/2022 14:23:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=127
06/02/2022 14:24:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/02/2022 14:24:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=128
06/02/2022 14:24:12 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.8470602378187093 on epoch=128
06/02/2022 14:24:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=129
06/02/2022 14:24:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=129
06/02/2022 14:24:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=130
06/02/2022 14:24:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=131
06/02/2022 14:24:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.11 on epoch=132
06/02/2022 14:24:33 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.8509542688548775 on epoch=132
06/02/2022 14:24:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
06/02/2022 14:24:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=133
06/02/2022 14:24:40 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/02/2022 14:24:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/02/2022 14:24:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
06/02/2022 14:24:53 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.8508428606552338 on epoch=135
06/02/2022 14:24:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=136
06/02/2022 14:24:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=137
06/02/2022 14:25:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
06/02/2022 14:25:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=138
06/02/2022 14:25:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/02/2022 14:25:14 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.7988957474098596 on epoch=139
06/02/2022 14:25:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=139
06/02/2022 14:25:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
06/02/2022 14:25:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=141
06/02/2022 14:25:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/02/2022 14:25:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=142
06/02/2022 14:25:35 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.9141737336725233 on epoch=142
06/02/2022 14:25:35 - INFO - __main__ - Saving model with best Classification-F1: 0.9099784602552384 -> 0.9141737336725233 on epoch=142, global_step=2000
06/02/2022 14:25:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/02/2022 14:25:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=144
06/02/2022 14:25:43 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=144
06/02/2022 14:25:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=145
06/02/2022 14:25:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=146
06/02/2022 14:25:57 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.9098596248422853 on epoch=146
06/02/2022 14:25:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=147
06/02/2022 14:26:02 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=147
06/02/2022 14:26:04 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=148
06/02/2022 14:26:07 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.09 on epoch=149
06/02/2022 14:26:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=149
06/02/2022 14:26:17 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.8508428606552338 on epoch=149
06/02/2022 14:26:20 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/02/2022 14:26:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/02/2022 14:26:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.13 on epoch=152
06/02/2022 14:26:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/02/2022 14:26:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
06/02/2022 14:26:39 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.9098596248422853 on epoch=153
06/02/2022 14:26:41 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=154
06/02/2022 14:26:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=154
06/02/2022 14:26:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=155
06/02/2022 14:26:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=156
06/02/2022 14:26:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
06/02/2022 14:27:00 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.8528712086513239 on epoch=157
06/02/2022 14:27:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=157
06/02/2022 14:27:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/02/2022 14:27:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=159
06/02/2022 14:27:10 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
06/02/2022 14:27:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
06/02/2022 14:27:21 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.8509772692573845 on epoch=160
06/02/2022 14:27:24 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
06/02/2022 14:27:26 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/02/2022 14:27:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/02/2022 14:27:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
06/02/2022 14:27:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/02/2022 14:27:43 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8586859979101358 on epoch=164
06/02/2022 14:27:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/02/2022 14:27:48 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=165
06/02/2022 14:27:50 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=166
06/02/2022 14:27:53 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/02/2022 14:27:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
06/02/2022 14:28:04 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7988957474098596 on epoch=167
06/02/2022 14:28:07 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/02/2022 14:28:09 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/02/2022 14:28:12 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/02/2022 14:28:14 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=170
06/02/2022 14:28:17 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/02/2022 14:28:26 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.8508428606552338 on epoch=171
06/02/2022 14:28:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=172
06/02/2022 14:28:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=172
06/02/2022 14:28:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=173
06/02/2022 14:28:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=174
06/02/2022 14:28:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/02/2022 14:28:47 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.8547759294839383 on epoch=174
06/02/2022 14:28:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/02/2022 14:28:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/02/2022 14:28:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/02/2022 14:28:57 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/02/2022 14:29:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=178
06/02/2022 14:29:09 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9140548982595701 on epoch=178
06/02/2022 14:29:11 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
06/02/2022 14:29:14 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/02/2022 14:29:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/02/2022 14:29:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
06/02/2022 14:29:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=182
06/02/2022 14:29:30 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.8509772692573845 on epoch=182
06/02/2022 14:29:33 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/02/2022 14:29:35 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/02/2022 14:29:38 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
06/02/2022 14:29:40 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
06/02/2022 14:29:43 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
06/02/2022 14:29:51 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.9140548982595701 on epoch=185
06/02/2022 14:29:54 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/02/2022 14:29:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
06/02/2022 14:29:59 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/02/2022 14:30:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
06/02/2022 14:30:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/02/2022 14:30:12 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9182256379141808 on epoch=189
06/02/2022 14:30:12 - INFO - __main__ - Saving model with best Classification-F1: 0.9141737336725233 -> 0.9182256379141808 on epoch=189, global_step=2650
06/02/2022 14:30:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/02/2022 14:30:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=190
06/02/2022 14:30:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/02/2022 14:30:22 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
06/02/2022 14:30:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/02/2022 14:30:33 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9182256379141808 on epoch=192
06/02/2022 14:30:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/02/2022 14:30:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/02/2022 14:30:41 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.09 on epoch=194
06/02/2022 14:30:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/02/2022 14:30:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
06/02/2022 14:30:55 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.9098841586049595 on epoch=196
06/02/2022 14:30:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/02/2022 14:31:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/02/2022 14:31:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/02/2022 14:31:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/02/2022 14:31:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/02/2022 14:31:16 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9226979472140762 on epoch=199
06/02/2022 14:31:16 - INFO - __main__ - Saving model with best Classification-F1: 0.9182256379141808 -> 0.9226979472140762 on epoch=199, global_step=2800
06/02/2022 14:31:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/02/2022 14:31:21 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
06/02/2022 14:31:24 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/02/2022 14:31:26 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/02/2022 14:31:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/02/2022 14:31:37 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.8588204065122864 on epoch=203
06/02/2022 14:31:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/02/2022 14:31:42 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/02/2022 14:31:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
06/02/2022 14:31:47 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/02/2022 14:31:50 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/02/2022 14:31:59 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9182256379141808 on epoch=207
06/02/2022 14:32:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/02/2022 14:32:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/02/2022 14:32:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=209
06/02/2022 14:32:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
06/02/2022 14:32:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/02/2022 14:32:21 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.9140548982595701 on epoch=210
06/02/2022 14:32:24 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/02/2022 14:32:26 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/02/2022 14:32:29 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/02/2022 14:32:31 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/02/2022 14:32:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/02/2022 14:32:35 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 14:32:35 - INFO - __main__ - Printing 3 examples
06/02/2022 14:32:35 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 14:32:35 - INFO - __main__ - ['Company']
06/02/2022 14:32:35 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 14:32:35 - INFO - __main__ - ['Company']
06/02/2022 14:32:35 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 14:32:35 - INFO - __main__ - ['Company']
06/02/2022 14:32:35 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:32:35 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:32:36 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 14:32:36 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 14:32:36 - INFO - __main__ - Printing 3 examples
06/02/2022 14:32:36 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 14:32:36 - INFO - __main__ - ['Company']
06/02/2022 14:32:36 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 14:32:36 - INFO - __main__ - ['Company']
06/02/2022 14:32:36 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 14:32:36 - INFO - __main__ - ['Company']
06/02/2022 14:32:36 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:32:36 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:32:36 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 14:32:44 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9098596248422853 on epoch=214
06/02/2022 14:32:44 - INFO - __main__ - save last model!
06/02/2022 14:32:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 14:32:44 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 14:32:44 - INFO - __main__ - Printing 3 examples
06/02/2022 14:32:44 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 14:32:44 - INFO - __main__ - ['Animal']
06/02/2022 14:32:44 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 14:32:44 - INFO - __main__ - ['Animal']
06/02/2022 14:32:44 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 14:32:44 - INFO - __main__ - ['Village']
06/02/2022 14:32:44 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:32:46 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:32:50 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 14:32:53 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 14:32:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 14:32:53 - INFO - __main__ - Starting training!
06/02/2022 14:35:55 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
06/02/2022 14:35:55 - INFO - __main__ - Classification-F1 on test data: 0.6493
06/02/2022 14:35:55 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.9226979472140762, test_performance=0.6492892449844112
06/02/2022 14:35:55 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
06/02/2022 14:35:56 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 14:35:56 - INFO - __main__ - Printing 3 examples
06/02/2022 14:35:56 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 14:35:56 - INFO - __main__ - ['Company']
06/02/2022 14:35:56 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 14:35:56 - INFO - __main__ - ['Company']
06/02/2022 14:35:56 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 14:35:56 - INFO - __main__ - ['Company']
06/02/2022 14:35:56 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:35:56 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:35:56 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 14:35:56 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 14:35:56 - INFO - __main__ - Printing 3 examples
06/02/2022 14:35:56 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 14:35:56 - INFO - __main__ - ['Company']
06/02/2022 14:35:56 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 14:35:56 - INFO - __main__ - ['Company']
06/02/2022 14:35:56 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 14:35:56 - INFO - __main__ - ['Company']
06/02/2022 14:35:56 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:35:57 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:35:57 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 14:36:14 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 14:36:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 14:36:14 - INFO - __main__ - Starting training!
06/02/2022 14:36:18 - INFO - __main__ - Step 10 Global step 10 Train loss 5.94 on epoch=0
06/02/2022 14:36:20 - INFO - __main__ - Step 20 Global step 20 Train loss 4.72 on epoch=1
06/02/2022 14:36:23 - INFO - __main__ - Step 30 Global step 30 Train loss 4.22 on epoch=2
06/02/2022 14:36:25 - INFO - __main__ - Step 40 Global step 40 Train loss 3.59 on epoch=2
06/02/2022 14:36:28 - INFO - __main__ - Step 50 Global step 50 Train loss 3.35 on epoch=3
06/02/2022 14:36:33 - INFO - __main__ - Global step 50 Train loss 4.36 Classification-F1 0.07836784267012344 on epoch=3
06/02/2022 14:36:33 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07836784267012344 on epoch=3, global_step=50
06/02/2022 14:36:35 - INFO - __main__ - Step 60 Global step 60 Train loss 2.98 on epoch=4
06/02/2022 14:36:38 - INFO - __main__ - Step 70 Global step 70 Train loss 2.86 on epoch=4
06/02/2022 14:36:40 - INFO - __main__ - Step 80 Global step 80 Train loss 2.44 on epoch=5
06/02/2022 14:36:43 - INFO - __main__ - Step 90 Global step 90 Train loss 2.47 on epoch=6
06/02/2022 14:36:45 - INFO - __main__ - Step 100 Global step 100 Train loss 2.41 on epoch=7
06/02/2022 14:36:50 - INFO - __main__ - Global step 100 Train loss 2.63 Classification-F1 0.09665552523237532 on epoch=7
06/02/2022 14:36:50 - INFO - __main__ - Saving model with best Classification-F1: 0.07836784267012344 -> 0.09665552523237532 on epoch=7, global_step=100
06/02/2022 14:36:53 - INFO - __main__ - Step 110 Global step 110 Train loss 2.33 on epoch=7
06/02/2022 14:36:55 - INFO - __main__ - Step 120 Global step 120 Train loss 2.04 on epoch=8
06/02/2022 14:36:58 - INFO - __main__ - Step 130 Global step 130 Train loss 2.12 on epoch=9
06/02/2022 14:37:00 - INFO - __main__ - Step 140 Global step 140 Train loss 1.99 on epoch=9
06/02/2022 14:37:03 - INFO - __main__ - Step 150 Global step 150 Train loss 1.89 on epoch=10
06/02/2022 14:37:07 - INFO - __main__ - Global step 150 Train loss 2.07 Classification-F1 0.11691712967096361 on epoch=10
06/02/2022 14:37:08 - INFO - __main__ - Saving model with best Classification-F1: 0.09665552523237532 -> 0.11691712967096361 on epoch=10, global_step=150
06/02/2022 14:37:10 - INFO - __main__ - Step 160 Global step 160 Train loss 1.78 on epoch=11
06/02/2022 14:37:12 - INFO - __main__ - Step 170 Global step 170 Train loss 1.81 on epoch=12
06/02/2022 14:37:15 - INFO - __main__ - Step 180 Global step 180 Train loss 1.78 on epoch=12
06/02/2022 14:37:17 - INFO - __main__ - Step 190 Global step 190 Train loss 1.56 on epoch=13
06/02/2022 14:37:20 - INFO - __main__ - Step 200 Global step 200 Train loss 1.58 on epoch=14
06/02/2022 14:37:25 - INFO - __main__ - Global step 200 Train loss 1.70 Classification-F1 0.14442730771503365 on epoch=14
06/02/2022 14:37:25 - INFO - __main__ - Saving model with best Classification-F1: 0.11691712967096361 -> 0.14442730771503365 on epoch=14, global_step=200
06/02/2022 14:37:28 - INFO - __main__ - Step 210 Global step 210 Train loss 1.58 on epoch=14
06/02/2022 14:37:30 - INFO - __main__ - Step 220 Global step 220 Train loss 1.41 on epoch=15
06/02/2022 14:37:33 - INFO - __main__ - Step 230 Global step 230 Train loss 1.46 on epoch=16
06/02/2022 14:37:35 - INFO - __main__ - Step 240 Global step 240 Train loss 1.27 on epoch=17
06/02/2022 14:37:38 - INFO - __main__ - Step 250 Global step 250 Train loss 1.25 on epoch=17
06/02/2022 14:37:43 - INFO - __main__ - Global step 250 Train loss 1.39 Classification-F1 0.25591148742052566 on epoch=17
06/02/2022 14:37:43 - INFO - __main__ - Saving model with best Classification-F1: 0.14442730771503365 -> 0.25591148742052566 on epoch=17, global_step=250
06/02/2022 14:37:46 - INFO - __main__ - Step 260 Global step 260 Train loss 1.17 on epoch=18
06/02/2022 14:37:48 - INFO - __main__ - Step 270 Global step 270 Train loss 1.19 on epoch=19
06/02/2022 14:37:51 - INFO - __main__ - Step 280 Global step 280 Train loss 1.19 on epoch=19
06/02/2022 14:37:53 - INFO - __main__ - Step 290 Global step 290 Train loss 1.04 on epoch=20
06/02/2022 14:37:56 - INFO - __main__ - Step 300 Global step 300 Train loss 0.96 on epoch=21
06/02/2022 14:38:01 - INFO - __main__ - Global step 300 Train loss 1.11 Classification-F1 0.4127991056562485 on epoch=21
06/02/2022 14:38:01 - INFO - __main__ - Saving model with best Classification-F1: 0.25591148742052566 -> 0.4127991056562485 on epoch=21, global_step=300
06/02/2022 14:38:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.97 on epoch=22
06/02/2022 14:38:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.94 on epoch=22
06/02/2022 14:38:09 - INFO - __main__ - Step 330 Global step 330 Train loss 0.91 on epoch=23
06/02/2022 14:38:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.92 on epoch=24
06/02/2022 14:38:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.84 on epoch=24
06/02/2022 14:38:20 - INFO - __main__ - Global step 350 Train loss 0.91 Classification-F1 0.4124762026061654 on epoch=24
06/02/2022 14:38:22 - INFO - __main__ - Step 360 Global step 360 Train loss 0.85 on epoch=25
06/02/2022 14:38:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.76 on epoch=26
06/02/2022 14:38:27 - INFO - __main__ - Step 380 Global step 380 Train loss 0.75 on epoch=27
06/02/2022 14:38:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.74 on epoch=27
06/02/2022 14:38:32 - INFO - __main__ - Step 400 Global step 400 Train loss 0.62 on epoch=28
06/02/2022 14:38:39 - INFO - __main__ - Global step 400 Train loss 0.75 Classification-F1 0.4546042757820065 on epoch=28
06/02/2022 14:38:39 - INFO - __main__ - Saving model with best Classification-F1: 0.4127991056562485 -> 0.4546042757820065 on epoch=28, global_step=400
06/02/2022 14:38:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.75 on epoch=29
06/02/2022 14:38:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.61 on epoch=29
06/02/2022 14:38:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.65 on epoch=30
06/02/2022 14:38:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.60 on epoch=31
06/02/2022 14:38:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.57 on epoch=32
06/02/2022 14:38:58 - INFO - __main__ - Global step 450 Train loss 0.63 Classification-F1 0.5259909285002525 on epoch=32
06/02/2022 14:38:58 - INFO - __main__ - Saving model with best Classification-F1: 0.4546042757820065 -> 0.5259909285002525 on epoch=32, global_step=450
06/02/2022 14:39:00 - INFO - __main__ - Step 460 Global step 460 Train loss 0.47 on epoch=32
06/02/2022 14:39:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.48 on epoch=33
06/02/2022 14:39:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.54 on epoch=34
06/02/2022 14:39:07 - INFO - __main__ - Step 490 Global step 490 Train loss 0.50 on epoch=34
06/02/2022 14:39:10 - INFO - __main__ - Step 500 Global step 500 Train loss 0.55 on epoch=35
06/02/2022 14:39:17 - INFO - __main__ - Global step 500 Train loss 0.51 Classification-F1 0.5418084869915539 on epoch=35
06/02/2022 14:39:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5259909285002525 -> 0.5418084869915539 on epoch=35, global_step=500
06/02/2022 14:39:19 - INFO - __main__ - Step 510 Global step 510 Train loss 0.44 on epoch=36
06/02/2022 14:39:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.49 on epoch=37
06/02/2022 14:39:24 - INFO - __main__ - Step 530 Global step 530 Train loss 0.50 on epoch=37
06/02/2022 14:39:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.43 on epoch=38
06/02/2022 14:39:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.52 on epoch=39
06/02/2022 14:39:36 - INFO - __main__ - Global step 550 Train loss 0.47 Classification-F1 0.590860887389094 on epoch=39
06/02/2022 14:39:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5418084869915539 -> 0.590860887389094 on epoch=39, global_step=550
06/02/2022 14:39:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.50 on epoch=39
06/02/2022 14:39:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.47 on epoch=40
06/02/2022 14:39:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.38 on epoch=41
06/02/2022 14:39:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.50 on epoch=42
06/02/2022 14:39:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.46 on epoch=42
06/02/2022 14:39:56 - INFO - __main__ - Global step 600 Train loss 0.46 Classification-F1 0.6299213331471396 on epoch=42
06/02/2022 14:39:56 - INFO - __main__ - Saving model with best Classification-F1: 0.590860887389094 -> 0.6299213331471396 on epoch=42, global_step=600
06/02/2022 14:39:58 - INFO - __main__ - Step 610 Global step 610 Train loss 0.38 on epoch=43
06/02/2022 14:40:01 - INFO - __main__ - Step 620 Global step 620 Train loss 0.42 on epoch=44
06/02/2022 14:40:03 - INFO - __main__ - Step 630 Global step 630 Train loss 0.41 on epoch=44
06/02/2022 14:40:06 - INFO - __main__ - Step 640 Global step 640 Train loss 0.36 on epoch=45
06/02/2022 14:40:08 - INFO - __main__ - Step 650 Global step 650 Train loss 0.33 on epoch=46
06/02/2022 14:40:15 - INFO - __main__ - Global step 650 Train loss 0.38 Classification-F1 0.5900259277264625 on epoch=46
06/02/2022 14:40:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.41 on epoch=47
06/02/2022 14:40:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.41 on epoch=47
06/02/2022 14:40:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.30 on epoch=48
06/02/2022 14:40:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.36 on epoch=49
06/02/2022 14:40:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.40 on epoch=49
06/02/2022 14:40:34 - INFO - __main__ - Global step 700 Train loss 0.37 Classification-F1 0.5912184015168318 on epoch=49
06/02/2022 14:40:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=50
06/02/2022 14:40:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.33 on epoch=51
06/02/2022 14:40:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.36 on epoch=52
06/02/2022 14:40:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.35 on epoch=52
06/02/2022 14:40:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.35 on epoch=53
06/02/2022 14:40:54 - INFO - __main__ - Global step 750 Train loss 0.33 Classification-F1 0.683942376391666 on epoch=53
06/02/2022 14:40:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6299213331471396 -> 0.683942376391666 on epoch=53, global_step=750
06/02/2022 14:40:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.29 on epoch=54
06/02/2022 14:40:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.29 on epoch=54
06/02/2022 14:41:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.26 on epoch=55
06/02/2022 14:41:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=56
06/02/2022 14:41:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.28 on epoch=57
06/02/2022 14:41:13 - INFO - __main__ - Global step 800 Train loss 0.28 Classification-F1 0.6745722475883792 on epoch=57
06/02/2022 14:41:16 - INFO - __main__ - Step 810 Global step 810 Train loss 0.27 on epoch=57
06/02/2022 14:41:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.29 on epoch=58
06/02/2022 14:41:21 - INFO - __main__ - Step 830 Global step 830 Train loss 0.27 on epoch=59
06/02/2022 14:41:23 - INFO - __main__ - Step 840 Global step 840 Train loss 0.33 on epoch=59
06/02/2022 14:41:26 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=60
06/02/2022 14:41:32 - INFO - __main__ - Global step 850 Train loss 0.28 Classification-F1 0.6556598240469208 on epoch=60
06/02/2022 14:41:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.27 on epoch=61
06/02/2022 14:41:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.34 on epoch=62
06/02/2022 14:41:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.42 on epoch=62
06/02/2022 14:41:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.26 on epoch=63
06/02/2022 14:41:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.25 on epoch=64
06/02/2022 14:41:52 - INFO - __main__ - Global step 900 Train loss 0.31 Classification-F1 0.714404943606981 on epoch=64
06/02/2022 14:41:52 - INFO - __main__ - Saving model with best Classification-F1: 0.683942376391666 -> 0.714404943606981 on epoch=64, global_step=900
06/02/2022 14:41:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=64
06/02/2022 14:41:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.29 on epoch=65
06/02/2022 14:41:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=66
06/02/2022 14:42:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=67
06/02/2022 14:42:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=67
06/02/2022 14:42:11 - INFO - __main__ - Global step 950 Train loss 0.22 Classification-F1 0.6890135698285105 on epoch=67
06/02/2022 14:42:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=68
06/02/2022 14:42:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=69
06/02/2022 14:42:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.26 on epoch=69
06/02/2022 14:42:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.20 on epoch=70
06/02/2022 14:42:23 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=71
06/02/2022 14:42:30 - INFO - __main__ - Global step 1000 Train loss 0.20 Classification-F1 0.6625999972240892 on epoch=71
06/02/2022 14:42:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=72
06/02/2022 14:42:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.22 on epoch=72
06/02/2022 14:42:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=73
06/02/2022 14:42:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.24 on epoch=74
06/02/2022 14:42:43 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=74
06/02/2022 14:42:50 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.7462886933854675 on epoch=74
06/02/2022 14:42:50 - INFO - __main__ - Saving model with best Classification-F1: 0.714404943606981 -> 0.7462886933854675 on epoch=74, global_step=1050
06/02/2022 14:42:53 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.21 on epoch=75
06/02/2022 14:42:55 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.26 on epoch=76
06/02/2022 14:42:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=77
06/02/2022 14:43:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.21 on epoch=77
06/02/2022 14:43:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.20 on epoch=78
06/02/2022 14:43:09 - INFO - __main__ - Global step 1100 Train loss 0.22 Classification-F1 0.7060706637195132 on epoch=78
06/02/2022 14:43:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.19 on epoch=79
06/02/2022 14:43:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.19 on epoch=79
06/02/2022 14:43:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=80
06/02/2022 14:43:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.17 on epoch=81
06/02/2022 14:43:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.16 on epoch=82
06/02/2022 14:43:28 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.747181051722045 on epoch=82
06/02/2022 14:43:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7462886933854675 -> 0.747181051722045 on epoch=82, global_step=1150
06/02/2022 14:43:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=82
06/02/2022 14:43:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=83
06/02/2022 14:43:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=84
06/02/2022 14:43:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.20 on epoch=84
06/02/2022 14:43:41 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=85
06/02/2022 14:43:48 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.7968717119892397 on epoch=85
06/02/2022 14:43:48 - INFO - __main__ - Saving model with best Classification-F1: 0.747181051722045 -> 0.7968717119892397 on epoch=85, global_step=1200
06/02/2022 14:43:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=86
06/02/2022 14:43:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=87
06/02/2022 14:43:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=87
06/02/2022 14:43:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=88
06/02/2022 14:44:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=89
06/02/2022 14:44:07 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.8469327922290364 on epoch=89
06/02/2022 14:44:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7968717119892397 -> 0.8469327922290364 on epoch=89, global_step=1250
06/02/2022 14:44:10 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=89
06/02/2022 14:44:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=90
06/02/2022 14:44:15 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=91
06/02/2022 14:44:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=92
06/02/2022 14:44:20 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=92
06/02/2022 14:44:26 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.84704420042868 on epoch=92
06/02/2022 14:44:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8469327922290364 -> 0.84704420042868 on epoch=92, global_step=1300
06/02/2022 14:44:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=93
06/02/2022 14:44:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=94
06/02/2022 14:44:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=94
06/02/2022 14:44:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=95
06/02/2022 14:44:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.19 on epoch=96
06/02/2022 14:44:45 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.84704420042868 on epoch=96
06/02/2022 14:44:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.13 on epoch=97
06/02/2022 14:44:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=97
06/02/2022 14:44:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
06/02/2022 14:44:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.17 on epoch=99
06/02/2022 14:44:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=99
06/02/2022 14:45:05 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.8547759294839383 on epoch=99
06/02/2022 14:45:05 - INFO - __main__ - Saving model with best Classification-F1: 0.84704420042868 -> 0.8547759294839383 on epoch=99, global_step=1400
06/02/2022 14:45:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=100
06/02/2022 14:45:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=101
06/02/2022 14:45:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=102
06/02/2022 14:45:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=102
06/02/2022 14:45:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/02/2022 14:45:24 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.8509542688548775 on epoch=103
06/02/2022 14:45:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=104
06/02/2022 14:45:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=104
06/02/2022 14:45:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
06/02/2022 14:45:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.17 on epoch=106
06/02/2022 14:45:37 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=107
06/02/2022 14:45:44 - INFO - __main__ - Global step 1500 Train loss 0.13 Classification-F1 0.8509542688548775 on epoch=107
06/02/2022 14:45:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=107
06/02/2022 14:45:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=108
06/02/2022 14:45:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=109
06/02/2022 14:45:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=109
06/02/2022 14:45:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=110
06/02/2022 14:46:03 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.84704420042868 on epoch=110
06/02/2022 14:46:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=111
06/02/2022 14:46:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.13 on epoch=112
06/02/2022 14:46:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
06/02/2022 14:46:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=113
06/02/2022 14:46:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.14 on epoch=114
06/02/2022 14:46:23 - INFO - __main__ - Global step 1600 Train loss 0.12 Classification-F1 0.8470442004286799 on epoch=114
06/02/2022 14:46:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=114
06/02/2022 14:46:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=115
06/02/2022 14:46:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=116
06/02/2022 14:46:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=117
06/02/2022 14:46:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.14 on epoch=117
06/02/2022 14:46:42 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.9058077206006279 on epoch=117
06/02/2022 14:46:42 - INFO - __main__ - Saving model with best Classification-F1: 0.8547759294839383 -> 0.9058077206006279 on epoch=117, global_step=1650
06/02/2022 14:46:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=118
06/02/2022 14:46:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=119
06/02/2022 14:46:50 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=119
06/02/2022 14:46:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
06/02/2022 14:46:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=121
06/02/2022 14:47:02 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.9058077206006279 on epoch=121
06/02/2022 14:47:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=122
06/02/2022 14:47:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.12 on epoch=122
06/02/2022 14:47:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=123
06/02/2022 14:47:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=124
06/02/2022 14:47:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=124
06/02/2022 14:47:21 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.84704420042868 on epoch=124
06/02/2022 14:47:23 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=125
06/02/2022 14:47:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/02/2022 14:47:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=127
06/02/2022 14:47:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=127
06/02/2022 14:47:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
06/02/2022 14:47:40 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.8547759294839383 on epoch=128
06/02/2022 14:47:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=129
06/02/2022 14:47:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
06/02/2022 14:47:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=130
06/02/2022 14:47:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
06/02/2022 14:47:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
06/02/2022 14:48:00 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.9058077206006279 on epoch=132
06/02/2022 14:48:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=132
06/02/2022 14:48:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=133
06/02/2022 14:48:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
06/02/2022 14:48:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=134
06/02/2022 14:48:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=135
06/02/2022 14:48:19 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.9058077206006279 on epoch=135
06/02/2022 14:48:22 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=136
06/02/2022 14:48:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=137
06/02/2022 14:48:27 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.11 on epoch=137
06/02/2022 14:48:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=138
06/02/2022 14:48:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=139
06/02/2022 14:48:39 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.9058077206006279 on epoch=139
06/02/2022 14:48:41 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/02/2022 14:48:44 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
06/02/2022 14:48:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/02/2022 14:48:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=142
06/02/2022 14:48:51 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=142
06/02/2022 14:48:59 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.8450280713964219 on epoch=142
06/02/2022 14:49:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.10 on epoch=143
06/02/2022 14:49:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=144
06/02/2022 14:49:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
06/02/2022 14:49:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.17 on epoch=145
06/02/2022 14:49:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=146
06/02/2022 14:49:18 - INFO - __main__ - Global step 2050 Train loss 0.10 Classification-F1 0.8471786090308304 on epoch=146
06/02/2022 14:49:20 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.11 on epoch=147
06/02/2022 14:49:23 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.14 on epoch=147
06/02/2022 14:49:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=148
06/02/2022 14:49:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/02/2022 14:49:30 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/02/2022 14:49:37 - INFO - __main__ - Global step 2100 Train loss 0.09 Classification-F1 0.8471786090308304 on epoch=149
06/02/2022 14:49:40 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=150
06/02/2022 14:49:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=151
06/02/2022 14:49:45 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=152
06/02/2022 14:49:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
06/02/2022 14:49:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=153
06/02/2022 14:49:57 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.8471786090308304 on epoch=153
06/02/2022 14:50:00 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/02/2022 14:50:02 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=154
06/02/2022 14:50:05 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.10 on epoch=155
06/02/2022 14:50:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.18 on epoch=156
06/02/2022 14:50:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=157
06/02/2022 14:50:17 - INFO - __main__ - Global step 2200 Train loss 0.10 Classification-F1 0.8473918761558623 on epoch=157
06/02/2022 14:50:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=157
06/02/2022 14:50:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=158
06/02/2022 14:50:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.11 on epoch=159
06/02/2022 14:50:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.10 on epoch=159
06/02/2022 14:50:29 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
06/02/2022 14:50:37 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.8488267316229758 on epoch=160
06/02/2022 14:50:39 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=161
06/02/2022 14:50:42 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=162
06/02/2022 14:50:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=162
06/02/2022 14:50:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=163
06/02/2022 14:50:49 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
06/02/2022 14:50:57 - INFO - __main__ - Global step 2300 Train loss 0.09 Classification-F1 0.8473918761558623 on epoch=164
06/02/2022 14:50:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=164
06/02/2022 14:51:02 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/02/2022 14:51:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/02/2022 14:51:07 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=167
06/02/2022 14:51:09 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=167
06/02/2022 14:51:17 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.8473918761558623 on epoch=167
06/02/2022 14:51:19 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
06/02/2022 14:51:22 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
06/02/2022 14:51:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
06/02/2022 14:51:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=170
06/02/2022 14:51:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=171
06/02/2022 14:51:36 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.842942487946741 on epoch=171
06/02/2022 14:51:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=172
06/02/2022 14:51:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=172
06/02/2022 14:51:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=173
06/02/2022 14:51:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=174
06/02/2022 14:51:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/02/2022 14:51:56 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.842942487946741 on epoch=174
06/02/2022 14:51:59 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=175
06/02/2022 14:52:01 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=176
06/02/2022 14:52:04 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=177
06/02/2022 14:52:06 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=177
06/02/2022 14:52:09 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=178
06/02/2022 14:52:16 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.7907338902916458 on epoch=178
06/02/2022 14:52:18 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=179
06/02/2022 14:52:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
06/02/2022 14:52:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/02/2022 14:52:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
06/02/2022 14:52:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.10 on epoch=182
06/02/2022 14:52:35 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.8466622896504138 on epoch=182
06/02/2022 14:52:38 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/02/2022 14:52:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=183
06/02/2022 14:52:43 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
06/02/2022 14:52:45 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=184
06/02/2022 14:52:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.11 on epoch=185
06/02/2022 14:52:55 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.8376206639890145 on epoch=185
06/02/2022 14:52:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/02/2022 14:53:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.09 on epoch=187
06/02/2022 14:53:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=187
06/02/2022 14:53:05 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/02/2022 14:53:07 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/02/2022 14:53:15 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.8426178126220658 on epoch=189
06/02/2022 14:53:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=189
06/02/2022 14:53:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/02/2022 14:53:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=191
06/02/2022 14:53:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
06/02/2022 14:53:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=192
06/02/2022 14:53:34 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.8426178126220658 on epoch=192
06/02/2022 14:53:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/02/2022 14:53:39 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=194
06/02/2022 14:53:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/02/2022 14:53:44 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/02/2022 14:53:47 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
06/02/2022 14:53:54 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.8450280713964219 on epoch=196
06/02/2022 14:53:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.10 on epoch=197
06/02/2022 14:53:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/02/2022 14:54:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/02/2022 14:54:04 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=199
06/02/2022 14:54:06 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/02/2022 14:54:14 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.8471786090308304 on epoch=199
06/02/2022 14:54:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/02/2022 14:54:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=201
06/02/2022 14:54:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/02/2022 14:54:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
06/02/2022 14:54:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=203
06/02/2022 14:54:35 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.8450280713964219 on epoch=203
06/02/2022 14:54:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=204
06/02/2022 14:54:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/02/2022 14:54:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/02/2022 14:54:45 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=206
06/02/2022 14:54:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=207
06/02/2022 14:54:55 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.8427292208217092 on epoch=207
06/02/2022 14:54:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=207
06/02/2022 14:55:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/02/2022 14:55:03 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
06/02/2022 14:55:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=209
06/02/2022 14:55:08 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=210
06/02/2022 14:55:15 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.9056888851876747 on epoch=210
06/02/2022 14:55:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=211
06/02/2022 14:55:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=212
06/02/2022 14:55:23 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=212
06/02/2022 14:55:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=213
06/02/2022 14:55:28 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=214
06/02/2022 14:55:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 14:55:29 - INFO - __main__ - Printing 3 examples
06/02/2022 14:55:29 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 14:55:29 - INFO - __main__ - ['Company']
06/02/2022 14:55:29 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 14:55:29 - INFO - __main__ - ['Company']
06/02/2022 14:55:29 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 14:55:29 - INFO - __main__ - ['Company']
06/02/2022 14:55:29 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:55:29 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:55:30 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 14:55:30 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 14:55:30 - INFO - __main__ - Printing 3 examples
06/02/2022 14:55:30 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 14:55:30 - INFO - __main__ - ['Company']
06/02/2022 14:55:30 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 14:55:30 - INFO - __main__ - ['Company']
06/02/2022 14:55:30 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 14:55:30 - INFO - __main__ - ['Company']
06/02/2022 14:55:30 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:55:30 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:55:30 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 14:55:36 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.8426178126220658 on epoch=214
06/02/2022 14:55:36 - INFO - __main__ - save last model!
06/02/2022 14:55:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 14:55:36 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 14:55:36 - INFO - __main__ - Printing 3 examples
06/02/2022 14:55:36 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 14:55:36 - INFO - __main__ - ['Animal']
06/02/2022 14:55:36 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 14:55:36 - INFO - __main__ - ['Animal']
06/02/2022 14:55:36 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 14:55:36 - INFO - __main__ - ['Village']
06/02/2022 14:55:36 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:55:38 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:55:41 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 14:55:48 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 14:55:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 14:55:49 - INFO - __main__ - Starting training!
06/02/2022 14:58:22 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
06/02/2022 14:58:22 - INFO - __main__ - Classification-F1 on test data: 0.6779
06/02/2022 14:58:22 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.9058077206006279, test_performance=0.6779293628764613
06/02/2022 14:58:22 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
06/02/2022 14:58:23 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 14:58:23 - INFO - __main__ - Printing 3 examples
06/02/2022 14:58:23 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 14:58:23 - INFO - __main__ - ['Company']
06/02/2022 14:58:23 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 14:58:23 - INFO - __main__ - ['Company']
06/02/2022 14:58:23 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 14:58:23 - INFO - __main__ - ['Company']
06/02/2022 14:58:23 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:58:23 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:58:23 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 14:58:23 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 14:58:23 - INFO - __main__ - Printing 3 examples
06/02/2022 14:58:23 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 14:58:23 - INFO - __main__ - ['Company']
06/02/2022 14:58:23 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 14:58:23 - INFO - __main__ - ['Company']
06/02/2022 14:58:23 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 14:58:23 - INFO - __main__ - ['Company']
06/02/2022 14:58:23 - INFO - __main__ - Tokenizing Input ...
06/02/2022 14:58:24 - INFO - __main__ - Tokenizing Output ...
06/02/2022 14:58:24 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 14:58:41 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 14:58:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 14:58:42 - INFO - __main__ - Starting training!
06/02/2022 14:58:45 - INFO - __main__ - Step 10 Global step 10 Train loss 5.97 on epoch=0
06/02/2022 14:58:47 - INFO - __main__ - Step 20 Global step 20 Train loss 5.09 on epoch=1
06/02/2022 14:58:50 - INFO - __main__ - Step 30 Global step 30 Train loss 4.60 on epoch=2
06/02/2022 14:58:52 - INFO - __main__ - Step 40 Global step 40 Train loss 4.12 on epoch=2
06/02/2022 14:58:55 - INFO - __main__ - Step 50 Global step 50 Train loss 4.07 on epoch=3
06/02/2022 14:59:00 - INFO - __main__ - Global step 50 Train loss 4.77 Classification-F1 0.059376470688687885 on epoch=3
06/02/2022 14:59:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.059376470688687885 on epoch=3, global_step=50
06/02/2022 14:59:02 - INFO - __main__ - Step 60 Global step 60 Train loss 3.55 on epoch=4
06/02/2022 14:59:05 - INFO - __main__ - Step 70 Global step 70 Train loss 3.37 on epoch=4
06/02/2022 14:59:07 - INFO - __main__ - Step 80 Global step 80 Train loss 3.19 on epoch=5
06/02/2022 14:59:10 - INFO - __main__ - Step 90 Global step 90 Train loss 2.98 on epoch=6
06/02/2022 14:59:12 - INFO - __main__ - Step 100 Global step 100 Train loss 2.96 on epoch=7
06/02/2022 14:59:17 - INFO - __main__ - Global step 100 Train loss 3.21 Classification-F1 0.08338483780609018 on epoch=7
06/02/2022 14:59:17 - INFO - __main__ - Saving model with best Classification-F1: 0.059376470688687885 -> 0.08338483780609018 on epoch=7, global_step=100
06/02/2022 14:59:20 - INFO - __main__ - Step 110 Global step 110 Train loss 2.88 on epoch=7
06/02/2022 14:59:22 - INFO - __main__ - Step 120 Global step 120 Train loss 2.55 on epoch=8
06/02/2022 14:59:25 - INFO - __main__ - Step 130 Global step 130 Train loss 2.55 on epoch=9
06/02/2022 14:59:27 - INFO - __main__ - Step 140 Global step 140 Train loss 2.38 on epoch=9
06/02/2022 14:59:30 - INFO - __main__ - Step 150 Global step 150 Train loss 2.26 on epoch=10
06/02/2022 14:59:35 - INFO - __main__ - Global step 150 Train loss 2.52 Classification-F1 0.10251679650416516 on epoch=10
06/02/2022 14:59:35 - INFO - __main__ - Saving model with best Classification-F1: 0.08338483780609018 -> 0.10251679650416516 on epoch=10, global_step=150
06/02/2022 14:59:37 - INFO - __main__ - Step 160 Global step 160 Train loss 2.24 on epoch=11
06/02/2022 14:59:40 - INFO - __main__ - Step 170 Global step 170 Train loss 2.20 on epoch=12
06/02/2022 14:59:42 - INFO - __main__ - Step 180 Global step 180 Train loss 2.21 on epoch=12
06/02/2022 14:59:44 - INFO - __main__ - Step 190 Global step 190 Train loss 1.87 on epoch=13
06/02/2022 14:59:47 - INFO - __main__ - Step 200 Global step 200 Train loss 2.03 on epoch=14
06/02/2022 14:59:52 - INFO - __main__ - Global step 200 Train loss 2.11 Classification-F1 0.12456595388445 on epoch=14
06/02/2022 14:59:52 - INFO - __main__ - Saving model with best Classification-F1: 0.10251679650416516 -> 0.12456595388445 on epoch=14, global_step=200
06/02/2022 14:59:54 - INFO - __main__ - Step 210 Global step 210 Train loss 2.01 on epoch=14
06/02/2022 14:59:57 - INFO - __main__ - Step 220 Global step 220 Train loss 1.94 on epoch=15
06/02/2022 14:59:59 - INFO - __main__ - Step 230 Global step 230 Train loss 1.75 on epoch=16
06/02/2022 15:00:02 - INFO - __main__ - Step 240 Global step 240 Train loss 1.84 on epoch=17
06/02/2022 15:00:04 - INFO - __main__ - Step 250 Global step 250 Train loss 1.77 on epoch=17
06/02/2022 15:00:09 - INFO - __main__ - Global step 250 Train loss 1.86 Classification-F1 0.13715280928851564 on epoch=17
06/02/2022 15:00:09 - INFO - __main__ - Saving model with best Classification-F1: 0.12456595388445 -> 0.13715280928851564 on epoch=17, global_step=250
06/02/2022 15:00:12 - INFO - __main__ - Step 260 Global step 260 Train loss 1.72 on epoch=18
06/02/2022 15:00:14 - INFO - __main__ - Step 270 Global step 270 Train loss 1.71 on epoch=19
06/02/2022 15:00:17 - INFO - __main__ - Step 280 Global step 280 Train loss 1.77 on epoch=19
06/02/2022 15:00:19 - INFO - __main__ - Step 290 Global step 290 Train loss 1.59 on epoch=20
06/02/2022 15:00:22 - INFO - __main__ - Step 300 Global step 300 Train loss 1.54 on epoch=21
06/02/2022 15:00:27 - INFO - __main__ - Global step 300 Train loss 1.67 Classification-F1 0.1849440442571698 on epoch=21
06/02/2022 15:00:27 - INFO - __main__ - Saving model with best Classification-F1: 0.13715280928851564 -> 0.1849440442571698 on epoch=21, global_step=300
06/02/2022 15:00:29 - INFO - __main__ - Step 310 Global step 310 Train loss 1.46 on epoch=22
06/02/2022 15:00:32 - INFO - __main__ - Step 320 Global step 320 Train loss 1.39 on epoch=22
06/02/2022 15:00:34 - INFO - __main__ - Step 330 Global step 330 Train loss 1.37 on epoch=23
06/02/2022 15:00:37 - INFO - __main__ - Step 340 Global step 340 Train loss 1.43 on epoch=24
06/02/2022 15:00:39 - INFO - __main__ - Step 350 Global step 350 Train loss 1.38 on epoch=24
06/02/2022 15:00:45 - INFO - __main__ - Global step 350 Train loss 1.41 Classification-F1 0.2186455250235465 on epoch=24
06/02/2022 15:00:45 - INFO - __main__ - Saving model with best Classification-F1: 0.1849440442571698 -> 0.2186455250235465 on epoch=24, global_step=350
06/02/2022 15:00:47 - INFO - __main__ - Step 360 Global step 360 Train loss 1.38 on epoch=25
06/02/2022 15:00:50 - INFO - __main__ - Step 370 Global step 370 Train loss 1.30 on epoch=26
06/02/2022 15:00:52 - INFO - __main__ - Step 380 Global step 380 Train loss 1.23 on epoch=27
06/02/2022 15:00:55 - INFO - __main__ - Step 390 Global step 390 Train loss 1.19 on epoch=27
06/02/2022 15:00:57 - INFO - __main__ - Step 400 Global step 400 Train loss 1.15 on epoch=28
06/02/2022 15:01:02 - INFO - __main__ - Global step 400 Train loss 1.25 Classification-F1 0.2982988803970857 on epoch=28
06/02/2022 15:01:02 - INFO - __main__ - Saving model with best Classification-F1: 0.2186455250235465 -> 0.2982988803970857 on epoch=28, global_step=400
06/02/2022 15:01:05 - INFO - __main__ - Step 410 Global step 410 Train loss 1.09 on epoch=29
06/02/2022 15:01:07 - INFO - __main__ - Step 420 Global step 420 Train loss 1.08 on epoch=29
06/02/2022 15:01:10 - INFO - __main__ - Step 430 Global step 430 Train loss 1.05 on epoch=30
06/02/2022 15:01:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.91 on epoch=31
06/02/2022 15:01:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.94 on epoch=32
06/02/2022 15:01:20 - INFO - __main__ - Global step 450 Train loss 1.02 Classification-F1 0.41513138588768844 on epoch=32
06/02/2022 15:01:20 - INFO - __main__ - Saving model with best Classification-F1: 0.2982988803970857 -> 0.41513138588768844 on epoch=32, global_step=450
06/02/2022 15:01:23 - INFO - __main__ - Step 460 Global step 460 Train loss 1.01 on epoch=32
06/02/2022 15:01:25 - INFO - __main__ - Step 470 Global step 470 Train loss 0.98 on epoch=33
06/02/2022 15:01:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.93 on epoch=34
06/02/2022 15:01:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.86 on epoch=34
06/02/2022 15:01:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.90 on epoch=35
06/02/2022 15:01:38 - INFO - __main__ - Global step 500 Train loss 0.94 Classification-F1 0.4269375426938452 on epoch=35
06/02/2022 15:01:38 - INFO - __main__ - Saving model with best Classification-F1: 0.41513138588768844 -> 0.4269375426938452 on epoch=35, global_step=500
06/02/2022 15:01:41 - INFO - __main__ - Step 510 Global step 510 Train loss 0.79 on epoch=36
06/02/2022 15:01:43 - INFO - __main__ - Step 520 Global step 520 Train loss 0.72 on epoch=37
06/02/2022 15:01:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.76 on epoch=37
06/02/2022 15:01:48 - INFO - __main__ - Step 540 Global step 540 Train loss 0.69 on epoch=38
06/02/2022 15:01:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.74 on epoch=39
06/02/2022 15:01:57 - INFO - __main__ - Global step 550 Train loss 0.74 Classification-F1 0.46179074475220516 on epoch=39
06/02/2022 15:01:57 - INFO - __main__ - Saving model with best Classification-F1: 0.4269375426938452 -> 0.46179074475220516 on epoch=39, global_step=550
06/02/2022 15:02:00 - INFO - __main__ - Step 560 Global step 560 Train loss 0.70 on epoch=39
06/02/2022 15:02:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.73 on epoch=40
06/02/2022 15:02:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.63 on epoch=41
06/02/2022 15:02:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.66 on epoch=42
06/02/2022 15:02:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.69 on epoch=42
06/02/2022 15:02:16 - INFO - __main__ - Global step 600 Train loss 0.68 Classification-F1 0.4806547160408641 on epoch=42
06/02/2022 15:02:16 - INFO - __main__ - Saving model with best Classification-F1: 0.46179074475220516 -> 0.4806547160408641 on epoch=42, global_step=600
06/02/2022 15:02:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.63 on epoch=43
06/02/2022 15:02:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.62 on epoch=44
06/02/2022 15:02:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.62 on epoch=44
06/02/2022 15:02:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.56 on epoch=45
06/02/2022 15:02:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.65 on epoch=46
06/02/2022 15:02:35 - INFO - __main__ - Global step 650 Train loss 0.61 Classification-F1 0.5348782715179127 on epoch=46
06/02/2022 15:02:35 - INFO - __main__ - Saving model with best Classification-F1: 0.4806547160408641 -> 0.5348782715179127 on epoch=46, global_step=650
06/02/2022 15:02:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.64 on epoch=47
06/02/2022 15:02:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.49 on epoch=47
06/02/2022 15:02:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.54 on epoch=48
06/02/2022 15:02:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.52 on epoch=49
06/02/2022 15:02:48 - INFO - __main__ - Step 700 Global step 700 Train loss 0.62 on epoch=49
06/02/2022 15:02:54 - INFO - __main__ - Global step 700 Train loss 0.56 Classification-F1 0.5229099226727311 on epoch=49
06/02/2022 15:02:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.50 on epoch=50
06/02/2022 15:02:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.54 on epoch=51
06/02/2022 15:03:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.55 on epoch=52
06/02/2022 15:03:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.46 on epoch=52
06/02/2022 15:03:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.46 on epoch=53
06/02/2022 15:03:13 - INFO - __main__ - Global step 750 Train loss 0.50 Classification-F1 0.5807668095230626 on epoch=53
06/02/2022 15:03:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5348782715179127 -> 0.5807668095230626 on epoch=53, global_step=750
06/02/2022 15:03:16 - INFO - __main__ - Step 760 Global step 760 Train loss 0.49 on epoch=54
06/02/2022 15:03:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.52 on epoch=54
06/02/2022 15:03:21 - INFO - __main__ - Step 780 Global step 780 Train loss 0.46 on epoch=55
06/02/2022 15:03:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.36 on epoch=56
06/02/2022 15:03:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.50 on epoch=57
06/02/2022 15:03:32 - INFO - __main__ - Global step 800 Train loss 0.47 Classification-F1 0.5104228426854612 on epoch=57
06/02/2022 15:03:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.49 on epoch=57
06/02/2022 15:03:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.36 on epoch=58
06/02/2022 15:03:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.47 on epoch=59
06/02/2022 15:03:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.42 on epoch=59
06/02/2022 15:03:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.39 on epoch=60
06/02/2022 15:03:51 - INFO - __main__ - Global step 850 Train loss 0.43 Classification-F1 0.6170109881684834 on epoch=60
06/02/2022 15:03:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5807668095230626 -> 0.6170109881684834 on epoch=60, global_step=850
06/02/2022 15:03:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.39 on epoch=61
06/02/2022 15:03:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.36 on epoch=62
06/02/2022 15:03:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.42 on epoch=62
06/02/2022 15:04:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.40 on epoch=63
06/02/2022 15:04:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.44 on epoch=64
06/02/2022 15:04:11 - INFO - __main__ - Global step 900 Train loss 0.40 Classification-F1 0.6215466196253674 on epoch=64
06/02/2022 15:04:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6170109881684834 -> 0.6215466196253674 on epoch=64, global_step=900
06/02/2022 15:04:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.31 on epoch=64
06/02/2022 15:04:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.29 on epoch=65
06/02/2022 15:04:18 - INFO - __main__ - Step 930 Global step 930 Train loss 0.41 on epoch=66
06/02/2022 15:04:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.42 on epoch=67
06/02/2022 15:04:23 - INFO - __main__ - Step 950 Global step 950 Train loss 0.40 on epoch=67
06/02/2022 15:04:30 - INFO - __main__ - Global step 950 Train loss 0.37 Classification-F1 0.6218841788914979 on epoch=67
06/02/2022 15:04:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6215466196253674 -> 0.6218841788914979 on epoch=67, global_step=950
06/02/2022 15:04:32 - INFO - __main__ - Step 960 Global step 960 Train loss 0.30 on epoch=68
06/02/2022 15:04:35 - INFO - __main__ - Step 970 Global step 970 Train loss 0.35 on epoch=69
06/02/2022 15:04:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.30 on epoch=69
06/02/2022 15:04:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.28 on epoch=70
06/02/2022 15:04:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.36 on epoch=71
06/02/2022 15:04:49 - INFO - __main__ - Global step 1000 Train loss 0.32 Classification-F1 0.635095376829123 on epoch=71
06/02/2022 15:04:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6218841788914979 -> 0.635095376829123 on epoch=71, global_step=1000
06/02/2022 15:04:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.36 on epoch=72
06/02/2022 15:04:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.34 on epoch=72
06/02/2022 15:04:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.36 on epoch=73
06/02/2022 15:04:59 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.31 on epoch=74
06/02/2022 15:05:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.41 on epoch=74
06/02/2022 15:05:09 - INFO - __main__ - Global step 1050 Train loss 0.35 Classification-F1 0.6385267283844135 on epoch=74
06/02/2022 15:05:09 - INFO - __main__ - Saving model with best Classification-F1: 0.635095376829123 -> 0.6385267283844135 on epoch=74, global_step=1050
06/02/2022 15:05:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.26 on epoch=75
06/02/2022 15:05:14 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.30 on epoch=76
06/02/2022 15:05:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.36 on epoch=77
06/02/2022 15:05:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.34 on epoch=77
06/02/2022 15:05:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.26 on epoch=78
06/02/2022 15:05:28 - INFO - __main__ - Global step 1100 Train loss 0.30 Classification-F1 0.6611006468591608 on epoch=78
06/02/2022 15:05:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6385267283844135 -> 0.6611006468591608 on epoch=78, global_step=1100
06/02/2022 15:05:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.30 on epoch=79
06/02/2022 15:05:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.25 on epoch=79
06/02/2022 15:05:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.29 on epoch=80
06/02/2022 15:05:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.37 on epoch=81
06/02/2022 15:05:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.29 on epoch=82
06/02/2022 15:05:47 - INFO - __main__ - Global step 1150 Train loss 0.30 Classification-F1 0.6208802104757988 on epoch=82
06/02/2022 15:05:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.33 on epoch=82
06/02/2022 15:05:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.25 on epoch=83
06/02/2022 15:05:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.26 on epoch=84
06/02/2022 15:05:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.26 on epoch=84
06/02/2022 15:06:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.29 on epoch=85
06/02/2022 15:06:07 - INFO - __main__ - Global step 1200 Train loss 0.28 Classification-F1 0.7001373531263536 on epoch=85
06/02/2022 15:06:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6611006468591608 -> 0.7001373531263536 on epoch=85, global_step=1200
06/02/2022 15:06:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.28 on epoch=86
06/02/2022 15:06:12 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.23 on epoch=87
06/02/2022 15:06:14 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.30 on epoch=87
06/02/2022 15:06:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.24 on epoch=88
06/02/2022 15:06:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.27 on epoch=89
06/02/2022 15:06:26 - INFO - __main__ - Global step 1250 Train loss 0.26 Classification-F1 0.6630640773055634 on epoch=89
06/02/2022 15:06:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.29 on epoch=89
06/02/2022 15:06:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.26 on epoch=90
06/02/2022 15:06:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.31 on epoch=91
06/02/2022 15:06:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.25 on epoch=92
06/02/2022 15:06:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.20 on epoch=92
06/02/2022 15:06:46 - INFO - __main__ - Global step 1300 Train loss 0.26 Classification-F1 0.651257957728546 on epoch=92
06/02/2022 15:06:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.22 on epoch=93
06/02/2022 15:06:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.27 on epoch=94
06/02/2022 15:06:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.22 on epoch=94
06/02/2022 15:06:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.19 on epoch=95
06/02/2022 15:06:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.23 on epoch=96
06/02/2022 15:07:05 - INFO - __main__ - Global step 1350 Train loss 0.23 Classification-F1 0.7076256849541163 on epoch=96
06/02/2022 15:07:05 - INFO - __main__ - Saving model with best Classification-F1: 0.7001373531263536 -> 0.7076256849541163 on epoch=96, global_step=1350
06/02/2022 15:07:08 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.26 on epoch=97
06/02/2022 15:07:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.26 on epoch=97
06/02/2022 15:07:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.23 on epoch=98
06/02/2022 15:07:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.30 on epoch=99
06/02/2022 15:07:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.30 on epoch=99
06/02/2022 15:07:24 - INFO - __main__ - Global step 1400 Train loss 0.27 Classification-F1 0.6103370641185767 on epoch=99
06/02/2022 15:07:27 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.19 on epoch=100
06/02/2022 15:07:29 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.19 on epoch=101
06/02/2022 15:07:32 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.19 on epoch=102
06/02/2022 15:07:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.26 on epoch=102
06/02/2022 15:07:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.17 on epoch=103
06/02/2022 15:07:44 - INFO - __main__ - Global step 1450 Train loss 0.20 Classification-F1 0.7446211740329388 on epoch=103
06/02/2022 15:07:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7076256849541163 -> 0.7446211740329388 on epoch=103, global_step=1450
06/02/2022 15:07:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.19 on epoch=104
06/02/2022 15:07:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.20 on epoch=104
06/02/2022 15:07:52 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.19 on epoch=105
06/02/2022 15:07:54 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.24 on epoch=106
06/02/2022 15:07:57 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.21 on epoch=107
06/02/2022 15:08:04 - INFO - __main__ - Global step 1500 Train loss 0.21 Classification-F1 0.7428324534942183 on epoch=107
06/02/2022 15:08:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=107
06/02/2022 15:08:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.21 on epoch=108
06/02/2022 15:08:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=109
06/02/2022 15:08:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.20 on epoch=109
06/02/2022 15:08:16 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.23 on epoch=110
06/02/2022 15:08:23 - INFO - __main__ - Global step 1550 Train loss 0.20 Classification-F1 0.6660285204991088 on epoch=110
06/02/2022 15:08:26 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.17 on epoch=111
06/02/2022 15:08:28 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.19 on epoch=112
06/02/2022 15:08:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.28 on epoch=112
06/02/2022 15:08:33 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.21 on epoch=113
06/02/2022 15:08:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.19 on epoch=114
06/02/2022 15:08:43 - INFO - __main__ - Global step 1600 Train loss 0.21 Classification-F1 0.7481269275386924 on epoch=114
06/02/2022 15:08:43 - INFO - __main__ - Saving model with best Classification-F1: 0.7446211740329388 -> 0.7481269275386924 on epoch=114, global_step=1600
06/02/2022 15:08:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.18 on epoch=114
06/02/2022 15:08:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.16 on epoch=115
06/02/2022 15:08:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.23 on epoch=116
06/02/2022 15:08:53 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.16 on epoch=117
06/02/2022 15:08:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.21 on epoch=117
06/02/2022 15:09:03 - INFO - __main__ - Global step 1650 Train loss 0.19 Classification-F1 0.748661030686811 on epoch=117
06/02/2022 15:09:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7481269275386924 -> 0.748661030686811 on epoch=117, global_step=1650
06/02/2022 15:09:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.16 on epoch=118
06/02/2022 15:09:08 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.17 on epoch=119
06/02/2022 15:09:10 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.17 on epoch=119
06/02/2022 15:09:13 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=120
06/02/2022 15:09:15 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.15 on epoch=121
06/02/2022 15:09:22 - INFO - __main__ - Global step 1700 Train loss 0.15 Classification-F1 0.7508321673407062 on epoch=121
06/02/2022 15:09:22 - INFO - __main__ - Saving model with best Classification-F1: 0.748661030686811 -> 0.7508321673407062 on epoch=121, global_step=1700
06/02/2022 15:09:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.17 on epoch=122
06/02/2022 15:09:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.16 on epoch=122
06/02/2022 15:09:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.17 on epoch=123
06/02/2022 15:09:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.21 on epoch=124
06/02/2022 15:09:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.25 on epoch=124
06/02/2022 15:09:41 - INFO - __main__ - Global step 1750 Train loss 0.19 Classification-F1 0.7528632306620922 on epoch=124
06/02/2022 15:09:41 - INFO - __main__ - Saving model with best Classification-F1: 0.7508321673407062 -> 0.7528632306620922 on epoch=124, global_step=1750
06/02/2022 15:09:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.17 on epoch=125
06/02/2022 15:09:46 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.22 on epoch=126
06/02/2022 15:09:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=127
06/02/2022 15:09:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.22 on epoch=127
06/02/2022 15:09:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.14 on epoch=128
06/02/2022 15:10:01 - INFO - __main__ - Global step 1800 Train loss 0.17 Classification-F1 0.799165432086238 on epoch=128
06/02/2022 15:10:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7528632306620922 -> 0.799165432086238 on epoch=128, global_step=1800
06/02/2022 15:10:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=129
06/02/2022 15:10:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.21 on epoch=129
06/02/2022 15:10:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.16 on epoch=130
06/02/2022 15:10:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.15 on epoch=131
06/02/2022 15:10:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.16 on epoch=132
06/02/2022 15:10:20 - INFO - __main__ - Global step 1850 Train loss 0.16 Classification-F1 0.7953241315977594 on epoch=132
06/02/2022 15:10:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.16 on epoch=132
06/02/2022 15:10:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.17 on epoch=133
06/02/2022 15:10:28 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.15 on epoch=134
06/02/2022 15:10:30 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.10 on epoch=134
06/02/2022 15:10:33 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=135
06/02/2022 15:10:40 - INFO - __main__ - Global step 1900 Train loss 0.14 Classification-F1 0.7953241315977594 on epoch=135
06/02/2022 15:10:42 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.11 on epoch=136
06/02/2022 15:10:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.20 on epoch=137
06/02/2022 15:10:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.14 on epoch=137
06/02/2022 15:10:50 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.14 on epoch=138
06/02/2022 15:10:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.14 on epoch=139
06/02/2022 15:10:59 - INFO - __main__ - Global step 1950 Train loss 0.15 Classification-F1 0.8511255821976884 on epoch=139
06/02/2022 15:11:00 - INFO - __main__ - Saving model with best Classification-F1: 0.799165432086238 -> 0.8511255821976884 on epoch=139, global_step=1950
06/02/2022 15:11:02 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.20 on epoch=139
06/02/2022 15:11:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.13 on epoch=140
06/02/2022 15:11:07 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.22 on epoch=141
06/02/2022 15:11:10 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.16 on epoch=142
06/02/2022 15:11:12 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.13 on epoch=142
06/02/2022 15:11:19 - INFO - __main__ - Global step 2000 Train loss 0.17 Classification-F1 0.802845496487365 on epoch=142
06/02/2022 15:11:22 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.16 on epoch=143
06/02/2022 15:11:24 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.13 on epoch=144
06/02/2022 15:11:27 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.14 on epoch=144
06/02/2022 15:11:29 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.12 on epoch=145
06/02/2022 15:11:32 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.12 on epoch=146
06/02/2022 15:11:39 - INFO - __main__ - Global step 2050 Train loss 0.14 Classification-F1 0.8550356506238859 on epoch=146
06/02/2022 15:11:39 - INFO - __main__ - Saving model with best Classification-F1: 0.8511255821976884 -> 0.8550356506238859 on epoch=146, global_step=2050
06/02/2022 15:11:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.14 on epoch=147
06/02/2022 15:11:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.14 on epoch=147
06/02/2022 15:11:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=148
06/02/2022 15:11:49 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.12 on epoch=149
06/02/2022 15:11:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.15 on epoch=149
06/02/2022 15:11:59 - INFO - __main__ - Global step 2100 Train loss 0.14 Classification-F1 0.802845496487365 on epoch=149
06/02/2022 15:12:01 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.14 on epoch=150
06/02/2022 15:12:04 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.18 on epoch=151
06/02/2022 15:12:06 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.14 on epoch=152
06/02/2022 15:12:09 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.10 on epoch=152
06/02/2022 15:12:11 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.11 on epoch=153
06/02/2022 15:12:18 - INFO - __main__ - Global step 2150 Train loss 0.13 Classification-F1 0.8509542688548775 on epoch=153
06/02/2022 15:12:21 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.17 on epoch=154
06/02/2022 15:12:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=154
06/02/2022 15:12:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=155
06/02/2022 15:12:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.13 on epoch=156
06/02/2022 15:12:31 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=157
06/02/2022 15:12:38 - INFO - __main__ - Global step 2200 Train loss 0.12 Classification-F1 0.8550356506238859 on epoch=157
06/02/2022 15:12:41 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.10 on epoch=157
06/02/2022 15:12:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.12 on epoch=158
06/02/2022 15:12:46 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.14 on epoch=159
06/02/2022 15:12:48 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.16 on epoch=159
06/02/2022 15:12:51 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.14 on epoch=160
06/02/2022 15:12:58 - INFO - __main__ - Global step 2250 Train loss 0.13 Classification-F1 0.8509542688548775 on epoch=160
06/02/2022 15:13:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=161
06/02/2022 15:13:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.11 on epoch=162
06/02/2022 15:13:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.16 on epoch=162
06/02/2022 15:13:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.10 on epoch=163
06/02/2022 15:13:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.14 on epoch=164
06/02/2022 15:13:18 - INFO - __main__ - Global step 2300 Train loss 0.12 Classification-F1 0.8508428606552338 on epoch=164
06/02/2022 15:13:20 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.11 on epoch=164
06/02/2022 15:13:23 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
06/02/2022 15:13:25 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.10 on epoch=166
06/02/2022 15:13:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.13 on epoch=167
06/02/2022 15:13:30 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.17 on epoch=167
06/02/2022 15:13:38 - INFO - __main__ - Global step 2350 Train loss 0.11 Classification-F1 0.8547759294839383 on epoch=167
06/02/2022 15:13:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.10 on epoch=168
06/02/2022 15:13:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.11 on epoch=169
06/02/2022 15:13:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.13 on epoch=169
06/02/2022 15:13:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.12 on epoch=170
06/02/2022 15:13:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.10 on epoch=171
06/02/2022 15:13:57 - INFO - __main__ - Global step 2400 Train loss 0.11 Classification-F1 0.8508428606552338 on epoch=171
06/02/2022 15:14:00 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.12 on epoch=172
06/02/2022 15:14:02 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.13 on epoch=172
06/02/2022 15:14:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
06/02/2022 15:14:07 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.13 on epoch=174
06/02/2022 15:14:10 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.16 on epoch=174
06/02/2022 15:14:17 - INFO - __main__ - Global step 2450 Train loss 0.12 Classification-F1 0.8508428606552338 on epoch=174
06/02/2022 15:14:20 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.12 on epoch=175
06/02/2022 15:14:22 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.20 on epoch=176
06/02/2022 15:14:25 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.11 on epoch=177
06/02/2022 15:14:27 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=177
06/02/2022 15:14:30 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.10 on epoch=178
06/02/2022 15:14:37 - INFO - __main__ - Global step 2500 Train loss 0.12 Classification-F1 0.7988957474098596 on epoch=178
06/02/2022 15:14:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=179
06/02/2022 15:14:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=179
06/02/2022 15:14:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=180
06/02/2022 15:14:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=181
06/02/2022 15:14:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.11 on epoch=182
06/02/2022 15:14:57 - INFO - __main__ - Global step 2550 Train loss 0.08 Classification-F1 0.7988957474098596 on epoch=182
06/02/2022 15:15:00 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.10 on epoch=182
06/02/2022 15:15:02 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.11 on epoch=183
06/02/2022 15:15:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.12 on epoch=184
06/02/2022 15:15:07 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=184
06/02/2022 15:15:10 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.10 on epoch=185
06/02/2022 15:15:17 - INFO - __main__ - Global step 2600 Train loss 0.10 Classification-F1 0.7932965023642479 on epoch=185
06/02/2022 15:15:19 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.11 on epoch=186
06/02/2022 15:15:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
06/02/2022 15:15:24 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/02/2022 15:15:27 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.19 on epoch=188
06/02/2022 15:15:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=189
06/02/2022 15:15:37 - INFO - __main__ - Global step 2650 Train loss 0.10 Classification-F1 0.7968717119892397 on epoch=189
06/02/2022 15:15:39 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.10 on epoch=189
06/02/2022 15:15:42 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=190
06/02/2022 15:15:44 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.16 on epoch=191
06/02/2022 15:15:47 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.11 on epoch=192
06/02/2022 15:15:49 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.12 on epoch=192
06/02/2022 15:15:56 - INFO - __main__ - Global step 2700 Train loss 0.11 Classification-F1 0.7526010613231708 on epoch=192
06/02/2022 15:15:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=193
06/02/2022 15:16:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.10 on epoch=194
06/02/2022 15:16:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.09 on epoch=194
06/02/2022 15:16:06 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=195
06/02/2022 15:16:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.11 on epoch=196
06/02/2022 15:16:16 - INFO - __main__ - Global step 2750 Train loss 0.09 Classification-F1 0.7988957474098596 on epoch=196
06/02/2022 15:16:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=197
06/02/2022 15:16:21 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.09 on epoch=197
06/02/2022 15:16:24 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.09 on epoch=198
06/02/2022 15:16:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.11 on epoch=199
06/02/2022 15:16:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
06/02/2022 15:16:36 - INFO - __main__ - Global step 2800 Train loss 0.08 Classification-F1 0.7988957474098596 on epoch=199
06/02/2022 15:16:38 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.10 on epoch=200
06/02/2022 15:16:41 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.10 on epoch=201
06/02/2022 15:16:43 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=202
06/02/2022 15:16:46 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=202
06/02/2022 15:16:48 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.14 on epoch=203
06/02/2022 15:16:56 - INFO - __main__ - Global step 2850 Train loss 0.09 Classification-F1 0.7988957474098596 on epoch=203
06/02/2022 15:16:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=204
06/02/2022 15:17:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=204
06/02/2022 15:17:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.08 on epoch=205
06/02/2022 15:17:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=206
06/02/2022 15:17:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.13 on epoch=207
06/02/2022 15:17:16 - INFO - __main__ - Global step 2900 Train loss 0.09 Classification-F1 0.7968717119892397 on epoch=207
06/02/2022 15:17:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.10 on epoch=207
06/02/2022 15:17:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.10 on epoch=208
06/02/2022 15:17:23 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=209
06/02/2022 15:17:26 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.09 on epoch=209
06/02/2022 15:17:28 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
06/02/2022 15:17:36 - INFO - __main__ - Global step 2950 Train loss 0.08 Classification-F1 0.8488267316229758 on epoch=210
06/02/2022 15:17:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.11 on epoch=211
06/02/2022 15:17:41 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=212
06/02/2022 15:17:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=212
06/02/2022 15:17:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=213
06/02/2022 15:17:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.08 on epoch=214
06/02/2022 15:17:50 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 15:17:50 - INFO - __main__ - Printing 3 examples
06/02/2022 15:17:50 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 15:17:50 - INFO - __main__ - ['Film']
06/02/2022 15:17:50 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 15:17:50 - INFO - __main__ - ['Film']
06/02/2022 15:17:50 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 15:17:50 - INFO - __main__ - ['Film']
06/02/2022 15:17:50 - INFO - __main__ - Tokenizing Input ...
06/02/2022 15:17:50 - INFO - __main__ - Tokenizing Output ...
06/02/2022 15:17:50 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 15:17:50 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 15:17:50 - INFO - __main__ - Printing 3 examples
06/02/2022 15:17:50 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 15:17:50 - INFO - __main__ - ['Film']
06/02/2022 15:17:50 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 15:17:50 - INFO - __main__ - ['Film']
06/02/2022 15:17:50 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 15:17:50 - INFO - __main__ - ['Film']
06/02/2022 15:17:50 - INFO - __main__ - Tokenizing Input ...
06/02/2022 15:17:51 - INFO - __main__ - Tokenizing Output ...
06/02/2022 15:17:51 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 15:17:56 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.8488267316229758 on epoch=214
06/02/2022 15:17:56 - INFO - __main__ - save last model!
06/02/2022 15:17:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 15:17:57 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 15:17:57 - INFO - __main__ - Printing 3 examples
06/02/2022 15:17:57 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 15:17:57 - INFO - __main__ - ['Animal']
06/02/2022 15:17:57 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 15:17:57 - INFO - __main__ - ['Animal']
06/02/2022 15:17:57 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 15:17:57 - INFO - __main__ - ['Village']
06/02/2022 15:17:57 - INFO - __main__ - Tokenizing Input ...
06/02/2022 15:17:58 - INFO - __main__ - Tokenizing Output ...
06/02/2022 15:18:02 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 15:18:09 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 15:18:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 15:18:10 - INFO - __main__ - Starting training!
06/02/2022 15:20:16 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
06/02/2022 15:20:17 - INFO - __main__ - Classification-F1 on test data: 0.6186
06/02/2022 15:20:17 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.8550356506238859, test_performance=0.618584325292149
06/02/2022 15:20:17 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
06/02/2022 15:20:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 15:20:18 - INFO - __main__ - Printing 3 examples
06/02/2022 15:20:18 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 15:20:18 - INFO - __main__ - ['Film']
06/02/2022 15:20:18 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 15:20:18 - INFO - __main__ - ['Film']
06/02/2022 15:20:18 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 15:20:18 - INFO - __main__ - ['Film']
06/02/2022 15:20:18 - INFO - __main__ - Tokenizing Input ...
06/02/2022 15:20:18 - INFO - __main__ - Tokenizing Output ...
06/02/2022 15:20:18 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 15:20:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 15:20:18 - INFO - __main__ - Printing 3 examples
06/02/2022 15:20:18 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 15:20:18 - INFO - __main__ - ['Film']
06/02/2022 15:20:18 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 15:20:18 - INFO - __main__ - ['Film']
06/02/2022 15:20:18 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 15:20:18 - INFO - __main__ - ['Film']
06/02/2022 15:20:18 - INFO - __main__ - Tokenizing Input ...
06/02/2022 15:20:18 - INFO - __main__ - Tokenizing Output ...
06/02/2022 15:20:18 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 15:20:36 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 15:20:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 15:20:37 - INFO - __main__ - Starting training!
06/02/2022 15:20:40 - INFO - __main__ - Step 10 Global step 10 Train loss 6.06 on epoch=0
06/02/2022 15:20:43 - INFO - __main__ - Step 20 Global step 20 Train loss 3.95 on epoch=1
06/02/2022 15:20:45 - INFO - __main__ - Step 30 Global step 30 Train loss 3.51 on epoch=2
06/02/2022 15:20:48 - INFO - __main__ - Step 40 Global step 40 Train loss 2.94 on epoch=2
06/02/2022 15:20:50 - INFO - __main__ - Step 50 Global step 50 Train loss 2.74 on epoch=3
06/02/2022 15:20:55 - INFO - __main__ - Global step 50 Train loss 3.84 Classification-F1 0.11696043381410375 on epoch=3
06/02/2022 15:20:55 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11696043381410375 on epoch=3, global_step=50
06/02/2022 15:20:58 - INFO - __main__ - Step 60 Global step 60 Train loss 2.44 on epoch=4
06/02/2022 15:21:00 - INFO - __main__ - Step 70 Global step 70 Train loss 2.05 on epoch=4
06/02/2022 15:21:03 - INFO - __main__ - Step 80 Global step 80 Train loss 2.29 on epoch=5
06/02/2022 15:21:05 - INFO - __main__ - Step 90 Global step 90 Train loss 1.88 on epoch=6
06/02/2022 15:21:08 - INFO - __main__ - Step 100 Global step 100 Train loss 1.90 on epoch=7
06/02/2022 15:21:13 - INFO - __main__ - Global step 100 Train loss 2.11 Classification-F1 0.16654739118753295 on epoch=7
06/02/2022 15:21:13 - INFO - __main__ - Saving model with best Classification-F1: 0.11696043381410375 -> 0.16654739118753295 on epoch=7, global_step=100
06/02/2022 15:21:15 - INFO - __main__ - Step 110 Global step 110 Train loss 1.62 on epoch=7
06/02/2022 15:21:18 - INFO - __main__ - Step 120 Global step 120 Train loss 1.74 on epoch=8
06/02/2022 15:21:20 - INFO - __main__ - Step 130 Global step 130 Train loss 1.61 on epoch=9
06/02/2022 15:21:23 - INFO - __main__ - Step 140 Global step 140 Train loss 1.40 on epoch=9
06/02/2022 15:21:25 - INFO - __main__ - Step 150 Global step 150 Train loss 1.49 on epoch=10
06/02/2022 15:21:31 - INFO - __main__ - Global step 150 Train loss 1.57 Classification-F1 0.2703601412231063 on epoch=10
06/02/2022 15:21:31 - INFO - __main__ - Saving model with best Classification-F1: 0.16654739118753295 -> 0.2703601412231063 on epoch=10, global_step=150
06/02/2022 15:21:33 - INFO - __main__ - Step 160 Global step 160 Train loss 1.05 on epoch=11
06/02/2022 15:21:36 - INFO - __main__ - Step 170 Global step 170 Train loss 1.17 on epoch=12
06/02/2022 15:21:38 - INFO - __main__ - Step 180 Global step 180 Train loss 0.96 on epoch=12
06/02/2022 15:21:41 - INFO - __main__ - Step 190 Global step 190 Train loss 1.00 on epoch=13
06/02/2022 15:21:43 - INFO - __main__ - Step 200 Global step 200 Train loss 0.90 on epoch=14
06/02/2022 15:21:49 - INFO - __main__ - Global step 200 Train loss 1.02 Classification-F1 0.4819138092836712 on epoch=14
06/02/2022 15:21:49 - INFO - __main__ - Saving model with best Classification-F1: 0.2703601412231063 -> 0.4819138092836712 on epoch=14, global_step=200
06/02/2022 15:21:51 - INFO - __main__ - Step 210 Global step 210 Train loss 0.72 on epoch=14
06/02/2022 15:21:54 - INFO - __main__ - Step 220 Global step 220 Train loss 0.72 on epoch=15
06/02/2022 15:21:56 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=16
06/02/2022 15:21:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.65 on epoch=17
06/02/2022 15:22:02 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=17
06/02/2022 15:22:08 - INFO - __main__ - Global step 250 Train loss 0.66 Classification-F1 0.5304494869602417 on epoch=17
06/02/2022 15:22:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4819138092836712 -> 0.5304494869602417 on epoch=17, global_step=250
06/02/2022 15:22:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.68 on epoch=18
06/02/2022 15:22:13 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=19
06/02/2022 15:22:16 - INFO - __main__ - Step 280 Global step 280 Train loss 0.57 on epoch=19
06/02/2022 15:22:18 - INFO - __main__ - Step 290 Global step 290 Train loss 0.54 on epoch=20
06/02/2022 15:22:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.42 on epoch=21
06/02/2022 15:22:27 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.49838427871915375 on epoch=21
06/02/2022 15:22:30 - INFO - __main__ - Step 310 Global step 310 Train loss 0.50 on epoch=22
06/02/2022 15:22:32 - INFO - __main__ - Step 320 Global step 320 Train loss 0.47 on epoch=22
06/02/2022 15:22:35 - INFO - __main__ - Step 330 Global step 330 Train loss 0.43 on epoch=23
06/02/2022 15:22:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.45 on epoch=24
06/02/2022 15:22:40 - INFO - __main__ - Step 350 Global step 350 Train loss 0.34 on epoch=24
06/02/2022 15:22:46 - INFO - __main__ - Global step 350 Train loss 0.44 Classification-F1 0.6029076989366794 on epoch=24
06/02/2022 15:22:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5304494869602417 -> 0.6029076989366794 on epoch=24, global_step=350
06/02/2022 15:22:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.40 on epoch=25
06/02/2022 15:22:51 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=26
06/02/2022 15:22:54 - INFO - __main__ - Step 380 Global step 380 Train loss 0.41 on epoch=27
06/02/2022 15:22:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=27
06/02/2022 15:22:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.34 on epoch=28
06/02/2022 15:23:06 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.7544040373196954 on epoch=28
06/02/2022 15:23:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6029076989366794 -> 0.7544040373196954 on epoch=28, global_step=400
06/02/2022 15:23:08 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=29
06/02/2022 15:23:11 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=29
06/02/2022 15:23:13 - INFO - __main__ - Step 430 Global step 430 Train loss 0.39 on epoch=30
06/02/2022 15:23:16 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=31
06/02/2022 15:23:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=32
06/02/2022 15:23:25 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.7348153185911916 on epoch=32
06/02/2022 15:23:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=32
06/02/2022 15:23:30 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=33
06/02/2022 15:23:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=34
06/02/2022 15:23:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
06/02/2022 15:23:37 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=35
06/02/2022 15:23:44 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.7489909319065899 on epoch=35
06/02/2022 15:23:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=36
06/02/2022 15:23:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=37
06/02/2022 15:23:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=37
06/02/2022 15:23:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=38
06/02/2022 15:23:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=39
06/02/2022 15:24:03 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.6037081957871632 on epoch=39
06/02/2022 15:24:05 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=39
06/02/2022 15:24:08 - INFO - __main__ - Step 570 Global step 570 Train loss 0.15 on epoch=40
06/02/2022 15:24:10 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=41
06/02/2022 15:24:12 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=42
06/02/2022 15:24:15 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=42
06/02/2022 15:24:22 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.6966470736507621 on epoch=42
06/02/2022 15:24:24 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=43
06/02/2022 15:24:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=44
06/02/2022 15:24:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=44
06/02/2022 15:24:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=45
06/02/2022 15:24:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=46
06/02/2022 15:24:41 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.7558362309654595 on epoch=46
06/02/2022 15:24:41 - INFO - __main__ - Saving model with best Classification-F1: 0.7544040373196954 -> 0.7558362309654595 on epoch=46, global_step=650
06/02/2022 15:24:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=47
06/02/2022 15:24:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=47
06/02/2022 15:24:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=48
06/02/2022 15:24:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=49
06/02/2022 15:24:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=49
06/02/2022 15:25:01 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.7945188094689077 on epoch=49
06/02/2022 15:25:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7558362309654595 -> 0.7945188094689077 on epoch=49, global_step=700
06/02/2022 15:25:03 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=50
06/02/2022 15:25:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=51
06/02/2022 15:25:08 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=52
06/02/2022 15:25:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=52
06/02/2022 15:25:13 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=53
06/02/2022 15:25:20 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.7986758906211894 on epoch=53
06/02/2022 15:25:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7945188094689077 -> 0.7986758906211894 on epoch=53, global_step=750
06/02/2022 15:25:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=54
06/02/2022 15:25:25 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=54
06/02/2022 15:25:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
06/02/2022 15:25:30 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
06/02/2022 15:25:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=57
06/02/2022 15:25:39 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.7961964858870687 on epoch=57
06/02/2022 15:25:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=57
06/02/2022 15:25:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=58
06/02/2022 15:25:46 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=59
06/02/2022 15:25:49 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=59
06/02/2022 15:25:51 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=60
06/02/2022 15:25:58 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.8523548892709071 on epoch=60
06/02/2022 15:25:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7986758906211894 -> 0.8523548892709071 on epoch=60, global_step=850
06/02/2022 15:26:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=61
06/02/2022 15:26:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=62
06/02/2022 15:26:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=62
06/02/2022 15:26:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=63
06/02/2022 15:26:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=64
06/02/2022 15:26:17 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.9160751002797721 on epoch=64
06/02/2022 15:26:17 - INFO - __main__ - Saving model with best Classification-F1: 0.8523548892709071 -> 0.9160751002797721 on epoch=64, global_step=900
06/02/2022 15:26:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=64
06/02/2022 15:26:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=65
06/02/2022 15:26:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=66
06/02/2022 15:26:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=67
06/02/2022 15:26:30 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=67
06/02/2022 15:26:37 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.9114276404598987 on epoch=67
06/02/2022 15:26:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=68
06/02/2022 15:26:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
06/02/2022 15:26:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/02/2022 15:26:47 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/02/2022 15:26:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
06/02/2022 15:26:56 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.9160751002797721 on epoch=71
06/02/2022 15:26:59 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/02/2022 15:27:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=72
06/02/2022 15:27:04 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
06/02/2022 15:27:06 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
06/02/2022 15:27:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
06/02/2022 15:27:15 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.9202458399343828 on epoch=74
06/02/2022 15:27:15 - INFO - __main__ - Saving model with best Classification-F1: 0.9160751002797721 -> 0.9202458399343828 on epoch=74, global_step=1050
06/02/2022 15:27:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=75
06/02/2022 15:27:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=76
06/02/2022 15:27:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=77
06/02/2022 15:27:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/02/2022 15:27:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/02/2022 15:27:35 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.9143564679048553 on epoch=78
06/02/2022 15:27:37 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
06/02/2022 15:27:40 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=79
06/02/2022 15:27:42 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/02/2022 15:27:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
06/02/2022 15:27:47 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
06/02/2022 15:27:54 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.9821254014802404 on epoch=82
06/02/2022 15:27:54 - INFO - __main__ - Saving model with best Classification-F1: 0.9202458399343828 -> 0.9821254014802404 on epoch=82, global_step=1150
06/02/2022 15:27:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/02/2022 15:27:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
06/02/2022 15:28:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
06/02/2022 15:28:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/02/2022 15:28:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
06/02/2022 15:28:14 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.9029427919750501 on epoch=85
06/02/2022 15:28:16 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
06/02/2022 15:28:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
06/02/2022 15:28:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
06/02/2022 15:28:24 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=88
06/02/2022 15:28:26 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
06/02/2022 15:28:33 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.9160751002797721 on epoch=89
06/02/2022 15:28:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
06/02/2022 15:28:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
06/02/2022 15:28:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
06/02/2022 15:28:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/02/2022 15:28:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=92
06/02/2022 15:28:53 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.9202458399343828 on epoch=92
06/02/2022 15:28:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=93
06/02/2022 15:28:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
06/02/2022 15:29:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
06/02/2022 15:29:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
06/02/2022 15:29:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
06/02/2022 15:29:13 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.9160751002797721 on epoch=96
06/02/2022 15:29:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
06/02/2022 15:29:18 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
06/02/2022 15:29:20 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=98
06/02/2022 15:29:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
06/02/2022 15:29:25 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/02/2022 15:29:32 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.8527598004516803 on epoch=99
06/02/2022 15:29:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/02/2022 15:29:37 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/02/2022 15:29:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
06/02/2022 15:29:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/02/2022 15:29:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
06/02/2022 15:29:52 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.9776304656760065 on epoch=103
06/02/2022 15:29:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/02/2022 15:29:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/02/2022 15:29:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
06/02/2022 15:30:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/02/2022 15:30:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
06/02/2022 15:30:12 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.9776304656760065 on epoch=107
06/02/2022 15:30:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
06/02/2022 15:30:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/02/2022 15:30:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
06/02/2022 15:30:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=109
06/02/2022 15:30:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/02/2022 15:30:32 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.9820991153059465 on epoch=110
06/02/2022 15:30:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/02/2022 15:30:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=112
06/02/2022 15:30:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/02/2022 15:30:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
06/02/2022 15:30:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
06/02/2022 15:30:52 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.9776567518503005 on epoch=114
06/02/2022 15:30:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
06/02/2022 15:30:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/02/2022 15:31:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/02/2022 15:31:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
06/02/2022 15:31:05 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
06/02/2022 15:31:12 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.9100029940179126 on epoch=117
06/02/2022 15:31:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
06/02/2022 15:31:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/02/2022 15:31:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/02/2022 15:31:22 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/02/2022 15:31:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/02/2022 15:31:32 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.9228413163897036 on epoch=121
06/02/2022 15:31:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=122
06/02/2022 15:31:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
06/02/2022 15:31:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/02/2022 15:31:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=124
06/02/2022 15:31:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/02/2022 15:31:53 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.9685395565850976 on epoch=124
06/02/2022 15:31:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
06/02/2022 15:31:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/02/2022 15:32:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/02/2022 15:32:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/02/2022 15:32:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/02/2022 15:32:13 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.9101611944875702 on epoch=128
06/02/2022 15:32:15 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/02/2022 15:32:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=129
06/02/2022 15:32:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
06/02/2022 15:32:23 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/02/2022 15:32:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
06/02/2022 15:32:33 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.9144753033178081 on epoch=132
06/02/2022 15:32:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/02/2022 15:32:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=133
06/02/2022 15:32:40 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/02/2022 15:32:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
06/02/2022 15:32:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/02/2022 15:32:53 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.9059904548329598 on epoch=135
06/02/2022 15:32:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=136
06/02/2022 15:32:59 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/02/2022 15:33:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/02/2022 15:33:04 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
06/02/2022 15:33:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=139
06/02/2022 15:33:14 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.9730344923893313 on epoch=139
06/02/2022 15:33:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/02/2022 15:33:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/02/2022 15:33:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/02/2022 15:33:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/02/2022 15:33:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/02/2022 15:33:35 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9865940511101802 on epoch=142
06/02/2022 15:33:35 - INFO - __main__ - Saving model with best Classification-F1: 0.9821254014802404 -> 0.9865940511101802 on epoch=142, global_step=2000
06/02/2022 15:33:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/02/2022 15:33:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/02/2022 15:33:43 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
06/02/2022 15:33:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/02/2022 15:33:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/02/2022 15:33:56 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9821254014802404 on epoch=146
06/02/2022 15:33:58 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/02/2022 15:34:01 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/02/2022 15:34:03 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/02/2022 15:34:06 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/02/2022 15:34:08 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/02/2022 15:34:16 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9775031420192712 on epoch=149
06/02/2022 15:34:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/02/2022 15:34:21 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/02/2022 15:34:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=152
06/02/2022 15:34:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/02/2022 15:34:29 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/02/2022 15:34:40 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.9776567518503005 on epoch=153
06/02/2022 15:34:43 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/02/2022 15:34:45 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=154
06/02/2022 15:34:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/02/2022 15:34:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/02/2022 15:34:53 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
06/02/2022 15:35:04 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9821254014802404 on epoch=157
06/02/2022 15:35:06 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/02/2022 15:35:09 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/02/2022 15:35:11 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
06/02/2022 15:35:14 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/02/2022 15:35:16 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/02/2022 15:35:25 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9821254014802404 on epoch=160
06/02/2022 15:35:27 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/02/2022 15:35:30 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/02/2022 15:35:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/02/2022 15:35:35 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/02/2022 15:35:37 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/02/2022 15:35:45 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9821254014802404 on epoch=164
06/02/2022 15:35:48 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/02/2022 15:35:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/02/2022 15:35:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/02/2022 15:35:56 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/02/2022 15:35:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/02/2022 15:36:06 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9865940511101804 on epoch=167
06/02/2022 15:36:06 - INFO - __main__ - Saving model with best Classification-F1: 0.9865940511101802 -> 0.9865940511101804 on epoch=167, global_step=2350
06/02/2022 15:36:09 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/02/2022 15:36:12 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/02/2022 15:36:14 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
06/02/2022 15:36:17 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/02/2022 15:36:19 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/02/2022 15:36:27 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9144753033178081 on epoch=171
06/02/2022 15:36:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/02/2022 15:36:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/02/2022 15:36:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/02/2022 15:36:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/02/2022 15:36:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/02/2022 15:36:47 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.847067200831187 on epoch=174
06/02/2022 15:36:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/02/2022 15:36:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/02/2022 15:36:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/02/2022 15:36:57 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/02/2022 15:37:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/02/2022 15:37:08 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7952156830087326 on epoch=178
06/02/2022 15:37:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/02/2022 15:37:13 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
06/02/2022 15:37:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/02/2022 15:37:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/02/2022 15:37:20 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/02/2022 15:37:29 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9144753033178081 on epoch=182
06/02/2022 15:37:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/02/2022 15:37:34 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/02/2022 15:37:36 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/02/2022 15:37:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=184
06/02/2022 15:37:41 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/02/2022 15:37:49 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9144753033178081 on epoch=185
06/02/2022 15:37:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/02/2022 15:37:54 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/02/2022 15:37:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/02/2022 15:37:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/02/2022 15:38:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/02/2022 15:38:10 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.859103128054741 on epoch=189
06/02/2022 15:38:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/02/2022 15:38:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/02/2022 15:38:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/02/2022 15:38:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/02/2022 15:38:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/02/2022 15:38:31 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9035383475532661 on epoch=192
06/02/2022 15:38:33 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/02/2022 15:38:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/02/2022 15:38:38 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/02/2022 15:38:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/02/2022 15:38:43 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/02/2022 15:38:52 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9820991153059465 on epoch=196
06/02/2022 15:38:54 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=197
06/02/2022 15:38:57 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/02/2022 15:38:59 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/02/2022 15:39:02 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/02/2022 15:39:04 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=199
06/02/2022 15:39:13 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9910627007401202 on epoch=199
06/02/2022 15:39:13 - INFO - __main__ - Saving model with best Classification-F1: 0.9865940511101804 -> 0.9910627007401202 on epoch=199, global_step=2800
06/02/2022 15:39:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/02/2022 15:39:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/02/2022 15:39:21 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/02/2022 15:39:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/02/2022 15:39:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/02/2022 15:39:34 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9775031420192712 on epoch=203
06/02/2022 15:39:36 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/02/2022 15:39:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/02/2022 15:39:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/02/2022 15:39:44 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/02/2022 15:39:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/02/2022 15:39:55 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=207
06/02/2022 15:39:57 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/02/2022 15:40:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/02/2022 15:40:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/02/2022 15:40:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/02/2022 15:40:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/02/2022 15:40:15 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9819717916492111 on epoch=210
06/02/2022 15:40:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/02/2022 15:40:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/02/2022 15:40:23 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/02/2022 15:40:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/02/2022 15:40:28 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/02/2022 15:40:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 15:40:29 - INFO - __main__ - Printing 3 examples
06/02/2022 15:40:29 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 15:40:29 - INFO - __main__ - ['Film']
06/02/2022 15:40:29 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 15:40:29 - INFO - __main__ - ['Film']
06/02/2022 15:40:29 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 15:40:29 - INFO - __main__ - ['Film']
06/02/2022 15:40:29 - INFO - __main__ - Tokenizing Input ...
06/02/2022 15:40:29 - INFO - __main__ - Tokenizing Output ...
06/02/2022 15:40:30 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 15:40:30 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 15:40:30 - INFO - __main__ - Printing 3 examples
06/02/2022 15:40:30 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 15:40:30 - INFO - __main__ - ['Film']
06/02/2022 15:40:30 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 15:40:30 - INFO - __main__ - ['Film']
06/02/2022 15:40:30 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 15:40:30 - INFO - __main__ - ['Film']
06/02/2022 15:40:30 - INFO - __main__ - Tokenizing Input ...
06/02/2022 15:40:30 - INFO - __main__ - Tokenizing Output ...
06/02/2022 15:40:30 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 15:40:35 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9819717916492111 on epoch=214
06/02/2022 15:40:35 - INFO - __main__ - save last model!
06/02/2022 15:40:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 15:40:35 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 15:40:35 - INFO - __main__ - Printing 3 examples
06/02/2022 15:40:35 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 15:40:35 - INFO - __main__ - ['Animal']
06/02/2022 15:40:35 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 15:40:35 - INFO - __main__ - ['Animal']
06/02/2022 15:40:35 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 15:40:35 - INFO - __main__ - ['Village']
06/02/2022 15:40:35 - INFO - __main__ - Tokenizing Input ...
06/02/2022 15:40:37 - INFO - __main__ - Tokenizing Output ...
06/02/2022 15:40:40 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 15:40:45 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 15:40:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 15:40:46 - INFO - __main__ - Starting training!
06/02/2022 15:43:08 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
06/02/2022 15:43:08 - INFO - __main__ - Classification-F1 on test data: 0.6220
06/02/2022 15:43:08 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.9910627007401202, test_performance=0.6220354647418881
06/02/2022 15:43:08 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
06/02/2022 15:43:09 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 15:43:09 - INFO - __main__ - Printing 3 examples
06/02/2022 15:43:09 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 15:43:09 - INFO - __main__ - ['Film']
06/02/2022 15:43:09 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 15:43:09 - INFO - __main__ - ['Film']
06/02/2022 15:43:09 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 15:43:09 - INFO - __main__ - ['Film']
06/02/2022 15:43:09 - INFO - __main__ - Tokenizing Input ...
06/02/2022 15:43:09 - INFO - __main__ - Tokenizing Output ...
06/02/2022 15:43:10 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 15:43:10 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 15:43:10 - INFO - __main__ - Printing 3 examples
06/02/2022 15:43:10 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 15:43:10 - INFO - __main__ - ['Film']
06/02/2022 15:43:10 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 15:43:10 - INFO - __main__ - ['Film']
06/02/2022 15:43:10 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 15:43:10 - INFO - __main__ - ['Film']
06/02/2022 15:43:10 - INFO - __main__ - Tokenizing Input ...
06/02/2022 15:43:10 - INFO - __main__ - Tokenizing Output ...
06/02/2022 15:43:10 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 15:43:27 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 15:43:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 15:43:28 - INFO - __main__ - Starting training!
06/02/2022 15:43:31 - INFO - __main__ - Step 10 Global step 10 Train loss 5.91 on epoch=0
06/02/2022 15:43:34 - INFO - __main__ - Step 20 Global step 20 Train loss 4.14 on epoch=1
06/02/2022 15:43:37 - INFO - __main__ - Step 30 Global step 30 Train loss 3.60 on epoch=2
06/02/2022 15:43:39 - INFO - __main__ - Step 40 Global step 40 Train loss 3.04 on epoch=2
06/02/2022 15:43:42 - INFO - __main__ - Step 50 Global step 50 Train loss 3.01 on epoch=3
06/02/2022 15:43:46 - INFO - __main__ - Global step 50 Train loss 3.94 Classification-F1 0.10226486161099499 on epoch=3
06/02/2022 15:43:46 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10226486161099499 on epoch=3, global_step=50
06/02/2022 15:43:49 - INFO - __main__ - Step 60 Global step 60 Train loss 2.67 on epoch=4
06/02/2022 15:43:51 - INFO - __main__ - Step 70 Global step 70 Train loss 2.21 on epoch=4
06/02/2022 15:43:54 - INFO - __main__ - Step 80 Global step 80 Train loss 2.58 on epoch=5
06/02/2022 15:43:56 - INFO - __main__ - Step 90 Global step 90 Train loss 2.05 on epoch=6
06/02/2022 15:43:59 - INFO - __main__ - Step 100 Global step 100 Train loss 2.10 on epoch=7
06/02/2022 15:44:04 - INFO - __main__ - Global step 100 Train loss 2.32 Classification-F1 0.13520751119317426 on epoch=7
06/02/2022 15:44:04 - INFO - __main__ - Saving model with best Classification-F1: 0.10226486161099499 -> 0.13520751119317426 on epoch=7, global_step=100
06/02/2022 15:44:06 - INFO - __main__ - Step 110 Global step 110 Train loss 1.89 on epoch=7
06/02/2022 15:44:09 - INFO - __main__ - Step 120 Global step 120 Train loss 1.94 on epoch=8
06/02/2022 15:44:11 - INFO - __main__ - Step 130 Global step 130 Train loss 1.72 on epoch=9
06/02/2022 15:44:14 - INFO - __main__ - Step 140 Global step 140 Train loss 1.51 on epoch=9
06/02/2022 15:44:16 - INFO - __main__ - Step 150 Global step 150 Train loss 1.79 on epoch=10
06/02/2022 15:44:21 - INFO - __main__ - Global step 150 Train loss 1.77 Classification-F1 0.19181868961927614 on epoch=10
06/02/2022 15:44:21 - INFO - __main__ - Saving model with best Classification-F1: 0.13520751119317426 -> 0.19181868961927614 on epoch=10, global_step=150
06/02/2022 15:44:24 - INFO - __main__ - Step 160 Global step 160 Train loss 1.34 on epoch=11
06/02/2022 15:44:26 - INFO - __main__ - Step 170 Global step 170 Train loss 1.39 on epoch=12
06/02/2022 15:44:29 - INFO - __main__ - Step 180 Global step 180 Train loss 1.25 on epoch=12
06/02/2022 15:44:31 - INFO - __main__ - Step 190 Global step 190 Train loss 1.30 on epoch=13
06/02/2022 15:44:34 - INFO - __main__ - Step 200 Global step 200 Train loss 1.14 on epoch=14
06/02/2022 15:44:39 - INFO - __main__ - Global step 200 Train loss 1.28 Classification-F1 0.251696755689781 on epoch=14
06/02/2022 15:44:39 - INFO - __main__ - Saving model with best Classification-F1: 0.19181868961927614 -> 0.251696755689781 on epoch=14, global_step=200
06/02/2022 15:44:42 - INFO - __main__ - Step 210 Global step 210 Train loss 1.11 on epoch=14
06/02/2022 15:44:44 - INFO - __main__ - Step 220 Global step 220 Train loss 1.11 on epoch=15
06/02/2022 15:44:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.89 on epoch=16
06/02/2022 15:44:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.90 on epoch=17
06/02/2022 15:44:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.82 on epoch=17
06/02/2022 15:44:57 - INFO - __main__ - Global step 250 Train loss 0.96 Classification-F1 0.37915476563167894 on epoch=17
06/02/2022 15:44:57 - INFO - __main__ - Saving model with best Classification-F1: 0.251696755689781 -> 0.37915476563167894 on epoch=17, global_step=250
06/02/2022 15:45:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.86 on epoch=18
06/02/2022 15:45:02 - INFO - __main__ - Step 270 Global step 270 Train loss 0.75 on epoch=19
06/02/2022 15:45:05 - INFO - __main__ - Step 280 Global step 280 Train loss 0.72 on epoch=19
06/02/2022 15:45:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.67 on epoch=20
06/02/2022 15:45:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.65 on epoch=21
06/02/2022 15:45:16 - INFO - __main__ - Global step 300 Train loss 0.73 Classification-F1 0.51924770177731 on epoch=21
06/02/2022 15:45:16 - INFO - __main__ - Saving model with best Classification-F1: 0.37915476563167894 -> 0.51924770177731 on epoch=21, global_step=300
06/02/2022 15:45:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.58 on epoch=22
06/02/2022 15:45:22 - INFO - __main__ - Step 320 Global step 320 Train loss 0.58 on epoch=22
06/02/2022 15:45:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.49 on epoch=23
06/02/2022 15:45:27 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=24
06/02/2022 15:45:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.55 on epoch=24
06/02/2022 15:45:36 - INFO - __main__ - Global step 350 Train loss 0.55 Classification-F1 0.6066968322580854 on epoch=24
06/02/2022 15:45:36 - INFO - __main__ - Saving model with best Classification-F1: 0.51924770177731 -> 0.6066968322580854 on epoch=24, global_step=350
06/02/2022 15:45:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.48 on epoch=25
06/02/2022 15:45:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.46 on epoch=26
06/02/2022 15:45:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.52 on epoch=27
06/02/2022 15:45:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.47 on epoch=27
06/02/2022 15:45:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=28
06/02/2022 15:45:56 - INFO - __main__ - Global step 400 Train loss 0.46 Classification-F1 0.5371815726872203 on epoch=28
06/02/2022 15:45:58 - INFO - __main__ - Step 410 Global step 410 Train loss 0.46 on epoch=29
06/02/2022 15:46:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.44 on epoch=29
06/02/2022 15:46:03 - INFO - __main__ - Step 430 Global step 430 Train loss 0.33 on epoch=30
06/02/2022 15:46:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.39 on epoch=31
06/02/2022 15:46:08 - INFO - __main__ - Step 450 Global step 450 Train loss 0.42 on epoch=32
06/02/2022 15:46:15 - INFO - __main__ - Global step 450 Train loss 0.41 Classification-F1 0.5616832886227053 on epoch=32
06/02/2022 15:46:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=32
06/02/2022 15:46:20 - INFO - __main__ - Step 470 Global step 470 Train loss 0.34 on epoch=33
06/02/2022 15:46:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.33 on epoch=34
06/02/2022 15:46:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=34
06/02/2022 15:46:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=35
06/02/2022 15:46:35 - INFO - __main__ - Global step 500 Train loss 0.31 Classification-F1 0.5659694656425893 on epoch=35
06/02/2022 15:46:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=36
06/02/2022 15:46:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.44 on epoch=37
06/02/2022 15:46:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=37
06/02/2022 15:46:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=38
06/02/2022 15:46:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.26 on epoch=39
06/02/2022 15:46:55 - INFO - __main__ - Global step 550 Train loss 0.32 Classification-F1 0.5767579264161921 on epoch=39
06/02/2022 15:46:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=39
06/02/2022 15:47:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.38 on epoch=40
06/02/2022 15:47:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=41
06/02/2022 15:47:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.27 on epoch=42
06/02/2022 15:47:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=42
06/02/2022 15:47:15 - INFO - __main__ - Global step 600 Train loss 0.28 Classification-F1 0.643338158826128 on epoch=42
06/02/2022 15:47:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6066968322580854 -> 0.643338158826128 on epoch=42, global_step=600
06/02/2022 15:47:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=43
06/02/2022 15:47:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=44
06/02/2022 15:47:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=44
06/02/2022 15:47:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=45
06/02/2022 15:47:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=46
06/02/2022 15:47:34 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.6226527243096042 on epoch=46
06/02/2022 15:47:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=47
06/02/2022 15:47:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=47
06/02/2022 15:47:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=48
06/02/2022 15:47:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=49
06/02/2022 15:47:47 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=49
06/02/2022 15:47:54 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.5913927002448363 on epoch=49
06/02/2022 15:47:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=50
06/02/2022 15:47:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=51
06/02/2022 15:48:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=52
06/02/2022 15:48:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=52
06/02/2022 15:48:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.24 on epoch=53
06/02/2022 15:48:13 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.7543158156061381 on epoch=53
06/02/2022 15:48:13 - INFO - __main__ - Saving model with best Classification-F1: 0.643338158826128 -> 0.7543158156061381 on epoch=53, global_step=750
06/02/2022 15:48:16 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=54
06/02/2022 15:48:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=54
06/02/2022 15:48:21 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=55
06/02/2022 15:48:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.23 on epoch=56
06/02/2022 15:48:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=57
06/02/2022 15:48:33 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.6864434318681729 on epoch=57
06/02/2022 15:48:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=57
06/02/2022 15:48:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=58
06/02/2022 15:48:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=59
06/02/2022 15:48:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=59
06/02/2022 15:48:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=60
06/02/2022 15:48:52 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.755856675767688 on epoch=60
06/02/2022 15:48:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7543158156061381 -> 0.755856675767688 on epoch=60, global_step=850
06/02/2022 15:48:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=61
06/02/2022 15:48:58 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=62
06/02/2022 15:49:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=62
06/02/2022 15:49:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=63
06/02/2022 15:49:05 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=64
06/02/2022 15:49:12 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.748789362853601 on epoch=64
06/02/2022 15:49:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=64
06/02/2022 15:49:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=65
06/02/2022 15:49:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=66
06/02/2022 15:49:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=67
06/02/2022 15:49:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=67
06/02/2022 15:49:32 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.7522615850758232 on epoch=67
06/02/2022 15:49:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=68
06/02/2022 15:49:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=69
06/02/2022 15:49:40 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
06/02/2022 15:49:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=70
06/02/2022 15:49:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=71
06/02/2022 15:49:51 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.7911761731692374 on epoch=71
06/02/2022 15:49:51 - INFO - __main__ - Saving model with best Classification-F1: 0.755856675767688 -> 0.7911761731692374 on epoch=71, global_step=1000
06/02/2022 15:49:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=72
06/02/2022 15:49:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=72
06/02/2022 15:49:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=73
06/02/2022 15:50:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=74
06/02/2022 15:50:04 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=74
06/02/2022 15:50:11 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.7969982142030285 on epoch=74
06/02/2022 15:50:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7911761731692374 -> 0.7969982142030285 on epoch=74, global_step=1050
06/02/2022 15:50:14 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=75
06/02/2022 15:50:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=76
06/02/2022 15:50:19 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=77
06/02/2022 15:50:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
06/02/2022 15:50:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/02/2022 15:50:31 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.9075943247828675 on epoch=78
06/02/2022 15:50:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7969982142030285 -> 0.9075943247828675 on epoch=78, global_step=1100
06/02/2022 15:50:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
06/02/2022 15:50:36 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
06/02/2022 15:50:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=80
06/02/2022 15:50:41 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=81
06/02/2022 15:50:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=82
06/02/2022 15:50:50 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.8447683502564743 on epoch=82
06/02/2022 15:50:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
06/02/2022 15:50:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/02/2022 15:50:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=84
06/02/2022 15:51:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
06/02/2022 15:51:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=85
06/02/2022 15:51:10 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.8566698688778778 on epoch=85
06/02/2022 15:51:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/02/2022 15:51:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=87
06/02/2022 15:51:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/02/2022 15:51:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=88
06/02/2022 15:51:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=89
06/02/2022 15:51:29 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.8568080959062258 on epoch=89
06/02/2022 15:51:32 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
06/02/2022 15:51:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=90
06/02/2022 15:51:37 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
06/02/2022 15:51:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
06/02/2022 15:51:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
06/02/2022 15:51:49 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.9077376939584949 on epoch=92
06/02/2022 15:51:49 - INFO - __main__ - Saving model with best Classification-F1: 0.9075943247828675 -> 0.9077376939584949 on epoch=92, global_step=1300
06/02/2022 15:51:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=93
06/02/2022 15:51:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=94
06/02/2022 15:51:56 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=94
06/02/2022 15:51:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
06/02/2022 15:52:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=96
06/02/2022 15:52:09 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.9160751002797721 on epoch=96
06/02/2022 15:52:09 - INFO - __main__ - Saving model with best Classification-F1: 0.9077376939584949 -> 0.9160751002797721 on epoch=96, global_step=1350
06/02/2022 15:52:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=97
06/02/2022 15:52:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
06/02/2022 15:52:16 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
06/02/2022 15:52:19 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
06/02/2022 15:52:21 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=99
06/02/2022 15:52:28 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.9034235851282572 on epoch=99
06/02/2022 15:52:31 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/02/2022 15:52:33 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.19 on epoch=101
06/02/2022 15:52:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
06/02/2022 15:52:39 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
06/02/2022 15:52:41 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=103
06/02/2022 15:52:48 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.9036571829662193 on epoch=103
06/02/2022 15:52:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/02/2022 15:52:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=104
06/02/2022 15:52:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
06/02/2022 15:52:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/02/2022 15:53:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
06/02/2022 15:53:08 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.9032049965636306 on epoch=107
06/02/2022 15:53:10 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/02/2022 15:53:13 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
06/02/2022 15:53:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
06/02/2022 15:53:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.13 on epoch=109
06/02/2022 15:53:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/02/2022 15:53:28 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.9032482781092348 on epoch=110
06/02/2022 15:53:30 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/02/2022 15:53:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/02/2022 15:53:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/02/2022 15:53:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=113
06/02/2022 15:53:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
06/02/2022 15:53:47 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.8527598004516803 on epoch=114
06/02/2022 15:53:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=114
06/02/2022 15:53:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/02/2022 15:53:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
06/02/2022 15:53:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
06/02/2022 15:53:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
06/02/2022 15:54:07 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.9865940511101802 on epoch=117
06/02/2022 15:54:07 - INFO - __main__ - Saving model with best Classification-F1: 0.9160751002797721 -> 0.9865940511101802 on epoch=117, global_step=1650
06/02/2022 15:54:09 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/02/2022 15:54:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/02/2022 15:54:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/02/2022 15:54:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
06/02/2022 15:54:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
06/02/2022 15:54:27 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.9820991153059465 on epoch=121
06/02/2022 15:54:30 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
06/02/2022 15:54:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
06/02/2022 15:54:35 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/02/2022 15:54:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=124
06/02/2022 15:54:40 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/02/2022 15:54:47 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.9641188541348384 on epoch=124
06/02/2022 15:54:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/02/2022 15:54:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
06/02/2022 15:54:55 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/02/2022 15:54:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/02/2022 15:55:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/02/2022 15:55:07 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.9820991153059465 on epoch=128
06/02/2022 15:55:09 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/02/2022 15:55:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/02/2022 15:55:14 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/02/2022 15:55:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
06/02/2022 15:55:19 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/02/2022 15:55:27 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.9101857282502446 on epoch=132
06/02/2022 15:55:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/02/2022 15:55:32 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
06/02/2022 15:55:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=134
06/02/2022 15:55:37 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/02/2022 15:55:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=135
06/02/2022 15:55:47 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.8972170060595109 on epoch=135
06/02/2022 15:55:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/02/2022 15:55:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/02/2022 15:55:55 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
06/02/2022 15:55:58 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/02/2022 15:56:00 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=139
06/02/2022 15:56:07 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.9144753033178081 on epoch=139
06/02/2022 15:56:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
06/02/2022 15:56:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=140
06/02/2022 15:56:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/02/2022 15:56:18 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/02/2022 15:56:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/02/2022 15:56:27 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.9910627007401202 on epoch=142
06/02/2022 15:56:27 - INFO - __main__ - Saving model with best Classification-F1: 0.9865940511101802 -> 0.9910627007401202 on epoch=142, global_step=2000
06/02/2022 15:56:30 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/02/2022 15:56:32 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/02/2022 15:56:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
06/02/2022 15:56:37 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/02/2022 15:56:40 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=146
06/02/2022 15:56:47 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.907375736218241 on epoch=146
06/02/2022 15:56:49 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/02/2022 15:56:52 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/02/2022 15:56:54 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/02/2022 15:56:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/02/2022 15:56:59 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/02/2022 15:57:07 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9059904548329598 on epoch=149
06/02/2022 15:57:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
06/02/2022 15:57:12 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/02/2022 15:57:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/02/2022 15:57:17 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/02/2022 15:57:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/02/2022 15:57:27 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.9776304656760065 on epoch=153
06/02/2022 15:57:29 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/02/2022 15:57:32 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/02/2022 15:57:34 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/02/2022 15:57:37 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/02/2022 15:57:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/02/2022 15:57:47 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9821254014802404 on epoch=157
06/02/2022 15:57:49 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/02/2022 15:57:52 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/02/2022 15:57:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/02/2022 15:57:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/02/2022 15:57:59 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/02/2022 15:58:06 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9681073822490873 on epoch=160
06/02/2022 15:58:09 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/02/2022 15:58:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/02/2022 15:58:14 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/02/2022 15:58:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/02/2022 15:58:19 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/02/2022 15:58:27 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9730344923893313 on epoch=164
06/02/2022 15:58:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/02/2022 15:58:32 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/02/2022 15:58:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/02/2022 15:58:37 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/02/2022 15:58:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/02/2022 15:58:47 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9776304656760065 on epoch=167
06/02/2022 15:58:50 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/02/2022 15:58:52 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/02/2022 15:58:55 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/02/2022 15:58:57 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/02/2022 15:59:00 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/02/2022 15:59:08 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9730082062150375 on epoch=171
06/02/2022 15:59:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/02/2022 15:59:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/02/2022 15:59:15 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=173
06/02/2022 15:59:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/02/2022 15:59:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/02/2022 15:59:28 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9731618160460668 on epoch=174
06/02/2022 15:59:31 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/02/2022 15:59:33 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/02/2022 15:59:36 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=177
06/02/2022 15:59:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/02/2022 15:59:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=178
06/02/2022 15:59:49 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9820991153059465 on epoch=178
06/02/2022 15:59:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/02/2022 15:59:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
06/02/2022 15:59:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/02/2022 15:59:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/02/2022 16:00:01 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/02/2022 16:00:09 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9776304656760065 on epoch=182
06/02/2022 16:00:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/02/2022 16:00:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/02/2022 16:00:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/02/2022 16:00:19 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/02/2022 16:00:22 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/02/2022 16:00:30 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9820991153059465 on epoch=185
06/02/2022 16:00:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/02/2022 16:00:35 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/02/2022 16:00:37 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/02/2022 16:00:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.08 on epoch=188
06/02/2022 16:00:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/02/2022 16:00:50 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9821254014802404 on epoch=189
06/02/2022 16:00:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/02/2022 16:00:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/02/2022 16:00:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/02/2022 16:01:00 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/02/2022 16:01:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/02/2022 16:01:10 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9776304656760065 on epoch=192
06/02/2022 16:01:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/02/2022 16:01:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/02/2022 16:01:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
06/02/2022 16:01:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/02/2022 16:01:23 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/02/2022 16:01:30 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9776304656760065 on epoch=196
06/02/2022 16:01:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/02/2022 16:01:35 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/02/2022 16:01:38 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/02/2022 16:01:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/02/2022 16:01:43 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
06/02/2022 16:01:51 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9686668802418329 on epoch=199
06/02/2022 16:01:53 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/02/2022 16:01:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/02/2022 16:01:59 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/02/2022 16:02:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/02/2022 16:02:04 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
06/02/2022 16:02:12 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9731618160460668 on epoch=203
06/02/2022 16:02:14 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/02/2022 16:02:17 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/02/2022 16:02:19 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/02/2022 16:02:22 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/02/2022 16:02:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/02/2022 16:02:32 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9685395565850976 on epoch=207
06/02/2022 16:02:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/02/2022 16:02:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/02/2022 16:02:40 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/02/2022 16:02:42 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/02/2022 16:02:45 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
06/02/2022 16:02:52 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9058470856573325 on epoch=210
06/02/2022 16:02:55 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/02/2022 16:02:57 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/02/2022 16:03:00 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/02/2022 16:03:03 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/02/2022 16:03:05 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/02/2022 16:03:07 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 16:03:07 - INFO - __main__ - Printing 3 examples
06/02/2022 16:03:07 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 16:03:07 - INFO - __main__ - ['Film']
06/02/2022 16:03:07 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 16:03:07 - INFO - __main__ - ['Film']
06/02/2022 16:03:07 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 16:03:07 - INFO - __main__ - ['Film']
06/02/2022 16:03:07 - INFO - __main__ - Tokenizing Input ...
06/02/2022 16:03:07 - INFO - __main__ - Tokenizing Output ...
06/02/2022 16:03:07 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 16:03:07 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 16:03:07 - INFO - __main__ - Printing 3 examples
06/02/2022 16:03:07 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 16:03:07 - INFO - __main__ - ['Film']
06/02/2022 16:03:07 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 16:03:07 - INFO - __main__ - ['Film']
06/02/2022 16:03:07 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 16:03:07 - INFO - __main__ - ['Film']
06/02/2022 16:03:07 - INFO - __main__ - Tokenizing Input ...
06/02/2022 16:03:07 - INFO - __main__ - Tokenizing Output ...
06/02/2022 16:03:07 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 16:03:13 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9730221707451309 on epoch=214
06/02/2022 16:03:13 - INFO - __main__ - save last model!
06/02/2022 16:03:13 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 16:03:13 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 16:03:13 - INFO - __main__ - Printing 3 examples
06/02/2022 16:03:13 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 16:03:13 - INFO - __main__ - ['Animal']
06/02/2022 16:03:13 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 16:03:13 - INFO - __main__ - ['Animal']
06/02/2022 16:03:13 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 16:03:13 - INFO - __main__ - ['Village']
06/02/2022 16:03:13 - INFO - __main__ - Tokenizing Input ...
06/02/2022 16:03:15 - INFO - __main__ - Tokenizing Output ...
06/02/2022 16:03:18 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 16:03:26 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 16:03:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 16:03:27 - INFO - __main__ - Starting training!
06/02/2022 16:05:56 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
06/02/2022 16:05:56 - INFO - __main__ - Classification-F1 on test data: 0.5656
06/02/2022 16:05:57 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.9910627007401202, test_performance=0.5656444783282123
06/02/2022 16:05:57 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
06/02/2022 16:05:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 16:05:58 - INFO - __main__ - Printing 3 examples
06/02/2022 16:05:58 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 16:05:58 - INFO - __main__ - ['Film']
06/02/2022 16:05:58 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 16:05:58 - INFO - __main__ - ['Film']
06/02/2022 16:05:58 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 16:05:58 - INFO - __main__ - ['Film']
06/02/2022 16:05:58 - INFO - __main__ - Tokenizing Input ...
06/02/2022 16:05:58 - INFO - __main__ - Tokenizing Output ...
06/02/2022 16:05:58 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 16:05:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 16:05:58 - INFO - __main__ - Printing 3 examples
06/02/2022 16:05:58 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 16:05:58 - INFO - __main__ - ['Film']
06/02/2022 16:05:58 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 16:05:58 - INFO - __main__ - ['Film']
06/02/2022 16:05:58 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 16:05:58 - INFO - __main__ - ['Film']
06/02/2022 16:05:58 - INFO - __main__ - Tokenizing Input ...
06/02/2022 16:05:58 - INFO - __main__ - Tokenizing Output ...
06/02/2022 16:05:58 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 16:06:15 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 16:06:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 16:06:16 - INFO - __main__ - Starting training!
06/02/2022 16:06:20 - INFO - __main__ - Step 10 Global step 10 Train loss 6.47 on epoch=0
06/02/2022 16:06:22 - INFO - __main__ - Step 20 Global step 20 Train loss 4.68 on epoch=1
06/02/2022 16:06:25 - INFO - __main__ - Step 30 Global step 30 Train loss 4.13 on epoch=2
06/02/2022 16:06:27 - INFO - __main__ - Step 40 Global step 40 Train loss 3.58 on epoch=2
06/02/2022 16:06:30 - INFO - __main__ - Step 50 Global step 50 Train loss 3.62 on epoch=3
06/02/2022 16:06:34 - INFO - __main__ - Global step 50 Train loss 4.50 Classification-F1 0.08483870396913876 on epoch=3
06/02/2022 16:06:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08483870396913876 on epoch=3, global_step=50
06/02/2022 16:06:37 - INFO - __main__ - Step 60 Global step 60 Train loss 3.04 on epoch=4
06/02/2022 16:06:39 - INFO - __main__ - Step 70 Global step 70 Train loss 2.66 on epoch=4
06/02/2022 16:06:42 - INFO - __main__ - Step 80 Global step 80 Train loss 2.94 on epoch=5
06/02/2022 16:06:45 - INFO - __main__ - Step 90 Global step 90 Train loss 2.42 on epoch=6
06/02/2022 16:06:47 - INFO - __main__ - Step 100 Global step 100 Train loss 2.53 on epoch=7
06/02/2022 16:06:52 - INFO - __main__ - Global step 100 Train loss 2.72 Classification-F1 0.13171232148532028 on epoch=7
06/02/2022 16:06:52 - INFO - __main__ - Saving model with best Classification-F1: 0.08483870396913876 -> 0.13171232148532028 on epoch=7, global_step=100
06/02/2022 16:06:54 - INFO - __main__ - Step 110 Global step 110 Train loss 2.15 on epoch=7
06/02/2022 16:06:57 - INFO - __main__ - Step 120 Global step 120 Train loss 2.21 on epoch=8
06/02/2022 16:06:59 - INFO - __main__ - Step 130 Global step 130 Train loss 2.12 on epoch=9
06/02/2022 16:07:02 - INFO - __main__ - Step 140 Global step 140 Train loss 2.00 on epoch=9
06/02/2022 16:07:04 - INFO - __main__ - Step 150 Global step 150 Train loss 2.13 on epoch=10
06/02/2022 16:07:09 - INFO - __main__ - Global step 150 Train loss 2.12 Classification-F1 0.14287867187841832 on epoch=10
06/02/2022 16:07:09 - INFO - __main__ - Saving model with best Classification-F1: 0.13171232148532028 -> 0.14287867187841832 on epoch=10, global_step=150
06/02/2022 16:07:12 - INFO - __main__ - Step 160 Global step 160 Train loss 1.79 on epoch=11
06/02/2022 16:07:14 - INFO - __main__ - Step 170 Global step 170 Train loss 1.73 on epoch=12
06/02/2022 16:07:17 - INFO - __main__ - Step 180 Global step 180 Train loss 1.60 on epoch=12
06/02/2022 16:07:19 - INFO - __main__ - Step 190 Global step 190 Train loss 1.80 on epoch=13
06/02/2022 16:07:22 - INFO - __main__ - Step 200 Global step 200 Train loss 1.64 on epoch=14
06/02/2022 16:07:27 - INFO - __main__ - Global step 200 Train loss 1.71 Classification-F1 0.18516139238064372 on epoch=14
06/02/2022 16:07:27 - INFO - __main__ - Saving model with best Classification-F1: 0.14287867187841832 -> 0.18516139238064372 on epoch=14, global_step=200
06/02/2022 16:07:29 - INFO - __main__ - Step 210 Global step 210 Train loss 1.54 on epoch=14
06/02/2022 16:07:32 - INFO - __main__ - Step 220 Global step 220 Train loss 1.59 on epoch=15
06/02/2022 16:07:34 - INFO - __main__ - Step 230 Global step 230 Train loss 1.24 on epoch=16
06/02/2022 16:07:37 - INFO - __main__ - Step 240 Global step 240 Train loss 1.31 on epoch=17
06/02/2022 16:07:39 - INFO - __main__ - Step 250 Global step 250 Train loss 1.18 on epoch=17
06/02/2022 16:07:45 - INFO - __main__ - Global step 250 Train loss 1.37 Classification-F1 0.22323055755317625 on epoch=17
06/02/2022 16:07:45 - INFO - __main__ - Saving model with best Classification-F1: 0.18516139238064372 -> 0.22323055755317625 on epoch=17, global_step=250
06/02/2022 16:07:47 - INFO - __main__ - Step 260 Global step 260 Train loss 1.34 on epoch=18
06/02/2022 16:07:50 - INFO - __main__ - Step 270 Global step 270 Train loss 1.16 on epoch=19
06/02/2022 16:07:52 - INFO - __main__ - Step 280 Global step 280 Train loss 1.06 on epoch=19
06/02/2022 16:07:55 - INFO - __main__ - Step 290 Global step 290 Train loss 1.09 on epoch=20
06/02/2022 16:07:57 - INFO - __main__ - Step 300 Global step 300 Train loss 0.86 on epoch=21
06/02/2022 16:08:03 - INFO - __main__ - Global step 300 Train loss 1.10 Classification-F1 0.3467103521213823 on epoch=21
06/02/2022 16:08:03 - INFO - __main__ - Saving model with best Classification-F1: 0.22323055755317625 -> 0.3467103521213823 on epoch=21, global_step=300
06/02/2022 16:08:05 - INFO - __main__ - Step 310 Global step 310 Train loss 1.00 on epoch=22
06/02/2022 16:08:08 - INFO - __main__ - Step 320 Global step 320 Train loss 0.97 on epoch=22
06/02/2022 16:08:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.87 on epoch=23
06/02/2022 16:08:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.88 on epoch=24
06/02/2022 16:08:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.78 on epoch=24
06/02/2022 16:08:21 - INFO - __main__ - Global step 350 Train loss 0.90 Classification-F1 0.42681640274548893 on epoch=24
06/02/2022 16:08:21 - INFO - __main__ - Saving model with best Classification-F1: 0.3467103521213823 -> 0.42681640274548893 on epoch=24, global_step=350
06/02/2022 16:08:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.80 on epoch=25
06/02/2022 16:08:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.73 on epoch=26
06/02/2022 16:08:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.79 on epoch=27
06/02/2022 16:08:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.59 on epoch=27
06/02/2022 16:08:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.74 on epoch=28
06/02/2022 16:08:39 - INFO - __main__ - Global step 400 Train loss 0.73 Classification-F1 0.5290934217306656 on epoch=28
06/02/2022 16:08:39 - INFO - __main__ - Saving model with best Classification-F1: 0.42681640274548893 -> 0.5290934217306656 on epoch=28, global_step=400
06/02/2022 16:08:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.60 on epoch=29
06/02/2022 16:08:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.57 on epoch=29
06/02/2022 16:08:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.58 on epoch=30
06/02/2022 16:08:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.53 on epoch=31
06/02/2022 16:08:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.47 on epoch=32
06/02/2022 16:08:58 - INFO - __main__ - Global step 450 Train loss 0.55 Classification-F1 0.5399009683440785 on epoch=32
06/02/2022 16:08:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5290934217306656 -> 0.5399009683440785 on epoch=32, global_step=450
06/02/2022 16:09:00 - INFO - __main__ - Step 460 Global step 460 Train loss 0.56 on epoch=32
06/02/2022 16:09:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.54 on epoch=33
06/02/2022 16:09:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.46 on epoch=34
06/02/2022 16:09:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.59 on epoch=34
06/02/2022 16:09:10 - INFO - __main__ - Step 500 Global step 500 Train loss 0.54 on epoch=35
06/02/2022 16:09:17 - INFO - __main__ - Global step 500 Train loss 0.54 Classification-F1 0.5521053924478162 on epoch=35
06/02/2022 16:09:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5399009683440785 -> 0.5521053924478162 on epoch=35, global_step=500
06/02/2022 16:09:19 - INFO - __main__ - Step 510 Global step 510 Train loss 0.38 on epoch=36
06/02/2022 16:09:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.50 on epoch=37
06/02/2022 16:09:24 - INFO - __main__ - Step 530 Global step 530 Train loss 0.43 on epoch=37
06/02/2022 16:09:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.44 on epoch=38
06/02/2022 16:09:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=39
06/02/2022 16:09:36 - INFO - __main__ - Global step 550 Train loss 0.43 Classification-F1 0.5535260839765845 on epoch=39
06/02/2022 16:09:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5521053924478162 -> 0.5535260839765845 on epoch=39, global_step=550
06/02/2022 16:09:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.45 on epoch=39
06/02/2022 16:09:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.41 on epoch=40
06/02/2022 16:09:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.37 on epoch=41
06/02/2022 16:09:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.36 on epoch=42
06/02/2022 16:09:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.30 on epoch=42
06/02/2022 16:09:55 - INFO - __main__ - Global step 600 Train loss 0.38 Classification-F1 0.5956477652301295 on epoch=42
06/02/2022 16:09:55 - INFO - __main__ - Saving model with best Classification-F1: 0.5535260839765845 -> 0.5956477652301295 on epoch=42, global_step=600
06/02/2022 16:09:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.39 on epoch=43
06/02/2022 16:10:00 - INFO - __main__ - Step 620 Global step 620 Train loss 0.31 on epoch=44
06/02/2022 16:10:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.44 on epoch=44
06/02/2022 16:10:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.35 on epoch=45
06/02/2022 16:10:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=46
06/02/2022 16:10:14 - INFO - __main__ - Global step 650 Train loss 0.35 Classification-F1 0.5871976196310048 on epoch=46
06/02/2022 16:10:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.39 on epoch=47
06/02/2022 16:10:19 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=47
06/02/2022 16:10:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.36 on epoch=48
06/02/2022 16:10:24 - INFO - __main__ - Step 690 Global step 690 Train loss 0.34 on epoch=49
06/02/2022 16:10:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.32 on epoch=49
06/02/2022 16:10:33 - INFO - __main__ - Global step 700 Train loss 0.33 Classification-F1 0.6433333814868855 on epoch=49
06/02/2022 16:10:33 - INFO - __main__ - Saving model with best Classification-F1: 0.5956477652301295 -> 0.6433333814868855 on epoch=49, global_step=700
06/02/2022 16:10:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.35 on epoch=50
06/02/2022 16:10:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=51
06/02/2022 16:10:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=52
06/02/2022 16:10:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.25 on epoch=52
06/02/2022 16:10:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.26 on epoch=53
06/02/2022 16:10:52 - INFO - __main__ - Global step 750 Train loss 0.27 Classification-F1 0.6563564842939588 on epoch=53
06/02/2022 16:10:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6433333814868855 -> 0.6563564842939588 on epoch=53, global_step=750
06/02/2022 16:10:55 - INFO - __main__ - Step 760 Global step 760 Train loss 0.26 on epoch=54
06/02/2022 16:10:57 - INFO - __main__ - Step 770 Global step 770 Train loss 0.27 on epoch=54
06/02/2022 16:11:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=55
06/02/2022 16:11:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.24 on epoch=56
06/02/2022 16:11:05 - INFO - __main__ - Step 800 Global step 800 Train loss 0.31 on epoch=57
06/02/2022 16:11:11 - INFO - __main__ - Global step 800 Train loss 0.27 Classification-F1 0.6930387504642123 on epoch=57
06/02/2022 16:11:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6563564842939588 -> 0.6930387504642123 on epoch=57, global_step=800
06/02/2022 16:11:14 - INFO - __main__ - Step 810 Global step 810 Train loss 0.26 on epoch=57
06/02/2022 16:11:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=58
06/02/2022 16:11:19 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=59
06/02/2022 16:11:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.26 on epoch=59
06/02/2022 16:11:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=60
06/02/2022 16:11:30 - INFO - __main__ - Global step 850 Train loss 0.22 Classification-F1 0.7523603167607533 on epoch=60
06/02/2022 16:11:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6930387504642123 -> 0.7523603167607533 on epoch=60, global_step=850
06/02/2022 16:11:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=61
06/02/2022 16:11:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.35 on epoch=62
06/02/2022 16:11:38 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=62
06/02/2022 16:11:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=63
06/02/2022 16:11:43 - INFO - __main__ - Step 900 Global step 900 Train loss 0.24 on epoch=64
06/02/2022 16:11:49 - INFO - __main__ - Global step 900 Train loss 0.24 Classification-F1 0.6521918913980269 on epoch=64
06/02/2022 16:11:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=64
06/02/2022 16:11:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.22 on epoch=65
06/02/2022 16:11:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=66
06/02/2022 16:11:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=67
06/02/2022 16:12:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=67
06/02/2022 16:12:08 - INFO - __main__ - Global step 950 Train loss 0.21 Classification-F1 0.7109050359259571 on epoch=67
06/02/2022 16:12:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=68
06/02/2022 16:12:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=69
06/02/2022 16:12:16 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=69
06/02/2022 16:12:18 - INFO - __main__ - Step 990 Global step 990 Train loss 0.21 on epoch=70
06/02/2022 16:12:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=71
06/02/2022 16:12:27 - INFO - __main__ - Global step 1000 Train loss 0.20 Classification-F1 0.6493497339738262 on epoch=71
06/02/2022 16:12:30 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=72
06/02/2022 16:12:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
06/02/2022 16:12:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=73
06/02/2022 16:12:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=74
06/02/2022 16:12:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
06/02/2022 16:12:46 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.7538747003503596 on epoch=74
06/02/2022 16:12:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7523603167607533 -> 0.7538747003503596 on epoch=74, global_step=1050
06/02/2022 16:12:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.20 on epoch=75
06/02/2022 16:12:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=76
06/02/2022 16:12:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=77
06/02/2022 16:12:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=77
06/02/2022 16:12:58 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=78
06/02/2022 16:13:05 - INFO - __main__ - Global step 1100 Train loss 0.18 Classification-F1 0.7194780942443464 on epoch=78
06/02/2022 16:13:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=79
06/02/2022 16:13:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=79
06/02/2022 16:13:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=80
06/02/2022 16:13:15 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=81
06/02/2022 16:13:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=82
06/02/2022 16:13:25 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.7428503692574883 on epoch=82
06/02/2022 16:13:27 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=82
06/02/2022 16:13:29 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=83
06/02/2022 16:13:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=84
06/02/2022 16:13:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=84
06/02/2022 16:13:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=85
06/02/2022 16:13:44 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.8016807289201452 on epoch=85
06/02/2022 16:13:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7538747003503596 -> 0.8016807289201452 on epoch=85, global_step=1200
06/02/2022 16:13:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=86
06/02/2022 16:13:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=87
06/02/2022 16:13:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
06/02/2022 16:13:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=88
06/02/2022 16:13:56 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=89
06/02/2022 16:14:03 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.7955107796761922 on epoch=89
06/02/2022 16:14:05 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.19 on epoch=89
06/02/2022 16:14:08 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=90
06/02/2022 16:14:10 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=91
06/02/2022 16:14:13 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.19 on epoch=92
06/02/2022 16:14:15 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=92
06/02/2022 16:14:22 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.8044848452190712 on epoch=92
06/02/2022 16:14:22 - INFO - __main__ - Saving model with best Classification-F1: 0.8016807289201452 -> 0.8044848452190712 on epoch=92, global_step=1300
06/02/2022 16:14:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.18 on epoch=93
06/02/2022 16:14:27 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=94
06/02/2022 16:14:29 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=94
06/02/2022 16:14:32 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=95
06/02/2022 16:14:34 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=96
06/02/2022 16:14:41 - INFO - __main__ - Global step 1350 Train loss 0.14 Classification-F1 0.8008264282555979 on epoch=96
06/02/2022 16:14:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=97
06/02/2022 16:14:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/02/2022 16:14:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=98
06/02/2022 16:14:51 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=99
06/02/2022 16:14:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=99
06/02/2022 16:15:00 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.8566698688778778 on epoch=99
06/02/2022 16:15:00 - INFO - __main__ - Saving model with best Classification-F1: 0.8044848452190712 -> 0.8566698688778778 on epoch=99, global_step=1400
06/02/2022 16:15:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
06/02/2022 16:15:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=101
06/02/2022 16:15:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=102
06/02/2022 16:15:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
06/02/2022 16:15:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=103
06/02/2022 16:15:20 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.8118666214589791 on epoch=103
06/02/2022 16:15:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.15 on epoch=104
06/02/2022 16:15:25 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=104
06/02/2022 16:15:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/02/2022 16:15:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=106
06/02/2022 16:15:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=107
06/02/2022 16:15:39 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.9077090872078768 on epoch=107
06/02/2022 16:15:39 - INFO - __main__ - Saving model with best Classification-F1: 0.8566698688778778 -> 0.9077090872078768 on epoch=107, global_step=1500
06/02/2022 16:15:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=107
06/02/2022 16:15:44 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.13 on epoch=108
06/02/2022 16:15:47 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=109
06/02/2022 16:15:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.19 on epoch=109
06/02/2022 16:15:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/02/2022 16:15:59 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.8607143459062259 on epoch=110
06/02/2022 16:16:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
06/02/2022 16:16:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.12 on epoch=112
06/02/2022 16:16:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=112
06/02/2022 16:16:09 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=113
06/02/2022 16:16:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=114
06/02/2022 16:16:18 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.8607143459062259 on epoch=114
06/02/2022 16:16:21 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=114
06/02/2022 16:16:23 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=115
06/02/2022 16:16:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=116
06/02/2022 16:16:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=117
06/02/2022 16:16:31 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=117
06/02/2022 16:16:38 - INFO - __main__ - Global step 1650 Train loss 0.11 Classification-F1 0.8605799373040752 on epoch=117
06/02/2022 16:16:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.16 on epoch=118
06/02/2022 16:16:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=119
06/02/2022 16:16:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.13 on epoch=119
06/02/2022 16:16:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=120
06/02/2022 16:16:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=121
06/02/2022 16:16:58 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.8605799373040752 on epoch=121
06/02/2022 16:17:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=122
06/02/2022 16:17:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/02/2022 16:17:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=123
06/02/2022 16:17:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/02/2022 16:17:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=124
06/02/2022 16:17:18 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.8646244143324232 on epoch=124
06/02/2022 16:17:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/02/2022 16:17:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/02/2022 16:17:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=127
06/02/2022 16:17:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=127
06/02/2022 16:17:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=128
06/02/2022 16:17:38 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.8568042774800283 on epoch=128
06/02/2022 16:17:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=129
06/02/2022 16:17:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
06/02/2022 16:17:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=130
06/02/2022 16:17:48 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=131
06/02/2022 16:17:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/02/2022 16:17:59 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.8568042774800283 on epoch=132
06/02/2022 16:18:01 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=132
06/02/2022 16:18:04 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=133
06/02/2022 16:18:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/02/2022 16:18:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=134
06/02/2022 16:18:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/02/2022 16:18:19 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.8646244143324232 on epoch=135
06/02/2022 16:18:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/02/2022 16:18:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.16 on epoch=137
06/02/2022 16:18:27 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/02/2022 16:18:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=138
06/02/2022 16:18:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=139
06/02/2022 16:18:39 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.8568042774800283 on epoch=139
06/02/2022 16:18:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=139
06/02/2022 16:18:44 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=140
06/02/2022 16:18:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/02/2022 16:18:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
06/02/2022 16:18:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.11 on epoch=142
06/02/2022 16:19:00 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.9202458399343828 on epoch=142
06/02/2022 16:19:00 - INFO - __main__ - Saving model with best Classification-F1: 0.9077090872078768 -> 0.9202458399343828 on epoch=142, global_step=2000
06/02/2022 16:19:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=143
06/02/2022 16:19:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=144
06/02/2022 16:19:07 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/02/2022 16:19:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/02/2022 16:19:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.14 on epoch=146
06/02/2022 16:19:20 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.9075902517949238 on epoch=146
06/02/2022 16:19:23 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.12 on epoch=147
06/02/2022 16:19:25 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=147
06/02/2022 16:19:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=148
06/02/2022 16:19:30 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
06/02/2022 16:19:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=149
06/02/2022 16:19:40 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.9119043606251618 on epoch=149
06/02/2022 16:19:43 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
06/02/2022 16:19:46 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=151
06/02/2022 16:19:48 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
06/02/2022 16:19:51 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/02/2022 16:19:53 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/02/2022 16:20:01 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9117609914495345 on epoch=153
06/02/2022 16:20:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=154
06/02/2022 16:20:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
06/02/2022 16:20:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=155
06/02/2022 16:20:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
06/02/2022 16:20:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
06/02/2022 16:20:21 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.9160751002797721 on epoch=157
06/02/2022 16:20:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/02/2022 16:20:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=158
06/02/2022 16:20:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=159
06/02/2022 16:20:32 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
06/02/2022 16:20:34 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/02/2022 16:20:42 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.9142130987292278 on epoch=160
06/02/2022 16:20:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
06/02/2022 16:20:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/02/2022 16:20:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/02/2022 16:20:52 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/02/2022 16:20:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
06/02/2022 16:21:02 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8528942090538308 on epoch=164
06/02/2022 16:21:04 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
06/02/2022 16:21:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/02/2022 16:21:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/02/2022 16:21:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/02/2022 16:21:15 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/02/2022 16:21:22 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9030616273880033 on epoch=167
06/02/2022 16:21:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/02/2022 16:21:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.10 on epoch=169
06/02/2022 16:21:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/02/2022 16:21:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/02/2022 16:21:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/02/2022 16:21:44 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.9100423590746173 on epoch=171
06/02/2022 16:21:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
06/02/2022 16:21:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/02/2022 16:21:51 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
06/02/2022 16:21:54 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=174
06/02/2022 16:21:56 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
06/02/2022 16:22:04 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.9143564679048553 on epoch=174
06/02/2022 16:22:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/02/2022 16:22:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/02/2022 16:22:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=177
06/02/2022 16:22:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/02/2022 16:22:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=178
06/02/2022 16:22:26 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9100423590746173 on epoch=178
06/02/2022 16:22:28 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=179
06/02/2022 16:22:31 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/02/2022 16:22:33 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/02/2022 16:22:36 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
06/02/2022 16:22:39 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/02/2022 16:22:47 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.9117609914495345 on epoch=182
06/02/2022 16:22:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/02/2022 16:22:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
06/02/2022 16:22:55 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
06/02/2022 16:22:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.10 on epoch=184
06/02/2022 16:23:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=185
06/02/2022 16:23:08 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.9100423590746173 on epoch=185
06/02/2022 16:23:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/02/2022 16:23:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
06/02/2022 16:23:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=187
06/02/2022 16:23:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/02/2022 16:23:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
06/02/2022 16:23:29 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.9117609914495345 on epoch=189
06/02/2022 16:23:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=189
06/02/2022 16:23:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/02/2022 16:23:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/02/2022 16:23:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=192
06/02/2022 16:23:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=192
06/02/2022 16:23:50 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.9820991153059465 on epoch=192
06/02/2022 16:23:50 - INFO - __main__ - Saving model with best Classification-F1: 0.9202458399343828 -> 0.9820991153059465 on epoch=192, global_step=2700
06/02/2022 16:23:53 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/02/2022 16:23:55 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/02/2022 16:23:58 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/02/2022 16:24:00 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/02/2022 16:24:03 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
06/02/2022 16:24:11 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9143564679048553 on epoch=196
06/02/2022 16:24:14 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=197
06/02/2022 16:24:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
06/02/2022 16:24:19 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=198
06/02/2022 16:24:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=199
06/02/2022 16:24:24 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=199
06/02/2022 16:24:33 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.9141737336725233 on epoch=199
06/02/2022 16:24:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/02/2022 16:24:38 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/02/2022 16:24:40 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/02/2022 16:24:43 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/02/2022 16:24:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=203
06/02/2022 16:24:55 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9731618160460668 on epoch=203
06/02/2022 16:24:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
06/02/2022 16:25:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/02/2022 16:25:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/02/2022 16:25:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
06/02/2022 16:25:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/02/2022 16:25:17 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9820991153059465 on epoch=207
06/02/2022 16:25:19 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/02/2022 16:25:22 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/02/2022 16:25:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/02/2022 16:25:27 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=209
06/02/2022 16:25:30 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/02/2022 16:25:39 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9142130987292278 on epoch=210
06/02/2022 16:25:41 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.28 on epoch=211
06/02/2022 16:25:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/02/2022 16:25:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/02/2022 16:25:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/02/2022 16:25:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
06/02/2022 16:25:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 16:25:53 - INFO - __main__ - Printing 3 examples
06/02/2022 16:25:53 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 16:25:53 - INFO - __main__ - ['Film']
06/02/2022 16:25:53 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 16:25:53 - INFO - __main__ - ['Film']
06/02/2022 16:25:53 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 16:25:53 - INFO - __main__ - ['Film']
06/02/2022 16:25:53 - INFO - __main__ - Tokenizing Input ...
06/02/2022 16:25:53 - INFO - __main__ - Tokenizing Output ...
06/02/2022 16:25:54 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 16:25:54 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 16:25:54 - INFO - __main__ - Printing 3 examples
06/02/2022 16:25:54 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 16:25:54 - INFO - __main__ - ['Film']
06/02/2022 16:25:54 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 16:25:54 - INFO - __main__ - ['Film']
06/02/2022 16:25:54 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 16:25:54 - INFO - __main__ - ['Film']
06/02/2022 16:25:54 - INFO - __main__ - Tokenizing Input ...
06/02/2022 16:25:54 - INFO - __main__ - Tokenizing Output ...
06/02/2022 16:25:54 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 16:26:00 - INFO - __main__ - Global step 3000 Train loss 0.07 Classification-F1 0.9140303644968959 on epoch=214
06/02/2022 16:26:00 - INFO - __main__ - save last model!
06/02/2022 16:26:00 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 16:26:00 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 16:26:00 - INFO - __main__ - Printing 3 examples
06/02/2022 16:26:00 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 16:26:00 - INFO - __main__ - ['Animal']
06/02/2022 16:26:00 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 16:26:00 - INFO - __main__ - ['Animal']
06/02/2022 16:26:00 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 16:26:00 - INFO - __main__ - ['Village']
06/02/2022 16:26:00 - INFO - __main__ - Tokenizing Input ...
06/02/2022 16:26:02 - INFO - __main__ - Tokenizing Output ...
06/02/2022 16:26:06 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 16:26:09 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 16:26:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 16:26:10 - INFO - __main__ - Starting training!
06/02/2022 16:28:50 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
06/02/2022 16:28:50 - INFO - __main__ - Classification-F1 on test data: 0.5221
06/02/2022 16:28:50 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.9820991153059465, test_performance=0.5220585441153379
06/02/2022 16:28:50 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
06/02/2022 16:28:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 16:28:51 - INFO - __main__ - Printing 3 examples
06/02/2022 16:28:51 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 16:28:51 - INFO - __main__ - ['Film']
06/02/2022 16:28:51 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 16:28:51 - INFO - __main__ - ['Film']
06/02/2022 16:28:51 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 16:28:51 - INFO - __main__ - ['Film']
06/02/2022 16:28:51 - INFO - __main__ - Tokenizing Input ...
06/02/2022 16:28:51 - INFO - __main__ - Tokenizing Output ...
06/02/2022 16:28:51 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 16:28:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 16:28:51 - INFO - __main__ - Printing 3 examples
06/02/2022 16:28:51 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 16:28:51 - INFO - __main__ - ['Film']
06/02/2022 16:28:51 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 16:28:51 - INFO - __main__ - ['Film']
06/02/2022 16:28:51 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 16:28:51 - INFO - __main__ - ['Film']
06/02/2022 16:28:51 - INFO - __main__ - Tokenizing Input ...
06/02/2022 16:28:51 - INFO - __main__ - Tokenizing Output ...
06/02/2022 16:28:52 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 16:29:09 - INFO - __main__ - load prompt embedding from ckpt
06/02/2022 16:29:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.92M parameters
06/02/2022 16:29:10 - INFO - __main__ - Starting training!
06/02/2022 16:29:13 - INFO - __main__ - Step 10 Global step 10 Train loss 6.43 on epoch=0
06/02/2022 16:29:16 - INFO - __main__ - Step 20 Global step 20 Train loss 4.84 on epoch=1
06/02/2022 16:29:18 - INFO - __main__ - Step 30 Global step 30 Train loss 4.35 on epoch=2
06/02/2022 16:29:21 - INFO - __main__ - Step 40 Global step 40 Train loss 3.87 on epoch=2
06/02/2022 16:29:23 - INFO - __main__ - Step 50 Global step 50 Train loss 4.18 on epoch=3
06/02/2022 16:29:28 - INFO - __main__ - Global step 50 Train loss 4.73 Classification-F1 0.060366836649189584 on epoch=3
06/02/2022 16:29:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.060366836649189584 on epoch=3, global_step=50
06/02/2022 16:29:31 - INFO - __main__ - Step 60 Global step 60 Train loss 3.58 on epoch=4
06/02/2022 16:29:33 - INFO - __main__ - Step 70 Global step 70 Train loss 3.08 on epoch=4
06/02/2022 16:29:36 - INFO - __main__ - Step 80 Global step 80 Train loss 3.55 on epoch=5
06/02/2022 16:29:38 - INFO - __main__ - Step 90 Global step 90 Train loss 2.99 on epoch=6
06/02/2022 16:29:41 - INFO - __main__ - Step 100 Global step 100 Train loss 2.67 on epoch=7
06/02/2022 16:29:45 - INFO - __main__ - Global step 100 Train loss 3.17 Classification-F1 0.10506660808339159 on epoch=7
06/02/2022 16:29:45 - INFO - __main__ - Saving model with best Classification-F1: 0.060366836649189584 -> 0.10506660808339159 on epoch=7, global_step=100
06/02/2022 16:29:48 - INFO - __main__ - Step 110 Global step 110 Train loss 2.58 on epoch=7
06/02/2022 16:29:50 - INFO - __main__ - Step 120 Global step 120 Train loss 2.77 on epoch=8
06/02/2022 16:29:53 - INFO - __main__ - Step 130 Global step 130 Train loss 2.46 on epoch=9
06/02/2022 16:29:55 - INFO - __main__ - Step 140 Global step 140 Train loss 2.13 on epoch=9
06/02/2022 16:29:58 - INFO - __main__ - Step 150 Global step 150 Train loss 2.47 on epoch=10
06/02/2022 16:30:03 - INFO - __main__ - Global step 150 Train loss 2.48 Classification-F1 0.13067723367262538 on epoch=10
06/02/2022 16:30:03 - INFO - __main__ - Saving model with best Classification-F1: 0.10506660808339159 -> 0.13067723367262538 on epoch=10, global_step=150
06/02/2022 16:30:05 - INFO - __main__ - Step 160 Global step 160 Train loss 2.21 on epoch=11
06/02/2022 16:30:08 - INFO - __main__ - Step 170 Global step 170 Train loss 2.19 on epoch=12
06/02/2022 16:30:10 - INFO - __main__ - Step 180 Global step 180 Train loss 1.96 on epoch=12
06/02/2022 16:30:13 - INFO - __main__ - Step 190 Global step 190 Train loss 2.05 on epoch=13
06/02/2022 16:30:15 - INFO - __main__ - Step 200 Global step 200 Train loss 2.02 on epoch=14
06/02/2022 16:30:20 - INFO - __main__ - Global step 200 Train loss 2.09 Classification-F1 0.13551343883400077 on epoch=14
06/02/2022 16:30:20 - INFO - __main__ - Saving model with best Classification-F1: 0.13067723367262538 -> 0.13551343883400077 on epoch=14, global_step=200
06/02/2022 16:30:23 - INFO - __main__ - Step 210 Global step 210 Train loss 1.72 on epoch=14
06/02/2022 16:30:25 - INFO - __main__ - Step 220 Global step 220 Train loss 2.03 on epoch=15
06/02/2022 16:30:28 - INFO - __main__ - Step 230 Global step 230 Train loss 1.63 on epoch=16
06/02/2022 16:30:30 - INFO - __main__ - Step 240 Global step 240 Train loss 1.87 on epoch=17
06/02/2022 16:30:33 - INFO - __main__ - Step 250 Global step 250 Train loss 1.63 on epoch=17
06/02/2022 16:30:38 - INFO - __main__ - Global step 250 Train loss 1.78 Classification-F1 0.16892022685542246 on epoch=17
06/02/2022 16:30:38 - INFO - __main__ - Saving model with best Classification-F1: 0.13551343883400077 -> 0.16892022685542246 on epoch=17, global_step=250
06/02/2022 16:30:41 - INFO - __main__ - Step 260 Global step 260 Train loss 1.77 on epoch=18
06/02/2022 16:30:43 - INFO - __main__ - Step 270 Global step 270 Train loss 1.63 on epoch=19
06/02/2022 16:30:46 - INFO - __main__ - Step 280 Global step 280 Train loss 1.42 on epoch=19
06/02/2022 16:30:48 - INFO - __main__ - Step 290 Global step 290 Train loss 1.74 on epoch=20
06/02/2022 16:30:51 - INFO - __main__ - Step 300 Global step 300 Train loss 1.51 on epoch=21
06/02/2022 16:30:56 - INFO - __main__ - Global step 300 Train loss 1.62 Classification-F1 0.19450870557115366 on epoch=21
06/02/2022 16:30:56 - INFO - __main__ - Saving model with best Classification-F1: 0.16892022685542246 -> 0.19450870557115366 on epoch=21, global_step=300
06/02/2022 16:30:58 - INFO - __main__ - Step 310 Global step 310 Train loss 1.52 on epoch=22
06/02/2022 16:31:01 - INFO - __main__ - Step 320 Global step 320 Train loss 1.29 on epoch=22
06/02/2022 16:31:03 - INFO - __main__ - Step 330 Global step 330 Train loss 1.45 on epoch=23
06/02/2022 16:31:06 - INFO - __main__ - Step 340 Global step 340 Train loss 1.42 on epoch=24
06/02/2022 16:31:08 - INFO - __main__ - Step 350 Global step 350 Train loss 1.16 on epoch=24
06/02/2022 16:31:14 - INFO - __main__ - Global step 350 Train loss 1.37 Classification-F1 0.22226279966554569 on epoch=24
06/02/2022 16:31:14 - INFO - __main__ - Saving model with best Classification-F1: 0.19450870557115366 -> 0.22226279966554569 on epoch=24, global_step=350
06/02/2022 16:31:17 - INFO - __main__ - Step 360 Global step 360 Train loss 1.41 on epoch=25
06/02/2022 16:31:19 - INFO - __main__ - Step 370 Global step 370 Train loss 1.11 on epoch=26
06/02/2022 16:31:22 - INFO - __main__ - Step 380 Global step 380 Train loss 1.13 on epoch=27
06/02/2022 16:31:24 - INFO - __main__ - Step 390 Global step 390 Train loss 1.17 on epoch=27
06/02/2022 16:31:26 - INFO - __main__ - Step 400 Global step 400 Train loss 1.12 on epoch=28
06/02/2022 16:31:32 - INFO - __main__ - Global step 400 Train loss 1.19 Classification-F1 0.2978594427311096 on epoch=28
06/02/2022 16:31:32 - INFO - __main__ - Saving model with best Classification-F1: 0.22226279966554569 -> 0.2978594427311096 on epoch=28, global_step=400
06/02/2022 16:31:34 - INFO - __main__ - Step 410 Global step 410 Train loss 1.08 on epoch=29
06/02/2022 16:31:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.93 on epoch=29
06/02/2022 16:31:39 - INFO - __main__ - Step 430 Global step 430 Train loss 1.06 on epoch=30
06/02/2022 16:31:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.90 on epoch=31
06/02/2022 16:31:44 - INFO - __main__ - Step 450 Global step 450 Train loss 1.03 on epoch=32
06/02/2022 16:31:50 - INFO - __main__ - Global step 450 Train loss 1.00 Classification-F1 0.3138773658697757 on epoch=32
06/02/2022 16:31:50 - INFO - __main__ - Saving model with best Classification-F1: 0.2978594427311096 -> 0.3138773658697757 on epoch=32, global_step=450
06/02/2022 16:31:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.83 on epoch=32
06/02/2022 16:31:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.89 on epoch=33
06/02/2022 16:31:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.86 on epoch=34
06/02/2022 16:32:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.93 on epoch=34
06/02/2022 16:32:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.95 on epoch=35
06/02/2022 16:32:08 - INFO - __main__ - Global step 500 Train loss 0.89 Classification-F1 0.42168267303216095 on epoch=35
06/02/2022 16:32:08 - INFO - __main__ - Saving model with best Classification-F1: 0.3138773658697757 -> 0.42168267303216095 on epoch=35, global_step=500
06/02/2022 16:32:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.85 on epoch=36
06/02/2022 16:32:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.77 on epoch=37
06/02/2022 16:32:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.73 on epoch=37
06/02/2022 16:32:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.84 on epoch=38
06/02/2022 16:32:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.65 on epoch=39
06/02/2022 16:32:27 - INFO - __main__ - Global step 550 Train loss 0.77 Classification-F1 0.4759591541767817 on epoch=39
06/02/2022 16:32:27 - INFO - __main__ - Saving model with best Classification-F1: 0.42168267303216095 -> 0.4759591541767817 on epoch=39, global_step=550
06/02/2022 16:32:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.62 on epoch=39
06/02/2022 16:32:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.70 on epoch=40
06/02/2022 16:32:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.73 on epoch=41
06/02/2022 16:32:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.63 on epoch=42
06/02/2022 16:32:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.64 on epoch=42
06/02/2022 16:32:46 - INFO - __main__ - Global step 600 Train loss 0.66 Classification-F1 0.5037986154248668 on epoch=42
06/02/2022 16:32:46 - INFO - __main__ - Saving model with best Classification-F1: 0.4759591541767817 -> 0.5037986154248668 on epoch=42, global_step=600
06/02/2022 16:32:48 - INFO - __main__ - Step 610 Global step 610 Train loss 0.63 on epoch=43
06/02/2022 16:32:51 - INFO - __main__ - Step 620 Global step 620 Train loss 0.56 on epoch=44
06/02/2022 16:32:53 - INFO - __main__ - Step 630 Global step 630 Train loss 0.56 on epoch=44
06/02/2022 16:32:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.66 on epoch=45
06/02/2022 16:32:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.60 on epoch=46
06/02/2022 16:33:05 - INFO - __main__ - Global step 650 Train loss 0.60 Classification-F1 0.5643162031197615 on epoch=46
06/02/2022 16:33:05 - INFO - __main__ - Saving model with best Classification-F1: 0.5037986154248668 -> 0.5643162031197615 on epoch=46, global_step=650
06/02/2022 16:33:08 - INFO - __main__ - Step 660 Global step 660 Train loss 0.49 on epoch=47
06/02/2022 16:33:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.50 on epoch=47
06/02/2022 16:33:13 - INFO - __main__ - Step 680 Global step 680 Train loss 0.41 on epoch=48
06/02/2022 16:33:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.55 on epoch=49
06/02/2022 16:33:18 - INFO - __main__ - Step 700 Global step 700 Train loss 0.46 on epoch=49
06/02/2022 16:33:24 - INFO - __main__ - Global step 700 Train loss 0.48 Classification-F1 0.5175945521903776 on epoch=49
06/02/2022 16:33:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.55 on epoch=50
06/02/2022 16:33:29 - INFO - __main__ - Step 720 Global step 720 Train loss 0.53 on epoch=51
06/02/2022 16:33:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.56 on epoch=52
06/02/2022 16:33:34 - INFO - __main__ - Step 740 Global step 740 Train loss 0.42 on epoch=52
06/02/2022 16:33:37 - INFO - __main__ - Step 750 Global step 750 Train loss 0.42 on epoch=53
06/02/2022 16:33:43 - INFO - __main__ - Global step 750 Train loss 0.50 Classification-F1 0.5614637541871269 on epoch=53
06/02/2022 16:33:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.50 on epoch=54
06/02/2022 16:33:48 - INFO - __main__ - Step 770 Global step 770 Train loss 0.47 on epoch=54
06/02/2022 16:33:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.43 on epoch=55
06/02/2022 16:33:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.31 on epoch=56
06/02/2022 16:33:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.42 on epoch=57
06/02/2022 16:34:02 - INFO - __main__ - Global step 800 Train loss 0.42 Classification-F1 0.5595158559557916 on epoch=57
06/02/2022 16:34:04 - INFO - __main__ - Step 810 Global step 810 Train loss 0.41 on epoch=57
06/02/2022 16:34:07 - INFO - __main__ - Step 820 Global step 820 Train loss 0.49 on epoch=58
06/02/2022 16:34:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.38 on epoch=59
06/02/2022 16:34:12 - INFO - __main__ - Step 840 Global step 840 Train loss 0.44 on epoch=59
06/02/2022 16:34:14 - INFO - __main__ - Step 850 Global step 850 Train loss 0.41 on epoch=60
06/02/2022 16:34:21 - INFO - __main__ - Global step 850 Train loss 0.43 Classification-F1 0.5801832991886863 on epoch=60
06/02/2022 16:34:21 - INFO - __main__ - Saving model with best Classification-F1: 0.5643162031197615 -> 0.5801832991886863 on epoch=60, global_step=850
06/02/2022 16:34:23 - INFO - __main__ - Step 860 Global step 860 Train loss 0.34 on epoch=61
06/02/2022 16:34:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.41 on epoch=62
06/02/2022 16:34:28 - INFO - __main__ - Step 880 Global step 880 Train loss 0.33 on epoch=62
06/02/2022 16:34:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.37 on epoch=63
06/02/2022 16:34:33 - INFO - __main__ - Step 900 Global step 900 Train loss 0.34 on epoch=64
06/02/2022 16:34:40 - INFO - __main__ - Global step 900 Train loss 0.36 Classification-F1 0.6056990732285263 on epoch=64
06/02/2022 16:34:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5801832991886863 -> 0.6056990732285263 on epoch=64, global_step=900
06/02/2022 16:34:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.40 on epoch=64
06/02/2022 16:34:45 - INFO - __main__ - Step 920 Global step 920 Train loss 0.33 on epoch=65
06/02/2022 16:34:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.29 on epoch=66
06/02/2022 16:34:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.31 on epoch=67
06/02/2022 16:34:52 - INFO - __main__ - Step 950 Global step 950 Train loss 0.35 on epoch=67
06/02/2022 16:34:59 - INFO - __main__ - Global step 950 Train loss 0.34 Classification-F1 0.5717376104328181 on epoch=67
06/02/2022 16:35:01 - INFO - __main__ - Step 960 Global step 960 Train loss 0.29 on epoch=68
06/02/2022 16:35:04 - INFO - __main__ - Step 970 Global step 970 Train loss 0.31 on epoch=69
06/02/2022 16:35:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.33 on epoch=69
06/02/2022 16:35:09 - INFO - __main__ - Step 990 Global step 990 Train loss 0.29 on epoch=70
06/02/2022 16:35:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.33 on epoch=71
06/02/2022 16:35:18 - INFO - __main__ - Global step 1000 Train loss 0.31 Classification-F1 0.6293044135351147 on epoch=71
06/02/2022 16:35:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6056990732285263 -> 0.6293044135351147 on epoch=71, global_step=1000
06/02/2022 16:35:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.25 on epoch=72
06/02/2022 16:35:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.32 on epoch=72
06/02/2022 16:35:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.31 on epoch=73
06/02/2022 16:35:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.31 on epoch=74
06/02/2022 16:35:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.28 on epoch=74
06/02/2022 16:35:37 - INFO - __main__ - Global step 1050 Train loss 0.29 Classification-F1 0.6313056643168533 on epoch=74
06/02/2022 16:35:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6293044135351147 -> 0.6313056643168533 on epoch=74, global_step=1050
06/02/2022 16:35:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.33 on epoch=75
06/02/2022 16:35:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.29 on epoch=76
06/02/2022 16:35:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.28 on epoch=77
06/02/2022 16:35:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.24 on epoch=77
06/02/2022 16:35:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.31 on epoch=78
06/02/2022 16:35:56 - INFO - __main__ - Global step 1100 Train loss 0.29 Classification-F1 0.6203922050162973 on epoch=78
06/02/2022 16:35:59 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=79
06/02/2022 16:36:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.29 on epoch=79
06/02/2022 16:36:04 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.24 on epoch=80
06/02/2022 16:36:06 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.29 on epoch=81
06/02/2022 16:36:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.27 on epoch=82
06/02/2022 16:36:15 - INFO - __main__ - Global step 1150 Train loss 0.26 Classification-F1 0.6240756553651801 on epoch=82
06/02/2022 16:36:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.24 on epoch=82
06/02/2022 16:36:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.25 on epoch=83
06/02/2022 16:36:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.20 on epoch=84
06/02/2022 16:36:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.29 on epoch=84
06/02/2022 16:36:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=85
06/02/2022 16:36:34 - INFO - __main__ - Global step 1200 Train loss 0.23 Classification-F1 0.6247594064423222 on epoch=85
06/02/2022 16:36:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.28 on epoch=86
06/02/2022 16:36:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.18 on epoch=87
06/02/2022 16:36:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.25 on epoch=87
06/02/2022 16:36:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.21 on epoch=88
06/02/2022 16:36:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.23 on epoch=89
06/02/2022 16:36:54 - INFO - __main__ - Global step 1250 Train loss 0.23 Classification-F1 0.5900059707110861 on epoch=89
06/02/2022 16:36:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.23 on epoch=89
06/02/2022 16:36:59 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.19 on epoch=90
06/02/2022 16:37:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=91
06/02/2022 16:37:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.20 on epoch=92
06/02/2022 16:37:06 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.19 on epoch=92
06/02/2022 16:37:13 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.5873236483816668 on epoch=92
06/02/2022 16:37:15 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.25 on epoch=93
06/02/2022 16:37:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.23 on epoch=94
06/02/2022 16:37:20 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.20 on epoch=94
06/02/2022 16:37:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.21 on epoch=95
06/02/2022 16:37:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.22 on epoch=96
06/02/2022 16:37:32 - INFO - __main__ - Global step 1350 Train loss 0.22 Classification-F1 0.6574136381324968 on epoch=96
06/02/2022 16:37:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6313056643168533 -> 0.6574136381324968 on epoch=96, global_step=1350
06/02/2022 16:37:35 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.25 on epoch=97
06/02/2022 16:37:37 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.17 on epoch=97
06/02/2022 16:37:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.22 on epoch=98
06/02/2022 16:37:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.22 on epoch=99
06/02/2022 16:37:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.18 on epoch=99
06/02/2022 16:37:51 - INFO - __main__ - Global step 1400 Train loss 0.21 Classification-F1 0.6930387504642123 on epoch=99
06/02/2022 16:37:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6574136381324968 -> 0.6930387504642123 on epoch=99, global_step=1400
06/02/2022 16:37:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.23 on epoch=100
06/02/2022 16:37:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.30 on epoch=101
06/02/2022 16:37:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.14 on epoch=102
06/02/2022 16:38:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=102
06/02/2022 16:38:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.26 on epoch=103
06/02/2022 16:38:10 - INFO - __main__ - Global step 1450 Train loss 0.22 Classification-F1 0.6821813341862794 on epoch=103
06/02/2022 16:38:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.26 on epoch=104
06/02/2022 16:38:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.28 on epoch=104
06/02/2022 16:38:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.15 on epoch=105
06/02/2022 16:38:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.16 on epoch=106
06/02/2022 16:38:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.17 on epoch=107
06/02/2022 16:38:30 - INFO - __main__ - Global step 1500 Train loss 0.20 Classification-F1 0.6702334398803028 on epoch=107
06/02/2022 16:38:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.22 on epoch=107
06/02/2022 16:38:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.18 on epoch=108
06/02/2022 16:38:37 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.21 on epoch=109
06/02/2022 16:38:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.22 on epoch=109
06/02/2022 16:38:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.14 on epoch=110
06/02/2022 16:38:49 - INFO - __main__ - Global step 1550 Train loss 0.19 Classification-F1 0.7508189127731998 on epoch=110
06/02/2022 16:38:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6930387504642123 -> 0.7508189127731998 on epoch=110, global_step=1550
06/02/2022 16:38:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.17 on epoch=111
06/02/2022 16:38:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.20 on epoch=112
06/02/2022 16:38:56 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.17 on epoch=112
06/02/2022 16:38:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.19 on epoch=113
06/02/2022 16:39:01 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.20 on epoch=114
06/02/2022 16:39:08 - INFO - __main__ - Global step 1600 Train loss 0.19 Classification-F1 0.7279815727898138 on epoch=114
06/02/2022 16:39:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.16 on epoch=114
06/02/2022 16:39:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.15 on epoch=115
06/02/2022 16:39:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.22 on epoch=116
06/02/2022 16:39:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.18 on epoch=117
06/02/2022 16:39:20 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.15 on epoch=117
06/02/2022 16:39:27 - INFO - __main__ - Global step 1650 Train loss 0.17 Classification-F1 0.7222513543056015 on epoch=117
06/02/2022 16:39:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.15 on epoch=118
06/02/2022 16:39:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.19 on epoch=119
06/02/2022 16:39:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.23 on epoch=119
06/02/2022 16:39:37 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=120
06/02/2022 16:39:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.18 on epoch=121
06/02/2022 16:39:47 - INFO - __main__ - Global step 1700 Train loss 0.18 Classification-F1 0.7768389453167518 on epoch=121
06/02/2022 16:39:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7508189127731998 -> 0.7768389453167518 on epoch=121, global_step=1700
06/02/2022 16:39:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.20 on epoch=122
06/02/2022 16:39:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=122
06/02/2022 16:39:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.15 on epoch=123
06/02/2022 16:39:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.20 on epoch=124
06/02/2022 16:39:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.18 on epoch=124
06/02/2022 16:40:06 - INFO - __main__ - Global step 1750 Train loss 0.17 Classification-F1 0.7222445659923616 on epoch=124
06/02/2022 16:40:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=125
06/02/2022 16:40:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.13 on epoch=126
06/02/2022 16:40:13 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.16 on epoch=127
06/02/2022 16:40:15 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.13 on epoch=127
06/02/2022 16:40:18 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.16 on epoch=128
06/02/2022 16:40:25 - INFO - __main__ - Global step 1800 Train loss 0.14 Classification-F1 0.7336661871700804 on epoch=128
06/02/2022 16:40:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=129
06/02/2022 16:40:30 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.17 on epoch=129
06/02/2022 16:40:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.13 on epoch=130
06/02/2022 16:40:35 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=131
06/02/2022 16:40:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.19 on epoch=132
06/02/2022 16:40:44 - INFO - __main__ - Global step 1850 Train loss 0.14 Classification-F1 0.7815174041128576 on epoch=132
06/02/2022 16:40:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7768389453167518 -> 0.7815174041128576 on epoch=132, global_step=1850
06/02/2022 16:40:46 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=132
06/02/2022 16:40:49 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.18 on epoch=133
06/02/2022 16:40:51 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=134
06/02/2022 16:40:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.16 on epoch=134
06/02/2022 16:40:56 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=135
06/02/2022 16:41:03 - INFO - __main__ - Global step 1900 Train loss 0.14 Classification-F1 0.785537618659388 on epoch=135
06/02/2022 16:41:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7815174041128576 -> 0.785537618659388 on epoch=135, global_step=1900
06/02/2022 16:41:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.14 on epoch=136
06/02/2022 16:41:08 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.19 on epoch=137
06/02/2022 16:41:10 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.13 on epoch=137
06/02/2022 16:41:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.13 on epoch=138
06/02/2022 16:41:15 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.14 on epoch=139
06/02/2022 16:41:22 - INFO - __main__ - Global step 1950 Train loss 0.15 Classification-F1 0.7500722035760968 on epoch=139
06/02/2022 16:41:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.11 on epoch=139
06/02/2022 16:41:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=140
06/02/2022 16:41:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.14 on epoch=141
06/02/2022 16:41:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.12 on epoch=142
06/02/2022 16:41:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=142
06/02/2022 16:41:41 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.7463257442740819 on epoch=142
06/02/2022 16:41:43 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.13 on epoch=143
06/02/2022 16:41:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=144
06/02/2022 16:41:48 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.12 on epoch=144
06/02/2022 16:41:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=145
06/02/2022 16:41:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.12 on epoch=146
06/02/2022 16:42:00 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.7478196751797775 on epoch=146
06/02/2022 16:42:03 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.11 on epoch=147
06/02/2022 16:42:05 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
06/02/2022 16:42:07 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.13 on epoch=148
06/02/2022 16:42:10 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.10 on epoch=149
06/02/2022 16:42:12 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.11 on epoch=149
06/02/2022 16:42:19 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.7513157363608483 on epoch=149
06/02/2022 16:42:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=150
06/02/2022 16:42:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
06/02/2022 16:42:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=152
06/02/2022 16:42:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=152
06/02/2022 16:42:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=153
06/02/2022 16:42:38 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.755856675767688 on epoch=153
06/02/2022 16:42:41 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.13 on epoch=154
06/02/2022 16:42:43 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=154
06/02/2022 16:42:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=155
06/02/2022 16:42:48 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=156
06/02/2022 16:42:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.11 on epoch=157
06/02/2022 16:42:57 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.7987807453973245 on epoch=157
06/02/2022 16:42:57 - INFO - __main__ - Saving model with best Classification-F1: 0.785537618659388 -> 0.7987807453973245 on epoch=157, global_step=2200
06/02/2022 16:43:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=157
06/02/2022 16:43:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=158
06/02/2022 16:43:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.12 on epoch=159
06/02/2022 16:43:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.16 on epoch=159
06/02/2022 16:43:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=160
06/02/2022 16:43:16 - INFO - __main__ - Global step 2250 Train loss 0.11 Classification-F1 0.8045064926567251 on epoch=160
06/02/2022 16:43:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7987807453973245 -> 0.8045064926567251 on epoch=160, global_step=2250
06/02/2022 16:43:19 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.12 on epoch=161
06/02/2022 16:43:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.11 on epoch=162
06/02/2022 16:43:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=162
06/02/2022 16:43:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.13 on epoch=163
06/02/2022 16:43:29 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.15 on epoch=164
06/02/2022 16:43:35 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.8528942090538308 on epoch=164
06/02/2022 16:43:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8045064926567251 -> 0.8528942090538308 on epoch=164, global_step=2300
06/02/2022 16:43:38 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.10 on epoch=164
06/02/2022 16:43:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
06/02/2022 16:43:43 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=166
06/02/2022 16:43:45 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=167
06/02/2022 16:43:48 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=167
06/02/2022 16:43:55 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.8646244143324232 on epoch=167
06/02/2022 16:43:55 - INFO - __main__ - Saving model with best Classification-F1: 0.8528942090538308 -> 0.8646244143324232 on epoch=167, global_step=2350
06/02/2022 16:43:57 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
06/02/2022 16:44:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=169
06/02/2022 16:44:02 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.11 on epoch=169
06/02/2022 16:44:05 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=170
06/02/2022 16:44:07 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.11 on epoch=171
06/02/2022 16:44:14 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.8607143459062259 on epoch=171
06/02/2022 16:44:17 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=172
06/02/2022 16:44:19 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=172
06/02/2022 16:44:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.10 on epoch=173
06/02/2022 16:44:24 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.12 on epoch=174
06/02/2022 16:44:27 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.09 on epoch=174
06/02/2022 16:44:33 - INFO - __main__ - Global step 2450 Train loss 0.09 Classification-F1 0.8045064926567251 on epoch=174
06/02/2022 16:44:36 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=175
06/02/2022 16:44:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.14 on epoch=176
06/02/2022 16:44:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=177
06/02/2022 16:44:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.11 on epoch=177
06/02/2022 16:44:46 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.11 on epoch=178
06/02/2022 16:44:53 - INFO - __main__ - Global step 2500 Train loss 0.10 Classification-F1 0.8568042774800283 on epoch=178
06/02/2022 16:44:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.16 on epoch=179
06/02/2022 16:44:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.11 on epoch=179
06/02/2022 16:45:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=180
06/02/2022 16:45:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.09 on epoch=181
06/02/2022 16:45:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=182
06/02/2022 16:45:13 - INFO - __main__ - Global step 2550 Train loss 0.10 Classification-F1 0.8607143459062259 on epoch=182
06/02/2022 16:45:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=182
06/02/2022 16:45:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=183
06/02/2022 16:45:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.10 on epoch=184
06/02/2022 16:45:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=184
06/02/2022 16:45:26 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=185
06/02/2022 16:45:33 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.8568042774800283 on epoch=185
06/02/2022 16:45:36 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.09 on epoch=186
06/02/2022 16:45:38 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.11 on epoch=187
06/02/2022 16:45:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/02/2022 16:45:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=188
06/02/2022 16:45:46 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.12 on epoch=189
06/02/2022 16:45:53 - INFO - __main__ - Global step 2650 Train loss 0.09 Classification-F1 0.8568042774800283 on epoch=189
06/02/2022 16:45:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.09 on epoch=189
06/02/2022 16:45:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=190
06/02/2022 16:46:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=191
06/02/2022 16:46:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=192
06/02/2022 16:46:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/02/2022 16:46:14 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.9120231960381148 on epoch=192
06/02/2022 16:46:14 - INFO - __main__ - Saving model with best Classification-F1: 0.8646244143324232 -> 0.9120231960381148 on epoch=192, global_step=2700
06/02/2022 16:46:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.07 on epoch=193
06/02/2022 16:46:19 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=194
06/02/2022 16:46:22 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.09 on epoch=194
06/02/2022 16:46:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=195
06/02/2022 16:46:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=196
06/02/2022 16:46:35 - INFO - __main__ - Global step 2750 Train loss 0.07 Classification-F1 0.8568042774800283 on epoch=196
06/02/2022 16:46:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.08 on epoch=197
06/02/2022 16:46:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=197
06/02/2022 16:46:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.11 on epoch=198
06/02/2022 16:46:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.10 on epoch=199
06/02/2022 16:46:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.11 on epoch=199
06/02/2022 16:46:55 - INFO - __main__ - Global step 2800 Train loss 0.09 Classification-F1 0.8607143459062259 on epoch=199
06/02/2022 16:46:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=200
06/02/2022 16:47:00 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/02/2022 16:47:03 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.10 on epoch=202
06/02/2022 16:47:05 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/02/2022 16:47:08 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.10 on epoch=203
06/02/2022 16:47:16 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.8568042774800284 on epoch=203
06/02/2022 16:47:18 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=204
06/02/2022 16:47:21 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.10 on epoch=204
06/02/2022 16:47:23 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.08 on epoch=205
06/02/2022 16:47:26 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=206
06/02/2022 16:47:29 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.11 on epoch=207
06/02/2022 16:47:36 - INFO - __main__ - Global step 2900 Train loss 0.08 Classification-F1 0.9120231960381148 on epoch=207
06/02/2022 16:47:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=207
06/02/2022 16:47:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.10 on epoch=208
06/02/2022 16:47:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=209
06/02/2022 16:47:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=209
06/02/2022 16:47:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.07 on epoch=210
06/02/2022 16:47:56 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.8568042774800283 on epoch=210
06/02/2022 16:47:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.12 on epoch=211
06/02/2022 16:48:02 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=212
06/02/2022 16:48:04 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/02/2022 16:48:07 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=213
06/02/2022 16:48:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.09 on epoch=214
06/02/2022 16:48:17 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.9120231960381148 on epoch=214
06/02/2022 16:48:17 - INFO - __main__ - save last model!
06/02/2022 16:48:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 16:48:17 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 16:48:17 - INFO - __main__ - Printing 3 examples
06/02/2022 16:48:17 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 16:48:17 - INFO - __main__ - ['Animal']
06/02/2022 16:48:17 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 16:48:17 - INFO - __main__ - ['Animal']
06/02/2022 16:48:17 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 16:48:17 - INFO - __main__ - ['Village']
06/02/2022 16:48:17 - INFO - __main__ - Tokenizing Input ...
06/02/2022 16:48:19 - INFO - __main__ - Tokenizing Output ...
06/02/2022 16:48:23 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 16:50:49 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-50prompt/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
06/02/2022 16:50:49 - INFO - __main__ - Classification-F1 on test data: 0.5677
06/02/2022 16:50:49 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.9120231960381148, test_performance=0.5677356983175444
