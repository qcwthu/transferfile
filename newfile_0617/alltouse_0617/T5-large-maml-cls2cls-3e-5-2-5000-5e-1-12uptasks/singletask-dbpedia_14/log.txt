05/27/2022 22:34:56 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/27/2022 22:34:56 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14
05/27/2022 22:34:56 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/27/2022 22:34:56 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14
05/27/2022 22:34:58 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/27/2022 22:34:58 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/27/2022 22:34:58 - INFO - __main__ - args.device: cuda:1
05/27/2022 22:34:58 - INFO - __main__ - args.device: cuda:0
05/27/2022 22:34:58 - INFO - __main__ - Using 2 gpus
05/27/2022 22:34:58 - INFO - __main__ - Using 2 gpus
05/27/2022 22:34:58 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/27/2022 22:34:58 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/27/2022 22:35:03 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
05/27/2022 22:35:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 22:35:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 22:35:03 - INFO - __main__ - Printing 3 examples
05/27/2022 22:35:03 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/27/2022 22:35:03 - INFO - __main__ - ['Animal']
05/27/2022 22:35:03 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/27/2022 22:35:03 - INFO - __main__ - ['Animal']
05/27/2022 22:35:03 - INFO - __main__ - Printing 3 examples
05/27/2022 22:35:03 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/27/2022 22:35:03 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/27/2022 22:35:03 - INFO - __main__ - ['Animal']
05/27/2022 22:35:03 - INFO - __main__ - ['Animal']
05/27/2022 22:35:03 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/27/2022 22:35:03 - INFO - __main__ - ['Animal']
05/27/2022 22:35:03 - INFO - __main__ - Tokenizing Input ...
05/27/2022 22:35:03 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/27/2022 22:35:03 - INFO - __main__ - ['Animal']
05/27/2022 22:35:03 - INFO - __main__ - Tokenizing Input ...
05/27/2022 22:35:04 - INFO - __main__ - Tokenizing Output ...
05/27/2022 22:35:04 - INFO - __main__ - Tokenizing Output ...
05/27/2022 22:35:04 - INFO - __main__ - Loaded 224 examples from train data
05/27/2022 22:35:04 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 22:35:04 - INFO - __main__ - Printing 3 examples
05/27/2022 22:35:04 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/27/2022 22:35:04 - INFO - __main__ - ['Animal']
05/27/2022 22:35:04 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/27/2022 22:35:04 - INFO - __main__ - ['Animal']
05/27/2022 22:35:04 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/27/2022 22:35:04 - INFO - __main__ - ['Animal']
05/27/2022 22:35:04 - INFO - __main__ - Tokenizing Input ...
05/27/2022 22:35:04 - INFO - __main__ - Loaded 224 examples from train data
05/27/2022 22:35:04 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 22:35:04 - INFO - __main__ - Printing 3 examples
05/27/2022 22:35:04 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/27/2022 22:35:04 - INFO - __main__ - ['Animal']
05/27/2022 22:35:04 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/27/2022 22:35:04 - INFO - __main__ - ['Animal']
05/27/2022 22:35:04 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/27/2022 22:35:04 - INFO - __main__ - ['Animal']
05/27/2022 22:35:04 - INFO - __main__ - Tokenizing Input ...
05/27/2022 22:35:04 - INFO - __main__ - Tokenizing Output ...
05/27/2022 22:35:04 - INFO - __main__ - Tokenizing Output ...
05/27/2022 22:35:04 - INFO - __main__ - Loaded 224 examples from dev data
05/27/2022 22:35:04 - INFO - __main__ - Loaded 224 examples from dev data
05/27/2022 22:35:22 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 22:35:22 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 22:35:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 22:35:23 - INFO - __main__ - Starting training!
05/27/2022 22:35:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 22:35:28 - INFO - __main__ - Starting training!
05/27/2022 22:35:32 - INFO - __main__ - Step 10 Global step 10 Train loss 6.13 on epoch=0
05/27/2022 22:35:34 - INFO - __main__ - Step 20 Global step 20 Train loss 3.83 on epoch=1
05/27/2022 22:35:37 - INFO - __main__ - Step 30 Global step 30 Train loss 2.88 on epoch=2
05/27/2022 22:35:39 - INFO - __main__ - Step 40 Global step 40 Train loss 2.20 on epoch=2
05/27/2022 22:35:42 - INFO - __main__ - Step 50 Global step 50 Train loss 1.82 on epoch=3
05/27/2022 22:35:46 - INFO - __main__ - Global step 50 Train loss 3.37 Classification-F1 0.31883424767756563 on epoch=3
05/27/2022 22:35:46 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.31883424767756563 on epoch=3, global_step=50
05/27/2022 22:35:49 - INFO - __main__ - Step 60 Global step 60 Train loss 1.43 on epoch=4
05/27/2022 22:35:51 - INFO - __main__ - Step 70 Global step 70 Train loss 1.12 on epoch=4
05/27/2022 22:35:54 - INFO - __main__ - Step 80 Global step 80 Train loss 1.03 on epoch=5
05/27/2022 22:35:56 - INFO - __main__ - Step 90 Global step 90 Train loss 0.97 on epoch=6
05/27/2022 22:35:58 - INFO - __main__ - Step 100 Global step 100 Train loss 0.91 on epoch=7
05/27/2022 22:36:05 - INFO - __main__ - Global step 100 Train loss 1.09 Classification-F1 0.5178581935560794 on epoch=7
05/27/2022 22:36:05 - INFO - __main__ - Saving model with best Classification-F1: 0.31883424767756563 -> 0.5178581935560794 on epoch=7, global_step=100
05/27/2022 22:36:07 - INFO - __main__ - Step 110 Global step 110 Train loss 0.67 on epoch=7
05/27/2022 22:36:10 - INFO - __main__ - Step 120 Global step 120 Train loss 0.63 on epoch=8
05/27/2022 22:36:12 - INFO - __main__ - Step 130 Global step 130 Train loss 0.74 on epoch=9
05/27/2022 22:36:15 - INFO - __main__ - Step 140 Global step 140 Train loss 0.54 on epoch=9
05/27/2022 22:36:17 - INFO - __main__ - Step 150 Global step 150 Train loss 0.66 on epoch=10
05/27/2022 22:36:23 - INFO - __main__ - Global step 150 Train loss 0.65 Classification-F1 0.6574708279962772 on epoch=10
05/27/2022 22:36:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5178581935560794 -> 0.6574708279962772 on epoch=10, global_step=150
05/27/2022 22:36:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.49 on epoch=11
05/27/2022 22:36:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.65 on epoch=12
05/27/2022 22:36:31 - INFO - __main__ - Step 180 Global step 180 Train loss 0.41 on epoch=12
05/27/2022 22:36:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.50 on epoch=13
05/27/2022 22:36:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.46 on epoch=14
05/27/2022 22:36:43 - INFO - __main__ - Global step 200 Train loss 0.50 Classification-F1 0.5864829824776665 on epoch=14
05/27/2022 22:36:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.39 on epoch=14
05/27/2022 22:36:48 - INFO - __main__ - Step 220 Global step 220 Train loss 0.53 on epoch=15
05/27/2022 22:36:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.38 on epoch=16
05/27/2022 22:36:53 - INFO - __main__ - Step 240 Global step 240 Train loss 0.41 on epoch=17
05/27/2022 22:36:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.38 on epoch=17
05/27/2022 22:37:02 - INFO - __main__ - Global step 250 Train loss 0.42 Classification-F1 0.7380826307023813 on epoch=17
05/27/2022 22:37:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6574708279962772 -> 0.7380826307023813 on epoch=17, global_step=250
05/27/2022 22:37:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.38 on epoch=18
05/27/2022 22:37:07 - INFO - __main__ - Step 270 Global step 270 Train loss 0.42 on epoch=19
05/27/2022 22:37:10 - INFO - __main__ - Step 280 Global step 280 Train loss 0.35 on epoch=19
05/27/2022 22:37:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.37 on epoch=20
05/27/2022 22:37:15 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=21
05/27/2022 22:37:22 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.8292159112320403 on epoch=21
05/27/2022 22:37:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7380826307023813 -> 0.8292159112320403 on epoch=21, global_step=300
05/27/2022 22:37:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.45 on epoch=22
05/27/2022 22:37:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=22
05/27/2022 22:37:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.32 on epoch=23
05/27/2022 22:37:32 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=24
05/27/2022 22:37:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=24
05/27/2022 22:37:41 - INFO - __main__ - Global step 350 Train loss 0.32 Classification-F1 0.7976360002829654 on epoch=24
05/27/2022 22:37:43 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=25
05/27/2022 22:37:46 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=26
05/27/2022 22:37:48 - INFO - __main__ - Step 380 Global step 380 Train loss 0.26 on epoch=27
05/27/2022 22:37:51 - INFO - __main__ - Step 390 Global step 390 Train loss 0.15 on epoch=27
05/27/2022 22:37:53 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=28
05/27/2022 22:38:00 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.7982093930590246 on epoch=28
05/27/2022 22:38:02 - INFO - __main__ - Step 410 Global step 410 Train loss 0.15 on epoch=29
05/27/2022 22:38:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=29
05/27/2022 22:38:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=30
05/27/2022 22:38:09 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=31
05/27/2022 22:38:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.15 on epoch=32
05/27/2022 22:38:18 - INFO - __main__ - Global step 450 Train loss 0.19 Classification-F1 0.8831468444163402 on epoch=32
05/27/2022 22:38:18 - INFO - __main__ - Saving model with best Classification-F1: 0.8292159112320403 -> 0.8831468444163402 on epoch=32, global_step=450
05/27/2022 22:38:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=32
05/27/2022 22:38:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.11 on epoch=33
05/27/2022 22:38:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.13 on epoch=34
05/27/2022 22:38:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.13 on epoch=34
05/27/2022 22:38:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.16 on epoch=35
05/27/2022 22:38:37 - INFO - __main__ - Global step 500 Train loss 0.13 Classification-F1 0.5881319255675567 on epoch=35
05/27/2022 22:38:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=36
05/27/2022 22:38:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=37
05/27/2022 22:38:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=37
05/27/2022 22:38:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.12 on epoch=38
05/27/2022 22:38:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=39
05/27/2022 22:38:55 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.7454638551412744 on epoch=39
05/27/2022 22:38:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=39
05/27/2022 22:39:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=40
05/27/2022 22:39:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=41
05/27/2022 22:39:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.11 on epoch=42
05/27/2022 22:39:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=42
05/27/2022 22:39:14 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.7381101086285817 on epoch=42
05/27/2022 22:39:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=43
05/27/2022 22:39:19 - INFO - __main__ - Step 620 Global step 620 Train loss 0.09 on epoch=44
05/27/2022 22:39:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=44
05/27/2022 22:39:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=45
05/27/2022 22:39:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=46
05/27/2022 22:39:32 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.8608810272235322 on epoch=46
05/27/2022 22:39:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=47
05/27/2022 22:39:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=47
05/27/2022 22:39:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=48
05/27/2022 22:39:42 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=49
05/27/2022 22:39:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=49
05/27/2022 22:39:50 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.8069537733837426 on epoch=49
05/27/2022 22:39:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=50
05/27/2022 22:39:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=51
05/27/2022 22:39:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.06 on epoch=52
05/27/2022 22:40:01 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=52
05/27/2022 22:40:03 - INFO - __main__ - Step 750 Global step 750 Train loss 0.04 on epoch=53
05/27/2022 22:40:09 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.9031628496951078 on epoch=53
05/27/2022 22:40:09 - INFO - __main__ - Saving model with best Classification-F1: 0.8831468444163402 -> 0.9031628496951078 on epoch=53, global_step=750
05/27/2022 22:40:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=54
05/27/2022 22:40:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=54
05/27/2022 22:40:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=55
05/27/2022 22:40:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=56
05/27/2022 22:40:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=57
05/27/2022 22:40:28 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.908242214774473 on epoch=57
05/27/2022 22:40:28 - INFO - __main__ - Saving model with best Classification-F1: 0.9031628496951078 -> 0.908242214774473 on epoch=57, global_step=800
05/27/2022 22:40:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=57
05/27/2022 22:40:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=58
05/27/2022 22:40:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=59
05/27/2022 22:40:38 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=59
05/27/2022 22:40:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=60
05/27/2022 22:40:46 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.8508627164714606 on epoch=60
05/27/2022 22:40:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=61
05/27/2022 22:40:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=62
05/27/2022 22:40:53 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=62
05/27/2022 22:40:56 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=63
05/27/2022 22:40:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=64
05/27/2022 22:41:04 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.8864702528127576 on epoch=64
05/27/2022 22:41:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=64
05/27/2022 22:41:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=65
05/27/2022 22:41:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=66
05/27/2022 22:41:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=67
05/27/2022 22:41:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=67
05/27/2022 22:41:22 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.8900712191034773 on epoch=67
05/27/2022 22:41:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=68
05/27/2022 22:41:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=69
05/27/2022 22:41:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=69
05/27/2022 22:41:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=70
05/27/2022 22:41:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=71
05/27/2022 22:41:40 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.8224005762206101 on epoch=71
05/27/2022 22:41:43 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=72
05/27/2022 22:41:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
05/27/2022 22:41:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=73
05/27/2022 22:41:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
05/27/2022 22:41:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=74
05/27/2022 22:41:59 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.98225708905263 on epoch=74
05/27/2022 22:41:59 - INFO - __main__ - Saving model with best Classification-F1: 0.908242214774473 -> 0.98225708905263 on epoch=74, global_step=1050
05/27/2022 22:42:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
05/27/2022 22:42:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=76
05/27/2022 22:42:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=77
05/27/2022 22:42:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
05/27/2022 22:42:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=78
05/27/2022 22:42:18 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.8592183546805819 on epoch=78
05/27/2022 22:42:21 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=79
05/27/2022 22:42:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=79
05/27/2022 22:42:26 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
05/27/2022 22:42:28 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=81
05/27/2022 22:42:31 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=82
05/27/2022 22:42:36 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.8710158788524414 on epoch=82
05/27/2022 22:42:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=82
05/27/2022 22:42:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=83
05/27/2022 22:42:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=84
05/27/2022 22:42:46 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=84
05/27/2022 22:42:49 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=85
05/27/2022 22:42:55 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.9085983437580528 on epoch=85
05/27/2022 22:42:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=86
05/27/2022 22:43:00 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=87
05/27/2022 22:43:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=87
05/27/2022 22:43:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=88
05/27/2022 22:43:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=89
05/27/2022 22:43:13 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.9084509015944817 on epoch=89
05/27/2022 22:43:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=89
05/27/2022 22:43:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
05/27/2022 22:43:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=91
05/27/2022 22:43:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
05/27/2022 22:43:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
05/27/2022 22:43:31 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.9036965480229237 on epoch=92
05/27/2022 22:43:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
05/27/2022 22:43:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
05/27/2022 22:43:39 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
05/27/2022 22:43:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
05/27/2022 22:43:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
05/27/2022 22:43:50 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.9071020314284072 on epoch=96
05/27/2022 22:43:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=97
05/27/2022 22:43:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
05/27/2022 22:43:57 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=98
05/27/2022 22:44:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
05/27/2022 22:44:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=99
05/27/2022 22:44:09 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.8969271167373634 on epoch=99
05/27/2022 22:44:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
05/27/2022 22:44:14 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=101
05/27/2022 22:44:16 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
05/27/2022 22:44:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
05/27/2022 22:44:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
05/27/2022 22:44:28 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.9865677649358864 on epoch=103
05/27/2022 22:44:28 - INFO - __main__ - Saving model with best Classification-F1: 0.98225708905263 -> 0.9865677649358864 on epoch=103, global_step=1450
05/27/2022 22:44:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
05/27/2022 22:44:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
05/27/2022 22:44:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
05/27/2022 22:44:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
05/27/2022 22:44:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
05/27/2022 22:44:46 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.9776348295916607 on epoch=107
05/27/2022 22:44:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
05/27/2022 22:44:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
05/27/2022 22:44:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=109
05/27/2022 22:44:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
05/27/2022 22:44:59 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=110
05/27/2022 22:45:05 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.910434899277404 on epoch=110
05/27/2022 22:45:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
05/27/2022 22:45:10 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
05/27/2022 22:45:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
05/27/2022 22:45:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
05/27/2022 22:45:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
05/27/2022 22:45:23 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=114
05/27/2022 22:45:23 - INFO - __main__ - Saving model with best Classification-F1: 0.9865677649358864 -> 0.9910627007401202 on epoch=114, global_step=1600
05/27/2022 22:45:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=114
05/27/2022 22:45:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
05/27/2022 22:45:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
05/27/2022 22:45:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
05/27/2022 22:45:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
05/27/2022 22:45:41 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.9732141271414017 on epoch=117
05/27/2022 22:45:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
05/27/2022 22:45:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
05/27/2022 22:45:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/27/2022 22:45:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
05/27/2022 22:45:54 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
05/27/2022 22:45:59 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.9205474095796676 on epoch=121
05/27/2022 22:46:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
05/27/2022 22:46:04 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
05/27/2022 22:46:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
05/27/2022 22:46:09 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
05/27/2022 22:46:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=124
05/27/2022 22:46:18 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.9228413163897036 on epoch=124
05/27/2022 22:46:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
05/27/2022 22:46:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=126
05/27/2022 22:46:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
05/27/2022 22:46:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
05/27/2022 22:46:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
05/27/2022 22:46:36 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.8588465298142718 on epoch=128
05/27/2022 22:46:39 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
05/27/2022 22:46:41 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
05/27/2022 22:46:44 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
05/27/2022 22:46:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
05/27/2022 22:46:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
05/27/2022 22:46:54 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.8028822379391639 on epoch=132
05/27/2022 22:46:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
05/27/2022 22:46:59 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/27/2022 22:47:02 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
05/27/2022 22:47:04 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
05/27/2022 22:47:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/27/2022 22:47:13 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8435959851519623 on epoch=135
05/27/2022 22:47:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
05/27/2022 22:47:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/27/2022 22:47:20 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=137
05/27/2022 22:47:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
05/27/2022 22:47:25 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
05/27/2022 22:47:31 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.8038443529904631 on epoch=139
05/27/2022 22:47:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=139
05/27/2022 22:47:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=140
05/27/2022 22:47:38 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
05/27/2022 22:47:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
05/27/2022 22:47:43 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=142
05/27/2022 22:47:49 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9820991153059465 on epoch=142
05/27/2022 22:47:52 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
05/27/2022 22:47:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=144
05/27/2022 22:47:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
05/27/2022 22:47:59 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=145
05/27/2022 22:48:02 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/27/2022 22:48:07 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.916499578325954 on epoch=146
05/27/2022 22:48:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/27/2022 22:48:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
05/27/2022 22:48:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
05/27/2022 22:48:17 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
05/27/2022 22:48:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
05/27/2022 22:48:26 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=149
05/27/2022 22:48:28 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/27/2022 22:48:31 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
05/27/2022 22:48:33 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
05/27/2022 22:48:36 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=152
05/27/2022 22:48:38 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
05/27/2022 22:48:44 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8609970674486804 on epoch=153
05/27/2022 22:48:47 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
05/27/2022 22:48:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
05/27/2022 22:48:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
05/27/2022 22:48:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=156
05/27/2022 22:48:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=157
05/27/2022 22:49:03 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=157
05/27/2022 22:49:06 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
05/27/2022 22:49:08 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
05/27/2022 22:49:11 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
05/27/2022 22:49:13 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
05/27/2022 22:49:16 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
05/27/2022 22:49:22 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9163521361623829 on epoch=160
05/27/2022 22:49:24 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=161
05/27/2022 22:49:26 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
05/27/2022 22:49:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
05/27/2022 22:49:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
05/27/2022 22:49:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
05/27/2022 22:49:40 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9154680445003026 on epoch=164
05/27/2022 22:49:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
05/27/2022 22:49:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/27/2022 22:49:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
05/27/2022 22:49:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
05/27/2022 22:49:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
05/27/2022 22:49:59 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8515096260278305 on epoch=167
05/27/2022 22:50:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
05/27/2022 22:50:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/27/2022 22:50:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
05/27/2022 22:50:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
05/27/2022 22:50:11 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
05/27/2022 22:50:17 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.904304695702545 on epoch=171
05/27/2022 22:50:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
05/27/2022 22:50:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
05/27/2022 22:50:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
05/27/2022 22:50:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/27/2022 22:50:29 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/27/2022 22:50:35 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8631514235092864 on epoch=174
05/27/2022 22:50:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
05/27/2022 22:50:40 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
05/27/2022 22:50:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
05/27/2022 22:50:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/27/2022 22:50:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/27/2022 22:50:54 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9228413163897036 on epoch=178
05/27/2022 22:50:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
05/27/2022 22:50:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
05/27/2022 22:51:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
05/27/2022 22:51:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/27/2022 22:51:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
05/27/2022 22:51:13 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.9865677649358864 on epoch=182
05/27/2022 22:51:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/27/2022 22:51:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
05/27/2022 22:51:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
05/27/2022 22:51:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
05/27/2022 22:51:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
05/27/2022 22:51:31 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.859241355083089 on epoch=185
05/27/2022 22:51:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/27/2022 22:51:36 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
05/27/2022 22:51:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
05/27/2022 22:51:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
05/27/2022 22:51:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/27/2022 22:51:50 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9163766699250571 on epoch=189
05/27/2022 22:51:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=189
05/27/2022 22:51:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
05/27/2022 22:51:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/27/2022 22:52:00 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/27/2022 22:52:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/27/2022 22:52:08 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=192
05/27/2022 22:52:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
05/27/2022 22:52:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
05/27/2022 22:52:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
05/27/2022 22:52:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/27/2022 22:52:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
05/27/2022 22:52:27 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.9186460429724188 on epoch=196
05/27/2022 22:52:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
05/27/2022 22:52:32 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
05/27/2022 22:52:35 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/27/2022 22:52:37 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
05/27/2022 22:52:40 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
05/27/2022 22:52:47 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.916380742913001 on epoch=199
05/27/2022 22:52:49 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/27/2022 22:52:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
05/27/2022 22:52:55 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/27/2022 22:52:57 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
05/27/2022 22:53:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/27/2022 22:53:06 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=203
05/27/2022 22:53:08 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
05/27/2022 22:53:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/27/2022 22:53:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/27/2022 22:53:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
05/27/2022 22:53:18 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
05/27/2022 22:53:24 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9163521361623829 on epoch=207
05/27/2022 22:53:27 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
05/27/2022 22:53:29 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/27/2022 22:53:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/27/2022 22:53:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
05/27/2022 22:53:37 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/27/2022 22:53:43 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.90276963180189 on epoch=210
05/27/2022 22:53:45 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/27/2022 22:53:48 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/27/2022 22:53:50 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/27/2022 22:53:53 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
05/27/2022 22:53:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
05/27/2022 22:53:57 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 22:53:57 - INFO - __main__ - Printing 3 examples
05/27/2022 22:53:57 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/27/2022 22:53:57 - INFO - __main__ - ['Animal']
05/27/2022 22:53:57 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/27/2022 22:53:57 - INFO - __main__ - ['Animal']
05/27/2022 22:53:57 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/27/2022 22:53:57 - INFO - __main__ - ['Animal']
05/27/2022 22:53:57 - INFO - __main__ - Tokenizing Input ...
05/27/2022 22:53:57 - INFO - __main__ - Tokenizing Output ...
05/27/2022 22:53:57 - INFO - __main__ - Loaded 224 examples from train data
05/27/2022 22:53:57 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 22:53:57 - INFO - __main__ - Printing 3 examples
05/27/2022 22:53:57 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/27/2022 22:53:57 - INFO - __main__ - ['Animal']
05/27/2022 22:53:57 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/27/2022 22:53:57 - INFO - __main__ - ['Animal']
05/27/2022 22:53:57 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/27/2022 22:53:57 - INFO - __main__ - ['Animal']
05/27/2022 22:53:57 - INFO - __main__ - Tokenizing Input ...
05/27/2022 22:53:57 - INFO - __main__ - Tokenizing Output ...
05/27/2022 22:53:57 - INFO - __main__ - Loaded 224 examples from dev data
05/27/2022 22:54:01 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.9096072386394968 on epoch=214
05/27/2022 22:54:01 - INFO - __main__ - save last model!
05/27/2022 22:54:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/27/2022 22:54:01 - INFO - __main__ - Start tokenizing ... 3500 instances
05/27/2022 22:54:01 - INFO - __main__ - Printing 3 examples
05/27/2022 22:54:01 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/27/2022 22:54:01 - INFO - __main__ - ['Animal']
05/27/2022 22:54:01 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/27/2022 22:54:01 - INFO - __main__ - ['Animal']
05/27/2022 22:54:01 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/27/2022 22:54:01 - INFO - __main__ - ['Village']
05/27/2022 22:54:01 - INFO - __main__ - Tokenizing Input ...
05/27/2022 22:54:03 - INFO - __main__ - Tokenizing Output ...
05/27/2022 22:54:06 - INFO - __main__ - Loaded 3500 examples from test data
05/27/2022 22:54:16 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 22:54:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 22:54:17 - INFO - __main__ - Starting training!
05/27/2022 22:56:15 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
05/27/2022 22:56:15 - INFO - __main__ - Classification-F1 on test data: 0.6094
05/27/2022 22:56:16 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.9910627007401202, test_performance=0.6094038093793335
05/27/2022 22:56:16 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
05/27/2022 22:56:17 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 22:56:17 - INFO - __main__ - Printing 3 examples
05/27/2022 22:56:17 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/27/2022 22:56:17 - INFO - __main__ - ['Animal']
05/27/2022 22:56:17 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/27/2022 22:56:17 - INFO - __main__ - ['Animal']
05/27/2022 22:56:17 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/27/2022 22:56:17 - INFO - __main__ - ['Animal']
05/27/2022 22:56:17 - INFO - __main__ - Tokenizing Input ...
05/27/2022 22:56:17 - INFO - __main__ - Tokenizing Output ...
05/27/2022 22:56:17 - INFO - __main__ - Loaded 224 examples from train data
05/27/2022 22:56:17 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 22:56:17 - INFO - __main__ - Printing 3 examples
05/27/2022 22:56:17 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/27/2022 22:56:17 - INFO - __main__ - ['Animal']
05/27/2022 22:56:17 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/27/2022 22:56:17 - INFO - __main__ - ['Animal']
05/27/2022 22:56:17 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/27/2022 22:56:17 - INFO - __main__ - ['Animal']
05/27/2022 22:56:17 - INFO - __main__ - Tokenizing Input ...
05/27/2022 22:56:17 - INFO - __main__ - Tokenizing Output ...
05/27/2022 22:56:17 - INFO - __main__ - Loaded 224 examples from dev data
05/27/2022 22:56:33 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 22:56:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 22:56:33 - INFO - __main__ - Starting training!
05/27/2022 22:56:37 - INFO - __main__ - Step 10 Global step 10 Train loss 6.69 on epoch=0
05/27/2022 22:56:40 - INFO - __main__ - Step 20 Global step 20 Train loss 4.55 on epoch=1
05/27/2022 22:56:42 - INFO - __main__ - Step 30 Global step 30 Train loss 3.37 on epoch=2
05/27/2022 22:56:45 - INFO - __main__ - Step 40 Global step 40 Train loss 2.88 on epoch=2
05/27/2022 22:56:47 - INFO - __main__ - Step 50 Global step 50 Train loss 2.36 on epoch=3
05/27/2022 22:56:53 - INFO - __main__ - Global step 50 Train loss 3.97 Classification-F1 0.045431692490516026 on epoch=3
05/27/2022 22:56:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.045431692490516026 on epoch=3, global_step=50
05/27/2022 22:56:55 - INFO - __main__ - Step 60 Global step 60 Train loss 1.77 on epoch=4
05/27/2022 22:56:58 - INFO - __main__ - Step 70 Global step 70 Train loss 1.48 on epoch=4
05/27/2022 22:57:00 - INFO - __main__ - Step 80 Global step 80 Train loss 1.15 on epoch=5
05/27/2022 22:57:03 - INFO - __main__ - Step 90 Global step 90 Train loss 1.06 on epoch=6
05/27/2022 22:57:05 - INFO - __main__ - Step 100 Global step 100 Train loss 1.00 on epoch=7
05/27/2022 22:57:12 - INFO - __main__ - Global step 100 Train loss 1.29 Classification-F1 0.48865785890051083 on epoch=7
05/27/2022 22:57:12 - INFO - __main__ - Saving model with best Classification-F1: 0.045431692490516026 -> 0.48865785890051083 on epoch=7, global_step=100
05/27/2022 22:57:15 - INFO - __main__ - Step 110 Global step 110 Train loss 0.89 on epoch=7
05/27/2022 22:57:17 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=8
05/27/2022 22:57:20 - INFO - __main__ - Step 130 Global step 130 Train loss 0.78 on epoch=9
05/27/2022 22:57:22 - INFO - __main__ - Step 140 Global step 140 Train loss 0.70 on epoch=9
05/27/2022 22:57:25 - INFO - __main__ - Step 150 Global step 150 Train loss 0.63 on epoch=10
05/27/2022 22:57:32 - INFO - __main__ - Global step 150 Train loss 0.78 Classification-F1 0.5776197230928901 on epoch=10
05/27/2022 22:57:32 - INFO - __main__ - Saving model with best Classification-F1: 0.48865785890051083 -> 0.5776197230928901 on epoch=10, global_step=150
05/27/2022 22:57:34 - INFO - __main__ - Step 160 Global step 160 Train loss 0.65 on epoch=11
05/27/2022 22:57:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.63 on epoch=12
05/27/2022 22:57:40 - INFO - __main__ - Step 180 Global step 180 Train loss 0.58 on epoch=12
05/27/2022 22:57:42 - INFO - __main__ - Step 190 Global step 190 Train loss 0.64 on epoch=13
05/27/2022 22:57:45 - INFO - __main__ - Step 200 Global step 200 Train loss 0.66 on epoch=14
05/27/2022 22:57:52 - INFO - __main__ - Global step 200 Train loss 0.63 Classification-F1 0.6171573176860097 on epoch=14
05/27/2022 22:57:52 - INFO - __main__ - Saving model with best Classification-F1: 0.5776197230928901 -> 0.6171573176860097 on epoch=14, global_step=200
05/27/2022 22:57:54 - INFO - __main__ - Step 210 Global step 210 Train loss 0.53 on epoch=14
05/27/2022 22:57:57 - INFO - __main__ - Step 220 Global step 220 Train loss 0.58 on epoch=15
05/27/2022 22:57:59 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=16
05/27/2022 22:58:02 - INFO - __main__ - Step 240 Global step 240 Train loss 0.44 on epoch=17
05/27/2022 22:58:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.50 on epoch=17
05/27/2022 22:58:11 - INFO - __main__ - Global step 250 Train loss 0.52 Classification-F1 0.6608290176008846 on epoch=17
05/27/2022 22:58:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6171573176860097 -> 0.6608290176008846 on epoch=17, global_step=250
05/27/2022 22:58:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=18
05/27/2022 22:58:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=19
05/27/2022 22:58:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.43 on epoch=19
05/27/2022 22:58:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.55 on epoch=20
05/27/2022 22:58:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.36 on epoch=21
05/27/2022 22:58:31 - INFO - __main__ - Global step 300 Train loss 0.45 Classification-F1 0.7753276403198074 on epoch=21
05/27/2022 22:58:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6608290176008846 -> 0.7753276403198074 on epoch=21, global_step=300
05/27/2022 22:58:33 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=22
05/27/2022 22:58:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=22
05/27/2022 22:58:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.36 on epoch=23
05/27/2022 22:58:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.35 on epoch=24
05/27/2022 22:58:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=24
05/27/2022 22:58:50 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.8068754490805216 on epoch=24
05/27/2022 22:58:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7753276403198074 -> 0.8068754490805216 on epoch=24, global_step=350
05/27/2022 22:58:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=25
05/27/2022 22:58:55 - INFO - __main__ - Step 370 Global step 370 Train loss 0.33 on epoch=26
05/27/2022 22:58:57 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=27
05/27/2022 22:59:00 - INFO - __main__ - Step 390 Global step 390 Train loss 0.26 on epoch=27
05/27/2022 22:59:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=28
05/27/2022 22:59:09 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.7440267912753681 on epoch=28
05/27/2022 22:59:11 - INFO - __main__ - Step 410 Global step 410 Train loss 0.27 on epoch=29
05/27/2022 22:59:14 - INFO - __main__ - Step 420 Global step 420 Train loss 0.31 on epoch=29
05/27/2022 22:59:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.26 on epoch=30
05/27/2022 22:59:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.30 on epoch=31
05/27/2022 22:59:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=32
05/27/2022 22:59:27 - INFO - __main__ - Global step 450 Train loss 0.28 Classification-F1 0.6262119004054488 on epoch=32
05/27/2022 22:59:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=32
05/27/2022 22:59:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=33
05/27/2022 22:59:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=34
05/27/2022 22:59:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=34
05/27/2022 22:59:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=35
05/27/2022 22:59:47 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.7577979001351274 on epoch=35
05/27/2022 22:59:50 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=36
05/27/2022 22:59:52 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=37
05/27/2022 22:59:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=37
05/27/2022 22:59:57 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=38
05/27/2022 23:00:00 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=39
05/27/2022 23:00:06 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.7507378413465855 on epoch=39
05/27/2022 23:00:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=39
05/27/2022 23:00:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.27 on epoch=40
05/27/2022 23:00:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.40 on epoch=41
05/27/2022 23:00:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=42
05/27/2022 23:00:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=42
05/27/2022 23:00:25 - INFO - __main__ - Global step 600 Train loss 0.27 Classification-F1 0.728012337059514 on epoch=42
05/27/2022 23:00:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=43
05/27/2022 23:00:30 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=44
05/27/2022 23:00:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=44
05/27/2022 23:00:35 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=45
05/27/2022 23:00:38 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=46
05/27/2022 23:00:44 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.7136434206727131 on epoch=46
05/27/2022 23:00:47 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=47
05/27/2022 23:00:49 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=47
05/27/2022 23:00:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=48
05/27/2022 23:00:54 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
05/27/2022 23:00:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=49
05/27/2022 23:01:03 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.8258723381825849 on epoch=49
05/27/2022 23:01:03 - INFO - __main__ - Saving model with best Classification-F1: 0.8068754490805216 -> 0.8258723381825849 on epoch=49, global_step=700
05/27/2022 23:01:05 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=50
05/27/2022 23:01:08 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=51
05/27/2022 23:01:10 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=52
05/27/2022 23:01:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.12 on epoch=52
05/27/2022 23:01:15 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=53
05/27/2022 23:01:21 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.7414143083308911 on epoch=53
05/27/2022 23:01:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=54
05/27/2022 23:01:26 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=54
05/27/2022 23:01:28 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=55
05/27/2022 23:01:31 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=56
05/27/2022 23:01:33 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=57
05/27/2022 23:01:39 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.6524383146894773 on epoch=57
05/27/2022 23:01:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=57
05/27/2022 23:01:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=58
05/27/2022 23:01:46 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=59
05/27/2022 23:01:49 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=59
05/27/2022 23:01:51 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=60
05/27/2022 23:01:57 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.7094127152088693 on epoch=60
05/27/2022 23:01:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=61
05/27/2022 23:02:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=62
05/27/2022 23:02:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=62
05/27/2022 23:02:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=63
05/27/2022 23:02:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=64
05/27/2022 23:02:15 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.7148481162522908 on epoch=64
05/27/2022 23:02:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=64
05/27/2022 23:02:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=65
05/27/2022 23:02:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=66
05/27/2022 23:02:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=67
05/27/2022 23:02:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=67
05/27/2022 23:02:34 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.7908849802751012 on epoch=67
05/27/2022 23:02:36 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=68
05/27/2022 23:02:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=69
05/27/2022 23:02:41 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=69
05/27/2022 23:02:44 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=70
05/27/2022 23:02:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
05/27/2022 23:02:52 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.7072388461738556 on epoch=71
05/27/2022 23:02:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=72
05/27/2022 23:02:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=72
05/27/2022 23:02:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=73
05/27/2022 23:03:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=74
05/27/2022 23:03:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
05/27/2022 23:03:11 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.7318525969904771 on epoch=74
05/27/2022 23:03:13 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
05/27/2022 23:03:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
05/27/2022 23:03:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
05/27/2022 23:03:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=77
05/27/2022 23:03:23 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=78
05/27/2022 23:03:29 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.6963644837323925 on epoch=78
05/27/2022 23:03:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
05/27/2022 23:03:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=79
05/27/2022 23:03:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
05/27/2022 23:03:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
05/27/2022 23:03:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
05/27/2022 23:03:47 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.8251236271634754 on epoch=82
05/27/2022 23:03:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
05/27/2022 23:03:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
05/27/2022 23:03:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=84
05/27/2022 23:03:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
05/27/2022 23:04:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=85
05/27/2022 23:04:05 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.6953024704248114 on epoch=85
05/27/2022 23:04:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
05/27/2022 23:04:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=87
05/27/2022 23:04:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
05/27/2022 23:04:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
05/27/2022 23:04:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
05/27/2022 23:04:23 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7749009573652872 on epoch=89
05/27/2022 23:04:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=89
05/27/2022 23:04:28 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=90
05/27/2022 23:04:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=91
05/27/2022 23:04:33 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
05/27/2022 23:04:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
05/27/2022 23:04:41 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.6887727846619219 on epoch=92
05/27/2022 23:04:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
05/27/2022 23:04:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
05/27/2022 23:04:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
05/27/2022 23:04:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
05/27/2022 23:04:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
05/27/2022 23:05:00 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7443413794879112 on epoch=96
05/27/2022 23:05:02 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
05/27/2022 23:05:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
05/27/2022 23:05:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
05/27/2022 23:05:10 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=99
05/27/2022 23:05:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
05/27/2022 23:05:18 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.669363862572691 on epoch=99
05/27/2022 23:05:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
05/27/2022 23:05:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
05/27/2022 23:05:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
05/27/2022 23:05:28 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
05/27/2022 23:05:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=103
05/27/2022 23:05:36 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.8463866778382908 on epoch=103
05/27/2022 23:05:36 - INFO - __main__ - Saving model with best Classification-F1: 0.8258723381825849 -> 0.8463866778382908 on epoch=103, global_step=1450
05/27/2022 23:05:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
05/27/2022 23:05:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
05/27/2022 23:05:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
05/27/2022 23:05:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
05/27/2022 23:05:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
05/27/2022 23:05:55 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7987281163974992 on epoch=107
05/27/2022 23:05:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
05/27/2022 23:06:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
05/27/2022 23:06:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=109
05/27/2022 23:06:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
05/27/2022 23:06:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
05/27/2022 23:06:13 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7935380065905717 on epoch=110
05/27/2022 23:06:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
05/27/2022 23:06:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
05/27/2022 23:06:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
05/27/2022 23:06:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
05/27/2022 23:06:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
05/27/2022 23:06:31 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7571429106468038 on epoch=114
05/27/2022 23:06:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
05/27/2022 23:06:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
05/27/2022 23:06:39 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
05/27/2022 23:06:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
05/27/2022 23:06:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
05/27/2022 23:06:49 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.6513110229429016 on epoch=117
05/27/2022 23:06:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
05/27/2022 23:06:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
05/27/2022 23:06:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
05/27/2022 23:07:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=120
05/27/2022 23:07:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
05/27/2022 23:07:08 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.804750936082558 on epoch=121
05/27/2022 23:07:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
05/27/2022 23:07:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
05/27/2022 23:07:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
05/27/2022 23:07:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
05/27/2022 23:07:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
05/27/2022 23:07:26 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.725734558541909 on epoch=124
05/27/2022 23:07:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
05/27/2022 23:07:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
05/27/2022 23:07:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
05/27/2022 23:07:36 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
05/27/2022 23:07:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
05/27/2022 23:07:44 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7681608895067429 on epoch=128
05/27/2022 23:07:47 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
05/27/2022 23:07:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
05/27/2022 23:07:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/27/2022 23:07:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
05/27/2022 23:07:57 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
05/27/2022 23:08:03 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9146227454813792 on epoch=132
05/27/2022 23:08:03 - INFO - __main__ - Saving model with best Classification-F1: 0.8463866778382908 -> 0.9146227454813792 on epoch=132, global_step=1850
05/27/2022 23:08:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
05/27/2022 23:08:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
05/27/2022 23:08:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
05/27/2022 23:08:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
05/27/2022 23:08:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
05/27/2022 23:08:21 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9822527251369758 on epoch=135
05/27/2022 23:08:21 - INFO - __main__ - Saving model with best Classification-F1: 0.9146227454813792 -> 0.9822527251369758 on epoch=135, global_step=1900
05/27/2022 23:08:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
05/27/2022 23:08:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
05/27/2022 23:08:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
05/27/2022 23:08:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
05/27/2022 23:08:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
05/27/2022 23:08:40 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9146227454813792 on epoch=139
05/27/2022 23:08:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
05/27/2022 23:08:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
05/27/2022 23:08:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
05/27/2022 23:08:50 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
05/27/2022 23:08:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
05/27/2022 23:08:58 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9822527251369758 on epoch=142
05/27/2022 23:09:00 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
05/27/2022 23:09:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
05/27/2022 23:09:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
05/27/2022 23:09:08 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.12 on epoch=145
05/27/2022 23:09:10 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=146
05/27/2022 23:09:16 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.9164955053380103 on epoch=146
05/27/2022 23:09:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/27/2022 23:09:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
05/27/2022 23:09:24 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
05/27/2022 23:09:26 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
05/27/2022 23:09:29 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
05/27/2022 23:09:34 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.855304467828187 on epoch=149
05/27/2022 23:09:37 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/27/2022 23:09:39 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/27/2022 23:09:42 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
05/27/2022 23:09:44 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
05/27/2022 23:09:47 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
05/27/2022 23:09:52 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8554465132827325 on epoch=153
05/27/2022 23:09:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=154
05/27/2022 23:09:57 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
05/27/2022 23:10:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/27/2022 23:10:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
05/27/2022 23:10:05 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
05/27/2022 23:10:10 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.789012651378756 on epoch=157
05/27/2022 23:10:13 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/27/2022 23:10:15 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
05/27/2022 23:10:18 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
05/27/2022 23:10:20 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
05/27/2022 23:10:23 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
05/27/2022 23:10:29 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8449058817581032 on epoch=160
05/27/2022 23:10:31 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
05/27/2022 23:10:34 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
05/27/2022 23:10:36 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/27/2022 23:10:39 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
05/27/2022 23:10:41 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/27/2022 23:10:47 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9187894121480459 on epoch=164
05/27/2022 23:10:49 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
05/27/2022 23:10:52 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/27/2022 23:10:54 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/27/2022 23:10:57 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
05/27/2022 23:10:59 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/27/2022 23:11:05 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8366254905554598 on epoch=167
05/27/2022 23:11:08 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
05/27/2022 23:11:10 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/27/2022 23:11:13 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
05/27/2022 23:11:15 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
05/27/2022 23:11:18 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/27/2022 23:11:23 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8167156134525118 on epoch=171
05/27/2022 23:11:26 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
05/27/2022 23:11:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
05/27/2022 23:11:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=173
05/27/2022 23:11:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/27/2022 23:11:36 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/27/2022 23:11:42 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.91649550533801 on epoch=174
05/27/2022 23:11:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
05/27/2022 23:11:47 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
05/27/2022 23:11:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/27/2022 23:11:52 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/27/2022 23:11:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/27/2022 23:12:00 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9103086366511415 on epoch=178
05/27/2022 23:12:03 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=179
05/27/2022 23:12:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
05/27/2022 23:12:08 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
05/27/2022 23:12:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/27/2022 23:12:13 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
05/27/2022 23:12:19 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9164955053380103 on epoch=182
05/27/2022 23:12:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/27/2022 23:12:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/27/2022 23:12:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
05/27/2022 23:12:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/27/2022 23:12:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
05/27/2022 23:12:37 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9780321732798691 on epoch=185
05/27/2022 23:12:40 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/27/2022 23:12:43 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
05/27/2022 23:12:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
05/27/2022 23:12:48 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
05/27/2022 23:12:50 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/27/2022 23:12:56 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9822527251369758 on epoch=189
05/27/2022 23:12:59 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/27/2022 23:13:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/27/2022 23:13:04 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
05/27/2022 23:13:06 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/27/2022 23:13:09 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/27/2022 23:13:15 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9777577893327418 on epoch=192
05/27/2022 23:13:18 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
05/27/2022 23:13:20 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
05/27/2022 23:13:23 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/27/2022 23:13:25 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
05/27/2022 23:13:28 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
05/27/2022 23:13:34 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9824964589941548 on epoch=196
05/27/2022 23:13:34 - INFO - __main__ - Saving model with best Classification-F1: 0.9822527251369758 -> 0.9824964589941548 on epoch=196, global_step=2750
05/27/2022 23:13:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
05/27/2022 23:13:39 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
05/27/2022 23:13:41 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/27/2022 23:13:44 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/27/2022 23:13:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/27/2022 23:13:53 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9867213747669157 on epoch=199
05/27/2022 23:13:53 - INFO - __main__ - Saving model with best Classification-F1: 0.9824964589941548 -> 0.9867213747669157 on epoch=199, global_step=2800
05/27/2022 23:13:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/27/2022 23:13:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
05/27/2022 23:14:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
05/27/2022 23:14:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/27/2022 23:14:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/27/2022 23:14:11 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=203
05/27/2022 23:14:11 - INFO - __main__ - Saving model with best Classification-F1: 0.9867213747669157 -> 0.9910627007401202 on epoch=203, global_step=2850
05/27/2022 23:14:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
05/27/2022 23:14:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/27/2022 23:14:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/27/2022 23:14:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
05/27/2022 23:14:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/27/2022 23:14:29 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8555177349532188 on epoch=207
05/27/2022 23:14:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
05/27/2022 23:14:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/27/2022 23:14:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/27/2022 23:14:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
05/27/2022 23:14:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/27/2022 23:14:48 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7908609338163418 on epoch=210
05/27/2022 23:14:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/27/2022 23:14:53 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/27/2022 23:14:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/27/2022 23:14:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/27/2022 23:15:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/27/2022 23:15:02 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 23:15:02 - INFO - __main__ - Printing 3 examples
05/27/2022 23:15:02 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/27/2022 23:15:02 - INFO - __main__ - ['Animal']
05/27/2022 23:15:02 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/27/2022 23:15:02 - INFO - __main__ - ['Animal']
05/27/2022 23:15:02 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/27/2022 23:15:02 - INFO - __main__ - ['Animal']
05/27/2022 23:15:02 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:15:02 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:15:02 - INFO - __main__ - Loaded 224 examples from train data
05/27/2022 23:15:02 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 23:15:02 - INFO - __main__ - Printing 3 examples
05/27/2022 23:15:02 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/27/2022 23:15:02 - INFO - __main__ - ['Animal']
05/27/2022 23:15:02 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/27/2022 23:15:02 - INFO - __main__ - ['Animal']
05/27/2022 23:15:02 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/27/2022 23:15:02 - INFO - __main__ - ['Animal']
05/27/2022 23:15:02 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:15:02 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:15:03 - INFO - __main__ - Loaded 224 examples from dev data
05/27/2022 23:15:06 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7966005791655977 on epoch=214
05/27/2022 23:15:06 - INFO - __main__ - save last model!
05/27/2022 23:15:06 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/27/2022 23:15:06 - INFO - __main__ - Start tokenizing ... 3500 instances
05/27/2022 23:15:06 - INFO - __main__ - Printing 3 examples
05/27/2022 23:15:06 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/27/2022 23:15:06 - INFO - __main__ - ['Animal']
05/27/2022 23:15:06 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/27/2022 23:15:06 - INFO - __main__ - ['Animal']
05/27/2022 23:15:06 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/27/2022 23:15:06 - INFO - __main__ - ['Village']
05/27/2022 23:15:06 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:15:08 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:15:12 - INFO - __main__ - Loaded 3500 examples from test data
05/27/2022 23:15:21 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 23:15:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 23:15:22 - INFO - __main__ - Starting training!
05/27/2022 23:17:18 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
05/27/2022 23:17:18 - INFO - __main__ - Classification-F1 on test data: 0.5001
05/27/2022 23:17:19 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.9910627007401202, test_performance=0.5000532318404814
05/27/2022 23:17:19 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
05/27/2022 23:17:20 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 23:17:20 - INFO - __main__ - Printing 3 examples
05/27/2022 23:17:20 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/27/2022 23:17:20 - INFO - __main__ - ['Animal']
05/27/2022 23:17:20 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/27/2022 23:17:20 - INFO - __main__ - ['Animal']
05/27/2022 23:17:20 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/27/2022 23:17:20 - INFO - __main__ - ['Animal']
05/27/2022 23:17:20 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:17:20 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:17:20 - INFO - __main__ - Loaded 224 examples from train data
05/27/2022 23:17:20 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 23:17:20 - INFO - __main__ - Printing 3 examples
05/27/2022 23:17:20 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/27/2022 23:17:20 - INFO - __main__ - ['Animal']
05/27/2022 23:17:20 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/27/2022 23:17:20 - INFO - __main__ - ['Animal']
05/27/2022 23:17:20 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/27/2022 23:17:20 - INFO - __main__ - ['Animal']
05/27/2022 23:17:20 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:17:20 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:17:20 - INFO - __main__ - Loaded 224 examples from dev data
05/27/2022 23:17:35 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 23:17:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 23:17:36 - INFO - __main__ - Starting training!
05/27/2022 23:17:40 - INFO - __main__ - Step 10 Global step 10 Train loss 6.98 on epoch=0
05/27/2022 23:17:42 - INFO - __main__ - Step 20 Global step 20 Train loss 4.68 on epoch=1
05/27/2022 23:17:45 - INFO - __main__ - Step 30 Global step 30 Train loss 3.70 on epoch=2
05/27/2022 23:17:47 - INFO - __main__ - Step 40 Global step 40 Train loss 3.22 on epoch=2
05/27/2022 23:17:50 - INFO - __main__ - Step 50 Global step 50 Train loss 2.81 on epoch=3
05/27/2022 23:17:56 - INFO - __main__ - Global step 50 Train loss 4.28 Classification-F1 0.03552145495879511 on epoch=3
05/27/2022 23:17:56 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03552145495879511 on epoch=3, global_step=50
05/27/2022 23:17:58 - INFO - __main__ - Step 60 Global step 60 Train loss 2.37 on epoch=4
05/27/2022 23:18:01 - INFO - __main__ - Step 70 Global step 70 Train loss 1.99 on epoch=4
05/27/2022 23:18:03 - INFO - __main__ - Step 80 Global step 80 Train loss 1.73 on epoch=5
05/27/2022 23:18:06 - INFO - __main__ - Step 90 Global step 90 Train loss 1.36 on epoch=6
05/27/2022 23:18:08 - INFO - __main__ - Step 100 Global step 100 Train loss 1.24 on epoch=7
05/27/2022 23:18:14 - INFO - __main__ - Global step 100 Train loss 1.74 Classification-F1 0.3602171535412823 on epoch=7
05/27/2022 23:18:14 - INFO - __main__ - Saving model with best Classification-F1: 0.03552145495879511 -> 0.3602171535412823 on epoch=7, global_step=100
05/27/2022 23:18:17 - INFO - __main__ - Step 110 Global step 110 Train loss 1.19 on epoch=7
05/27/2022 23:18:19 - INFO - __main__ - Step 120 Global step 120 Train loss 1.02 on epoch=8
05/27/2022 23:18:22 - INFO - __main__ - Step 130 Global step 130 Train loss 0.91 on epoch=9
05/27/2022 23:18:24 - INFO - __main__ - Step 140 Global step 140 Train loss 0.77 on epoch=9
05/27/2022 23:18:27 - INFO - __main__ - Step 150 Global step 150 Train loss 0.80 on epoch=10
05/27/2022 23:18:35 - INFO - __main__ - Global step 150 Train loss 0.94 Classification-F1 0.4756399777381986 on epoch=10
05/27/2022 23:18:35 - INFO - __main__ - Saving model with best Classification-F1: 0.3602171535412823 -> 0.4756399777381986 on epoch=10, global_step=150
05/27/2022 23:18:37 - INFO - __main__ - Step 160 Global step 160 Train loss 0.77 on epoch=11
05/27/2022 23:18:40 - INFO - __main__ - Step 170 Global step 170 Train loss 0.75 on epoch=12
05/27/2022 23:18:42 - INFO - __main__ - Step 180 Global step 180 Train loss 0.65 on epoch=12
05/27/2022 23:18:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.67 on epoch=13
05/27/2022 23:18:47 - INFO - __main__ - Step 200 Global step 200 Train loss 0.65 on epoch=14
05/27/2022 23:18:55 - INFO - __main__ - Global step 200 Train loss 0.70 Classification-F1 0.4639040029635394 on epoch=14
05/27/2022 23:18:58 - INFO - __main__ - Step 210 Global step 210 Train loss 0.65 on epoch=14
05/27/2022 23:19:00 - INFO - __main__ - Step 220 Global step 220 Train loss 0.59 on epoch=15
05/27/2022 23:19:02 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=16
05/27/2022 23:19:05 - INFO - __main__ - Step 240 Global step 240 Train loss 0.64 on epoch=17
05/27/2022 23:19:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=17
05/27/2022 23:19:15 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.6555523527935685 on epoch=17
05/27/2022 23:19:15 - INFO - __main__ - Saving model with best Classification-F1: 0.4756399777381986 -> 0.6555523527935685 on epoch=17, global_step=250
05/27/2022 23:19:17 - INFO - __main__ - Step 260 Global step 260 Train loss 0.58 on epoch=18
05/27/2022 23:19:20 - INFO - __main__ - Step 270 Global step 270 Train loss 0.50 on epoch=19
05/27/2022 23:19:22 - INFO - __main__ - Step 280 Global step 280 Train loss 0.54 on epoch=19
05/27/2022 23:19:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=20
05/27/2022 23:19:27 - INFO - __main__ - Step 300 Global step 300 Train loss 0.45 on epoch=21
05/27/2022 23:19:34 - INFO - __main__ - Global step 300 Train loss 0.51 Classification-F1 0.6319039497804603 on epoch=21
05/27/2022 23:19:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.56 on epoch=22
05/27/2022 23:19:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.47 on epoch=22
05/27/2022 23:19:41 - INFO - __main__ - Step 330 Global step 330 Train loss 0.37 on epoch=23
05/27/2022 23:19:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=24
05/27/2022 23:19:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=24
05/27/2022 23:19:53 - INFO - __main__ - Global step 350 Train loss 0.44 Classification-F1 0.7089927117377361 on epoch=24
05/27/2022 23:19:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6555523527935685 -> 0.7089927117377361 on epoch=24, global_step=350
05/27/2022 23:19:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.41 on epoch=25
05/27/2022 23:19:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.44 on epoch=26
05/27/2022 23:20:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.43 on epoch=27
05/27/2022 23:20:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.38 on epoch=27
05/27/2022 23:20:05 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=28
05/27/2022 23:20:12 - INFO - __main__ - Global step 400 Train loss 0.42 Classification-F1 0.7135430815417422 on epoch=28
05/27/2022 23:20:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7089927117377361 -> 0.7135430815417422 on epoch=28, global_step=400
05/27/2022 23:20:14 - INFO - __main__ - Step 410 Global step 410 Train loss 0.35 on epoch=29
05/27/2022 23:20:17 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=29
05/27/2022 23:20:19 - INFO - __main__ - Step 430 Global step 430 Train loss 0.37 on epoch=30
05/27/2022 23:20:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.36 on epoch=31
05/27/2022 23:20:24 - INFO - __main__ - Step 450 Global step 450 Train loss 0.42 on epoch=32
05/27/2022 23:20:31 - INFO - __main__ - Global step 450 Train loss 0.37 Classification-F1 0.8092631110894869 on epoch=32
05/27/2022 23:20:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7135430815417422 -> 0.8092631110894869 on epoch=32, global_step=450
05/27/2022 23:20:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=32
05/27/2022 23:20:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.28 on epoch=33
05/27/2022 23:20:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.38 on epoch=34
05/27/2022 23:20:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.39 on epoch=34
05/27/2022 23:20:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.34 on epoch=35
05/27/2022 23:20:50 - INFO - __main__ - Global step 500 Train loss 0.35 Classification-F1 0.7590927052842968 on epoch=35
05/27/2022 23:20:53 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=36
05/27/2022 23:20:55 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=37
05/27/2022 23:20:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.33 on epoch=37
05/27/2022 23:21:00 - INFO - __main__ - Step 540 Global step 540 Train loss 0.26 on epoch=38
05/27/2022 23:21:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=39
05/27/2022 23:21:09 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.7585587603134324 on epoch=39
05/27/2022 23:21:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.31 on epoch=39
05/27/2022 23:21:14 - INFO - __main__ - Step 570 Global step 570 Train loss 0.36 on epoch=40
05/27/2022 23:21:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=41
05/27/2022 23:21:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=42
05/27/2022 23:21:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=42
05/27/2022 23:21:28 - INFO - __main__ - Global step 600 Train loss 0.29 Classification-F1 0.7649419062628863 on epoch=42
05/27/2022 23:21:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=43
05/27/2022 23:21:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=44
05/27/2022 23:21:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=44
05/27/2022 23:21:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=45
05/27/2022 23:21:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=46
05/27/2022 23:21:48 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.7646095553323968 on epoch=46
05/27/2022 23:21:50 - INFO - __main__ - Step 660 Global step 660 Train loss 0.27 on epoch=47
05/27/2022 23:21:53 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=47
05/27/2022 23:21:55 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=48
05/27/2022 23:21:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=49
05/27/2022 23:22:00 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=49
05/27/2022 23:22:07 - INFO - __main__ - Global step 700 Train loss 0.24 Classification-F1 0.8405460721748267 on epoch=49
05/27/2022 23:22:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8092631110894869 -> 0.8405460721748267 on epoch=49, global_step=700
05/27/2022 23:22:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=50
05/27/2022 23:22:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=51
05/27/2022 23:22:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=52
05/27/2022 23:22:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=52
05/27/2022 23:22:19 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=53
05/27/2022 23:22:27 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.8261976122903487 on epoch=53
05/27/2022 23:22:29 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=54
05/27/2022 23:22:32 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=54
05/27/2022 23:22:34 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=55
05/27/2022 23:22:37 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
05/27/2022 23:22:39 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=57
05/27/2022 23:22:46 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.8287985484190418 on epoch=57
05/27/2022 23:22:48 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=57
05/27/2022 23:22:51 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=58
05/27/2022 23:22:53 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=59
05/27/2022 23:22:56 - INFO - __main__ - Step 840 Global step 840 Train loss 0.21 on epoch=59
05/27/2022 23:22:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=60
05/27/2022 23:23:05 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.7701558161754438 on epoch=60
05/27/2022 23:23:08 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=61
05/27/2022 23:23:10 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=62
05/27/2022 23:23:13 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=62
05/27/2022 23:23:15 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=63
05/27/2022 23:23:18 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=64
05/27/2022 23:23:25 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.6444386237536828 on epoch=64
05/27/2022 23:23:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=64
05/27/2022 23:23:30 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=65
05/27/2022 23:23:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=66
05/27/2022 23:23:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=67
05/27/2022 23:23:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=67
05/27/2022 23:23:44 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.7667703736173911 on epoch=67
05/27/2022 23:23:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=68
05/27/2022 23:23:49 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=69
05/27/2022 23:23:52 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=69
05/27/2022 23:23:54 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=70
05/27/2022 23:23:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=71
05/27/2022 23:24:03 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.7394988744954202 on epoch=71
05/27/2022 23:24:06 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
05/27/2022 23:24:08 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=72
05/27/2022 23:24:11 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=73
05/27/2022 23:24:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=74
05/27/2022 23:24:16 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=74
05/27/2022 23:24:22 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.7960552440391151 on epoch=74
05/27/2022 23:24:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
05/27/2022 23:24:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=76
05/27/2022 23:24:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=77
05/27/2022 23:24:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=77
05/27/2022 23:24:34 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
05/27/2022 23:24:41 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.8800816172021108 on epoch=78
05/27/2022 23:24:41 - INFO - __main__ - Saving model with best Classification-F1: 0.8405460721748267 -> 0.8800816172021108 on epoch=78, global_step=1100
05/27/2022 23:24:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
05/27/2022 23:24:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
05/27/2022 23:24:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.17 on epoch=80
05/27/2022 23:24:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=81
05/27/2022 23:24:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
05/27/2022 23:25:01 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.8333698222381727 on epoch=82
05/27/2022 23:25:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
05/27/2022 23:25:06 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
05/27/2022 23:25:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=84
05/27/2022 23:25:11 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=84
05/27/2022 23:25:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=85
05/27/2022 23:25:20 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.843569861849977 on epoch=85
05/27/2022 23:25:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
05/27/2022 23:25:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=87
05/27/2022 23:25:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=87
05/27/2022 23:25:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
05/27/2022 23:25:32 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
05/27/2022 23:25:39 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.744511205443373 on epoch=89
05/27/2022 23:25:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
05/27/2022 23:25:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
05/27/2022 23:25:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
05/27/2022 23:25:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
05/27/2022 23:25:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=92
05/27/2022 23:25:57 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7927236968834455 on epoch=92
05/27/2022 23:26:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
05/27/2022 23:26:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
05/27/2022 23:26:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
05/27/2022 23:26:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
05/27/2022 23:26:10 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
05/27/2022 23:26:16 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.7799992738644297 on epoch=96
05/27/2022 23:26:19 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
05/27/2022 23:26:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=97
05/27/2022 23:26:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
05/27/2022 23:26:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
05/27/2022 23:26:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
05/27/2022 23:26:35 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.6202802095911679 on epoch=99
05/27/2022 23:26:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
05/27/2022 23:26:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
05/27/2022 23:26:43 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
05/27/2022 23:26:45 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
05/27/2022 23:26:48 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
05/27/2022 23:26:54 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.6666527992814347 on epoch=103
05/27/2022 23:26:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=104
05/27/2022 23:26:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
05/27/2022 23:27:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
05/27/2022 23:27:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
05/27/2022 23:27:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
05/27/2022 23:27:12 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.5667758967978909 on epoch=107
05/27/2022 23:27:15 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=107
05/27/2022 23:27:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
05/27/2022 23:27:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
05/27/2022 23:27:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
05/27/2022 23:27:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
05/27/2022 23:27:31 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6483894532886468 on epoch=110
05/27/2022 23:27:33 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
05/27/2022 23:27:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
05/27/2022 23:27:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
05/27/2022 23:27:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
05/27/2022 23:27:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
05/27/2022 23:27:49 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7894152690014875 on epoch=114
05/27/2022 23:27:52 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
05/27/2022 23:27:54 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
05/27/2022 23:27:57 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
05/27/2022 23:27:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=117
05/27/2022 23:28:02 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
05/27/2022 23:28:07 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.7347613658670061 on epoch=117
05/27/2022 23:28:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
05/27/2022 23:28:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
05/27/2022 23:28:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
05/27/2022 23:28:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
05/27/2022 23:28:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
05/27/2022 23:28:26 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7890814551240304 on epoch=121
05/27/2022 23:28:28 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
05/27/2022 23:28:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
05/27/2022 23:28:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
05/27/2022 23:28:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
05/27/2022 23:28:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
05/27/2022 23:28:44 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7799655960891081 on epoch=124
05/27/2022 23:28:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
05/27/2022 23:28:49 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
05/27/2022 23:28:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
05/27/2022 23:28:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
05/27/2022 23:28:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
05/27/2022 23:29:03 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7325365517951186 on epoch=128
05/27/2022 23:29:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
05/27/2022 23:29:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
05/27/2022 23:29:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
05/27/2022 23:29:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
05/27/2022 23:29:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
05/27/2022 23:29:21 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6588053711992593 on epoch=132
05/27/2022 23:29:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
05/27/2022 23:29:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
05/27/2022 23:29:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
05/27/2022 23:29:31 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
05/27/2022 23:29:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/27/2022 23:29:39 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.6780104985648306 on epoch=135
05/27/2022 23:29:42 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
05/27/2022 23:29:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=137
05/27/2022 23:29:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
05/27/2022 23:29:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
05/27/2022 23:29:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
05/27/2022 23:29:58 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7415512653415879 on epoch=139
05/27/2022 23:30:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
05/27/2022 23:30:03 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
05/27/2022 23:30:05 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
05/27/2022 23:30:08 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
05/27/2022 23:30:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=142
05/27/2022 23:30:16 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7856398424472428 on epoch=142
05/27/2022 23:30:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
05/27/2022 23:30:21 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
05/27/2022 23:30:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
05/27/2022 23:30:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
05/27/2022 23:30:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
05/27/2022 23:30:34 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.8937925076188833 on epoch=146
05/27/2022 23:30:34 - INFO - __main__ - Saving model with best Classification-F1: 0.8800816172021108 -> 0.8937925076188833 on epoch=146, global_step=2050
05/27/2022 23:30:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
05/27/2022 23:30:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
05/27/2022 23:30:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
05/27/2022 23:30:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
05/27/2022 23:30:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
05/27/2022 23:30:52 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.902504551402401 on epoch=149
05/27/2022 23:30:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8937925076188833 -> 0.902504551402401 on epoch=149, global_step=2100
05/27/2022 23:30:55 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/27/2022 23:30:57 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
05/27/2022 23:31:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
05/27/2022 23:31:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
05/27/2022 23:31:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=153
05/27/2022 23:31:10 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.9096491822535467 on epoch=153
05/27/2022 23:31:10 - INFO - __main__ - Saving model with best Classification-F1: 0.902504551402401 -> 0.9096491822535467 on epoch=153, global_step=2150
05/27/2022 23:31:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=154
05/27/2022 23:31:15 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/27/2022 23:31:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=155
05/27/2022 23:31:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
05/27/2022 23:31:23 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
05/27/2022 23:31:29 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8354166582745213 on epoch=157
05/27/2022 23:31:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
05/27/2022 23:31:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
05/27/2022 23:31:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
05/27/2022 23:31:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=159
05/27/2022 23:31:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
05/27/2022 23:31:47 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8522748036979538 on epoch=160
05/27/2022 23:31:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
05/27/2022 23:31:52 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
05/27/2022 23:31:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
05/27/2022 23:31:57 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
05/27/2022 23:32:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
05/27/2022 23:32:06 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7787891586013586 on epoch=164
05/27/2022 23:32:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
05/27/2022 23:32:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=165
05/27/2022 23:32:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
05/27/2022 23:32:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
05/27/2022 23:32:18 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
05/27/2022 23:32:24 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8446722237282009 on epoch=167
05/27/2022 23:32:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
05/27/2022 23:32:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
05/27/2022 23:32:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
05/27/2022 23:32:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
05/27/2022 23:32:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/27/2022 23:32:42 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8352072095756868 on epoch=171
05/27/2022 23:32:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
05/27/2022 23:32:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
05/27/2022 23:32:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=173
05/27/2022 23:32:52 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/27/2022 23:32:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/27/2022 23:33:00 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8365801467720266 on epoch=174
05/27/2022 23:33:03 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/27/2022 23:33:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/27/2022 23:33:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
05/27/2022 23:33:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/27/2022 23:33:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/27/2022 23:33:19 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.795444585458817 on epoch=178
05/27/2022 23:33:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
05/27/2022 23:33:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
05/27/2022 23:33:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
05/27/2022 23:33:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/27/2022 23:33:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
05/27/2022 23:33:37 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7994033424996703 on epoch=182
05/27/2022 23:33:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=182
05/27/2022 23:33:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
05/27/2022 23:33:44 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
05/27/2022 23:33:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/27/2022 23:33:49 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
05/27/2022 23:33:55 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8513821804381577 on epoch=185
05/27/2022 23:33:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/27/2022 23:34:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/27/2022 23:34:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
05/27/2022 23:34:05 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
05/27/2022 23:34:07 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/27/2022 23:34:13 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8981945802107094 on epoch=189
05/27/2022 23:34:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/27/2022 23:34:18 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/27/2022 23:34:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/27/2022 23:34:23 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
05/27/2022 23:34:26 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
05/27/2022 23:34:31 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7852863529028127 on epoch=192
05/27/2022 23:34:34 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
05/27/2022 23:34:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
05/27/2022 23:34:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/27/2022 23:34:42 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
05/27/2022 23:34:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
05/27/2022 23:34:50 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7828633294799084 on epoch=196
05/27/2022 23:34:52 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
05/27/2022 23:34:55 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/27/2022 23:34:57 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
05/27/2022 23:35:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/27/2022 23:35:02 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/27/2022 23:35:08 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.788814709647161 on epoch=199
05/27/2022 23:35:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
05/27/2022 23:35:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
05/27/2022 23:35:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/27/2022 23:35:18 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
05/27/2022 23:35:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
05/27/2022 23:35:27 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9013354113007321 on epoch=203
05/27/2022 23:35:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
05/27/2022 23:35:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/27/2022 23:35:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/27/2022 23:35:37 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/27/2022 23:35:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/27/2022 23:35:45 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8977092994139713 on epoch=207
05/27/2022 23:35:48 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
05/27/2022 23:35:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
05/27/2022 23:35:53 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
05/27/2022 23:35:56 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
05/27/2022 23:35:58 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
05/27/2022 23:36:04 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.847685379136992 on epoch=210
05/27/2022 23:36:07 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
05/27/2022 23:36:09 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
05/27/2022 23:36:12 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/27/2022 23:36:14 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/27/2022 23:36:17 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/27/2022 23:36:18 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 23:36:18 - INFO - __main__ - Printing 3 examples
05/27/2022 23:36:18 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/27/2022 23:36:18 - INFO - __main__ - ['Animal']
05/27/2022 23:36:18 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/27/2022 23:36:18 - INFO - __main__ - ['Animal']
05/27/2022 23:36:18 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/27/2022 23:36:18 - INFO - __main__ - ['Animal']
05/27/2022 23:36:18 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:36:18 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:36:19 - INFO - __main__ - Loaded 224 examples from train data
05/27/2022 23:36:19 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 23:36:19 - INFO - __main__ - Printing 3 examples
05/27/2022 23:36:19 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/27/2022 23:36:19 - INFO - __main__ - ['Animal']
05/27/2022 23:36:19 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/27/2022 23:36:19 - INFO - __main__ - ['Animal']
05/27/2022 23:36:19 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/27/2022 23:36:19 - INFO - __main__ - ['Animal']
05/27/2022 23:36:19 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:36:19 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:36:19 - INFO - __main__ - Loaded 224 examples from dev data
05/27/2022 23:36:23 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8339346441265241 on epoch=214
05/27/2022 23:36:23 - INFO - __main__ - save last model!
05/27/2022 23:36:23 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/27/2022 23:36:23 - INFO - __main__ - Start tokenizing ... 3500 instances
05/27/2022 23:36:23 - INFO - __main__ - Printing 3 examples
05/27/2022 23:36:23 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/27/2022 23:36:23 - INFO - __main__ - ['Animal']
05/27/2022 23:36:23 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/27/2022 23:36:23 - INFO - __main__ - ['Animal']
05/27/2022 23:36:23 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/27/2022 23:36:23 - INFO - __main__ - ['Village']
05/27/2022 23:36:23 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:36:25 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:36:28 - INFO - __main__ - Loaded 3500 examples from test data
05/27/2022 23:36:35 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 23:36:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 23:36:35 - INFO - __main__ - Starting training!
05/27/2022 23:38:31 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
05/27/2022 23:38:31 - INFO - __main__ - Classification-F1 on test data: 0.6631
05/27/2022 23:38:32 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.9096491822535467, test_performance=0.663070485904781
05/27/2022 23:38:32 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
05/27/2022 23:38:33 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 23:38:33 - INFO - __main__ - Printing 3 examples
05/27/2022 23:38:33 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/27/2022 23:38:33 - INFO - __main__ - ['Animal']
05/27/2022 23:38:33 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/27/2022 23:38:33 - INFO - __main__ - ['Animal']
05/27/2022 23:38:33 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/27/2022 23:38:33 - INFO - __main__ - ['Animal']
05/27/2022 23:38:33 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:38:33 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:38:33 - INFO - __main__ - Loaded 224 examples from train data
05/27/2022 23:38:33 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 23:38:33 - INFO - __main__ - Printing 3 examples
05/27/2022 23:38:33 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/27/2022 23:38:33 - INFO - __main__ - ['Animal']
05/27/2022 23:38:33 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/27/2022 23:38:33 - INFO - __main__ - ['Animal']
05/27/2022 23:38:33 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/27/2022 23:38:33 - INFO - __main__ - ['Animal']
05/27/2022 23:38:33 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:38:33 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:38:33 - INFO - __main__ - Loaded 224 examples from dev data
05/27/2022 23:38:52 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 23:38:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 23:38:53 - INFO - __main__ - Starting training!
05/27/2022 23:38:57 - INFO - __main__ - Step 10 Global step 10 Train loss 7.61 on epoch=0
05/27/2022 23:38:59 - INFO - __main__ - Step 20 Global step 20 Train loss 5.67 on epoch=1
05/27/2022 23:39:02 - INFO - __main__ - Step 30 Global step 30 Train loss 4.57 on epoch=2
05/27/2022 23:39:04 - INFO - __main__ - Step 40 Global step 40 Train loss 3.98 on epoch=2
05/27/2022 23:39:07 - INFO - __main__ - Step 50 Global step 50 Train loss 3.72 on epoch=3
05/27/2022 23:39:13 - INFO - __main__ - Global step 50 Train loss 5.11 Classification-F1 0.0 on epoch=3
05/27/2022 23:39:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/27/2022 23:39:15 - INFO - __main__ - Step 60 Global step 60 Train loss 3.34 on epoch=4
05/27/2022 23:39:18 - INFO - __main__ - Step 70 Global step 70 Train loss 2.91 on epoch=4
05/27/2022 23:39:21 - INFO - __main__ - Step 80 Global step 80 Train loss 2.80 on epoch=5
05/27/2022 23:39:23 - INFO - __main__ - Step 90 Global step 90 Train loss 2.49 on epoch=6
05/27/2022 23:39:26 - INFO - __main__ - Step 100 Global step 100 Train loss 2.28 on epoch=7
05/27/2022 23:39:31 - INFO - __main__ - Global step 100 Train loss 2.76 Classification-F1 0.009523809523809523 on epoch=7
05/27/2022 23:39:31 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.009523809523809523 on epoch=7, global_step=100
05/27/2022 23:39:34 - INFO - __main__ - Step 110 Global step 110 Train loss 1.97 on epoch=7
05/27/2022 23:39:36 - INFO - __main__ - Step 120 Global step 120 Train loss 1.90 on epoch=8
05/27/2022 23:39:39 - INFO - __main__ - Step 130 Global step 130 Train loss 1.64 on epoch=9
05/27/2022 23:39:41 - INFO - __main__ - Step 140 Global step 140 Train loss 1.52 on epoch=9
05/27/2022 23:39:44 - INFO - __main__ - Step 150 Global step 150 Train loss 1.45 on epoch=10
05/27/2022 23:39:50 - INFO - __main__ - Global step 150 Train loss 1.70 Classification-F1 0.3895726442862449 on epoch=10
05/27/2022 23:39:50 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.3895726442862449 on epoch=10, global_step=150
05/27/2022 23:39:53 - INFO - __main__ - Step 160 Global step 160 Train loss 1.23 on epoch=11
05/27/2022 23:39:55 - INFO - __main__ - Step 170 Global step 170 Train loss 1.14 on epoch=12
05/27/2022 23:39:58 - INFO - __main__ - Step 180 Global step 180 Train loss 1.03 on epoch=12
05/27/2022 23:40:00 - INFO - __main__ - Step 190 Global step 190 Train loss 1.01 on epoch=13
05/27/2022 23:40:03 - INFO - __main__ - Step 200 Global step 200 Train loss 0.88 on epoch=14
05/27/2022 23:40:10 - INFO - __main__ - Global step 200 Train loss 1.06 Classification-F1 0.5310730144808784 on epoch=14
05/27/2022 23:40:10 - INFO - __main__ - Saving model with best Classification-F1: 0.3895726442862449 -> 0.5310730144808784 on epoch=14, global_step=200
05/27/2022 23:40:12 - INFO - __main__ - Step 210 Global step 210 Train loss 0.83 on epoch=14
05/27/2022 23:40:15 - INFO - __main__ - Step 220 Global step 220 Train loss 0.82 on epoch=15
05/27/2022 23:40:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.77 on epoch=16
05/27/2022 23:40:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.87 on epoch=17
05/27/2022 23:40:23 - INFO - __main__ - Step 250 Global step 250 Train loss 0.69 on epoch=17
05/27/2022 23:40:30 - INFO - __main__ - Global step 250 Train loss 0.80 Classification-F1 0.6302895363168854 on epoch=17
05/27/2022 23:40:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5310730144808784 -> 0.6302895363168854 on epoch=17, global_step=250
05/27/2022 23:40:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.71 on epoch=18
05/27/2022 23:40:35 - INFO - __main__ - Step 270 Global step 270 Train loss 0.67 on epoch=19
05/27/2022 23:40:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.70 on epoch=19
05/27/2022 23:40:40 - INFO - __main__ - Step 290 Global step 290 Train loss 0.68 on epoch=20
05/27/2022 23:40:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.69 on epoch=21
05/27/2022 23:40:50 - INFO - __main__ - Global step 300 Train loss 0.69 Classification-F1 0.6498275573059136 on epoch=21
05/27/2022 23:40:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6302895363168854 -> 0.6498275573059136 on epoch=21, global_step=300
05/27/2022 23:40:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.75 on epoch=22
05/27/2022 23:40:55 - INFO - __main__ - Step 320 Global step 320 Train loss 0.54 on epoch=22
05/27/2022 23:40:58 - INFO - __main__ - Step 330 Global step 330 Train loss 0.62 on epoch=23
05/27/2022 23:41:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.59 on epoch=24
05/27/2022 23:41:03 - INFO - __main__ - Step 350 Global step 350 Train loss 0.51 on epoch=24
05/27/2022 23:41:10 - INFO - __main__ - Global step 350 Train loss 0.60 Classification-F1 0.7159315097933925 on epoch=24
05/27/2022 23:41:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6498275573059136 -> 0.7159315097933925 on epoch=24, global_step=350
05/27/2022 23:41:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.59 on epoch=25
05/27/2022 23:41:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.54 on epoch=26
05/27/2022 23:41:17 - INFO - __main__ - Step 380 Global step 380 Train loss 0.53 on epoch=27
05/27/2022 23:41:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.56 on epoch=27
05/27/2022 23:41:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.57 on epoch=28
05/27/2022 23:41:29 - INFO - __main__ - Global step 400 Train loss 0.56 Classification-F1 0.6546681155090917 on epoch=28
05/27/2022 23:41:32 - INFO - __main__ - Step 410 Global step 410 Train loss 0.48 on epoch=29
05/27/2022 23:41:35 - INFO - __main__ - Step 420 Global step 420 Train loss 0.45 on epoch=29
05/27/2022 23:41:37 - INFO - __main__ - Step 430 Global step 430 Train loss 0.54 on epoch=30
05/27/2022 23:41:40 - INFO - __main__ - Step 440 Global step 440 Train loss 0.40 on epoch=31
05/27/2022 23:41:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.52 on epoch=32
05/27/2022 23:41:49 - INFO - __main__ - Global step 450 Train loss 0.48 Classification-F1 0.659281846307463 on epoch=32
05/27/2022 23:41:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.42 on epoch=32
05/27/2022 23:41:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.44 on epoch=33
05/27/2022 23:41:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.37 on epoch=34
05/27/2022 23:42:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.33 on epoch=34
05/27/2022 23:42:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.37 on epoch=35
05/27/2022 23:42:10 - INFO - __main__ - Global step 500 Train loss 0.38 Classification-F1 0.6382597728285834 on epoch=35
05/27/2022 23:42:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.46 on epoch=36
05/27/2022 23:42:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.40 on epoch=37
05/27/2022 23:42:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.39 on epoch=37
05/27/2022 23:42:20 - INFO - __main__ - Step 540 Global step 540 Train loss 0.43 on epoch=38
05/27/2022 23:42:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.36 on epoch=39
05/27/2022 23:42:29 - INFO - __main__ - Global step 550 Train loss 0.41 Classification-F1 0.6919781817051572 on epoch=39
05/27/2022 23:42:32 - INFO - __main__ - Step 560 Global step 560 Train loss 0.39 on epoch=39
05/27/2022 23:42:35 - INFO - __main__ - Step 570 Global step 570 Train loss 0.36 on epoch=40
05/27/2022 23:42:37 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=41
05/27/2022 23:42:40 - INFO - __main__ - Step 590 Global step 590 Train loss 0.35 on epoch=42
05/27/2022 23:42:42 - INFO - __main__ - Step 600 Global step 600 Train loss 0.34 on epoch=42
05/27/2022 23:42:49 - INFO - __main__ - Global step 600 Train loss 0.36 Classification-F1 0.8038826588526147 on epoch=42
05/27/2022 23:42:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7159315097933925 -> 0.8038826588526147 on epoch=42, global_step=600
05/27/2022 23:42:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=43
05/27/2022 23:42:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.37 on epoch=44
05/27/2022 23:42:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.41 on epoch=44
05/27/2022 23:42:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.29 on epoch=45
05/27/2022 23:43:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.26 on epoch=46
05/27/2022 23:43:09 - INFO - __main__ - Global step 650 Train loss 0.32 Classification-F1 0.7585239031835019 on epoch=46
05/27/2022 23:43:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.36 on epoch=47
05/27/2022 23:43:14 - INFO - __main__ - Step 670 Global step 670 Train loss 0.30 on epoch=47
05/27/2022 23:43:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.25 on epoch=48
05/27/2022 23:43:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.31 on epoch=49
05/27/2022 23:43:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=49
05/27/2022 23:43:29 - INFO - __main__ - Global step 700 Train loss 0.30 Classification-F1 0.816646739593805 on epoch=49
05/27/2022 23:43:29 - INFO - __main__ - Saving model with best Classification-F1: 0.8038826588526147 -> 0.816646739593805 on epoch=49, global_step=700
05/27/2022 23:43:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.29 on epoch=50
05/27/2022 23:43:34 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=51
05/27/2022 23:43:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=52
05/27/2022 23:43:39 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=52
05/27/2022 23:43:42 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=53
05/27/2022 23:43:49 - INFO - __main__ - Global step 750 Train loss 0.25 Classification-F1 0.808734844013519 on epoch=53
05/27/2022 23:43:51 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=54
05/27/2022 23:43:54 - INFO - __main__ - Step 770 Global step 770 Train loss 0.32 on epoch=54
05/27/2022 23:43:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.34 on epoch=55
05/27/2022 23:43:59 - INFO - __main__ - Step 790 Global step 790 Train loss 0.26 on epoch=56
05/27/2022 23:44:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=57
05/27/2022 23:44:09 - INFO - __main__ - Global step 800 Train loss 0.28 Classification-F1 0.8103458043228523 on epoch=57
05/27/2022 23:44:12 - INFO - __main__ - Step 810 Global step 810 Train loss 0.27 on epoch=57
05/27/2022 23:44:14 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=58
05/27/2022 23:44:17 - INFO - __main__ - Step 830 Global step 830 Train loss 0.27 on epoch=59
05/27/2022 23:44:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=59
05/27/2022 23:44:22 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=60
05/27/2022 23:44:29 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.7561721591307804 on epoch=60
05/27/2022 23:44:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.25 on epoch=61
05/27/2022 23:44:34 - INFO - __main__ - Step 870 Global step 870 Train loss 0.28 on epoch=62
05/27/2022 23:44:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=62
05/27/2022 23:44:39 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=63
05/27/2022 23:44:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.26 on epoch=64
05/27/2022 23:44:49 - INFO - __main__ - Global step 900 Train loss 0.23 Classification-F1 0.7711805467775643 on epoch=64
05/27/2022 23:44:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=64
05/27/2022 23:44:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=65
05/27/2022 23:44:57 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=66
05/27/2022 23:44:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=67
05/27/2022 23:45:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=67
05/27/2022 23:45:09 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.8062748035784236 on epoch=67
05/27/2022 23:45:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=68
05/27/2022 23:45:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=69
05/27/2022 23:45:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.19 on epoch=69
05/27/2022 23:45:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.20 on epoch=70
05/27/2022 23:45:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=71
05/27/2022 23:45:29 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.7633701669206294 on epoch=71
05/27/2022 23:45:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.22 on epoch=72
05/27/2022 23:45:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=72
05/27/2022 23:45:36 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=73
05/27/2022 23:45:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=74
05/27/2022 23:45:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=74
05/27/2022 23:45:48 - INFO - __main__ - Global step 1050 Train loss 0.19 Classification-F1 0.719776412023618 on epoch=74
05/27/2022 23:45:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=75
05/27/2022 23:45:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=76
05/27/2022 23:45:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=77
05/27/2022 23:45:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=77
05/27/2022 23:46:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=78
05/27/2022 23:46:08 - INFO - __main__ - Global step 1100 Train loss 0.16 Classification-F1 0.7960221860958028 on epoch=78
05/27/2022 23:46:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=79
05/27/2022 23:46:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=79
05/27/2022 23:46:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=80
05/27/2022 23:46:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.17 on epoch=81
05/27/2022 23:46:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.16 on epoch=82
05/27/2022 23:46:28 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.8174342080750502 on epoch=82
05/27/2022 23:46:28 - INFO - __main__ - Saving model with best Classification-F1: 0.816646739593805 -> 0.8174342080750502 on epoch=82, global_step=1150
05/27/2022 23:46:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=82
05/27/2022 23:46:33 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=83
05/27/2022 23:46:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.16 on epoch=84
05/27/2022 23:46:38 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
05/27/2022 23:46:41 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=85
05/27/2022 23:46:48 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.7513551360821968 on epoch=85
05/27/2022 23:46:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=86
05/27/2022 23:46:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
05/27/2022 23:46:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=87
05/27/2022 23:46:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=88
05/27/2022 23:47:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.19 on epoch=89
05/27/2022 23:47:07 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.6112438905180839 on epoch=89
05/27/2022 23:47:10 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=89
05/27/2022 23:47:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=90
05/27/2022 23:47:15 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=91
05/27/2022 23:47:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=92
05/27/2022 23:47:20 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
05/27/2022 23:47:27 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.6996553324273123 on epoch=92
05/27/2022 23:47:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=93
05/27/2022 23:47:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
05/27/2022 23:47:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=94
05/27/2022 23:47:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=95
05/27/2022 23:47:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.20 on epoch=96
05/27/2022 23:47:46 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.7183836879372768 on epoch=96
05/27/2022 23:47:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=97
05/27/2022 23:47:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=97
05/27/2022 23:47:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
05/27/2022 23:47:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
05/27/2022 23:47:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
05/27/2022 23:48:06 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.7327709894645378 on epoch=99
05/27/2022 23:48:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
05/27/2022 23:48:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=101
05/27/2022 23:48:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=102
05/27/2022 23:48:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=102
05/27/2022 23:48:19 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=103
05/27/2022 23:48:25 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.7039777506434086 on epoch=103
05/27/2022 23:48:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=104
05/27/2022 23:48:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
05/27/2022 23:48:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
05/27/2022 23:48:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
05/27/2022 23:48:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=107
05/27/2022 23:48:45 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.8371532869012708 on epoch=107
05/27/2022 23:48:45 - INFO - __main__ - Saving model with best Classification-F1: 0.8174342080750502 -> 0.8371532869012708 on epoch=107, global_step=1500
05/27/2022 23:48:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=107
05/27/2022 23:48:50 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=108
05/27/2022 23:48:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=109
05/27/2022 23:48:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
05/27/2022 23:48:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
05/27/2022 23:49:04 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.6526118717119102 on epoch=110
05/27/2022 23:49:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
05/27/2022 23:49:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=112
05/27/2022 23:49:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
05/27/2022 23:49:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
05/27/2022 23:49:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=114
05/27/2022 23:49:23 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.651687797445812 on epoch=114
05/27/2022 23:49:26 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=114
05/27/2022 23:49:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=115
05/27/2022 23:49:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
05/27/2022 23:49:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
05/27/2022 23:49:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=117
05/27/2022 23:49:42 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.7079642813369286 on epoch=117
05/27/2022 23:49:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
05/27/2022 23:49:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
05/27/2022 23:49:50 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
05/27/2022 23:49:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
05/27/2022 23:49:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
05/27/2022 23:50:01 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.6151698284654193 on epoch=121
05/27/2022 23:50:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.12 on epoch=122
05/27/2022 23:50:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
05/27/2022 23:50:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
05/27/2022 23:50:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=124
05/27/2022 23:50:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=124
05/27/2022 23:50:21 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.7354611390812859 on epoch=124
05/27/2022 23:50:23 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=125
05/27/2022 23:50:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=126
05/27/2022 23:50:29 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
05/27/2022 23:50:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.16 on epoch=127
05/27/2022 23:50:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
05/27/2022 23:50:40 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.7036340257665036 on epoch=128
05/27/2022 23:50:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
05/27/2022 23:50:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
05/27/2022 23:50:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
05/27/2022 23:50:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=131
05/27/2022 23:50:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
05/27/2022 23:50:59 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.692566125338105 on epoch=132
05/27/2022 23:51:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
05/27/2022 23:51:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
05/27/2022 23:51:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
05/27/2022 23:51:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
05/27/2022 23:51:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
05/27/2022 23:51:19 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.6779669679584387 on epoch=135
05/27/2022 23:51:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
05/27/2022 23:51:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=137
05/27/2022 23:51:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=137
05/27/2022 23:51:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=138
05/27/2022 23:51:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
05/27/2022 23:51:38 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.7267168910574983 on epoch=139
05/27/2022 23:51:40 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=139
05/27/2022 23:51:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
05/27/2022 23:51:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
05/27/2022 23:51:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
05/27/2022 23:51:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
05/27/2022 23:51:57 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7308678023811306 on epoch=142
05/27/2022 23:51:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=143
05/27/2022 23:52:02 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=144
05/27/2022 23:52:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
05/27/2022 23:52:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
05/27/2022 23:52:10 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
05/27/2022 23:52:16 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7357795241387305 on epoch=146
05/27/2022 23:52:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
05/27/2022 23:52:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
05/27/2022 23:52:24 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=148
05/27/2022 23:52:26 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
05/27/2022 23:52:29 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
05/27/2022 23:52:35 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.7227265311468347 on epoch=149
05/27/2022 23:52:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
05/27/2022 23:52:40 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
05/27/2022 23:52:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
05/27/2022 23:52:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
05/27/2022 23:52:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=153
05/27/2022 23:52:54 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7376297407762107 on epoch=153
05/27/2022 23:52:57 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
05/27/2022 23:52:59 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
05/27/2022 23:53:02 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=155
05/27/2022 23:53:04 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
05/27/2022 23:53:07 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
05/27/2022 23:53:14 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7824566778774837 on epoch=157
05/27/2022 23:53:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
05/27/2022 23:53:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=158
05/27/2022 23:53:21 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
05/27/2022 23:53:24 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
05/27/2022 23:53:26 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
05/27/2022 23:53:33 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7747659670722012 on epoch=160
05/27/2022 23:53:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
05/27/2022 23:53:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
05/27/2022 23:53:41 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
05/27/2022 23:53:43 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
05/27/2022 23:53:46 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
05/27/2022 23:53:52 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7795032851969431 on epoch=164
05/27/2022 23:53:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
05/27/2022 23:53:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
05/27/2022 23:54:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
05/27/2022 23:54:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
05/27/2022 23:54:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
05/27/2022 23:54:11 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7957455597384718 on epoch=167
05/27/2022 23:54:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=168
05/27/2022 23:54:17 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
05/27/2022 23:54:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
05/27/2022 23:54:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
05/27/2022 23:54:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
05/27/2022 23:54:31 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6652349294961185 on epoch=171
05/27/2022 23:54:33 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
05/27/2022 23:54:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
05/27/2022 23:54:38 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
05/27/2022 23:54:41 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=174
05/27/2022 23:54:44 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/27/2022 23:54:50 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.7314298104383493 on epoch=174
05/27/2022 23:54:53 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
05/27/2022 23:54:55 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
05/27/2022 23:54:58 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
05/27/2022 23:55:00 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
05/27/2022 23:55:03 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
05/27/2022 23:55:09 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7489067676260963 on epoch=178
05/27/2022 23:55:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
05/27/2022 23:55:14 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
05/27/2022 23:55:17 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
05/27/2022 23:55:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=181
05/27/2022 23:55:22 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=182
05/27/2022 23:55:28 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7318066542354968 on epoch=182
05/27/2022 23:55:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/27/2022 23:55:33 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/27/2022 23:55:36 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
05/27/2022 23:55:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
05/27/2022 23:55:41 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
05/27/2022 23:55:48 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8392585192573845 on epoch=185
05/27/2022 23:55:48 - INFO - __main__ - Saving model with best Classification-F1: 0.8371532869012708 -> 0.8392585192573845 on epoch=185, global_step=2600
05/27/2022 23:55:50 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/27/2022 23:55:53 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/27/2022 23:55:55 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
05/27/2022 23:55:58 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
05/27/2022 23:56:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
05/27/2022 23:56:07 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7064631887636981 on epoch=189
05/27/2022 23:56:09 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/27/2022 23:56:12 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
05/27/2022 23:56:14 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/27/2022 23:56:17 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
05/27/2022 23:56:19 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
05/27/2022 23:56:26 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7212428602917218 on epoch=192
05/27/2022 23:56:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
05/27/2022 23:56:31 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
05/27/2022 23:56:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/27/2022 23:56:36 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/27/2022 23:56:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
05/27/2022 23:56:44 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6857778364557052 on epoch=196
05/27/2022 23:56:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.08 on epoch=197
05/27/2022 23:56:50 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
05/27/2022 23:56:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
05/27/2022 23:56:55 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
05/27/2022 23:56:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
05/27/2022 23:57:03 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7016098719227587 on epoch=199
05/27/2022 23:57:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/27/2022 23:57:08 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
05/27/2022 23:57:11 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
05/27/2022 23:57:14 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=202
05/27/2022 23:57:16 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
05/27/2022 23:57:22 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.6874715689469011 on epoch=203
05/27/2022 23:57:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
05/27/2022 23:57:28 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=204
05/27/2022 23:57:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/27/2022 23:57:33 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
05/27/2022 23:57:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/27/2022 23:57:41 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.764656707647846 on epoch=207
05/27/2022 23:57:44 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/27/2022 23:57:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/27/2022 23:57:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/27/2022 23:57:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/27/2022 23:57:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
05/27/2022 23:58:00 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7739835851539166 on epoch=210
05/27/2022 23:58:03 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/27/2022 23:58:06 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
05/27/2022 23:58:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/27/2022 23:58:11 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
05/27/2022 23:58:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
05/27/2022 23:58:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 23:58:15 - INFO - __main__ - Printing 3 examples
05/27/2022 23:58:15 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/27/2022 23:58:15 - INFO - __main__ - ['Animal']
05/27/2022 23:58:15 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/27/2022 23:58:15 - INFO - __main__ - ['Animal']
05/27/2022 23:58:15 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/27/2022 23:58:15 - INFO - __main__ - ['Animal']
05/27/2022 23:58:15 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:58:15 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:58:15 - INFO - __main__ - Loaded 224 examples from train data
05/27/2022 23:58:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/27/2022 23:58:15 - INFO - __main__ - Printing 3 examples
05/27/2022 23:58:15 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/27/2022 23:58:15 - INFO - __main__ - ['Animal']
05/27/2022 23:58:15 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/27/2022 23:58:15 - INFO - __main__ - ['Animal']
05/27/2022 23:58:15 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/27/2022 23:58:15 - INFO - __main__ - ['Animal']
05/27/2022 23:58:15 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:58:15 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:58:15 - INFO - __main__ - Loaded 224 examples from dev data
05/27/2022 23:58:19 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7261620793641667 on epoch=214
05/27/2022 23:58:19 - INFO - __main__ - save last model!
05/27/2022 23:58:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/27/2022 23:58:19 - INFO - __main__ - Start tokenizing ... 3500 instances
05/27/2022 23:58:19 - INFO - __main__ - Printing 3 examples
05/27/2022 23:58:19 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/27/2022 23:58:19 - INFO - __main__ - ['Animal']
05/27/2022 23:58:19 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/27/2022 23:58:19 - INFO - __main__ - ['Animal']
05/27/2022 23:58:19 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/27/2022 23:58:19 - INFO - __main__ - ['Village']
05/27/2022 23:58:19 - INFO - __main__ - Tokenizing Input ...
05/27/2022 23:58:21 - INFO - __main__ - Tokenizing Output ...
05/27/2022 23:58:25 - INFO - __main__ - Loaded 3500 examples from test data
05/27/2022 23:58:34 - INFO - __main__ - load prompt embedding from ckpt
05/27/2022 23:58:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/27/2022 23:58:35 - INFO - __main__ - Starting training!
05/28/2022 00:00:25 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
05/28/2022 00:00:25 - INFO - __main__ - Classification-F1 on test data: 0.5213
05/28/2022 00:00:26 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.8392585192573845, test_performance=0.5213041193876635
05/28/2022 00:00:26 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
05/28/2022 00:00:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 00:00:26 - INFO - __main__ - Printing 3 examples
05/28/2022 00:00:26 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 00:00:26 - INFO - __main__ - ['Animal']
05/28/2022 00:00:26 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 00:00:26 - INFO - __main__ - ['Animal']
05/28/2022 00:00:26 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/28/2022 00:00:26 - INFO - __main__ - ['Animal']
05/28/2022 00:00:26 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:00:27 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:00:27 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 00:00:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 00:00:27 - INFO - __main__ - Printing 3 examples
05/28/2022 00:00:27 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/28/2022 00:00:27 - INFO - __main__ - ['Animal']
05/28/2022 00:00:27 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/28/2022 00:00:27 - INFO - __main__ - ['Animal']
05/28/2022 00:00:27 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/28/2022 00:00:27 - INFO - __main__ - ['Animal']
05/28/2022 00:00:27 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:00:27 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:00:27 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 00:00:46 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 00:00:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 00:00:46 - INFO - __main__ - Starting training!
05/28/2022 00:00:50 - INFO - __main__ - Step 10 Global step 10 Train loss 6.00 on epoch=0
05/28/2022 00:00:53 - INFO - __main__ - Step 20 Global step 20 Train loss 4.01 on epoch=1
05/28/2022 00:00:56 - INFO - __main__ - Step 30 Global step 30 Train loss 3.04 on epoch=2
05/28/2022 00:00:59 - INFO - __main__ - Step 40 Global step 40 Train loss 2.24 on epoch=2
05/28/2022 00:01:01 - INFO - __main__ - Step 50 Global step 50 Train loss 1.85 on epoch=3
05/28/2022 00:01:06 - INFO - __main__ - Global step 50 Train loss 3.43 Classification-F1 0.20597690738439203 on epoch=3
05/28/2022 00:01:06 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.20597690738439203 on epoch=3, global_step=50
05/28/2022 00:01:08 - INFO - __main__ - Step 60 Global step 60 Train loss 1.62 on epoch=4
05/28/2022 00:01:11 - INFO - __main__ - Step 70 Global step 70 Train loss 1.31 on epoch=4
05/28/2022 00:01:14 - INFO - __main__ - Step 80 Global step 80 Train loss 1.19 on epoch=5
05/28/2022 00:01:16 - INFO - __main__ - Step 90 Global step 90 Train loss 0.95 on epoch=6
05/28/2022 00:01:19 - INFO - __main__ - Step 100 Global step 100 Train loss 0.82 on epoch=7
05/28/2022 00:01:27 - INFO - __main__ - Global step 100 Train loss 1.18 Classification-F1 0.5228909163472397 on epoch=7
05/28/2022 00:01:27 - INFO - __main__ - Saving model with best Classification-F1: 0.20597690738439203 -> 0.5228909163472397 on epoch=7, global_step=100
05/28/2022 00:01:30 - INFO - __main__ - Step 110 Global step 110 Train loss 0.68 on epoch=7
05/28/2022 00:01:33 - INFO - __main__ - Step 120 Global step 120 Train loss 0.73 on epoch=8
05/28/2022 00:01:35 - INFO - __main__ - Step 130 Global step 130 Train loss 0.71 on epoch=9
05/28/2022 00:01:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.61 on epoch=9
05/28/2022 00:01:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.65 on epoch=10
05/28/2022 00:01:47 - INFO - __main__ - Global step 150 Train loss 0.68 Classification-F1 0.5144386678316378 on epoch=10
05/28/2022 00:01:50 - INFO - __main__ - Step 160 Global step 160 Train loss 0.64 on epoch=11
05/28/2022 00:01:52 - INFO - __main__ - Step 170 Global step 170 Train loss 0.54 on epoch=12
05/28/2022 00:01:55 - INFO - __main__ - Step 180 Global step 180 Train loss 0.52 on epoch=12
05/28/2022 00:01:58 - INFO - __main__ - Step 190 Global step 190 Train loss 0.49 on epoch=13
05/28/2022 00:02:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.54 on epoch=14
05/28/2022 00:02:08 - INFO - __main__ - Global step 200 Train loss 0.55 Classification-F1 0.7447346042649035 on epoch=14
05/28/2022 00:02:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5228909163472397 -> 0.7447346042649035 on epoch=14, global_step=200
05/28/2022 00:02:11 - INFO - __main__ - Step 210 Global step 210 Train loss 0.51 on epoch=14
05/28/2022 00:02:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.41 on epoch=15
05/28/2022 00:02:16 - INFO - __main__ - Step 230 Global step 230 Train loss 0.43 on epoch=16
05/28/2022 00:02:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.53 on epoch=17
05/28/2022 00:02:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.35 on epoch=17
05/28/2022 00:02:27 - INFO - __main__ - Global step 250 Train loss 0.45 Classification-F1 0.5244074818079357 on epoch=17
05/28/2022 00:02:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.41 on epoch=18
05/28/2022 00:02:33 - INFO - __main__ - Step 270 Global step 270 Train loss 0.39 on epoch=19
05/28/2022 00:02:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.30 on epoch=19
05/28/2022 00:02:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.33 on epoch=20
05/28/2022 00:02:40 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=21
05/28/2022 00:02:47 - INFO - __main__ - Global step 300 Train loss 0.35 Classification-F1 0.6714391527419075 on epoch=21
05/28/2022 00:02:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.30 on epoch=22
05/28/2022 00:02:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=22
05/28/2022 00:02:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.24 on epoch=23
05/28/2022 00:02:57 - INFO - __main__ - Step 340 Global step 340 Train loss 0.33 on epoch=24
05/28/2022 00:02:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.32 on epoch=24
05/28/2022 00:03:06 - INFO - __main__ - Global step 350 Train loss 0.31 Classification-F1 0.6839601817187206 on epoch=24
05/28/2022 00:03:09 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=25
05/28/2022 00:03:11 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=26
05/28/2022 00:03:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.29 on epoch=27
05/28/2022 00:03:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=27
05/28/2022 00:03:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.24 on epoch=28
05/28/2022 00:03:26 - INFO - __main__ - Global step 400 Train loss 0.26 Classification-F1 0.7249801205530563 on epoch=28
05/28/2022 00:03:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=29
05/28/2022 00:03:31 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=29
05/28/2022 00:03:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=30
05/28/2022 00:03:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=31
05/28/2022 00:03:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=32
05/28/2022 00:03:46 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.7916440671966324 on epoch=32
05/28/2022 00:03:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7447346042649035 -> 0.7916440671966324 on epoch=32, global_step=450
05/28/2022 00:03:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=32
05/28/2022 00:03:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=33
05/28/2022 00:03:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=34
05/28/2022 00:03:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=34
05/28/2022 00:03:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=35
05/28/2022 00:04:06 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.8729099419087315 on epoch=35
05/28/2022 00:04:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7916440671966324 -> 0.8729099419087315 on epoch=35, global_step=500
05/28/2022 00:04:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=36
05/28/2022 00:04:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=37
05/28/2022 00:04:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.10 on epoch=37
05/28/2022 00:04:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=38
05/28/2022 00:04:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=39
05/28/2022 00:04:27 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.7456408633104145 on epoch=39
05/28/2022 00:04:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=39
05/28/2022 00:04:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=40
05/28/2022 00:04:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=41
05/28/2022 00:04:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=42
05/28/2022 00:04:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=42
05/28/2022 00:04:47 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.7081131832692735 on epoch=42
05/28/2022 00:04:49 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=43
05/28/2022 00:04:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=44
05/28/2022 00:04:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=44
05/28/2022 00:04:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=45
05/28/2022 00:05:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=46
05/28/2022 00:05:07 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.6981058261420315 on epoch=46
05/28/2022 00:05:10 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=47
05/28/2022 00:05:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=47
05/28/2022 00:05:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=48
05/28/2022 00:05:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=49
05/28/2022 00:05:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=49
05/28/2022 00:05:26 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.719887641436503 on epoch=49
05/28/2022 00:05:28 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=50
05/28/2022 00:05:31 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=51
05/28/2022 00:05:34 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=52
05/28/2022 00:05:36 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
05/28/2022 00:05:39 - INFO - __main__ - Step 750 Global step 750 Train loss 0.04 on epoch=53
05/28/2022 00:05:44 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.7248516376428563 on epoch=53
05/28/2022 00:05:47 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=54
05/28/2022 00:05:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=54
05/28/2022 00:05:52 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=55
05/28/2022 00:05:55 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=56
05/28/2022 00:05:57 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=57
05/28/2022 00:06:03 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7673785445091444 on epoch=57
05/28/2022 00:06:06 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=57
05/28/2022 00:06:08 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=58
05/28/2022 00:06:11 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=59
05/28/2022 00:06:14 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=59
05/28/2022 00:06:16 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=60
05/28/2022 00:06:21 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.6171175714537162 on epoch=60
05/28/2022 00:06:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=61
05/28/2022 00:06:27 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=62
05/28/2022 00:06:29 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=62
05/28/2022 00:06:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=63
05/28/2022 00:06:34 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=64
05/28/2022 00:06:41 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.7564909709974545 on epoch=64
05/28/2022 00:06:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=64
05/28/2022 00:06:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=65
05/28/2022 00:06:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=66
05/28/2022 00:06:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=67
05/28/2022 00:06:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
05/28/2022 00:06:59 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.784486305683827 on epoch=67
05/28/2022 00:07:02 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=68
05/28/2022 00:07:04 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=69
05/28/2022 00:07:07 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=69
05/28/2022 00:07:10 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=70
05/28/2022 00:07:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
05/28/2022 00:07:18 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.8080419032121393 on epoch=71
05/28/2022 00:07:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
05/28/2022 00:07:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
05/28/2022 00:07:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
05/28/2022 00:07:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
05/28/2022 00:07:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
05/28/2022 00:07:37 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.8983196862862177 on epoch=74
05/28/2022 00:07:37 - INFO - __main__ - Saving model with best Classification-F1: 0.8729099419087315 -> 0.8983196862862177 on epoch=74, global_step=1050
05/28/2022 00:07:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=75
05/28/2022 00:07:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=76
05/28/2022 00:07:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
05/28/2022 00:07:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
05/28/2022 00:07:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
05/28/2022 00:07:56 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.7632385701004332 on epoch=78
05/28/2022 00:07:58 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
05/28/2022 00:08:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
05/28/2022 00:08:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
05/28/2022 00:08:06 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=81
05/28/2022 00:08:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
05/28/2022 00:08:14 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7926693710538506 on epoch=82
05/28/2022 00:08:17 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=82
05/28/2022 00:08:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
05/28/2022 00:08:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
05/28/2022 00:08:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=84
05/28/2022 00:08:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
05/28/2022 00:08:33 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.8403146113650739 on epoch=85
05/28/2022 00:08:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
05/28/2022 00:08:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
05/28/2022 00:08:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
05/28/2022 00:08:43 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
05/28/2022 00:08:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=89
05/28/2022 00:08:53 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.8859269162210339 on epoch=89
05/28/2022 00:08:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
05/28/2022 00:08:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=90
05/28/2022 00:09:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=91
05/28/2022 00:09:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=92
05/28/2022 00:09:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
05/28/2022 00:09:11 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.7758958027859237 on epoch=92
05/28/2022 00:09:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=93
05/28/2022 00:09:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
05/28/2022 00:09:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
05/28/2022 00:09:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=95
05/28/2022 00:09:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
05/28/2022 00:09:30 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.785293289073531 on epoch=96
05/28/2022 00:09:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
05/28/2022 00:09:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=97
05/28/2022 00:09:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=98
05/28/2022 00:09:40 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=99
05/28/2022 00:09:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
05/28/2022 00:09:49 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.882360420474025 on epoch=99
05/28/2022 00:09:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
05/28/2022 00:09:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
05/28/2022 00:09:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
05/28/2022 00:09:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=102
05/28/2022 00:10:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
05/28/2022 00:10:08 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.8581592881419486 on epoch=103
05/28/2022 00:10:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
05/28/2022 00:10:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
05/28/2022 00:10:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
05/28/2022 00:10:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
05/28/2022 00:10:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
05/28/2022 00:10:27 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.8951845534452026 on epoch=107
05/28/2022 00:10:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
05/28/2022 00:10:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
05/28/2022 00:10:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=109
05/28/2022 00:10:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
05/28/2022 00:10:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
05/28/2022 00:10:47 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.8902348052174657 on epoch=110
05/28/2022 00:10:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
05/28/2022 00:10:52 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=112
05/28/2022 00:10:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
05/28/2022 00:10:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
05/28/2022 00:11:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
05/28/2022 00:11:06 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.895046071855108 on epoch=114
05/28/2022 00:11:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=114
05/28/2022 00:11:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
05/28/2022 00:11:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
05/28/2022 00:11:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
05/28/2022 00:11:19 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
05/28/2022 00:11:25 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8820867156841911 on epoch=117
05/28/2022 00:11:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
05/28/2022 00:11:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
05/28/2022 00:11:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/28/2022 00:11:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
05/28/2022 00:11:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
05/28/2022 00:11:43 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8840329768270944 on epoch=121
05/28/2022 00:11:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
05/28/2022 00:11:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
05/28/2022 00:11:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
05/28/2022 00:11:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=124
05/28/2022 00:11:56 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
05/28/2022 00:12:02 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.910046432062561 on epoch=124
05/28/2022 00:12:02 - INFO - __main__ - Saving model with best Classification-F1: 0.8983196862862177 -> 0.910046432062561 on epoch=124, global_step=1750
05/28/2022 00:12:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=125
05/28/2022 00:12:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
05/28/2022 00:12:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
05/28/2022 00:12:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=127
05/28/2022 00:12:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
05/28/2022 00:12:21 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.8979573512906847 on epoch=128
05/28/2022 00:12:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
05/28/2022 00:12:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
05/28/2022 00:12:29 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/28/2022 00:12:32 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
05/28/2022 00:12:34 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
05/28/2022 00:12:40 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.914360540892799 on epoch=132
05/28/2022 00:12:40 - INFO - __main__ - Saving model with best Classification-F1: 0.910046432062561 -> 0.914360540892799 on epoch=132, global_step=1850
05/28/2022 00:12:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=132
05/28/2022 00:12:45 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
05/28/2022 00:12:48 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
05/28/2022 00:12:50 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=134
05/28/2022 00:12:53 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/28/2022 00:12:59 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8821511852647898 on epoch=135
05/28/2022 00:13:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
05/28/2022 00:13:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/28/2022 00:13:07 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
05/28/2022 00:13:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
05/28/2022 00:13:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
05/28/2022 00:13:18 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9080188028290496 on epoch=139
05/28/2022 00:13:20 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
05/28/2022 00:13:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=140
05/28/2022 00:13:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
05/28/2022 00:13:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
05/28/2022 00:13:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=142
05/28/2022 00:13:37 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.9774812197606314 on epoch=142
05/28/2022 00:13:37 - INFO - __main__ - Saving model with best Classification-F1: 0.914360540892799 -> 0.9774812197606314 on epoch=142, global_step=2000
05/28/2022 00:13:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
05/28/2022 00:13:42 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=144
05/28/2022 00:13:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
05/28/2022 00:13:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=145
05/28/2022 00:13:50 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/28/2022 00:13:56 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.9775118698505795 on epoch=146
05/28/2022 00:13:56 - INFO - __main__ - Saving model with best Classification-F1: 0.9774812197606314 -> 0.9775118698505795 on epoch=146, global_step=2050
05/28/2022 00:13:58 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/28/2022 00:14:01 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
05/28/2022 00:14:03 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
05/28/2022 00:14:06 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
05/28/2022 00:14:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
05/28/2022 00:14:15 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8087648864241638 on epoch=149
05/28/2022 00:14:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/28/2022 00:14:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/28/2022 00:14:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
05/28/2022 00:14:25 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
05/28/2022 00:14:28 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
05/28/2022 00:14:34 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8099905303030304 on epoch=153
05/28/2022 00:14:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
05/28/2022 00:14:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/28/2022 00:14:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/28/2022 00:14:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=156
05/28/2022 00:14:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/28/2022 00:14:53 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8956166522106346 on epoch=157
05/28/2022 00:14:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=157
05/28/2022 00:14:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=158
05/28/2022 00:15:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
05/28/2022 00:15:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
05/28/2022 00:15:05 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
05/28/2022 00:15:12 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9055741227626655 on epoch=160
05/28/2022 00:15:14 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
05/28/2022 00:15:17 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
05/28/2022 00:15:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
05/28/2022 00:15:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
05/28/2022 00:15:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/28/2022 00:15:31 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8957715215875155 on epoch=164
05/28/2022 00:15:34 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
05/28/2022 00:15:36 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
05/28/2022 00:15:39 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
05/28/2022 00:15:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
05/28/2022 00:15:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/28/2022 00:15:50 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8874247208386993 on epoch=167
05/28/2022 00:15:53 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
05/28/2022 00:15:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/28/2022 00:15:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
05/28/2022 00:16:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
05/28/2022 00:16:03 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
05/28/2022 00:16:09 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8377004249484088 on epoch=171
05/28/2022 00:16:12 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
05/28/2022 00:16:14 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
05/28/2022 00:16:17 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
05/28/2022 00:16:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
05/28/2022 00:16:22 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=174
05/28/2022 00:16:28 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8409028234233323 on epoch=174
05/28/2022 00:16:31 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
05/28/2022 00:16:33 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
05/28/2022 00:16:36 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
05/28/2022 00:16:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
05/28/2022 00:16:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/28/2022 00:16:47 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8986253289194466 on epoch=178
05/28/2022 00:16:50 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
05/28/2022 00:16:52 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
05/28/2022 00:16:55 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
05/28/2022 00:16:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
05/28/2022 00:17:00 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
05/28/2022 00:17:06 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8994774827381318 on epoch=182
05/28/2022 00:17:09 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/28/2022 00:17:11 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/28/2022 00:17:14 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
05/28/2022 00:17:16 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/28/2022 00:17:19 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
05/28/2022 00:17:25 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.892577715838365 on epoch=185
05/28/2022 00:17:28 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
05/28/2022 00:17:30 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
05/28/2022 00:17:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
05/28/2022 00:17:35 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
05/28/2022 00:17:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/28/2022 00:17:44 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.837007889950651 on epoch=189
05/28/2022 00:17:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
05/28/2022 00:17:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
05/28/2022 00:17:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/28/2022 00:17:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=192
05/28/2022 00:17:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/28/2022 00:18:03 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8885258115967074 on epoch=192
05/28/2022 00:18:06 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
05/28/2022 00:18:08 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
05/28/2022 00:18:11 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/28/2022 00:18:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/28/2022 00:18:16 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
05/28/2022 00:18:22 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.8817092790195257 on epoch=196
05/28/2022 00:18:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/28/2022 00:18:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
05/28/2022 00:18:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/28/2022 00:18:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
05/28/2022 00:18:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
05/28/2022 00:18:41 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8207824038706393 on epoch=199
05/28/2022 00:18:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
05/28/2022 00:18:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
05/28/2022 00:18:49 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/28/2022 00:18:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
05/28/2022 00:18:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
05/28/2022 00:19:00 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8167278409303351 on epoch=203
05/28/2022 00:19:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
05/28/2022 00:19:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/28/2022 00:19:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/28/2022 00:19:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
05/28/2022 00:19:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
05/28/2022 00:19:19 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8637956645563136 on epoch=207
05/28/2022 00:19:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
05/28/2022 00:19:24 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/28/2022 00:19:27 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
05/28/2022 00:19:29 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
05/28/2022 00:19:32 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/28/2022 00:19:38 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8066849561794416 on epoch=210
05/28/2022 00:19:41 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/28/2022 00:19:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
05/28/2022 00:19:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/28/2022 00:19:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
05/28/2022 00:19:51 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/28/2022 00:19:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 00:19:53 - INFO - __main__ - Printing 3 examples
05/28/2022 00:19:53 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 00:19:53 - INFO - __main__ - ['Animal']
05/28/2022 00:19:53 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 00:19:53 - INFO - __main__ - ['Animal']
05/28/2022 00:19:53 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/28/2022 00:19:53 - INFO - __main__ - ['Animal']
05/28/2022 00:19:53 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:19:53 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:19:53 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 00:19:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 00:19:53 - INFO - __main__ - Printing 3 examples
05/28/2022 00:19:53 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/28/2022 00:19:53 - INFO - __main__ - ['Animal']
05/28/2022 00:19:53 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/28/2022 00:19:53 - INFO - __main__ - ['Animal']
05/28/2022 00:19:53 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/28/2022 00:19:53 - INFO - __main__ - ['Animal']
05/28/2022 00:19:53 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:19:53 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:19:53 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 00:19:57 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8943981176587668 on epoch=214
05/28/2022 00:19:57 - INFO - __main__ - save last model!
05/28/2022 00:19:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 00:19:57 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 00:19:57 - INFO - __main__ - Printing 3 examples
05/28/2022 00:19:57 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 00:19:57 - INFO - __main__ - ['Animal']
05/28/2022 00:19:57 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 00:19:57 - INFO - __main__ - ['Animal']
05/28/2022 00:19:57 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 00:19:57 - INFO - __main__ - ['Village']
05/28/2022 00:19:57 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:19:59 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:20:03 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 00:20:09 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 00:20:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 00:20:10 - INFO - __main__ - Starting training!
05/28/2022 00:22:09 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
05/28/2022 00:22:09 - INFO - __main__ - Classification-F1 on test data: 0.6756
05/28/2022 00:22:09 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.9775118698505795, test_performance=0.6755746235953347
05/28/2022 00:22:09 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
05/28/2022 00:22:10 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 00:22:10 - INFO - __main__ - Printing 3 examples
05/28/2022 00:22:10 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 00:22:10 - INFO - __main__ - ['Animal']
05/28/2022 00:22:10 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 00:22:10 - INFO - __main__ - ['Animal']
05/28/2022 00:22:10 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/28/2022 00:22:10 - INFO - __main__ - ['Animal']
05/28/2022 00:22:10 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:22:10 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:22:10 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 00:22:10 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 00:22:10 - INFO - __main__ - Printing 3 examples
05/28/2022 00:22:10 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/28/2022 00:22:10 - INFO - __main__ - ['Animal']
05/28/2022 00:22:10 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/28/2022 00:22:10 - INFO - __main__ - ['Animal']
05/28/2022 00:22:10 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/28/2022 00:22:10 - INFO - __main__ - ['Animal']
05/28/2022 00:22:10 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:22:10 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:22:11 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 00:22:26 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 00:22:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 00:22:27 - INFO - __main__ - Starting training!
05/28/2022 00:22:30 - INFO - __main__ - Step 10 Global step 10 Train loss 6.59 on epoch=0
05/28/2022 00:22:33 - INFO - __main__ - Step 20 Global step 20 Train loss 4.51 on epoch=1
05/28/2022 00:22:36 - INFO - __main__ - Step 30 Global step 30 Train loss 3.45 on epoch=2
05/28/2022 00:22:38 - INFO - __main__ - Step 40 Global step 40 Train loss 2.65 on epoch=2
05/28/2022 00:22:41 - INFO - __main__ - Step 50 Global step 50 Train loss 2.13 on epoch=3
05/28/2022 00:22:47 - INFO - __main__ - Global step 50 Train loss 3.86 Classification-F1 0.07481996508620836 on epoch=3
05/28/2022 00:22:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07481996508620836 on epoch=3, global_step=50
05/28/2022 00:22:50 - INFO - __main__ - Step 60 Global step 60 Train loss 1.77 on epoch=4
05/28/2022 00:22:52 - INFO - __main__ - Step 70 Global step 70 Train loss 1.61 on epoch=4
05/28/2022 00:22:55 - INFO - __main__ - Step 80 Global step 80 Train loss 1.17 on epoch=5
05/28/2022 00:22:58 - INFO - __main__ - Step 90 Global step 90 Train loss 0.99 on epoch=6
05/28/2022 00:23:00 - INFO - __main__ - Step 100 Global step 100 Train loss 1.00 on epoch=7
05/28/2022 00:23:09 - INFO - __main__ - Global step 100 Train loss 1.31 Classification-F1 0.4034008379848787 on epoch=7
05/28/2022 00:23:09 - INFO - __main__ - Saving model with best Classification-F1: 0.07481996508620836 -> 0.4034008379848787 on epoch=7, global_step=100
05/28/2022 00:23:11 - INFO - __main__ - Step 110 Global step 110 Train loss 0.89 on epoch=7
05/28/2022 00:23:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.80 on epoch=8
05/28/2022 00:23:16 - INFO - __main__ - Step 130 Global step 130 Train loss 0.82 on epoch=9
05/28/2022 00:23:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.71 on epoch=9
05/28/2022 00:23:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.64 on epoch=10
05/28/2022 00:23:29 - INFO - __main__ - Global step 150 Train loss 0.77 Classification-F1 0.553228773398917 on epoch=10
05/28/2022 00:23:29 - INFO - __main__ - Saving model with best Classification-F1: 0.4034008379848787 -> 0.553228773398917 on epoch=10, global_step=150
05/28/2022 00:23:32 - INFO - __main__ - Step 160 Global step 160 Train loss 0.59 on epoch=11
05/28/2022 00:23:34 - INFO - __main__ - Step 170 Global step 170 Train loss 0.70 on epoch=12
05/28/2022 00:23:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.63 on epoch=12
05/28/2022 00:23:39 - INFO - __main__ - Step 190 Global step 190 Train loss 0.59 on epoch=13
05/28/2022 00:23:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.57 on epoch=14
05/28/2022 00:23:49 - INFO - __main__ - Global step 200 Train loss 0.62 Classification-F1 0.4599227440314143 on epoch=14
05/28/2022 00:23:51 - INFO - __main__ - Step 210 Global step 210 Train loss 0.55 on epoch=14
05/28/2022 00:23:54 - INFO - __main__ - Step 220 Global step 220 Train loss 0.57 on epoch=15
05/28/2022 00:23:56 - INFO - __main__ - Step 230 Global step 230 Train loss 0.46 on epoch=16
05/28/2022 00:23:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.47 on epoch=17
05/28/2022 00:24:01 - INFO - __main__ - Step 250 Global step 250 Train loss 0.51 on epoch=17
05/28/2022 00:24:09 - INFO - __main__ - Global step 250 Train loss 0.51 Classification-F1 0.5495504992057836 on epoch=17
05/28/2022 00:24:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.48 on epoch=18
05/28/2022 00:24:14 - INFO - __main__ - Step 270 Global step 270 Train loss 0.43 on epoch=19
05/28/2022 00:24:16 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=19
05/28/2022 00:24:19 - INFO - __main__ - Step 290 Global step 290 Train loss 0.43 on epoch=20
05/28/2022 00:24:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.39 on epoch=21
05/28/2022 00:24:28 - INFO - __main__ - Global step 300 Train loss 0.43 Classification-F1 0.6066442943640519 on epoch=21
05/28/2022 00:24:28 - INFO - __main__ - Saving model with best Classification-F1: 0.553228773398917 -> 0.6066442943640519 on epoch=21, global_step=300
05/28/2022 00:24:31 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=22
05/28/2022 00:24:33 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=22
05/28/2022 00:24:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.38 on epoch=23
05/28/2022 00:24:38 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=24
05/28/2022 00:24:41 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=24
05/28/2022 00:24:47 - INFO - __main__ - Global step 350 Train loss 0.38 Classification-F1 0.6883452418672488 on epoch=24
05/28/2022 00:24:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6066442943640519 -> 0.6883452418672488 on epoch=24, global_step=350
05/28/2022 00:24:50 - INFO - __main__ - Step 360 Global step 360 Train loss 0.37 on epoch=25
05/28/2022 00:24:52 - INFO - __main__ - Step 370 Global step 370 Train loss 0.37 on epoch=26
05/28/2022 00:24:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.38 on epoch=27
05/28/2022 00:24:58 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=27
05/28/2022 00:25:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=28
05/28/2022 00:25:07 - INFO - __main__ - Global step 400 Train loss 0.35 Classification-F1 0.7146515986648814 on epoch=28
05/28/2022 00:25:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6883452418672488 -> 0.7146515986648814 on epoch=28, global_step=400
05/28/2022 00:25:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.31 on epoch=29
05/28/2022 00:25:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=29
05/28/2022 00:25:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=30
05/28/2022 00:25:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=31
05/28/2022 00:25:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.32 on epoch=32
05/28/2022 00:25:26 - INFO - __main__ - Global step 450 Train loss 0.30 Classification-F1 0.7471824649708414 on epoch=32
05/28/2022 00:25:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7146515986648814 -> 0.7471824649708414 on epoch=32, global_step=450
05/28/2022 00:25:29 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=32
05/28/2022 00:25:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=33
05/28/2022 00:25:34 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=34
05/28/2022 00:25:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=34
05/28/2022 00:25:39 - INFO - __main__ - Step 500 Global step 500 Train loss 0.29 on epoch=35
05/28/2022 00:25:46 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.8472451651197052 on epoch=35
05/28/2022 00:25:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7471824649708414 -> 0.8472451651197052 on epoch=35, global_step=500
05/28/2022 00:25:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.15 on epoch=36
05/28/2022 00:25:51 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=37
05/28/2022 00:25:53 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=37
05/28/2022 00:25:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=38
05/28/2022 00:25:58 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=39
05/28/2022 00:26:05 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.7926643775053286 on epoch=39
05/28/2022 00:26:08 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=39
05/28/2022 00:26:10 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=40
05/28/2022 00:26:13 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=41
05/28/2022 00:26:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=42
05/28/2022 00:26:18 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=42
05/28/2022 00:26:25 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.8860415506009041 on epoch=42
05/28/2022 00:26:25 - INFO - __main__ - Saving model with best Classification-F1: 0.8472451651197052 -> 0.8860415506009041 on epoch=42, global_step=600
05/28/2022 00:26:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=43
05/28/2022 00:26:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=44
05/28/2022 00:26:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=44
05/28/2022 00:26:35 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=45
05/28/2022 00:26:38 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=46
05/28/2022 00:26:45 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.8083117935885717 on epoch=46
05/28/2022 00:26:47 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=47
05/28/2022 00:26:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=47
05/28/2022 00:26:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=48
05/28/2022 00:26:55 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=49
05/28/2022 00:26:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=49
05/28/2022 00:27:04 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.878821599093663 on epoch=49
05/28/2022 00:27:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=50
05/28/2022 00:27:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=51
05/28/2022 00:27:12 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=52
05/28/2022 00:27:15 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=52
05/28/2022 00:27:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=53
05/28/2022 00:27:24 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.831965702832371 on epoch=53
05/28/2022 00:27:27 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=54
05/28/2022 00:27:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=54
05/28/2022 00:27:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=55
05/28/2022 00:27:34 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=56
05/28/2022 00:27:37 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=57
05/28/2022 00:27:44 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.8001673390519453 on epoch=57
05/28/2022 00:27:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=57
05/28/2022 00:27:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=58
05/28/2022 00:27:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=59
05/28/2022 00:27:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=59
05/28/2022 00:27:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=60
05/28/2022 00:28:04 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.7829059821046869 on epoch=60
05/28/2022 00:28:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=61
05/28/2022 00:28:09 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=62
05/28/2022 00:28:11 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=62
05/28/2022 00:28:14 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=63
05/28/2022 00:28:16 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=64
05/28/2022 00:28:23 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.7931886042756486 on epoch=64
05/28/2022 00:28:25 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=64
05/28/2022 00:28:28 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=65
05/28/2022 00:28:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=66
05/28/2022 00:28:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=67
05/28/2022 00:28:35 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=67
05/28/2022 00:28:42 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.7294368415336157 on epoch=67
05/28/2022 00:28:45 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=68
05/28/2022 00:28:47 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=69
05/28/2022 00:28:50 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
05/28/2022 00:28:52 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=70
05/28/2022 00:28:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
05/28/2022 00:29:02 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.8980356378458846 on epoch=71
05/28/2022 00:29:02 - INFO - __main__ - Saving model with best Classification-F1: 0.8860415506009041 -> 0.8980356378458846 on epoch=71, global_step=1000
05/28/2022 00:29:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
05/28/2022 00:29:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=72
05/28/2022 00:29:09 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=73
05/28/2022 00:29:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=74
05/28/2022 00:29:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
05/28/2022 00:29:21 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.855058651026393 on epoch=74
05/28/2022 00:29:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=75
05/28/2022 00:29:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=76
05/28/2022 00:29:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=77
05/28/2022 00:29:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=77
05/28/2022 00:29:33 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=78
05/28/2022 00:29:40 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.8589687194525905 on epoch=78
05/28/2022 00:29:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
05/28/2022 00:29:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
05/28/2022 00:29:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
05/28/2022 00:29:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
05/28/2022 00:29:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
05/28/2022 00:29:59 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7889585467231333 on epoch=82
05/28/2022 00:30:02 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
05/28/2022 00:30:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=83
05/28/2022 00:30:07 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=84
05/28/2022 00:30:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
05/28/2022 00:30:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=85
05/28/2022 00:30:18 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.669518529622514 on epoch=85
05/28/2022 00:30:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
05/28/2022 00:30:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
05/28/2022 00:30:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
05/28/2022 00:30:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=88
05/28/2022 00:30:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=89
05/28/2022 00:30:37 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.7886253538848694 on epoch=89
05/28/2022 00:30:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
05/28/2022 00:30:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
05/28/2022 00:30:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
05/28/2022 00:30:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
05/28/2022 00:30:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
05/28/2022 00:30:57 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.8346942325520954 on epoch=92
05/28/2022 00:30:59 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
05/28/2022 00:31:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=94
05/28/2022 00:31:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
05/28/2022 00:31:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
05/28/2022 00:31:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
05/28/2022 00:31:16 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.8124534580714579 on epoch=96
05/28/2022 00:31:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=97
05/28/2022 00:31:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
05/28/2022 00:31:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
05/28/2022 00:31:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
05/28/2022 00:31:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
05/28/2022 00:31:35 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7834791575764342 on epoch=99
05/28/2022 00:31:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
05/28/2022 00:31:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
05/28/2022 00:31:43 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
05/28/2022 00:31:45 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=102
05/28/2022 00:31:48 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
05/28/2022 00:31:54 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7753453428208827 on epoch=103
05/28/2022 00:31:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
05/28/2022 00:31:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
05/28/2022 00:32:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
05/28/2022 00:32:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
05/28/2022 00:32:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
05/28/2022 00:32:13 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.800821043216137 on epoch=107
05/28/2022 00:32:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
05/28/2022 00:32:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
05/28/2022 00:32:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=109
05/28/2022 00:32:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
05/28/2022 00:32:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
05/28/2022 00:32:33 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.9773678606339897 on epoch=110
05/28/2022 00:32:33 - INFO - __main__ - Saving model with best Classification-F1: 0.8980356378458846 -> 0.9773678606339897 on epoch=110, global_step=1550
05/28/2022 00:32:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
05/28/2022 00:32:38 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
05/28/2022 00:32:41 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
05/28/2022 00:32:43 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
05/28/2022 00:32:46 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
05/28/2022 00:32:52 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9771537455107434 on epoch=114
05/28/2022 00:32:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
05/28/2022 00:32:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
05/28/2022 00:33:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
05/28/2022 00:33:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
05/28/2022 00:33:05 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
05/28/2022 00:33:11 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.9773538961038961 on epoch=117
05/28/2022 00:33:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
05/28/2022 00:33:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
05/28/2022 00:33:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
05/28/2022 00:33:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
05/28/2022 00:33:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
05/28/2022 00:33:30 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.9033990513655827 on epoch=121
05/28/2022 00:33:33 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
05/28/2022 00:33:35 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
05/28/2022 00:33:38 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
05/28/2022 00:33:40 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
05/28/2022 00:33:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
05/28/2022 00:33:50 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.9643277325592994 on epoch=124
05/28/2022 00:33:52 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
05/28/2022 00:33:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
05/28/2022 00:33:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
05/28/2022 00:34:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
05/28/2022 00:34:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
05/28/2022 00:34:08 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.968225174082172 on epoch=128
05/28/2022 00:34:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
05/28/2022 00:34:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
05/28/2022 00:34:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
05/28/2022 00:34:19 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
05/28/2022 00:34:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
05/28/2022 00:34:28 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9773538961038961 on epoch=132
05/28/2022 00:34:31 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
05/28/2022 00:34:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
05/28/2022 00:34:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=134
05/28/2022 00:34:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
05/28/2022 00:34:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
05/28/2022 00:34:47 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.9818181818181818 on epoch=135
05/28/2022 00:34:47 - INFO - __main__ - Saving model with best Classification-F1: 0.9773678606339897 -> 0.9818181818181818 on epoch=135, global_step=1900
05/28/2022 00:34:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
05/28/2022 00:34:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
05/28/2022 00:34:55 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
05/28/2022 00:34:58 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
05/28/2022 00:35:00 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
05/28/2022 00:35:07 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9730221707451309 on epoch=139
05/28/2022 00:35:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
05/28/2022 00:35:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
05/28/2022 00:35:14 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
05/28/2022 00:35:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
05/28/2022 00:35:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
05/28/2022 00:35:25 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9773538961038961 on epoch=142
05/28/2022 00:35:28 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
05/28/2022 00:35:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
05/28/2022 00:35:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
05/28/2022 00:35:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
05/28/2022 00:35:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/28/2022 00:35:44 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9818181818181818 on epoch=146
05/28/2022 00:35:46 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=147
05/28/2022 00:35:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
05/28/2022 00:35:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
05/28/2022 00:35:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
05/28/2022 00:35:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
05/28/2022 00:36:03 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9142130987292278 on epoch=149
05/28/2022 00:36:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/28/2022 00:36:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/28/2022 00:36:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
05/28/2022 00:36:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
05/28/2022 00:36:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
05/28/2022 00:36:22 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.968076800949928 on epoch=153
05/28/2022 00:36:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
05/28/2022 00:36:27 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/28/2022 00:36:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/28/2022 00:36:32 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
05/28/2022 00:36:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/28/2022 00:36:40 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.972903574919704 on epoch=157
05/28/2022 00:36:43 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
05/28/2022 00:36:45 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
05/28/2022 00:36:48 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
05/28/2022 00:36:51 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
05/28/2022 00:36:53 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
05/28/2022 00:36:59 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9098596248422853 on epoch=160
05/28/2022 00:37:02 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
05/28/2022 00:37:04 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
05/28/2022 00:37:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
05/28/2022 00:37:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
05/28/2022 00:37:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
05/28/2022 00:37:18 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8952911698943237 on epoch=164
05/28/2022 00:37:20 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
05/28/2022 00:37:23 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=165
05/28/2022 00:37:25 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
05/28/2022 00:37:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
05/28/2022 00:37:30 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/28/2022 00:37:36 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9684478584638426 on epoch=167
05/28/2022 00:37:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
05/28/2022 00:37:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/28/2022 00:37:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
05/28/2022 00:37:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
05/28/2022 00:37:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/28/2022 00:37:55 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.900007693421672 on epoch=171
05/28/2022 00:37:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
05/28/2022 00:38:00 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
05/28/2022 00:38:03 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
05/28/2022 00:38:05 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
05/28/2022 00:38:08 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/28/2022 00:38:14 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8475168350168351 on epoch=174
05/28/2022 00:38:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/28/2022 00:38:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=176
05/28/2022 00:38:21 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/28/2022 00:38:24 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
05/28/2022 00:38:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/28/2022 00:38:32 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8899747474747474 on epoch=178
05/28/2022 00:38:35 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
05/28/2022 00:38:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
05/28/2022 00:38:40 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
05/28/2022 00:38:43 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/28/2022 00:38:45 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=182
05/28/2022 00:38:51 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8736924750349798 on epoch=182
05/28/2022 00:38:54 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/28/2022 00:38:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/28/2022 00:38:59 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
05/28/2022 00:39:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
05/28/2022 00:39:04 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
05/28/2022 00:39:10 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9026861937345809 on epoch=185
05/28/2022 00:39:13 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/28/2022 00:39:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
05/28/2022 00:39:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
05/28/2022 00:39:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
05/28/2022 00:39:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=189
05/28/2022 00:39:29 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.81468871149557 on epoch=189
05/28/2022 00:39:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/28/2022 00:39:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.08 on epoch=190
05/28/2022 00:39:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/28/2022 00:39:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
05/28/2022 00:39:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
05/28/2022 00:39:47 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9773538961038961 on epoch=192
05/28/2022 00:39:50 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/28/2022 00:39:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/28/2022 00:39:55 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/28/2022 00:39:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
05/28/2022 00:40:00 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
05/28/2022 00:40:06 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9774812197606314 on epoch=196
05/28/2022 00:40:09 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/28/2022 00:40:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/28/2022 00:40:14 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
05/28/2022 00:40:16 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/28/2022 00:40:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
05/28/2022 00:40:25 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9101652674755142 on epoch=199
05/28/2022 00:40:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
05/28/2022 00:40:30 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
05/28/2022 00:40:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/28/2022 00:40:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
05/28/2022 00:40:38 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
05/28/2022 00:40:44 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7638869120661653 on epoch=203
05/28/2022 00:40:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
05/28/2022 00:40:49 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/28/2022 00:40:52 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
05/28/2022 00:40:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/28/2022 00:40:57 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/28/2022 00:41:03 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8819448029995698 on epoch=207
05/28/2022 00:41:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/28/2022 00:41:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/28/2022 00:41:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
05/28/2022 00:41:13 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
05/28/2022 00:41:16 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/28/2022 00:41:22 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8762162994769486 on epoch=210
05/28/2022 00:41:24 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/28/2022 00:41:27 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/28/2022 00:41:29 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/28/2022 00:41:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
05/28/2022 00:41:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/28/2022 00:41:36 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 00:41:36 - INFO - __main__ - Printing 3 examples
05/28/2022 00:41:36 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 00:41:36 - INFO - __main__ - ['Animal']
05/28/2022 00:41:36 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 00:41:36 - INFO - __main__ - ['Animal']
05/28/2022 00:41:36 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/28/2022 00:41:36 - INFO - __main__ - ['Animal']
05/28/2022 00:41:36 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:41:36 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:41:36 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 00:41:36 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 00:41:36 - INFO - __main__ - Printing 3 examples
05/28/2022 00:41:36 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/28/2022 00:41:36 - INFO - __main__ - ['Animal']
05/28/2022 00:41:36 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/28/2022 00:41:36 - INFO - __main__ - ['Animal']
05/28/2022 00:41:36 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/28/2022 00:41:36 - INFO - __main__ - ['Animal']
05/28/2022 00:41:36 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:41:36 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:41:37 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 00:41:41 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8770895275560591 on epoch=214
05/28/2022 00:41:41 - INFO - __main__ - save last model!
05/28/2022 00:41:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 00:41:41 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 00:41:41 - INFO - __main__ - Printing 3 examples
05/28/2022 00:41:41 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 00:41:41 - INFO - __main__ - ['Animal']
05/28/2022 00:41:41 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 00:41:41 - INFO - __main__ - ['Animal']
05/28/2022 00:41:41 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 00:41:41 - INFO - __main__ - ['Village']
05/28/2022 00:41:41 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:41:43 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:41:46 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 00:41:52 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 00:41:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 00:41:53 - INFO - __main__ - Starting training!
05/28/2022 00:43:55 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
05/28/2022 00:43:55 - INFO - __main__ - Classification-F1 on test data: 0.6891
05/28/2022 00:43:56 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.9818181818181818, test_performance=0.6891170724078283
05/28/2022 00:43:56 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
05/28/2022 00:43:57 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 00:43:57 - INFO - __main__ - Printing 3 examples
05/28/2022 00:43:57 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 00:43:57 - INFO - __main__ - ['Animal']
05/28/2022 00:43:57 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 00:43:57 - INFO - __main__ - ['Animal']
05/28/2022 00:43:57 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/28/2022 00:43:57 - INFO - __main__ - ['Animal']
05/28/2022 00:43:57 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:43:57 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:43:57 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 00:43:57 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 00:43:57 - INFO - __main__ - Printing 3 examples
05/28/2022 00:43:57 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/28/2022 00:43:57 - INFO - __main__ - ['Animal']
05/28/2022 00:43:57 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/28/2022 00:43:57 - INFO - __main__ - ['Animal']
05/28/2022 00:43:57 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/28/2022 00:43:57 - INFO - __main__ - ['Animal']
05/28/2022 00:43:57 - INFO - __main__ - Tokenizing Input ...
05/28/2022 00:43:57 - INFO - __main__ - Tokenizing Output ...
05/28/2022 00:43:57 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 00:44:16 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 00:44:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 00:44:17 - INFO - __main__ - Starting training!
05/28/2022 00:44:20 - INFO - __main__ - Step 10 Global step 10 Train loss 6.81 on epoch=0
05/28/2022 00:44:23 - INFO - __main__ - Step 20 Global step 20 Train loss 4.85 on epoch=1
05/28/2022 00:44:25 - INFO - __main__ - Step 30 Global step 30 Train loss 3.69 on epoch=2
05/28/2022 00:44:28 - INFO - __main__ - Step 40 Global step 40 Train loss 3.18 on epoch=2
05/28/2022 00:44:31 - INFO - __main__ - Step 50 Global step 50 Train loss 2.95 on epoch=3
05/28/2022 00:44:37 - INFO - __main__ - Global step 50 Train loss 4.30 Classification-F1 0.017692536425810285 on epoch=3
05/28/2022 00:44:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.017692536425810285 on epoch=3, global_step=50
05/28/2022 00:44:40 - INFO - __main__ - Step 60 Global step 60 Train loss 2.41 on epoch=4
05/28/2022 00:44:43 - INFO - __main__ - Step 70 Global step 70 Train loss 2.04 on epoch=4
05/28/2022 00:44:45 - INFO - __main__ - Step 80 Global step 80 Train loss 1.65 on epoch=5
05/28/2022 00:44:48 - INFO - __main__ - Step 90 Global step 90 Train loss 1.62 on epoch=6
05/28/2022 00:44:50 - INFO - __main__ - Step 100 Global step 100 Train loss 1.46 on epoch=7
05/28/2022 00:44:57 - INFO - __main__ - Global step 100 Train loss 1.83 Classification-F1 0.3487906544328804 on epoch=7
05/28/2022 00:44:57 - INFO - __main__ - Saving model with best Classification-F1: 0.017692536425810285 -> 0.3487906544328804 on epoch=7, global_step=100
05/28/2022 00:45:00 - INFO - __main__ - Step 110 Global step 110 Train loss 1.15 on epoch=7
05/28/2022 00:45:02 - INFO - __main__ - Step 120 Global step 120 Train loss 1.11 on epoch=8
05/28/2022 00:45:05 - INFO - __main__ - Step 130 Global step 130 Train loss 1.05 on epoch=9
05/28/2022 00:45:08 - INFO - __main__ - Step 140 Global step 140 Train loss 1.01 on epoch=9
05/28/2022 00:45:10 - INFO - __main__ - Step 150 Global step 150 Train loss 0.86 on epoch=10
05/28/2022 00:45:18 - INFO - __main__ - Global step 150 Train loss 1.04 Classification-F1 0.43597861717429165 on epoch=10
05/28/2022 00:45:18 - INFO - __main__ - Saving model with best Classification-F1: 0.3487906544328804 -> 0.43597861717429165 on epoch=10, global_step=150
05/28/2022 00:45:21 - INFO - __main__ - Step 160 Global step 160 Train loss 0.71 on epoch=11
05/28/2022 00:45:23 - INFO - __main__ - Step 170 Global step 170 Train loss 0.90 on epoch=12
05/28/2022 00:45:26 - INFO - __main__ - Step 180 Global step 180 Train loss 0.75 on epoch=12
05/28/2022 00:45:29 - INFO - __main__ - Step 190 Global step 190 Train loss 0.70 on epoch=13
05/28/2022 00:45:31 - INFO - __main__ - Step 200 Global step 200 Train loss 0.73 on epoch=14
05/28/2022 00:45:39 - INFO - __main__ - Global step 200 Train loss 0.76 Classification-F1 0.4608771463180799 on epoch=14
05/28/2022 00:45:39 - INFO - __main__ - Saving model with best Classification-F1: 0.43597861717429165 -> 0.4608771463180799 on epoch=14, global_step=200
05/28/2022 00:45:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.58 on epoch=14
05/28/2022 00:45:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.58 on epoch=15
05/28/2022 00:45:46 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=16
05/28/2022 00:45:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.64 on epoch=17
05/28/2022 00:45:51 - INFO - __main__ - Step 250 Global step 250 Train loss 0.56 on epoch=17
05/28/2022 00:45:59 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.6171873841233906 on epoch=17
05/28/2022 00:45:59 - INFO - __main__ - Saving model with best Classification-F1: 0.4608771463180799 -> 0.6171873841233906 on epoch=17, global_step=250
05/28/2022 00:46:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.64 on epoch=18
05/28/2022 00:46:04 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=19
05/28/2022 00:46:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.48 on epoch=19
05/28/2022 00:46:09 - INFO - __main__ - Step 290 Global step 290 Train loss 0.56 on epoch=20
05/28/2022 00:46:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.49 on epoch=21
05/28/2022 00:46:19 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.6007393959227102 on epoch=21
05/28/2022 00:46:22 - INFO - __main__ - Step 310 Global step 310 Train loss 0.42 on epoch=22
05/28/2022 00:46:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=22
05/28/2022 00:46:27 - INFO - __main__ - Step 330 Global step 330 Train loss 0.44 on epoch=23
05/28/2022 00:46:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.44 on epoch=24
05/28/2022 00:46:32 - INFO - __main__ - Step 350 Global step 350 Train loss 0.37 on epoch=24
05/28/2022 00:46:39 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.7081893790153899 on epoch=24
05/28/2022 00:46:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6171873841233906 -> 0.7081893790153899 on epoch=24, global_step=350
05/28/2022 00:46:42 - INFO - __main__ - Step 360 Global step 360 Train loss 0.39 on epoch=25
05/28/2022 00:46:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=26
05/28/2022 00:46:47 - INFO - __main__ - Step 380 Global step 380 Train loss 0.53 on epoch=27
05/28/2022 00:46:50 - INFO - __main__ - Step 390 Global step 390 Train loss 0.35 on epoch=27
05/28/2022 00:46:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.31 on epoch=28
05/28/2022 00:47:00 - INFO - __main__ - Global step 400 Train loss 0.40 Classification-F1 0.7506612717402483 on epoch=28
05/28/2022 00:47:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7081893790153899 -> 0.7506612717402483 on epoch=28, global_step=400
05/28/2022 00:47:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.31 on epoch=29
05/28/2022 00:47:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=29
05/28/2022 00:47:08 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=30
05/28/2022 00:47:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=31
05/28/2022 00:47:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.40 on epoch=32
05/28/2022 00:47:21 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.7412973867971131 on epoch=32
05/28/2022 00:47:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=32
05/28/2022 00:47:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=33
05/28/2022 00:47:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=34
05/28/2022 00:47:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
05/28/2022 00:47:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=35
05/28/2022 00:47:41 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.7489199064955073 on epoch=35
05/28/2022 00:47:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.34 on epoch=36
05/28/2022 00:47:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=37
05/28/2022 00:47:49 - INFO - __main__ - Step 530 Global step 530 Train loss 0.28 on epoch=37
05/28/2022 00:47:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=38
05/28/2022 00:47:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=39
05/28/2022 00:48:01 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.7540215605347139 on epoch=39
05/28/2022 00:48:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7506612717402483 -> 0.7540215605347139 on epoch=39, global_step=550
05/28/2022 00:48:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=39
05/28/2022 00:48:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.29 on epoch=40
05/28/2022 00:48:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.22 on epoch=41
05/28/2022 00:48:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=42
05/28/2022 00:48:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.27 on epoch=42
05/28/2022 00:48:22 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.9264345645394033 on epoch=42
05/28/2022 00:48:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7540215605347139 -> 0.9264345645394033 on epoch=42, global_step=600
05/28/2022 00:48:24 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=43
05/28/2022 00:48:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=44
05/28/2022 00:48:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=44
05/28/2022 00:48:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=45
05/28/2022 00:48:35 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=46
05/28/2022 00:48:42 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.7005460126283372 on epoch=46
05/28/2022 00:48:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=47
05/28/2022 00:48:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=47
05/28/2022 00:48:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=48
05/28/2022 00:48:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.25 on epoch=49
05/28/2022 00:48:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=49
05/28/2022 00:49:02 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.7405512630661764 on epoch=49
05/28/2022 00:49:04 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=50
05/28/2022 00:49:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=51
05/28/2022 00:49:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=52
05/28/2022 00:49:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=52
05/28/2022 00:49:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=53
05/28/2022 00:49:22 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.8566408592705929 on epoch=53
05/28/2022 00:49:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=54
05/28/2022 00:49:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=54
05/28/2022 00:49:29 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=55
05/28/2022 00:49:32 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=56
05/28/2022 00:49:34 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=57
05/28/2022 00:49:42 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.8787270466888342 on epoch=57
05/28/2022 00:49:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=57
05/28/2022 00:49:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=58
05/28/2022 00:49:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=59
05/28/2022 00:49:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=59
05/28/2022 00:49:55 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=60
05/28/2022 00:50:02 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.8771461409475871 on epoch=60
05/28/2022 00:50:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=61
05/28/2022 00:50:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=62
05/28/2022 00:50:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=62
05/28/2022 00:50:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.20 on epoch=63
05/28/2022 00:50:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=64
05/28/2022 00:50:22 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.775936567379578 on epoch=64
05/28/2022 00:50:24 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=64
05/28/2022 00:50:27 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=65
05/28/2022 00:50:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=66
05/28/2022 00:50:32 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=67
05/28/2022 00:50:35 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=67
05/28/2022 00:50:42 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.7263194324650681 on epoch=67
05/28/2022 00:50:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=68
05/28/2022 00:50:47 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=69
05/28/2022 00:50:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=69
05/28/2022 00:50:52 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=70
05/28/2022 00:50:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=71
05/28/2022 00:51:01 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.7689025087350793 on epoch=71
05/28/2022 00:51:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=72
05/28/2022 00:51:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
05/28/2022 00:51:09 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=73
05/28/2022 00:51:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
05/28/2022 00:51:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=74
05/28/2022 00:51:21 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.8080858094704158 on epoch=74
05/28/2022 00:51:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=75
05/28/2022 00:51:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=76
05/28/2022 00:51:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
05/28/2022 00:51:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
05/28/2022 00:51:33 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
05/28/2022 00:51:40 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.812812508038792 on epoch=78
05/28/2022 00:51:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=79
05/28/2022 00:51:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=79
05/28/2022 00:51:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=80
05/28/2022 00:51:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=81
05/28/2022 00:51:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=82
05/28/2022 00:51:59 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.7709272516435703 on epoch=82
05/28/2022 00:52:02 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
05/28/2022 00:52:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=83
05/28/2022 00:52:07 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=84
05/28/2022 00:52:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
05/28/2022 00:52:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=85
05/28/2022 00:52:19 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.7925785068426198 on epoch=85
05/28/2022 00:52:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
05/28/2022 00:52:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
05/28/2022 00:52:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
05/28/2022 00:52:29 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
05/28/2022 00:52:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
05/28/2022 00:52:38 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.7857495652725647 on epoch=89
05/28/2022 00:52:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
05/28/2022 00:52:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
05/28/2022 00:52:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
05/28/2022 00:52:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=92
05/28/2022 00:52:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
05/28/2022 00:52:57 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7450496586421355 on epoch=92
05/28/2022 00:53:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
05/28/2022 00:53:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
05/28/2022 00:53:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
05/28/2022 00:53:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
05/28/2022 00:53:10 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=96
05/28/2022 00:53:16 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7942472489362313 on epoch=96
05/28/2022 00:53:19 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
05/28/2022 00:53:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.16 on epoch=97
05/28/2022 00:53:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
05/28/2022 00:53:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
05/28/2022 00:53:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
05/28/2022 00:53:36 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.8579538266919672 on epoch=99
05/28/2022 00:53:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
05/28/2022 00:53:41 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
05/28/2022 00:53:43 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
05/28/2022 00:53:46 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
05/28/2022 00:53:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
05/28/2022 00:53:55 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.8009053862869684 on epoch=103
05/28/2022 00:53:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
05/28/2022 00:54:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=104
05/28/2022 00:54:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
05/28/2022 00:54:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
05/28/2022 00:54:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=107
05/28/2022 00:54:13 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.7486757151828589 on epoch=107
05/28/2022 00:54:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=107
05/28/2022 00:54:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
05/28/2022 00:54:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
05/28/2022 00:54:24 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=109
05/28/2022 00:54:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
05/28/2022 00:54:32 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.8607547645972694 on epoch=110
05/28/2022 00:54:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=111
05/28/2022 00:54:38 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
05/28/2022 00:54:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
05/28/2022 00:54:43 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
05/28/2022 00:54:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
05/28/2022 00:54:51 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7867715754039826 on epoch=114
05/28/2022 00:54:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=114
05/28/2022 00:54:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
05/28/2022 00:54:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
05/28/2022 00:55:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
05/28/2022 00:55:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
05/28/2022 00:55:11 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.8010115385352577 on epoch=117
05/28/2022 00:55:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
05/28/2022 00:55:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=119
05/28/2022 00:55:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
05/28/2022 00:55:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
05/28/2022 00:55:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
05/28/2022 00:55:30 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.815743033517634 on epoch=121
05/28/2022 00:55:32 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
05/28/2022 00:55:35 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
05/28/2022 00:55:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
05/28/2022 00:55:40 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
05/28/2022 00:55:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
05/28/2022 00:55:49 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7554378335199298 on epoch=124
05/28/2022 00:55:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
05/28/2022 00:55:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
05/28/2022 00:55:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
05/28/2022 00:55:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
05/28/2022 00:56:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
05/28/2022 00:56:08 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8973353991207162 on epoch=128
05/28/2022 00:56:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
05/28/2022 00:56:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
05/28/2022 00:56:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
05/28/2022 00:56:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
05/28/2022 00:56:20 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
05/28/2022 00:56:26 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.753739164277498 on epoch=132
05/28/2022 00:56:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
05/28/2022 00:56:31 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
05/28/2022 00:56:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
05/28/2022 00:56:37 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=134
05/28/2022 00:56:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
05/28/2022 00:56:45 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.860508288719614 on epoch=135
05/28/2022 00:56:48 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
05/28/2022 00:56:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
05/28/2022 00:56:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
05/28/2022 00:56:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
05/28/2022 00:56:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
05/28/2022 00:57:04 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.8724632472734939 on epoch=139
05/28/2022 00:57:07 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
05/28/2022 00:57:10 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
05/28/2022 00:57:12 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
05/28/2022 00:57:15 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
05/28/2022 00:57:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
05/28/2022 00:57:24 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9103216702125622 on epoch=142
05/28/2022 00:57:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
05/28/2022 00:57:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
05/28/2022 00:57:31 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
05/28/2022 00:57:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
05/28/2022 00:57:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
05/28/2022 00:57:43 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8931521324611686 on epoch=146
05/28/2022 00:57:45 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
05/28/2022 00:57:48 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
05/28/2022 00:57:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
05/28/2022 00:57:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=149
05/28/2022 00:57:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
05/28/2022 00:58:02 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.8227031620932831 on epoch=149
05/28/2022 00:58:04 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
05/28/2022 00:58:07 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
05/28/2022 00:58:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
05/28/2022 00:58:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
05/28/2022 00:58:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
05/28/2022 00:58:21 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8987646251071297 on epoch=153
05/28/2022 00:58:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
05/28/2022 00:58:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
05/28/2022 00:58:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
05/28/2022 00:58:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
05/28/2022 00:58:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
05/28/2022 00:58:40 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8864702528127576 on epoch=157
05/28/2022 00:58:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
05/28/2022 00:58:45 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
05/28/2022 00:58:48 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
05/28/2022 00:58:50 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
05/28/2022 00:58:53 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
05/28/2022 00:58:59 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7574198068252603 on epoch=160
05/28/2022 00:59:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.10 on epoch=161
05/28/2022 00:59:04 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
05/28/2022 00:59:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/28/2022 00:59:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
05/28/2022 00:59:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/28/2022 00:59:18 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.833852912549892 on epoch=164
05/28/2022 00:59:20 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
05/28/2022 00:59:23 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/28/2022 00:59:25 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
05/28/2022 00:59:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
05/28/2022 00:59:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
05/28/2022 00:59:37 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7332330887030944 on epoch=167
05/28/2022 00:59:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
05/28/2022 00:59:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/28/2022 00:59:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
05/28/2022 00:59:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
05/28/2022 00:59:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
05/28/2022 00:59:56 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8145996081717144 on epoch=171
05/28/2022 00:59:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=172
05/28/2022 01:00:01 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
05/28/2022 01:00:03 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/28/2022 01:00:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
05/28/2022 01:00:08 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/28/2022 01:00:14 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.803261265405478 on epoch=174
05/28/2022 01:00:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
05/28/2022 01:00:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
05/28/2022 01:00:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/28/2022 01:00:25 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/28/2022 01:00:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/28/2022 01:00:33 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8892956645563136 on epoch=178
05/28/2022 01:00:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=179
05/28/2022 01:00:38 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
05/28/2022 01:00:41 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
05/28/2022 01:00:44 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
05/28/2022 01:00:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
05/28/2022 01:00:52 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8863722177638109 on epoch=182
05/28/2022 01:00:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/28/2022 01:00:57 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/28/2022 01:01:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
05/28/2022 01:01:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
05/28/2022 01:01:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
05/28/2022 01:01:11 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9778051249825445 on epoch=185
05/28/2022 01:01:11 - INFO - __main__ - Saving model with best Classification-F1: 0.9264345645394033 -> 0.9778051249825445 on epoch=185, global_step=2600
05/28/2022 01:01:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/28/2022 01:01:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/28/2022 01:01:19 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
05/28/2022 01:01:22 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
05/28/2022 01:01:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
05/28/2022 01:01:30 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9774812197606314 on epoch=189
05/28/2022 01:01:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/28/2022 01:01:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
05/28/2022 01:01:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/28/2022 01:01:41 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
05/28/2022 01:01:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
05/28/2022 01:01:49 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8970253754584384 on epoch=192
05/28/2022 01:01:52 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/28/2022 01:01:54 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/28/2022 01:01:57 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/28/2022 01:02:00 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/28/2022 01:02:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
05/28/2022 01:02:08 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8148760622284105 on epoch=196
05/28/2022 01:02:11 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/28/2022 01:02:13 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
05/28/2022 01:02:16 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
05/28/2022 01:02:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/28/2022 01:02:21 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/28/2022 01:02:27 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7165907345342829 on epoch=199
05/28/2022 01:02:30 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
05/28/2022 01:02:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
05/28/2022 01:02:35 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/28/2022 01:02:37 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/28/2022 01:02:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/28/2022 01:02:46 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7815816243696031 on epoch=203
05/28/2022 01:02:48 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
05/28/2022 01:02:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
05/28/2022 01:02:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/28/2022 01:02:56 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
05/28/2022 01:02:59 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
05/28/2022 01:03:05 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9027919955861132 on epoch=207
05/28/2022 01:03:07 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
05/28/2022 01:03:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/28/2022 01:03:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
05/28/2022 01:03:15 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
05/28/2022 01:03:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/28/2022 01:03:24 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.822591497115747 on epoch=210
05/28/2022 01:03:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
05/28/2022 01:03:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/28/2022 01:03:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/28/2022 01:03:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/28/2022 01:03:36 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
05/28/2022 01:03:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 01:03:38 - INFO - __main__ - Printing 3 examples
05/28/2022 01:03:38 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 01:03:38 - INFO - __main__ - ['Animal']
05/28/2022 01:03:38 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 01:03:38 - INFO - __main__ - ['Animal']
05/28/2022 01:03:38 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/28/2022 01:03:38 - INFO - __main__ - ['Animal']
05/28/2022 01:03:38 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:03:38 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:03:38 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 01:03:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 01:03:38 - INFO - __main__ - Printing 3 examples
05/28/2022 01:03:38 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/28/2022 01:03:38 - INFO - __main__ - ['Animal']
05/28/2022 01:03:38 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/28/2022 01:03:38 - INFO - __main__ - ['Animal']
05/28/2022 01:03:38 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/28/2022 01:03:38 - INFO - __main__ - ['Animal']
05/28/2022 01:03:38 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:03:38 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:03:39 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 01:03:43 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8246532869012708 on epoch=214
05/28/2022 01:03:43 - INFO - __main__ - save last model!
05/28/2022 01:03:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 01:03:43 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 01:03:43 - INFO - __main__ - Printing 3 examples
05/28/2022 01:03:43 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 01:03:43 - INFO - __main__ - ['Animal']
05/28/2022 01:03:43 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 01:03:43 - INFO - __main__ - ['Animal']
05/28/2022 01:03:43 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 01:03:43 - INFO - __main__ - ['Village']
05/28/2022 01:03:43 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:03:44 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:03:48 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 01:03:57 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 01:03:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 01:03:58 - INFO - __main__ - Starting training!
05/28/2022 01:05:48 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
05/28/2022 01:05:49 - INFO - __main__ - Classification-F1 on test data: 0.5044
05/28/2022 01:05:49 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.9778051249825445, test_performance=0.5043526321423629
05/28/2022 01:05:49 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
05/28/2022 01:05:50 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 01:05:50 - INFO - __main__ - Printing 3 examples
05/28/2022 01:05:50 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/28/2022 01:05:50 - INFO - __main__ - ['Animal']
05/28/2022 01:05:50 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/28/2022 01:05:50 - INFO - __main__ - ['Animal']
05/28/2022 01:05:50 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/28/2022 01:05:50 - INFO - __main__ - ['Animal']
05/28/2022 01:05:50 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:05:50 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:05:50 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 01:05:50 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 01:05:50 - INFO - __main__ - Printing 3 examples
05/28/2022 01:05:50 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/28/2022 01:05:50 - INFO - __main__ - ['Animal']
05/28/2022 01:05:50 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/28/2022 01:05:50 - INFO - __main__ - ['Animal']
05/28/2022 01:05:50 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/28/2022 01:05:50 - INFO - __main__ - ['Animal']
05/28/2022 01:05:50 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:05:50 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:05:50 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 01:06:06 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 01:06:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 01:06:07 - INFO - __main__ - Starting training!
05/28/2022 01:06:10 - INFO - __main__ - Step 10 Global step 10 Train loss 7.58 on epoch=0
05/28/2022 01:06:12 - INFO - __main__ - Step 20 Global step 20 Train loss 5.82 on epoch=1
05/28/2022 01:06:15 - INFO - __main__ - Step 30 Global step 30 Train loss 4.76 on epoch=2
05/28/2022 01:06:18 - INFO - __main__ - Step 40 Global step 40 Train loss 4.02 on epoch=2
05/28/2022 01:06:20 - INFO - __main__ - Step 50 Global step 50 Train loss 3.59 on epoch=3
05/28/2022 01:06:36 - INFO - __main__ - Global step 50 Train loss 5.16 Classification-F1 0.009096816114359975 on epoch=3
05/28/2022 01:06:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009096816114359975 on epoch=3, global_step=50
05/28/2022 01:06:38 - INFO - __main__ - Step 60 Global step 60 Train loss 3.35 on epoch=4
05/28/2022 01:06:41 - INFO - __main__ - Step 70 Global step 70 Train loss 3.06 on epoch=4
05/28/2022 01:06:43 - INFO - __main__ - Step 80 Global step 80 Train loss 2.46 on epoch=5
05/28/2022 01:06:46 - INFO - __main__ - Step 90 Global step 90 Train loss 2.34 on epoch=6
05/28/2022 01:06:48 - INFO - __main__ - Step 100 Global step 100 Train loss 2.19 on epoch=7
05/28/2022 01:06:55 - INFO - __main__ - Global step 100 Train loss 2.68 Classification-F1 0.05535639925406912 on epoch=7
05/28/2022 01:06:55 - INFO - __main__ - Saving model with best Classification-F1: 0.009096816114359975 -> 0.05535639925406912 on epoch=7, global_step=100
05/28/2022 01:06:58 - INFO - __main__ - Step 110 Global step 110 Train loss 1.78 on epoch=7
05/28/2022 01:07:00 - INFO - __main__ - Step 120 Global step 120 Train loss 1.66 on epoch=8
05/28/2022 01:07:03 - INFO - __main__ - Step 130 Global step 130 Train loss 1.55 on epoch=9
05/28/2022 01:07:05 - INFO - __main__ - Step 140 Global step 140 Train loss 1.46 on epoch=9
05/28/2022 01:07:08 - INFO - __main__ - Step 150 Global step 150 Train loss 1.31 on epoch=10
05/28/2022 01:07:15 - INFO - __main__ - Global step 150 Train loss 1.55 Classification-F1 0.3803297018190189 on epoch=10
05/28/2022 01:07:15 - INFO - __main__ - Saving model with best Classification-F1: 0.05535639925406912 -> 0.3803297018190189 on epoch=10, global_step=150
05/28/2022 01:07:18 - INFO - __main__ - Step 160 Global step 160 Train loss 1.24 on epoch=11
05/28/2022 01:07:20 - INFO - __main__ - Step 170 Global step 170 Train loss 1.06 on epoch=12
05/28/2022 01:07:23 - INFO - __main__ - Step 180 Global step 180 Train loss 1.07 on epoch=12
05/28/2022 01:07:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.98 on epoch=13
05/28/2022 01:07:28 - INFO - __main__ - Step 200 Global step 200 Train loss 0.97 on epoch=14
05/28/2022 01:07:36 - INFO - __main__ - Global step 200 Train loss 1.06 Classification-F1 0.4089444977198507 on epoch=14
05/28/2022 01:07:36 - INFO - __main__ - Saving model with best Classification-F1: 0.3803297018190189 -> 0.4089444977198507 on epoch=14, global_step=200
05/28/2022 01:07:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.91 on epoch=14
05/28/2022 01:07:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.87 on epoch=15
05/28/2022 01:07:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.73 on epoch=16
05/28/2022 01:07:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.85 on epoch=17
05/28/2022 01:07:49 - INFO - __main__ - Step 250 Global step 250 Train loss 0.85 on epoch=17
05/28/2022 01:07:57 - INFO - __main__ - Global step 250 Train loss 0.84 Classification-F1 0.4136986078901476 on epoch=17
05/28/2022 01:07:57 - INFO - __main__ - Saving model with best Classification-F1: 0.4089444977198507 -> 0.4136986078901476 on epoch=17, global_step=250
05/28/2022 01:07:59 - INFO - __main__ - Step 260 Global step 260 Train loss 0.69 on epoch=18
05/28/2022 01:08:02 - INFO - __main__ - Step 270 Global step 270 Train loss 0.80 on epoch=19
05/28/2022 01:08:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.69 on epoch=19
05/28/2022 01:08:07 - INFO - __main__ - Step 290 Global step 290 Train loss 0.69 on epoch=20
05/28/2022 01:08:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.62 on epoch=21
05/28/2022 01:08:17 - INFO - __main__ - Global step 300 Train loss 0.70 Classification-F1 0.46299093741060465 on epoch=21
05/28/2022 01:08:17 - INFO - __main__ - Saving model with best Classification-F1: 0.4136986078901476 -> 0.46299093741060465 on epoch=21, global_step=300
05/28/2022 01:08:20 - INFO - __main__ - Step 310 Global step 310 Train loss 0.61 on epoch=22
05/28/2022 01:08:22 - INFO - __main__ - Step 320 Global step 320 Train loss 0.61 on epoch=22
05/28/2022 01:08:25 - INFO - __main__ - Step 330 Global step 330 Train loss 0.59 on epoch=23
05/28/2022 01:08:28 - INFO - __main__ - Step 340 Global step 340 Train loss 0.61 on epoch=24
05/28/2022 01:08:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.54 on epoch=24
05/28/2022 01:08:38 - INFO - __main__ - Global step 350 Train loss 0.59 Classification-F1 0.5218461269961036 on epoch=24
05/28/2022 01:08:38 - INFO - __main__ - Saving model with best Classification-F1: 0.46299093741060465 -> 0.5218461269961036 on epoch=24, global_step=350
05/28/2022 01:08:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.57 on epoch=25
05/28/2022 01:08:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.52 on epoch=26
05/28/2022 01:08:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.59 on epoch=27
05/28/2022 01:08:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=27
05/28/2022 01:08:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.53 on epoch=28
05/28/2022 01:08:58 - INFO - __main__ - Global step 400 Train loss 0.55 Classification-F1 0.6282424737969985 on epoch=28
05/28/2022 01:08:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5218461269961036 -> 0.6282424737969985 on epoch=28, global_step=400
05/28/2022 01:09:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.55 on epoch=29
05/28/2022 01:09:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.65 on epoch=29
05/28/2022 01:09:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.50 on epoch=30
05/28/2022 01:09:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.43 on epoch=31
05/28/2022 01:09:11 - INFO - __main__ - Step 450 Global step 450 Train loss 0.54 on epoch=32
05/28/2022 01:09:18 - INFO - __main__ - Global step 450 Train loss 0.53 Classification-F1 0.5395818638125204 on epoch=32
05/28/2022 01:09:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.47 on epoch=32
05/28/2022 01:09:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.41 on epoch=33
05/28/2022 01:09:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.43 on epoch=34
05/28/2022 01:09:29 - INFO - __main__ - Step 490 Global step 490 Train loss 0.49 on epoch=34
05/28/2022 01:09:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.43 on epoch=35
05/28/2022 01:09:39 - INFO - __main__ - Global step 500 Train loss 0.45 Classification-F1 0.4780121419986607 on epoch=35
05/28/2022 01:09:41 - INFO - __main__ - Step 510 Global step 510 Train loss 0.39 on epoch=36
05/28/2022 01:09:44 - INFO - __main__ - Step 520 Global step 520 Train loss 0.43 on epoch=37
05/28/2022 01:09:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.37 on epoch=37
05/28/2022 01:09:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.38 on epoch=38
05/28/2022 01:09:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=39
05/28/2022 01:09:59 - INFO - __main__ - Global step 550 Train loss 0.39 Classification-F1 0.684562010686081 on epoch=39
05/28/2022 01:09:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6282424737969985 -> 0.684562010686081 on epoch=39, global_step=550
05/28/2022 01:10:01 - INFO - __main__ - Step 560 Global step 560 Train loss 0.42 on epoch=39
05/28/2022 01:10:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.34 on epoch=40
05/28/2022 01:10:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.37 on epoch=41
05/28/2022 01:10:09 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=42
05/28/2022 01:10:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.28 on epoch=42
05/28/2022 01:10:19 - INFO - __main__ - Global step 600 Train loss 0.34 Classification-F1 0.6830654424161098 on epoch=42
05/28/2022 01:10:22 - INFO - __main__ - Step 610 Global step 610 Train loss 0.30 on epoch=43
05/28/2022 01:10:24 - INFO - __main__ - Step 620 Global step 620 Train loss 0.45 on epoch=44
05/28/2022 01:10:27 - INFO - __main__ - Step 630 Global step 630 Train loss 0.37 on epoch=44
05/28/2022 01:10:30 - INFO - __main__ - Step 640 Global step 640 Train loss 0.32 on epoch=45
05/28/2022 01:10:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.29 on epoch=46
05/28/2022 01:10:40 - INFO - __main__ - Global step 650 Train loss 0.35 Classification-F1 0.6950858726278086 on epoch=46
05/28/2022 01:10:40 - INFO - __main__ - Saving model with best Classification-F1: 0.684562010686081 -> 0.6950858726278086 on epoch=46, global_step=650
05/28/2022 01:10:42 - INFO - __main__ - Step 660 Global step 660 Train loss 0.31 on epoch=47
05/28/2022 01:10:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=47
05/28/2022 01:10:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.33 on epoch=48
05/28/2022 01:10:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.29 on epoch=49
05/28/2022 01:10:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.28 on epoch=49
05/28/2022 01:11:00 - INFO - __main__ - Global step 700 Train loss 0.30 Classification-F1 0.7751944124423964 on epoch=49
05/28/2022 01:11:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6950858726278086 -> 0.7751944124423964 on epoch=49, global_step=700
05/28/2022 01:11:03 - INFO - __main__ - Step 710 Global step 710 Train loss 0.37 on epoch=50
05/28/2022 01:11:05 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=51
05/28/2022 01:11:08 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=52
05/28/2022 01:11:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=52
05/28/2022 01:11:13 - INFO - __main__ - Step 750 Global step 750 Train loss 0.29 on epoch=53
05/28/2022 01:11:20 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.8503981881634685 on epoch=53
05/28/2022 01:11:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7751944124423964 -> 0.8503981881634685 on epoch=53, global_step=750
05/28/2022 01:11:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=54
05/28/2022 01:11:25 - INFO - __main__ - Step 770 Global step 770 Train loss 0.28 on epoch=54
05/28/2022 01:11:28 - INFO - __main__ - Step 780 Global step 780 Train loss 0.27 on epoch=55
05/28/2022 01:11:31 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=56
05/28/2022 01:11:33 - INFO - __main__ - Step 800 Global step 800 Train loss 0.28 on epoch=57
05/28/2022 01:11:41 - INFO - __main__ - Global step 800 Train loss 0.26 Classification-F1 0.855572915383162 on epoch=57
05/28/2022 01:11:41 - INFO - __main__ - Saving model with best Classification-F1: 0.8503981881634685 -> 0.855572915383162 on epoch=57, global_step=800
05/28/2022 01:11:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=57
05/28/2022 01:11:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=58
05/28/2022 01:11:48 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=59
05/28/2022 01:11:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=59
05/28/2022 01:11:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.30 on epoch=60
05/28/2022 01:12:01 - INFO - __main__ - Global step 850 Train loss 0.26 Classification-F1 0.8948345960033445 on epoch=60
05/28/2022 01:12:01 - INFO - __main__ - Saving model with best Classification-F1: 0.855572915383162 -> 0.8948345960033445 on epoch=60, global_step=850
05/28/2022 01:12:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=61
05/28/2022 01:12:06 - INFO - __main__ - Step 870 Global step 870 Train loss 0.25 on epoch=62
05/28/2022 01:12:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=62
05/28/2022 01:12:11 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=63
05/28/2022 01:12:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=64
05/28/2022 01:12:21 - INFO - __main__ - Global step 900 Train loss 0.22 Classification-F1 0.7463341634337884 on epoch=64
05/28/2022 01:12:24 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=64
05/28/2022 01:12:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=65
05/28/2022 01:12:29 - INFO - __main__ - Step 930 Global step 930 Train loss 0.26 on epoch=66
05/28/2022 01:12:31 - INFO - __main__ - Step 940 Global step 940 Train loss 0.22 on epoch=67
05/28/2022 01:12:34 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=67
05/28/2022 01:12:42 - INFO - __main__ - Global step 950 Train loss 0.22 Classification-F1 0.8598237753882915 on epoch=67
05/28/2022 01:12:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.22 on epoch=68
05/28/2022 01:12:47 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=69
05/28/2022 01:12:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=69
05/28/2022 01:12:52 - INFO - __main__ - Step 990 Global step 990 Train loss 0.21 on epoch=70
05/28/2022 01:12:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=71
05/28/2022 01:13:01 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.8417777609350134 on epoch=71
05/28/2022 01:13:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=72
05/28/2022 01:13:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.19 on epoch=72
05/28/2022 01:13:09 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=73
05/28/2022 01:13:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=74
05/28/2022 01:13:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.17 on epoch=74
05/28/2022 01:13:21 - INFO - __main__ - Global step 1050 Train loss 0.18 Classification-F1 0.8144041283263576 on epoch=74
05/28/2022 01:13:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.21 on epoch=75
05/28/2022 01:13:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=76
05/28/2022 01:13:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=77
05/28/2022 01:13:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=77
05/28/2022 01:13:34 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=78
05/28/2022 01:13:42 - INFO - __main__ - Global step 1100 Train loss 0.16 Classification-F1 0.8225658721878479 on epoch=78
05/28/2022 01:13:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.23 on epoch=79
05/28/2022 01:13:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.23 on epoch=79
05/28/2022 01:13:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=80
05/28/2022 01:13:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=81
05/28/2022 01:13:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=82
05/28/2022 01:14:02 - INFO - __main__ - Global step 1150 Train loss 0.18 Classification-F1 0.870418547999193 on epoch=82
05/28/2022 01:14:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=82
05/28/2022 01:14:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
05/28/2022 01:14:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=84
05/28/2022 01:14:12 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=84
05/28/2022 01:14:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.17 on epoch=85
05/28/2022 01:14:23 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.8244508618248538 on epoch=85
05/28/2022 01:14:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=86
05/28/2022 01:14:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.23 on epoch=87
05/28/2022 01:14:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=87
05/28/2022 01:14:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=88
05/28/2022 01:14:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=89
05/28/2022 01:14:43 - INFO - __main__ - Global step 1250 Train loss 0.16 Classification-F1 0.8158919536114204 on epoch=89
05/28/2022 01:14:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
05/28/2022 01:14:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=90
05/28/2022 01:14:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=91
05/28/2022 01:14:53 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=92
05/28/2022 01:14:56 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=92
05/28/2022 01:15:03 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.8739084597670934 on epoch=92
05/28/2022 01:15:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=93
05/28/2022 01:15:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=94
05/28/2022 01:15:11 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=94
05/28/2022 01:15:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=95
05/28/2022 01:15:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=96
05/28/2022 01:15:23 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.8307508963996155 on epoch=96
05/28/2022 01:15:26 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=97
05/28/2022 01:15:28 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.11 on epoch=97
05/28/2022 01:15:31 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=98
05/28/2022 01:15:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=99
05/28/2022 01:15:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
05/28/2022 01:15:43 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.8153592567892259 on epoch=99
05/28/2022 01:15:46 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=100
05/28/2022 01:15:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=101
05/28/2022 01:15:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=102
05/28/2022 01:15:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=102
05/28/2022 01:15:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
05/28/2022 01:16:03 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.8240105592424141 on epoch=103
05/28/2022 01:16:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=104
05/28/2022 01:16:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=104
05/28/2022 01:16:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.15 on epoch=105
05/28/2022 01:16:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=106
05/28/2022 01:16:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=107
05/28/2022 01:16:23 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.8265109568893287 on epoch=107
05/28/2022 01:16:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=107
05/28/2022 01:16:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=108
05/28/2022 01:16:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
05/28/2022 01:16:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=109
05/28/2022 01:16:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=110
05/28/2022 01:16:43 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.8908969540895536 on epoch=110
05/28/2022 01:16:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
05/28/2022 01:16:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=112
05/28/2022 01:16:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=112
05/28/2022 01:16:53 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=113
05/28/2022 01:16:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=114
05/28/2022 01:17:03 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.8055192579683774 on epoch=114
05/28/2022 01:17:05 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
05/28/2022 01:17:08 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
05/28/2022 01:17:10 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=116
05/28/2022 01:17:13 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.12 on epoch=117
05/28/2022 01:17:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.12 on epoch=117
05/28/2022 01:17:23 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.8953067430835212 on epoch=117
05/28/2022 01:17:23 - INFO - __main__ - Saving model with best Classification-F1: 0.8948345960033445 -> 0.8953067430835212 on epoch=117, global_step=1650
05/28/2022 01:17:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
05/28/2022 01:17:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=119
05/28/2022 01:17:30 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
05/28/2022 01:17:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=120
05/28/2022 01:17:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=121
05/28/2022 01:17:43 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.9104560788147126 on epoch=121
05/28/2022 01:17:43 - INFO - __main__ - Saving model with best Classification-F1: 0.8953067430835212 -> 0.9104560788147126 on epoch=121, global_step=1700
05/28/2022 01:17:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
05/28/2022 01:17:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
05/28/2022 01:17:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=123
05/28/2022 01:17:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
05/28/2022 01:17:56 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
05/28/2022 01:18:04 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.8838179723502305 on epoch=124
05/28/2022 01:18:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.14 on epoch=125
05/28/2022 01:18:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
05/28/2022 01:18:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
05/28/2022 01:18:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
05/28/2022 01:18:17 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=128
05/28/2022 01:18:24 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.8368675511316641 on epoch=128
05/28/2022 01:18:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
05/28/2022 01:18:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=129
05/28/2022 01:18:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
05/28/2022 01:18:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
05/28/2022 01:18:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
05/28/2022 01:18:43 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.8051849567312009 on epoch=132
05/28/2022 01:18:46 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=132
05/28/2022 01:18:48 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
05/28/2022 01:18:51 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=134
05/28/2022 01:18:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.13 on epoch=134
05/28/2022 01:18:56 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=135
05/28/2022 01:19:03 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.8263898172905526 on epoch=135
05/28/2022 01:19:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
05/28/2022 01:19:08 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=137
05/28/2022 01:19:10 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
05/28/2022 01:19:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=138
05/28/2022 01:19:15 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=139
05/28/2022 01:19:22 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.8337941749484088 on epoch=139
05/28/2022 01:19:25 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
05/28/2022 01:19:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
05/28/2022 01:19:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=141
05/28/2022 01:19:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
05/28/2022 01:19:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=142
05/28/2022 01:19:42 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.8188657257763556 on epoch=142
05/28/2022 01:19:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=143
05/28/2022 01:19:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=144
05/28/2022 01:19:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
05/28/2022 01:19:52 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
05/28/2022 01:19:55 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
05/28/2022 01:20:01 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.8210329636815561 on epoch=146
05/28/2022 01:20:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=147
05/28/2022 01:20:06 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
05/28/2022 01:20:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
05/28/2022 01:20:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.09 on epoch=149
05/28/2022 01:20:14 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
05/28/2022 01:20:20 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.8435588989994826 on epoch=149
05/28/2022 01:20:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
05/28/2022 01:20:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=151
05/28/2022 01:20:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=152
05/28/2022 01:20:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
05/28/2022 01:20:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
05/28/2022 01:20:40 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.8337439414304334 on epoch=153
05/28/2022 01:20:43 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.08 on epoch=154
05/28/2022 01:20:45 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=154
05/28/2022 01:20:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
05/28/2022 01:20:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
05/28/2022 01:20:53 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=157
05/28/2022 01:20:59 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.8334696204256132 on epoch=157
05/28/2022 01:21:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=157
05/28/2022 01:21:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
05/28/2022 01:21:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
05/28/2022 01:21:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
05/28/2022 01:21:12 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
05/28/2022 01:21:18 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8249775559473733 on epoch=160
05/28/2022 01:21:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
05/28/2022 01:21:23 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
05/28/2022 01:21:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
05/28/2022 01:21:29 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
05/28/2022 01:21:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=164
05/28/2022 01:21:38 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8931556988926289 on epoch=164
05/28/2022 01:21:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
05/28/2022 01:21:43 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
05/28/2022 01:21:46 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
05/28/2022 01:21:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
05/28/2022 01:21:51 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=167
05/28/2022 01:21:57 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7762805284934352 on epoch=167
05/28/2022 01:21:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
05/28/2022 01:22:02 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
05/28/2022 01:22:05 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
05/28/2022 01:22:07 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
05/28/2022 01:22:10 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=171
05/28/2022 01:22:16 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.8211415066951172 on epoch=171
05/28/2022 01:22:18 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
05/28/2022 01:22:21 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
05/28/2022 01:22:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
05/28/2022 01:22:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=174
05/28/2022 01:22:29 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/28/2022 01:22:35 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.831052761872852 on epoch=174
05/28/2022 01:22:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
05/28/2022 01:22:40 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=176
05/28/2022 01:22:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/28/2022 01:22:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=177
05/28/2022 01:22:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/28/2022 01:22:54 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7383864492735461 on epoch=178
05/28/2022 01:22:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
05/28/2022 01:22:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=179
05/28/2022 01:23:02 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/28/2022 01:23:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
05/28/2022 01:23:07 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=182
05/28/2022 01:23:13 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.766683935088612 on epoch=182
05/28/2022 01:23:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=182
05/28/2022 01:23:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
05/28/2022 01:23:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=184
05/28/2022 01:23:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=184
05/28/2022 01:23:26 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
05/28/2022 01:23:32 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.8847823976571606 on epoch=185
05/28/2022 01:23:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
05/28/2022 01:23:38 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/28/2022 01:23:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
05/28/2022 01:23:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=188
05/28/2022 01:23:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
05/28/2022 01:23:52 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.8270983414084747 on epoch=189
05/28/2022 01:23:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=189
05/28/2022 01:23:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=190
05/28/2022 01:24:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=191
05/28/2022 01:24:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=192
05/28/2022 01:24:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=192
05/28/2022 01:24:11 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.835152292822529 on epoch=192
05/28/2022 01:24:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
05/28/2022 01:24:16 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
05/28/2022 01:24:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
05/28/2022 01:24:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/28/2022 01:24:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
05/28/2022 01:24:30 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8897058837220129 on epoch=196
05/28/2022 01:24:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
05/28/2022 01:24:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
05/28/2022 01:24:38 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
05/28/2022 01:24:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
05/28/2022 01:24:43 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
05/28/2022 01:24:50 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9062608053974278 on epoch=199
05/28/2022 01:24:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
05/28/2022 01:24:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
05/28/2022 01:24:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
05/28/2022 01:25:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=202
05/28/2022 01:25:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=203
05/28/2022 01:25:09 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.8986212559315025 on epoch=203
05/28/2022 01:25:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
05/28/2022 01:25:14 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=204
05/28/2022 01:25:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
05/28/2022 01:25:19 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
05/28/2022 01:25:22 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/28/2022 01:25:28 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.902055346087604 on epoch=207
05/28/2022 01:25:30 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
05/28/2022 01:25:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/28/2022 01:25:36 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/28/2022 01:25:38 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/28/2022 01:25:41 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/28/2022 01:25:47 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9730308985764394 on epoch=210
05/28/2022 01:25:47 - INFO - __main__ - Saving model with best Classification-F1: 0.9104560788147126 -> 0.9730308985764394 on epoch=210, global_step=2950
05/28/2022 01:25:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
05/28/2022 01:25:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=212
05/28/2022 01:25:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=212
05/28/2022 01:25:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
05/28/2022 01:26:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
05/28/2022 01:26:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 01:26:01 - INFO - __main__ - Printing 3 examples
05/28/2022 01:26:01 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 01:26:01 - INFO - __main__ - ['Plant']
05/28/2022 01:26:01 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 01:26:01 - INFO - __main__ - ['Plant']
05/28/2022 01:26:01 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 01:26:01 - INFO - __main__ - ['Plant']
05/28/2022 01:26:01 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:26:02 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:26:02 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 01:26:02 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 01:26:02 - INFO - __main__ - Printing 3 examples
05/28/2022 01:26:02 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/28/2022 01:26:02 - INFO - __main__ - ['Plant']
05/28/2022 01:26:02 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/28/2022 01:26:02 - INFO - __main__ - ['Plant']
05/28/2022 01:26:02 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/28/2022 01:26:02 - INFO - __main__ - ['Plant']
05/28/2022 01:26:02 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:26:02 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:26:02 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 01:26:06 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9687920182735851 on epoch=214
05/28/2022 01:26:06 - INFO - __main__ - save last model!
05/28/2022 01:26:06 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 01:26:06 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 01:26:06 - INFO - __main__ - Printing 3 examples
05/28/2022 01:26:06 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 01:26:06 - INFO - __main__ - ['Animal']
05/28/2022 01:26:06 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 01:26:06 - INFO - __main__ - ['Animal']
05/28/2022 01:26:06 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 01:26:06 - INFO - __main__ - ['Village']
05/28/2022 01:26:06 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:26:08 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:26:12 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 01:26:20 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 01:26:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 01:26:21 - INFO - __main__ - Starting training!
05/28/2022 01:28:26 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
05/28/2022 01:28:26 - INFO - __main__ - Classification-F1 on test data: 0.7616
05/28/2022 01:28:26 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.9730308985764394, test_performance=0.761615353239849
05/28/2022 01:28:26 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
05/28/2022 01:28:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 01:28:27 - INFO - __main__ - Printing 3 examples
05/28/2022 01:28:27 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 01:28:27 - INFO - __main__ - ['Plant']
05/28/2022 01:28:27 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 01:28:27 - INFO - __main__ - ['Plant']
05/28/2022 01:28:27 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 01:28:27 - INFO - __main__ - ['Plant']
05/28/2022 01:28:27 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:28:27 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:28:27 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 01:28:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 01:28:27 - INFO - __main__ - Printing 3 examples
05/28/2022 01:28:27 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/28/2022 01:28:27 - INFO - __main__ - ['Plant']
05/28/2022 01:28:27 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/28/2022 01:28:27 - INFO - __main__ - ['Plant']
05/28/2022 01:28:27 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/28/2022 01:28:27 - INFO - __main__ - ['Plant']
05/28/2022 01:28:27 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:28:27 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:28:28 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 01:28:43 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 01:28:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 01:28:44 - INFO - __main__ - Starting training!
05/28/2022 01:28:47 - INFO - __main__ - Step 10 Global step 10 Train loss 6.53 on epoch=0
05/28/2022 01:28:49 - INFO - __main__ - Step 20 Global step 20 Train loss 4.00 on epoch=1
05/28/2022 01:28:52 - INFO - __main__ - Step 30 Global step 30 Train loss 3.17 on epoch=2
05/28/2022 01:28:54 - INFO - __main__ - Step 40 Global step 40 Train loss 2.61 on epoch=2
05/28/2022 01:28:57 - INFO - __main__ - Step 50 Global step 50 Train loss 1.99 on epoch=3
05/28/2022 01:29:03 - INFO - __main__ - Global step 50 Train loss 3.66 Classification-F1 0.12145081318013648 on epoch=3
05/28/2022 01:29:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.12145081318013648 on epoch=3, global_step=50
05/28/2022 01:29:05 - INFO - __main__ - Step 60 Global step 60 Train loss 1.66 on epoch=4
05/28/2022 01:29:08 - INFO - __main__ - Step 70 Global step 70 Train loss 1.28 on epoch=4
05/28/2022 01:29:10 - INFO - __main__ - Step 80 Global step 80 Train loss 1.09 on epoch=5
05/28/2022 01:29:13 - INFO - __main__ - Step 90 Global step 90 Train loss 0.99 on epoch=6
05/28/2022 01:29:15 - INFO - __main__ - Step 100 Global step 100 Train loss 0.90 on epoch=7
05/28/2022 01:29:23 - INFO - __main__ - Global step 100 Train loss 1.18 Classification-F1 0.46554947976000605 on epoch=7
05/28/2022 01:29:23 - INFO - __main__ - Saving model with best Classification-F1: 0.12145081318013648 -> 0.46554947976000605 on epoch=7, global_step=100
05/28/2022 01:29:25 - INFO - __main__ - Step 110 Global step 110 Train loss 0.72 on epoch=7
05/28/2022 01:29:28 - INFO - __main__ - Step 120 Global step 120 Train loss 0.72 on epoch=8
05/28/2022 01:29:31 - INFO - __main__ - Step 130 Global step 130 Train loss 0.64 on epoch=9
05/28/2022 01:29:33 - INFO - __main__ - Step 140 Global step 140 Train loss 0.59 on epoch=9
05/28/2022 01:29:36 - INFO - __main__ - Step 150 Global step 150 Train loss 0.64 on epoch=10
05/28/2022 01:29:42 - INFO - __main__ - Global step 150 Train loss 0.66 Classification-F1 0.5122895002035868 on epoch=10
05/28/2022 01:29:42 - INFO - __main__ - Saving model with best Classification-F1: 0.46554947976000605 -> 0.5122895002035868 on epoch=10, global_step=150
05/28/2022 01:29:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.56 on epoch=11
05/28/2022 01:29:47 - INFO - __main__ - Step 170 Global step 170 Train loss 0.50 on epoch=12
05/28/2022 01:29:49 - INFO - __main__ - Step 180 Global step 180 Train loss 0.51 on epoch=12
05/28/2022 01:29:52 - INFO - __main__ - Step 190 Global step 190 Train loss 0.50 on epoch=13
05/28/2022 01:29:54 - INFO - __main__ - Step 200 Global step 200 Train loss 0.54 on epoch=14
05/28/2022 01:30:00 - INFO - __main__ - Global step 200 Train loss 0.52 Classification-F1 0.5595814162759483 on epoch=14
05/28/2022 01:30:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5122895002035868 -> 0.5595814162759483 on epoch=14, global_step=200
05/28/2022 01:30:03 - INFO - __main__ - Step 210 Global step 210 Train loss 0.43 on epoch=14
05/28/2022 01:30:05 - INFO - __main__ - Step 220 Global step 220 Train loss 0.44 on epoch=15
05/28/2022 01:30:08 - INFO - __main__ - Step 230 Global step 230 Train loss 0.41 on epoch=16
05/28/2022 01:30:10 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=17
05/28/2022 01:30:13 - INFO - __main__ - Step 250 Global step 250 Train loss 0.38 on epoch=17
05/28/2022 01:30:19 - INFO - __main__ - Global step 250 Train loss 0.41 Classification-F1 0.691498033421127 on epoch=17
05/28/2022 01:30:19 - INFO - __main__ - Saving model with best Classification-F1: 0.5595814162759483 -> 0.691498033421127 on epoch=17, global_step=250
05/28/2022 01:30:22 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=18
05/28/2022 01:30:25 - INFO - __main__ - Step 270 Global step 270 Train loss 0.45 on epoch=19
05/28/2022 01:30:27 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=19
05/28/2022 01:30:30 - INFO - __main__ - Step 290 Global step 290 Train loss 0.33 on epoch=20
05/28/2022 01:30:32 - INFO - __main__ - Step 300 Global step 300 Train loss 0.33 on epoch=21
05/28/2022 01:30:39 - INFO - __main__ - Global step 300 Train loss 0.37 Classification-F1 0.785284926927929 on epoch=21
05/28/2022 01:30:39 - INFO - __main__ - Saving model with best Classification-F1: 0.691498033421127 -> 0.785284926927929 on epoch=21, global_step=300
05/28/2022 01:30:41 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=22
05/28/2022 01:30:44 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=22
05/28/2022 01:30:46 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=23
05/28/2022 01:30:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=24
05/28/2022 01:30:51 - INFO - __main__ - Step 350 Global step 350 Train loss 0.34 on epoch=24
05/28/2022 01:30:59 - INFO - __main__ - Global step 350 Train loss 0.27 Classification-F1 0.6502906627191418 on epoch=24
05/28/2022 01:31:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=25
05/28/2022 01:31:04 - INFO - __main__ - Step 370 Global step 370 Train loss 0.35 on epoch=26
05/28/2022 01:31:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=27
05/28/2022 01:31:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=27
05/28/2022 01:31:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=28
05/28/2022 01:31:18 - INFO - __main__ - Global step 400 Train loss 0.25 Classification-F1 0.8499653989976572 on epoch=28
05/28/2022 01:31:18 - INFO - __main__ - Saving model with best Classification-F1: 0.785284926927929 -> 0.8499653989976572 on epoch=28, global_step=400
05/28/2022 01:31:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=29
05/28/2022 01:31:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=29
05/28/2022 01:31:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=30
05/28/2022 01:31:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=31
05/28/2022 01:31:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=32
05/28/2022 01:31:37 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.8778165969659242 on epoch=32
05/28/2022 01:31:37 - INFO - __main__ - Saving model with best Classification-F1: 0.8499653989976572 -> 0.8778165969659242 on epoch=32, global_step=450
05/28/2022 01:31:40 - INFO - __main__ - Step 460 Global step 460 Train loss 0.16 on epoch=32
05/28/2022 01:31:42 - INFO - __main__ - Step 470 Global step 470 Train loss 0.15 on epoch=33
05/28/2022 01:31:45 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=34
05/28/2022 01:31:47 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=34
05/28/2022 01:31:50 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=35
05/28/2022 01:31:57 - INFO - __main__ - Global step 500 Train loss 0.17 Classification-F1 0.9642817345362656 on epoch=35
05/28/2022 01:31:57 - INFO - __main__ - Saving model with best Classification-F1: 0.8778165969659242 -> 0.9642817345362656 on epoch=35, global_step=500
05/28/2022 01:31:59 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=36
05/28/2022 01:32:02 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=37
05/28/2022 01:32:04 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=37
05/28/2022 01:32:07 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=38
05/28/2022 01:32:09 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=39
05/28/2022 01:32:15 - INFO - __main__ - Global step 550 Train loss 0.17 Classification-F1 0.9103127096390854 on epoch=39
05/28/2022 01:32:18 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=39
05/28/2022 01:32:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=40
05/28/2022 01:32:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.10 on epoch=41
05/28/2022 01:32:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.09 on epoch=42
05/28/2022 01:32:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=42
05/28/2022 01:32:35 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.7652613092074373 on epoch=42
05/28/2022 01:32:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=43
05/28/2022 01:32:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.12 on epoch=44
05/28/2022 01:32:42 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=44
05/28/2022 01:32:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=45
05/28/2022 01:32:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=46
05/28/2022 01:32:54 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.832424046837887 on epoch=46
05/28/2022 01:32:56 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=47
05/28/2022 01:32:59 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=47
05/28/2022 01:33:02 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=48
05/28/2022 01:33:04 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=49
05/28/2022 01:33:07 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=49
05/28/2022 01:33:13 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.8815291470775343 on epoch=49
05/28/2022 01:33:16 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=50
05/28/2022 01:33:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=51
05/28/2022 01:33:21 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=52
05/28/2022 01:33:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=52
05/28/2022 01:33:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=53
05/28/2022 01:33:32 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.8472193321976884 on epoch=53
05/28/2022 01:33:35 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=54
05/28/2022 01:33:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=54
05/28/2022 01:33:40 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=55
05/28/2022 01:33:42 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=56
05/28/2022 01:33:45 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=57
05/28/2022 01:33:51 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.8419342754020174 on epoch=57
05/28/2022 01:33:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=57
05/28/2022 01:33:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=58
05/28/2022 01:33:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=59
05/28/2022 01:34:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=59
05/28/2022 01:34:04 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=60
05/28/2022 01:34:10 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.7189170001337712 on epoch=60
05/28/2022 01:34:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=61
05/28/2022 01:34:15 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=62
05/28/2022 01:34:17 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
05/28/2022 01:34:20 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=63
05/28/2022 01:34:22 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
05/28/2022 01:34:28 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.8161587261370824 on epoch=64
05/28/2022 01:34:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=64
05/28/2022 01:34:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=65
05/28/2022 01:34:36 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=66
05/28/2022 01:34:38 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=67
05/28/2022 01:34:41 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=67
05/28/2022 01:34:47 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.8747530810955858 on epoch=67
05/28/2022 01:34:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=68
05/28/2022 01:34:52 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
05/28/2022 01:34:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=69
05/28/2022 01:34:57 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
05/28/2022 01:34:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
05/28/2022 01:35:06 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.8880510170832749 on epoch=71
05/28/2022 01:35:08 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=72
05/28/2022 01:35:11 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
05/28/2022 01:35:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=73
05/28/2022 01:35:16 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=74
05/28/2022 01:35:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=74
05/28/2022 01:35:25 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.9056929581756187 on epoch=74
05/28/2022 01:35:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=75
05/28/2022 01:35:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
05/28/2022 01:35:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
05/28/2022 01:35:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=77
05/28/2022 01:35:38 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
05/28/2022 01:35:43 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.8215992659893869 on epoch=78
05/28/2022 01:35:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
05/28/2022 01:35:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
05/28/2022 01:35:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
05/28/2022 01:35:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=81
05/28/2022 01:35:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=82
05/28/2022 01:36:02 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.8527636188778778 on epoch=82
05/28/2022 01:36:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
05/28/2022 01:36:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
05/28/2022 01:36:09 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=84
05/28/2022 01:36:12 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
05/28/2022 01:36:14 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
05/28/2022 01:36:20 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.8200649761370824 on epoch=85
05/28/2022 01:36:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=86
05/28/2022 01:36:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=87
05/28/2022 01:36:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
05/28/2022 01:36:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=88
05/28/2022 01:36:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
05/28/2022 01:36:38 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.9104103655147299 on epoch=89
05/28/2022 01:36:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
05/28/2022 01:36:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=90
05/28/2022 01:36:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
05/28/2022 01:36:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=92
05/28/2022 01:36:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=92
05/28/2022 01:36:57 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.6963643106313885 on epoch=92
05/28/2022 01:36:59 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=93
05/28/2022 01:37:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
05/28/2022 01:37:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
05/28/2022 01:37:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
05/28/2022 01:37:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
05/28/2022 01:37:15 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.846555028006641 on epoch=96
05/28/2022 01:37:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=97
05/28/2022 01:37:20 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
05/28/2022 01:37:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
05/28/2022 01:37:25 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=99
05/28/2022 01:37:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=99
05/28/2022 01:37:33 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.9091337336498626 on epoch=99
05/28/2022 01:37:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
05/28/2022 01:37:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
05/28/2022 01:37:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=102
05/28/2022 01:37:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
05/28/2022 01:37:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
05/28/2022 01:37:52 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.9186705767350927 on epoch=103
05/28/2022 01:37:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=104
05/28/2022 01:37:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
05/28/2022 01:37:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
05/28/2022 01:38:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
05/28/2022 01:38:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
05/28/2022 01:38:10 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.8543412232928362 on epoch=107
05/28/2022 01:38:13 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
05/28/2022 01:38:15 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
05/28/2022 01:38:18 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
05/28/2022 01:38:20 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=109
05/28/2022 01:38:23 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
05/28/2022 01:38:28 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.8509880506960597 on epoch=110
05/28/2022 01:38:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=111
05/28/2022 01:38:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
05/28/2022 01:38:36 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=112
05/28/2022 01:38:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
05/28/2022 01:38:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=114
05/28/2022 01:38:47 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.9228453893776475 on epoch=114
05/28/2022 01:38:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=114
05/28/2022 01:38:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
05/28/2022 01:38:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
05/28/2022 01:38:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
05/28/2022 01:38:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
05/28/2022 01:39:05 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.8591069464809384 on epoch=117
05/28/2022 01:39:08 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
05/28/2022 01:39:10 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
05/28/2022 01:39:13 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/28/2022 01:39:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
05/28/2022 01:39:18 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
05/28/2022 01:39:23 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7953429421157404 on epoch=121
05/28/2022 01:39:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
05/28/2022 01:39:28 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
05/28/2022 01:39:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
05/28/2022 01:39:33 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=124
05/28/2022 01:39:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
05/28/2022 01:39:42 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.859103128054741 on epoch=124
05/28/2022 01:39:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=125
05/28/2022 01:39:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
05/28/2022 01:39:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
05/28/2022 01:39:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
05/28/2022 01:39:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
05/28/2022 01:40:00 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.9187894121480459 on epoch=128
05/28/2022 01:40:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
05/28/2022 01:40:05 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
05/28/2022 01:40:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
05/28/2022 01:40:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=131
05/28/2022 01:40:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
05/28/2022 01:40:19 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9865984150258343 on epoch=132
05/28/2022 01:40:19 - INFO - __main__ - Saving model with best Classification-F1: 0.9642817345362656 -> 0.9865984150258343 on epoch=132, global_step=1850
05/28/2022 01:40:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
05/28/2022 01:40:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/28/2022 01:40:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
05/28/2022 01:40:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
05/28/2022 01:40:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
05/28/2022 01:40:37 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=135
05/28/2022 01:40:37 - INFO - __main__ - Saving model with best Classification-F1: 0.9865984150258343 -> 0.9910627007401202 on epoch=135, global_step=1900
05/28/2022 01:40:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
05/28/2022 01:40:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/28/2022 01:40:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
05/28/2022 01:40:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
05/28/2022 01:40:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
05/28/2022 01:40:56 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.9228413163897036 on epoch=139
05/28/2022 01:40:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
05/28/2022 01:41:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
05/28/2022 01:41:04 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=141
05/28/2022 01:41:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
05/28/2022 01:41:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=142
05/28/2022 01:41:15 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=142
05/28/2022 01:41:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=143
05/28/2022 01:41:20 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
05/28/2022 01:41:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=144
05/28/2022 01:41:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
05/28/2022 01:41:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/28/2022 01:41:34 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9865677649358864 on epoch=146
05/28/2022 01:41:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/28/2022 01:41:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
05/28/2022 01:41:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
05/28/2022 01:41:45 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
05/28/2022 01:41:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=149
05/28/2022 01:41:53 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=149
05/28/2022 01:41:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=150
05/28/2022 01:41:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/28/2022 01:42:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
05/28/2022 01:42:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
05/28/2022 01:42:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=153
05/28/2022 01:42:12 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.9910627007401202 on epoch=153
05/28/2022 01:42:15 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
05/28/2022 01:42:18 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=154
05/28/2022 01:42:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
05/28/2022 01:42:23 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=156
05/28/2022 01:42:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=157
05/28/2022 01:42:31 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.99553135037006 on epoch=157
05/28/2022 01:42:31 - INFO - __main__ - Saving model with best Classification-F1: 0.9910627007401202 -> 0.99553135037006 on epoch=157, global_step=2200
05/28/2022 01:42:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
05/28/2022 01:42:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
05/28/2022 01:42:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=159
05/28/2022 01:42:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
05/28/2022 01:42:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
05/28/2022 01:42:50 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=160
05/28/2022 01:42:53 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
05/28/2022 01:42:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
05/28/2022 01:42:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
05/28/2022 01:43:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
05/28/2022 01:43:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/28/2022 01:43:09 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.99553135037006 on epoch=164
05/28/2022 01:43:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
05/28/2022 01:43:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/28/2022 01:43:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/28/2022 01:43:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
05/28/2022 01:43:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
05/28/2022 01:43:28 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.99553135037006 on epoch=167
05/28/2022 01:43:31 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
05/28/2022 01:43:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/28/2022 01:43:36 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
05/28/2022 01:43:39 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
05/28/2022 01:43:41 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/28/2022 01:43:47 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.99553135037006 on epoch=171
05/28/2022 01:43:50 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
05/28/2022 01:43:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
05/28/2022 01:43:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
05/28/2022 01:43:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
05/28/2022 01:44:00 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/28/2022 01:44:06 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.99553135037006 on epoch=174
05/28/2022 01:44:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
05/28/2022 01:44:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
05/28/2022 01:44:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
05/28/2022 01:44:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
05/28/2022 01:44:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
05/28/2022 01:44:25 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.99553135037006 on epoch=178
05/28/2022 01:44:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
05/28/2022 01:44:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
05/28/2022 01:44:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=180
05/28/2022 01:44:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/28/2022 01:44:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
05/28/2022 01:44:43 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9247181492342783 on epoch=182
05/28/2022 01:44:46 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
05/28/2022 01:44:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
05/28/2022 01:44:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
05/28/2022 01:44:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
05/28/2022 01:44:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
05/28/2022 01:45:03 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.9867213747669155 on epoch=185
05/28/2022 01:45:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/28/2022 01:45:08 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
05/28/2022 01:45:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
05/28/2022 01:45:13 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
05/28/2022 01:45:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/28/2022 01:45:21 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=189
05/28/2022 01:45:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
05/28/2022 01:45:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/28/2022 01:45:29 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
05/28/2022 01:45:32 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/28/2022 01:45:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/28/2022 01:45:40 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.99553135037006 on epoch=192
05/28/2022 01:45:43 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
05/28/2022 01:45:45 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/28/2022 01:45:48 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
05/28/2022 01:45:51 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/28/2022 01:45:53 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
05/28/2022 01:45:59 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.99553135037006 on epoch=196
05/28/2022 01:46:02 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
05/28/2022 01:46:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
05/28/2022 01:46:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/28/2022 01:46:09 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
05/28/2022 01:46:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
05/28/2022 01:46:18 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.99553135037006 on epoch=199
05/28/2022 01:46:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
05/28/2022 01:46:23 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
05/28/2022 01:46:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
05/28/2022 01:46:28 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
05/28/2022 01:46:31 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/28/2022 01:46:38 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.9910670646557743 on epoch=203
05/28/2022 01:46:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
05/28/2022 01:46:43 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
05/28/2022 01:46:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/28/2022 01:46:48 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/28/2022 01:46:51 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
05/28/2022 01:46:57 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.9270120560443141 on epoch=207
05/28/2022 01:47:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
05/28/2022 01:47:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/28/2022 01:47:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/28/2022 01:47:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/28/2022 01:47:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/28/2022 01:47:16 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.99553135037006 on epoch=210
05/28/2022 01:47:19 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
05/28/2022 01:47:21 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/28/2022 01:47:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
05/28/2022 01:47:26 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
05/28/2022 01:47:29 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
05/28/2022 01:47:30 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 01:47:30 - INFO - __main__ - Printing 3 examples
05/28/2022 01:47:30 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 01:47:30 - INFO - __main__ - ['Plant']
05/28/2022 01:47:30 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 01:47:30 - INFO - __main__ - ['Plant']
05/28/2022 01:47:30 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 01:47:30 - INFO - __main__ - ['Plant']
05/28/2022 01:47:30 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:47:30 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:47:31 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 01:47:31 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 01:47:31 - INFO - __main__ - Printing 3 examples
05/28/2022 01:47:31 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/28/2022 01:47:31 - INFO - __main__ - ['Plant']
05/28/2022 01:47:31 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/28/2022 01:47:31 - INFO - __main__ - ['Plant']
05/28/2022 01:47:31 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/28/2022 01:47:31 - INFO - __main__ - ['Plant']
05/28/2022 01:47:31 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:47:31 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:47:31 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 01:47:35 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9909090909090909 on epoch=214
05/28/2022 01:47:35 - INFO - __main__ - save last model!
05/28/2022 01:47:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 01:47:35 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 01:47:35 - INFO - __main__ - Printing 3 examples
05/28/2022 01:47:35 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 01:47:35 - INFO - __main__ - ['Animal']
05/28/2022 01:47:35 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 01:47:35 - INFO - __main__ - ['Animal']
05/28/2022 01:47:35 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 01:47:35 - INFO - __main__ - ['Village']
05/28/2022 01:47:35 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:47:37 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:47:41 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 01:47:47 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 01:47:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 01:47:47 - INFO - __main__ - Starting training!
05/28/2022 01:49:51 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
05/28/2022 01:49:51 - INFO - __main__ - Classification-F1 on test data: 0.7612
05/28/2022 01:49:51 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.99553135037006, test_performance=0.7612331148738063
05/28/2022 01:49:51 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
05/28/2022 01:49:52 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 01:49:52 - INFO - __main__ - Printing 3 examples
05/28/2022 01:49:52 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 01:49:52 - INFO - __main__ - ['Plant']
05/28/2022 01:49:52 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 01:49:52 - INFO - __main__ - ['Plant']
05/28/2022 01:49:52 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 01:49:52 - INFO - __main__ - ['Plant']
05/28/2022 01:49:52 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:49:52 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:49:53 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 01:49:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 01:49:53 - INFO - __main__ - Printing 3 examples
05/28/2022 01:49:53 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/28/2022 01:49:53 - INFO - __main__ - ['Plant']
05/28/2022 01:49:53 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/28/2022 01:49:53 - INFO - __main__ - ['Plant']
05/28/2022 01:49:53 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/28/2022 01:49:53 - INFO - __main__ - ['Plant']
05/28/2022 01:49:53 - INFO - __main__ - Tokenizing Input ...
05/28/2022 01:49:53 - INFO - __main__ - Tokenizing Output ...
05/28/2022 01:49:53 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 01:50:12 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 01:50:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 01:50:12 - INFO - __main__ - Starting training!
05/28/2022 01:50:16 - INFO - __main__ - Step 10 Global step 10 Train loss 7.18 on epoch=0
05/28/2022 01:50:19 - INFO - __main__ - Step 20 Global step 20 Train loss 4.39 on epoch=1
05/28/2022 01:50:21 - INFO - __main__ - Step 30 Global step 30 Train loss 3.45 on epoch=2
05/28/2022 01:50:24 - INFO - __main__ - Step 40 Global step 40 Train loss 2.81 on epoch=2
05/28/2022 01:50:26 - INFO - __main__ - Step 50 Global step 50 Train loss 2.31 on epoch=3
05/28/2022 01:50:32 - INFO - __main__ - Global step 50 Train loss 4.03 Classification-F1 0.02022914428929467 on epoch=3
05/28/2022 01:50:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.02022914428929467 on epoch=3, global_step=50
05/28/2022 01:50:35 - INFO - __main__ - Step 60 Global step 60 Train loss 2.05 on epoch=4
05/28/2022 01:50:37 - INFO - __main__ - Step 70 Global step 70 Train loss 1.72 on epoch=4
05/28/2022 01:50:40 - INFO - __main__ - Step 80 Global step 80 Train loss 1.43 on epoch=5
05/28/2022 01:50:42 - INFO - __main__ - Step 90 Global step 90 Train loss 1.12 on epoch=6
05/28/2022 01:50:45 - INFO - __main__ - Step 100 Global step 100 Train loss 1.16 on epoch=7
05/28/2022 01:50:52 - INFO - __main__ - Global step 100 Train loss 1.50 Classification-F1 0.36634729548331557 on epoch=7
05/28/2022 01:50:52 - INFO - __main__ - Saving model with best Classification-F1: 0.02022914428929467 -> 0.36634729548331557 on epoch=7, global_step=100
05/28/2022 01:50:54 - INFO - __main__ - Step 110 Global step 110 Train loss 0.96 on epoch=7
05/28/2022 01:50:57 - INFO - __main__ - Step 120 Global step 120 Train loss 0.89 on epoch=8
05/28/2022 01:50:59 - INFO - __main__ - Step 130 Global step 130 Train loss 0.76 on epoch=9
05/28/2022 01:51:02 - INFO - __main__ - Step 140 Global step 140 Train loss 0.78 on epoch=9
05/28/2022 01:51:05 - INFO - __main__ - Step 150 Global step 150 Train loss 0.77 on epoch=10
05/28/2022 01:51:11 - INFO - __main__ - Global step 150 Train loss 0.83 Classification-F1 0.5396239497703356 on epoch=10
05/28/2022 01:51:11 - INFO - __main__ - Saving model with best Classification-F1: 0.36634729548331557 -> 0.5396239497703356 on epoch=10, global_step=150
05/28/2022 01:51:14 - INFO - __main__ - Step 160 Global step 160 Train loss 0.67 on epoch=11
05/28/2022 01:51:17 - INFO - __main__ - Step 170 Global step 170 Train loss 0.66 on epoch=12
05/28/2022 01:51:19 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=12
05/28/2022 01:51:22 - INFO - __main__ - Step 190 Global step 190 Train loss 0.60 on epoch=13
05/28/2022 01:51:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=14
05/28/2022 01:51:31 - INFO - __main__ - Global step 200 Train loss 0.61 Classification-F1 0.6417440978859664 on epoch=14
05/28/2022 01:51:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5396239497703356 -> 0.6417440978859664 on epoch=14, global_step=200
05/28/2022 01:51:34 - INFO - __main__ - Step 210 Global step 210 Train loss 0.52 on epoch=14
05/28/2022 01:51:37 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=15
05/28/2022 01:51:39 - INFO - __main__ - Step 230 Global step 230 Train loss 0.45 on epoch=16
05/28/2022 01:51:42 - INFO - __main__ - Step 240 Global step 240 Train loss 0.47 on epoch=17
05/28/2022 01:51:44 - INFO - __main__ - Step 250 Global step 250 Train loss 0.41 on epoch=17
05/28/2022 01:51:51 - INFO - __main__ - Global step 250 Train loss 0.47 Classification-F1 0.6687419974617207 on epoch=17
05/28/2022 01:51:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6417440978859664 -> 0.6687419974617207 on epoch=17, global_step=250
05/28/2022 01:51:54 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=18
05/28/2022 01:51:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.42 on epoch=19
05/28/2022 01:51:59 - INFO - __main__ - Step 280 Global step 280 Train loss 0.47 on epoch=19
05/28/2022 01:52:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.54 on epoch=20
05/28/2022 01:52:04 - INFO - __main__ - Step 300 Global step 300 Train loss 0.48 on epoch=21
05/28/2022 01:52:11 - INFO - __main__ - Global step 300 Train loss 0.46 Classification-F1 0.7950557723732596 on epoch=21
05/28/2022 01:52:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6687419974617207 -> 0.7950557723732596 on epoch=21, global_step=300
05/28/2022 01:52:14 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=22
05/28/2022 01:52:16 - INFO - __main__ - Step 320 Global step 320 Train loss 0.37 on epoch=22
05/28/2022 01:52:19 - INFO - __main__ - Step 330 Global step 330 Train loss 0.29 on epoch=23
05/28/2022 01:52:21 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=24
05/28/2022 01:52:24 - INFO - __main__ - Step 350 Global step 350 Train loss 0.37 on epoch=24
05/28/2022 01:52:30 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.8572359014307265 on epoch=24
05/28/2022 01:52:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7950557723732596 -> 0.8572359014307265 on epoch=24, global_step=350
05/28/2022 01:52:33 - INFO - __main__ - Step 360 Global step 360 Train loss 0.27 on epoch=25
05/28/2022 01:52:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.32 on epoch=26
05/28/2022 01:52:38 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=27
05/28/2022 01:52:40 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=27
05/28/2022 01:52:43 - INFO - __main__ - Step 400 Global step 400 Train loss 0.34 on epoch=28
05/28/2022 01:52:49 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.8543987623372508 on epoch=28
05/28/2022 01:52:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.29 on epoch=29
05/28/2022 01:52:54 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=29
05/28/2022 01:52:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=30
05/28/2022 01:52:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.26 on epoch=31
05/28/2022 01:53:02 - INFO - __main__ - Step 450 Global step 450 Train loss 0.18 on epoch=32
05/28/2022 01:53:08 - INFO - __main__ - Global step 450 Train loss 0.26 Classification-F1 0.8123905097760465 on epoch=32
05/28/2022 01:53:11 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=32
05/28/2022 01:53:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=33
05/28/2022 01:53:16 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=34
05/28/2022 01:53:18 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=34
05/28/2022 01:53:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=35
05/28/2022 01:53:27 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.7592407454882844 on epoch=35
05/28/2022 01:53:30 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=36
05/28/2022 01:53:32 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=37
05/28/2022 01:53:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=37
05/28/2022 01:53:38 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=38
05/28/2022 01:53:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=39
05/28/2022 01:53:46 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.5938839130342675 on epoch=39
05/28/2022 01:53:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=39
05/28/2022 01:53:51 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=40
05/28/2022 01:53:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=41
05/28/2022 01:53:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=42
05/28/2022 01:53:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=42
05/28/2022 01:54:05 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.6575458309175597 on epoch=42
05/28/2022 01:54:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=43
05/28/2022 01:54:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=44
05/28/2022 01:54:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=44
05/28/2022 01:54:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=45
05/28/2022 01:54:18 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=46
05/28/2022 01:54:25 - INFO - __main__ - Global step 650 Train loss 0.16 Classification-F1 0.6920173130296953 on epoch=46
05/28/2022 01:54:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=47
05/28/2022 01:54:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=47
05/28/2022 01:54:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.23 on epoch=48
05/28/2022 01:54:35 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=49
05/28/2022 01:54:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=49
05/28/2022 01:54:45 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.7876650493813195 on epoch=49
05/28/2022 01:54:47 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=50
05/28/2022 01:54:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=51
05/28/2022 01:54:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=52
05/28/2022 01:54:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.12 on epoch=52
05/28/2022 01:54:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=53
05/28/2022 01:55:04 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.7575401082449978 on epoch=53
05/28/2022 01:55:06 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=54
05/28/2022 01:55:09 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=54
05/28/2022 01:55:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=55
05/28/2022 01:55:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=56
05/28/2022 01:55:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=57
05/28/2022 01:55:23 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.6276771362695275 on epoch=57
05/28/2022 01:55:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=57
05/28/2022 01:55:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=58
05/28/2022 01:55:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=59
05/28/2022 01:55:33 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=59
05/28/2022 01:55:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=60
05/28/2022 01:55:42 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.6626463879784563 on epoch=60
05/28/2022 01:55:45 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=61
05/28/2022 01:55:47 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=62
05/28/2022 01:55:50 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
05/28/2022 01:55:52 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=63
05/28/2022 01:55:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=64
05/28/2022 01:56:01 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.4799901037992041 on epoch=64
05/28/2022 01:56:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=64
05/28/2022 01:56:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=65
05/28/2022 01:56:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=66
05/28/2022 01:56:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
05/28/2022 01:56:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=67
05/28/2022 01:56:19 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.7579931178207383 on epoch=67
05/28/2022 01:56:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=68
05/28/2022 01:56:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
05/28/2022 01:56:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=69
05/28/2022 01:56:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
05/28/2022 01:56:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=71
05/28/2022 01:56:38 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.5553587515162468 on epoch=71
05/28/2022 01:56:41 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=72
05/28/2022 01:56:43 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=72
05/28/2022 01:56:46 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=73
05/28/2022 01:56:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
05/28/2022 01:56:51 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=74
05/28/2022 01:56:57 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.6146015921204212 on epoch=74
05/28/2022 01:56:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=75
05/28/2022 01:57:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=76
05/28/2022 01:57:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=77
05/28/2022 01:57:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
05/28/2022 01:57:10 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=78
05/28/2022 01:57:16 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.7931527596375794 on epoch=78
05/28/2022 01:57:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=79
05/28/2022 01:57:21 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
05/28/2022 01:57:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
05/28/2022 01:57:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
05/28/2022 01:57:29 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
05/28/2022 01:57:35 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.6850110613777847 on epoch=82
05/28/2022 01:57:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=82
05/28/2022 01:57:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=83
05/28/2022 01:57:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=84
05/28/2022 01:57:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=84
05/28/2022 01:57:48 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=85
05/28/2022 01:57:54 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.8415613696701139 on epoch=85
05/28/2022 01:57:56 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=86
05/28/2022 01:57:59 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=87
05/28/2022 01:58:01 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
05/28/2022 01:58:04 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
05/28/2022 01:58:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
05/28/2022 01:58:13 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7974268299695245 on epoch=89
05/28/2022 01:58:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
05/28/2022 01:58:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
05/28/2022 01:58:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
05/28/2022 01:58:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
05/28/2022 01:58:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=92
05/28/2022 01:58:31 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.7150840747351968 on epoch=92
05/28/2022 01:58:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
05/28/2022 01:58:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=94
05/28/2022 01:58:39 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
05/28/2022 01:58:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
05/28/2022 01:58:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=96
05/28/2022 01:58:50 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.610975093105796 on epoch=96
05/28/2022 01:58:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
05/28/2022 01:58:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
05/28/2022 01:58:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
05/28/2022 01:59:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
05/28/2022 01:59:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
05/28/2022 01:59:08 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7292172082257472 on epoch=99
05/28/2022 01:59:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
05/28/2022 01:59:14 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=101
05/28/2022 01:59:16 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
05/28/2022 01:59:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
05/28/2022 01:59:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
05/28/2022 01:59:28 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7387717252926963 on epoch=103
05/28/2022 01:59:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
05/28/2022 01:59:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
05/28/2022 01:59:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
05/28/2022 01:59:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
05/28/2022 01:59:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=107
05/28/2022 01:59:46 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.912223036819811 on epoch=107
05/28/2022 01:59:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8572359014307265 -> 0.912223036819811 on epoch=107, global_step=1500
05/28/2022 01:59:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
05/28/2022 01:59:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
05/28/2022 01:59:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
05/28/2022 01:59:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=109
05/28/2022 01:59:59 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
05/28/2022 02:00:05 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9018774994408051 on epoch=110
05/28/2022 02:00:08 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
05/28/2022 02:00:11 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
05/28/2022 02:00:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
05/28/2022 02:00:16 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
05/28/2022 02:00:18 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
05/28/2022 02:00:24 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.8512446489365288 on epoch=114
05/28/2022 02:00:27 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
05/28/2022 02:00:29 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
05/28/2022 02:00:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
05/28/2022 02:00:34 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
05/28/2022 02:00:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
05/28/2022 02:00:43 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7454100966725288 on epoch=117
05/28/2022 02:00:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
05/28/2022 02:00:48 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
05/28/2022 02:00:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/28/2022 02:00:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
05/28/2022 02:00:56 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
05/28/2022 02:01:02 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8485302524602216 on epoch=121
05/28/2022 02:01:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
05/28/2022 02:01:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
05/28/2022 02:01:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
05/28/2022 02:01:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
05/28/2022 02:01:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
05/28/2022 02:01:21 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.9778881640632794 on epoch=124
05/28/2022 02:01:21 - INFO - __main__ - Saving model with best Classification-F1: 0.912223036819811 -> 0.9778881640632794 on epoch=124, global_step=1750
05/28/2022 02:01:23 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
05/28/2022 02:01:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
05/28/2022 02:01:29 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
05/28/2022 02:01:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
05/28/2022 02:01:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
05/28/2022 02:01:40 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.6702552541544478 on epoch=128
05/28/2022 02:01:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
05/28/2022 02:01:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
05/28/2022 02:01:47 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/28/2022 02:01:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
05/28/2022 02:01:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
05/28/2022 02:01:59 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9731845084074686 on epoch=132
05/28/2022 02:02:01 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
05/28/2022 02:02:04 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/28/2022 02:02:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
05/28/2022 02:02:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
05/28/2022 02:02:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/28/2022 02:02:18 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9038610967358596 on epoch=135
05/28/2022 02:02:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
05/28/2022 02:02:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=137
05/28/2022 02:02:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
05/28/2022 02:02:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
05/28/2022 02:02:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
05/28/2022 02:02:37 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9062350463156915 on epoch=139
05/28/2022 02:02:40 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
05/28/2022 02:02:42 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
05/28/2022 02:02:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=141
05/28/2022 02:02:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
05/28/2022 02:02:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
05/28/2022 02:02:56 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.614068715193503 on epoch=142
05/28/2022 02:02:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
05/28/2022 02:03:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
05/28/2022 02:03:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
05/28/2022 02:03:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
05/28/2022 02:03:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
05/28/2022 02:03:15 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.798490205984067 on epoch=146
05/28/2022 02:03:18 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=147
05/28/2022 02:03:20 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
05/28/2022 02:03:23 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
05/28/2022 02:03:25 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
05/28/2022 02:03:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
05/28/2022 02:03:34 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.641413029175126 on epoch=149
05/28/2022 02:03:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
05/28/2022 02:03:39 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/28/2022 02:03:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
05/28/2022 02:03:44 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
05/28/2022 02:03:47 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=153
05/28/2022 02:03:53 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.5930710717001039 on epoch=153
05/28/2022 02:03:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
05/28/2022 02:03:58 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/28/2022 02:04:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
05/28/2022 02:04:03 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
05/28/2022 02:04:05 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
05/28/2022 02:04:11 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6926673610141353 on epoch=157
05/28/2022 02:04:14 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/28/2022 02:04:16 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
05/28/2022 02:04:19 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
05/28/2022 02:04:21 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
05/28/2022 02:04:24 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
05/28/2022 02:04:30 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.6399774844128219 on epoch=160
05/28/2022 02:04:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
05/28/2022 02:04:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
05/28/2022 02:04:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/28/2022 02:04:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
05/28/2022 02:04:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
05/28/2022 02:04:49 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8301571188119456 on epoch=164
05/28/2022 02:04:51 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
05/28/2022 02:04:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/28/2022 02:04:56 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/28/2022 02:04:59 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
05/28/2022 02:05:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
05/28/2022 02:05:08 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8291044428230661 on epoch=167
05/28/2022 02:05:10 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=168
05/28/2022 02:05:13 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/28/2022 02:05:16 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
05/28/2022 02:05:18 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
05/28/2022 02:05:21 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/28/2022 02:05:27 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8290336955896729 on epoch=171
05/28/2022 02:05:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
05/28/2022 02:05:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
05/28/2022 02:05:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
05/28/2022 02:05:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/28/2022 02:05:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/28/2022 02:05:45 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8359181652866425 on epoch=174
05/28/2022 02:05:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
05/28/2022 02:05:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
05/28/2022 02:05:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
05/28/2022 02:05:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
05/28/2022 02:05:58 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/28/2022 02:06:04 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.760617301518957 on epoch=178
05/28/2022 02:06:06 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
05/28/2022 02:06:09 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
05/28/2022 02:06:12 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/28/2022 02:06:14 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/28/2022 02:06:17 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
05/28/2022 02:06:23 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7970206185339013 on epoch=182
05/28/2022 02:06:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
05/28/2022 02:06:28 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/28/2022 02:06:30 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
05/28/2022 02:06:33 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
05/28/2022 02:06:36 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
05/28/2022 02:06:41 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6894359859293488 on epoch=185
05/28/2022 02:06:44 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/28/2022 02:06:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/28/2022 02:06:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
05/28/2022 02:06:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
05/28/2022 02:06:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/28/2022 02:07:00 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8503005646906856 on epoch=189
05/28/2022 02:07:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/28/2022 02:07:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/28/2022 02:07:08 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/28/2022 02:07:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
05/28/2022 02:07:13 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/28/2022 02:07:18 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7880146962067028 on epoch=192
05/28/2022 02:07:21 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/28/2022 02:07:24 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
05/28/2022 02:07:26 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/28/2022 02:07:29 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/28/2022 02:07:31 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
05/28/2022 02:07:37 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7749412117980039 on epoch=196
05/28/2022 02:07:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/28/2022 02:07:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/28/2022 02:07:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/28/2022 02:07:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/28/2022 02:07:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
05/28/2022 02:07:55 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7363958437040847 on epoch=199
05/28/2022 02:07:58 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.10 on epoch=200
05/28/2022 02:08:00 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
05/28/2022 02:08:03 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
05/28/2022 02:08:06 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
05/28/2022 02:08:08 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
05/28/2022 02:08:14 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.6945631041598784 on epoch=203
05/28/2022 02:08:17 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
05/28/2022 02:08:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
05/28/2022 02:08:22 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/28/2022 02:08:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
05/28/2022 02:08:27 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
05/28/2022 02:08:33 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7195277746339838 on epoch=207
05/28/2022 02:08:36 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
05/28/2022 02:08:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/28/2022 02:08:41 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/28/2022 02:08:44 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
05/28/2022 02:08:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/28/2022 02:08:52 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8996162723693312 on epoch=210
05/28/2022 02:08:55 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
05/28/2022 02:08:57 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/28/2022 02:09:00 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
05/28/2022 02:09:03 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/28/2022 02:09:05 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
05/28/2022 02:09:06 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 02:09:06 - INFO - __main__ - Printing 3 examples
05/28/2022 02:09:06 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 02:09:06 - INFO - __main__ - ['Plant']
05/28/2022 02:09:06 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 02:09:06 - INFO - __main__ - ['Plant']
05/28/2022 02:09:06 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 02:09:06 - INFO - __main__ - ['Plant']
05/28/2022 02:09:06 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:09:07 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:09:07 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 02:09:07 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 02:09:07 - INFO - __main__ - Printing 3 examples
05/28/2022 02:09:07 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/28/2022 02:09:07 - INFO - __main__ - ['Plant']
05/28/2022 02:09:07 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/28/2022 02:09:07 - INFO - __main__ - ['Plant']
05/28/2022 02:09:07 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/28/2022 02:09:07 - INFO - __main__ - ['Plant']
05/28/2022 02:09:07 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:09:07 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:09:07 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 02:09:12 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8537830870373564 on epoch=214
05/28/2022 02:09:12 - INFO - __main__ - save last model!
05/28/2022 02:09:12 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 02:09:12 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 02:09:12 - INFO - __main__ - Printing 3 examples
05/28/2022 02:09:12 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 02:09:12 - INFO - __main__ - ['Animal']
05/28/2022 02:09:12 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 02:09:12 - INFO - __main__ - ['Animal']
05/28/2022 02:09:12 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 02:09:12 - INFO - __main__ - ['Village']
05/28/2022 02:09:12 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:09:13 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:09:17 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 02:09:25 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 02:09:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 02:09:26 - INFO - __main__ - Starting training!
05/28/2022 02:11:25 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
05/28/2022 02:11:25 - INFO - __main__ - Classification-F1 on test data: 0.5790
05/28/2022 02:11:25 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.9778881640632794, test_performance=0.578986991119197
05/28/2022 02:11:25 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
05/28/2022 02:11:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 02:11:26 - INFO - __main__ - Printing 3 examples
05/28/2022 02:11:26 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 02:11:26 - INFO - __main__ - ['Plant']
05/28/2022 02:11:26 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 02:11:26 - INFO - __main__ - ['Plant']
05/28/2022 02:11:26 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 02:11:26 - INFO - __main__ - ['Plant']
05/28/2022 02:11:26 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:11:26 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:11:26 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 02:11:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 02:11:26 - INFO - __main__ - Printing 3 examples
05/28/2022 02:11:26 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/28/2022 02:11:26 - INFO - __main__ - ['Plant']
05/28/2022 02:11:26 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/28/2022 02:11:26 - INFO - __main__ - ['Plant']
05/28/2022 02:11:26 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/28/2022 02:11:26 - INFO - __main__ - ['Plant']
05/28/2022 02:11:26 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:11:26 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:11:27 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 02:11:42 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 02:11:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 02:11:43 - INFO - __main__ - Starting training!
05/28/2022 02:11:46 - INFO - __main__ - Step 10 Global step 10 Train loss 7.02 on epoch=0
05/28/2022 02:11:49 - INFO - __main__ - Step 20 Global step 20 Train loss 4.78 on epoch=1
05/28/2022 02:11:51 - INFO - __main__ - Step 30 Global step 30 Train loss 4.06 on epoch=2
05/28/2022 02:11:54 - INFO - __main__ - Step 40 Global step 40 Train loss 3.30 on epoch=2
05/28/2022 02:11:56 - INFO - __main__ - Step 50 Global step 50 Train loss 2.81 on epoch=3
05/28/2022 02:12:02 - INFO - __main__ - Global step 50 Train loss 4.40 Classification-F1 0.009523809523809523 on epoch=3
05/28/2022 02:12:02 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009523809523809523 on epoch=3, global_step=50
05/28/2022 02:12:05 - INFO - __main__ - Step 60 Global step 60 Train loss 2.30 on epoch=4
05/28/2022 02:12:07 - INFO - __main__ - Step 70 Global step 70 Train loss 2.18 on epoch=4
05/28/2022 02:12:10 - INFO - __main__ - Step 80 Global step 80 Train loss 1.71 on epoch=5
05/28/2022 02:12:13 - INFO - __main__ - Step 90 Global step 90 Train loss 1.57 on epoch=6
05/28/2022 02:12:15 - INFO - __main__ - Step 100 Global step 100 Train loss 1.42 on epoch=7
05/28/2022 02:12:22 - INFO - __main__ - Global step 100 Train loss 1.84 Classification-F1 0.26013214903879867 on epoch=7
05/28/2022 02:12:22 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.26013214903879867 on epoch=7, global_step=100
05/28/2022 02:12:25 - INFO - __main__ - Step 110 Global step 110 Train loss 1.35 on epoch=7
05/28/2022 02:12:27 - INFO - __main__ - Step 120 Global step 120 Train loss 1.07 on epoch=8
05/28/2022 02:12:30 - INFO - __main__ - Step 130 Global step 130 Train loss 1.03 on epoch=9
05/28/2022 02:12:33 - INFO - __main__ - Step 140 Global step 140 Train loss 0.90 on epoch=9
05/28/2022 02:12:35 - INFO - __main__ - Step 150 Global step 150 Train loss 0.83 on epoch=10
05/28/2022 02:12:42 - INFO - __main__ - Global step 150 Train loss 1.04 Classification-F1 0.45960357073543257 on epoch=10
05/28/2022 02:12:42 - INFO - __main__ - Saving model with best Classification-F1: 0.26013214903879867 -> 0.45960357073543257 on epoch=10, global_step=150
05/28/2022 02:12:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.78 on epoch=11
05/28/2022 02:12:47 - INFO - __main__ - Step 170 Global step 170 Train loss 0.72 on epoch=12
05/28/2022 02:12:49 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=12
05/28/2022 02:12:52 - INFO - __main__ - Step 190 Global step 190 Train loss 0.68 on epoch=13
05/28/2022 02:12:55 - INFO - __main__ - Step 200 Global step 200 Train loss 0.70 on epoch=14
05/28/2022 02:13:02 - INFO - __main__ - Global step 200 Train loss 0.71 Classification-F1 0.3991725348381695 on epoch=14
05/28/2022 02:13:05 - INFO - __main__ - Step 210 Global step 210 Train loss 0.63 on epoch=14
05/28/2022 02:13:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.58 on epoch=15
05/28/2022 02:13:10 - INFO - __main__ - Step 230 Global step 230 Train loss 0.51 on epoch=16
05/28/2022 02:13:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.50 on epoch=17
05/28/2022 02:13:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.56 on epoch=17
05/28/2022 02:13:22 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.6020656828585024 on epoch=17
05/28/2022 02:13:22 - INFO - __main__ - Saving model with best Classification-F1: 0.45960357073543257 -> 0.6020656828585024 on epoch=17, global_step=250
05/28/2022 02:13:25 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=18
05/28/2022 02:13:27 - INFO - __main__ - Step 270 Global step 270 Train loss 0.52 on epoch=19
05/28/2022 02:13:30 - INFO - __main__ - Step 280 Global step 280 Train loss 0.48 on epoch=19
05/28/2022 02:13:33 - INFO - __main__ - Step 290 Global step 290 Train loss 0.57 on epoch=20
05/28/2022 02:13:35 - INFO - __main__ - Step 300 Global step 300 Train loss 0.42 on epoch=21
05/28/2022 02:13:42 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.6374633708225039 on epoch=21
05/28/2022 02:13:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6020656828585024 -> 0.6374633708225039 on epoch=21, global_step=300
05/28/2022 02:13:45 - INFO - __main__ - Step 310 Global step 310 Train loss 0.41 on epoch=22
05/28/2022 02:13:48 - INFO - __main__ - Step 320 Global step 320 Train loss 0.47 on epoch=22
05/28/2022 02:13:50 - INFO - __main__ - Step 330 Global step 330 Train loss 0.43 on epoch=23
05/28/2022 02:13:53 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=24
05/28/2022 02:13:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=24
05/28/2022 02:14:03 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.8471828119882991 on epoch=24
05/28/2022 02:14:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6374633708225039 -> 0.8471828119882991 on epoch=24, global_step=350
05/28/2022 02:14:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=25
05/28/2022 02:14:08 - INFO - __main__ - Step 370 Global step 370 Train loss 0.40 on epoch=26
05/28/2022 02:14:10 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=27
05/28/2022 02:14:13 - INFO - __main__ - Step 390 Global step 390 Train loss 0.37 on epoch=27
05/28/2022 02:14:16 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=28
05/28/2022 02:14:22 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.6345838834058929 on epoch=28
05/28/2022 02:14:25 - INFO - __main__ - Step 410 Global step 410 Train loss 0.35 on epoch=29
05/28/2022 02:14:28 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=29
05/28/2022 02:14:30 - INFO - __main__ - Step 430 Global step 430 Train loss 0.31 on epoch=30
05/28/2022 02:14:33 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=31
05/28/2022 02:14:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=32
05/28/2022 02:14:43 - INFO - __main__ - Global step 450 Train loss 0.30 Classification-F1 0.857710541248143 on epoch=32
05/28/2022 02:14:43 - INFO - __main__ - Saving model with best Classification-F1: 0.8471828119882991 -> 0.857710541248143 on epoch=32, global_step=450
05/28/2022 02:14:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=32
05/28/2022 02:14:48 - INFO - __main__ - Step 470 Global step 470 Train loss 0.28 on epoch=33
05/28/2022 02:14:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.34 on epoch=34
05/28/2022 02:14:53 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=34
05/28/2022 02:14:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.36 on epoch=35
05/28/2022 02:15:02 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.8050434363923209 on epoch=35
05/28/2022 02:15:05 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=36
05/28/2022 02:15:07 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=37
05/28/2022 02:15:10 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=37
05/28/2022 02:15:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=38
05/28/2022 02:15:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=39
05/28/2022 02:15:22 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.8479758409254529 on epoch=39
05/28/2022 02:15:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=39
05/28/2022 02:15:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=40
05/28/2022 02:15:30 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=41
05/28/2022 02:15:33 - INFO - __main__ - Step 590 Global step 590 Train loss 0.27 on epoch=42
05/28/2022 02:15:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=42
05/28/2022 02:15:42 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.8174402092568988 on epoch=42
05/28/2022 02:15:44 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=43
05/28/2022 02:15:47 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=44
05/28/2022 02:15:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=44
05/28/2022 02:15:52 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=45
05/28/2022 02:15:55 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=46
05/28/2022 02:16:02 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.7990487761286234 on epoch=46
05/28/2022 02:16:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=47
05/28/2022 02:16:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=47
05/28/2022 02:16:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=48
05/28/2022 02:16:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.24 on epoch=49
05/28/2022 02:16:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.25 on epoch=49
05/28/2022 02:16:22 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.8800862220718779 on epoch=49
05/28/2022 02:16:22 - INFO - __main__ - Saving model with best Classification-F1: 0.857710541248143 -> 0.8800862220718779 on epoch=49, global_step=700
05/28/2022 02:16:25 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=50
05/28/2022 02:16:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=51
05/28/2022 02:16:30 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=52
05/28/2022 02:16:32 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=52
05/28/2022 02:16:35 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=53
05/28/2022 02:16:42 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.86633290331447 on epoch=53
05/28/2022 02:16:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=54
05/28/2022 02:16:47 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=54
05/28/2022 02:16:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=55
05/28/2022 02:16:52 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=56
05/28/2022 02:16:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=57
05/28/2022 02:17:02 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.8184346402203696 on epoch=57
05/28/2022 02:17:04 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=57
05/28/2022 02:17:07 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=58
05/28/2022 02:17:10 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=59
05/28/2022 02:17:12 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=59
05/28/2022 02:17:15 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=60
05/28/2022 02:17:22 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.7210232060510148 on epoch=60
05/28/2022 02:17:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=61
05/28/2022 02:17:27 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=62
05/28/2022 02:17:29 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=62
05/28/2022 02:17:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=63
05/28/2022 02:17:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=64
05/28/2022 02:17:42 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.7629792320950787 on epoch=64
05/28/2022 02:17:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=64
05/28/2022 02:17:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=65
05/28/2022 02:17:49 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=66
05/28/2022 02:17:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=67
05/28/2022 02:17:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=67
05/28/2022 02:18:01 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.7153386606931481 on epoch=67
05/28/2022 02:18:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
05/28/2022 02:18:06 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
05/28/2022 02:18:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=69
05/28/2022 02:18:11 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=70
05/28/2022 02:18:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
05/28/2022 02:18:21 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.7452974444909929 on epoch=71
05/28/2022 02:18:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
05/28/2022 02:18:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=72
05/28/2022 02:18:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=73
05/28/2022 02:18:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=74
05/28/2022 02:18:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=74
05/28/2022 02:18:40 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.8436784683864773 on epoch=74
05/28/2022 02:18:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
05/28/2022 02:18:45 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=76
05/28/2022 02:18:48 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=77
05/28/2022 02:18:50 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
05/28/2022 02:18:53 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=78
05/28/2022 02:18:59 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.7457322169804639 on epoch=78
05/28/2022 02:19:02 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
05/28/2022 02:19:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
05/28/2022 02:19:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
05/28/2022 02:19:09 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=81
05/28/2022 02:19:12 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=82
05/28/2022 02:19:19 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.6590895607914519 on epoch=82
05/28/2022 02:19:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=82
05/28/2022 02:19:24 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=83
05/28/2022 02:19:26 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
05/28/2022 02:19:29 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
05/28/2022 02:19:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
05/28/2022 02:19:37 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.5788801625862645 on epoch=85
05/28/2022 02:19:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
05/28/2022 02:19:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
05/28/2022 02:19:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
05/28/2022 02:19:48 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=88
05/28/2022 02:19:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
05/28/2022 02:19:57 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.5644708612373376 on epoch=89
05/28/2022 02:19:59 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
05/28/2022 02:20:02 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
05/28/2022 02:20:04 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
05/28/2022 02:20:07 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
05/28/2022 02:20:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=92
05/28/2022 02:20:16 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.6123162802110171 on epoch=92
05/28/2022 02:20:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
05/28/2022 02:20:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
05/28/2022 02:20:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
05/28/2022 02:20:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
05/28/2022 02:20:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
05/28/2022 02:20:35 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7013089751862681 on epoch=96
05/28/2022 02:20:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
05/28/2022 02:20:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
05/28/2022 02:20:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
05/28/2022 02:20:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
05/28/2022 02:20:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
05/28/2022 02:20:54 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7657695022593929 on epoch=99
05/28/2022 02:20:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
05/28/2022 02:20:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
05/28/2022 02:21:02 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
05/28/2022 02:21:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
05/28/2022 02:21:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
05/28/2022 02:21:13 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.77459605543097 on epoch=103
05/28/2022 02:21:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
05/28/2022 02:21:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
05/28/2022 02:21:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
05/28/2022 02:21:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=106
05/28/2022 02:21:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
05/28/2022 02:21:32 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7493080007576604 on epoch=107
05/28/2022 02:21:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
05/28/2022 02:21:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
05/28/2022 02:21:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=109
05/28/2022 02:21:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
05/28/2022 02:21:45 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
05/28/2022 02:21:51 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7333990601779976 on epoch=110
05/28/2022 02:21:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=111
05/28/2022 02:21:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
05/28/2022 02:21:59 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
05/28/2022 02:22:02 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
05/28/2022 02:22:04 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
05/28/2022 02:22:10 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7402521419124836 on epoch=114
05/28/2022 02:22:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
05/28/2022 02:22:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
05/28/2022 02:22:18 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
05/28/2022 02:22:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
05/28/2022 02:22:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
05/28/2022 02:22:29 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8007855775496905 on epoch=117
05/28/2022 02:22:32 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=118
05/28/2022 02:22:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
05/28/2022 02:22:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
05/28/2022 02:22:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
05/28/2022 02:22:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=121
05/28/2022 02:22:48 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.7440551147145075 on epoch=121
05/28/2022 02:22:51 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
05/28/2022 02:22:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
05/28/2022 02:22:56 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
05/28/2022 02:22:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
05/28/2022 02:23:01 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
05/28/2022 02:23:07 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8629053022316779 on epoch=124
05/28/2022 02:23:10 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=125
05/28/2022 02:23:13 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
05/28/2022 02:23:15 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
05/28/2022 02:23:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
05/28/2022 02:23:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=128
05/28/2022 02:23:27 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.6651516710873598 on epoch=128
05/28/2022 02:23:30 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
05/28/2022 02:23:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
05/28/2022 02:23:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/28/2022 02:23:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
05/28/2022 02:23:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
05/28/2022 02:23:46 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7468009568843925 on epoch=132
05/28/2022 02:23:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
05/28/2022 02:23:51 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
05/28/2022 02:23:54 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
05/28/2022 02:23:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
05/28/2022 02:23:59 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/28/2022 02:24:05 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7758649794228542 on epoch=135
05/28/2022 02:24:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
05/28/2022 02:24:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/28/2022 02:24:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
05/28/2022 02:24:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
05/28/2022 02:24:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
05/28/2022 02:24:25 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8970745589009347 on epoch=139
05/28/2022 02:24:25 - INFO - __main__ - Saving model with best Classification-F1: 0.8800862220718779 -> 0.8970745589009347 on epoch=139, global_step=1950
05/28/2022 02:24:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
05/28/2022 02:24:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
05/28/2022 02:24:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
05/28/2022 02:24:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
05/28/2022 02:24:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
05/28/2022 02:24:45 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8143398785177753 on epoch=142
05/28/2022 02:24:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
05/28/2022 02:24:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
05/28/2022 02:24:52 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
05/28/2022 02:24:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
05/28/2022 02:24:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/28/2022 02:25:04 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8822824066087823 on epoch=146
05/28/2022 02:25:06 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
05/28/2022 02:25:09 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
05/28/2022 02:25:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
05/28/2022 02:25:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
05/28/2022 02:25:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
05/28/2022 02:25:23 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8251396645535047 on epoch=149
05/28/2022 02:25:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/28/2022 02:25:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
05/28/2022 02:25:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
05/28/2022 02:25:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
05/28/2022 02:25:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
05/28/2022 02:25:42 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8480864144289193 on epoch=153
05/28/2022 02:25:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
05/28/2022 02:25:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/28/2022 02:25:50 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/28/2022 02:25:52 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
05/28/2022 02:25:55 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/28/2022 02:26:01 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8352589920323605 on epoch=157
05/28/2022 02:26:04 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
05/28/2022 02:26:06 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
05/28/2022 02:26:09 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=159
05/28/2022 02:26:12 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
05/28/2022 02:26:14 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
05/28/2022 02:26:20 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7643608763153356 on epoch=160
05/28/2022 02:26:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
05/28/2022 02:26:26 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
05/28/2022 02:26:28 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
05/28/2022 02:26:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
05/28/2022 02:26:33 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.08 on epoch=164
05/28/2022 02:26:39 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7761028898362864 on epoch=164
05/28/2022 02:26:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
05/28/2022 02:26:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
05/28/2022 02:26:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
05/28/2022 02:26:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
05/28/2022 02:26:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/28/2022 02:26:59 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7513241297899184 on epoch=167
05/28/2022 02:27:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
05/28/2022 02:27:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
05/28/2022 02:27:07 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
05/28/2022 02:27:10 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
05/28/2022 02:27:12 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/28/2022 02:27:19 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8350184311819207 on epoch=171
05/28/2022 02:27:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
05/28/2022 02:27:24 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
05/28/2022 02:27:26 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=173
05/28/2022 02:27:29 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/28/2022 02:27:32 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/28/2022 02:27:37 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.774308858440737 on epoch=174
05/28/2022 02:27:40 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/28/2022 02:27:43 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/28/2022 02:27:45 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
05/28/2022 02:27:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=177
05/28/2022 02:27:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/28/2022 02:27:57 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7875337818411822 on epoch=178
05/28/2022 02:27:59 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
05/28/2022 02:28:02 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
05/28/2022 02:28:05 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/28/2022 02:28:07 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=181
05/28/2022 02:28:10 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
05/28/2022 02:28:16 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8369269704407327 on epoch=182
05/28/2022 02:28:19 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/28/2022 02:28:21 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/28/2022 02:28:24 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
05/28/2022 02:28:26 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/28/2022 02:28:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
05/28/2022 02:28:35 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9072494735919783 on epoch=185
05/28/2022 02:28:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8970745589009347 -> 0.9072494735919783 on epoch=185, global_step=2600
05/28/2022 02:28:38 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/28/2022 02:28:40 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
05/28/2022 02:28:43 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
05/28/2022 02:28:45 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
05/28/2022 02:28:48 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
05/28/2022 02:28:54 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7716060031050543 on epoch=189
05/28/2022 02:28:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/28/2022 02:29:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
05/28/2022 02:29:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
05/28/2022 02:29:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
05/28/2022 02:29:07 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=192
05/28/2022 02:29:13 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7722451343556407 on epoch=192
05/28/2022 02:29:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
05/28/2022 02:29:19 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
05/28/2022 02:29:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/28/2022 02:29:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/28/2022 02:29:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
05/28/2022 02:29:33 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8289459616324535 on epoch=196
05/28/2022 02:29:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/28/2022 02:29:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
05/28/2022 02:29:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/28/2022 02:29:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
05/28/2022 02:29:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/28/2022 02:29:52 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7220512996404338 on epoch=199
05/28/2022 02:29:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/28/2022 02:29:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
05/28/2022 02:29:59 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/28/2022 02:30:02 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
05/28/2022 02:30:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
05/28/2022 02:30:11 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7666524427335373 on epoch=203
05/28/2022 02:30:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
05/28/2022 02:30:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
05/28/2022 02:30:19 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/28/2022 02:30:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
05/28/2022 02:30:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/28/2022 02:30:30 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7685686637674054 on epoch=207
05/28/2022 02:30:33 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
05/28/2022 02:30:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/28/2022 02:30:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/28/2022 02:30:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
05/28/2022 02:30:43 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/28/2022 02:30:49 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7658501523776666 on epoch=210
05/28/2022 02:30:52 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/28/2022 02:30:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/28/2022 02:30:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/28/2022 02:31:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/28/2022 02:31:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
05/28/2022 02:31:04 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 02:31:04 - INFO - __main__ - Printing 3 examples
05/28/2022 02:31:04 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 02:31:04 - INFO - __main__ - ['Plant']
05/28/2022 02:31:04 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 02:31:04 - INFO - __main__ - ['Plant']
05/28/2022 02:31:04 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 02:31:04 - INFO - __main__ - ['Plant']
05/28/2022 02:31:04 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:31:04 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:31:04 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 02:31:04 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 02:31:04 - INFO - __main__ - Printing 3 examples
05/28/2022 02:31:04 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/28/2022 02:31:04 - INFO - __main__ - ['Plant']
05/28/2022 02:31:04 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/28/2022 02:31:04 - INFO - __main__ - ['Plant']
05/28/2022 02:31:04 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/28/2022 02:31:04 - INFO - __main__ - ['Plant']
05/28/2022 02:31:04 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:31:04 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:31:05 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 02:31:09 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7508246602648879 on epoch=214
05/28/2022 02:31:09 - INFO - __main__ - save last model!
05/28/2022 02:31:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 02:31:09 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 02:31:09 - INFO - __main__ - Printing 3 examples
05/28/2022 02:31:09 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 02:31:09 - INFO - __main__ - ['Animal']
05/28/2022 02:31:09 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 02:31:09 - INFO - __main__ - ['Animal']
05/28/2022 02:31:09 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 02:31:09 - INFO - __main__ - ['Village']
05/28/2022 02:31:09 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:31:11 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:31:14 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 02:31:22 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 02:31:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 02:31:22 - INFO - __main__ - Starting training!
05/28/2022 02:33:20 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
05/28/2022 02:33:20 - INFO - __main__ - Classification-F1 on test data: 0.5276
05/28/2022 02:33:21 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.9072494735919783, test_performance=0.5275907879287375
05/28/2022 02:33:21 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
05/28/2022 02:33:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 02:33:22 - INFO - __main__ - Printing 3 examples
05/28/2022 02:33:22 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/28/2022 02:33:22 - INFO - __main__ - ['Plant']
05/28/2022 02:33:22 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/28/2022 02:33:22 - INFO - __main__ - ['Plant']
05/28/2022 02:33:22 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/28/2022 02:33:22 - INFO - __main__ - ['Plant']
05/28/2022 02:33:22 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:33:22 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:33:22 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 02:33:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 02:33:22 - INFO - __main__ - Printing 3 examples
05/28/2022 02:33:22 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/28/2022 02:33:22 - INFO - __main__ - ['Plant']
05/28/2022 02:33:22 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/28/2022 02:33:22 - INFO - __main__ - ['Plant']
05/28/2022 02:33:22 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/28/2022 02:33:22 - INFO - __main__ - ['Plant']
05/28/2022 02:33:22 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:33:22 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:33:23 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 02:33:41 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 02:33:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 02:33:42 - INFO - __main__ - Starting training!
05/28/2022 02:33:45 - INFO - __main__ - Step 10 Global step 10 Train loss 8.15 on epoch=0
05/28/2022 02:33:48 - INFO - __main__ - Step 20 Global step 20 Train loss 5.66 on epoch=1
05/28/2022 02:33:50 - INFO - __main__ - Step 30 Global step 30 Train loss 4.72 on epoch=2
05/28/2022 02:33:53 - INFO - __main__ - Step 40 Global step 40 Train loss 3.98 on epoch=2
05/28/2022 02:33:56 - INFO - __main__ - Step 50 Global step 50 Train loss 3.53 on epoch=3
05/28/2022 02:34:02 - INFO - __main__ - Global step 50 Train loss 5.21 Classification-F1 0.02086956521739131 on epoch=3
05/28/2022 02:34:02 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.02086956521739131 on epoch=3, global_step=50
05/28/2022 02:34:04 - INFO - __main__ - Step 60 Global step 60 Train loss 3.21 on epoch=4
05/28/2022 02:34:07 - INFO - __main__ - Step 70 Global step 70 Train loss 2.94 on epoch=4
05/28/2022 02:34:10 - INFO - __main__ - Step 80 Global step 80 Train loss 2.64 on epoch=5
05/28/2022 02:34:12 - INFO - __main__ - Step 90 Global step 90 Train loss 2.20 on epoch=6
05/28/2022 02:34:15 - INFO - __main__ - Step 100 Global step 100 Train loss 2.20 on epoch=7
05/28/2022 02:34:21 - INFO - __main__ - Global step 100 Train loss 2.64 Classification-F1 0.08651283357165711 on epoch=7
05/28/2022 02:34:21 - INFO - __main__ - Saving model with best Classification-F1: 0.02086956521739131 -> 0.08651283357165711 on epoch=7, global_step=100
05/28/2022 02:34:24 - INFO - __main__ - Step 110 Global step 110 Train loss 1.87 on epoch=7
05/28/2022 02:34:26 - INFO - __main__ - Step 120 Global step 120 Train loss 1.67 on epoch=8
05/28/2022 02:34:29 - INFO - __main__ - Step 130 Global step 130 Train loss 1.53 on epoch=9
05/28/2022 02:34:32 - INFO - __main__ - Step 140 Global step 140 Train loss 1.42 on epoch=9
05/28/2022 02:34:34 - INFO - __main__ - Step 150 Global step 150 Train loss 1.28 on epoch=10
05/28/2022 02:34:40 - INFO - __main__ - Global step 150 Train loss 1.55 Classification-F1 0.31907101781927205 on epoch=10
05/28/2022 02:34:40 - INFO - __main__ - Saving model with best Classification-F1: 0.08651283357165711 -> 0.31907101781927205 on epoch=10, global_step=150
05/28/2022 02:34:43 - INFO - __main__ - Step 160 Global step 160 Train loss 1.02 on epoch=11
05/28/2022 02:34:45 - INFO - __main__ - Step 170 Global step 170 Train loss 1.08 on epoch=12
05/28/2022 02:34:48 - INFO - __main__ - Step 180 Global step 180 Train loss 1.07 on epoch=12
05/28/2022 02:34:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.83 on epoch=13
05/28/2022 02:34:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.94 on epoch=14
05/28/2022 02:35:01 - INFO - __main__ - Global step 200 Train loss 0.99 Classification-F1 0.41430490515190227 on epoch=14
05/28/2022 02:35:01 - INFO - __main__ - Saving model with best Classification-F1: 0.31907101781927205 -> 0.41430490515190227 on epoch=14, global_step=200
05/28/2022 02:35:04 - INFO - __main__ - Step 210 Global step 210 Train loss 0.88 on epoch=14
05/28/2022 02:35:06 - INFO - __main__ - Step 220 Global step 220 Train loss 0.73 on epoch=15
05/28/2022 02:35:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.74 on epoch=16
05/28/2022 02:35:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.80 on epoch=17
05/28/2022 02:35:14 - INFO - __main__ - Step 250 Global step 250 Train loss 0.78 on epoch=17
05/28/2022 02:35:21 - INFO - __main__ - Global step 250 Train loss 0.79 Classification-F1 0.49777311243476646 on epoch=17
05/28/2022 02:35:21 - INFO - __main__ - Saving model with best Classification-F1: 0.41430490515190227 -> 0.49777311243476646 on epoch=17, global_step=250
05/28/2022 02:35:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.68 on epoch=18
05/28/2022 02:35:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.69 on epoch=19
05/28/2022 02:35:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.66 on epoch=19
05/28/2022 02:35:32 - INFO - __main__ - Step 290 Global step 290 Train loss 0.61 on epoch=20
05/28/2022 02:35:34 - INFO - __main__ - Step 300 Global step 300 Train loss 0.66 on epoch=21
05/28/2022 02:35:41 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.4034533403394018 on epoch=21
05/28/2022 02:35:44 - INFO - __main__ - Step 310 Global step 310 Train loss 0.61 on epoch=22
05/28/2022 02:35:47 - INFO - __main__ - Step 320 Global step 320 Train loss 0.59 on epoch=22
05/28/2022 02:35:49 - INFO - __main__ - Step 330 Global step 330 Train loss 0.58 on epoch=23
05/28/2022 02:35:52 - INFO - __main__ - Step 340 Global step 340 Train loss 0.51 on epoch=24
05/28/2022 02:35:54 - INFO - __main__ - Step 350 Global step 350 Train loss 0.54 on epoch=24
05/28/2022 02:36:02 - INFO - __main__ - Global step 350 Train loss 0.56 Classification-F1 0.45588923118560587 on epoch=24
05/28/2022 02:36:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.55 on epoch=25
05/28/2022 02:36:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.55 on epoch=26
05/28/2022 02:36:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.45 on epoch=27
05/28/2022 02:36:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.48 on epoch=27
05/28/2022 02:36:15 - INFO - __main__ - Step 400 Global step 400 Train loss 0.46 on epoch=28
05/28/2022 02:36:22 - INFO - __main__ - Global step 400 Train loss 0.50 Classification-F1 0.5558896708700097 on epoch=28
05/28/2022 02:36:22 - INFO - __main__ - Saving model with best Classification-F1: 0.49777311243476646 -> 0.5558896708700097 on epoch=28, global_step=400
05/28/2022 02:36:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.52 on epoch=29
05/28/2022 02:36:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.45 on epoch=29
05/28/2022 02:36:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.39 on epoch=30
05/28/2022 02:36:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=31
05/28/2022 02:36:34 - INFO - __main__ - Step 450 Global step 450 Train loss 0.49 on epoch=32
05/28/2022 02:36:42 - INFO - __main__ - Global step 450 Train loss 0.45 Classification-F1 0.5845051490782041 on epoch=32
05/28/2022 02:36:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5558896708700097 -> 0.5845051490782041 on epoch=32, global_step=450
05/28/2022 02:36:44 - INFO - __main__ - Step 460 Global step 460 Train loss 0.33 on epoch=32
05/28/2022 02:36:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=33
05/28/2022 02:36:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.36 on epoch=34
05/28/2022 02:36:52 - INFO - __main__ - Step 490 Global step 490 Train loss 0.33 on epoch=34
05/28/2022 02:36:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.41 on epoch=35
05/28/2022 02:37:01 - INFO - __main__ - Global step 500 Train loss 0.36 Classification-F1 0.5548080280433968 on epoch=35
05/28/2022 02:37:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.31 on epoch=36
05/28/2022 02:37:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.41 on epoch=37
05/28/2022 02:37:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.48 on epoch=37
05/28/2022 02:37:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.43 on epoch=38
05/28/2022 02:37:14 - INFO - __main__ - Step 550 Global step 550 Train loss 0.43 on epoch=39
05/28/2022 02:37:21 - INFO - __main__ - Global step 550 Train loss 0.41 Classification-F1 0.7828766731534512 on epoch=39
05/28/2022 02:37:21 - INFO - __main__ - Saving model with best Classification-F1: 0.5845051490782041 -> 0.7828766731534512 on epoch=39, global_step=550
05/28/2022 02:37:24 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=39
05/28/2022 02:37:26 - INFO - __main__ - Step 570 Global step 570 Train loss 0.33 on epoch=40
05/28/2022 02:37:29 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=41
05/28/2022 02:37:32 - INFO - __main__ - Step 590 Global step 590 Train loss 0.35 on epoch=42
05/28/2022 02:37:34 - INFO - __main__ - Step 600 Global step 600 Train loss 0.31 on epoch=42
05/28/2022 02:37:41 - INFO - __main__ - Global step 600 Train loss 0.34 Classification-F1 0.728145093021074 on epoch=42
05/28/2022 02:37:44 - INFO - __main__ - Step 610 Global step 610 Train loss 0.31 on epoch=43
05/28/2022 02:37:47 - INFO - __main__ - Step 620 Global step 620 Train loss 0.36 on epoch=44
05/28/2022 02:37:49 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=44
05/28/2022 02:37:52 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=45
05/28/2022 02:37:54 - INFO - __main__ - Step 650 Global step 650 Train loss 0.28 on epoch=46
05/28/2022 02:38:02 - INFO - __main__ - Global step 650 Train loss 0.29 Classification-F1 0.8038033815564406 on epoch=46
05/28/2022 02:38:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7828766731534512 -> 0.8038033815564406 on epoch=46, global_step=650
05/28/2022 02:38:04 - INFO - __main__ - Step 660 Global step 660 Train loss 0.32 on epoch=47
05/28/2022 02:38:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.26 on epoch=47
05/28/2022 02:38:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.29 on epoch=48
05/28/2022 02:38:12 - INFO - __main__ - Step 690 Global step 690 Train loss 0.29 on epoch=49
05/28/2022 02:38:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=49
05/28/2022 02:38:22 - INFO - __main__ - Global step 700 Train loss 0.28 Classification-F1 0.7970622061435527 on epoch=49
05/28/2022 02:38:25 - INFO - __main__ - Step 710 Global step 710 Train loss 0.33 on epoch=50
05/28/2022 02:38:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.29 on epoch=51
05/28/2022 02:38:30 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=52
05/28/2022 02:38:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=52
05/28/2022 02:38:35 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=53
05/28/2022 02:38:42 - INFO - __main__ - Global step 750 Train loss 0.27 Classification-F1 0.796622486268349 on epoch=53
05/28/2022 02:38:45 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=54
05/28/2022 02:38:47 - INFO - __main__ - Step 770 Global step 770 Train loss 0.28 on epoch=54
05/28/2022 02:38:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.27 on epoch=55
05/28/2022 02:38:52 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=56
05/28/2022 02:38:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.28 on epoch=57
05/28/2022 02:39:02 - INFO - __main__ - Global step 800 Train loss 0.25 Classification-F1 0.7455921140519881 on epoch=57
05/28/2022 02:39:04 - INFO - __main__ - Step 810 Global step 810 Train loss 0.26 on epoch=57
05/28/2022 02:39:07 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=58
05/28/2022 02:39:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=59
05/28/2022 02:39:12 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=59
05/28/2022 02:39:15 - INFO - __main__ - Step 850 Global step 850 Train loss 0.24 on epoch=60
05/28/2022 02:39:21 - INFO - __main__ - Global step 850 Train loss 0.22 Classification-F1 0.9091922926024308 on epoch=60
05/28/2022 02:39:21 - INFO - __main__ - Saving model with best Classification-F1: 0.8038033815564406 -> 0.9091922926024308 on epoch=60, global_step=850
05/28/2022 02:39:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=61
05/28/2022 02:39:27 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=62
05/28/2022 02:39:29 - INFO - __main__ - Step 880 Global step 880 Train loss 0.23 on epoch=62
05/28/2022 02:39:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.20 on epoch=63
05/28/2022 02:39:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=64
05/28/2022 02:39:41 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.7641603721000523 on epoch=64
05/28/2022 02:39:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=64
05/28/2022 02:39:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.25 on epoch=65
05/28/2022 02:39:49 - INFO - __main__ - Step 930 Global step 930 Train loss 0.26 on epoch=66
05/28/2022 02:39:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=67
05/28/2022 02:39:55 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=67
05/28/2022 02:40:02 - INFO - __main__ - Global step 950 Train loss 0.21 Classification-F1 0.8586404456404456 on epoch=67
05/28/2022 02:40:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=68
05/28/2022 02:40:07 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=69
05/28/2022 02:40:10 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=69
05/28/2022 02:40:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=70
05/28/2022 02:40:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.18 on epoch=71
05/28/2022 02:40:22 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.8461572336663902 on epoch=71
05/28/2022 02:40:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=72
05/28/2022 02:40:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=72
05/28/2022 02:40:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=73
05/28/2022 02:40:32 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=74
05/28/2022 02:40:35 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.20 on epoch=74
05/28/2022 02:40:42 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.79679991768277 on epoch=74
05/28/2022 02:40:44 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=75
05/28/2022 02:40:47 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=76
05/28/2022 02:40:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=77
05/28/2022 02:40:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=77
05/28/2022 02:40:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=78
05/28/2022 02:41:01 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.9638495305257978 on epoch=78
05/28/2022 02:41:01 - INFO - __main__ - Saving model with best Classification-F1: 0.9091922926024308 -> 0.9638495305257978 on epoch=78, global_step=1100
05/28/2022 02:41:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
05/28/2022 02:41:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=79
05/28/2022 02:41:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=80
05/28/2022 02:41:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=81
05/28/2022 02:41:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=82
05/28/2022 02:41:21 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.8626832026832026 on epoch=82
05/28/2022 02:41:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
05/28/2022 02:41:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=83
05/28/2022 02:41:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=84
05/28/2022 02:41:31 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=84
05/28/2022 02:41:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
05/28/2022 02:41:40 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.6912136081429043 on epoch=85
05/28/2022 02:41:43 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=86
05/28/2022 02:41:46 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=87
05/28/2022 02:41:48 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=87
05/28/2022 02:41:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
05/28/2022 02:41:53 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=89
05/28/2022 02:42:00 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.7650446398074481 on epoch=89
05/28/2022 02:42:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=89
05/28/2022 02:42:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=90
05/28/2022 02:42:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=91
05/28/2022 02:42:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=92
05/28/2022 02:42:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=92
05/28/2022 02:42:20 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.8161599924704763 on epoch=92
05/28/2022 02:42:22 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=93
05/28/2022 02:42:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=94
05/28/2022 02:42:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
05/28/2022 02:42:30 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=95
05/28/2022 02:42:33 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=96
05/28/2022 02:42:39 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.8714098804421385 on epoch=96
05/28/2022 02:42:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
05/28/2022 02:42:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=97
05/28/2022 02:42:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=98
05/28/2022 02:42:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=99
05/28/2022 02:42:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
05/28/2022 02:42:59 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.8805509397556117 on epoch=99
05/28/2022 02:43:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
05/28/2022 02:43:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=101
05/28/2022 02:43:07 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
05/28/2022 02:43:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
05/28/2022 02:43:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=103
05/28/2022 02:43:18 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.8727489953296406 on epoch=103
05/28/2022 02:43:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=104
05/28/2022 02:43:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
05/28/2022 02:43:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=105
05/28/2022 02:43:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=106
05/28/2022 02:43:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
05/28/2022 02:43:38 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.8800206332777489 on epoch=107
05/28/2022 02:43:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
05/28/2022 02:43:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
05/28/2022 02:43:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=109
05/28/2022 02:43:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
05/28/2022 02:43:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=110
05/28/2022 02:43:57 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.6782989452976802 on epoch=110
05/28/2022 02:44:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
05/28/2022 02:44:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
05/28/2022 02:44:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
05/28/2022 02:44:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
05/28/2022 02:44:10 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.15 on epoch=114
05/28/2022 02:44:16 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.6804906243336285 on epoch=114
05/28/2022 02:44:19 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=114
05/28/2022 02:44:21 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=115
05/28/2022 02:44:24 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=116
05/28/2022 02:44:27 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
05/28/2022 02:44:29 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=117
05/28/2022 02:44:35 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.7877726356304985 on epoch=117
05/28/2022 02:44:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.11 on epoch=118
05/28/2022 02:44:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
05/28/2022 02:44:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
05/28/2022 02:44:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=120
05/28/2022 02:44:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=121
05/28/2022 02:44:55 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.7561822412249357 on epoch=121
05/28/2022 02:44:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
05/28/2022 02:45:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=122
05/28/2022 02:45:02 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
05/28/2022 02:45:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
05/28/2022 02:45:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
05/28/2022 02:45:14 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.8821766047572498 on epoch=124
05/28/2022 02:45:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.14 on epoch=125
05/28/2022 02:45:19 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
05/28/2022 02:45:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=127
05/28/2022 02:45:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=127
05/28/2022 02:45:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
05/28/2022 02:45:33 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.8018700578161561 on epoch=128
05/28/2022 02:45:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
05/28/2022 02:45:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
05/28/2022 02:45:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
05/28/2022 02:45:43 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
05/28/2022 02:45:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
05/28/2022 02:45:52 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8323359167714006 on epoch=132
05/28/2022 02:45:55 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
05/28/2022 02:45:57 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
05/28/2022 02:46:00 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
05/28/2022 02:46:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=134
05/28/2022 02:46:05 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
05/28/2022 02:46:11 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.768161039836171 on epoch=135
05/28/2022 02:46:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.16 on epoch=136
05/28/2022 02:46:17 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
05/28/2022 02:46:19 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
05/28/2022 02:46:22 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
05/28/2022 02:46:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=139
05/28/2022 02:46:31 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.7695886139993107 on epoch=139
05/28/2022 02:46:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=139
05/28/2022 02:46:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
05/28/2022 02:46:38 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=141
05/28/2022 02:46:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
05/28/2022 02:46:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
05/28/2022 02:46:50 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8867762581678512 on epoch=142
05/28/2022 02:46:53 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=143
05/28/2022 02:46:55 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=144
05/28/2022 02:46:58 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
05/28/2022 02:47:00 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
05/28/2022 02:47:03 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
05/28/2022 02:47:09 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8193844696969697 on epoch=146
05/28/2022 02:47:12 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/28/2022 02:47:14 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
05/28/2022 02:47:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
05/28/2022 02:47:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=149
05/28/2022 02:47:22 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
05/28/2022 02:47:29 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.8022150638537616 on epoch=149
05/28/2022 02:47:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
05/28/2022 02:47:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
05/28/2022 02:47:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
05/28/2022 02:47:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
05/28/2022 02:47:42 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=153
05/28/2022 02:47:48 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.8953280616705664 on epoch=153
05/28/2022 02:47:51 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
05/28/2022 02:47:53 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
05/28/2022 02:47:56 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=155
05/28/2022 02:47:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
05/28/2022 02:48:01 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
05/28/2022 02:48:07 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8155255340976404 on epoch=157
05/28/2022 02:48:10 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
05/28/2022 02:48:12 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
05/28/2022 02:48:15 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
05/28/2022 02:48:18 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=159
05/28/2022 02:48:20 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=160
05/28/2022 02:48:26 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.7809201393167238 on epoch=160
05/28/2022 02:48:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
05/28/2022 02:48:32 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
05/28/2022 02:48:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/28/2022 02:48:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.12 on epoch=163
05/28/2022 02:48:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
05/28/2022 02:48:45 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7770255423914363 on epoch=164
05/28/2022 02:48:48 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
05/28/2022 02:48:51 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
05/28/2022 02:48:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
05/28/2022 02:48:56 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
05/28/2022 02:48:59 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=167
05/28/2022 02:49:05 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.8329970461983085 on epoch=167
05/28/2022 02:49:07 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
05/28/2022 02:49:10 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/28/2022 02:49:13 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
05/28/2022 02:49:15 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
05/28/2022 02:49:18 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
05/28/2022 02:49:24 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8247154726993436 on epoch=171
05/28/2022 02:49:27 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
05/28/2022 02:49:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
05/28/2022 02:49:32 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
05/28/2022 02:49:34 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
05/28/2022 02:49:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
05/28/2022 02:49:43 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8527636188778778 on epoch=174
05/28/2022 02:49:46 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
05/28/2022 02:49:49 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=176
05/28/2022 02:49:51 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
05/28/2022 02:49:54 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/28/2022 02:49:56 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/28/2022 02:50:03 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9024114750711841 on epoch=178
05/28/2022 02:50:05 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.11 on epoch=179
05/28/2022 02:50:08 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
05/28/2022 02:50:10 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
05/28/2022 02:50:13 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
05/28/2022 02:50:16 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
05/28/2022 02:50:22 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.8464202912748171 on epoch=182
05/28/2022 02:50:24 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
05/28/2022 02:50:27 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
05/28/2022 02:50:30 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
05/28/2022 02:50:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=184
05/28/2022 02:50:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.08 on epoch=185
05/28/2022 02:50:41 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.851267627652234 on epoch=185
05/28/2022 02:50:44 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=186
05/28/2022 02:50:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/28/2022 02:50:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
05/28/2022 02:50:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
05/28/2022 02:50:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/28/2022 02:51:01 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.847193208895703 on epoch=189
05/28/2022 02:51:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/28/2022 02:51:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=190
05/28/2022 02:51:09 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.09 on epoch=191
05/28/2022 02:51:11 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=192
05/28/2022 02:51:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
05/28/2022 02:51:20 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.8463943146906856 on epoch=192
05/28/2022 02:51:23 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
05/28/2022 02:51:25 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
05/28/2022 02:51:28 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
05/28/2022 02:51:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/28/2022 02:51:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=196
05/28/2022 02:51:40 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8448060591961801 on epoch=196
05/28/2022 02:51:42 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/28/2022 02:51:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
05/28/2022 02:51:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
05/28/2022 02:51:50 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
05/28/2022 02:51:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/28/2022 02:51:59 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8511562194525905 on epoch=199
05/28/2022 02:52:02 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/28/2022 02:52:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
05/28/2022 02:52:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/28/2022 02:52:10 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/28/2022 02:52:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
05/28/2022 02:52:19 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9018122879650394 on epoch=203
05/28/2022 02:52:21 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
05/28/2022 02:52:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
05/28/2022 02:52:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
05/28/2022 02:52:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
05/28/2022 02:52:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
05/28/2022 02:52:38 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.8436105850168351 on epoch=207
05/28/2022 02:52:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
05/28/2022 02:52:43 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/28/2022 02:52:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
05/28/2022 02:52:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/28/2022 02:52:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.07 on epoch=210
05/28/2022 02:52:58 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8417981120943563 on epoch=210
05/28/2022 02:53:00 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=211
05/28/2022 02:53:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=212
05/28/2022 02:53:06 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
05/28/2022 02:53:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/28/2022 02:53:11 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
05/28/2022 02:53:12 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 02:53:12 - INFO - __main__ - Printing 3 examples
05/28/2022 02:53:12 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 02:53:12 - INFO - __main__ - ['Company']
05/28/2022 02:53:12 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 02:53:12 - INFO - __main__ - ['Company']
05/28/2022 02:53:12 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 02:53:12 - INFO - __main__ - ['Company']
05/28/2022 02:53:12 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:53:12 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:53:13 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 02:53:13 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 02:53:13 - INFO - __main__ - Printing 3 examples
05/28/2022 02:53:13 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/28/2022 02:53:13 - INFO - __main__ - ['Company']
05/28/2022 02:53:13 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/28/2022 02:53:13 - INFO - __main__ - ['Company']
05/28/2022 02:53:13 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/28/2022 02:53:13 - INFO - __main__ - ['Company']
05/28/2022 02:53:13 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:53:13 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:53:13 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 02:53:17 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7952517056979531 on epoch=214
05/28/2022 02:53:17 - INFO - __main__ - save last model!
05/28/2022 02:53:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 02:53:17 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 02:53:17 - INFO - __main__ - Printing 3 examples
05/28/2022 02:53:17 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 02:53:17 - INFO - __main__ - ['Animal']
05/28/2022 02:53:17 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 02:53:17 - INFO - __main__ - ['Animal']
05/28/2022 02:53:17 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 02:53:17 - INFO - __main__ - ['Village']
05/28/2022 02:53:17 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:53:19 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:53:23 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 02:53:29 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 02:53:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 02:53:29 - INFO - __main__ - Starting training!
05/28/2022 02:55:30 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
05/28/2022 02:55:30 - INFO - __main__ - Classification-F1 on test data: 0.5579
05/28/2022 02:55:31 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.9638495305257978, test_performance=0.5578794639199894
05/28/2022 02:55:31 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
05/28/2022 02:55:32 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 02:55:32 - INFO - __main__ - Printing 3 examples
05/28/2022 02:55:32 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 02:55:32 - INFO - __main__ - ['Company']
05/28/2022 02:55:32 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 02:55:32 - INFO - __main__ - ['Company']
05/28/2022 02:55:32 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 02:55:32 - INFO - __main__ - ['Company']
05/28/2022 02:55:32 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:55:32 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:55:32 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 02:55:32 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 02:55:32 - INFO - __main__ - Printing 3 examples
05/28/2022 02:55:32 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/28/2022 02:55:32 - INFO - __main__ - ['Company']
05/28/2022 02:55:32 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/28/2022 02:55:32 - INFO - __main__ - ['Company']
05/28/2022 02:55:32 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/28/2022 02:55:32 - INFO - __main__ - ['Company']
05/28/2022 02:55:32 - INFO - __main__ - Tokenizing Input ...
05/28/2022 02:55:32 - INFO - __main__ - Tokenizing Output ...
05/28/2022 02:55:32 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 02:55:48 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 02:55:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 02:55:49 - INFO - __main__ - Starting training!
05/28/2022 02:55:52 - INFO - __main__ - Step 10 Global step 10 Train loss 6.69 on epoch=0
05/28/2022 02:55:55 - INFO - __main__ - Step 20 Global step 20 Train loss 4.10 on epoch=1
05/28/2022 02:55:57 - INFO - __main__ - Step 30 Global step 30 Train loss 3.23 on epoch=2
05/28/2022 02:56:00 - INFO - __main__ - Step 40 Global step 40 Train loss 2.46 on epoch=2
05/28/2022 02:56:02 - INFO - __main__ - Step 50 Global step 50 Train loss 2.03 on epoch=3
05/28/2022 02:56:07 - INFO - __main__ - Global step 50 Train loss 3.70 Classification-F1 0.13473322460391426 on epoch=3
05/28/2022 02:56:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13473322460391426 on epoch=3, global_step=50
05/28/2022 02:56:10 - INFO - __main__ - Step 60 Global step 60 Train loss 1.57 on epoch=4
05/28/2022 02:56:12 - INFO - __main__ - Step 70 Global step 70 Train loss 1.26 on epoch=4
05/28/2022 02:56:15 - INFO - __main__ - Step 80 Global step 80 Train loss 1.01 on epoch=5
05/28/2022 02:56:17 - INFO - __main__ - Step 90 Global step 90 Train loss 0.87 on epoch=6
05/28/2022 02:56:20 - INFO - __main__ - Step 100 Global step 100 Train loss 0.87 on epoch=7
05/28/2022 02:56:28 - INFO - __main__ - Global step 100 Train loss 1.12 Classification-F1 0.46546066497783356 on epoch=7
05/28/2022 02:56:28 - INFO - __main__ - Saving model with best Classification-F1: 0.13473322460391426 -> 0.46546066497783356 on epoch=7, global_step=100
05/28/2022 02:56:30 - INFO - __main__ - Step 110 Global step 110 Train loss 0.69 on epoch=7
05/28/2022 02:56:33 - INFO - __main__ - Step 120 Global step 120 Train loss 0.67 on epoch=8
05/28/2022 02:56:35 - INFO - __main__ - Step 130 Global step 130 Train loss 0.66 on epoch=9
05/28/2022 02:56:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.67 on epoch=9
05/28/2022 02:56:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.56 on epoch=10
05/28/2022 02:56:47 - INFO - __main__ - Global step 150 Train loss 0.65 Classification-F1 0.5410379630577727 on epoch=10
05/28/2022 02:56:47 - INFO - __main__ - Saving model with best Classification-F1: 0.46546066497783356 -> 0.5410379630577727 on epoch=10, global_step=150
05/28/2022 02:56:50 - INFO - __main__ - Step 160 Global step 160 Train loss 0.51 on epoch=11
05/28/2022 02:56:52 - INFO - __main__ - Step 170 Global step 170 Train loss 0.56 on epoch=12
05/28/2022 02:56:55 - INFO - __main__ - Step 180 Global step 180 Train loss 0.56 on epoch=12
05/28/2022 02:56:57 - INFO - __main__ - Step 190 Global step 190 Train loss 0.53 on epoch=13
05/28/2022 02:57:00 - INFO - __main__ - Step 200 Global step 200 Train loss 0.50 on epoch=14
05/28/2022 02:57:07 - INFO - __main__ - Global step 200 Train loss 0.53 Classification-F1 0.6306608881066613 on epoch=14
05/28/2022 02:57:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5410379630577727 -> 0.6306608881066613 on epoch=14, global_step=200
05/28/2022 02:57:09 - INFO - __main__ - Step 210 Global step 210 Train loss 0.60 on epoch=14
05/28/2022 02:57:12 - INFO - __main__ - Step 220 Global step 220 Train loss 0.44 on epoch=15
05/28/2022 02:57:14 - INFO - __main__ - Step 230 Global step 230 Train loss 0.55 on epoch=16
05/28/2022 02:57:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.47 on epoch=17
05/28/2022 02:57:19 - INFO - __main__ - Step 250 Global step 250 Train loss 0.39 on epoch=17
05/28/2022 02:57:25 - INFO - __main__ - Global step 250 Train loss 0.49 Classification-F1 0.6743231400532766 on epoch=17
05/28/2022 02:57:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6306608881066613 -> 0.6743231400532766 on epoch=17, global_step=250
05/28/2022 02:57:28 - INFO - __main__ - Step 260 Global step 260 Train loss 0.34 on epoch=18
05/28/2022 02:57:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.40 on epoch=19
05/28/2022 02:57:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.44 on epoch=19
05/28/2022 02:57:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.33 on epoch=20
05/28/2022 02:57:38 - INFO - __main__ - Step 300 Global step 300 Train loss 0.36 on epoch=21
05/28/2022 02:57:45 - INFO - __main__ - Global step 300 Train loss 0.37 Classification-F1 0.6383393679864365 on epoch=21
05/28/2022 02:57:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.39 on epoch=22
05/28/2022 02:57:50 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=22
05/28/2022 02:57:53 - INFO - __main__ - Step 330 Global step 330 Train loss 0.36 on epoch=23
05/28/2022 02:57:55 - INFO - __main__ - Step 340 Global step 340 Train loss 0.35 on epoch=24
05/28/2022 02:57:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.33 on epoch=24
05/28/2022 02:58:05 - INFO - __main__ - Global step 350 Train loss 0.37 Classification-F1 0.8046607713827829 on epoch=24
05/28/2022 02:58:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6743231400532766 -> 0.8046607713827829 on epoch=24, global_step=350
05/28/2022 02:58:07 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=25
05/28/2022 02:58:10 - INFO - __main__ - Step 370 Global step 370 Train loss 0.35 on epoch=26
05/28/2022 02:58:12 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=27
05/28/2022 02:58:15 - INFO - __main__ - Step 390 Global step 390 Train loss 0.25 on epoch=27
05/28/2022 02:58:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=28
05/28/2022 02:58:24 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.7701601094983448 on epoch=28
05/28/2022 02:58:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=29
05/28/2022 02:58:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=29
05/28/2022 02:58:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=30
05/28/2022 02:58:34 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=31
05/28/2022 02:58:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=32
05/28/2022 02:58:44 - INFO - __main__ - Global step 450 Train loss 0.27 Classification-F1 0.8604860189689911 on epoch=32
05/28/2022 02:58:45 - INFO - __main__ - Saving model with best Classification-F1: 0.8046607713827829 -> 0.8604860189689911 on epoch=32, global_step=450
05/28/2022 02:58:47 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=32
05/28/2022 02:58:50 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=33
05/28/2022 02:58:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=34
05/28/2022 02:58:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=34
05/28/2022 02:58:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=35
05/28/2022 02:59:04 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.8729922467520732 on epoch=35
05/28/2022 02:59:04 - INFO - __main__ - Saving model with best Classification-F1: 0.8604860189689911 -> 0.8729922467520732 on epoch=35, global_step=500
05/28/2022 02:59:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=36
05/28/2022 02:59:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=37
05/28/2022 02:59:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=37
05/28/2022 02:59:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.12 on epoch=38
05/28/2022 02:59:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=39
05/28/2022 02:59:23 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.6813794810632255 on epoch=39
05/28/2022 02:59:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=39
05/28/2022 02:59:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=40
05/28/2022 02:59:30 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=41
05/28/2022 02:59:33 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=42
05/28/2022 02:59:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=42
05/28/2022 02:59:42 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.7242044035147485 on epoch=42
05/28/2022 02:59:45 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=43
05/28/2022 02:59:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=44
05/28/2022 02:59:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=44
05/28/2022 02:59:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.30 on epoch=45
05/28/2022 02:59:55 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=46
05/28/2022 03:00:03 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.9116074973488908 on epoch=46
05/28/2022 03:00:03 - INFO - __main__ - Saving model with best Classification-F1: 0.8729922467520732 -> 0.9116074973488908 on epoch=46, global_step=650
05/28/2022 03:00:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=47
05/28/2022 03:00:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=47
05/28/2022 03:00:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=48
05/28/2022 03:00:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=49
05/28/2022 03:00:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=49
05/28/2022 03:00:22 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.8176168827002092 on epoch=49
05/28/2022 03:00:25 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=50
05/28/2022 03:00:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=51
05/28/2022 03:00:30 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=52
05/28/2022 03:00:32 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=52
05/28/2022 03:00:35 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=53
05/28/2022 03:00:42 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.741058827299167 on epoch=53
05/28/2022 03:00:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=54
05/28/2022 03:00:47 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=54
05/28/2022 03:00:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=55
05/28/2022 03:00:52 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=56
05/28/2022 03:00:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=57
05/28/2022 03:01:02 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.8067785653160695 on epoch=57
05/28/2022 03:01:04 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=57
05/28/2022 03:01:07 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=58
05/28/2022 03:01:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=59
05/28/2022 03:01:12 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=59
05/28/2022 03:01:14 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=60
05/28/2022 03:01:21 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.9029565166815707 on epoch=60
05/28/2022 03:01:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=61
05/28/2022 03:01:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=62
05/28/2022 03:01:29 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=62
05/28/2022 03:01:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=63
05/28/2022 03:01:34 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=64
05/28/2022 03:01:40 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.548966303749396 on epoch=64
05/28/2022 03:01:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=64
05/28/2022 03:01:45 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=65
05/28/2022 03:01:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=66
05/28/2022 03:01:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=67
05/28/2022 03:01:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=67
05/28/2022 03:02:00 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.8104802771548502 on epoch=67
05/28/2022 03:02:03 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
05/28/2022 03:02:05 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
05/28/2022 03:02:08 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=69
05/28/2022 03:02:10 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=70
05/28/2022 03:02:13 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=71
05/28/2022 03:02:19 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.696697646296616 on epoch=71
05/28/2022 03:02:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=72
05/28/2022 03:02:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=72
05/28/2022 03:02:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
05/28/2022 03:02:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=74
05/28/2022 03:02:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
05/28/2022 03:02:38 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7074429365127319 on epoch=74
05/28/2022 03:02:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
05/28/2022 03:02:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=76
05/28/2022 03:02:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=77
05/28/2022 03:02:48 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
05/28/2022 03:02:51 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
05/28/2022 03:02:58 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.9864404412791509 on epoch=78
05/28/2022 03:02:58 - INFO - __main__ - Saving model with best Classification-F1: 0.9116074973488908 -> 0.9864404412791509 on epoch=78, global_step=1100
05/28/2022 03:03:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=79
05/28/2022 03:03:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
05/28/2022 03:03:05 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
05/28/2022 03:03:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
05/28/2022 03:03:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=82
05/28/2022 03:03:17 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.9072323670426137 on epoch=82
05/28/2022 03:03:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
05/28/2022 03:03:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
05/28/2022 03:03:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
05/28/2022 03:03:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
05/28/2022 03:03:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
05/28/2022 03:03:37 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.8569564088465298 on epoch=85
05/28/2022 03:03:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=86
05/28/2022 03:03:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
05/28/2022 03:03:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=87
05/28/2022 03:03:47 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
05/28/2022 03:03:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
05/28/2022 03:03:56 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.7535763851176038 on epoch=89
05/28/2022 03:03:59 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
05/28/2022 03:04:01 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
05/28/2022 03:04:04 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
05/28/2022 03:04:06 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
05/28/2022 03:04:09 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
05/28/2022 03:04:16 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.8626082853001651 on epoch=92
05/28/2022 03:04:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
05/28/2022 03:04:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
05/28/2022 03:04:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
05/28/2022 03:04:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=95
05/28/2022 03:04:28 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=96
05/28/2022 03:04:35 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7704176489755237 on epoch=96
05/28/2022 03:04:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
05/28/2022 03:04:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
05/28/2022 03:04:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
05/28/2022 03:04:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
05/28/2022 03:04:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=99
05/28/2022 03:04:54 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.8417053814889128 on epoch=99
05/28/2022 03:04:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
05/28/2022 03:04:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=101
05/28/2022 03:05:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
05/28/2022 03:05:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
05/28/2022 03:05:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
05/28/2022 03:05:13 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.9820991153059465 on epoch=103
05/28/2022 03:05:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=104
05/28/2022 03:05:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
05/28/2022 03:05:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
05/28/2022 03:05:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
05/28/2022 03:05:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
05/28/2022 03:05:33 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.8528973319533092 on epoch=107
05/28/2022 03:05:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
05/28/2022 03:05:38 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
05/28/2022 03:05:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
05/28/2022 03:05:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=109
05/28/2022 03:05:45 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
05/28/2022 03:05:52 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7778854210305823 on epoch=110
05/28/2022 03:05:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
05/28/2022 03:05:57 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
05/28/2022 03:06:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
05/28/2022 03:06:02 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
05/28/2022 03:06:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
05/28/2022 03:06:12 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7994605287536976 on epoch=114
05/28/2022 03:06:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
05/28/2022 03:06:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
05/28/2022 03:06:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
05/28/2022 03:06:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
05/28/2022 03:06:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
05/28/2022 03:06:31 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7985392411710004 on epoch=117
05/28/2022 03:06:34 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=118
05/28/2022 03:06:36 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
05/28/2022 03:06:39 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
05/28/2022 03:06:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
05/28/2022 03:06:44 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
05/28/2022 03:06:51 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.796747217353687 on epoch=121
05/28/2022 03:06:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
05/28/2022 03:06:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
05/28/2022 03:06:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
05/28/2022 03:07:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
05/28/2022 03:07:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
05/28/2022 03:07:10 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8549486803519062 on epoch=124
05/28/2022 03:07:12 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
05/28/2022 03:07:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
05/28/2022 03:07:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
05/28/2022 03:07:20 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
05/28/2022 03:07:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=128
05/28/2022 03:07:29 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8027023140247754 on epoch=128
05/28/2022 03:07:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
05/28/2022 03:07:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
05/28/2022 03:07:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
05/28/2022 03:07:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
05/28/2022 03:07:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
05/28/2022 03:07:48 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6872333979294931 on epoch=132
05/28/2022 03:07:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
05/28/2022 03:07:53 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
05/28/2022 03:07:56 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
05/28/2022 03:07:58 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=134
05/28/2022 03:08:01 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
05/28/2022 03:08:07 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8601452311129731 on epoch=135
05/28/2022 03:08:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=136
05/28/2022 03:08:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
05/28/2022 03:08:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
05/28/2022 03:08:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
05/28/2022 03:08:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
05/28/2022 03:08:26 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9205474095796676 on epoch=139
05/28/2022 03:08:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
05/28/2022 03:08:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
05/28/2022 03:08:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=141
05/28/2022 03:08:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
05/28/2022 03:08:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
05/28/2022 03:08:44 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.8514391224068644 on epoch=142
05/28/2022 03:08:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
05/28/2022 03:08:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
05/28/2022 03:08:52 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
05/28/2022 03:08:54 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
05/28/2022 03:08:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
05/28/2022 03:09:03 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.8439917609272448 on epoch=146
05/28/2022 03:09:05 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
05/28/2022 03:09:08 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=147
05/28/2022 03:09:11 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
05/28/2022 03:09:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
05/28/2022 03:09:16 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
05/28/2022 03:09:22 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.8631514235092864 on epoch=149
05/28/2022 03:09:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/28/2022 03:09:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
05/28/2022 03:09:30 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
05/28/2022 03:09:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
05/28/2022 03:09:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
05/28/2022 03:09:42 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=153
05/28/2022 03:09:42 - INFO - __main__ - Saving model with best Classification-F1: 0.9864404412791509 -> 0.9910627007401202 on epoch=153, global_step=2150
05/28/2022 03:09:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
05/28/2022 03:09:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
05/28/2022 03:09:49 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
05/28/2022 03:09:52 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
05/28/2022 03:09:54 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
05/28/2022 03:10:01 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9910627007401202 on epoch=157
05/28/2022 03:10:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
05/28/2022 03:10:06 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
05/28/2022 03:10:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
05/28/2022 03:10:11 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
05/28/2022 03:10:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
05/28/2022 03:10:19 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.99553135037006 on epoch=160
05/28/2022 03:10:19 - INFO - __main__ - Saving model with best Classification-F1: 0.9910627007401202 -> 0.99553135037006 on epoch=160, global_step=2250
05/28/2022 03:10:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
05/28/2022 03:10:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
05/28/2022 03:10:27 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
05/28/2022 03:10:30 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=163
05/28/2022 03:10:32 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
05/28/2022 03:10:38 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9126461750117664 on epoch=164
05/28/2022 03:10:41 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
05/28/2022 03:10:44 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
05/28/2022 03:10:46 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/28/2022 03:10:49 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
05/28/2022 03:10:51 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
05/28/2022 03:10:58 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9163766699250571 on epoch=167
05/28/2022 03:11:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
05/28/2022 03:11:03 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/28/2022 03:11:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
05/28/2022 03:11:08 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
05/28/2022 03:11:11 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/28/2022 03:11:18 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9247181492342783 on epoch=171
05/28/2022 03:11:20 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
05/28/2022 03:11:23 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/28/2022 03:11:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
05/28/2022 03:11:28 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/28/2022 03:11:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/28/2022 03:11:37 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9247181492342783 on epoch=174
05/28/2022 03:11:40 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
05/28/2022 03:11:43 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/28/2022 03:11:45 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
05/28/2022 03:11:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/28/2022 03:11:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=178
05/28/2022 03:11:57 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9228453893776475 on epoch=178
05/28/2022 03:12:00 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=179
05/28/2022 03:12:02 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
05/28/2022 03:12:05 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/28/2022 03:12:07 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/28/2022 03:12:10 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
05/28/2022 03:12:16 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=182
05/28/2022 03:12:19 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/28/2022 03:12:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
05/28/2022 03:12:24 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
05/28/2022 03:12:27 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/28/2022 03:12:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
05/28/2022 03:12:36 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9819717916492109 on epoch=185
05/28/2022 03:12:38 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/28/2022 03:12:41 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
05/28/2022 03:12:44 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
05/28/2022 03:12:46 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
05/28/2022 03:12:49 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/28/2022 03:12:55 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9819717916492109 on epoch=189
05/28/2022 03:12:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
05/28/2022 03:13:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/28/2022 03:13:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=191
05/28/2022 03:13:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
05/28/2022 03:13:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
05/28/2022 03:13:14 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9126461750117664 on epoch=192
05/28/2022 03:13:17 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/28/2022 03:13:19 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
05/28/2022 03:13:22 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
05/28/2022 03:13:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
05/28/2022 03:13:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
05/28/2022 03:13:33 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.99553135037006 on epoch=196
05/28/2022 03:13:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
05/28/2022 03:13:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/28/2022 03:13:41 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/28/2022 03:13:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
05/28/2022 03:13:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/28/2022 03:13:52 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9268686868686868 on epoch=199
05/28/2022 03:13:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/28/2022 03:13:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
05/28/2022 03:13:59 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
05/28/2022 03:14:02 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/28/2022 03:14:04 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
05/28/2022 03:14:11 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8670576735092864 on epoch=203
05/28/2022 03:14:14 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
05/28/2022 03:14:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/28/2022 03:14:19 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/28/2022 03:14:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
05/28/2022 03:14:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/28/2022 03:14:30 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8610008858748779 on epoch=207
05/28/2022 03:14:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
05/28/2022 03:14:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/28/2022 03:14:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
05/28/2022 03:14:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/28/2022 03:14:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/28/2022 03:14:48 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.977167710040837 on epoch=210
05/28/2022 03:14:51 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
05/28/2022 03:14:53 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/28/2022 03:14:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/28/2022 03:14:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/28/2022 03:15:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/28/2022 03:15:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 03:15:03 - INFO - __main__ - Printing 3 examples
05/28/2022 03:15:03 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 03:15:03 - INFO - __main__ - ['Company']
05/28/2022 03:15:03 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 03:15:03 - INFO - __main__ - ['Company']
05/28/2022 03:15:03 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 03:15:03 - INFO - __main__ - ['Company']
05/28/2022 03:15:03 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:15:03 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:15:03 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 03:15:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 03:15:03 - INFO - __main__ - Printing 3 examples
05/28/2022 03:15:03 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/28/2022 03:15:03 - INFO - __main__ - ['Company']
05/28/2022 03:15:03 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/28/2022 03:15:03 - INFO - __main__ - ['Company']
05/28/2022 03:15:03 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/28/2022 03:15:03 - INFO - __main__ - ['Company']
05/28/2022 03:15:03 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:15:03 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:15:03 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 03:15:07 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9864448051948053 on epoch=214
05/28/2022 03:15:07 - INFO - __main__ - save last model!
05/28/2022 03:15:07 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 03:15:07 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 03:15:07 - INFO - __main__ - Printing 3 examples
05/28/2022 03:15:07 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 03:15:07 - INFO - __main__ - ['Animal']
05/28/2022 03:15:07 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 03:15:07 - INFO - __main__ - ['Animal']
05/28/2022 03:15:07 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 03:15:07 - INFO - __main__ - ['Village']
05/28/2022 03:15:07 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:15:09 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:15:13 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 03:15:19 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 03:15:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 03:15:19 - INFO - __main__ - Starting training!
05/28/2022 03:17:15 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
05/28/2022 03:17:15 - INFO - __main__ - Classification-F1 on test data: 0.6487
05/28/2022 03:17:16 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.99553135037006, test_performance=0.6486918570506575
05/28/2022 03:17:16 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
05/28/2022 03:17:16 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 03:17:16 - INFO - __main__ - Printing 3 examples
05/28/2022 03:17:16 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 03:17:16 - INFO - __main__ - ['Company']
05/28/2022 03:17:16 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 03:17:16 - INFO - __main__ - ['Company']
05/28/2022 03:17:16 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 03:17:16 - INFO - __main__ - ['Company']
05/28/2022 03:17:16 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:17:17 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:17:17 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 03:17:17 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 03:17:17 - INFO - __main__ - Printing 3 examples
05/28/2022 03:17:17 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/28/2022 03:17:17 - INFO - __main__ - ['Company']
05/28/2022 03:17:17 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/28/2022 03:17:17 - INFO - __main__ - ['Company']
05/28/2022 03:17:17 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/28/2022 03:17:17 - INFO - __main__ - ['Company']
05/28/2022 03:17:17 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:17:17 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:17:17 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 03:17:32 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 03:17:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 03:17:33 - INFO - __main__ - Starting training!
05/28/2022 03:17:36 - INFO - __main__ - Step 10 Global step 10 Train loss 6.40 on epoch=0
05/28/2022 03:17:39 - INFO - __main__ - Step 20 Global step 20 Train loss 4.35 on epoch=1
05/28/2022 03:17:42 - INFO - __main__ - Step 30 Global step 30 Train loss 3.44 on epoch=2
05/28/2022 03:17:44 - INFO - __main__ - Step 40 Global step 40 Train loss 2.76 on epoch=2
05/28/2022 03:17:47 - INFO - __main__ - Step 50 Global step 50 Train loss 2.35 on epoch=3
05/28/2022 03:17:52 - INFO - __main__ - Global step 50 Train loss 3.86 Classification-F1 0.025135718004015765 on epoch=3
05/28/2022 03:17:52 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.025135718004015765 on epoch=3, global_step=50
05/28/2022 03:17:54 - INFO - __main__ - Step 60 Global step 60 Train loss 2.01 on epoch=4
05/28/2022 03:17:57 - INFO - __main__ - Step 70 Global step 70 Train loss 1.49 on epoch=4
05/28/2022 03:17:59 - INFO - __main__ - Step 80 Global step 80 Train loss 1.16 on epoch=5
05/28/2022 03:18:02 - INFO - __main__ - Step 90 Global step 90 Train loss 1.15 on epoch=6
05/28/2022 03:18:05 - INFO - __main__ - Step 100 Global step 100 Train loss 1.02 on epoch=7
05/28/2022 03:18:11 - INFO - __main__ - Global step 100 Train loss 1.37 Classification-F1 0.39130278683431596 on epoch=7
05/28/2022 03:18:11 - INFO - __main__ - Saving model with best Classification-F1: 0.025135718004015765 -> 0.39130278683431596 on epoch=7, global_step=100
05/28/2022 03:18:14 - INFO - __main__ - Step 110 Global step 110 Train loss 0.87 on epoch=7
05/28/2022 03:18:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.75 on epoch=8
05/28/2022 03:18:19 - INFO - __main__ - Step 130 Global step 130 Train loss 0.92 on epoch=9
05/28/2022 03:18:21 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=9
05/28/2022 03:18:24 - INFO - __main__ - Step 150 Global step 150 Train loss 0.56 on epoch=10
05/28/2022 03:18:31 - INFO - __main__ - Global step 150 Train loss 0.77 Classification-F1 0.5503025135155595 on epoch=10
05/28/2022 03:18:31 - INFO - __main__ - Saving model with best Classification-F1: 0.39130278683431596 -> 0.5503025135155595 on epoch=10, global_step=150
05/28/2022 03:18:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.75 on epoch=11
05/28/2022 03:18:36 - INFO - __main__ - Step 170 Global step 170 Train loss 0.73 on epoch=12
05/28/2022 03:18:39 - INFO - __main__ - Step 180 Global step 180 Train loss 0.71 on epoch=12
05/28/2022 03:18:41 - INFO - __main__ - Step 190 Global step 190 Train loss 0.57 on epoch=13
05/28/2022 03:18:44 - INFO - __main__ - Step 200 Global step 200 Train loss 0.60 on epoch=14
05/28/2022 03:18:50 - INFO - __main__ - Global step 200 Train loss 0.67 Classification-F1 0.6965796925623974 on epoch=14
05/28/2022 03:18:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5503025135155595 -> 0.6965796925623974 on epoch=14, global_step=200
05/28/2022 03:18:53 - INFO - __main__ - Step 210 Global step 210 Train loss 0.56 on epoch=14
05/28/2022 03:18:55 - INFO - __main__ - Step 220 Global step 220 Train loss 0.43 on epoch=15
05/28/2022 03:18:58 - INFO - __main__ - Step 230 Global step 230 Train loss 0.52 on epoch=16
05/28/2022 03:19:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.59 on epoch=17
05/28/2022 03:19:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.51 on epoch=17
05/28/2022 03:19:10 - INFO - __main__ - Global step 250 Train loss 0.52 Classification-F1 0.6136650782013685 on epoch=17
05/28/2022 03:19:12 - INFO - __main__ - Step 260 Global step 260 Train loss 0.40 on epoch=18
05/28/2022 03:19:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.44 on epoch=19
05/28/2022 03:19:17 - INFO - __main__ - Step 280 Global step 280 Train loss 0.43 on epoch=19
05/28/2022 03:19:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=20
05/28/2022 03:19:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=21
05/28/2022 03:19:30 - INFO - __main__ - Global step 300 Train loss 0.41 Classification-F1 0.6215162785704292 on epoch=21
05/28/2022 03:19:32 - INFO - __main__ - Step 310 Global step 310 Train loss 0.45 on epoch=22
05/28/2022 03:19:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=22
05/28/2022 03:19:37 - INFO - __main__ - Step 330 Global step 330 Train loss 0.33 on epoch=23
05/28/2022 03:19:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.32 on epoch=24
05/28/2022 03:19:42 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=24
05/28/2022 03:19:49 - INFO - __main__ - Global step 350 Train loss 0.38 Classification-F1 0.885705926724367 on epoch=24
05/28/2022 03:19:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6965796925623974 -> 0.885705926724367 on epoch=24, global_step=350
05/28/2022 03:19:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=25
05/28/2022 03:19:55 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=26
05/28/2022 03:19:57 - INFO - __main__ - Step 380 Global step 380 Train loss 0.38 on epoch=27
05/28/2022 03:20:00 - INFO - __main__ - Step 390 Global step 390 Train loss 0.30 on epoch=27
05/28/2022 03:20:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.24 on epoch=28
05/28/2022 03:20:10 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.7733183870161325 on epoch=28
05/28/2022 03:20:13 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=29
05/28/2022 03:20:15 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=29
05/28/2022 03:20:18 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=30
05/28/2022 03:20:20 - INFO - __main__ - Step 440 Global step 440 Train loss 0.25 on epoch=31
05/28/2022 03:20:23 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=32
05/28/2022 03:20:31 - INFO - __main__ - Global step 450 Train loss 0.29 Classification-F1 0.8221998488871811 on epoch=32
05/28/2022 03:20:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=32
05/28/2022 03:20:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=33
05/28/2022 03:20:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.35 on epoch=34
05/28/2022 03:20:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=34
05/28/2022 03:20:43 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=35
05/28/2022 03:20:50 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.9459694911578892 on epoch=35
05/28/2022 03:20:50 - INFO - __main__ - Saving model with best Classification-F1: 0.885705926724367 -> 0.9459694911578892 on epoch=35, global_step=500
05/28/2022 03:20:53 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=36
05/28/2022 03:20:55 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=37
05/28/2022 03:20:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=37
05/28/2022 03:21:00 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=38
05/28/2022 03:21:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=39
05/28/2022 03:21:09 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.7616688953096958 on epoch=39
05/28/2022 03:21:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=39
05/28/2022 03:21:14 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=40
05/28/2022 03:21:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=41
05/28/2022 03:21:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=42
05/28/2022 03:21:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=42
05/28/2022 03:21:28 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.8815885816692269 on epoch=42
05/28/2022 03:21:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=43
05/28/2022 03:21:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=44
05/28/2022 03:21:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=44
05/28/2022 03:21:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=45
05/28/2022 03:21:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=46
05/28/2022 03:21:47 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.7155556424378762 on epoch=46
05/28/2022 03:21:50 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=47
05/28/2022 03:21:53 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=47
05/28/2022 03:21:55 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=48
05/28/2022 03:21:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=49
05/28/2022 03:22:00 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=49
05/28/2022 03:22:07 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.7281309297912714 on epoch=49
05/28/2022 03:22:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=50
05/28/2022 03:22:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=51
05/28/2022 03:22:14 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=52
05/28/2022 03:22:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=52
05/28/2022 03:22:19 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=53
05/28/2022 03:22:26 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.695068580886269 on epoch=53
05/28/2022 03:22:28 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=54
05/28/2022 03:22:31 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=54
05/28/2022 03:22:33 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=55
05/28/2022 03:22:36 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=56
05/28/2022 03:22:38 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=57
05/28/2022 03:22:45 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.8148018182423455 on epoch=57
05/28/2022 03:22:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=57
05/28/2022 03:22:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=58
05/28/2022 03:22:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=59
05/28/2022 03:22:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=59
05/28/2022 03:22:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=60
05/28/2022 03:23:04 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.7991081577212484 on epoch=60
05/28/2022 03:23:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=61
05/28/2022 03:23:09 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=62
05/28/2022 03:23:12 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
05/28/2022 03:23:14 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=63
05/28/2022 03:23:17 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=64
05/28/2022 03:23:23 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.8124069013312997 on epoch=64
05/28/2022 03:23:26 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
05/28/2022 03:23:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=65
05/28/2022 03:23:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=66
05/28/2022 03:23:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=67
05/28/2022 03:23:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=67
05/28/2022 03:23:42 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.790180881736859 on epoch=67
05/28/2022 03:23:45 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=68
05/28/2022 03:23:47 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=69
05/28/2022 03:23:50 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=69
05/28/2022 03:23:53 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
05/28/2022 03:23:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=71
05/28/2022 03:24:02 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.8425499622385051 on epoch=71
05/28/2022 03:24:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=72
05/28/2022 03:24:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=72
05/28/2022 03:24:09 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=73
05/28/2022 03:24:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=74
05/28/2022 03:24:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=74
05/28/2022 03:24:21 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.7763590611425926 on epoch=74
05/28/2022 03:24:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=75
05/28/2022 03:24:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=76
05/28/2022 03:24:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=77
05/28/2022 03:24:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=77
05/28/2022 03:24:33 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
05/28/2022 03:24:40 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.7864610800331864 on epoch=78
05/28/2022 03:24:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=79
05/28/2022 03:24:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=79
05/28/2022 03:24:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
05/28/2022 03:24:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=81
05/28/2022 03:24:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=82
05/28/2022 03:24:59 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.842974440284687 on epoch=82
05/28/2022 03:25:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
05/28/2022 03:25:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=83
05/28/2022 03:25:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
05/28/2022 03:25:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=84
05/28/2022 03:25:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
05/28/2022 03:25:18 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.8123368326330769 on epoch=85
05/28/2022 03:25:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
05/28/2022 03:25:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=87
05/28/2022 03:25:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
05/28/2022 03:25:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
05/28/2022 03:25:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
05/28/2022 03:25:36 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.7912960247637668 on epoch=89
05/28/2022 03:25:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
05/28/2022 03:25:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
05/28/2022 03:25:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
05/28/2022 03:25:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
05/28/2022 03:25:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
05/28/2022 03:25:55 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7987344837128401 on epoch=92
05/28/2022 03:25:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=93
05/28/2022 03:26:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
05/28/2022 03:26:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
05/28/2022 03:26:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
05/28/2022 03:26:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=96
05/28/2022 03:26:14 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.8564238207501965 on epoch=96
05/28/2022 03:26:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=97
05/28/2022 03:26:19 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
05/28/2022 03:26:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
05/28/2022 03:26:24 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=99
05/28/2022 03:26:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
05/28/2022 03:26:32 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.8967725521220145 on epoch=99
05/28/2022 03:26:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
05/28/2022 03:26:37 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
05/28/2022 03:26:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
05/28/2022 03:26:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
05/28/2022 03:26:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
05/28/2022 03:26:51 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.8362012987012988 on epoch=103
05/28/2022 03:26:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
05/28/2022 03:26:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
05/28/2022 03:26:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
05/28/2022 03:27:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
05/28/2022 03:27:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
05/28/2022 03:27:10 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.7966605184821504 on epoch=107
05/28/2022 03:27:12 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=107
05/28/2022 03:27:15 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
05/28/2022 03:27:18 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
05/28/2022 03:27:20 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
05/28/2022 03:27:23 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
05/28/2022 03:27:28 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7495567402588276 on epoch=110
05/28/2022 03:27:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
05/28/2022 03:27:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
05/28/2022 03:27:36 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
05/28/2022 03:27:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
05/28/2022 03:27:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
05/28/2022 03:27:47 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7061943358314325 on epoch=114
05/28/2022 03:27:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
05/28/2022 03:27:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
05/28/2022 03:27:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=116
05/28/2022 03:27:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
05/28/2022 03:28:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
05/28/2022 03:28:06 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.796319935598873 on epoch=117
05/28/2022 03:28:08 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
05/28/2022 03:28:11 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
05/28/2022 03:28:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=119
05/28/2022 03:28:16 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
05/28/2022 03:28:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
05/28/2022 03:28:25 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.8987615283267457 on epoch=121
05/28/2022 03:28:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
05/28/2022 03:28:30 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
05/28/2022 03:28:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
05/28/2022 03:28:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
05/28/2022 03:28:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
05/28/2022 03:28:44 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7648597643028413 on epoch=124
05/28/2022 03:28:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
05/28/2022 03:28:49 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
05/28/2022 03:28:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
05/28/2022 03:28:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
05/28/2022 03:28:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
05/28/2022 03:29:03 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.8942419587580877 on epoch=128
05/28/2022 03:29:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
05/28/2022 03:29:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
05/28/2022 03:29:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/28/2022 03:29:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
05/28/2022 03:29:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
05/28/2022 03:29:21 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.8506062485901196 on epoch=132
05/28/2022 03:29:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
05/28/2022 03:29:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
05/28/2022 03:29:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
05/28/2022 03:29:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
05/28/2022 03:29:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/28/2022 03:29:40 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9163562091503269 on epoch=135
05/28/2022 03:29:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=136
05/28/2022 03:29:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
05/28/2022 03:29:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
05/28/2022 03:29:50 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
05/28/2022 03:29:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
05/28/2022 03:29:59 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.9120380273321449 on epoch=139
05/28/2022 03:30:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
05/28/2022 03:30:04 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
05/28/2022 03:30:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
05/28/2022 03:30:09 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
05/28/2022 03:30:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
05/28/2022 03:30:17 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8141603415559772 on epoch=142
05/28/2022 03:30:19 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
05/28/2022 03:30:22 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=144
05/28/2022 03:30:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
05/28/2022 03:30:27 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
05/28/2022 03:30:30 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=146
05/28/2022 03:30:36 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.9096234873765463 on epoch=146
05/28/2022 03:30:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
05/28/2022 03:30:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
05/28/2022 03:30:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
05/28/2022 03:30:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
05/28/2022 03:30:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
05/28/2022 03:30:54 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9205514825676117 on epoch=149
05/28/2022 03:30:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
05/28/2022 03:30:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/28/2022 03:31:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
05/28/2022 03:31:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
05/28/2022 03:31:07 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
05/28/2022 03:31:13 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9226979472140762 on epoch=153
05/28/2022 03:31:15 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
05/28/2022 03:31:18 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=154
05/28/2022 03:31:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/28/2022 03:31:23 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
05/28/2022 03:31:26 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
05/28/2022 03:31:32 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9162463343108503 on epoch=157
05/28/2022 03:31:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
05/28/2022 03:31:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=158
05/28/2022 03:31:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
05/28/2022 03:31:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
05/28/2022 03:31:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
05/28/2022 03:31:50 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8449404677983308 on epoch=160
05/28/2022 03:31:53 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
05/28/2022 03:31:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
05/28/2022 03:31:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
05/28/2022 03:32:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
05/28/2022 03:32:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/28/2022 03:32:09 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8670614919354839 on epoch=164
05/28/2022 03:32:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
05/28/2022 03:32:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
05/28/2022 03:32:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
05/28/2022 03:32:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
05/28/2022 03:32:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/28/2022 03:32:28 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9228494623655915 on epoch=167
05/28/2022 03:32:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
05/28/2022 03:32:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/28/2022 03:32:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
05/28/2022 03:32:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
05/28/2022 03:32:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/28/2022 03:32:46 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9205514825676117 on epoch=171
05/28/2022 03:32:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
05/28/2022 03:32:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/28/2022 03:32:54 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
05/28/2022 03:32:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
05/28/2022 03:32:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/28/2022 03:33:05 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9205514825676117 on epoch=174
05/28/2022 03:33:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
05/28/2022 03:33:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/28/2022 03:33:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
05/28/2022 03:33:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/28/2022 03:33:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/28/2022 03:33:23 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.99553135037006 on epoch=178
05/28/2022 03:33:23 - INFO - __main__ - Saving model with best Classification-F1: 0.9459694911578892 -> 0.99553135037006 on epoch=178, global_step=2500
05/28/2022 03:33:26 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
05/28/2022 03:33:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
05/28/2022 03:33:31 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
05/28/2022 03:33:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
05/28/2022 03:33:36 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.10 on epoch=182
05/28/2022 03:33:42 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9270120560443141 on epoch=182
05/28/2022 03:33:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/28/2022 03:33:47 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
05/28/2022 03:33:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
05/28/2022 03:33:52 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
05/28/2022 03:33:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
05/28/2022 03:34:00 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9186746497230367 on epoch=185
05/28/2022 03:34:03 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
05/28/2022 03:34:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
05/28/2022 03:34:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
05/28/2022 03:34:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
05/28/2022 03:34:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
05/28/2022 03:34:20 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9270120560443141 on epoch=189
05/28/2022 03:34:22 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/28/2022 03:34:25 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
05/28/2022 03:34:27 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/28/2022 03:34:30 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/28/2022 03:34:32 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
05/28/2022 03:34:38 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9228494623655915 on epoch=192
05/28/2022 03:34:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/28/2022 03:34:43 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=194
05/28/2022 03:34:46 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
05/28/2022 03:34:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/28/2022 03:34:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
05/28/2022 03:34:56 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9154761904761906 on epoch=196
05/28/2022 03:34:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
05/28/2022 03:35:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/28/2022 03:35:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/28/2022 03:35:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
05/28/2022 03:35:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
05/28/2022 03:35:15 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9096153846153847 on epoch=199
05/28/2022 03:35:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/28/2022 03:35:20 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
05/28/2022 03:35:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/28/2022 03:35:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/28/2022 03:35:28 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
05/28/2022 03:35:33 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9154761904761906 on epoch=203
05/28/2022 03:35:36 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
05/28/2022 03:35:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
05/28/2022 03:35:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/28/2022 03:35:44 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
05/28/2022 03:35:46 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
05/28/2022 03:35:52 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9910714285714286 on epoch=207
05/28/2022 03:35:55 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
05/28/2022 03:35:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/28/2022 03:36:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/28/2022 03:36:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
05/28/2022 03:36:05 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/28/2022 03:36:11 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8946888237210818 on epoch=210
05/28/2022 03:36:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
05/28/2022 03:36:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/28/2022 03:36:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=212
05/28/2022 03:36:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
05/28/2022 03:36:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
05/28/2022 03:36:25 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 03:36:25 - INFO - __main__ - Printing 3 examples
05/28/2022 03:36:25 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 03:36:25 - INFO - __main__ - ['Company']
05/28/2022 03:36:25 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 03:36:25 - INFO - __main__ - ['Company']
05/28/2022 03:36:25 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 03:36:25 - INFO - __main__ - ['Company']
05/28/2022 03:36:25 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:36:25 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:36:25 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 03:36:25 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 03:36:25 - INFO - __main__ - Printing 3 examples
05/28/2022 03:36:25 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/28/2022 03:36:25 - INFO - __main__ - ['Company']
05/28/2022 03:36:25 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/28/2022 03:36:25 - INFO - __main__ - ['Company']
05/28/2022 03:36:25 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/28/2022 03:36:25 - INFO - __main__ - ['Company']
05/28/2022 03:36:25 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:36:25 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:36:26 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 03:36:29 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.890075292091421 on epoch=214
05/28/2022 03:36:29 - INFO - __main__ - save last model!
05/28/2022 03:36:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 03:36:29 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 03:36:29 - INFO - __main__ - Printing 3 examples
05/28/2022 03:36:29 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 03:36:29 - INFO - __main__ - ['Animal']
05/28/2022 03:36:29 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 03:36:29 - INFO - __main__ - ['Animal']
05/28/2022 03:36:29 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 03:36:29 - INFO - __main__ - ['Village']
05/28/2022 03:36:29 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:36:31 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:36:35 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 03:36:44 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 03:36:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 03:36:45 - INFO - __main__ - Starting training!
05/28/2022 03:38:36 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
05/28/2022 03:38:36 - INFO - __main__ - Classification-F1 on test data: 0.4911
05/28/2022 03:38:36 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.99553135037006, test_performance=0.4910859659596069
05/28/2022 03:38:36 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
05/28/2022 03:38:37 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 03:38:37 - INFO - __main__ - Printing 3 examples
05/28/2022 03:38:37 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 03:38:37 - INFO - __main__ - ['Company']
05/28/2022 03:38:37 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 03:38:37 - INFO - __main__ - ['Company']
05/28/2022 03:38:37 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 03:38:37 - INFO - __main__ - ['Company']
05/28/2022 03:38:37 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:38:37 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:38:37 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 03:38:37 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 03:38:37 - INFO - __main__ - Printing 3 examples
05/28/2022 03:38:37 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/28/2022 03:38:37 - INFO - __main__ - ['Company']
05/28/2022 03:38:37 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/28/2022 03:38:37 - INFO - __main__ - ['Company']
05/28/2022 03:38:37 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/28/2022 03:38:37 - INFO - __main__ - ['Company']
05/28/2022 03:38:37 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:38:37 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:38:38 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 03:38:53 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 03:38:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 03:38:54 - INFO - __main__ - Starting training!
05/28/2022 03:38:57 - INFO - __main__ - Step 10 Global step 10 Train loss 7.13 on epoch=0
05/28/2022 03:38:59 - INFO - __main__ - Step 20 Global step 20 Train loss 5.17 on epoch=1
05/28/2022 03:39:02 - INFO - __main__ - Step 30 Global step 30 Train loss 4.13 on epoch=2
05/28/2022 03:39:05 - INFO - __main__ - Step 40 Global step 40 Train loss 3.23 on epoch=2
05/28/2022 03:39:07 - INFO - __main__ - Step 50 Global step 50 Train loss 3.00 on epoch=3
05/28/2022 03:39:13 - INFO - __main__ - Global step 50 Train loss 4.53 Classification-F1 0.009566517189835576 on epoch=3
05/28/2022 03:39:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009566517189835576 on epoch=3, global_step=50
05/28/2022 03:39:16 - INFO - __main__ - Step 60 Global step 60 Train loss 2.51 on epoch=4
05/28/2022 03:39:18 - INFO - __main__ - Step 70 Global step 70 Train loss 2.17 on epoch=4
05/28/2022 03:39:21 - INFO - __main__ - Step 80 Global step 80 Train loss 1.81 on epoch=5
05/28/2022 03:39:23 - INFO - __main__ - Step 90 Global step 90 Train loss 1.59 on epoch=6
05/28/2022 03:39:26 - INFO - __main__ - Step 100 Global step 100 Train loss 1.28 on epoch=7
05/28/2022 03:39:33 - INFO - __main__ - Global step 100 Train loss 1.87 Classification-F1 0.22566128619809211 on epoch=7
05/28/2022 03:39:33 - INFO - __main__ - Saving model with best Classification-F1: 0.009566517189835576 -> 0.22566128619809211 on epoch=7, global_step=100
05/28/2022 03:39:36 - INFO - __main__ - Step 110 Global step 110 Train loss 1.14 on epoch=7
05/28/2022 03:39:39 - INFO - __main__ - Step 120 Global step 120 Train loss 1.01 on epoch=8
05/28/2022 03:39:41 - INFO - __main__ - Step 130 Global step 130 Train loss 0.96 on epoch=9
05/28/2022 03:39:44 - INFO - __main__ - Step 140 Global step 140 Train loss 0.96 on epoch=9
05/28/2022 03:39:46 - INFO - __main__ - Step 150 Global step 150 Train loss 0.83 on epoch=10
05/28/2022 03:39:53 - INFO - __main__ - Global step 150 Train loss 0.98 Classification-F1 0.4752582378240879 on epoch=10
05/28/2022 03:39:53 - INFO - __main__ - Saving model with best Classification-F1: 0.22566128619809211 -> 0.4752582378240879 on epoch=10, global_step=150
05/28/2022 03:39:56 - INFO - __main__ - Step 160 Global step 160 Train loss 0.85 on epoch=11
05/28/2022 03:39:58 - INFO - __main__ - Step 170 Global step 170 Train loss 0.80 on epoch=12
05/28/2022 03:40:01 - INFO - __main__ - Step 180 Global step 180 Train loss 0.73 on epoch=12
05/28/2022 03:40:03 - INFO - __main__ - Step 190 Global step 190 Train loss 0.64 on epoch=13
05/28/2022 03:40:06 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=14
05/28/2022 03:40:13 - INFO - __main__ - Global step 200 Train loss 0.74 Classification-F1 0.4393872807728203 on epoch=14
05/28/2022 03:40:15 - INFO - __main__ - Step 210 Global step 210 Train loss 0.83 on epoch=14
05/28/2022 03:40:18 - INFO - __main__ - Step 220 Global step 220 Train loss 0.57 on epoch=15
05/28/2022 03:40:20 - INFO - __main__ - Step 230 Global step 230 Train loss 0.55 on epoch=16
05/28/2022 03:40:23 - INFO - __main__ - Step 240 Global step 240 Train loss 0.64 on epoch=17
05/28/2022 03:40:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.64 on epoch=17
05/28/2022 03:40:32 - INFO - __main__ - Global step 250 Train loss 0.64 Classification-F1 0.6083757158447561 on epoch=17
05/28/2022 03:40:32 - INFO - __main__ - Saving model with best Classification-F1: 0.4752582378240879 -> 0.6083757158447561 on epoch=17, global_step=250
05/28/2022 03:40:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.52 on epoch=18
05/28/2022 03:40:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=19
05/28/2022 03:40:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.54 on epoch=19
05/28/2022 03:40:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=20
05/28/2022 03:40:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.56 on epoch=21
05/28/2022 03:40:51 - INFO - __main__ - Global step 300 Train loss 0.52 Classification-F1 0.5068199505054106 on epoch=21
05/28/2022 03:40:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.57 on epoch=22
05/28/2022 03:40:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.49 on epoch=22
05/28/2022 03:40:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=23
05/28/2022 03:41:02 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=24
05/28/2022 03:41:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.51 on epoch=24
05/28/2022 03:41:11 - INFO - __main__ - Global step 350 Train loss 0.49 Classification-F1 0.6055971009515884 on epoch=24
05/28/2022 03:41:13 - INFO - __main__ - Step 360 Global step 360 Train loss 0.59 on epoch=25
05/28/2022 03:41:16 - INFO - __main__ - Step 370 Global step 370 Train loss 0.46 on epoch=26
05/28/2022 03:41:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.48 on epoch=27
05/28/2022 03:41:21 - INFO - __main__ - Step 390 Global step 390 Train loss 0.44 on epoch=27
05/28/2022 03:41:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.42 on epoch=28
05/28/2022 03:41:30 - INFO - __main__ - Global step 400 Train loss 0.48 Classification-F1 0.682732377493155 on epoch=28
05/28/2022 03:41:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6083757158447561 -> 0.682732377493155 on epoch=28, global_step=400
05/28/2022 03:41:33 - INFO - __main__ - Step 410 Global step 410 Train loss 0.43 on epoch=29
05/28/2022 03:41:36 - INFO - __main__ - Step 420 Global step 420 Train loss 0.46 on epoch=29
05/28/2022 03:41:38 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=30
05/28/2022 03:41:41 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=31
05/28/2022 03:41:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.43 on epoch=32
05/28/2022 03:41:50 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.6690655332311911 on epoch=32
05/28/2022 03:41:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.38 on epoch=32
05/28/2022 03:41:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=33
05/28/2022 03:41:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=34
05/28/2022 03:42:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.43 on epoch=34
05/28/2022 03:42:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=35
05/28/2022 03:42:09 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.7187048440690511 on epoch=35
05/28/2022 03:42:09 - INFO - __main__ - Saving model with best Classification-F1: 0.682732377493155 -> 0.7187048440690511 on epoch=35, global_step=500
05/28/2022 03:42:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=36
05/28/2022 03:42:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.41 on epoch=37
05/28/2022 03:42:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.28 on epoch=37
05/28/2022 03:42:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.26 on epoch=38
05/28/2022 03:42:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=39
05/28/2022 03:42:28 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.71348145925953 on epoch=39
05/28/2022 03:42:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=39
05/28/2022 03:42:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=40
05/28/2022 03:42:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=41
05/28/2022 03:42:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.29 on epoch=42
05/28/2022 03:42:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.28 on epoch=42
05/28/2022 03:42:47 - INFO - __main__ - Global step 600 Train loss 0.30 Classification-F1 0.6946424464213838 on epoch=42
05/28/2022 03:42:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.34 on epoch=43
05/28/2022 03:42:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.28 on epoch=44
05/28/2022 03:42:55 - INFO - __main__ - Step 630 Global step 630 Train loss 0.30 on epoch=44
05/28/2022 03:42:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=45
05/28/2022 03:43:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=46
05/28/2022 03:43:06 - INFO - __main__ - Global step 650 Train loss 0.27 Classification-F1 0.6915080140886593 on epoch=46
05/28/2022 03:43:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=47
05/28/2022 03:43:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.33 on epoch=47
05/28/2022 03:43:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=48
05/28/2022 03:43:17 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=49
05/28/2022 03:43:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.34 on epoch=49
05/28/2022 03:43:26 - INFO - __main__ - Global step 700 Train loss 0.28 Classification-F1 0.7526530514027255 on epoch=49
05/28/2022 03:43:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7187048440690511 -> 0.7526530514027255 on epoch=49, global_step=700
05/28/2022 03:43:28 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=50
05/28/2022 03:43:31 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=51
05/28/2022 03:43:33 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=52
05/28/2022 03:43:36 - INFO - __main__ - Step 740 Global step 740 Train loss 0.26 on epoch=52
05/28/2022 03:43:39 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=53
05/28/2022 03:43:46 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.789023590557924 on epoch=53
05/28/2022 03:43:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7526530514027255 -> 0.789023590557924 on epoch=53, global_step=750
05/28/2022 03:43:48 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=54
05/28/2022 03:43:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=54
05/28/2022 03:43:53 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=55
05/28/2022 03:43:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=56
05/28/2022 03:43:58 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=57
05/28/2022 03:44:05 - INFO - __main__ - Global step 800 Train loss 0.22 Classification-F1 0.819097446407693 on epoch=57
05/28/2022 03:44:05 - INFO - __main__ - Saving model with best Classification-F1: 0.789023590557924 -> 0.819097446407693 on epoch=57, global_step=800
05/28/2022 03:44:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=57
05/28/2022 03:44:10 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=58
05/28/2022 03:44:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=59
05/28/2022 03:44:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.21 on epoch=59
05/28/2022 03:44:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.21 on epoch=60
05/28/2022 03:44:25 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.7715114814898378 on epoch=60
05/28/2022 03:44:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=61
05/28/2022 03:44:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.22 on epoch=62
05/28/2022 03:44:32 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=62
05/28/2022 03:44:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
05/28/2022 03:44:37 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=64
05/28/2022 03:44:44 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.6949199037883749 on epoch=64
05/28/2022 03:44:47 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=64
05/28/2022 03:44:49 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=65
05/28/2022 03:44:52 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=66
05/28/2022 03:44:54 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=67
05/28/2022 03:44:57 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=67
05/28/2022 03:45:04 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.818617901706137 on epoch=67
05/28/2022 03:45:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=68
05/28/2022 03:45:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=69
05/28/2022 03:45:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=69
05/28/2022 03:45:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=70
05/28/2022 03:45:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=71
05/28/2022 03:45:23 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.7442598774890326 on epoch=71
05/28/2022 03:45:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=72
05/28/2022 03:45:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=72
05/28/2022 03:45:31 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=73
05/28/2022 03:45:33 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=74
05/28/2022 03:45:36 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=74
05/28/2022 03:45:43 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.8373060139663555 on epoch=74
05/28/2022 03:45:43 - INFO - __main__ - Saving model with best Classification-F1: 0.819097446407693 -> 0.8373060139663555 on epoch=74, global_step=1050
05/28/2022 03:45:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
05/28/2022 03:45:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=76
05/28/2022 03:45:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=77
05/28/2022 03:45:53 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=77
05/28/2022 03:45:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=78
05/28/2022 03:46:02 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.8225541536262599 on epoch=78
05/28/2022 03:46:05 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=79
05/28/2022 03:46:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=79
05/28/2022 03:46:10 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=80
05/28/2022 03:46:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=81
05/28/2022 03:46:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=82
05/28/2022 03:46:22 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.7947543219937384 on epoch=82
05/28/2022 03:46:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=82
05/28/2022 03:46:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=83
05/28/2022 03:46:30 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=84
05/28/2022 03:46:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=84
05/28/2022 03:46:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
05/28/2022 03:46:42 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.8025974592486403 on epoch=85
05/28/2022 03:46:44 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
05/28/2022 03:46:47 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
05/28/2022 03:46:50 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
05/28/2022 03:46:52 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=88
05/28/2022 03:46:55 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=89
05/28/2022 03:47:01 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.6006106988249845 on epoch=89
05/28/2022 03:47:04 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=89
05/28/2022 03:47:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=90
05/28/2022 03:47:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
05/28/2022 03:47:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=92
05/28/2022 03:47:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=92
05/28/2022 03:47:20 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.5914957236688985 on epoch=92
05/28/2022 03:47:23 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
05/28/2022 03:47:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=94
05/28/2022 03:47:28 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=94
05/28/2022 03:47:30 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
05/28/2022 03:47:33 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=96
05/28/2022 03:47:40 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.6907745162252233 on epoch=96
05/28/2022 03:47:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=97
05/28/2022 03:47:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
05/28/2022 03:47:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=98
05/28/2022 03:47:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=99
05/28/2022 03:47:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=99
05/28/2022 03:47:59 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.5952022141538271 on epoch=99
05/28/2022 03:48:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=100
05/28/2022 03:48:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=101
05/28/2022 03:48:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=102
05/28/2022 03:48:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=102
05/28/2022 03:48:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=103
05/28/2022 03:48:18 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.5836417535034136 on epoch=103
05/28/2022 03:48:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=104
05/28/2022 03:48:23 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=104
05/28/2022 03:48:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
05/28/2022 03:48:28 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=106
05/28/2022 03:48:30 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=107
05/28/2022 03:48:37 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.6805929942589785 on epoch=107
05/28/2022 03:48:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
05/28/2022 03:48:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
05/28/2022 03:48:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
05/28/2022 03:48:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
05/28/2022 03:48:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
05/28/2022 03:48:56 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.6420411627762697 on epoch=110
05/28/2022 03:48:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
05/28/2022 03:49:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=112
05/28/2022 03:49:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
05/28/2022 03:49:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
05/28/2022 03:49:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=114
05/28/2022 03:49:15 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.6533716919752574 on epoch=114
05/28/2022 03:49:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=114
05/28/2022 03:49:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
05/28/2022 03:49:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=116
05/28/2022 03:49:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
05/28/2022 03:49:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
05/28/2022 03:49:33 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.6345933217372972 on epoch=117
05/28/2022 03:49:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
05/28/2022 03:49:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=119
05/28/2022 03:49:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=119
05/28/2022 03:49:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=120
05/28/2022 03:49:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
05/28/2022 03:49:52 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.6073634472271847 on epoch=121
05/28/2022 03:49:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
05/28/2022 03:49:57 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
05/28/2022 03:49:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
05/28/2022 03:50:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=124
05/28/2022 03:50:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
05/28/2022 03:50:11 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.6571945394808297 on epoch=124
05/28/2022 03:50:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=125
05/28/2022 03:50:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
05/28/2022 03:50:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
05/28/2022 03:50:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
05/28/2022 03:50:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
05/28/2022 03:50:30 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7364939719778429 on epoch=128
05/28/2022 03:50:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
05/28/2022 03:50:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
05/28/2022 03:50:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
05/28/2022 03:50:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
05/28/2022 03:50:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
05/28/2022 03:50:49 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8341318156661491 on epoch=132
05/28/2022 03:50:51 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
05/28/2022 03:50:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
05/28/2022 03:50:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
05/28/2022 03:50:59 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
05/28/2022 03:51:02 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
05/28/2022 03:51:08 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.531587779906684 on epoch=135
05/28/2022 03:51:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
05/28/2022 03:51:13 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
05/28/2022 03:51:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
05/28/2022 03:51:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
05/28/2022 03:51:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=139
05/28/2022 03:51:26 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.7936072410678952 on epoch=139
05/28/2022 03:51:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.13 on epoch=139
05/28/2022 03:51:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=140
05/28/2022 03:51:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=141
05/28/2022 03:51:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
05/28/2022 03:51:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
05/28/2022 03:51:45 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.6997586961172231 on epoch=142
05/28/2022 03:51:48 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
05/28/2022 03:51:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=144
05/28/2022 03:51:53 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
05/28/2022 03:51:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=145
05/28/2022 03:51:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=146
05/28/2022 03:52:04 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.6828373503392531 on epoch=146
05/28/2022 03:52:06 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
05/28/2022 03:52:09 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
05/28/2022 03:52:11 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
05/28/2022 03:52:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.10 on epoch=149
05/28/2022 03:52:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=149
05/28/2022 03:52:22 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.7988059866478698 on epoch=149
05/28/2022 03:52:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
05/28/2022 03:52:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=151
05/28/2022 03:52:30 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
05/28/2022 03:52:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=152
05/28/2022 03:52:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
05/28/2022 03:52:41 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6575291314473004 on epoch=153
05/28/2022 03:52:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
05/28/2022 03:52:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
05/28/2022 03:52:49 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
05/28/2022 03:52:51 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
05/28/2022 03:52:54 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
05/28/2022 03:53:00 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9186460429724188 on epoch=157
05/28/2022 03:53:00 - INFO - __main__ - Saving model with best Classification-F1: 0.8373060139663555 -> 0.9186460429724188 on epoch=157, global_step=2200
05/28/2022 03:53:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
05/28/2022 03:53:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=158
05/28/2022 03:53:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
05/28/2022 03:53:10 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
05/28/2022 03:53:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
05/28/2022 03:53:19 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8541144200626959 on epoch=160
05/28/2022 03:53:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
05/28/2022 03:53:24 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
05/28/2022 03:53:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
05/28/2022 03:53:29 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
05/28/2022 03:53:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
05/28/2022 03:53:38 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8497696454453962 on epoch=164
05/28/2022 03:53:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
05/28/2022 03:53:43 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
05/28/2022 03:53:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
05/28/2022 03:53:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
05/28/2022 03:53:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
05/28/2022 03:53:56 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7333758840779714 on epoch=167
05/28/2022 03:53:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
05/28/2022 03:54:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
05/28/2022 03:54:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
05/28/2022 03:54:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
05/28/2022 03:54:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
05/28/2022 03:54:15 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.750446380083477 on epoch=171
05/28/2022 03:54:17 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.10 on epoch=172
05/28/2022 03:54:20 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
05/28/2022 03:54:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=173
05/28/2022 03:54:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/28/2022 03:54:27 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
05/28/2022 03:54:33 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.8527720194155122 on epoch=174
05/28/2022 03:54:36 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/28/2022 03:54:38 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
05/28/2022 03:54:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/28/2022 03:54:43 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
05/28/2022 03:54:46 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=178
05/28/2022 03:54:52 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8102351791156345 on epoch=178
05/28/2022 03:54:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
05/28/2022 03:54:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
05/28/2022 03:54:59 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/28/2022 03:55:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
05/28/2022 03:55:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
05/28/2022 03:55:10 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7543940859353047 on epoch=182
05/28/2022 03:55:13 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/28/2022 03:55:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=183
05/28/2022 03:55:18 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
05/28/2022 03:55:21 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/28/2022 03:55:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
05/28/2022 03:55:29 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.8445286057592215 on epoch=185
05/28/2022 03:55:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=186
05/28/2022 03:55:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
05/28/2022 03:55:37 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
05/28/2022 03:55:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
05/28/2022 03:55:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
05/28/2022 03:55:48 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.8372190436943758 on epoch=189
05/28/2022 03:55:51 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/28/2022 03:55:53 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
05/28/2022 03:55:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
05/28/2022 03:55:58 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
05/28/2022 03:56:01 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
05/28/2022 03:56:07 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8047509360825579 on epoch=192
05/28/2022 03:56:10 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/28/2022 03:56:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
05/28/2022 03:56:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=194
05/28/2022 03:56:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/28/2022 03:56:20 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
05/28/2022 03:56:26 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7486338205859079 on epoch=196
05/28/2022 03:56:28 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
05/28/2022 03:56:31 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
05/28/2022 03:56:34 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
05/28/2022 03:56:36 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
05/28/2022 03:56:39 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/28/2022 03:56:45 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9183968719452589 on epoch=199
05/28/2022 03:56:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/28/2022 03:56:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
05/28/2022 03:56:52 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
05/28/2022 03:56:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/28/2022 03:56:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
05/28/2022 03:57:03 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8046460813064229 on epoch=203
05/28/2022 03:57:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
05/28/2022 03:57:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=204
05/28/2022 03:57:11 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
05/28/2022 03:57:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/28/2022 03:57:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
05/28/2022 03:57:22 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7599543825350277 on epoch=207
05/28/2022 03:57:25 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/28/2022 03:57:27 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/28/2022 03:57:30 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/28/2022 03:57:32 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/28/2022 03:57:35 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
05/28/2022 03:57:41 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.863147605083089 on epoch=210
05/28/2022 03:57:44 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
05/28/2022 03:57:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/28/2022 03:57:49 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/28/2022 03:57:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
05/28/2022 03:57:54 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/28/2022 03:57:55 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 03:57:55 - INFO - __main__ - Printing 3 examples
05/28/2022 03:57:55 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 03:57:55 - INFO - __main__ - ['Company']
05/28/2022 03:57:55 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 03:57:55 - INFO - __main__ - ['Company']
05/28/2022 03:57:55 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 03:57:55 - INFO - __main__ - ['Company']
05/28/2022 03:57:55 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:57:55 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:57:56 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 03:57:56 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 03:57:56 - INFO - __main__ - Printing 3 examples
05/28/2022 03:57:56 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/28/2022 03:57:56 - INFO - __main__ - ['Company']
05/28/2022 03:57:56 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/28/2022 03:57:56 - INFO - __main__ - ['Company']
05/28/2022 03:57:56 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/28/2022 03:57:56 - INFO - __main__ - ['Company']
05/28/2022 03:57:56 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:57:56 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:57:56 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 03:58:00 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9186705767350927 on epoch=214
05/28/2022 03:58:00 - INFO - __main__ - Saving model with best Classification-F1: 0.9186460429724188 -> 0.9186705767350927 on epoch=214, global_step=3000
05/28/2022 03:58:00 - INFO - __main__ - save last model!
05/28/2022 03:58:00 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 03:58:00 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 03:58:00 - INFO - __main__ - Printing 3 examples
05/28/2022 03:58:00 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 03:58:00 - INFO - __main__ - ['Animal']
05/28/2022 03:58:00 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 03:58:00 - INFO - __main__ - ['Animal']
05/28/2022 03:58:00 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 03:58:00 - INFO - __main__ - ['Village']
05/28/2022 03:58:00 - INFO - __main__ - Tokenizing Input ...
05/28/2022 03:58:02 - INFO - __main__ - Tokenizing Output ...
05/28/2022 03:58:05 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 03:58:14 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 03:58:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 03:58:15 - INFO - __main__ - Starting training!
05/28/2022 04:00:06 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
05/28/2022 04:00:06 - INFO - __main__ - Classification-F1 on test data: 0.5875
05/28/2022 04:00:07 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.9186705767350927, test_performance=0.5874867193842228
05/28/2022 04:00:07 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
05/28/2022 04:00:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 04:00:08 - INFO - __main__ - Printing 3 examples
05/28/2022 04:00:08 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/28/2022 04:00:08 - INFO - __main__ - ['Company']
05/28/2022 04:00:08 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/28/2022 04:00:08 - INFO - __main__ - ['Company']
05/28/2022 04:00:08 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/28/2022 04:00:08 - INFO - __main__ - ['Company']
05/28/2022 04:00:08 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:00:08 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:00:08 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 04:00:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 04:00:08 - INFO - __main__ - Printing 3 examples
05/28/2022 04:00:08 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/28/2022 04:00:08 - INFO - __main__ - ['Company']
05/28/2022 04:00:08 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/28/2022 04:00:08 - INFO - __main__ - ['Company']
05/28/2022 04:00:08 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/28/2022 04:00:08 - INFO - __main__ - ['Company']
05/28/2022 04:00:08 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:00:08 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:00:08 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 04:00:23 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 04:00:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 04:00:24 - INFO - __main__ - Starting training!
05/28/2022 04:00:28 - INFO - __main__ - Step 10 Global step 10 Train loss 7.58 on epoch=0
05/28/2022 04:00:30 - INFO - __main__ - Step 20 Global step 20 Train loss 5.73 on epoch=1
05/28/2022 04:00:33 - INFO - __main__ - Step 30 Global step 30 Train loss 4.82 on epoch=2
05/28/2022 04:00:35 - INFO - __main__ - Step 40 Global step 40 Train loss 3.62 on epoch=2
05/28/2022 04:00:38 - INFO - __main__ - Step 50 Global step 50 Train loss 3.40 on epoch=3
05/28/2022 04:00:44 - INFO - __main__ - Global step 50 Train loss 5.03 Classification-F1 0.008187134502923975 on epoch=3
05/28/2022 04:00:44 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.008187134502923975 on epoch=3, global_step=50
05/28/2022 04:00:47 - INFO - __main__ - Step 60 Global step 60 Train loss 3.08 on epoch=4
05/28/2022 04:00:49 - INFO - __main__ - Step 70 Global step 70 Train loss 2.75 on epoch=4
05/28/2022 04:00:52 - INFO - __main__ - Step 80 Global step 80 Train loss 2.36 on epoch=5
05/28/2022 04:00:54 - INFO - __main__ - Step 90 Global step 90 Train loss 2.27 on epoch=6
05/28/2022 04:00:57 - INFO - __main__ - Step 100 Global step 100 Train loss 1.97 on epoch=7
05/28/2022 04:01:02 - INFO - __main__ - Global step 100 Train loss 2.48 Classification-F1 0.07130909908447612 on epoch=7
05/28/2022 04:01:02 - INFO - __main__ - Saving model with best Classification-F1: 0.008187134502923975 -> 0.07130909908447612 on epoch=7, global_step=100
05/28/2022 04:01:05 - INFO - __main__ - Step 110 Global step 110 Train loss 1.75 on epoch=7
05/28/2022 04:01:07 - INFO - __main__ - Step 120 Global step 120 Train loss 1.65 on epoch=8
05/28/2022 04:01:10 - INFO - __main__ - Step 130 Global step 130 Train loss 1.59 on epoch=9
05/28/2022 04:01:12 - INFO - __main__ - Step 140 Global step 140 Train loss 1.52 on epoch=9
05/28/2022 04:01:15 - INFO - __main__ - Step 150 Global step 150 Train loss 1.20 on epoch=10
05/28/2022 04:01:23 - INFO - __main__ - Global step 150 Train loss 1.54 Classification-F1 0.3612385165519794 on epoch=10
05/28/2022 04:01:23 - INFO - __main__ - Saving model with best Classification-F1: 0.07130909908447612 -> 0.3612385165519794 on epoch=10, global_step=150
05/28/2022 04:01:25 - INFO - __main__ - Step 160 Global step 160 Train loss 1.21 on epoch=11
05/28/2022 04:01:28 - INFO - __main__ - Step 170 Global step 170 Train loss 1.05 on epoch=12
05/28/2022 04:01:30 - INFO - __main__ - Step 180 Global step 180 Train loss 0.95 on epoch=12
05/28/2022 04:01:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.91 on epoch=13
05/28/2022 04:01:35 - INFO - __main__ - Step 200 Global step 200 Train loss 0.90 on epoch=14
05/28/2022 04:01:43 - INFO - __main__ - Global step 200 Train loss 1.01 Classification-F1 0.42264379435806476 on epoch=14
05/28/2022 04:01:43 - INFO - __main__ - Saving model with best Classification-F1: 0.3612385165519794 -> 0.42264379435806476 on epoch=14, global_step=200
05/28/2022 04:01:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.89 on epoch=14
05/28/2022 04:01:48 - INFO - __main__ - Step 220 Global step 220 Train loss 0.77 on epoch=15
05/28/2022 04:01:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.83 on epoch=16
05/28/2022 04:01:53 - INFO - __main__ - Step 240 Global step 240 Train loss 0.75 on epoch=17
05/28/2022 04:01:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.72 on epoch=17
05/28/2022 04:02:02 - INFO - __main__ - Global step 250 Train loss 0.79 Classification-F1 0.4104754775361004 on epoch=17
05/28/2022 04:02:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.70 on epoch=18
05/28/2022 04:02:07 - INFO - __main__ - Step 270 Global step 270 Train loss 0.68 on epoch=19
05/28/2022 04:02:10 - INFO - __main__ - Step 280 Global step 280 Train loss 0.73 on epoch=19
05/28/2022 04:02:13 - INFO - __main__ - Step 290 Global step 290 Train loss 0.69 on epoch=20
05/28/2022 04:02:15 - INFO - __main__ - Step 300 Global step 300 Train loss 0.60 on epoch=21
05/28/2022 04:02:22 - INFO - __main__ - Global step 300 Train loss 0.68 Classification-F1 0.42296062643191956 on epoch=21
05/28/2022 04:02:22 - INFO - __main__ - Saving model with best Classification-F1: 0.42264379435806476 -> 0.42296062643191956 on epoch=21, global_step=300
05/28/2022 04:02:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.67 on epoch=22
05/28/2022 04:02:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.60 on epoch=22
05/28/2022 04:02:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.60 on epoch=23
05/28/2022 04:02:32 - INFO - __main__ - Step 340 Global step 340 Train loss 0.67 on epoch=24
05/28/2022 04:02:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.67 on epoch=24
05/28/2022 04:02:42 - INFO - __main__ - Global step 350 Train loss 0.64 Classification-F1 0.5041908823279997 on epoch=24
05/28/2022 04:02:42 - INFO - __main__ - Saving model with best Classification-F1: 0.42296062643191956 -> 0.5041908823279997 on epoch=24, global_step=350
05/28/2022 04:02:44 - INFO - __main__ - Step 360 Global step 360 Train loss 0.51 on epoch=25
05/28/2022 04:02:47 - INFO - __main__ - Step 370 Global step 370 Train loss 0.60 on epoch=26
05/28/2022 04:02:50 - INFO - __main__ - Step 380 Global step 380 Train loss 0.56 on epoch=27
05/28/2022 04:02:52 - INFO - __main__ - Step 390 Global step 390 Train loss 0.58 on epoch=27
05/28/2022 04:02:55 - INFO - __main__ - Step 400 Global step 400 Train loss 0.56 on epoch=28
05/28/2022 04:03:02 - INFO - __main__ - Global step 400 Train loss 0.56 Classification-F1 0.5213857991433747 on epoch=28
05/28/2022 04:03:02 - INFO - __main__ - Saving model with best Classification-F1: 0.5041908823279997 -> 0.5213857991433747 on epoch=28, global_step=400
05/28/2022 04:03:04 - INFO - __main__ - Step 410 Global step 410 Train loss 0.52 on epoch=29
05/28/2022 04:03:07 - INFO - __main__ - Step 420 Global step 420 Train loss 0.55 on epoch=29
05/28/2022 04:03:10 - INFO - __main__ - Step 430 Global step 430 Train loss 0.53 on epoch=30
05/28/2022 04:03:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.53 on epoch=31
05/28/2022 04:03:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.62 on epoch=32
05/28/2022 04:03:21 - INFO - __main__ - Global step 450 Train loss 0.55 Classification-F1 0.5286866514375865 on epoch=32
05/28/2022 04:03:21 - INFO - __main__ - Saving model with best Classification-F1: 0.5213857991433747 -> 0.5286866514375865 on epoch=32, global_step=450
05/28/2022 04:03:24 - INFO - __main__ - Step 460 Global step 460 Train loss 0.53 on epoch=32
05/28/2022 04:03:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.42 on epoch=33
05/28/2022 04:03:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.49 on epoch=34
05/28/2022 04:03:32 - INFO - __main__ - Step 490 Global step 490 Train loss 0.47 on epoch=34
05/28/2022 04:03:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=35
05/28/2022 04:03:41 - INFO - __main__ - Global step 500 Train loss 0.45 Classification-F1 0.6578571359613475 on epoch=35
05/28/2022 04:03:41 - INFO - __main__ - Saving model with best Classification-F1: 0.5286866514375865 -> 0.6578571359613475 on epoch=35, global_step=500
05/28/2022 04:03:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.50 on epoch=36
05/28/2022 04:03:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.42 on epoch=37
05/28/2022 04:03:49 - INFO - __main__ - Step 530 Global step 530 Train loss 0.44 on epoch=37
05/28/2022 04:03:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.31 on epoch=38
05/28/2022 04:03:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.43 on epoch=39
05/28/2022 04:04:01 - INFO - __main__ - Global step 550 Train loss 0.42 Classification-F1 0.65308524404338 on epoch=39
05/28/2022 04:04:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.42 on epoch=39
05/28/2022 04:04:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.42 on epoch=40
05/28/2022 04:04:08 - INFO - __main__ - Step 580 Global step 580 Train loss 0.38 on epoch=41
05/28/2022 04:04:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.39 on epoch=42
05/28/2022 04:04:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.46 on epoch=42
05/28/2022 04:04:21 - INFO - __main__ - Global step 600 Train loss 0.41 Classification-F1 0.63164535612731 on epoch=42
05/28/2022 04:04:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.44 on epoch=43
05/28/2022 04:04:26 - INFO - __main__ - Step 620 Global step 620 Train loss 0.35 on epoch=44
05/28/2022 04:04:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.36 on epoch=44
05/28/2022 04:04:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.32 on epoch=45
05/28/2022 04:04:33 - INFO - __main__ - Step 650 Global step 650 Train loss 0.43 on epoch=46
05/28/2022 04:04:40 - INFO - __main__ - Global step 650 Train loss 0.38 Classification-F1 0.640185316946777 on epoch=46
05/28/2022 04:04:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.42 on epoch=47
05/28/2022 04:04:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.41 on epoch=47
05/28/2022 04:04:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.37 on epoch=48
05/28/2022 04:04:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.36 on epoch=49
05/28/2022 04:04:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.33 on epoch=49
05/28/2022 04:04:59 - INFO - __main__ - Global step 700 Train loss 0.38 Classification-F1 0.7443455482755175 on epoch=49
05/28/2022 04:05:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6578571359613475 -> 0.7443455482755175 on epoch=49, global_step=700
05/28/2022 04:05:02 - INFO - __main__ - Step 710 Global step 710 Train loss 0.32 on epoch=50
05/28/2022 04:05:05 - INFO - __main__ - Step 720 Global step 720 Train loss 0.31 on epoch=51
05/28/2022 04:05:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.35 on epoch=52
05/28/2022 04:05:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.40 on epoch=52
05/28/2022 04:05:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.33 on epoch=53
05/28/2022 04:05:19 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.7236759584791703 on epoch=53
05/28/2022 04:05:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.39 on epoch=54
05/28/2022 04:05:25 - INFO - __main__ - Step 770 Global step 770 Train loss 0.36 on epoch=54
05/28/2022 04:05:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.30 on epoch=55
05/28/2022 04:05:30 - INFO - __main__ - Step 790 Global step 790 Train loss 0.24 on epoch=56
05/28/2022 04:05:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.28 on epoch=57
05/28/2022 04:05:39 - INFO - __main__ - Global step 800 Train loss 0.32 Classification-F1 0.7384616217828631 on epoch=57
05/28/2022 04:05:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.30 on epoch=57
05/28/2022 04:05:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.30 on epoch=58
05/28/2022 04:05:46 - INFO - __main__ - Step 830 Global step 830 Train loss 0.31 on epoch=59
05/28/2022 04:05:49 - INFO - __main__ - Step 840 Global step 840 Train loss 0.28 on epoch=59
05/28/2022 04:05:51 - INFO - __main__ - Step 850 Global step 850 Train loss 0.24 on epoch=60
05/28/2022 04:05:59 - INFO - __main__ - Global step 850 Train loss 0.28 Classification-F1 0.8133041912285189 on epoch=60
05/28/2022 04:05:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7443455482755175 -> 0.8133041912285189 on epoch=60, global_step=850
05/28/2022 04:06:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.27 on epoch=61
05/28/2022 04:06:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.37 on epoch=62
05/28/2022 04:06:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.26 on epoch=62
05/28/2022 04:06:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.24 on epoch=63
05/28/2022 04:06:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.37 on epoch=64
05/28/2022 04:06:19 - INFO - __main__ - Global step 900 Train loss 0.30 Classification-F1 0.7588763936947328 on epoch=64
05/28/2022 04:06:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.34 on epoch=64
05/28/2022 04:06:24 - INFO - __main__ - Step 920 Global step 920 Train loss 0.21 on epoch=65
05/28/2022 04:06:26 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=66
05/28/2022 04:06:29 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=67
05/28/2022 04:06:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.31 on epoch=67
05/28/2022 04:06:38 - INFO - __main__ - Global step 950 Train loss 0.25 Classification-F1 0.6595944752341436 on epoch=67
05/28/2022 04:06:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=68
05/28/2022 04:06:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.24 on epoch=69
05/28/2022 04:06:46 - INFO - __main__ - Step 980 Global step 980 Train loss 0.24 on epoch=69
05/28/2022 04:06:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=70
05/28/2022 04:06:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=71
05/28/2022 04:06:58 - INFO - __main__ - Global step 1000 Train loss 0.22 Classification-F1 0.5977964758312806 on epoch=71
05/28/2022 04:07:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.20 on epoch=72
05/28/2022 04:07:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=72
05/28/2022 04:07:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=73
05/28/2022 04:07:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=74
05/28/2022 04:07:11 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=74
05/28/2022 04:07:17 - INFO - __main__ - Global step 1050 Train loss 0.19 Classification-F1 0.5973866526082574 on epoch=74
05/28/2022 04:07:20 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=75
05/28/2022 04:07:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=76
05/28/2022 04:07:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=77
05/28/2022 04:07:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=77
05/28/2022 04:07:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.19 on epoch=78
05/28/2022 04:07:37 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.6635160359353908 on epoch=78
05/28/2022 04:07:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
05/28/2022 04:07:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.19 on epoch=79
05/28/2022 04:07:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=80
05/28/2022 04:07:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.17 on epoch=81
05/28/2022 04:07:50 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=82
05/28/2022 04:07:57 - INFO - __main__ - Global step 1150 Train loss 0.16 Classification-F1 0.648330271878659 on epoch=82
05/28/2022 04:07:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.17 on epoch=82
05/28/2022 04:08:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=83
05/28/2022 04:08:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.22 on epoch=84
05/28/2022 04:08:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=84
05/28/2022 04:08:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=85
05/28/2022 04:08:16 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.6148652234136105 on epoch=85
05/28/2022 04:08:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=86
05/28/2022 04:08:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=87
05/28/2022 04:08:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
05/28/2022 04:08:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
05/28/2022 04:08:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=89
05/28/2022 04:08:35 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.679993907583696 on epoch=89
05/28/2022 04:08:38 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=89
05/28/2022 04:08:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=90
05/28/2022 04:08:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=91
05/28/2022 04:08:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=92
05/28/2022 04:08:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.15 on epoch=92
05/28/2022 04:08:54 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.680437615581928 on epoch=92
05/28/2022 04:08:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=93
05/28/2022 04:08:59 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=94
05/28/2022 04:09:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=94
05/28/2022 04:09:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
05/28/2022 04:09:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=96
05/28/2022 04:09:13 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.6029718730999185 on epoch=96
05/28/2022 04:09:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=97
05/28/2022 04:09:18 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=97
05/28/2022 04:09:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
05/28/2022 04:09:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=99
05/28/2022 04:09:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=99
05/28/2022 04:09:32 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.5560791406820141 on epoch=99
05/28/2022 04:09:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=100
05/28/2022 04:09:37 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
05/28/2022 04:09:39 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=102
05/28/2022 04:09:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=102
05/28/2022 04:09:44 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=103
05/28/2022 04:09:50 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.5800300734586163 on epoch=103
05/28/2022 04:09:53 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.15 on epoch=104
05/28/2022 04:09:55 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=104
05/28/2022 04:09:58 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
05/28/2022 04:10:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
05/28/2022 04:10:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=107
05/28/2022 04:10:09 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.6635757523535649 on epoch=107
05/28/2022 04:10:12 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=107
05/28/2022 04:10:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
05/28/2022 04:10:17 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=109
05/28/2022 04:10:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=109
05/28/2022 04:10:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
05/28/2022 04:10:28 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.7295316516418667 on epoch=110
05/28/2022 04:10:30 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=111
05/28/2022 04:10:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=112
05/28/2022 04:10:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
05/28/2022 04:10:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=113
05/28/2022 04:10:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=114
05/28/2022 04:10:46 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.6307752102762431 on epoch=114
05/28/2022 04:10:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.18 on epoch=114
05/28/2022 04:10:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
05/28/2022 04:10:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
05/28/2022 04:10:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
05/28/2022 04:10:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=117
05/28/2022 04:11:05 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.7372912427069007 on epoch=117
05/28/2022 04:11:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=118
05/28/2022 04:11:10 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=119
05/28/2022 04:11:12 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=119
05/28/2022 04:11:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=120
05/28/2022 04:11:18 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=121
05/28/2022 04:11:23 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.6945219699239473 on epoch=121
05/28/2022 04:11:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.13 on epoch=122
05/28/2022 04:11:28 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.14 on epoch=122
05/28/2022 04:11:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=123
05/28/2022 04:11:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
05/28/2022 04:11:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=124
05/28/2022 04:11:42 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.791151688811911 on epoch=124
05/28/2022 04:11:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
05/28/2022 04:11:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
05/28/2022 04:11:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=127
05/28/2022 04:11:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=127
05/28/2022 04:11:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=128
05/28/2022 04:12:00 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.9059442349764931 on epoch=128
05/28/2022 04:12:00 - INFO - __main__ - Saving model with best Classification-F1: 0.8133041912285189 -> 0.9059442349764931 on epoch=128, global_step=1800
05/28/2022 04:12:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=129
05/28/2022 04:12:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.11 on epoch=129
05/28/2022 04:12:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=130
05/28/2022 04:12:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
05/28/2022 04:12:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
05/28/2022 04:12:19 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.7071586281351517 on epoch=132
05/28/2022 04:12:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=132
05/28/2022 04:12:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
05/28/2022 04:12:27 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=134
05/28/2022 04:12:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
05/28/2022 04:12:32 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.13 on epoch=135
05/28/2022 04:12:37 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.6261414114976896 on epoch=135
05/28/2022 04:12:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=136
05/28/2022 04:12:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
05/28/2022 04:12:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
05/28/2022 04:12:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
05/28/2022 04:12:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.09 on epoch=139
05/28/2022 04:12:56 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.7429369819141588 on epoch=139
05/28/2022 04:12:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
05/28/2022 04:13:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
05/28/2022 04:13:04 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=141
05/28/2022 04:13:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=142
05/28/2022 04:13:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
05/28/2022 04:13:15 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.9864404412791509 on epoch=142
05/28/2022 04:13:15 - INFO - __main__ - Saving model with best Classification-F1: 0.9059442349764931 -> 0.9864404412791509 on epoch=142, global_step=2000
05/28/2022 04:13:17 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
05/28/2022 04:13:20 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=144
05/28/2022 04:13:22 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=144
05/28/2022 04:13:25 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=145
05/28/2022 04:13:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=146
05/28/2022 04:13:33 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.8029719987011539 on epoch=146
05/28/2022 04:13:36 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=147
05/28/2022 04:13:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
05/28/2022 04:13:41 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
05/28/2022 04:13:43 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
05/28/2022 04:13:46 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=149
05/28/2022 04:13:52 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.9270120560443141 on epoch=149
05/28/2022 04:13:54 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=150
05/28/2022 04:13:57 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=151
05/28/2022 04:14:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=152
05/28/2022 04:14:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
05/28/2022 04:14:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
05/28/2022 04:14:10 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.9061133632338567 on epoch=153
05/28/2022 04:14:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
05/28/2022 04:14:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=154
05/28/2022 04:14:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
05/28/2022 04:14:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
05/28/2022 04:14:23 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
05/28/2022 04:14:29 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.800808374630836 on epoch=157
05/28/2022 04:14:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
05/28/2022 04:14:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=158
05/28/2022 04:14:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
05/28/2022 04:14:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
05/28/2022 04:14:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
05/28/2022 04:14:47 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.7160405758228588 on epoch=160
05/28/2022 04:14:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
05/28/2022 04:14:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
05/28/2022 04:14:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=162
05/28/2022 04:14:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
05/28/2022 04:15:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/28/2022 04:15:06 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.9187934851359898 on epoch=164
05/28/2022 04:15:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
05/28/2022 04:15:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
05/28/2022 04:15:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.11 on epoch=166
05/28/2022 04:15:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=167
05/28/2022 04:15:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
05/28/2022 04:15:25 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.9120755946562398 on epoch=167
05/28/2022 04:15:27 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=168
05/28/2022 04:15:30 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=169
05/28/2022 04:15:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
05/28/2022 04:15:35 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
05/28/2022 04:15:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
05/28/2022 04:15:43 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.9059789546317061 on epoch=171
05/28/2022 04:15:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
05/28/2022 04:15:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
05/28/2022 04:15:51 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
05/28/2022 04:15:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
05/28/2022 04:15:56 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.12 on epoch=174
05/28/2022 04:16:02 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.9910670646557743 on epoch=174
05/28/2022 04:16:02 - INFO - __main__ - Saving model with best Classification-F1: 0.9864404412791509 -> 0.9910670646557743 on epoch=174, global_step=2450
05/28/2022 04:16:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
05/28/2022 04:16:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
05/28/2022 04:16:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=177
05/28/2022 04:16:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=177
05/28/2022 04:16:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=178
05/28/2022 04:16:21 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.9910670646557743 on epoch=178
05/28/2022 04:16:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
05/28/2022 04:16:26 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=179
05/28/2022 04:16:28 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
05/28/2022 04:16:31 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.07 on epoch=181
05/28/2022 04:16:34 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
05/28/2022 04:16:39 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.9142015985279743 on epoch=182
05/28/2022 04:16:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/28/2022 04:16:45 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
05/28/2022 04:16:47 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
05/28/2022 04:16:50 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/28/2022 04:16:52 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
05/28/2022 04:16:58 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9186460429724188 on epoch=185
05/28/2022 04:17:01 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.09 on epoch=186
05/28/2022 04:17:03 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
05/28/2022 04:17:06 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
05/28/2022 04:17:08 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
05/28/2022 04:17:11 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
05/28/2022 04:17:17 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.9821341293115486 on epoch=189
05/28/2022 04:17:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=189
05/28/2022 04:17:22 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
05/28/2022 04:17:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
05/28/2022 04:17:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
05/28/2022 04:17:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
05/28/2022 04:17:36 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9773372105440418 on epoch=192
05/28/2022 04:17:38 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
05/28/2022 04:17:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
05/28/2022 04:17:43 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
05/28/2022 04:17:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=195
05/28/2022 04:17:48 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=196
05/28/2022 04:17:54 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7943445477207616 on epoch=196
05/28/2022 04:17:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
05/28/2022 04:17:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/28/2022 04:18:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=198
05/28/2022 04:18:04 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
05/28/2022 04:18:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/28/2022 04:18:13 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.783975907078374 on epoch=199
05/28/2022 04:18:15 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
05/28/2022 04:18:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=201
05/28/2022 04:18:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=202
05/28/2022 04:18:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
05/28/2022 04:18:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
05/28/2022 04:18:31 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7367427870959964 on epoch=203
05/28/2022 04:18:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
05/28/2022 04:18:36 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=204
05/28/2022 04:18:39 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
05/28/2022 04:18:41 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
05/28/2022 04:18:44 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=207
05/28/2022 04:18:50 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.8512492093611639 on epoch=207
05/28/2022 04:18:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/28/2022 04:18:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
05/28/2022 04:18:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
05/28/2022 04:19:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
05/28/2022 04:19:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
05/28/2022 04:19:09 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9103216702125622 on epoch=210
05/28/2022 04:19:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
05/28/2022 04:19:14 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
05/28/2022 04:19:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
05/28/2022 04:19:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
05/28/2022 04:19:21 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
05/28/2022 04:19:23 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 04:19:23 - INFO - __main__ - Printing 3 examples
05/28/2022 04:19:23 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/28/2022 04:19:23 - INFO - __main__ - ['Film']
05/28/2022 04:19:23 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 04:19:23 - INFO - __main__ - ['Film']
05/28/2022 04:19:23 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 04:19:23 - INFO - __main__ - ['Film']
05/28/2022 04:19:23 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:19:23 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:19:23 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 04:19:23 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 04:19:23 - INFO - __main__ - Printing 3 examples
05/28/2022 04:19:23 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/28/2022 04:19:23 - INFO - __main__ - ['Film']
05/28/2022 04:19:23 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/28/2022 04:19:23 - INFO - __main__ - ['Film']
05/28/2022 04:19:23 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/28/2022 04:19:23 - INFO - __main__ - ['Film']
05/28/2022 04:19:23 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:19:23 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:19:24 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 04:19:27 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8465019044641318 on epoch=214
05/28/2022 04:19:27 - INFO - __main__ - save last model!
05/28/2022 04:19:27 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 04:19:27 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 04:19:27 - INFO - __main__ - Printing 3 examples
05/28/2022 04:19:27 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 04:19:27 - INFO - __main__ - ['Animal']
05/28/2022 04:19:27 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 04:19:27 - INFO - __main__ - ['Animal']
05/28/2022 04:19:27 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 04:19:27 - INFO - __main__ - ['Village']
05/28/2022 04:19:27 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:19:29 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:19:32 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 04:19:39 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 04:19:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 04:19:40 - INFO - __main__ - Starting training!
05/28/2022 04:21:29 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
05/28/2022 04:21:29 - INFO - __main__ - Classification-F1 on test data: 0.4493
05/28/2022 04:21:30 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.9910670646557743, test_performance=0.44931543419922304
05/28/2022 04:21:30 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
05/28/2022 04:21:31 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 04:21:31 - INFO - __main__ - Printing 3 examples
05/28/2022 04:21:31 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/28/2022 04:21:31 - INFO - __main__ - ['Film']
05/28/2022 04:21:31 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 04:21:31 - INFO - __main__ - ['Film']
05/28/2022 04:21:31 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 04:21:31 - INFO - __main__ - ['Film']
05/28/2022 04:21:31 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:21:31 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:21:31 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 04:21:31 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 04:21:31 - INFO - __main__ - Printing 3 examples
05/28/2022 04:21:31 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/28/2022 04:21:31 - INFO - __main__ - ['Film']
05/28/2022 04:21:31 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/28/2022 04:21:31 - INFO - __main__ - ['Film']
05/28/2022 04:21:31 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/28/2022 04:21:31 - INFO - __main__ - ['Film']
05/28/2022 04:21:31 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:21:31 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:21:32 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 04:21:47 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 04:21:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 04:21:48 - INFO - __main__ - Starting training!
05/28/2022 04:21:51 - INFO - __main__ - Step 10 Global step 10 Train loss 6.19 on epoch=0
05/28/2022 04:21:54 - INFO - __main__ - Step 20 Global step 20 Train loss 3.97 on epoch=1
05/28/2022 04:21:56 - INFO - __main__ - Step 30 Global step 30 Train loss 2.87 on epoch=2
05/28/2022 04:21:59 - INFO - __main__ - Step 40 Global step 40 Train loss 2.21 on epoch=2
05/28/2022 04:22:01 - INFO - __main__ - Step 50 Global step 50 Train loss 1.76 on epoch=3
05/28/2022 04:22:08 - INFO - __main__ - Global step 50 Train loss 3.40 Classification-F1 0.2483442196175278 on epoch=3
05/28/2022 04:22:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2483442196175278 on epoch=3, global_step=50
05/28/2022 04:22:11 - INFO - __main__ - Step 60 Global step 60 Train loss 1.32 on epoch=4
05/28/2022 04:22:13 - INFO - __main__ - Step 70 Global step 70 Train loss 1.03 on epoch=4
05/28/2022 04:22:16 - INFO - __main__ - Step 80 Global step 80 Train loss 0.83 on epoch=5
05/28/2022 04:22:18 - INFO - __main__ - Step 90 Global step 90 Train loss 0.84 on epoch=6
05/28/2022 04:22:21 - INFO - __main__ - Step 100 Global step 100 Train loss 0.73 on epoch=7
05/28/2022 04:22:28 - INFO - __main__ - Global step 100 Train loss 0.95 Classification-F1 0.5627247432508045 on epoch=7
05/28/2022 04:22:28 - INFO - __main__ - Saving model with best Classification-F1: 0.2483442196175278 -> 0.5627247432508045 on epoch=7, global_step=100
05/28/2022 04:22:31 - INFO - __main__ - Step 110 Global step 110 Train loss 0.75 on epoch=7
05/28/2022 04:22:33 - INFO - __main__ - Step 120 Global step 120 Train loss 0.70 on epoch=8
05/28/2022 04:22:36 - INFO - __main__ - Step 130 Global step 130 Train loss 0.67 on epoch=9
05/28/2022 04:22:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.57 on epoch=9
05/28/2022 04:22:41 - INFO - __main__ - Step 150 Global step 150 Train loss 0.54 on epoch=10
05/28/2022 04:22:49 - INFO - __main__ - Global step 150 Train loss 0.65 Classification-F1 0.669458588232491 on epoch=10
05/28/2022 04:22:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5627247432508045 -> 0.669458588232491 on epoch=10, global_step=150
05/28/2022 04:22:52 - INFO - __main__ - Step 160 Global step 160 Train loss 0.53 on epoch=11
05/28/2022 04:22:54 - INFO - __main__ - Step 170 Global step 170 Train loss 0.47 on epoch=12
05/28/2022 04:22:57 - INFO - __main__ - Step 180 Global step 180 Train loss 0.39 on epoch=12
05/28/2022 04:22:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.45 on epoch=13
05/28/2022 04:23:02 - INFO - __main__ - Step 200 Global step 200 Train loss 0.50 on epoch=14
05/28/2022 04:23:09 - INFO - __main__ - Global step 200 Train loss 0.47 Classification-F1 0.717295696805303 on epoch=14
05/28/2022 04:23:09 - INFO - __main__ - Saving model with best Classification-F1: 0.669458588232491 -> 0.717295696805303 on epoch=14, global_step=200
05/28/2022 04:23:12 - INFO - __main__ - Step 210 Global step 210 Train loss 0.46 on epoch=14
05/28/2022 04:23:14 - INFO - __main__ - Step 220 Global step 220 Train loss 0.41 on epoch=15
05/28/2022 04:23:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.46 on epoch=16
05/28/2022 04:23:19 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=17
05/28/2022 04:23:22 - INFO - __main__ - Step 250 Global step 250 Train loss 0.32 on epoch=17
05/28/2022 04:23:29 - INFO - __main__ - Global step 250 Train loss 0.40 Classification-F1 0.7108613633479961 on epoch=17
05/28/2022 04:23:31 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=18
05/28/2022 04:23:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.32 on epoch=19
05/28/2022 04:23:36 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=19
05/28/2022 04:23:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.35 on epoch=20
05/28/2022 04:23:41 - INFO - __main__ - Step 300 Global step 300 Train loss 0.37 on epoch=21
05/28/2022 04:23:49 - INFO - __main__ - Global step 300 Train loss 0.36 Classification-F1 0.8081024576055003 on epoch=21
05/28/2022 04:23:49 - INFO - __main__ - Saving model with best Classification-F1: 0.717295696805303 -> 0.8081024576055003 on epoch=21, global_step=300
05/28/2022 04:23:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.33 on epoch=22
05/28/2022 04:23:54 - INFO - __main__ - Step 320 Global step 320 Train loss 0.31 on epoch=22
05/28/2022 04:23:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=23
05/28/2022 04:23:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=24
05/28/2022 04:24:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=24
05/28/2022 04:24:09 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.8084879152051827 on epoch=24
05/28/2022 04:24:09 - INFO - __main__ - Saving model with best Classification-F1: 0.8081024576055003 -> 0.8084879152051827 on epoch=24, global_step=350
05/28/2022 04:24:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.25 on epoch=25
05/28/2022 04:24:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=26
05/28/2022 04:24:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.27 on epoch=27
05/28/2022 04:24:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.18 on epoch=27
05/28/2022 04:24:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.24 on epoch=28
05/28/2022 04:24:28 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.9599165619326911 on epoch=28
05/28/2022 04:24:28 - INFO - __main__ - Saving model with best Classification-F1: 0.8084879152051827 -> 0.9599165619326911 on epoch=28, global_step=400
05/28/2022 04:24:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.31 on epoch=29
05/28/2022 04:24:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.21 on epoch=29
05/28/2022 04:24:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.17 on epoch=30
05/28/2022 04:24:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=31
05/28/2022 04:24:41 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=32
05/28/2022 04:24:48 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.9460331932106126 on epoch=32
05/28/2022 04:24:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.14 on epoch=32
05/28/2022 04:24:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=33
05/28/2022 04:24:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=34
05/28/2022 04:24:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.14 on epoch=34
05/28/2022 04:25:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=35
05/28/2022 04:25:08 - INFO - __main__ - Global step 500 Train loss 0.16 Classification-F1 0.8759515003585212 on epoch=35
05/28/2022 04:25:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.17 on epoch=36
05/28/2022 04:25:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.13 on epoch=37
05/28/2022 04:25:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=37
05/28/2022 04:25:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=38
05/28/2022 04:25:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.10 on epoch=39
05/28/2022 04:25:27 - INFO - __main__ - Global step 550 Train loss 0.13 Classification-F1 0.7747643437226539 on epoch=39
05/28/2022 04:25:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.10 on epoch=39
05/28/2022 04:25:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=40
05/28/2022 04:25:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=41
05/28/2022 04:25:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=42
05/28/2022 04:25:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=42
05/28/2022 04:25:46 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.7156713488109292 on epoch=42
05/28/2022 04:25:49 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=43
05/28/2022 04:25:51 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=44
05/28/2022 04:25:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=44
05/28/2022 04:25:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=45
05/28/2022 04:25:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=46
05/28/2022 04:26:05 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.6898569701961542 on epoch=46
05/28/2022 04:26:08 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=47
05/28/2022 04:26:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=47
05/28/2022 04:26:13 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=48
05/28/2022 04:26:16 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=49
05/28/2022 04:26:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=49
05/28/2022 04:26:24 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.6243470087379256 on epoch=49
05/28/2022 04:26:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=50
05/28/2022 04:26:30 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=51
05/28/2022 04:26:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=52
05/28/2022 04:26:35 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=52
05/28/2022 04:26:37 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=53
05/28/2022 04:26:44 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.5529852231961365 on epoch=53
05/28/2022 04:26:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=54
05/28/2022 04:26:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=54
05/28/2022 04:26:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=55
05/28/2022 04:26:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=56
05/28/2022 04:26:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=57
05/28/2022 04:27:02 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7091517819430005 on epoch=57
05/28/2022 04:27:05 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=57
05/28/2022 04:27:07 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=58
05/28/2022 04:27:10 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=59
05/28/2022 04:27:13 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=59
05/28/2022 04:27:15 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=60
05/28/2022 04:27:22 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.6947962406967785 on epoch=60
05/28/2022 04:27:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=61
05/28/2022 04:27:27 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=62
05/28/2022 04:27:29 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=62
05/28/2022 04:27:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=63
05/28/2022 04:27:34 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=64
05/28/2022 04:27:41 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.6474693882800843 on epoch=64
05/28/2022 04:27:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=64
05/28/2022 04:27:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=65
05/28/2022 04:27:49 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=66
05/28/2022 04:27:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=67
05/28/2022 04:27:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=67
05/28/2022 04:28:00 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.8064160033514873 on epoch=67
05/28/2022 04:28:02 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=68
05/28/2022 04:28:05 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=69
05/28/2022 04:28:08 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=69
05/28/2022 04:28:10 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=70
05/28/2022 04:28:13 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
05/28/2022 04:28:19 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.7990373436377937 on epoch=71
05/28/2022 04:28:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=72
05/28/2022 04:28:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=72
05/28/2022 04:28:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=73
05/28/2022 04:28:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
05/28/2022 04:28:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=74
05/28/2022 04:28:37 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.7916084468978207 on epoch=74
05/28/2022 04:28:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=75
05/28/2022 04:28:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=76
05/28/2022 04:28:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=77
05/28/2022 04:28:48 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
05/28/2022 04:28:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
05/28/2022 04:28:56 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.9776611157659545 on epoch=78
05/28/2022 04:28:56 - INFO - __main__ - Saving model with best Classification-F1: 0.9599165619326911 -> 0.9776611157659545 on epoch=78, global_step=1100
05/28/2022 04:28:59 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=79
05/28/2022 04:29:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
05/28/2022 04:29:04 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=80
05/28/2022 04:29:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=81
05/28/2022 04:29:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=82
05/28/2022 04:29:15 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.8354521619864954 on epoch=82
05/28/2022 04:29:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
05/28/2022 04:29:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=83
05/28/2022 04:29:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=84
05/28/2022 04:29:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=84
05/28/2022 04:29:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=85
05/28/2022 04:29:35 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.794324193930783 on epoch=85
05/28/2022 04:29:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
05/28/2022 04:29:40 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=87
05/28/2022 04:29:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
05/28/2022 04:29:45 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=88
05/28/2022 04:29:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
05/28/2022 04:29:53 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7715700888862917 on epoch=89
05/28/2022 04:29:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
05/28/2022 04:29:59 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=90
05/28/2022 04:30:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
05/28/2022 04:30:04 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=92
05/28/2022 04:30:06 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
05/28/2022 04:30:12 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7296921842641712 on epoch=92
05/28/2022 04:30:15 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
05/28/2022 04:30:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=94
05/28/2022 04:30:20 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=94
05/28/2022 04:30:22 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
05/28/2022 04:30:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
05/28/2022 04:30:31 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7515795321060975 on epoch=96
05/28/2022 04:30:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=97
05/28/2022 04:30:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=97
05/28/2022 04:30:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
05/28/2022 04:30:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
05/28/2022 04:30:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=99
05/28/2022 04:30:50 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.8122353840773613 on epoch=99
05/28/2022 04:30:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
05/28/2022 04:30:55 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
05/28/2022 04:30:58 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
05/28/2022 04:31:00 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
05/28/2022 04:31:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
05/28/2022 04:31:09 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.8374177034059542 on epoch=103
05/28/2022 04:31:12 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
05/28/2022 04:31:14 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
05/28/2022 04:31:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
05/28/2022 04:31:19 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
05/28/2022 04:31:22 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
05/28/2022 04:31:28 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.853180749022483 on epoch=107
05/28/2022 04:31:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
05/28/2022 04:31:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
05/28/2022 04:31:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
05/28/2022 04:31:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
05/28/2022 04:31:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
05/28/2022 04:31:47 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.8787580605844362 on epoch=110
05/28/2022 04:31:50 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
05/28/2022 04:31:53 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
05/28/2022 04:31:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
05/28/2022 04:31:58 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
05/28/2022 04:32:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
05/28/2022 04:32:06 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.8415473520786614 on epoch=114
05/28/2022 04:32:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
05/28/2022 04:32:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
05/28/2022 04:32:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
05/28/2022 04:32:17 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=117
05/28/2022 04:32:19 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
05/28/2022 04:32:25 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.977796397151236 on epoch=117
05/28/2022 04:32:25 - INFO - __main__ - Saving model with best Classification-F1: 0.9776611157659545 -> 0.977796397151236 on epoch=117, global_step=1650
05/28/2022 04:32:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
05/28/2022 04:32:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
05/28/2022 04:32:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/28/2022 04:32:36 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
05/28/2022 04:32:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
05/28/2022 04:32:44 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.8514250366568915 on epoch=121
05/28/2022 04:32:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
05/28/2022 04:32:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=122
05/28/2022 04:32:52 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
05/28/2022 04:32:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
05/28/2022 04:32:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
05/28/2022 04:33:03 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8553312866568915 on epoch=124
05/28/2022 04:33:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
05/28/2022 04:33:08 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
05/28/2022 04:33:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
05/28/2022 04:33:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
05/28/2022 04:33:16 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
05/28/2022 04:33:22 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.9021089931573805 on epoch=128
05/28/2022 04:33:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
05/28/2022 04:33:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
05/28/2022 04:33:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/28/2022 04:33:32 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=131
05/28/2022 04:33:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
05/28/2022 04:33:41 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.982265046781176 on epoch=132
05/28/2022 04:33:41 - INFO - __main__ - Saving model with best Classification-F1: 0.977796397151236 -> 0.982265046781176 on epoch=132, global_step=1850
05/28/2022 04:33:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
05/28/2022 04:33:46 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/28/2022 04:33:48 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
05/28/2022 04:33:51 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=134
05/28/2022 04:33:53 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
05/28/2022 04:33:59 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.8554496578690127 on epoch=135
05/28/2022 04:34:02 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
05/28/2022 04:34:05 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=137
05/28/2022 04:34:07 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
05/28/2022 04:34:10 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
05/28/2022 04:34:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
05/28/2022 04:34:18 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.848288254084625 on epoch=139
05/28/2022 04:34:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
05/28/2022 04:34:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
05/28/2022 04:34:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
05/28/2022 04:34:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=142
05/28/2022 04:34:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
05/28/2022 04:34:37 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8030501588465297 on epoch=142
05/28/2022 04:34:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=143
05/28/2022 04:34:42 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
05/28/2022 04:34:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
05/28/2022 04:34:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
05/28/2022 04:34:50 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
05/28/2022 04:34:56 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7346493030539799 on epoch=146
05/28/2022 04:34:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/28/2022 04:35:01 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=147
05/28/2022 04:35:04 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
05/28/2022 04:35:06 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
05/28/2022 04:35:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
05/28/2022 04:35:15 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7673002215038762 on epoch=149
05/28/2022 04:35:18 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=150
05/28/2022 04:35:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=151
05/28/2022 04:35:23 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
05/28/2022 04:35:25 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
05/28/2022 04:35:28 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=153
05/28/2022 04:35:34 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.851398217828187 on epoch=153
05/28/2022 04:35:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
05/28/2022 04:35:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/28/2022 04:35:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/28/2022 04:35:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
05/28/2022 04:35:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=157
05/28/2022 04:35:53 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7922307515381519 on epoch=157
05/28/2022 04:35:56 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
05/28/2022 04:35:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
05/28/2022 04:36:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
05/28/2022 04:36:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
05/28/2022 04:36:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=160
05/28/2022 04:36:12 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.795240924259278 on epoch=160
05/28/2022 04:36:14 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
05/28/2022 04:36:17 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
05/28/2022 04:36:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=162
05/28/2022 04:36:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
05/28/2022 04:36:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/28/2022 04:36:30 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.916380742913001 on epoch=164
05/28/2022 04:36:33 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
05/28/2022 04:36:36 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/28/2022 04:36:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/28/2022 04:36:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
05/28/2022 04:36:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/28/2022 04:36:49 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8463943146906856 on epoch=167
05/28/2022 04:36:52 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
05/28/2022 04:36:54 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/28/2022 04:36:57 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
05/28/2022 04:36:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
05/28/2022 04:37:02 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
05/28/2022 04:37:08 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6930797175154941 on epoch=171
05/28/2022 04:37:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
05/28/2022 04:37:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/28/2022 04:37:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
05/28/2022 04:37:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/28/2022 04:37:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
05/28/2022 04:37:27 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8217654822698621 on epoch=174
05/28/2022 04:37:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
05/28/2022 04:37:32 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
05/28/2022 04:37:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
05/28/2022 04:37:37 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
05/28/2022 04:37:40 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/28/2022 04:37:46 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7947849003323944 on epoch=178
05/28/2022 04:37:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
05/28/2022 04:37:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
05/28/2022 04:37:54 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
05/28/2022 04:37:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
05/28/2022 04:37:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
05/28/2022 04:38:05 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7934597460298354 on epoch=182
05/28/2022 04:38:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/28/2022 04:38:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=183
05/28/2022 04:38:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
05/28/2022 04:38:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/28/2022 04:38:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=185
05/28/2022 04:38:23 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7829783672999993 on epoch=185
05/28/2022 04:38:26 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
05/28/2022 04:38:29 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
05/28/2022 04:38:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
05/28/2022 04:38:34 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
05/28/2022 04:38:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
05/28/2022 04:38:42 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.8492706805962855 on epoch=189
05/28/2022 04:38:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
05/28/2022 04:38:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
05/28/2022 04:38:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/28/2022 04:38:53 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
05/28/2022 04:38:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/28/2022 04:39:01 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.8901272475972033 on epoch=192
05/28/2022 04:39:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
05/28/2022 04:39:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/28/2022 04:39:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
05/28/2022 04:39:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
05/28/2022 04:39:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
05/28/2022 04:39:20 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.791679455683578 on epoch=196
05/28/2022 04:39:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
05/28/2022 04:39:25 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
05/28/2022 04:39:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/28/2022 04:39:30 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/28/2022 04:39:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/28/2022 04:39:39 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8762224481785575 on epoch=199
05/28/2022 04:39:42 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
05/28/2022 04:39:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
05/28/2022 04:39:47 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/28/2022 04:39:50 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
05/28/2022 04:39:52 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
05/28/2022 04:39:59 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.8977908113391986 on epoch=203
05/28/2022 04:40:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
05/28/2022 04:40:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
05/28/2022 04:40:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/28/2022 04:40:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
05/28/2022 04:40:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/28/2022 04:40:18 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7766083510628102 on epoch=207
05/28/2022 04:40:20 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
05/28/2022 04:40:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
05/28/2022 04:40:25 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
05/28/2022 04:40:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
05/28/2022 04:40:30 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/28/2022 04:40:36 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7081059248397958 on epoch=210
05/28/2022 04:40:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/28/2022 04:40:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/28/2022 04:40:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
05/28/2022 04:40:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
05/28/2022 04:40:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/28/2022 04:40:51 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 04:40:51 - INFO - __main__ - Printing 3 examples
05/28/2022 04:40:51 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/28/2022 04:40:51 - INFO - __main__ - ['Film']
05/28/2022 04:40:51 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 04:40:51 - INFO - __main__ - ['Film']
05/28/2022 04:40:51 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 04:40:51 - INFO - __main__ - ['Film']
05/28/2022 04:40:51 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:40:51 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:40:51 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 04:40:51 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 04:40:51 - INFO - __main__ - Printing 3 examples
05/28/2022 04:40:51 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/28/2022 04:40:51 - INFO - __main__ - ['Film']
05/28/2022 04:40:51 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/28/2022 04:40:51 - INFO - __main__ - ['Film']
05/28/2022 04:40:51 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/28/2022 04:40:51 - INFO - __main__ - ['Film']
05/28/2022 04:40:51 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:40:51 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:40:52 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 04:40:55 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6809974073331709 on epoch=214
05/28/2022 04:40:55 - INFO - __main__ - save last model!
05/28/2022 04:40:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 04:40:55 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 04:40:55 - INFO - __main__ - Printing 3 examples
05/28/2022 04:40:55 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 04:40:55 - INFO - __main__ - ['Animal']
05/28/2022 04:40:55 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 04:40:55 - INFO - __main__ - ['Animal']
05/28/2022 04:40:55 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 04:40:55 - INFO - __main__ - ['Village']
05/28/2022 04:40:55 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:40:57 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:41:01 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 04:41:07 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 04:41:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 04:41:08 - INFO - __main__ - Starting training!
05/28/2022 04:43:06 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
05/28/2022 04:43:06 - INFO - __main__ - Classification-F1 on test data: 0.5496
05/28/2022 04:43:07 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.982265046781176, test_performance=0.5495504391685481
05/28/2022 04:43:07 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
05/28/2022 04:43:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 04:43:08 - INFO - __main__ - Printing 3 examples
05/28/2022 04:43:08 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/28/2022 04:43:08 - INFO - __main__ - ['Film']
05/28/2022 04:43:08 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 04:43:08 - INFO - __main__ - ['Film']
05/28/2022 04:43:08 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 04:43:08 - INFO - __main__ - ['Film']
05/28/2022 04:43:08 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:43:08 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:43:08 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 04:43:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 04:43:08 - INFO - __main__ - Printing 3 examples
05/28/2022 04:43:08 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/28/2022 04:43:08 - INFO - __main__ - ['Film']
05/28/2022 04:43:08 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/28/2022 04:43:08 - INFO - __main__ - ['Film']
05/28/2022 04:43:08 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/28/2022 04:43:08 - INFO - __main__ - ['Film']
05/28/2022 04:43:08 - INFO - __main__ - Tokenizing Input ...
05/28/2022 04:43:08 - INFO - __main__ - Tokenizing Output ...
05/28/2022 04:43:08 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 04:43:23 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 04:43:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 04:43:24 - INFO - __main__ - Starting training!
05/28/2022 04:43:28 - INFO - __main__ - Step 10 Global step 10 Train loss 6.54 on epoch=0
05/28/2022 04:43:30 - INFO - __main__ - Step 20 Global step 20 Train loss 4.45 on epoch=1
05/28/2022 04:43:33 - INFO - __main__ - Step 30 Global step 30 Train loss 3.44 on epoch=2
05/28/2022 04:43:36 - INFO - __main__ - Step 40 Global step 40 Train loss 2.78 on epoch=2
05/28/2022 04:43:38 - INFO - __main__ - Step 50 Global step 50 Train loss 2.34 on epoch=3
05/28/2022 04:43:44 - INFO - __main__ - Global step 50 Train loss 3.91 Classification-F1 0.04216683149651685 on epoch=3
05/28/2022 04:43:44 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04216683149651685 on epoch=3, global_step=50
05/28/2022 04:43:46 - INFO - __main__ - Step 60 Global step 60 Train loss 1.86 on epoch=4
05/28/2022 04:43:49 - INFO - __main__ - Step 70 Global step 70 Train loss 1.68 on epoch=4
05/28/2022 04:43:51 - INFO - __main__ - Step 80 Global step 80 Train loss 1.40 on epoch=5
05/28/2022 04:43:54 - INFO - __main__ - Step 90 Global step 90 Train loss 1.09 on epoch=6
05/28/2022 04:43:57 - INFO - __main__ - Step 100 Global step 100 Train loss 1.13 on epoch=7
05/28/2022 04:44:03 - INFO - __main__ - Global step 100 Train loss 1.43 Classification-F1 0.4594348937860341 on epoch=7
05/28/2022 04:44:03 - INFO - __main__ - Saving model with best Classification-F1: 0.04216683149651685 -> 0.4594348937860341 on epoch=7, global_step=100
05/28/2022 04:44:06 - INFO - __main__ - Step 110 Global step 110 Train loss 0.96 on epoch=7
05/28/2022 04:44:08 - INFO - __main__ - Step 120 Global step 120 Train loss 0.86 on epoch=8
05/28/2022 04:44:11 - INFO - __main__ - Step 130 Global step 130 Train loss 0.86 on epoch=9
05/28/2022 04:44:13 - INFO - __main__ - Step 140 Global step 140 Train loss 0.75 on epoch=9
05/28/2022 04:44:16 - INFO - __main__ - Step 150 Global step 150 Train loss 0.65 on epoch=10
05/28/2022 04:44:22 - INFO - __main__ - Global step 150 Train loss 0.82 Classification-F1 0.5000747514753117 on epoch=10
05/28/2022 04:44:22 - INFO - __main__ - Saving model with best Classification-F1: 0.4594348937860341 -> 0.5000747514753117 on epoch=10, global_step=150
05/28/2022 04:44:25 - INFO - __main__ - Step 160 Global step 160 Train loss 0.67 on epoch=11
05/28/2022 04:44:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.60 on epoch=12
05/28/2022 04:44:30 - INFO - __main__ - Step 180 Global step 180 Train loss 0.58 on epoch=12
05/28/2022 04:44:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.57 on epoch=13
05/28/2022 04:44:35 - INFO - __main__ - Step 200 Global step 200 Train loss 0.55 on epoch=14
05/28/2022 04:44:42 - INFO - __main__ - Global step 200 Train loss 0.59 Classification-F1 0.6129663457781405 on epoch=14
05/28/2022 04:44:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5000747514753117 -> 0.6129663457781405 on epoch=14, global_step=200
05/28/2022 04:44:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.61 on epoch=14
05/28/2022 04:44:47 - INFO - __main__ - Step 220 Global step 220 Train loss 0.40 on epoch=15
05/28/2022 04:44:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.43 on epoch=16
05/28/2022 04:44:52 - INFO - __main__ - Step 240 Global step 240 Train loss 0.42 on epoch=17
05/28/2022 04:44:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.49 on epoch=17
05/28/2022 04:45:02 - INFO - __main__ - Global step 250 Train loss 0.47 Classification-F1 0.6720359551515079 on epoch=17
05/28/2022 04:45:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6129663457781405 -> 0.6720359551515079 on epoch=17, global_step=250
05/28/2022 04:45:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.51 on epoch=18
05/28/2022 04:45:07 - INFO - __main__ - Step 270 Global step 270 Train loss 0.44 on epoch=19
05/28/2022 04:45:10 - INFO - __main__ - Step 280 Global step 280 Train loss 0.44 on epoch=19
05/28/2022 04:45:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.35 on epoch=20
05/28/2022 04:45:15 - INFO - __main__ - Step 300 Global step 300 Train loss 0.38 on epoch=21
05/28/2022 04:45:21 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.6797716194565732 on epoch=21
05/28/2022 04:45:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6720359551515079 -> 0.6797716194565732 on epoch=21, global_step=300
05/28/2022 04:45:24 - INFO - __main__ - Step 310 Global step 310 Train loss 0.38 on epoch=22
05/28/2022 04:45:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.38 on epoch=22
05/28/2022 04:45:29 - INFO - __main__ - Step 330 Global step 330 Train loss 0.37 on epoch=23
05/28/2022 04:45:32 - INFO - __main__ - Step 340 Global step 340 Train loss 0.45 on epoch=24
05/28/2022 04:45:34 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=24
05/28/2022 04:45:40 - INFO - __main__ - Global step 350 Train loss 0.39 Classification-F1 0.6474514511406135 on epoch=24
05/28/2022 04:45:43 - INFO - __main__ - Step 360 Global step 360 Train loss 0.34 on epoch=25
05/28/2022 04:45:45 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=26
05/28/2022 04:45:48 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=27
05/28/2022 04:45:51 - INFO - __main__ - Step 390 Global step 390 Train loss 0.25 on epoch=27
05/28/2022 04:45:53 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=28
05/28/2022 04:46:00 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.8613428142518004 on epoch=28
05/28/2022 04:46:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6797716194565732 -> 0.8613428142518004 on epoch=28, global_step=400
05/28/2022 04:46:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.29 on epoch=29
05/28/2022 04:46:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.25 on epoch=29
05/28/2022 04:46:08 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=30
05/28/2022 04:46:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.25 on epoch=31
05/28/2022 04:46:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.34 on epoch=32
05/28/2022 04:46:19 - INFO - __main__ - Global step 450 Train loss 0.28 Classification-F1 0.6942718568653383 on epoch=32
05/28/2022 04:46:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=32
05/28/2022 04:46:24 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=33
05/28/2022 04:46:27 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=34
05/28/2022 04:46:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=34
05/28/2022 04:46:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=35
05/28/2022 04:46:38 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.6068196481172113 on epoch=35
05/28/2022 04:46:41 - INFO - __main__ - Step 510 Global step 510 Train loss 0.31 on epoch=36
05/28/2022 04:46:43 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=37
05/28/2022 04:46:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=37
05/28/2022 04:46:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=38
05/28/2022 04:46:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=39
05/28/2022 04:46:57 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.6886452854194789 on epoch=39
05/28/2022 04:47:00 - INFO - __main__ - Step 560 Global step 560 Train loss 0.29 on epoch=39
05/28/2022 04:47:03 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=40
05/28/2022 04:47:05 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=41
05/28/2022 04:47:08 - INFO - __main__ - Step 590 Global step 590 Train loss 0.14 on epoch=42
05/28/2022 04:47:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=42
05/28/2022 04:47:17 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.8196787503491132 on epoch=42
05/28/2022 04:47:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=43
05/28/2022 04:47:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=44
05/28/2022 04:47:25 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=44
05/28/2022 04:47:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=45
05/28/2022 04:47:30 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=46
05/28/2022 04:47:36 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.8995429149176777 on epoch=46
05/28/2022 04:47:36 - INFO - __main__ - Saving model with best Classification-F1: 0.8613428142518004 -> 0.8995429149176777 on epoch=46, global_step=650
05/28/2022 04:47:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.10 on epoch=47
05/28/2022 04:47:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=47
05/28/2022 04:47:44 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=48
05/28/2022 04:47:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=49
05/28/2022 04:47:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=49
05/28/2022 04:47:55 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.7281736074285621 on epoch=49
05/28/2022 04:47:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=50
05/28/2022 04:48:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=51
05/28/2022 04:48:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=52
05/28/2022 04:48:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
05/28/2022 04:48:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=53
05/28/2022 04:48:14 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.8941987053020555 on epoch=53
05/28/2022 04:48:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=54
05/28/2022 04:48:19 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=54
05/28/2022 04:48:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
05/28/2022 04:48:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=56
05/28/2022 04:48:27 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=57
05/28/2022 04:48:33 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.794749191516024 on epoch=57
05/28/2022 04:48:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=57
05/28/2022 04:48:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=58
05/28/2022 04:48:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=59
05/28/2022 04:48:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=59
05/28/2022 04:48:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=60
05/28/2022 04:48:52 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.775836742321562 on epoch=60
05/28/2022 04:48:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=61
05/28/2022 04:48:57 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=62
05/28/2022 04:49:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
05/28/2022 04:49:02 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=63
05/28/2022 04:49:05 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=64
05/28/2022 04:49:11 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.9817760049717127 on epoch=64
05/28/2022 04:49:11 - INFO - __main__ - Saving model with best Classification-F1: 0.8995429149176777 -> 0.9817760049717127 on epoch=64, global_step=900
05/28/2022 04:49:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=64
05/28/2022 04:49:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=65
05/28/2022 04:49:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=66
05/28/2022 04:49:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=67
05/28/2022 04:49:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=67
05/28/2022 04:49:30 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.7973010465183141 on epoch=67
05/28/2022 04:49:33 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=68
05/28/2022 04:49:35 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=69
05/28/2022 04:49:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
05/28/2022 04:49:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
05/28/2022 04:49:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
05/28/2022 04:49:49 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.9060034883943803 on epoch=71
05/28/2022 04:49:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=72
05/28/2022 04:49:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
05/28/2022 04:49:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
05/28/2022 04:50:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
05/28/2022 04:50:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
05/28/2022 04:50:08 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.6253135847118705 on epoch=74
05/28/2022 04:50:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
05/28/2022 04:50:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=76
05/28/2022 04:50:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=77
05/28/2022 04:50:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=77
05/28/2022 04:50:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
05/28/2022 04:50:27 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.8008625150940141 on epoch=78
05/28/2022 04:50:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=79
05/28/2022 04:50:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
05/28/2022 04:50:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
05/28/2022 04:50:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
05/28/2022 04:50:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=82
05/28/2022 04:50:47 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.747345535443422 on epoch=82
05/28/2022 04:50:49 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=82
05/28/2022 04:50:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=83
05/28/2022 04:50:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
05/28/2022 04:50:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=84
05/28/2022 04:50:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
05/28/2022 04:51:06 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.6635974185251159 on epoch=85
05/28/2022 04:51:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
05/28/2022 04:51:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=87
05/28/2022 04:51:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
05/28/2022 04:51:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
05/28/2022 04:51:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
05/28/2022 04:51:24 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.73366953714554 on epoch=89
05/28/2022 04:51:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=89
05/28/2022 04:51:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=90
05/28/2022 04:51:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
05/28/2022 04:51:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
05/28/2022 04:51:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
05/28/2022 04:51:43 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.8148830252408882 on epoch=92
05/28/2022 04:51:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
05/28/2022 04:51:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
05/28/2022 04:51:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
05/28/2022 04:51:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
05/28/2022 04:51:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=96
05/28/2022 04:52:03 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.847384378054741 on epoch=96
05/28/2022 04:52:05 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
05/28/2022 04:52:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
05/28/2022 04:52:10 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
05/28/2022 04:52:13 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
05/28/2022 04:52:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
05/28/2022 04:52:23 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.9776427873202067 on epoch=99
05/28/2022 04:52:25 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
05/28/2022 04:52:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
05/28/2022 04:52:30 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
05/28/2022 04:52:33 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=102
05/28/2022 04:52:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
05/28/2022 04:52:42 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.8250783939500191 on epoch=103
05/28/2022 04:52:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
05/28/2022 04:52:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
05/28/2022 04:52:49 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
05/28/2022 04:52:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=106
05/28/2022 04:52:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
05/28/2022 04:53:00 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7144158236228129 on epoch=107
05/28/2022 04:53:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
05/28/2022 04:53:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
05/28/2022 04:53:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=109
05/28/2022 04:53:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
05/28/2022 04:53:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
05/28/2022 04:53:20 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.8066737105399345 on epoch=110
05/28/2022 04:53:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
05/28/2022 04:53:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
05/28/2022 04:53:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=112
05/28/2022 04:53:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
05/28/2022 04:53:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
05/28/2022 04:53:42 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7905560347306079 on epoch=114
05/28/2022 04:53:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
05/28/2022 04:53:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
05/28/2022 04:53:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
05/28/2022 04:53:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
05/28/2022 04:53:55 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
05/28/2022 04:54:02 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8592375366568915 on epoch=117
05/28/2022 04:54:04 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
05/28/2022 04:54:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
05/28/2022 04:54:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
05/28/2022 04:54:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
05/28/2022 04:54:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
05/28/2022 04:54:20 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7954547394063523 on epoch=121
05/28/2022 04:54:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
05/28/2022 04:54:25 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
05/28/2022 04:54:28 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
05/28/2022 04:54:30 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
05/28/2022 04:54:33 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
05/28/2022 04:54:39 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7437110704992893 on epoch=124
05/28/2022 04:54:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
05/28/2022 04:54:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
05/28/2022 04:54:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
05/28/2022 04:54:49 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
05/28/2022 04:54:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
05/28/2022 04:54:59 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7721265385302137 on epoch=128
05/28/2022 04:55:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
05/28/2022 04:55:04 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
05/28/2022 04:55:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
05/28/2022 04:55:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
05/28/2022 04:55:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=132
05/28/2022 04:55:18 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.808709485749334 on epoch=132
05/28/2022 04:55:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
05/28/2022 04:55:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
05/28/2022 04:55:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
05/28/2022 04:55:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
05/28/2022 04:55:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
05/28/2022 04:55:37 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8327101661779082 on epoch=135
05/28/2022 04:55:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
05/28/2022 04:55:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/28/2022 04:55:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=137
05/28/2022 04:55:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
05/28/2022 04:55:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
05/28/2022 04:55:56 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.8285155704510543 on epoch=139
05/28/2022 04:55:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
05/28/2022 04:56:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
05/28/2022 04:56:04 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
05/28/2022 04:56:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
05/28/2022 04:56:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
05/28/2022 04:56:15 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.775972793809606 on epoch=142
05/28/2022 04:56:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
05/28/2022 04:56:20 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
05/28/2022 04:56:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
05/28/2022 04:56:25 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
05/28/2022 04:56:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=146
05/28/2022 04:56:34 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8904241220054684 on epoch=146
05/28/2022 04:56:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
05/28/2022 04:56:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
05/28/2022 04:56:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=148
05/28/2022 04:56:45 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
05/28/2022 04:56:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
05/28/2022 04:56:53 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.690181741009415 on epoch=149
05/28/2022 04:56:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
05/28/2022 04:56:58 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
05/28/2022 04:57:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
05/28/2022 04:57:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
05/28/2022 04:57:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
05/28/2022 04:57:12 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7472952998899705 on epoch=153
05/28/2022 04:57:15 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
05/28/2022 04:57:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
05/28/2022 04:57:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
05/28/2022 04:57:23 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
05/28/2022 04:57:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
05/28/2022 04:57:32 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7309516051451536 on epoch=157
05/28/2022 04:57:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
05/28/2022 04:57:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
05/28/2022 04:57:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
05/28/2022 04:57:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
05/28/2022 04:57:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
05/28/2022 04:57:52 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7220404383392499 on epoch=160
05/28/2022 04:57:54 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
05/28/2022 04:57:57 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
05/28/2022 04:57:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
05/28/2022 04:58:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
05/28/2022 04:58:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/28/2022 04:58:12 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6645552297165201 on epoch=164
05/28/2022 04:58:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
05/28/2022 04:58:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
05/28/2022 04:58:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
05/28/2022 04:58:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
05/28/2022 04:58:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
05/28/2022 04:58:31 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8183560991922623 on epoch=167
05/28/2022 04:58:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
05/28/2022 04:58:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
05/28/2022 04:58:39 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
05/28/2022 04:58:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
05/28/2022 04:58:44 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
05/28/2022 04:58:51 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8609970674486804 on epoch=171
05/28/2022 04:58:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
05/28/2022 04:58:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/28/2022 04:58:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
05/28/2022 04:59:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=174
05/28/2022 04:59:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/28/2022 04:59:10 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9186705767350929 on epoch=174
05/28/2022 04:59:13 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/28/2022 04:59:16 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
05/28/2022 04:59:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
05/28/2022 04:59:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
05/28/2022 04:59:23 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/28/2022 04:59:30 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.859103128054741 on epoch=178
05/28/2022 04:59:32 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
05/28/2022 04:59:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
05/28/2022 04:59:37 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/28/2022 04:59:40 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
05/28/2022 04:59:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
05/28/2022 04:59:49 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9820991153059465 on epoch=182
05/28/2022 04:59:49 - INFO - __main__ - Saving model with best Classification-F1: 0.9817760049717127 -> 0.9820991153059465 on epoch=182, global_step=2550
05/28/2022 04:59:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
05/28/2022 04:59:54 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/28/2022 04:59:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
05/28/2022 05:00:00 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
05/28/2022 05:00:02 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
05/28/2022 05:00:08 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7623686355687695 on epoch=185
05/28/2022 05:00:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/28/2022 05:00:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/28/2022 05:00:16 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
05/28/2022 05:00:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
05/28/2022 05:00:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
05/28/2022 05:00:27 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7165392061027736 on epoch=189
05/28/2022 05:00:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/28/2022 05:00:32 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/28/2022 05:00:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/28/2022 05:00:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
05/28/2022 05:00:40 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/28/2022 05:00:46 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7648400513675656 on epoch=192
05/28/2022 05:00:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/28/2022 05:00:51 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
05/28/2022 05:00:54 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
05/28/2022 05:00:56 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
05/28/2022 05:00:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
05/28/2022 05:01:05 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6431648553849693 on epoch=196
05/28/2022 05:01:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
05/28/2022 05:01:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
05/28/2022 05:01:12 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/28/2022 05:01:15 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/28/2022 05:01:17 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
05/28/2022 05:01:24 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8264872224549644 on epoch=199
05/28/2022 05:01:26 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
05/28/2022 05:01:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=201
05/28/2022 05:01:32 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/28/2022 05:01:34 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/28/2022 05:01:37 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
05/28/2022 05:01:43 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7968905225072208 on epoch=203
05/28/2022 05:01:46 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
05/28/2022 05:01:48 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
05/28/2022 05:01:51 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/28/2022 05:01:53 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
05/28/2022 05:01:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
05/28/2022 05:02:02 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7222294630896783 on epoch=207
05/28/2022 05:02:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
05/28/2022 05:02:07 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
05/28/2022 05:02:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/28/2022 05:02:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/28/2022 05:02:15 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/28/2022 05:02:21 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7751710654936462 on epoch=210
05/28/2022 05:02:24 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
05/28/2022 05:02:26 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
05/28/2022 05:02:29 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
05/28/2022 05:02:31 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
05/28/2022 05:02:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
05/28/2022 05:02:36 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 05:02:36 - INFO - __main__ - Printing 3 examples
05/28/2022 05:02:36 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/28/2022 05:02:36 - INFO - __main__ - ['Film']
05/28/2022 05:02:36 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 05:02:36 - INFO - __main__ - ['Film']
05/28/2022 05:02:36 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 05:02:36 - INFO - __main__ - ['Film']
05/28/2022 05:02:36 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:02:36 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:02:36 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 05:02:36 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 05:02:36 - INFO - __main__ - Printing 3 examples
05/28/2022 05:02:36 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/28/2022 05:02:36 - INFO - __main__ - ['Film']
05/28/2022 05:02:36 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/28/2022 05:02:36 - INFO - __main__ - ['Film']
05/28/2022 05:02:36 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/28/2022 05:02:36 - INFO - __main__ - ['Film']
05/28/2022 05:02:36 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:02:36 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:02:36 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 05:02:41 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8045195790926343 on epoch=214
05/28/2022 05:02:41 - INFO - __main__ - save last model!
05/28/2022 05:02:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 05:02:41 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 05:02:41 - INFO - __main__ - Printing 3 examples
05/28/2022 05:02:41 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 05:02:41 - INFO - __main__ - ['Animal']
05/28/2022 05:02:41 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 05:02:41 - INFO - __main__ - ['Animal']
05/28/2022 05:02:41 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 05:02:41 - INFO - __main__ - ['Village']
05/28/2022 05:02:41 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:02:43 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:02:46 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 05:02:52 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 05:02:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 05:02:52 - INFO - __main__ - Starting training!
05/28/2022 05:04:51 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
05/28/2022 05:04:51 - INFO - __main__ - Classification-F1 on test data: 0.6465
05/28/2022 05:04:52 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.9820991153059465, test_performance=0.6464736427165115
05/28/2022 05:04:52 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
05/28/2022 05:04:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 05:04:53 - INFO - __main__ - Printing 3 examples
05/28/2022 05:04:53 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/28/2022 05:04:53 - INFO - __main__ - ['Film']
05/28/2022 05:04:53 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 05:04:53 - INFO - __main__ - ['Film']
05/28/2022 05:04:53 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 05:04:53 - INFO - __main__ - ['Film']
05/28/2022 05:04:53 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:04:53 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:04:53 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 05:04:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 05:04:53 - INFO - __main__ - Printing 3 examples
05/28/2022 05:04:53 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/28/2022 05:04:53 - INFO - __main__ - ['Film']
05/28/2022 05:04:53 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/28/2022 05:04:53 - INFO - __main__ - ['Film']
05/28/2022 05:04:53 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/28/2022 05:04:53 - INFO - __main__ - ['Film']
05/28/2022 05:04:53 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:04:53 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:04:53 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 05:05:09 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 05:05:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 05:05:09 - INFO - __main__ - Starting training!
05/28/2022 05:05:13 - INFO - __main__ - Step 10 Global step 10 Train loss 7.24 on epoch=0
05/28/2022 05:05:16 - INFO - __main__ - Step 20 Global step 20 Train loss 5.14 on epoch=1
05/28/2022 05:05:18 - INFO - __main__ - Step 30 Global step 30 Train loss 3.82 on epoch=2
05/28/2022 05:05:21 - INFO - __main__ - Step 40 Global step 40 Train loss 3.41 on epoch=2
05/28/2022 05:05:23 - INFO - __main__ - Step 50 Global step 50 Train loss 2.96 on epoch=3
05/28/2022 05:05:30 - INFO - __main__ - Global step 50 Train loss 4.51 Classification-F1 0.04318813716404078 on epoch=3
05/28/2022 05:05:30 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04318813716404078 on epoch=3, global_step=50
05/28/2022 05:05:32 - INFO - __main__ - Step 60 Global step 60 Train loss 2.45 on epoch=4
05/28/2022 05:05:35 - INFO - __main__ - Step 70 Global step 70 Train loss 2.12 on epoch=4
05/28/2022 05:05:37 - INFO - __main__ - Step 80 Global step 80 Train loss 1.69 on epoch=5
05/28/2022 05:05:40 - INFO - __main__ - Step 90 Global step 90 Train loss 1.46 on epoch=6
05/28/2022 05:05:42 - INFO - __main__ - Step 100 Global step 100 Train loss 1.32 on epoch=7
05/28/2022 05:05:50 - INFO - __main__ - Global step 100 Train loss 1.81 Classification-F1 0.3105560032832969 on epoch=7
05/28/2022 05:05:50 - INFO - __main__ - Saving model with best Classification-F1: 0.04318813716404078 -> 0.3105560032832969 on epoch=7, global_step=100
05/28/2022 05:05:52 - INFO - __main__ - Step 110 Global step 110 Train loss 1.20 on epoch=7
05/28/2022 05:05:55 - INFO - __main__ - Step 120 Global step 120 Train loss 1.03 on epoch=8
05/28/2022 05:05:57 - INFO - __main__ - Step 130 Global step 130 Train loss 0.88 on epoch=9
05/28/2022 05:06:00 - INFO - __main__ - Step 140 Global step 140 Train loss 0.85 on epoch=9
05/28/2022 05:06:02 - INFO - __main__ - Step 150 Global step 150 Train loss 0.69 on epoch=10
05/28/2022 05:06:09 - INFO - __main__ - Global step 150 Train loss 0.93 Classification-F1 0.4524875404560822 on epoch=10
05/28/2022 05:06:09 - INFO - __main__ - Saving model with best Classification-F1: 0.3105560032832969 -> 0.4524875404560822 on epoch=10, global_step=150
05/28/2022 05:06:12 - INFO - __main__ - Step 160 Global step 160 Train loss 0.82 on epoch=11
05/28/2022 05:06:15 - INFO - __main__ - Step 170 Global step 170 Train loss 0.74 on epoch=12
05/28/2022 05:06:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.74 on epoch=12
05/28/2022 05:06:20 - INFO - __main__ - Step 190 Global step 190 Train loss 0.70 on epoch=13
05/28/2022 05:06:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.62 on epoch=14
05/28/2022 05:06:29 - INFO - __main__ - Global step 200 Train loss 0.73 Classification-F1 0.487079578555062 on epoch=14
05/28/2022 05:06:29 - INFO - __main__ - Saving model with best Classification-F1: 0.4524875404560822 -> 0.487079578555062 on epoch=14, global_step=200
05/28/2022 05:06:31 - INFO - __main__ - Step 210 Global step 210 Train loss 0.61 on epoch=14
05/28/2022 05:06:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=15
05/28/2022 05:06:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.63 on epoch=16
05/28/2022 05:06:39 - INFO - __main__ - Step 240 Global step 240 Train loss 0.55 on epoch=17
05/28/2022 05:06:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=17
05/28/2022 05:06:48 - INFO - __main__ - Global step 250 Train loss 0.57 Classification-F1 0.6759370523799854 on epoch=17
05/28/2022 05:06:48 - INFO - __main__ - Saving model with best Classification-F1: 0.487079578555062 -> 0.6759370523799854 on epoch=17, global_step=250
05/28/2022 05:06:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.57 on epoch=18
05/28/2022 05:06:53 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=19
05/28/2022 05:06:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.52 on epoch=19
05/28/2022 05:06:58 - INFO - __main__ - Step 290 Global step 290 Train loss 0.50 on epoch=20
05/28/2022 05:07:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.38 on epoch=21
05/28/2022 05:07:08 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.6397729993318229 on epoch=21
05/28/2022 05:07:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.53 on epoch=22
05/28/2022 05:07:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.41 on epoch=22
05/28/2022 05:07:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=23
05/28/2022 05:07:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.44 on epoch=24
05/28/2022 05:07:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=24
05/28/2022 05:07:27 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.6858498508392232 on epoch=24
05/28/2022 05:07:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6759370523799854 -> 0.6858498508392232 on epoch=24, global_step=350
05/28/2022 05:07:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.42 on epoch=25
05/28/2022 05:07:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=26
05/28/2022 05:07:35 - INFO - __main__ - Step 380 Global step 380 Train loss 0.40 on epoch=27
05/28/2022 05:07:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.42 on epoch=27
05/28/2022 05:07:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.40 on epoch=28
05/28/2022 05:07:47 - INFO - __main__ - Global step 400 Train loss 0.42 Classification-F1 0.8785356978337432 on epoch=28
05/28/2022 05:07:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6858498508392232 -> 0.8785356978337432 on epoch=28, global_step=400
05/28/2022 05:07:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.41 on epoch=29
05/28/2022 05:07:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=29
05/28/2022 05:07:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=30
05/28/2022 05:07:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=31
05/28/2022 05:08:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.29 on epoch=32
05/28/2022 05:08:07 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.8669390521763507 on epoch=32
05/28/2022 05:08:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.34 on epoch=32
05/28/2022 05:08:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.36 on epoch=33
05/28/2022 05:08:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=34
05/28/2022 05:08:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=34
05/28/2022 05:08:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.30 on epoch=35
05/28/2022 05:08:27 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.8490779072053581 on epoch=35
05/28/2022 05:08:30 - INFO - __main__ - Step 510 Global step 510 Train loss 0.32 on epoch=36
05/28/2022 05:08:32 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=37
05/28/2022 05:08:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.30 on epoch=37
05/28/2022 05:08:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=38
05/28/2022 05:08:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=39
05/28/2022 05:08:46 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.8020286194103563 on epoch=39
05/28/2022 05:08:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=39
05/28/2022 05:08:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=40
05/28/2022 05:08:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=41
05/28/2022 05:08:57 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=42
05/28/2022 05:08:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=42
05/28/2022 05:09:06 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.8683401294502409 on epoch=42
05/28/2022 05:09:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=43
05/28/2022 05:09:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=44
05/28/2022 05:09:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=44
05/28/2022 05:09:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=45
05/28/2022 05:09:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=46
05/28/2022 05:09:26 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.8388828157729367 on epoch=46
05/28/2022 05:09:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=47
05/28/2022 05:09:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
05/28/2022 05:09:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.25 on epoch=48
05/28/2022 05:09:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=49
05/28/2022 05:09:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=49
05/28/2022 05:09:45 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.8597314550271539 on epoch=49
05/28/2022 05:09:48 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=50
05/28/2022 05:09:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=51
05/28/2022 05:09:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=52
05/28/2022 05:09:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=52
05/28/2022 05:09:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=53
05/28/2022 05:10:05 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.9648185188568404 on epoch=53
05/28/2022 05:10:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8785356978337432 -> 0.9648185188568404 on epoch=53, global_step=750
05/28/2022 05:10:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=54
05/28/2022 05:10:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=54
05/28/2022 05:10:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=55
05/28/2022 05:10:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=56
05/28/2022 05:10:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=57
05/28/2022 05:10:25 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.9494717591491787 on epoch=57
05/28/2022 05:10:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=57
05/28/2022 05:10:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=58
05/28/2022 05:10:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=59
05/28/2022 05:10:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=59
05/28/2022 05:10:38 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=60
05/28/2022 05:10:45 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.7906707811831152 on epoch=60
05/28/2022 05:10:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=61
05/28/2022 05:10:50 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=62
05/28/2022 05:10:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=62
05/28/2022 05:10:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=63
05/28/2022 05:10:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=64
05/28/2022 05:11:04 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.7091773484760974 on epoch=64
05/28/2022 05:11:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=64
05/28/2022 05:11:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=65
05/28/2022 05:11:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=66
05/28/2022 05:11:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=67
05/28/2022 05:11:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=67
05/28/2022 05:11:24 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.6565890049247212 on epoch=67
05/28/2022 05:11:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=68
05/28/2022 05:11:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
05/28/2022 05:11:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
05/28/2022 05:11:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=70
05/28/2022 05:11:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=71
05/28/2022 05:11:43 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.5951765431713912 on epoch=71
05/28/2022 05:11:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
05/28/2022 05:11:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=72
05/28/2022 05:11:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=73
05/28/2022 05:11:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
05/28/2022 05:11:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=74
05/28/2022 05:12:02 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.6469034573236612 on epoch=74
05/28/2022 05:12:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=75
05/28/2022 05:12:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
05/28/2022 05:12:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
05/28/2022 05:12:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=77
05/28/2022 05:12:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=78
05/28/2022 05:12:21 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7548855983656184 on epoch=78
05/28/2022 05:12:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
05/28/2022 05:12:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=79
05/28/2022 05:12:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=80
05/28/2022 05:12:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=81
05/28/2022 05:12:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=82
05/28/2022 05:12:40 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.8526549655721732 on epoch=82
05/28/2022 05:12:43 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
05/28/2022 05:12:45 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=83
05/28/2022 05:12:48 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=84
05/28/2022 05:12:50 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
05/28/2022 05:12:53 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
05/28/2022 05:13:00 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.753525860912336 on epoch=85
05/28/2022 05:13:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
05/28/2022 05:13:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
05/28/2022 05:13:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=87
05/28/2022 05:13:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=88
05/28/2022 05:13:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
05/28/2022 05:13:19 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.7039466647323417 on epoch=89
05/28/2022 05:13:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
05/28/2022 05:13:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=90
05/28/2022 05:13:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=91
05/28/2022 05:13:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
05/28/2022 05:13:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
05/28/2022 05:13:38 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.8067079565819486 on epoch=92
05/28/2022 05:13:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
05/28/2022 05:13:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
05/28/2022 05:13:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
05/28/2022 05:13:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
05/28/2022 05:13:51 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
05/28/2022 05:13:57 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.8524396399159209 on epoch=96
05/28/2022 05:14:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=97
05/28/2022 05:14:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
05/28/2022 05:14:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=98
05/28/2022 05:14:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
05/28/2022 05:14:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
05/28/2022 05:14:17 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.9029312917737966 on epoch=99
05/28/2022 05:14:19 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
05/28/2022 05:14:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
05/28/2022 05:14:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
05/28/2022 05:14:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
05/28/2022 05:14:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
05/28/2022 05:14:36 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.8647985228630392 on epoch=103
05/28/2022 05:14:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
05/28/2022 05:14:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
05/28/2022 05:14:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
05/28/2022 05:14:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
05/28/2022 05:14:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
05/28/2022 05:14:56 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7444152147662585 on epoch=107
05/28/2022 05:14:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
05/28/2022 05:15:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
05/28/2022 05:15:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
05/28/2022 05:15:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
05/28/2022 05:15:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
05/28/2022 05:15:15 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.9011223901546482 on epoch=110
05/28/2022 05:15:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
05/28/2022 05:15:20 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
05/28/2022 05:15:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
05/28/2022 05:15:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
05/28/2022 05:15:28 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
05/28/2022 05:15:33 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7998981977258494 on epoch=114
05/28/2022 05:15:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=114
05/28/2022 05:15:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
05/28/2022 05:15:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
05/28/2022 05:15:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
05/28/2022 05:15:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
05/28/2022 05:15:53 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8919194581275546 on epoch=117
05/28/2022 05:15:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
05/28/2022 05:15:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
05/28/2022 05:16:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
05/28/2022 05:16:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
05/28/2022 05:16:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
05/28/2022 05:16:13 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9029312917737966 on epoch=121
05/28/2022 05:16:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
05/28/2022 05:16:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
05/28/2022 05:16:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
05/28/2022 05:16:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
05/28/2022 05:16:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
05/28/2022 05:16:31 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.8979837080482244 on epoch=124
05/28/2022 05:16:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
05/28/2022 05:16:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
05/28/2022 05:16:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
05/28/2022 05:16:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
05/28/2022 05:16:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
05/28/2022 05:16:50 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.8413161253310438 on epoch=128
05/28/2022 05:16:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
05/28/2022 05:16:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
05/28/2022 05:16:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
05/28/2022 05:17:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
05/28/2022 05:17:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
05/28/2022 05:17:10 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.897840338872597 on epoch=132
05/28/2022 05:17:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
05/28/2022 05:17:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
05/28/2022 05:17:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
05/28/2022 05:17:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
05/28/2022 05:17:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
05/28/2022 05:17:29 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8458129683936139 on epoch=135
05/28/2022 05:17:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
05/28/2022 05:17:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
05/28/2022 05:17:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
05/28/2022 05:17:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
05/28/2022 05:17:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
05/28/2022 05:17:48 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.8894390337319409 on epoch=139
05/28/2022 05:17:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
05/28/2022 05:17:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
05/28/2022 05:17:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
05/28/2022 05:17:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
05/28/2022 05:18:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
05/28/2022 05:18:07 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.8820087018189485 on epoch=142
05/28/2022 05:18:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
05/28/2022 05:18:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
05/28/2022 05:18:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
05/28/2022 05:18:17 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
05/28/2022 05:18:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
05/28/2022 05:18:26 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.8969516505000378 on epoch=146
05/28/2022 05:18:29 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
05/28/2022 05:18:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=147
05/28/2022 05:18:34 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
05/28/2022 05:18:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
05/28/2022 05:18:39 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
05/28/2022 05:18:45 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8390693242612042 on epoch=149
05/28/2022 05:18:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
05/28/2022 05:18:50 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
05/28/2022 05:18:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
05/28/2022 05:18:55 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
05/28/2022 05:18:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
05/28/2022 05:19:04 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9103045636631976 on epoch=153
05/28/2022 05:19:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
05/28/2022 05:19:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
05/28/2022 05:19:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
05/28/2022 05:19:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
05/28/2022 05:19:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
05/28/2022 05:19:23 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8363758553274683 on epoch=157
05/28/2022 05:19:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
05/28/2022 05:19:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
05/28/2022 05:19:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
05/28/2022 05:19:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
05/28/2022 05:19:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
05/28/2022 05:19:42 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9776304656760065 on epoch=160
05/28/2022 05:19:42 - INFO - __main__ - Saving model with best Classification-F1: 0.9648185188568404 -> 0.9776304656760065 on epoch=160, global_step=2250
05/28/2022 05:19:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
05/28/2022 05:19:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
05/28/2022 05:19:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
05/28/2022 05:19:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
05/28/2022 05:19:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
05/28/2022 05:20:02 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9777840755070358 on epoch=164
05/28/2022 05:20:02 - INFO - __main__ - Saving model with best Classification-F1: 0.9776304656760065 -> 0.9777840755070358 on epoch=164, global_step=2300
05/28/2022 05:20:04 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
05/28/2022 05:20:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
05/28/2022 05:20:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=166
05/28/2022 05:20:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
05/28/2022 05:20:14 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
05/28/2022 05:20:21 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9186705767350929 on epoch=167
05/28/2022 05:20:23 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
05/28/2022 05:20:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
05/28/2022 05:20:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
05/28/2022 05:20:31 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
05/28/2022 05:20:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=171
05/28/2022 05:20:40 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8375657907346714 on epoch=171
05/28/2022 05:20:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
05/28/2022 05:20:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
05/28/2022 05:20:47 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
05/28/2022 05:20:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
05/28/2022 05:20:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
05/28/2022 05:20:59 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8410988921472793 on epoch=174
05/28/2022 05:21:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
05/28/2022 05:21:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
05/28/2022 05:21:06 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
05/28/2022 05:21:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
05/28/2022 05:21:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
05/28/2022 05:21:18 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.823619257086999 on epoch=178
05/28/2022 05:21:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
05/28/2022 05:21:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
05/28/2022 05:21:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
05/28/2022 05:21:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
05/28/2022 05:21:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
05/28/2022 05:21:37 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8535896600412729 on epoch=182
05/28/2022 05:21:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/28/2022 05:21:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
05/28/2022 05:21:44 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
05/28/2022 05:21:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
05/28/2022 05:21:49 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
05/28/2022 05:21:55 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9774768558449775 on epoch=185
05/28/2022 05:21:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
05/28/2022 05:22:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
05/28/2022 05:22:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
05/28/2022 05:22:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
05/28/2022 05:22:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/28/2022 05:22:14 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.914360540892799 on epoch=189
05/28/2022 05:22:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
05/28/2022 05:22:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
05/28/2022 05:22:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
05/28/2022 05:22:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
05/28/2022 05:22:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
05/28/2022 05:22:34 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8609970674486804 on epoch=192
05/28/2022 05:22:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/28/2022 05:22:39 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
05/28/2022 05:22:41 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
05/28/2022 05:22:44 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.07 on epoch=195
05/28/2022 05:22:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
05/28/2022 05:22:53 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9137811934697363 on epoch=196
05/28/2022 05:22:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
05/28/2022 05:22:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
05/28/2022 05:23:01 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
05/28/2022 05:23:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
05/28/2022 05:23:06 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/28/2022 05:23:13 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8818954727541066 on epoch=199
05/28/2022 05:23:15 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/28/2022 05:23:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
05/28/2022 05:23:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/28/2022 05:23:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
05/28/2022 05:23:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
05/28/2022 05:23:32 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9822527251369758 on epoch=203
05/28/2022 05:23:32 - INFO - __main__ - Saving model with best Classification-F1: 0.9777840755070358 -> 0.9822527251369758 on epoch=203, global_step=2850
05/28/2022 05:23:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
05/28/2022 05:23:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
05/28/2022 05:23:40 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
05/28/2022 05:23:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
05/28/2022 05:23:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/28/2022 05:23:52 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9777840755070358 on epoch=207
05/28/2022 05:23:54 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
05/28/2022 05:23:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
05/28/2022 05:23:59 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
05/28/2022 05:24:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
05/28/2022 05:24:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
05/28/2022 05:24:12 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9055626225614122 on epoch=210
05/28/2022 05:24:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
05/28/2022 05:24:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
05/28/2022 05:24:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
05/28/2022 05:24:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
05/28/2022 05:24:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
05/28/2022 05:24:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 05:24:26 - INFO - __main__ - Printing 3 examples
05/28/2022 05:24:26 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/28/2022 05:24:26 - INFO - __main__ - ['Film']
05/28/2022 05:24:26 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 05:24:26 - INFO - __main__ - ['Film']
05/28/2022 05:24:26 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 05:24:26 - INFO - __main__ - ['Film']
05/28/2022 05:24:26 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:24:26 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:24:27 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 05:24:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 05:24:27 - INFO - __main__ - Printing 3 examples
05/28/2022 05:24:27 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/28/2022 05:24:27 - INFO - __main__ - ['Film']
05/28/2022 05:24:27 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/28/2022 05:24:27 - INFO - __main__ - ['Film']
05/28/2022 05:24:27 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/28/2022 05:24:27 - INFO - __main__ - ['Film']
05/28/2022 05:24:27 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:24:27 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:24:27 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 05:24:31 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9730082062150375 on epoch=214
05/28/2022 05:24:31 - INFO - __main__ - save last model!
05/28/2022 05:24:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 05:24:31 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 05:24:31 - INFO - __main__ - Printing 3 examples
05/28/2022 05:24:31 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 05:24:31 - INFO - __main__ - ['Animal']
05/28/2022 05:24:31 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 05:24:31 - INFO - __main__ - ['Animal']
05/28/2022 05:24:31 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 05:24:31 - INFO - __main__ - ['Village']
05/28/2022 05:24:31 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:24:33 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:24:36 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 05:24:45 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 05:24:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 05:24:46 - INFO - __main__ - Starting training!
05/28/2022 05:26:45 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
05/28/2022 05:26:45 - INFO - __main__ - Classification-F1 on test data: 0.6817
05/28/2022 05:26:45 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.9822527251369758, test_performance=0.6817050742729899
05/28/2022 05:26:45 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
05/28/2022 05:26:46 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 05:26:46 - INFO - __main__ - Printing 3 examples
05/28/2022 05:26:46 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/28/2022 05:26:46 - INFO - __main__ - ['Film']
05/28/2022 05:26:46 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/28/2022 05:26:46 - INFO - __main__ - ['Film']
05/28/2022 05:26:46 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/28/2022 05:26:46 - INFO - __main__ - ['Film']
05/28/2022 05:26:46 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:26:47 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:26:47 - INFO - __main__ - Loaded 224 examples from train data
05/28/2022 05:26:47 - INFO - __main__ - Start tokenizing ... 224 instances
05/28/2022 05:26:47 - INFO - __main__ - Printing 3 examples
05/28/2022 05:26:47 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/28/2022 05:26:47 - INFO - __main__ - ['Film']
05/28/2022 05:26:47 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/28/2022 05:26:47 - INFO - __main__ - ['Film']
05/28/2022 05:26:47 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/28/2022 05:26:47 - INFO - __main__ - ['Film']
05/28/2022 05:26:47 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:26:47 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:26:47 - INFO - __main__ - Loaded 224 examples from dev data
05/28/2022 05:27:02 - INFO - __main__ - load prompt embedding from ckpt
05/28/2022 05:27:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/28/2022 05:27:03 - INFO - __main__ - Starting training!
05/28/2022 05:27:07 - INFO - __main__ - Step 10 Global step 10 Train loss 7.18 on epoch=0
05/28/2022 05:27:09 - INFO - __main__ - Step 20 Global step 20 Train loss 5.60 on epoch=1
05/28/2022 05:27:12 - INFO - __main__ - Step 30 Global step 30 Train loss 4.46 on epoch=2
05/28/2022 05:27:15 - INFO - __main__ - Step 40 Global step 40 Train loss 3.91 on epoch=2
05/28/2022 05:27:17 - INFO - __main__ - Step 50 Global step 50 Train loss 3.51 on epoch=3
05/28/2022 05:27:34 - INFO - __main__ - Global step 50 Train loss 4.93 Classification-F1 0.009877319911921988 on epoch=3
05/28/2022 05:27:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009877319911921988 on epoch=3, global_step=50
05/28/2022 05:27:36 - INFO - __main__ - Step 60 Global step 60 Train loss 3.08 on epoch=4
05/28/2022 05:27:39 - INFO - __main__ - Step 70 Global step 70 Train loss 2.82 on epoch=4
05/28/2022 05:27:41 - INFO - __main__ - Step 80 Global step 80 Train loss 2.61 on epoch=5
05/28/2022 05:27:44 - INFO - __main__ - Step 90 Global step 90 Train loss 2.37 on epoch=6
05/28/2022 05:27:47 - INFO - __main__ - Step 100 Global step 100 Train loss 2.05 on epoch=7
05/28/2022 05:27:52 - INFO - __main__ - Global step 100 Train loss 2.59 Classification-F1 0.04243521184697655 on epoch=7
05/28/2022 05:27:52 - INFO - __main__ - Saving model with best Classification-F1: 0.009877319911921988 -> 0.04243521184697655 on epoch=7, global_step=100
05/28/2022 05:27:55 - INFO - __main__ - Step 110 Global step 110 Train loss 1.90 on epoch=7
05/28/2022 05:27:57 - INFO - __main__ - Step 120 Global step 120 Train loss 1.72 on epoch=8
05/28/2022 05:28:00 - INFO - __main__ - Step 130 Global step 130 Train loss 1.48 on epoch=9
05/28/2022 05:28:02 - INFO - __main__ - Step 140 Global step 140 Train loss 1.42 on epoch=9
05/28/2022 05:28:05 - INFO - __main__ - Step 150 Global step 150 Train loss 1.19 on epoch=10
05/28/2022 05:28:13 - INFO - __main__ - Global step 150 Train loss 1.54 Classification-F1 0.38084053991769456 on epoch=10
05/28/2022 05:28:13 - INFO - __main__ - Saving model with best Classification-F1: 0.04243521184697655 -> 0.38084053991769456 on epoch=10, global_step=150
05/28/2022 05:28:16 - INFO - __main__ - Step 160 Global step 160 Train loss 1.10 on epoch=11
05/28/2022 05:28:18 - INFO - __main__ - Step 170 Global step 170 Train loss 1.01 on epoch=12
05/28/2022 05:28:21 - INFO - __main__ - Step 180 Global step 180 Train loss 0.88 on epoch=12
05/28/2022 05:28:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.85 on epoch=13
05/28/2022 05:28:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.86 on epoch=14
05/28/2022 05:28:33 - INFO - __main__ - Global step 200 Train loss 0.94 Classification-F1 0.4613199788199787 on epoch=14
05/28/2022 05:28:33 - INFO - __main__ - Saving model with best Classification-F1: 0.38084053991769456 -> 0.4613199788199787 on epoch=14, global_step=200
05/28/2022 05:28:35 - INFO - __main__ - Step 210 Global step 210 Train loss 0.93 on epoch=14
05/28/2022 05:28:38 - INFO - __main__ - Step 220 Global step 220 Train loss 0.76 on epoch=15
05/28/2022 05:28:40 - INFO - __main__ - Step 230 Global step 230 Train loss 0.65 on epoch=16
05/28/2022 05:28:43 - INFO - __main__ - Step 240 Global step 240 Train loss 0.76 on epoch=17
05/28/2022 05:28:45 - INFO - __main__ - Step 250 Global step 250 Train loss 0.78 on epoch=17
05/28/2022 05:28:52 - INFO - __main__ - Global step 250 Train loss 0.78 Classification-F1 0.4225438905742511 on epoch=17
05/28/2022 05:28:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.73 on epoch=18
05/28/2022 05:28:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.68 on epoch=19
05/28/2022 05:29:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.65 on epoch=19
05/28/2022 05:29:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.60 on epoch=20
05/28/2022 05:29:05 - INFO - __main__ - Step 300 Global step 300 Train loss 0.65 on epoch=21
05/28/2022 05:29:11 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.5222643657539011 on epoch=21
05/28/2022 05:29:11 - INFO - __main__ - Saving model with best Classification-F1: 0.4613199788199787 -> 0.5222643657539011 on epoch=21, global_step=300
05/28/2022 05:29:14 - INFO - __main__ - Step 310 Global step 310 Train loss 0.55 on epoch=22
05/28/2022 05:29:16 - INFO - __main__ - Step 320 Global step 320 Train loss 0.55 on epoch=22
05/28/2022 05:29:19 - INFO - __main__ - Step 330 Global step 330 Train loss 0.51 on epoch=23
05/28/2022 05:29:22 - INFO - __main__ - Step 340 Global step 340 Train loss 0.62 on epoch=24
05/28/2022 05:29:24 - INFO - __main__ - Step 350 Global step 350 Train loss 0.48 on epoch=24
05/28/2022 05:29:31 - INFO - __main__ - Global step 350 Train loss 0.54 Classification-F1 0.6391639119171799 on epoch=24
05/28/2022 05:29:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5222643657539011 -> 0.6391639119171799 on epoch=24, global_step=350
05/28/2022 05:29:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.48 on epoch=25
05/28/2022 05:29:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.58 on epoch=26
05/28/2022 05:29:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.55 on epoch=27
05/28/2022 05:29:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.45 on epoch=27
05/28/2022 05:29:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.50 on epoch=28
05/28/2022 05:29:51 - INFO - __main__ - Global step 400 Train loss 0.51 Classification-F1 0.6104588860443748 on epoch=28
05/28/2022 05:29:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.55 on epoch=29
05/28/2022 05:29:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.40 on epoch=29
05/28/2022 05:29:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.40 on epoch=30
05/28/2022 05:30:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.48 on epoch=31
05/28/2022 05:30:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.47 on epoch=32
05/28/2022 05:30:10 - INFO - __main__ - Global step 450 Train loss 0.46 Classification-F1 0.7075996851456224 on epoch=32
05/28/2022 05:30:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6391639119171799 -> 0.7075996851456224 on epoch=32, global_step=450
05/28/2022 05:30:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.33 on epoch=32
05/28/2022 05:30:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.52 on epoch=33
05/28/2022 05:30:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.46 on epoch=34
05/28/2022 05:30:21 - INFO - __main__ - Step 490 Global step 490 Train loss 0.48 on epoch=34
05/28/2022 05:30:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.39 on epoch=35
05/28/2022 05:30:30 - INFO - __main__ - Global step 500 Train loss 0.43 Classification-F1 0.65304504958655 on epoch=35
05/28/2022 05:30:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.38 on epoch=36
05/28/2022 05:30:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=37
05/28/2022 05:30:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.30 on epoch=37
05/28/2022 05:30:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=38
05/28/2022 05:30:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.43 on epoch=39
05/28/2022 05:30:50 - INFO - __main__ - Global step 550 Train loss 0.38 Classification-F1 0.7904336004690974 on epoch=39
05/28/2022 05:30:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7075996851456224 -> 0.7904336004690974 on epoch=39, global_step=550
05/28/2022 05:30:52 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=39
05/28/2022 05:30:55 - INFO - __main__ - Step 570 Global step 570 Train loss 0.36 on epoch=40
05/28/2022 05:30:57 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=41
05/28/2022 05:31:00 - INFO - __main__ - Step 590 Global step 590 Train loss 0.41 on epoch=42
05/28/2022 05:31:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.28 on epoch=42
05/28/2022 05:31:09 - INFO - __main__ - Global step 600 Train loss 0.35 Classification-F1 0.787005958789176 on epoch=42
05/28/2022 05:31:12 - INFO - __main__ - Step 610 Global step 610 Train loss 0.37 on epoch=43
05/28/2022 05:31:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.31 on epoch=44
05/28/2022 05:31:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.28 on epoch=44
05/28/2022 05:31:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.29 on epoch=45
05/28/2022 05:31:22 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=46
05/28/2022 05:31:28 - INFO - __main__ - Global step 650 Train loss 0.31 Classification-F1 0.8062785191002747 on epoch=46
05/28/2022 05:31:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7904336004690974 -> 0.8062785191002747 on epoch=46, global_step=650
05/28/2022 05:31:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.33 on epoch=47
05/28/2022 05:31:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.32 on epoch=47
05/28/2022 05:31:36 - INFO - __main__ - Step 680 Global step 680 Train loss 0.30 on epoch=48
05/28/2022 05:31:39 - INFO - __main__ - Step 690 Global step 690 Train loss 0.32 on epoch=49
05/28/2022 05:31:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.38 on epoch=49
05/28/2022 05:31:47 - INFO - __main__ - Global step 700 Train loss 0.33 Classification-F1 0.7431171231322441 on epoch=49
05/28/2022 05:31:50 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=50
05/28/2022 05:31:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=51
05/28/2022 05:31:55 - INFO - __main__ - Step 730 Global step 730 Train loss 0.31 on epoch=52
05/28/2022 05:31:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.27 on epoch=52
05/28/2022 05:32:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.34 on epoch=53
05/28/2022 05:32:07 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.8117154016807225 on epoch=53
05/28/2022 05:32:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8062785191002747 -> 0.8117154016807225 on epoch=53, global_step=750
05/28/2022 05:32:10 - INFO - __main__ - Step 760 Global step 760 Train loss 0.28 on epoch=54
05/28/2022 05:32:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.26 on epoch=54
05/28/2022 05:32:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=55
05/28/2022 05:32:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.34 on epoch=56
05/28/2022 05:32:20 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=57
05/28/2022 05:32:27 - INFO - __main__ - Global step 800 Train loss 0.28 Classification-F1 0.8131059126047021 on epoch=57
05/28/2022 05:32:27 - INFO - __main__ - Saving model with best Classification-F1: 0.8117154016807225 -> 0.8131059126047021 on epoch=57, global_step=800
05/28/2022 05:32:29 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=57
05/28/2022 05:32:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.28 on epoch=58
05/28/2022 05:32:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.25 on epoch=59
05/28/2022 05:32:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.24 on epoch=59
05/28/2022 05:32:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.25 on epoch=60
05/28/2022 05:32:47 - INFO - __main__ - Global step 850 Train loss 0.24 Classification-F1 0.7687542678548599 on epoch=60
05/28/2022 05:32:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=61
05/28/2022 05:32:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.29 on epoch=62
05/28/2022 05:32:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=62
05/28/2022 05:32:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.22 on epoch=63
05/28/2022 05:33:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=64
05/28/2022 05:33:07 - INFO - __main__ - Global step 900 Train loss 0.23 Classification-F1 0.8777402557746731 on epoch=64
05/28/2022 05:33:07 - INFO - __main__ - Saving model with best Classification-F1: 0.8131059126047021 -> 0.8777402557746731 on epoch=64, global_step=900
05/28/2022 05:33:09 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=64
05/28/2022 05:33:12 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=65
05/28/2022 05:33:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=66
05/28/2022 05:33:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.30 on epoch=67
05/28/2022 05:33:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=67
05/28/2022 05:33:26 - INFO - __main__ - Global step 950 Train loss 0.24 Classification-F1 0.80704937953204 on epoch=67
05/28/2022 05:33:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.22 on epoch=68
05/28/2022 05:33:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=69
05/28/2022 05:33:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=69
05/28/2022 05:33:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=70
05/28/2022 05:33:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.23 on epoch=71
05/28/2022 05:33:45 - INFO - __main__ - Global step 1000 Train loss 0.20 Classification-F1 0.8127636652463257 on epoch=71
05/28/2022 05:33:48 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=72
05/28/2022 05:33:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=72
05/28/2022 05:33:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=73
05/28/2022 05:33:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=74
05/28/2022 05:33:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.22 on epoch=74
05/28/2022 05:34:05 - INFO - __main__ - Global step 1050 Train loss 0.19 Classification-F1 0.7162998019808146 on epoch=74
05/28/2022 05:34:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=75
05/28/2022 05:34:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=76
05/28/2022 05:34:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.25 on epoch=77
05/28/2022 05:34:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=77
05/28/2022 05:34:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=78
05/28/2022 05:34:24 - INFO - __main__ - Global step 1100 Train loss 0.20 Classification-F1 0.7690842462857325 on epoch=78
05/28/2022 05:34:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=79
05/28/2022 05:34:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=79
05/28/2022 05:34:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=80
05/28/2022 05:34:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=81
05/28/2022 05:34:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.29 on epoch=82
05/28/2022 05:34:44 - INFO - __main__ - Global step 1150 Train loss 0.21 Classification-F1 0.7326902545118863 on epoch=82
05/28/2022 05:34:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=82
05/28/2022 05:34:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.22 on epoch=83
05/28/2022 05:34:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=84
05/28/2022 05:34:54 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.18 on epoch=84
05/28/2022 05:34:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=85
05/28/2022 05:35:04 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.8228973055690922 on epoch=85
05/28/2022 05:35:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=86
05/28/2022 05:35:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.18 on epoch=87
05/28/2022 05:35:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
05/28/2022 05:35:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
05/28/2022 05:35:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=89
05/28/2022 05:35:24 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.7873044709784803 on epoch=89
05/28/2022 05:35:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=89
05/28/2022 05:35:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=90
05/28/2022 05:35:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=91
05/28/2022 05:35:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.17 on epoch=92
05/28/2022 05:35:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=92
05/28/2022 05:35:44 - INFO - __main__ - Global step 1300 Train loss 0.14 Classification-F1 0.8216437029835522 on epoch=92
05/28/2022 05:35:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=93
05/28/2022 05:35:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=94
05/28/2022 05:35:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=94
05/28/2022 05:35:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=95
05/28/2022 05:35:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=96
05/28/2022 05:36:04 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.6639511927385717 on epoch=96
05/28/2022 05:36:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=97
05/28/2022 05:36:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.18 on epoch=97
05/28/2022 05:36:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
05/28/2022 05:36:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.28 on epoch=99
05/28/2022 05:36:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=99
05/28/2022 05:36:24 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.6662564443735106 on epoch=99
05/28/2022 05:36:27 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
05/28/2022 05:36:29 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=101
05/28/2022 05:36:32 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.16 on epoch=102
05/28/2022 05:36:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=102
05/28/2022 05:36:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=103
05/28/2022 05:36:44 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.7724143777358904 on epoch=103
05/28/2022 05:36:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=104
05/28/2022 05:36:50 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
05/28/2022 05:36:52 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
05/28/2022 05:36:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
05/28/2022 05:36:57 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=107
05/28/2022 05:37:05 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.7803777816111781 on epoch=107
05/28/2022 05:37:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
05/28/2022 05:37:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=108
05/28/2022 05:37:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=109
05/28/2022 05:37:15 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
05/28/2022 05:37:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
05/28/2022 05:37:25 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.6659698446612957 on epoch=110
05/28/2022 05:37:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.13 on epoch=111
05/28/2022 05:37:31 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
05/28/2022 05:37:33 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
05/28/2022 05:37:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
05/28/2022 05:37:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
05/28/2022 05:37:46 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.6079030032947085 on epoch=114
05/28/2022 05:37:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=114
05/28/2022 05:37:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=115
05/28/2022 05:37:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=116
05/28/2022 05:37:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=117
05/28/2022 05:37:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
05/28/2022 05:38:07 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.6554987769146862 on epoch=117
05/28/2022 05:38:09 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
05/28/2022 05:38:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
05/28/2022 05:38:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=119
05/28/2022 05:38:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
05/28/2022 05:38:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=121
05/28/2022 05:38:27 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.5656567912422233 on epoch=121
05/28/2022 05:38:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.12 on epoch=122
05/28/2022 05:38:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
05/28/2022 05:38:35 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=123
05/28/2022 05:38:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
05/28/2022 05:38:40 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
05/28/2022 05:38:47 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.6676451799529299 on epoch=124
05/28/2022 05:38:50 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=125
05/28/2022 05:38:53 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.16 on epoch=126
05/28/2022 05:38:55 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
05/28/2022 05:38:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
05/28/2022 05:39:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=128
05/28/2022 05:39:08 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.662968822349128 on epoch=128
05/28/2022 05:39:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
05/28/2022 05:39:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
05/28/2022 05:39:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=130
05/28/2022 05:39:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=131
05/28/2022 05:39:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
05/28/2022 05:39:28 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.7368340664711632 on epoch=132
05/28/2022 05:39:30 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
05/28/2022 05:39:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=133
05/28/2022 05:39:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
05/28/2022 05:39:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=134
05/28/2022 05:39:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
05/28/2022 05:39:48 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.8410303993721333 on epoch=135
05/28/2022 05:39:51 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.11 on epoch=136
05/28/2022 05:39:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=137
05/28/2022 05:39:56 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
05/28/2022 05:39:58 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=138
05/28/2022 05:40:01 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=139
05/28/2022 05:40:09 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.6529758895164902 on epoch=139
05/28/2022 05:40:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
05/28/2022 05:40:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
05/28/2022 05:40:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=141
05/28/2022 05:40:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.10 on epoch=142
05/28/2022 05:40:22 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=142
05/28/2022 05:40:29 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.6643415916675094 on epoch=142
05/28/2022 05:40:32 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
05/28/2022 05:40:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
05/28/2022 05:40:37 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=144
05/28/2022 05:40:39 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=145
05/28/2022 05:40:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
05/28/2022 05:40:49 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7557272515426916 on epoch=146
05/28/2022 05:40:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
05/28/2022 05:40:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
05/28/2022 05:40:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
05/28/2022 05:41:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
05/28/2022 05:41:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
05/28/2022 05:41:10 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7171829126667837 on epoch=149
05/28/2022 05:41:13 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
05/28/2022 05:41:15 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=151
05/28/2022 05:41:18 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=152
05/28/2022 05:41:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
05/28/2022 05:41:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=153
05/28/2022 05:41:30 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.6397852080714983 on epoch=153
05/28/2022 05:41:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
05/28/2022 05:41:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=154
05/28/2022 05:41:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
05/28/2022 05:41:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=156
05/28/2022 05:41:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
05/28/2022 05:41:50 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7611898471381144 on epoch=157
05/28/2022 05:41:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
05/28/2022 05:41:55 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
05/28/2022 05:41:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=159
05/28/2022 05:42:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
05/28/2022 05:42:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
05/28/2022 05:42:10 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.751316942164135 on epoch=160
05/28/2022 05:42:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=161
05/28/2022 05:42:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=162
05/28/2022 05:42:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
05/28/2022 05:42:21 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=163
05/28/2022 05:42:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
05/28/2022 05:42:31 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.7028940347725927 on epoch=164
05/28/2022 05:42:33 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
05/28/2022 05:42:36 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
05/28/2022 05:42:39 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
05/28/2022 05:42:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
05/28/2022 05:42:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
05/28/2022 05:42:51 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.640040324798243 on epoch=167
05/28/2022 05:42:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
05/28/2022 05:42:56 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
05/28/2022 05:42:59 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
05/28/2022 05:43:02 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
05/28/2022 05:43:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
05/28/2022 05:43:12 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7169257406449058 on epoch=171
05/28/2022 05:43:14 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
05/28/2022 05:43:17 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
05/28/2022 05:43:19 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=173
05/28/2022 05:43:22 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
05/28/2022 05:43:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=174
05/28/2022 05:43:31 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.7324991215620084 on epoch=174
05/28/2022 05:43:34 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
05/28/2022 05:43:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
05/28/2022 05:43:39 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
05/28/2022 05:43:42 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
05/28/2022 05:43:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
05/28/2022 05:43:51 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6902928549787634 on epoch=178
05/28/2022 05:43:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
05/28/2022 05:43:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
05/28/2022 05:43:59 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
05/28/2022 05:44:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=181
05/28/2022 05:44:04 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=182
05/28/2022 05:44:11 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7548493884357261 on epoch=182
05/28/2022 05:44:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
05/28/2022 05:44:17 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
05/28/2022 05:44:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
05/28/2022 05:44:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
05/28/2022 05:44:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
05/28/2022 05:44:31 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7278031056019671 on epoch=185
05/28/2022 05:44:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
05/28/2022 05:44:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
05/28/2022 05:44:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
05/28/2022 05:44:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
05/28/2022 05:44:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
05/28/2022 05:44:51 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8352302099781939 on epoch=189
05/28/2022 05:44:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
05/28/2022 05:44:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
05/28/2022 05:44:59 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
05/28/2022 05:45:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
05/28/2022 05:45:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
05/28/2022 05:45:11 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.6715683141037259 on epoch=192
05/28/2022 05:45:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
05/28/2022 05:45:16 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
05/28/2022 05:45:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
05/28/2022 05:45:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
05/28/2022 05:45:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
05/28/2022 05:45:31 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8106581519781859 on epoch=196
05/28/2022 05:45:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
05/28/2022 05:45:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
05/28/2022 05:45:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
05/28/2022 05:45:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
05/28/2022 05:45:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
05/28/2022 05:45:50 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8065895853698273 on epoch=199
05/28/2022 05:45:53 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
05/28/2022 05:45:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
05/28/2022 05:45:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
05/28/2022 05:46:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
05/28/2022 05:46:04 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=203
05/28/2022 05:46:10 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7074777608733466 on epoch=203
05/28/2022 05:46:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
05/28/2022 05:46:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
05/28/2022 05:46:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
05/28/2022 05:46:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
05/28/2022 05:46:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
05/28/2022 05:46:30 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7463104159878353 on epoch=207
05/28/2022 05:46:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
05/28/2022 05:46:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
05/28/2022 05:46:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
05/28/2022 05:46:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
05/28/2022 05:46:43 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
05/28/2022 05:46:50 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7801362773848544 on epoch=210
05/28/2022 05:46:52 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
05/28/2022 05:46:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
05/28/2022 05:46:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
05/28/2022 05:47:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
05/28/2022 05:47:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
05/28/2022 05:47:10 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6990351653867556 on epoch=214
05/28/2022 05:47:10 - INFO - __main__ - save last model!
05/28/2022 05:47:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/28/2022 05:47:10 - INFO - __main__ - Start tokenizing ... 3500 instances
05/28/2022 05:47:10 - INFO - __main__ - Printing 3 examples
05/28/2022 05:47:10 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/28/2022 05:47:10 - INFO - __main__ - ['Animal']
05/28/2022 05:47:10 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/28/2022 05:47:10 - INFO - __main__ - ['Animal']
05/28/2022 05:47:10 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/28/2022 05:47:10 - INFO - __main__ - ['Village']
05/28/2022 05:47:10 - INFO - __main__ - Tokenizing Input ...
05/28/2022 05:47:12 - INFO - __main__ - Tokenizing Output ...
05/28/2022 05:47:15 - INFO - __main__ - Loaded 3500 examples from test data
05/28/2022 05:49:22 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
05/28/2022 05:49:22 - INFO - __main__ - Classification-F1 on test data: 0.5517
05/28/2022 05:49:22 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.8777402557746731, test_performance=0.551678894810819
