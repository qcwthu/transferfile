05/21/2022 21:30:35 - INFO - __main__ - Namespace(task_dir='data_128/wiki_qa/', task_name='wiki_qa', identifier='T5-large-ft-cls2cls-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/21/2022 21:30:35 - INFO - __main__ - models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa
05/21/2022 21:30:35 - INFO - __main__ - Namespace(task_dir='data_128/wiki_qa/', task_name='wiki_qa', identifier='T5-large-ft-cls2cls-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/21/2022 21:30:35 - INFO - __main__ - models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa
05/21/2022 21:30:37 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:30:37 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:30:37 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:30:37 - INFO - __main__ - Using 2 gpus
05/21/2022 21:30:37 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:30:37 - INFO - __main__ - Using 2 gpus
05/21/2022 21:30:37 - INFO - __main__ - Fine-tuning the following samples: ['wiki_qa_128_100', 'wiki_qa_128_13', 'wiki_qa_128_21', 'wiki_qa_128_42', 'wiki_qa_128_87']
05/21/2022 21:30:37 - INFO - __main__ - Fine-tuning the following samples: ['wiki_qa_128_100', 'wiki_qa_128_13', 'wiki_qa_128_21', 'wiki_qa_128_42', 'wiki_qa_128_87']
05/21/2022 21:30:42 - INFO - __main__ - Running ... prefix=wiki_qa_128_100, lr=0.0005, bsz=8 ...
06/03/2022 17:15:27 - INFO - __main__ - Namespace(task_dir='data_128/wiki_qa/', task_name='wiki_qa', identifier='T5-large-ft-cls2cls-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
06/03/2022 17:15:27 - INFO - __main__ - models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa
06/03/2022 17:15:28 - INFO - __main__ - Namespace(task_dir='data_128/wiki_qa/', task_name='wiki_qa', identifier='T5-large-ft-cls2cls-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
06/03/2022 17:15:28 - INFO - __main__ - models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa
06/03/2022 17:15:28 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/03/2022 17:15:28 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/03/2022 17:15:28 - INFO - __main__ - args.device: cuda:0
06/03/2022 17:15:28 - INFO - __main__ - Using 2 gpus
06/03/2022 17:15:28 - INFO - __main__ - args.device: cuda:1
06/03/2022 17:15:28 - INFO - __main__ - Using 2 gpus
06/03/2022 17:15:28 - INFO - __main__ - Fine-tuning the following samples: ['wiki_qa_128_100', 'wiki_qa_128_13', 'wiki_qa_128_21', 'wiki_qa_128_42', 'wiki_qa_128_87']
06/03/2022 17:15:28 - INFO - __main__ - Fine-tuning the following samples: ['wiki_qa_128_100', 'wiki_qa_128_13', 'wiki_qa_128_21', 'wiki_qa_128_42', 'wiki_qa_128_87']
06/03/2022 17:15:33 - INFO - __main__ - Running ... prefix=wiki_qa_128_100, lr=0.0005, bsz=8 ...
06/03/2022 17:15:34 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:15:34 - INFO - __main__ - Printing 3 examples
06/03/2022 17:15:34 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/03/2022 17:15:34 - INFO - __main__ - ['false']
06/03/2022 17:15:34 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/03/2022 17:15:34 - INFO - __main__ - ['false']
06/03/2022 17:15:34 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/03/2022 17:15:34 - INFO - __main__ - ['false']
06/03/2022 17:15:34 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:15:34 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:15:34 - INFO - __main__ - Printing 3 examples
06/03/2022 17:15:34 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/03/2022 17:15:34 - INFO - __main__ - ['false']
06/03/2022 17:15:34 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/03/2022 17:15:34 - INFO - __main__ - ['false']
06/03/2022 17:15:34 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/03/2022 17:15:34 - INFO - __main__ - ['false']
06/03/2022 17:15:34 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:15:34 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:15:34 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:15:34 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 17:15:34 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:15:34 - INFO - __main__ - Printing 3 examples
06/03/2022 17:15:34 - INFO - __main__ -  [wiki_qa] question: who plays judas in lady gaga video judas? [SEP] answer: "Judas" is a song by American recording artist Lady Gaga , from her second studio album Born This Way (2011).
06/03/2022 17:15:34 - INFO - __main__ - ['false']
06/03/2022 17:15:34 - INFO - __main__ -  [wiki_qa] question: when was the state of utah established [SEP] answer: The world headquarters of The Church of Jesus Christ of Latter-day Saints (LDS Church) is located in Utah's state capital .
06/03/2022 17:15:34 - INFO - __main__ - ['false']
06/03/2022 17:15:34 - INFO - __main__ -  [wiki_qa] question: WHAT SINGER MARRIED HIS COUSIN [SEP] answer: In the meantime he was determined to gain back some of his popularity.
06/03/2022 17:15:34 - INFO - __main__ - ['false']
06/03/2022 17:15:34 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:15:34 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 17:15:34 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:15:34 - INFO - __main__ - Printing 3 examples
06/03/2022 17:15:34 - INFO - __main__ -  [wiki_qa] question: who plays judas in lady gaga video judas? [SEP] answer: "Judas" is a song by American recording artist Lady Gaga , from her second studio album Born This Way (2011).
06/03/2022 17:15:34 - INFO - __main__ - ['false']
06/03/2022 17:15:34 - INFO - __main__ -  [wiki_qa] question: when was the state of utah established [SEP] answer: The world headquarters of The Church of Jesus Christ of Latter-day Saints (LDS Church) is located in Utah's state capital .
06/03/2022 17:15:34 - INFO - __main__ - ['false']
06/03/2022 17:15:34 - INFO - __main__ -  [wiki_qa] question: WHAT SINGER MARRIED HIS COUSIN [SEP] answer: In the meantime he was determined to gain back some of his popularity.
06/03/2022 17:15:34 - INFO - __main__ - ['false']
06/03/2022 17:15:34 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:15:34 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:15:34 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:15:35 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 17:15:35 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 17:15:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 17:15:48 - INFO - __main__ - Starting training!
06/03/2022 17:15:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 17:15:48 - INFO - __main__ - Starting training!
06/03/2022 17:15:53 - INFO - __main__ - Step 10 Global step 10 Train loss 23.995972 on epoch=0
06/03/2022 17:15:58 - INFO - __main__ - Step 20 Global step 20 Train loss 18.790287 on epoch=1
06/03/2022 17:16:03 - INFO - __main__ - Step 30 Global step 30 Train loss 15.630811 on epoch=1
06/03/2022 17:16:08 - INFO - __main__ - Step 40 Global step 40 Train loss 13.762131 on epoch=2
06/03/2022 17:16:13 - INFO - __main__ - Step 50 Global step 50 Train loss 10.481844 on epoch=3
06/03/2022 17:16:15 - INFO - __main__ - Global step 50 Train loss 16.532209 Classification-F1 0.005128205128205128 on epoch=3
06/03/2022 17:16:21 - INFO - __main__ - Step 60 Global step 60 Train loss 4.528026 on epoch=3
06/03/2022 17:16:26 - INFO - __main__ - Step 70 Global step 70 Train loss 2.009426 on epoch=4
06/03/2022 17:16:31 - INFO - __main__ - Step 80 Global step 80 Train loss 4.639950 on epoch=4
06/03/2022 17:16:35 - INFO - __main__ - Step 90 Global step 90 Train loss 1.262181 on epoch=5
06/03/2022 17:16:40 - INFO - __main__ - Step 100 Global step 100 Train loss 0.685011 on epoch=6
06/03/2022 17:16:43 - INFO - __main__ - Global step 100 Train loss 2.624919 Classification-F1 0.350463149416029 on epoch=6
06/03/2022 17:16:50 - INFO - __main__ - Step 110 Global step 110 Train loss 0.516523 on epoch=6
06/03/2022 17:16:55 - INFO - __main__ - Step 120 Global step 120 Train loss 0.444893 on epoch=7
06/03/2022 17:17:00 - INFO - __main__ - Step 130 Global step 130 Train loss 0.535695 on epoch=8
06/03/2022 17:17:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.352010 on epoch=8
06/03/2022 17:17:10 - INFO - __main__ - Step 150 Global step 150 Train loss 0.382144 on epoch=9
06/03/2022 17:17:13 - INFO - __main__ - Global step 150 Train loss 0.446253 Classification-F1 0.37922403003754696 on epoch=9
06/03/2022 17:17:19 - INFO - __main__ - Step 160 Global step 160 Train loss 0.444713 on epoch=9
06/03/2022 17:17:24 - INFO - __main__ - Step 170 Global step 170 Train loss 0.423613 on epoch=10
06/03/2022 17:17:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.512609 on epoch=11
06/03/2022 17:17:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.346770 on epoch=11
06/03/2022 17:17:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.403637 on epoch=12
06/03/2022 17:17:41 - INFO - __main__ - Global step 200 Train loss 0.426268 Classification-F1 0.588093322606597 on epoch=12
06/03/2022 17:17:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.460064 on epoch=13
06/03/2022 17:17:53 - INFO - __main__ - Step 220 Global step 220 Train loss 0.398113 on epoch=13
06/03/2022 17:17:57 - INFO - __main__ - Step 230 Global step 230 Train loss 0.406657 on epoch=14
06/03/2022 17:18:02 - INFO - __main__ - Step 240 Global step 240 Train loss 0.390015 on epoch=14
06/03/2022 17:18:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.381778 on epoch=15
06/03/2022 17:18:10 - INFO - __main__ - Global step 250 Train loss 0.407325 Classification-F1 0.5681776360179107 on epoch=15
06/03/2022 17:18:15 - INFO - __main__ - Step 260 Global step 260 Train loss 0.392859 on epoch=16
06/03/2022 17:18:20 - INFO - __main__ - Step 270 Global step 270 Train loss 0.420847 on epoch=16
06/03/2022 17:18:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.395928 on epoch=17
06/03/2022 17:18:30 - INFO - __main__ - Step 290 Global step 290 Train loss 0.393208 on epoch=18
06/03/2022 17:18:35 - INFO - __main__ - Step 300 Global step 300 Train loss 0.340692 on epoch=18
06/03/2022 17:18:38 - INFO - __main__ - Global step 300 Train loss 0.388707 Classification-F1 0.39866578972094335 on epoch=18
06/03/2022 17:18:43 - INFO - __main__ - Step 310 Global step 310 Train loss 0.333452 on epoch=19
06/03/2022 17:18:48 - INFO - __main__ - Step 320 Global step 320 Train loss 0.378501 on epoch=19
06/03/2022 17:18:53 - INFO - __main__ - Step 330 Global step 330 Train loss 0.350170 on epoch=20
06/03/2022 17:18:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.404734 on epoch=21
06/03/2022 17:19:03 - INFO - __main__ - Step 350 Global step 350 Train loss 0.319995 on epoch=21
06/03/2022 17:19:05 - INFO - __main__ - Global step 350 Train loss 0.357370 Classification-F1 0.49750868186622377 on epoch=21
06/03/2022 17:19:10 - INFO - __main__ - Step 360 Global step 360 Train loss 0.325933 on epoch=22
06/03/2022 17:19:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.278298 on epoch=23
06/03/2022 17:19:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.305179 on epoch=23
06/03/2022 17:19:25 - INFO - __main__ - Step 390 Global step 390 Train loss 0.247223 on epoch=24
06/03/2022 17:19:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.302284 on epoch=24
06/03/2022 17:19:33 - INFO - __main__ - Global step 400 Train loss 0.291783 Classification-F1 0.412425019769707 on epoch=24
06/03/2022 17:19:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.192617 on epoch=25
06/03/2022 17:19:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.213314 on epoch=26
06/03/2022 17:19:48 - INFO - __main__ - Step 430 Global step 430 Train loss 0.256353 on epoch=26
06/03/2022 17:19:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.196568 on epoch=27
06/03/2022 17:19:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.218066 on epoch=28
06/03/2022 17:20:01 - INFO - __main__ - Global step 450 Train loss 0.215383 Classification-F1 0.37485022581338906 on epoch=28
06/03/2022 17:20:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.190141 on epoch=28
06/03/2022 17:20:11 - INFO - __main__ - Step 470 Global step 470 Train loss 0.188653 on epoch=29
06/03/2022 17:20:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.149007 on epoch=29
06/03/2022 17:20:22 - INFO - __main__ - Step 490 Global step 490 Train loss 0.073868 on epoch=30
06/03/2022 17:20:27 - INFO - __main__ - Step 500 Global step 500 Train loss 0.053199 on epoch=31
06/03/2022 17:20:29 - INFO - __main__ - Global step 500 Train loss 0.130974 Classification-F1 0.6059150067640061 on epoch=31
06/03/2022 17:20:35 - INFO - __main__ - Step 510 Global step 510 Train loss 0.046226 on epoch=31
06/03/2022 17:20:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.048233 on epoch=32
06/03/2022 17:20:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.037648 on epoch=33
06/03/2022 17:20:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.040357 on epoch=33
06/03/2022 17:20:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.075653 on epoch=34
06/03/2022 17:20:58 - INFO - __main__ - Global step 550 Train loss 0.049623 Classification-F1 0.396023995250087 on epoch=34
06/03/2022 17:21:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.054877 on epoch=34
06/03/2022 17:21:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.026375 on epoch=35
06/03/2022 17:21:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.022345 on epoch=36
06/03/2022 17:21:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.010802 on epoch=36
06/03/2022 17:21:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.992779 on epoch=37
06/03/2022 17:21:26 - INFO - __main__ - Global step 600 Train loss 0.221436 Classification-F1 0.5370264610698648 on epoch=37
06/03/2022 17:21:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.056174 on epoch=38
06/03/2022 17:21:37 - INFO - __main__ - Step 620 Global step 620 Train loss 0.023888 on epoch=38
06/03/2022 17:21:42 - INFO - __main__ - Step 630 Global step 630 Train loss 0.021657 on epoch=39
06/03/2022 17:21:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.004410 on epoch=39
06/03/2022 17:21:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.010429 on epoch=40
06/03/2022 17:21:54 - INFO - __main__ - Global step 650 Train loss 0.023312 Classification-F1 0.37798020692757534 on epoch=40
06/03/2022 17:21:59 - INFO - __main__ - Step 660 Global step 660 Train loss 0.018271 on epoch=41
06/03/2022 17:22:04 - INFO - __main__ - Step 670 Global step 670 Train loss 0.032905 on epoch=41
06/03/2022 17:22:09 - INFO - __main__ - Step 680 Global step 680 Train loss 0.003695 on epoch=42
06/03/2022 17:22:14 - INFO - __main__ - Step 690 Global step 690 Train loss 0.010274 on epoch=43
06/03/2022 17:22:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.024661 on epoch=43
06/03/2022 17:22:22 - INFO - __main__ - Global step 700 Train loss 0.017961 Classification-F1 0.590857603922603 on epoch=43
06/03/2022 17:22:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.050532 on epoch=44
06/03/2022 17:22:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.012740 on epoch=44
06/03/2022 17:22:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.002084 on epoch=45
06/03/2022 17:22:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.003658 on epoch=46
06/03/2022 17:22:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.015790 on epoch=46
06/03/2022 17:22:50 - INFO - __main__ - Global step 750 Train loss 0.016961 Classification-F1 0.5511350411966423 on epoch=46
06/03/2022 17:22:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.006830 on epoch=47
06/03/2022 17:23:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.009540 on epoch=48
06/03/2022 17:23:06 - INFO - __main__ - Step 780 Global step 780 Train loss 0.027252 on epoch=48
06/03/2022 17:23:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.025428 on epoch=49
06/03/2022 17:23:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.001403 on epoch=49
06/03/2022 17:23:19 - INFO - __main__ - Global step 800 Train loss 0.014091 Classification-F1 0.3653880445157704 on epoch=49
06/03/2022 17:23:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.002427 on epoch=50
06/03/2022 17:23:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.001814 on epoch=51
06/03/2022 17:23:34 - INFO - __main__ - Step 830 Global step 830 Train loss 0.004479 on epoch=51
06/03/2022 17:23:39 - INFO - __main__ - Step 840 Global step 840 Train loss 0.024584 on epoch=52
06/03/2022 17:23:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.058252 on epoch=53
06/03/2022 17:23:47 - INFO - __main__ - Global step 850 Train loss 0.018311 Classification-F1 0.4652837798905215 on epoch=53
06/03/2022 17:23:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.155371 on epoch=53
06/03/2022 17:23:57 - INFO - __main__ - Step 870 Global step 870 Train loss 0.034853 on epoch=54
06/03/2022 17:24:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.078515 on epoch=54
06/03/2022 17:24:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.082754 on epoch=55
06/03/2022 17:24:13 - INFO - __main__ - Step 900 Global step 900 Train loss 0.006075 on epoch=56
06/03/2022 17:24:15 - INFO - __main__ - Global step 900 Train loss 0.071514 Classification-F1 0.36779037695372363 on epoch=56
06/03/2022 17:24:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.013187 on epoch=56
06/03/2022 17:24:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.019821 on epoch=57
06/03/2022 17:24:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.012700 on epoch=58
06/03/2022 17:24:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.003361 on epoch=58
06/03/2022 17:24:41 - INFO - __main__ - Step 950 Global step 950 Train loss 0.001166 on epoch=59
06/03/2022 17:24:44 - INFO - __main__ - Global step 950 Train loss 0.010047 Classification-F1 0.5207817754933689 on epoch=59
06/03/2022 17:24:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.002767 on epoch=59
06/03/2022 17:24:54 - INFO - __main__ - Step 970 Global step 970 Train loss 0.001478 on epoch=60
06/03/2022 17:24:59 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000754 on epoch=61
06/03/2022 17:25:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.001822 on epoch=61
06/03/2022 17:25:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.008698 on epoch=62
06/03/2022 17:25:10 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:25:10 - INFO - __main__ - Printing 3 examples
06/03/2022 17:25:10 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/03/2022 17:25:10 - INFO - __main__ - ['false']
06/03/2022 17:25:10 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/03/2022 17:25:10 - INFO - __main__ - ['false']
06/03/2022 17:25:10 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/03/2022 17:25:10 - INFO - __main__ - ['false']
06/03/2022 17:25:10 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:25:10 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:25:11 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 17:25:11 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:25:11 - INFO - __main__ - Printing 3 examples
06/03/2022 17:25:11 - INFO - __main__ -  [wiki_qa] question: who plays judas in lady gaga video judas? [SEP] answer: "Judas" is a song by American recording artist Lady Gaga , from her second studio album Born This Way (2011).
06/03/2022 17:25:11 - INFO - __main__ - ['false']
06/03/2022 17:25:11 - INFO - __main__ -  [wiki_qa] question: when was the state of utah established [SEP] answer: The world headquarters of The Church of Jesus Christ of Latter-day Saints (LDS Church) is located in Utah's state capital .
06/03/2022 17:25:11 - INFO - __main__ - ['false']
06/03/2022 17:25:11 - INFO - __main__ -  [wiki_qa] question: WHAT SINGER MARRIED HIS COUSIN [SEP] answer: In the meantime he was determined to gain back some of his popularity.
06/03/2022 17:25:11 - INFO - __main__ - ['false']
06/03/2022 17:25:11 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:25:11 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:25:11 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 17:25:12 - INFO - __main__ - Global step 1000 Train loss 0.003104 Classification-F1 0.5445198469556455 on epoch=62
06/03/2022 17:25:12 - INFO - __main__ - save last model!
06/03/2022 17:25:19 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 17:25:20 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 17:25:20 - INFO - __main__ - Printing 3 examples
06/03/2022 17:25:20 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 17:25:20 - INFO - __main__ - ['false']
06/03/2022 17:25:20 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 17:25:20 - INFO - __main__ - ['false']
06/03/2022 17:25:20 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 17:25:20 - INFO - __main__ - ['false']
06/03/2022 17:25:20 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:25:21 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:25:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 17:25:24 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 17:25:24 - INFO - __main__ - Starting training!
06/03/2022 17:25:52 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_100_0.0005_8_predictions.txt
06/03/2022 17:25:52 - INFO - __main__ - Classification-F1 on test data: 0.1723
06/03/2022 17:25:52 - INFO - __main__ - prefix=wiki_qa_128_100, lr=0.0005, bsz=8, dev_performance=0.6059150067640061, test_performance=0.1722776895805995
06/03/2022 17:25:52 - INFO - __main__ - Running ... prefix=wiki_qa_128_100, lr=0.0003, bsz=8 ...
06/03/2022 17:25:53 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:25:53 - INFO - __main__ - Printing 3 examples
06/03/2022 17:25:53 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/03/2022 17:25:53 - INFO - __main__ - ['false']
06/03/2022 17:25:53 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/03/2022 17:25:53 - INFO - __main__ - ['false']
06/03/2022 17:25:53 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/03/2022 17:25:53 - INFO - __main__ - ['false']
06/03/2022 17:25:53 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:25:53 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:25:53 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 17:25:53 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:25:53 - INFO - __main__ - Printing 3 examples
06/03/2022 17:25:53 - INFO - __main__ -  [wiki_qa] question: who plays judas in lady gaga video judas? [SEP] answer: "Judas" is a song by American recording artist Lady Gaga , from her second studio album Born This Way (2011).
06/03/2022 17:25:53 - INFO - __main__ - ['false']
06/03/2022 17:25:53 - INFO - __main__ -  [wiki_qa] question: when was the state of utah established [SEP] answer: The world headquarters of The Church of Jesus Christ of Latter-day Saints (LDS Church) is located in Utah's state capital .
06/03/2022 17:25:53 - INFO - __main__ - ['false']
06/03/2022 17:25:53 - INFO - __main__ -  [wiki_qa] question: WHAT SINGER MARRIED HIS COUSIN [SEP] answer: In the meantime he was determined to gain back some of his popularity.
06/03/2022 17:25:53 - INFO - __main__ - ['false']
06/03/2022 17:25:53 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:25:53 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:25:54 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 17:26:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 17:26:05 - INFO - __main__ - Starting training!
06/03/2022 17:26:09 - INFO - __main__ - Step 10 Global step 10 Train loss 22.944921 on epoch=0
06/03/2022 17:26:14 - INFO - __main__ - Step 20 Global step 20 Train loss 18.556492 on epoch=1
06/03/2022 17:26:20 - INFO - __main__ - Step 30 Global step 30 Train loss 16.739586 on epoch=1
06/03/2022 17:26:25 - INFO - __main__ - Step 40 Global step 40 Train loss 15.674963 on epoch=2
06/03/2022 17:26:30 - INFO - __main__ - Step 50 Global step 50 Train loss 14.459846 on epoch=3
06/03/2022 17:26:56 - INFO - __main__ - Global step 50 Train loss 17.675163 Classification-F1 0.0 on epoch=3
06/03/2022 17:27:01 - INFO - __main__ - Step 60 Global step 60 Train loss 14.720241 on epoch=3
06/03/2022 17:27:07 - INFO - __main__ - Step 70 Global step 70 Train loss 13.653788 on epoch=4
06/03/2022 17:27:11 - INFO - __main__ - Step 80 Global step 80 Train loss 8.419012 on epoch=4
06/03/2022 17:27:17 - INFO - __main__ - Step 90 Global step 90 Train loss 3.229191 on epoch=5
06/03/2022 17:27:22 - INFO - __main__ - Step 100 Global step 100 Train loss 0.568709 on epoch=6
06/03/2022 17:27:25 - INFO - __main__ - Global step 100 Train loss 8.118188 Classification-F1 0.3333333333333333 on epoch=6
06/03/2022 17:27:30 - INFO - __main__ - Step 110 Global step 110 Train loss 0.487973 on epoch=6
06/03/2022 17:27:36 - INFO - __main__ - Step 120 Global step 120 Train loss 0.497192 on epoch=7
06/03/2022 17:27:41 - INFO - __main__ - Step 130 Global step 130 Train loss 0.491391 on epoch=8
06/03/2022 17:27:46 - INFO - __main__ - Step 140 Global step 140 Train loss 0.372126 on epoch=8
06/03/2022 17:27:51 - INFO - __main__ - Step 150 Global step 150 Train loss 0.578597 on epoch=9
06/03/2022 17:27:54 - INFO - __main__ - Global step 150 Train loss 0.485456 Classification-F1 0.3401530406766009 on epoch=9
06/03/2022 17:28:00 - INFO - __main__ - Step 160 Global step 160 Train loss 0.426129 on epoch=9
06/03/2022 17:28:05 - INFO - __main__ - Step 170 Global step 170 Train loss 0.447347 on epoch=10
06/03/2022 17:28:10 - INFO - __main__ - Step 180 Global step 180 Train loss 0.432153 on epoch=11
06/03/2022 17:28:15 - INFO - __main__ - Step 190 Global step 190 Train loss 0.419578 on epoch=11
06/03/2022 17:28:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.439446 on epoch=12
06/03/2022 17:28:23 - INFO - __main__ - Global step 200 Train loss 0.432931 Classification-F1 0.3486005089058525 on epoch=12
06/03/2022 17:28:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.479641 on epoch=13
06/03/2022 17:28:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.404916 on epoch=13
06/03/2022 17:28:39 - INFO - __main__ - Step 230 Global step 230 Train loss 0.428100 on epoch=14
06/03/2022 17:28:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.419841 on epoch=14
06/03/2022 17:28:49 - INFO - __main__ - Step 250 Global step 250 Train loss 0.391933 on epoch=15
06/03/2022 17:28:52 - INFO - __main__ - Global step 250 Train loss 0.424886 Classification-F1 0.34195559333697656 on epoch=15
06/03/2022 17:28:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.394734 on epoch=16
06/03/2022 17:29:02 - INFO - __main__ - Step 270 Global step 270 Train loss 0.380890 on epoch=16
06/03/2022 17:29:07 - INFO - __main__ - Step 280 Global step 280 Train loss 0.391074 on epoch=17
06/03/2022 17:29:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.486493 on epoch=18
06/03/2022 17:29:18 - INFO - __main__ - Step 300 Global step 300 Train loss 0.410965 on epoch=18
06/03/2022 17:29:20 - INFO - __main__ - Global step 300 Train loss 0.412831 Classification-F1 0.34195559333697656 on epoch=18
06/03/2022 17:29:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.413573 on epoch=19
06/03/2022 17:29:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.453648 on epoch=19
06/03/2022 17:29:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.389042 on epoch=20
06/03/2022 17:29:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.384095 on epoch=21
06/03/2022 17:29:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.394203 on epoch=21
06/03/2022 17:29:49 - INFO - __main__ - Global step 350 Train loss 0.406912 Classification-F1 0.3401530406766009 on epoch=21
06/03/2022 17:29:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.395752 on epoch=22
06/03/2022 17:29:59 - INFO - __main__ - Step 370 Global step 370 Train loss 0.408794 on epoch=23
06/03/2022 17:30:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.389605 on epoch=23
06/03/2022 17:30:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.449003 on epoch=24
06/03/2022 17:30:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.371204 on epoch=24
06/03/2022 17:30:17 - INFO - __main__ - Global step 400 Train loss 0.402872 Classification-F1 0.3333333333333333 on epoch=24
06/03/2022 17:30:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.397225 on epoch=25
06/03/2022 17:30:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.422377 on epoch=26
06/03/2022 17:30:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.404922 on epoch=26
06/03/2022 17:30:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.386000 on epoch=27
06/03/2022 17:30:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.382546 on epoch=28
06/03/2022 17:30:45 - INFO - __main__ - Global step 450 Train loss 0.398614 Classification-F1 0.3401530406766009 on epoch=28
06/03/2022 17:30:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.342133 on epoch=28
06/03/2022 17:30:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.376944 on epoch=29
06/03/2022 17:31:01 - INFO - __main__ - Step 480 Global step 480 Train loss 0.408500 on epoch=29
06/03/2022 17:31:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.366827 on epoch=30
06/03/2022 17:31:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.421247 on epoch=31
06/03/2022 17:31:14 - INFO - __main__ - Global step 500 Train loss 0.383130 Classification-F1 0.45898174831892413 on epoch=31
06/03/2022 17:31:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.367882 on epoch=31
06/03/2022 17:31:25 - INFO - __main__ - Step 520 Global step 520 Train loss 0.371169 on epoch=32
06/03/2022 17:31:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.395000 on epoch=33
06/03/2022 17:31:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.390624 on epoch=33
06/03/2022 17:31:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.402275 on epoch=34
06/03/2022 17:31:43 - INFO - __main__ - Global step 550 Train loss 0.385390 Classification-F1 0.3913043478260869 on epoch=34
06/03/2022 17:31:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.408449 on epoch=34
06/03/2022 17:31:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.391005 on epoch=35
06/03/2022 17:31:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.356619 on epoch=36
06/03/2022 17:32:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.374760 on epoch=36
06/03/2022 17:32:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.365266 on epoch=37
06/03/2022 17:32:11 - INFO - __main__ - Global step 600 Train loss 0.379220 Classification-F1 0.5323076923076923 on epoch=37
06/03/2022 17:32:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.372631 on epoch=38
06/03/2022 17:32:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.338960 on epoch=38
06/03/2022 17:32:27 - INFO - __main__ - Step 630 Global step 630 Train loss 0.374629 on epoch=39
06/03/2022 17:32:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.377766 on epoch=39
06/03/2022 17:32:37 - INFO - __main__ - Step 650 Global step 650 Train loss 0.390317 on epoch=40
06/03/2022 17:32:40 - INFO - __main__ - Global step 650 Train loss 0.370860 Classification-F1 0.49220246238030096 on epoch=40
06/03/2022 17:32:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.365768 on epoch=41
06/03/2022 17:32:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.372230 on epoch=41
06/03/2022 17:32:55 - INFO - __main__ - Step 680 Global step 680 Train loss 0.355682 on epoch=42
06/03/2022 17:33:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.378792 on epoch=43
06/03/2022 17:33:06 - INFO - __main__ - Step 700 Global step 700 Train loss 0.349298 on epoch=43
06/03/2022 17:33:08 - INFO - __main__ - Global step 700 Train loss 0.364354 Classification-F1 0.516276211690606 on epoch=43
06/03/2022 17:33:13 - INFO - __main__ - Step 710 Global step 710 Train loss 0.362270 on epoch=44
06/03/2022 17:33:19 - INFO - __main__ - Step 720 Global step 720 Train loss 0.336684 on epoch=44
06/03/2022 17:33:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.341652 on epoch=45
06/03/2022 17:33:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.374370 on epoch=46
06/03/2022 17:33:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.341642 on epoch=46
06/03/2022 17:33:37 - INFO - __main__ - Global step 750 Train loss 0.351323 Classification-F1 0.5979536937693397 on epoch=46
06/03/2022 17:33:43 - INFO - __main__ - Step 760 Global step 760 Train loss 0.364921 on epoch=47
06/03/2022 17:33:48 - INFO - __main__ - Step 770 Global step 770 Train loss 0.363854 on epoch=48
06/03/2022 17:33:53 - INFO - __main__ - Step 780 Global step 780 Train loss 0.342815 on epoch=48
06/03/2022 17:33:59 - INFO - __main__ - Step 790 Global step 790 Train loss 0.369511 on epoch=49
06/03/2022 17:34:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.339813 on epoch=49
06/03/2022 17:34:06 - INFO - __main__ - Global step 800 Train loss 0.356183 Classification-F1 0.3333333333333333 on epoch=49
06/03/2022 17:34:12 - INFO - __main__ - Step 810 Global step 810 Train loss 0.310936 on epoch=50
06/03/2022 17:34:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.339127 on epoch=51
06/03/2022 17:34:22 - INFO - __main__ - Step 830 Global step 830 Train loss 0.359277 on epoch=51
06/03/2022 17:34:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.314011 on epoch=52
06/03/2022 17:34:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.321743 on epoch=53
06/03/2022 17:34:35 - INFO - __main__ - Global step 850 Train loss 0.329019 Classification-F1 0.36516753625488524 on epoch=53
06/03/2022 17:34:40 - INFO - __main__ - Step 860 Global step 860 Train loss 0.298063 on epoch=53
06/03/2022 17:34:45 - INFO - __main__ - Step 870 Global step 870 Train loss 0.333083 on epoch=54
06/03/2022 17:34:50 - INFO - __main__ - Step 880 Global step 880 Train loss 0.335180 on epoch=54
06/03/2022 17:34:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.347237 on epoch=55
06/03/2022 17:35:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.328332 on epoch=56
06/03/2022 17:35:03 - INFO - __main__ - Global step 900 Train loss 0.328379 Classification-F1 0.4055576703464027 on epoch=56
06/03/2022 17:35:08 - INFO - __main__ - Step 910 Global step 910 Train loss 0.353809 on epoch=56
06/03/2022 17:35:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.366012 on epoch=57
06/03/2022 17:35:18 - INFO - __main__ - Step 930 Global step 930 Train loss 0.349038 on epoch=58
06/03/2022 17:35:24 - INFO - __main__ - Step 940 Global step 940 Train loss 0.307425 on epoch=58
06/03/2022 17:35:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.330348 on epoch=59
06/03/2022 17:35:31 - INFO - __main__ - Global step 950 Train loss 0.341327 Classification-F1 0.3401530406766009 on epoch=59
06/03/2022 17:35:37 - INFO - __main__ - Step 960 Global step 960 Train loss 0.341820 on epoch=59
06/03/2022 17:35:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.369175 on epoch=60
06/03/2022 17:35:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.355030 on epoch=61
06/03/2022 17:35:52 - INFO - __main__ - Step 990 Global step 990 Train loss 0.682875 on epoch=61
06/03/2022 17:35:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.417498 on epoch=62
06/03/2022 17:35:58 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:35:58 - INFO - __main__ - Printing 3 examples
06/03/2022 17:35:58 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/03/2022 17:35:58 - INFO - __main__ - ['false']
06/03/2022 17:35:58 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/03/2022 17:35:58 - INFO - __main__ - ['false']
06/03/2022 17:35:58 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/03/2022 17:35:58 - INFO - __main__ - ['false']
06/03/2022 17:35:58 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:35:58 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:35:59 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 17:35:59 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:35:59 - INFO - __main__ - Printing 3 examples
06/03/2022 17:35:59 - INFO - __main__ -  [wiki_qa] question: who plays judas in lady gaga video judas? [SEP] answer: "Judas" is a song by American recording artist Lady Gaga , from her second studio album Born This Way (2011).
06/03/2022 17:35:59 - INFO - __main__ - ['false']
06/03/2022 17:35:59 - INFO - __main__ -  [wiki_qa] question: when was the state of utah established [SEP] answer: The world headquarters of The Church of Jesus Christ of Latter-day Saints (LDS Church) is located in Utah's state capital .
06/03/2022 17:35:59 - INFO - __main__ - ['false']
06/03/2022 17:35:59 - INFO - __main__ -  [wiki_qa] question: WHAT SINGER MARRIED HIS COUSIN [SEP] answer: In the meantime he was determined to gain back some of his popularity.
06/03/2022 17:35:59 - INFO - __main__ - ['false']
06/03/2022 17:35:59 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:35:59 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:35:59 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 17:36:00 - INFO - __main__ - Global step 1000 Train loss 0.433280 Classification-F1 0.6365801163163438 on epoch=62
06/03/2022 17:36:01 - INFO - __main__ - save last model!
06/03/2022 17:36:08 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 17:36:09 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 17:36:09 - INFO - __main__ - Printing 3 examples
06/03/2022 17:36:09 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 17:36:09 - INFO - __main__ - ['false']
06/03/2022 17:36:09 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 17:36:09 - INFO - __main__ - ['false']
06/03/2022 17:36:09 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 17:36:09 - INFO - __main__ - ['false']
06/03/2022 17:36:09 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:36:10 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:36:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 17:36:12 - INFO - __main__ - Starting training!
06/03/2022 17:36:13 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 17:36:42 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_100_0.0003_8_predictions.txt
06/03/2022 17:36:42 - INFO - __main__ - Classification-F1 on test data: 0.4183
06/03/2022 17:36:42 - INFO - __main__ - prefix=wiki_qa_128_100, lr=0.0003, bsz=8, dev_performance=0.6365801163163438, test_performance=0.41830961136489186
06/03/2022 17:36:42 - INFO - __main__ - Running ... prefix=wiki_qa_128_100, lr=0.0002, bsz=8 ...
06/03/2022 17:36:43 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:36:43 - INFO - __main__ - Printing 3 examples
06/03/2022 17:36:43 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/03/2022 17:36:43 - INFO - __main__ - ['false']
06/03/2022 17:36:43 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/03/2022 17:36:43 - INFO - __main__ - ['false']
06/03/2022 17:36:43 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/03/2022 17:36:43 - INFO - __main__ - ['false']
06/03/2022 17:36:43 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:36:43 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:36:43 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 17:36:43 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:36:43 - INFO - __main__ - Printing 3 examples
06/03/2022 17:36:43 - INFO - __main__ -  [wiki_qa] question: who plays judas in lady gaga video judas? [SEP] answer: "Judas" is a song by American recording artist Lady Gaga , from her second studio album Born This Way (2011).
06/03/2022 17:36:43 - INFO - __main__ - ['false']
06/03/2022 17:36:43 - INFO - __main__ -  [wiki_qa] question: when was the state of utah established [SEP] answer: The world headquarters of The Church of Jesus Christ of Latter-day Saints (LDS Church) is located in Utah's state capital .
06/03/2022 17:36:43 - INFO - __main__ - ['false']
06/03/2022 17:36:43 - INFO - __main__ -  [wiki_qa] question: WHAT SINGER MARRIED HIS COUSIN [SEP] answer: In the meantime he was determined to gain back some of his popularity.
06/03/2022 17:36:43 - INFO - __main__ - ['false']
06/03/2022 17:36:43 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:36:44 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:36:44 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 17:36:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 17:36:56 - INFO - __main__ - Starting training!
06/03/2022 17:37:01 - INFO - __main__ - Step 10 Global step 10 Train loss 23.370701 on epoch=0
06/03/2022 17:37:06 - INFO - __main__ - Step 20 Global step 20 Train loss 19.674109 on epoch=1
06/03/2022 17:37:11 - INFO - __main__ - Step 30 Global step 30 Train loss 18.167578 on epoch=1
06/03/2022 17:37:16 - INFO - __main__ - Step 40 Global step 40 Train loss 17.691380 on epoch=2
06/03/2022 17:37:21 - INFO - __main__ - Step 50 Global step 50 Train loss 15.753245 on epoch=3
06/03/2022 17:38:00 - INFO - __main__ - Global step 50 Train loss 18.931402 Classification-F1 0.0 on epoch=3
06/03/2022 17:38:06 - INFO - __main__ - Step 60 Global step 60 Train loss 15.204839 on epoch=3
06/03/2022 17:38:11 - INFO - __main__ - Step 70 Global step 70 Train loss 14.655508 on epoch=4
06/03/2022 17:38:16 - INFO - __main__ - Step 80 Global step 80 Train loss 13.932852 on epoch=4
06/03/2022 17:38:21 - INFO - __main__ - Step 90 Global step 90 Train loss 12.856253 on epoch=5
06/03/2022 17:38:26 - INFO - __main__ - Step 100 Global step 100 Train loss 11.380043 on epoch=6
06/03/2022 17:39:11 - INFO - __main__ - Global step 100 Train loss 13.605900 Classification-F1 0.0009049773755656109 on epoch=6
06/03/2022 17:39:17 - INFO - __main__ - Step 110 Global step 110 Train loss 4.567565 on epoch=6
06/03/2022 17:39:22 - INFO - __main__ - Step 120 Global step 120 Train loss 0.684730 on epoch=7
06/03/2022 17:39:27 - INFO - __main__ - Step 130 Global step 130 Train loss 0.588587 on epoch=8
06/03/2022 17:39:32 - INFO - __main__ - Step 140 Global step 140 Train loss 0.566807 on epoch=8
06/03/2022 17:39:37 - INFO - __main__ - Step 150 Global step 150 Train loss 0.535360 on epoch=9
06/03/2022 17:39:40 - INFO - __main__ - Global step 150 Train loss 1.388610 Classification-F1 0.3591989987484355 on epoch=9
06/03/2022 17:39:46 - INFO - __main__ - Step 160 Global step 160 Train loss 0.490293 on epoch=9
06/03/2022 17:39:51 - INFO - __main__ - Step 170 Global step 170 Train loss 0.555409 on epoch=10
06/03/2022 17:39:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.408375 on epoch=11
06/03/2022 17:40:01 - INFO - __main__ - Step 190 Global step 190 Train loss 0.381775 on epoch=11
06/03/2022 17:40:06 - INFO - __main__ - Step 200 Global step 200 Train loss 0.536924 on epoch=12
06/03/2022 17:40:09 - INFO - __main__ - Global step 200 Train loss 0.474555 Classification-F1 0.3333333333333333 on epoch=12
06/03/2022 17:40:14 - INFO - __main__ - Step 210 Global step 210 Train loss 0.430828 on epoch=13
06/03/2022 17:40:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.393622 on epoch=13
06/03/2022 17:40:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.390809 on epoch=14
06/03/2022 17:40:29 - INFO - __main__ - Step 240 Global step 240 Train loss 0.430829 on epoch=14
06/03/2022 17:40:35 - INFO - __main__ - Step 250 Global step 250 Train loss 0.362592 on epoch=15
06/03/2022 17:40:37 - INFO - __main__ - Global step 250 Train loss 0.401736 Classification-F1 0.6367372902089348 on epoch=15
06/03/2022 17:40:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.366750 on epoch=16
06/03/2022 17:40:48 - INFO - __main__ - Step 270 Global step 270 Train loss 0.360088 on epoch=16
06/03/2022 17:40:54 - INFO - __main__ - Step 280 Global step 280 Train loss 0.360014 on epoch=17
06/03/2022 17:40:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.678401 on epoch=18
06/03/2022 17:41:04 - INFO - __main__ - Step 300 Global step 300 Train loss 0.344736 on epoch=18
06/03/2022 17:41:07 - INFO - __main__ - Global step 300 Train loss 0.421998 Classification-F1 0.3333333333333333 on epoch=18
06/03/2022 17:41:12 - INFO - __main__ - Step 310 Global step 310 Train loss 0.365372 on epoch=19
06/03/2022 17:41:17 - INFO - __main__ - Step 320 Global step 320 Train loss 0.355040 on epoch=19
06/03/2022 17:41:22 - INFO - __main__ - Step 330 Global step 330 Train loss 0.395396 on epoch=20
06/03/2022 17:41:28 - INFO - __main__ - Step 340 Global step 340 Train loss 0.339784 on epoch=21
06/03/2022 17:41:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.331187 on epoch=21
06/03/2022 17:41:36 - INFO - __main__ - Global step 350 Train loss 0.357356 Classification-F1 0.4492753623188406 on epoch=21
06/03/2022 17:41:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.314359 on epoch=22
06/03/2022 17:41:46 - INFO - __main__ - Step 370 Global step 370 Train loss 0.313199 on epoch=23
06/03/2022 17:41:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.296823 on epoch=23
06/03/2022 17:41:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.283132 on epoch=24
06/03/2022 17:42:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.291092 on epoch=24
06/03/2022 17:42:04 - INFO - __main__ - Global step 400 Train loss 0.299721 Classification-F1 0.7409065816107465 on epoch=24
06/03/2022 17:42:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.255035 on epoch=25
06/03/2022 17:42:16 - INFO - __main__ - Step 420 Global step 420 Train loss 0.243178 on epoch=26
06/03/2022 17:42:21 - INFO - __main__ - Step 430 Global step 430 Train loss 0.201340 on epoch=26
06/03/2022 17:42:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.213414 on epoch=27
06/03/2022 17:42:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.180608 on epoch=28
06/03/2022 17:42:34 - INFO - __main__ - Global step 450 Train loss 0.218715 Classification-F1 0.6940880503144655 on epoch=28
06/03/2022 17:42:39 - INFO - __main__ - Step 460 Global step 460 Train loss 0.179709 on epoch=28
06/03/2022 17:42:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.131386 on epoch=29
06/03/2022 17:42:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.197336 on epoch=29
06/03/2022 17:42:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.176060 on epoch=30
06/03/2022 17:43:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.099077 on epoch=31
06/03/2022 17:43:02 - INFO - __main__ - Global step 500 Train loss 0.156714 Classification-F1 0.42742444227791476 on epoch=31
06/03/2022 17:43:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.143953 on epoch=31
06/03/2022 17:43:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.074271 on epoch=32
06/03/2022 17:43:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.139011 on epoch=33
06/03/2022 17:43:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.070362 on epoch=33
06/03/2022 17:43:28 - INFO - __main__ - Step 550 Global step 550 Train loss 0.055362 on epoch=34
06/03/2022 17:43:31 - INFO - __main__ - Global step 550 Train loss 0.096592 Classification-F1 0.6659027247262541 on epoch=34
06/03/2022 17:43:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.082937 on epoch=34
06/03/2022 17:43:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.051251 on epoch=35
06/03/2022 17:43:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.057846 on epoch=36
06/03/2022 17:43:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.023707 on epoch=36
06/03/2022 17:43:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.015784 on epoch=37
06/03/2022 17:44:00 - INFO - __main__ - Global step 600 Train loss 0.046305 Classification-F1 0.5984821654439667 on epoch=37
06/03/2022 17:44:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.013610 on epoch=38
06/03/2022 17:44:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.019370 on epoch=38
06/03/2022 17:44:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.013905 on epoch=39
06/03/2022 17:44:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.007345 on epoch=39
06/03/2022 17:44:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.008681 on epoch=40
06/03/2022 17:44:28 - INFO - __main__ - Global step 650 Train loss 0.012582 Classification-F1 0.5919942288657373 on epoch=40
06/03/2022 17:44:33 - INFO - __main__ - Step 660 Global step 660 Train loss 0.003995 on epoch=41
06/03/2022 17:44:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.002005 on epoch=41
06/03/2022 17:44:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.035300 on epoch=42
06/03/2022 17:44:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.084618 on epoch=43
06/03/2022 17:44:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.006520 on epoch=43
06/03/2022 17:44:56 - INFO - __main__ - Global step 700 Train loss 0.026488 Classification-F1 0.5478040163948482 on epoch=43
06/03/2022 17:45:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.008171 on epoch=44
06/03/2022 17:45:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.012448 on epoch=44
06/03/2022 17:45:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.008235 on epoch=45
06/03/2022 17:45:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.050025 on epoch=46
06/03/2022 17:45:22 - INFO - __main__ - Step 750 Global step 750 Train loss 0.001023 on epoch=46
06/03/2022 17:45:24 - INFO - __main__ - Global step 750 Train loss 0.015980 Classification-F1 0.6635897435897435 on epoch=46
06/03/2022 17:45:30 - INFO - __main__ - Step 760 Global step 760 Train loss 0.005784 on epoch=47
06/03/2022 17:45:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.001482 on epoch=48
06/03/2022 17:45:40 - INFO - __main__ - Step 780 Global step 780 Train loss 0.001029 on epoch=48
06/03/2022 17:45:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.001635 on epoch=49
06/03/2022 17:45:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.016979 on epoch=49
06/03/2022 17:45:53 - INFO - __main__ - Global step 800 Train loss 0.005382 Classification-F1 0.6735053770213034 on epoch=49
06/03/2022 17:45:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.257984 on epoch=50
06/03/2022 17:46:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.099614 on epoch=51
06/03/2022 17:46:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.017247 on epoch=51
06/03/2022 17:46:13 - INFO - __main__ - Step 840 Global step 840 Train loss 0.022059 on epoch=52
06/03/2022 17:46:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.079625 on epoch=53
06/03/2022 17:46:21 - INFO - __main__ - Global step 850 Train loss 0.095306 Classification-F1 0.6716716716716716 on epoch=53
06/03/2022 17:46:26 - INFO - __main__ - Step 860 Global step 860 Train loss 0.039249 on epoch=53
06/03/2022 17:46:31 - INFO - __main__ - Step 870 Global step 870 Train loss 0.027043 on epoch=54
06/03/2022 17:46:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.023702 on epoch=54
06/03/2022 17:46:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.005656 on epoch=55
06/03/2022 17:46:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.001416 on epoch=56
06/03/2022 17:46:50 - INFO - __main__ - Global step 900 Train loss 0.019413 Classification-F1 0.6735053770213034 on epoch=56
06/03/2022 17:46:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.009969 on epoch=56
06/03/2022 17:47:00 - INFO - __main__ - Step 920 Global step 920 Train loss 0.004195 on epoch=57
06/03/2022 17:47:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.023117 on epoch=58
06/03/2022 17:47:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.031233 on epoch=58
06/03/2022 17:47:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.004017 on epoch=59
06/03/2022 17:47:19 - INFO - __main__ - Global step 950 Train loss 0.014506 Classification-F1 0.6225641025641027 on epoch=59
06/03/2022 17:47:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.001770 on epoch=59
06/03/2022 17:47:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.008611 on epoch=60
06/03/2022 17:47:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000670 on epoch=61
06/03/2022 17:47:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.001324 on epoch=61
06/03/2022 17:47:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.004197 on epoch=62
06/03/2022 17:47:46 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:47:46 - INFO - __main__ - Printing 3 examples
06/03/2022 17:47:46 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/03/2022 17:47:46 - INFO - __main__ - ['false']
06/03/2022 17:47:46 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/03/2022 17:47:46 - INFO - __main__ - ['false']
06/03/2022 17:47:46 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/03/2022 17:47:46 - INFO - __main__ - ['false']
06/03/2022 17:47:46 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:47:46 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:47:47 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 17:47:47 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:47:47 - INFO - __main__ - Printing 3 examples
06/03/2022 17:47:47 - INFO - __main__ -  [wiki_qa] question: who plays judas in lady gaga video judas? [SEP] answer: "Judas" is a song by American recording artist Lady Gaga , from her second studio album Born This Way (2011).
06/03/2022 17:47:47 - INFO - __main__ - ['false']
06/03/2022 17:47:47 - INFO - __main__ -  [wiki_qa] question: when was the state of utah established [SEP] answer: The world headquarters of The Church of Jesus Christ of Latter-day Saints (LDS Church) is located in Utah's state capital .
06/03/2022 17:47:47 - INFO - __main__ - ['false']
06/03/2022 17:47:47 - INFO - __main__ -  [wiki_qa] question: WHAT SINGER MARRIED HIS COUSIN [SEP] answer: In the meantime he was determined to gain back some of his popularity.
06/03/2022 17:47:47 - INFO - __main__ - ['false']
06/03/2022 17:47:47 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:47:47 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:47:47 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 17:47:48 - INFO - __main__ - Global step 1000 Train loss 0.003314 Classification-F1 0.6485052736691006 on epoch=62
06/03/2022 17:47:48 - INFO - __main__ - save last model!
06/03/2022 17:47:54 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 17:47:55 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 17:47:55 - INFO - __main__ - Printing 3 examples
06/03/2022 17:47:55 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 17:47:55 - INFO - __main__ - ['false']
06/03/2022 17:47:55 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 17:47:55 - INFO - __main__ - ['false']
06/03/2022 17:47:55 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 17:47:55 - INFO - __main__ - ['false']
06/03/2022 17:47:55 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:47:56 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:47:59 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 17:48:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 17:48:00 - INFO - __main__ - Starting training!
06/03/2022 17:48:29 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_100_0.0002_8_predictions.txt
06/03/2022 17:48:29 - INFO - __main__ - Classification-F1 on test data: 0.6075
06/03/2022 17:48:29 - INFO - __main__ - prefix=wiki_qa_128_100, lr=0.0002, bsz=8, dev_performance=0.7409065816107465, test_performance=0.607502745105096
06/03/2022 17:48:29 - INFO - __main__ - Running ... prefix=wiki_qa_128_100, lr=0.0001, bsz=8 ...
06/03/2022 17:48:30 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:48:30 - INFO - __main__ - Printing 3 examples
06/03/2022 17:48:30 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
06/03/2022 17:48:30 - INFO - __main__ - ['false']
06/03/2022 17:48:30 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
06/03/2022 17:48:30 - INFO - __main__ - ['false']
06/03/2022 17:48:30 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
06/03/2022 17:48:30 - INFO - __main__ - ['false']
06/03/2022 17:48:30 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:48:30 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:48:30 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 17:48:30 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 17:48:30 - INFO - __main__ - Printing 3 examples
06/03/2022 17:48:30 - INFO - __main__ -  [wiki_qa] question: who plays judas in lady gaga video judas? [SEP] answer: "Judas" is a song by American recording artist Lady Gaga , from her second studio album Born This Way (2011).
06/03/2022 17:48:30 - INFO - __main__ - ['false']
06/03/2022 17:48:30 - INFO - __main__ -  [wiki_qa] question: when was the state of utah established [SEP] answer: The world headquarters of The Church of Jesus Christ of Latter-day Saints (LDS Church) is located in Utah's state capital .
06/03/2022 17:48:30 - INFO - __main__ - ['false']
06/03/2022 17:48:30 - INFO - __main__ -  [wiki_qa] question: WHAT SINGER MARRIED HIS COUSIN [SEP] answer: In the meantime he was determined to gain back some of his popularity.
06/03/2022 17:48:30 - INFO - __main__ - ['false']
06/03/2022 17:48:30 - INFO - __main__ - Tokenizing Input ...
06/03/2022 17:48:30 - INFO - __main__ - Tokenizing Output ...
06/03/2022 17:48:31 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 17:48:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 17:48:41 - INFO - __main__ - Starting training!
06/03/2022 17:48:46 - INFO - __main__ - Step 10 Global step 10 Train loss 23.668936 on epoch=0
06/03/2022 17:48:51 - INFO - __main__ - Step 20 Global step 20 Train loss 20.518808 on epoch=1
06/03/2022 17:48:56 - INFO - __main__ - Step 30 Global step 30 Train loss 18.289951 on epoch=1
06/03/2022 17:49:01 - INFO - __main__ - Step 40 Global step 40 Train loss 17.197601 on epoch=2
06/03/2022 17:49:06 - INFO - __main__ - Step 50 Global step 50 Train loss 17.468182 on epoch=3
06/03/2022 17:50:04 - INFO - __main__ - Global step 50 Train loss 19.428696 Classification-F1 0.0 on epoch=3
06/03/2022 17:50:10 - INFO - __main__ - Step 60 Global step 60 Train loss 17.390558 on epoch=3
06/03/2022 17:50:15 - INFO - __main__ - Step 70 Global step 70 Train loss 16.289089 on epoch=4
06/03/2022 17:50:20 - INFO - __main__ - Step 80 Global step 80 Train loss 16.375557 on epoch=4
06/03/2022 17:50:25 - INFO - __main__ - Step 90 Global step 90 Train loss 15.566195 on epoch=5
06/03/2022 17:50:30 - INFO - __main__ - Step 100 Global step 100 Train loss 15.542689 on epoch=6
06/03/2022 17:51:24 - INFO - __main__ - Global step 100 Train loss 16.232817 Classification-F1 0.0 on epoch=6
06/03/2022 17:51:29 - INFO - __main__ - Step 110 Global step 110 Train loss 15.136179 on epoch=6
06/03/2022 17:51:34 - INFO - __main__ - Step 120 Global step 120 Train loss 15.187223 on epoch=7
06/03/2022 17:51:40 - INFO - __main__ - Step 130 Global step 130 Train loss 14.097791 on epoch=8
06/03/2022 17:51:45 - INFO - __main__ - Step 140 Global step 140 Train loss 13.610280 on epoch=8
06/03/2022 17:51:50 - INFO - __main__ - Step 150 Global step 150 Train loss 12.342658 on epoch=9
06/03/2022 17:52:35 - INFO - __main__ - Global step 150 Train loss 14.074828 Classification-F1 0.0 on epoch=9
06/03/2022 17:52:41 - INFO - __main__ - Step 160 Global step 160 Train loss 12.593824 on epoch=9
06/03/2022 17:52:46 - INFO - __main__ - Step 170 Global step 170 Train loss 8.150898 on epoch=10
06/03/2022 17:52:51 - INFO - __main__ - Step 180 Global step 180 Train loss 1.221934 on epoch=11
06/03/2022 17:52:56 - INFO - __main__ - Step 190 Global step 190 Train loss 0.871422 on epoch=11
06/03/2022 17:53:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.972418 on epoch=12
06/03/2022 17:53:04 - INFO - __main__ - Global step 200 Train loss 4.762100 Classification-F1 0.3401530406766009 on epoch=12
06/03/2022 17:53:10 - INFO - __main__ - Step 210 Global step 210 Train loss 0.912780 on epoch=13
06/03/2022 17:53:15 - INFO - __main__ - Step 220 Global step 220 Train loss 0.526874 on epoch=13
06/03/2022 17:53:20 - INFO - __main__ - Step 230 Global step 230 Train loss 0.422781 on epoch=14
06/03/2022 17:53:26 - INFO - __main__ - Step 240 Global step 240 Train loss 0.437911 on epoch=14
06/03/2022 17:53:31 - INFO - __main__ - Step 250 Global step 250 Train loss 0.505913 on epoch=15
06/03/2022 17:53:33 - INFO - __main__ - Global step 250 Train loss 0.561252 Classification-F1 0.5966160294950051 on epoch=15
06/03/2022 17:53:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.418078 on epoch=16
06/03/2022 17:53:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.557806 on epoch=16
06/03/2022 17:53:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.449025 on epoch=17
06/03/2022 17:53:55 - INFO - __main__ - Step 290 Global step 290 Train loss 0.553696 on epoch=18
06/03/2022 17:54:00 - INFO - __main__ - Step 300 Global step 300 Train loss 0.336962 on epoch=18
06/03/2022 17:54:03 - INFO - __main__ - Global step 300 Train loss 0.463114 Classification-F1 0.3333333333333333 on epoch=18
06/03/2022 17:54:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.367975 on epoch=19
06/03/2022 17:54:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.338547 on epoch=19
06/03/2022 17:54:18 - INFO - __main__ - Step 330 Global step 330 Train loss 0.421168 on epoch=20
06/03/2022 17:54:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.340433 on epoch=21
06/03/2022 17:54:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.372988 on epoch=21
06/03/2022 17:54:31 - INFO - __main__ - Global step 350 Train loss 0.368222 Classification-F1 0.6157138294474608 on epoch=21
06/03/2022 17:54:37 - INFO - __main__ - Step 360 Global step 360 Train loss 0.385599 on epoch=22
06/03/2022 17:54:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.400822 on epoch=23
06/03/2022 17:54:48 - INFO - __main__ - Step 380 Global step 380 Train loss 0.316248 on epoch=23
06/03/2022 17:54:53 - INFO - __main__ - Step 390 Global step 390 Train loss 0.305051 on epoch=24
06/03/2022 17:54:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.329923 on epoch=24
06/03/2022 17:55:01 - INFO - __main__ - Global step 400 Train loss 0.347528 Classification-F1 0.6447808262377799 on epoch=24
06/03/2022 17:55:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.368064 on epoch=25
06/03/2022 17:55:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.317311 on epoch=26
06/03/2022 17:55:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.345290 on epoch=26
06/03/2022 17:55:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.351827 on epoch=27
06/03/2022 17:55:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.342299 on epoch=28
06/03/2022 17:55:30 - INFO - __main__ - Global step 450 Train loss 0.344958 Classification-F1 0.33159268929503916 on epoch=28
06/03/2022 17:55:36 - INFO - __main__ - Step 460 Global step 460 Train loss 0.234528 on epoch=28
06/03/2022 17:55:41 - INFO - __main__ - Step 470 Global step 470 Train loss 0.272104 on epoch=29
06/03/2022 17:55:46 - INFO - __main__ - Step 480 Global step 480 Train loss 0.308003 on epoch=29
06/03/2022 17:55:51 - INFO - __main__ - Step 490 Global step 490 Train loss 0.308440 on epoch=30
06/03/2022 17:55:56 - INFO - __main__ - Step 500 Global step 500 Train loss 0.234252 on epoch=31
06/03/2022 17:55:59 - INFO - __main__ - Global step 500 Train loss 0.271465 Classification-F1 0.6669839456818327 on epoch=31
06/03/2022 17:56:05 - INFO - __main__ - Step 510 Global step 510 Train loss 0.236676 on epoch=31
06/03/2022 17:56:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.278920 on epoch=32
06/03/2022 17:56:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.231577 on epoch=33
06/03/2022 17:56:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.227272 on epoch=33
06/03/2022 17:56:26 - INFO - __main__ - Step 550 Global step 550 Train loss 0.254639 on epoch=34
06/03/2022 17:56:29 - INFO - __main__ - Global step 550 Train loss 0.245817 Classification-F1 0.6669839456818327 on epoch=34
06/03/2022 17:56:34 - INFO - __main__ - Step 560 Global step 560 Train loss 0.216447 on epoch=34
06/03/2022 17:56:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.265818 on epoch=35
06/03/2022 17:56:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.163600 on epoch=36
06/03/2022 17:56:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.178910 on epoch=36
06/03/2022 17:56:54 - INFO - __main__ - Step 600 Global step 600 Train loss 0.160425 on epoch=37
06/03/2022 17:56:57 - INFO - __main__ - Global step 600 Train loss 0.197040 Classification-F1 0.6984126984126984 on epoch=37
06/03/2022 17:57:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.161485 on epoch=38
06/03/2022 17:57:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.151621 on epoch=38
06/03/2022 17:57:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.126573 on epoch=39
06/03/2022 17:57:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.158514 on epoch=39
06/03/2022 17:57:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.103179 on epoch=40
06/03/2022 17:57:27 - INFO - __main__ - Global step 650 Train loss 0.140274 Classification-F1 0.48409044687263114 on epoch=40
06/03/2022 17:57:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.123725 on epoch=41
06/03/2022 17:57:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.121301 on epoch=41
06/03/2022 17:57:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.120772 on epoch=42
06/03/2022 17:57:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.102107 on epoch=43
06/03/2022 17:57:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.075195 on epoch=43
06/03/2022 17:57:56 - INFO - __main__ - Global step 700 Train loss 0.108620 Classification-F1 0.5627857229113117 on epoch=43
06/03/2022 17:58:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.114957 on epoch=44
06/03/2022 17:58:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.046234 on epoch=44
06/03/2022 17:58:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.107727 on epoch=45
06/03/2022 17:58:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.118663 on epoch=46
06/03/2022 17:58:21 - INFO - __main__ - Step 750 Global step 750 Train loss 0.107745 on epoch=46
06/03/2022 17:58:24 - INFO - __main__ - Global step 750 Train loss 0.099065 Classification-F1 0.4372120586492325 on epoch=46
06/03/2022 17:58:29 - INFO - __main__ - Step 760 Global step 760 Train loss 0.073054 on epoch=47
06/03/2022 17:58:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.039524 on epoch=48
06/03/2022 17:58:40 - INFO - __main__ - Step 780 Global step 780 Train loss 0.042818 on epoch=48
06/03/2022 17:58:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.042226 on epoch=49
06/03/2022 17:58:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.046639 on epoch=49
06/03/2022 17:58:53 - INFO - __main__ - Global step 800 Train loss 0.048852 Classification-F1 0.6645474399417617 on epoch=49
06/03/2022 17:58:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.065999 on epoch=50
06/03/2022 17:59:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.036805 on epoch=51
06/03/2022 17:59:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.025551 on epoch=51
06/03/2022 17:59:14 - INFO - __main__ - Step 840 Global step 840 Train loss 0.054922 on epoch=52
06/03/2022 17:59:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.035972 on epoch=53
06/03/2022 17:59:22 - INFO - __main__ - Global step 850 Train loss 0.043850 Classification-F1 0.6669839456818327 on epoch=53
06/03/2022 17:59:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.046558 on epoch=53
06/03/2022 17:59:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.051518 on epoch=54
06/03/2022 17:59:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.011262 on epoch=54
06/03/2022 17:59:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.024159 on epoch=55
06/03/2022 17:59:48 - INFO - __main__ - Step 900 Global step 900 Train loss 0.079260 on epoch=56
06/03/2022 17:59:50 - INFO - __main__ - Global step 900 Train loss 0.042551 Classification-F1 0.6471794871794871 on epoch=56
06/03/2022 17:59:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.014619 on epoch=56
06/03/2022 18:00:01 - INFO - __main__ - Step 920 Global step 920 Train loss 0.022925 on epoch=57
06/03/2022 18:00:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.012381 on epoch=58
06/03/2022 18:00:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.029039 on epoch=58
06/03/2022 18:00:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.017349 on epoch=59
06/03/2022 18:00:19 - INFO - __main__ - Global step 950 Train loss 0.019262 Classification-F1 0.6389743589743591 on epoch=59
06/03/2022 18:00:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.040402 on epoch=59
06/03/2022 18:00:30 - INFO - __main__ - Step 970 Global step 970 Train loss 0.023151 on epoch=60
06/03/2022 18:00:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.022233 on epoch=61
06/03/2022 18:00:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.020013 on epoch=61
06/03/2022 18:00:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.003159 on epoch=62
06/03/2022 18:00:46 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:00:46 - INFO - __main__ - Printing 3 examples
06/03/2022 18:00:46 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/03/2022 18:00:46 - INFO - __main__ - ['false']
06/03/2022 18:00:46 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/03/2022 18:00:46 - INFO - __main__ - ['false']
06/03/2022 18:00:46 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/03/2022 18:00:46 - INFO - __main__ - ['false']
06/03/2022 18:00:46 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:00:46 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:00:47 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 18:00:47 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:00:47 - INFO - __main__ - Printing 3 examples
06/03/2022 18:00:47 - INFO - __main__ -  [wiki_qa] question: what is a registered agent for an llc [SEP] answer: The registered agent's address may also be where the state will send the paperwork for the yearly renewal of the business entity's charter.
06/03/2022 18:00:47 - INFO - __main__ - ['false']
06/03/2022 18:00:47 - INFO - __main__ -  [wiki_qa] question: what does low self esteem mean [SEP] answer: Self-esteem encompasses beliefs (for example, "I am competent," "I am worthy") and emotions such as triumph, despair , pride and shame .
06/03/2022 18:00:47 - INFO - __main__ - ['false']
06/03/2022 18:00:47 - INFO - __main__ -  [wiki_qa] question: how many british soldiers were missing [SEP] answer: Becoming MIA has been an occupational risk for service personnel for as long as there has been warfare.
06/03/2022 18:00:47 - INFO - __main__ - ['false']
06/03/2022 18:00:47 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:00:47 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:00:47 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 18:00:48 - INFO - __main__ - Global step 1000 Train loss 0.021792 Classification-F1 0.6333078686019862 on epoch=62
06/03/2022 18:00:48 - INFO - __main__ - save last model!
06/03/2022 18:00:55 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 18:00:55 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 18:00:55 - INFO - __main__ - Printing 3 examples
06/03/2022 18:00:55 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 18:00:55 - INFO - __main__ - ['false']
06/03/2022 18:00:55 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 18:00:55 - INFO - __main__ - ['false']
06/03/2022 18:00:55 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 18:00:55 - INFO - __main__ - ['false']
06/03/2022 18:00:55 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:00:57 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:00:59 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 18:01:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 18:01:00 - INFO - __main__ - Starting training!
06/03/2022 18:01:29 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_100_0.0001_8_predictions.txt
06/03/2022 18:01:29 - INFO - __main__ - Classification-F1 on test data: 0.4733
06/03/2022 18:01:29 - INFO - __main__ - prefix=wiki_qa_128_100, lr=0.0001, bsz=8, dev_performance=0.6984126984126984, test_performance=0.4733050924495027
06/03/2022 18:01:29 - INFO - __main__ - Running ... prefix=wiki_qa_128_13, lr=0.0005, bsz=8 ...
06/03/2022 18:01:30 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:01:30 - INFO - __main__ - Printing 3 examples
06/03/2022 18:01:30 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/03/2022 18:01:30 - INFO - __main__ - ['false']
06/03/2022 18:01:30 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/03/2022 18:01:30 - INFO - __main__ - ['false']
06/03/2022 18:01:30 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/03/2022 18:01:30 - INFO - __main__ - ['false']
06/03/2022 18:01:30 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:01:30 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:01:30 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 18:01:30 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:01:30 - INFO - __main__ - Printing 3 examples
06/03/2022 18:01:30 - INFO - __main__ -  [wiki_qa] question: what is a registered agent for an llc [SEP] answer: The registered agent's address may also be where the state will send the paperwork for the yearly renewal of the business entity's charter.
06/03/2022 18:01:30 - INFO - __main__ - ['false']
06/03/2022 18:01:30 - INFO - __main__ -  [wiki_qa] question: what does low self esteem mean [SEP] answer: Self-esteem encompasses beliefs (for example, "I am competent," "I am worthy") and emotions such as triumph, despair , pride and shame .
06/03/2022 18:01:30 - INFO - __main__ - ['false']
06/03/2022 18:01:30 - INFO - __main__ -  [wiki_qa] question: how many british soldiers were missing [SEP] answer: Becoming MIA has been an occupational risk for service personnel for as long as there has been warfare.
06/03/2022 18:01:30 - INFO - __main__ - ['false']
06/03/2022 18:01:30 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:01:30 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:01:31 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 18:01:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 18:01:44 - INFO - __main__ - Starting training!
06/03/2022 18:01:48 - INFO - __main__ - Step 10 Global step 10 Train loss 22.601208 on epoch=0
06/03/2022 18:01:53 - INFO - __main__ - Step 20 Global step 20 Train loss 20.899746 on epoch=1
06/03/2022 18:01:58 - INFO - __main__ - Step 30 Global step 30 Train loss 17.090683 on epoch=1
06/03/2022 18:02:03 - INFO - __main__ - Step 40 Global step 40 Train loss 15.183632 on epoch=2
06/03/2022 18:02:08 - INFO - __main__ - Step 50 Global step 50 Train loss 12.962092 on epoch=3
06/03/2022 18:02:12 - INFO - __main__ - Global step 50 Train loss 17.747475 Classification-F1 0.0 on epoch=3
06/03/2022 18:02:18 - INFO - __main__ - Step 60 Global step 60 Train loss 7.391864 on epoch=3
06/03/2022 18:02:23 - INFO - __main__ - Step 70 Global step 70 Train loss 1.566378 on epoch=4
06/03/2022 18:02:28 - INFO - __main__ - Step 80 Global step 80 Train loss 0.710714 on epoch=4
06/03/2022 18:02:34 - INFO - __main__ - Step 90 Global step 90 Train loss 0.517280 on epoch=5
06/03/2022 18:02:39 - INFO - __main__ - Step 100 Global step 100 Train loss 0.418308 on epoch=6
06/03/2022 18:02:42 - INFO - __main__ - Global step 100 Train loss 2.120909 Classification-F1 0.3333333333333333 on epoch=6
06/03/2022 18:02:47 - INFO - __main__ - Step 110 Global step 110 Train loss 0.378890 on epoch=6
06/03/2022 18:02:52 - INFO - __main__ - Step 120 Global step 120 Train loss 0.370348 on epoch=7
06/03/2022 18:02:58 - INFO - __main__ - Step 130 Global step 130 Train loss 0.500915 on epoch=8
06/03/2022 18:03:03 - INFO - __main__ - Step 140 Global step 140 Train loss 0.534529 on epoch=8
06/03/2022 18:03:08 - INFO - __main__ - Step 150 Global step 150 Train loss 0.314477 on epoch=9
06/03/2022 18:03:11 - INFO - __main__ - Global step 150 Train loss 0.419832 Classification-F1 0.4599255196198932 on epoch=9
06/03/2022 18:03:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.302789 on epoch=9
06/03/2022 18:03:22 - INFO - __main__ - Step 170 Global step 170 Train loss 0.324984 on epoch=10
06/03/2022 18:03:27 - INFO - __main__ - Step 180 Global step 180 Train loss 0.282266 on epoch=11
06/03/2022 18:03:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.358387 on epoch=11
06/03/2022 18:03:37 - INFO - __main__ - Step 200 Global step 200 Train loss 0.151072 on epoch=12
06/03/2022 18:03:40 - INFO - __main__ - Global step 200 Train loss 0.283900 Classification-F1 0.6541208260953484 on epoch=12
06/03/2022 18:03:46 - INFO - __main__ - Step 210 Global step 210 Train loss 0.198344 on epoch=13
06/03/2022 18:03:51 - INFO - __main__ - Step 220 Global step 220 Train loss 0.093355 on epoch=13
06/03/2022 18:03:56 - INFO - __main__ - Step 230 Global step 230 Train loss 0.056547 on epoch=14
06/03/2022 18:04:01 - INFO - __main__ - Step 240 Global step 240 Train loss 0.362494 on epoch=14
06/03/2022 18:04:06 - INFO - __main__ - Step 250 Global step 250 Train loss 0.214772 on epoch=15
06/03/2022 18:04:09 - INFO - __main__ - Global step 250 Train loss 0.185102 Classification-F1 0.46515798620740656 on epoch=15
06/03/2022 18:04:15 - INFO - __main__ - Step 260 Global step 260 Train loss 0.061538 on epoch=16
06/03/2022 18:04:20 - INFO - __main__ - Step 270 Global step 270 Train loss 0.106335 on epoch=16
06/03/2022 18:04:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.068298 on epoch=17
06/03/2022 18:04:30 - INFO - __main__ - Step 290 Global step 290 Train loss 0.085418 on epoch=18
06/03/2022 18:04:35 - INFO - __main__ - Step 300 Global step 300 Train loss 0.057123 on epoch=18
06/03/2022 18:04:38 - INFO - __main__ - Global step 300 Train loss 0.075742 Classification-F1 0.5243403939056113 on epoch=18
06/03/2022 18:04:43 - INFO - __main__ - Step 310 Global step 310 Train loss 0.217599 on epoch=19
06/03/2022 18:04:48 - INFO - __main__ - Step 320 Global step 320 Train loss 0.222104 on epoch=19
06/03/2022 18:04:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.083264 on epoch=20
06/03/2022 18:04:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.197568 on epoch=21
06/03/2022 18:05:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.140833 on epoch=21
06/03/2022 18:05:07 - INFO - __main__ - Global step 350 Train loss 0.172274 Classification-F1 0.5602292613225873 on epoch=21
06/03/2022 18:05:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.106857 on epoch=22
06/03/2022 18:05:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.107624 on epoch=23
06/03/2022 18:05:23 - INFO - __main__ - Step 380 Global step 380 Train loss 0.091755 on epoch=23
06/03/2022 18:05:28 - INFO - __main__ - Step 390 Global step 390 Train loss 0.065286 on epoch=24
06/03/2022 18:05:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.106344 on epoch=24
06/03/2022 18:05:36 - INFO - __main__ - Global step 400 Train loss 0.095573 Classification-F1 0.6032388663967612 on epoch=24
06/03/2022 18:05:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.142629 on epoch=25
06/03/2022 18:05:46 - INFO - __main__ - Step 420 Global step 420 Train loss 0.050475 on epoch=26
06/03/2022 18:05:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.060368 on epoch=26
06/03/2022 18:05:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.042723 on epoch=27
06/03/2022 18:06:02 - INFO - __main__ - Step 450 Global step 450 Train loss 0.121231 on epoch=28
06/03/2022 18:06:05 - INFO - __main__ - Global step 450 Train loss 0.083485 Classification-F1 0.5060728744939271 on epoch=28
06/03/2022 18:06:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.222980 on epoch=28
06/03/2022 18:06:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.324253 on epoch=29
06/03/2022 18:06:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.173969 on epoch=29
06/03/2022 18:06:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.072518 on epoch=30
06/03/2022 18:06:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.027785 on epoch=31
06/03/2022 18:06:33 - INFO - __main__ - Global step 500 Train loss 0.164301 Classification-F1 0.5916666666666667 on epoch=31
06/03/2022 18:06:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.021255 on epoch=31
06/03/2022 18:06:44 - INFO - __main__ - Step 520 Global step 520 Train loss 0.033489 on epoch=32
06/03/2022 18:06:49 - INFO - __main__ - Step 530 Global step 530 Train loss 0.030312 on epoch=33
06/03/2022 18:06:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.045688 on epoch=33
06/03/2022 18:06:59 - INFO - __main__ - Step 550 Global step 550 Train loss 0.004508 on epoch=34
06/03/2022 18:07:02 - INFO - __main__ - Global step 550 Train loss 0.027050 Classification-F1 0.6225641025641027 on epoch=34
06/03/2022 18:07:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.003737 on epoch=34
06/03/2022 18:07:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.002412 on epoch=35
06/03/2022 18:07:18 - INFO - __main__ - Step 580 Global step 580 Train loss 0.002245 on epoch=36
06/03/2022 18:07:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.002576 on epoch=36
06/03/2022 18:07:29 - INFO - __main__ - Step 600 Global step 600 Train loss 0.002965 on epoch=37
06/03/2022 18:07:31 - INFO - __main__ - Global step 600 Train loss 0.002787 Classification-F1 0.6170742076175781 on epoch=37
06/03/2022 18:07:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.020738 on epoch=38
06/03/2022 18:07:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.014217 on epoch=38
06/03/2022 18:07:47 - INFO - __main__ - Step 630 Global step 630 Train loss 0.108032 on epoch=39
06/03/2022 18:07:52 - INFO - __main__ - Step 640 Global step 640 Train loss 0.007104 on epoch=39
06/03/2022 18:07:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.002569 on epoch=40
06/03/2022 18:08:00 - INFO - __main__ - Global step 650 Train loss 0.030532 Classification-F1 0.5974842767295597 on epoch=40
06/03/2022 18:08:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.001268 on epoch=41
06/03/2022 18:08:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.000364 on epoch=41
06/03/2022 18:08:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.001215 on epoch=42
06/03/2022 18:08:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000346 on epoch=43
06/03/2022 18:08:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.030084 on epoch=43
06/03/2022 18:08:29 - INFO - __main__ - Global step 700 Train loss 0.006655 Classification-F1 0.652296000122087 on epoch=43
06/03/2022 18:08:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000632 on epoch=44
06/03/2022 18:08:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000146 on epoch=44
06/03/2022 18:08:44 - INFO - __main__ - Step 730 Global step 730 Train loss 0.003058 on epoch=45
06/03/2022 18:08:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000658 on epoch=46
06/03/2022 18:08:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000076 on epoch=46
06/03/2022 18:08:57 - INFO - __main__ - Global step 750 Train loss 0.000914 Classification-F1 0.5784035133040558 on epoch=46
06/03/2022 18:09:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.008244 on epoch=47
06/03/2022 18:09:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000685 on epoch=48
06/03/2022 18:09:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000318 on epoch=48
06/03/2022 18:09:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000630 on epoch=49
06/03/2022 18:09:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000078 on epoch=49
06/03/2022 18:09:26 - INFO - __main__ - Global step 800 Train loss 0.001991 Classification-F1 0.5750866167109823 on epoch=49
06/03/2022 18:09:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.001012 on epoch=50
06/03/2022 18:09:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.003439 on epoch=51
06/03/2022 18:09:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000444 on epoch=51
06/03/2022 18:09:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000049 on epoch=52
06/03/2022 18:09:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000031 on epoch=53
06/03/2022 18:09:54 - INFO - __main__ - Global step 850 Train loss 0.000995 Classification-F1 0.6090126119884745 on epoch=53
06/03/2022 18:09:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000155 on epoch=53
06/03/2022 18:10:05 - INFO - __main__ - Step 870 Global step 870 Train loss 0.007292 on epoch=54
06/03/2022 18:10:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000054 on epoch=54
06/03/2022 18:10:15 - INFO - __main__ - Step 890 Global step 890 Train loss 0.019305 on epoch=55
06/03/2022 18:10:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.004040 on epoch=56
06/03/2022 18:10:23 - INFO - __main__ - Global step 900 Train loss 0.006169 Classification-F1 0.6101275461640967 on epoch=56
06/03/2022 18:10:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000063 on epoch=56
06/03/2022 18:10:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000082 on epoch=57
06/03/2022 18:10:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000201 on epoch=58
06/03/2022 18:10:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000287 on epoch=58
06/03/2022 18:10:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000060 on epoch=59
06/03/2022 18:10:52 - INFO - __main__ - Global step 950 Train loss 0.000139 Classification-F1 0.6271552736669015 on epoch=59
06/03/2022 18:10:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.016549 on epoch=59
06/03/2022 18:11:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000089 on epoch=60
06/03/2022 18:11:07 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000035 on epoch=61
06/03/2022 18:11:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000302 on epoch=61
06/03/2022 18:11:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000355 on epoch=62
06/03/2022 18:11:19 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:11:19 - INFO - __main__ - Printing 3 examples
06/03/2022 18:11:19 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/03/2022 18:11:19 - INFO - __main__ - ['false']
06/03/2022 18:11:19 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/03/2022 18:11:19 - INFO - __main__ - ['false']
06/03/2022 18:11:19 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/03/2022 18:11:19 - INFO - __main__ - ['false']
06/03/2022 18:11:19 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:11:19 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:11:19 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 18:11:19 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:11:19 - INFO - __main__ - Printing 3 examples
06/03/2022 18:11:19 - INFO - __main__ -  [wiki_qa] question: what is a registered agent for an llc [SEP] answer: The registered agent's address may also be where the state will send the paperwork for the yearly renewal of the business entity's charter.
06/03/2022 18:11:19 - INFO - __main__ - ['false']
06/03/2022 18:11:19 - INFO - __main__ -  [wiki_qa] question: what does low self esteem mean [SEP] answer: Self-esteem encompasses beliefs (for example, "I am competent," "I am worthy") and emotions such as triumph, despair , pride and shame .
06/03/2022 18:11:19 - INFO - __main__ - ['false']
06/03/2022 18:11:19 - INFO - __main__ -  [wiki_qa] question: how many british soldiers were missing [SEP] answer: Becoming MIA has been an occupational risk for service personnel for as long as there has been warfare.
06/03/2022 18:11:19 - INFO - __main__ - ['false']
06/03/2022 18:11:19 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:11:19 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:11:19 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 18:11:20 - INFO - __main__ - Global step 1000 Train loss 0.003466 Classification-F1 0.6170742076175781 on epoch=62
06/03/2022 18:11:20 - INFO - __main__ - save last model!
06/03/2022 18:11:27 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 18:11:28 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 18:11:28 - INFO - __main__ - Printing 3 examples
06/03/2022 18:11:28 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 18:11:28 - INFO - __main__ - ['false']
06/03/2022 18:11:28 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 18:11:28 - INFO - __main__ - ['false']
06/03/2022 18:11:28 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 18:11:28 - INFO - __main__ - ['false']
06/03/2022 18:11:28 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:11:29 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:11:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 18:11:31 - INFO - __main__ - Starting training!
06/03/2022 18:11:32 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 18:12:01 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_13_0.0005_8_predictions.txt
06/03/2022 18:12:01 - INFO - __main__ - Classification-F1 on test data: 0.3950
06/03/2022 18:12:01 - INFO - __main__ - prefix=wiki_qa_128_13, lr=0.0005, bsz=8, dev_performance=0.6541208260953484, test_performance=0.3950418814186021
06/03/2022 18:12:01 - INFO - __main__ - Running ... prefix=wiki_qa_128_13, lr=0.0003, bsz=8 ...
06/03/2022 18:12:02 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:12:02 - INFO - __main__ - Printing 3 examples
06/03/2022 18:12:02 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/03/2022 18:12:02 - INFO - __main__ - ['false']
06/03/2022 18:12:02 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/03/2022 18:12:02 - INFO - __main__ - ['false']
06/03/2022 18:12:02 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/03/2022 18:12:02 - INFO - __main__ - ['false']
06/03/2022 18:12:02 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:12:02 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:12:02 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 18:12:02 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:12:02 - INFO - __main__ - Printing 3 examples
06/03/2022 18:12:02 - INFO - __main__ -  [wiki_qa] question: what is a registered agent for an llc [SEP] answer: The registered agent's address may also be where the state will send the paperwork for the yearly renewal of the business entity's charter.
06/03/2022 18:12:02 - INFO - __main__ - ['false']
06/03/2022 18:12:02 - INFO - __main__ -  [wiki_qa] question: what does low self esteem mean [SEP] answer: Self-esteem encompasses beliefs (for example, "I am competent," "I am worthy") and emotions such as triumph, despair , pride and shame .
06/03/2022 18:12:02 - INFO - __main__ - ['false']
06/03/2022 18:12:02 - INFO - __main__ -  [wiki_qa] question: how many british soldiers were missing [SEP] answer: Becoming MIA has been an occupational risk for service personnel for as long as there has been warfare.
06/03/2022 18:12:02 - INFO - __main__ - ['false']
06/03/2022 18:12:02 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:12:03 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:12:03 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 18:12:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 18:12:16 - INFO - __main__ - Starting training!
06/03/2022 18:12:20 - INFO - __main__ - Step 10 Global step 10 Train loss 22.983690 on epoch=0
06/03/2022 18:12:25 - INFO - __main__ - Step 20 Global step 20 Train loss 17.574078 on epoch=1
06/03/2022 18:12:30 - INFO - __main__ - Step 30 Global step 30 Train loss 17.161854 on epoch=1
06/03/2022 18:12:36 - INFO - __main__ - Step 40 Global step 40 Train loss 16.472935 on epoch=2
06/03/2022 18:12:41 - INFO - __main__ - Step 50 Global step 50 Train loss 15.055316 on epoch=3
06/03/2022 18:12:56 - INFO - __main__ - Global step 50 Train loss 17.849575 Classification-F1 0.0 on epoch=3
06/03/2022 18:13:02 - INFO - __main__ - Step 60 Global step 60 Train loss 14.919881 on epoch=3
06/03/2022 18:13:07 - INFO - __main__ - Step 70 Global step 70 Train loss 12.281360 on epoch=4
06/03/2022 18:13:12 - INFO - __main__ - Step 80 Global step 80 Train loss 10.877437 on epoch=4
06/03/2022 18:13:17 - INFO - __main__ - Step 90 Global step 90 Train loss 3.679741 on epoch=5
06/03/2022 18:13:22 - INFO - __main__ - Step 100 Global step 100 Train loss 3.124812 on epoch=6
06/03/2022 18:13:25 - INFO - __main__ - Global step 100 Train loss 8.976646 Classification-F1 0.3333333333333333 on epoch=6
06/03/2022 18:13:30 - INFO - __main__ - Step 110 Global step 110 Train loss 3.924219 on epoch=6
06/03/2022 18:13:36 - INFO - __main__ - Step 120 Global step 120 Train loss 2.000667 on epoch=7
06/03/2022 18:13:41 - INFO - __main__ - Step 130 Global step 130 Train loss 2.397143 on epoch=8
06/03/2022 18:13:46 - INFO - __main__ - Step 140 Global step 140 Train loss 2.569012 on epoch=8
06/03/2022 18:13:51 - INFO - __main__ - Step 150 Global step 150 Train loss 1.525641 on epoch=9
06/03/2022 18:13:53 - INFO - __main__ - Global step 150 Train loss 2.483336 Classification-F1 0.3328595119639896 on epoch=9
06/03/2022 18:13:58 - INFO - __main__ - Step 160 Global step 160 Train loss 1.541637 on epoch=9
06/03/2022 18:14:03 - INFO - __main__ - Step 170 Global step 170 Train loss 1.460007 on epoch=10
06/03/2022 18:14:08 - INFO - __main__ - Step 180 Global step 180 Train loss 2.228220 on epoch=11
06/03/2022 18:14:14 - INFO - __main__ - Step 190 Global step 190 Train loss 1.166565 on epoch=11
06/03/2022 18:14:19 - INFO - __main__ - Step 200 Global step 200 Train loss 0.769637 on epoch=12
06/03/2022 18:14:21 - INFO - __main__ - Global step 200 Train loss 1.433213 Classification-F1 0.49090909090909085 on epoch=12
06/03/2022 18:14:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.636986 on epoch=13
06/03/2022 18:14:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.584424 on epoch=13
06/03/2022 18:14:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.404414 on epoch=14
06/03/2022 18:14:42 - INFO - __main__ - Step 240 Global step 240 Train loss 0.324703 on epoch=14
06/03/2022 18:14:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.394386 on epoch=15
06/03/2022 18:14:50 - INFO - __main__ - Global step 250 Train loss 0.468983 Classification-F1 0.3333333333333333 on epoch=15
06/03/2022 18:14:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.373205 on epoch=16
06/03/2022 18:15:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.339770 on epoch=16
06/03/2022 18:15:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.317878 on epoch=17
06/03/2022 18:15:11 - INFO - __main__ - Step 290 Global step 290 Train loss 0.335180 on epoch=18
06/03/2022 18:15:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.388316 on epoch=18
06/03/2022 18:15:19 - INFO - __main__ - Global step 300 Train loss 0.350870 Classification-F1 0.3732922688146569 on epoch=18
06/03/2022 18:15:24 - INFO - __main__ - Step 310 Global step 310 Train loss 0.291943 on epoch=19
06/03/2022 18:15:29 - INFO - __main__ - Step 320 Global step 320 Train loss 0.284755 on epoch=19
06/03/2022 18:15:34 - INFO - __main__ - Step 330 Global step 330 Train loss 0.239576 on epoch=20
06/03/2022 18:15:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.209598 on epoch=21
06/03/2022 18:15:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.246358 on epoch=21
06/03/2022 18:15:47 - INFO - __main__ - Global step 350 Train loss 0.254446 Classification-F1 0.609549344164914 on epoch=21
06/03/2022 18:15:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.192734 on epoch=22
06/03/2022 18:15:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.207050 on epoch=23
06/03/2022 18:16:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.209817 on epoch=23
06/03/2022 18:16:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.131647 on epoch=24
06/03/2022 18:16:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.182575 on epoch=24
06/03/2022 18:16:16 - INFO - __main__ - Global step 400 Train loss 0.184765 Classification-F1 0.6557246775475274 on epoch=24
06/03/2022 18:16:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.159318 on epoch=25
06/03/2022 18:16:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.162006 on epoch=26
06/03/2022 18:16:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.139403 on epoch=26
06/03/2022 18:16:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.086870 on epoch=27
06/03/2022 18:16:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.096778 on epoch=28
06/03/2022 18:16:45 - INFO - __main__ - Global step 450 Train loss 0.128875 Classification-F1 0.5542865102026604 on epoch=28
06/03/2022 18:16:50 - INFO - __main__ - Step 460 Global step 460 Train loss 0.077093 on epoch=28
06/03/2022 18:16:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.085116 on epoch=29
06/03/2022 18:17:01 - INFO - __main__ - Step 480 Global step 480 Train loss 0.074674 on epoch=29
06/03/2022 18:17:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.090580 on epoch=30
06/03/2022 18:17:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.072373 on epoch=31
06/03/2022 18:17:14 - INFO - __main__ - Global step 500 Train loss 0.079967 Classification-F1 0.5364579706107667 on epoch=31
06/03/2022 18:17:19 - INFO - __main__ - Step 510 Global step 510 Train loss 0.078481 on epoch=31
06/03/2022 18:17:24 - INFO - __main__ - Step 520 Global step 520 Train loss 0.048854 on epoch=32
06/03/2022 18:17:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.081830 on epoch=33
06/03/2022 18:17:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.085377 on epoch=33
06/03/2022 18:17:40 - INFO - __main__ - Step 550 Global step 550 Train loss 0.033859 on epoch=34
06/03/2022 18:17:43 - INFO - __main__ - Global step 550 Train loss 0.065680 Classification-F1 0.3963507015348133 on epoch=34
06/03/2022 18:17:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.078503 on epoch=34
06/03/2022 18:17:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.026187 on epoch=35
06/03/2022 18:17:59 - INFO - __main__ - Step 580 Global step 580 Train loss 0.038088 on epoch=36
06/03/2022 18:18:04 - INFO - __main__ - Step 590 Global step 590 Train loss 0.037978 on epoch=36
06/03/2022 18:18:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.068147 on epoch=37
06/03/2022 18:18:12 - INFO - __main__ - Global step 600 Train loss 0.049780 Classification-F1 0.386038799535732 on epoch=37
06/03/2022 18:18:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.015309 on epoch=38
06/03/2022 18:18:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.029400 on epoch=38
06/03/2022 18:18:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.030572 on epoch=39
06/03/2022 18:18:33 - INFO - __main__ - Step 640 Global step 640 Train loss 0.025191 on epoch=39
06/03/2022 18:18:38 - INFO - __main__ - Step 650 Global step 650 Train loss 0.069878 on epoch=40
06/03/2022 18:18:41 - INFO - __main__ - Global step 650 Train loss 0.034070 Classification-F1 0.41633874272334054 on epoch=40
06/03/2022 18:18:46 - INFO - __main__ - Step 660 Global step 660 Train loss 0.040776 on epoch=41
06/03/2022 18:18:52 - INFO - __main__ - Step 670 Global step 670 Train loss 0.027442 on epoch=41
06/03/2022 18:18:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.019457 on epoch=42
06/03/2022 18:19:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.008437 on epoch=43
06/03/2022 18:19:07 - INFO - __main__ - Step 700 Global step 700 Train loss 0.027697 on epoch=43
06/03/2022 18:19:10 - INFO - __main__ - Global step 700 Train loss 0.024762 Classification-F1 0.4826588016822328 on epoch=43
06/03/2022 18:19:15 - INFO - __main__ - Step 710 Global step 710 Train loss 0.005671 on epoch=44
06/03/2022 18:19:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.018569 on epoch=44
06/03/2022 18:19:26 - INFO - __main__ - Step 730 Global step 730 Train loss 0.009438 on epoch=45
06/03/2022 18:19:31 - INFO - __main__ - Step 740 Global step 740 Train loss 0.018911 on epoch=46
06/03/2022 18:19:36 - INFO - __main__ - Step 750 Global step 750 Train loss 0.001138 on epoch=46
06/03/2022 18:19:39 - INFO - __main__ - Global step 750 Train loss 0.010746 Classification-F1 0.5725777890209968 on epoch=46
06/03/2022 18:19:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.006627 on epoch=47
06/03/2022 18:19:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.003372 on epoch=48
06/03/2022 18:19:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.078083 on epoch=48
06/03/2022 18:20:00 - INFO - __main__ - Step 790 Global step 790 Train loss 0.003474 on epoch=49
06/03/2022 18:20:05 - INFO - __main__ - Step 800 Global step 800 Train loss 0.021184 on epoch=49
06/03/2022 18:20:08 - INFO - __main__ - Global step 800 Train loss 0.022548 Classification-F1 0.6437246963562753 on epoch=49
06/03/2022 18:20:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.034598 on epoch=50
06/03/2022 18:20:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.007987 on epoch=51
06/03/2022 18:20:23 - INFO - __main__ - Step 830 Global step 830 Train loss 0.004088 on epoch=51
06/03/2022 18:20:28 - INFO - __main__ - Step 840 Global step 840 Train loss 0.010030 on epoch=52
06/03/2022 18:20:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.006568 on epoch=53
06/03/2022 18:20:36 - INFO - __main__ - Global step 850 Train loss 0.012654 Classification-F1 0.5652347652347651 on epoch=53
06/03/2022 18:20:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.023726 on epoch=53
06/03/2022 18:20:47 - INFO - __main__ - Step 870 Global step 870 Train loss 0.042734 on epoch=54
06/03/2022 18:20:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.016587 on epoch=54
06/03/2022 18:20:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.006191 on epoch=55
06/03/2022 18:21:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.005135 on epoch=56
06/03/2022 18:21:05 - INFO - __main__ - Global step 900 Train loss 0.018875 Classification-F1 0.6016184251478369 on epoch=56
06/03/2022 18:21:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.003173 on epoch=56
06/03/2022 18:21:15 - INFO - __main__ - Step 920 Global step 920 Train loss 0.003262 on epoch=57
06/03/2022 18:21:21 - INFO - __main__ - Step 930 Global step 930 Train loss 0.005235 on epoch=58
06/03/2022 18:21:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000417 on epoch=58
06/03/2022 18:21:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000279 on epoch=59
06/03/2022 18:21:34 - INFO - __main__ - Global step 950 Train loss 0.002473 Classification-F1 0.5834046336839633 on epoch=59
06/03/2022 18:21:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000646 on epoch=59
06/03/2022 18:21:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.001591 on epoch=60
06/03/2022 18:21:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000393 on epoch=61
06/03/2022 18:21:55 - INFO - __main__ - Step 990 Global step 990 Train loss 0.006819 on epoch=61
06/03/2022 18:22:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.006020 on epoch=62
06/03/2022 18:22:01 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:22:01 - INFO - __main__ - Printing 3 examples
06/03/2022 18:22:01 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/03/2022 18:22:01 - INFO - __main__ - ['false']
06/03/2022 18:22:01 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/03/2022 18:22:01 - INFO - __main__ - ['false']
06/03/2022 18:22:01 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/03/2022 18:22:01 - INFO - __main__ - ['false']
06/03/2022 18:22:01 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:22:01 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:22:01 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 18:22:01 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:22:01 - INFO - __main__ - Printing 3 examples
06/03/2022 18:22:01 - INFO - __main__ -  [wiki_qa] question: what is a registered agent for an llc [SEP] answer: The registered agent's address may also be where the state will send the paperwork for the yearly renewal of the business entity's charter.
06/03/2022 18:22:01 - INFO - __main__ - ['false']
06/03/2022 18:22:01 - INFO - __main__ -  [wiki_qa] question: what does low self esteem mean [SEP] answer: Self-esteem encompasses beliefs (for example, "I am competent," "I am worthy") and emotions such as triumph, despair , pride and shame .
06/03/2022 18:22:01 - INFO - __main__ - ['false']
06/03/2022 18:22:01 - INFO - __main__ -  [wiki_qa] question: how many british soldiers were missing [SEP] answer: Becoming MIA has been an occupational risk for service personnel for as long as there has been warfare.
06/03/2022 18:22:01 - INFO - __main__ - ['false']
06/03/2022 18:22:01 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:22:01 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:22:02 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 18:22:03 - INFO - __main__ - Global step 1000 Train loss 0.003094 Classification-F1 0.6333078686019862 on epoch=62
06/03/2022 18:22:03 - INFO - __main__ - save last model!
06/03/2022 18:22:09 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 18:22:10 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 18:22:10 - INFO - __main__ - Printing 3 examples
06/03/2022 18:22:10 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 18:22:10 - INFO - __main__ - ['false']
06/03/2022 18:22:10 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 18:22:10 - INFO - __main__ - ['false']
06/03/2022 18:22:10 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 18:22:10 - INFO - __main__ - ['false']
06/03/2022 18:22:10 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:22:11 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:22:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 18:22:12 - INFO - __main__ - Starting training!
06/03/2022 18:22:14 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 18:22:43 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_13_0.0003_8_predictions.txt
06/03/2022 18:22:43 - INFO - __main__ - Classification-F1 on test data: 0.5050
06/03/2022 18:22:43 - INFO - __main__ - prefix=wiki_qa_128_13, lr=0.0003, bsz=8, dev_performance=0.6557246775475274, test_performance=0.5050088507007241
06/03/2022 18:22:43 - INFO - __main__ - Running ... prefix=wiki_qa_128_13, lr=0.0002, bsz=8 ...
06/03/2022 18:22:44 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:22:44 - INFO - __main__ - Printing 3 examples
06/03/2022 18:22:44 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/03/2022 18:22:44 - INFO - __main__ - ['false']
06/03/2022 18:22:44 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/03/2022 18:22:44 - INFO - __main__ - ['false']
06/03/2022 18:22:44 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/03/2022 18:22:44 - INFO - __main__ - ['false']
06/03/2022 18:22:44 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:22:44 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:22:45 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 18:22:45 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:22:45 - INFO - __main__ - Printing 3 examples
06/03/2022 18:22:45 - INFO - __main__ -  [wiki_qa] question: what is a registered agent for an llc [SEP] answer: The registered agent's address may also be where the state will send the paperwork for the yearly renewal of the business entity's charter.
06/03/2022 18:22:45 - INFO - __main__ - ['false']
06/03/2022 18:22:45 - INFO - __main__ -  [wiki_qa] question: what does low self esteem mean [SEP] answer: Self-esteem encompasses beliefs (for example, "I am competent," "I am worthy") and emotions such as triumph, despair , pride and shame .
06/03/2022 18:22:45 - INFO - __main__ - ['false']
06/03/2022 18:22:45 - INFO - __main__ -  [wiki_qa] question: how many british soldiers were missing [SEP] answer: Becoming MIA has been an occupational risk for service personnel for as long as there has been warfare.
06/03/2022 18:22:45 - INFO - __main__ - ['false']
06/03/2022 18:22:45 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:22:45 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:22:45 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 18:22:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 18:22:56 - INFO - __main__ - Starting training!
06/03/2022 18:23:00 - INFO - __main__ - Step 10 Global step 10 Train loss 24.227438 on epoch=0
06/03/2022 18:23:05 - INFO - __main__ - Step 20 Global step 20 Train loss 19.735224 on epoch=1
06/03/2022 18:23:10 - INFO - __main__ - Step 30 Global step 30 Train loss 18.138943 on epoch=1
06/03/2022 18:23:16 - INFO - __main__ - Step 40 Global step 40 Train loss 17.002317 on epoch=2
06/03/2022 18:23:21 - INFO - __main__ - Step 50 Global step 50 Train loss 16.306744 on epoch=3
06/03/2022 18:24:03 - INFO - __main__ - Global step 50 Train loss 19.082132 Classification-F1 0.0 on epoch=3
06/03/2022 18:24:08 - INFO - __main__ - Step 60 Global step 60 Train loss 15.138094 on epoch=3
06/03/2022 18:24:14 - INFO - __main__ - Step 70 Global step 70 Train loss 15.078356 on epoch=4
06/03/2022 18:24:19 - INFO - __main__ - Step 80 Global step 80 Train loss 13.364759 on epoch=4
06/03/2022 18:24:24 - INFO - __main__ - Step 90 Global step 90 Train loss 12.636827 on epoch=5
06/03/2022 18:24:29 - INFO - __main__ - Step 100 Global step 100 Train loss 12.215488 on epoch=6
06/03/2022 18:24:32 - INFO - __main__ - Global step 100 Train loss 13.686706 Classification-F1 0.0 on epoch=6
06/03/2022 18:24:37 - INFO - __main__ - Step 110 Global step 110 Train loss 9.375113 on epoch=6
06/03/2022 18:24:42 - INFO - __main__ - Step 120 Global step 120 Train loss 6.101527 on epoch=7
06/03/2022 18:24:47 - INFO - __main__ - Step 130 Global step 130 Train loss 2.086666 on epoch=8
06/03/2022 18:24:52 - INFO - __main__ - Step 140 Global step 140 Train loss 0.899949 on epoch=8
06/03/2022 18:24:58 - INFO - __main__ - Step 150 Global step 150 Train loss 0.777233 on epoch=9
06/03/2022 18:25:00 - INFO - __main__ - Global step 150 Train loss 3.848098 Classification-F1 0.3333333333333333 on epoch=9
06/03/2022 18:25:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.555790 on epoch=9
06/03/2022 18:25:12 - INFO - __main__ - Step 170 Global step 170 Train loss 0.626168 on epoch=10
06/03/2022 18:25:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.437399 on epoch=11
06/03/2022 18:25:22 - INFO - __main__ - Step 190 Global step 190 Train loss 0.439852 on epoch=11
06/03/2022 18:25:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.526516 on epoch=12
06/03/2022 18:25:30 - INFO - __main__ - Global step 200 Train loss 0.517145 Classification-F1 0.3333333333333333 on epoch=12
06/03/2022 18:25:35 - INFO - __main__ - Step 210 Global step 210 Train loss 0.436676 on epoch=13
06/03/2022 18:25:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.430854 on epoch=13
06/03/2022 18:25:46 - INFO - __main__ - Step 230 Global step 230 Train loss 0.456695 on epoch=14
06/03/2022 18:25:51 - INFO - __main__ - Step 240 Global step 240 Train loss 0.402771 on epoch=14
06/03/2022 18:25:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.664652 on epoch=15
06/03/2022 18:25:59 - INFO - __main__ - Global step 250 Train loss 0.478329 Classification-F1 0.39581271412257324 on epoch=15
06/03/2022 18:26:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.337059 on epoch=16
06/03/2022 18:26:10 - INFO - __main__ - Step 270 Global step 270 Train loss 0.356790 on epoch=16
06/03/2022 18:26:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.291462 on epoch=17
06/03/2022 18:26:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.253643 on epoch=18
06/03/2022 18:26:26 - INFO - __main__ - Step 300 Global step 300 Train loss 0.279736 on epoch=18
06/03/2022 18:26:28 - INFO - __main__ - Global step 300 Train loss 0.303738 Classification-F1 0.3333333333333333 on epoch=18
06/03/2022 18:26:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.245037 on epoch=19
06/03/2022 18:26:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.269376 on epoch=19
06/03/2022 18:26:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.295435 on epoch=20
06/03/2022 18:26:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.165081 on epoch=21
06/03/2022 18:26:54 - INFO - __main__ - Step 350 Global step 350 Train loss 0.217977 on epoch=21
06/03/2022 18:26:57 - INFO - __main__ - Global step 350 Train loss 0.238581 Classification-F1 0.6810189671881489 on epoch=21
06/03/2022 18:27:03 - INFO - __main__ - Step 360 Global step 360 Train loss 0.182210 on epoch=22
06/03/2022 18:27:08 - INFO - __main__ - Step 370 Global step 370 Train loss 0.134993 on epoch=23
06/03/2022 18:27:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.164844 on epoch=23
06/03/2022 18:27:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.112115 on epoch=24
06/03/2022 18:27:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.148434 on epoch=24
06/03/2022 18:27:27 - INFO - __main__ - Global step 400 Train loss 0.148519 Classification-F1 0.6951450381679389 on epoch=24
06/03/2022 18:27:33 - INFO - __main__ - Step 410 Global step 410 Train loss 0.090330 on epoch=25
06/03/2022 18:27:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.091116 on epoch=26
06/03/2022 18:27:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.091284 on epoch=26
06/03/2022 18:27:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.069150 on epoch=27
06/03/2022 18:27:54 - INFO - __main__ - Step 450 Global step 450 Train loss 0.071556 on epoch=28
06/03/2022 18:27:57 - INFO - __main__ - Global step 450 Train loss 0.082687 Classification-F1 0.6385802315345392 on epoch=28
06/03/2022 18:28:02 - INFO - __main__ - Step 460 Global step 460 Train loss 0.079843 on epoch=28
06/03/2022 18:28:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.028243 on epoch=29
06/03/2022 18:28:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.093841 on epoch=29
06/03/2022 18:28:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.042712 on epoch=30
06/03/2022 18:28:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.067375 on epoch=31
06/03/2022 18:28:25 - INFO - __main__ - Global step 500 Train loss 0.062403 Classification-F1 0.5077994631067257 on epoch=31
06/03/2022 18:28:30 - INFO - __main__ - Step 510 Global step 510 Train loss 0.119019 on epoch=31
06/03/2022 18:28:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.033020 on epoch=32
06/03/2022 18:28:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.029232 on epoch=33
06/03/2022 18:28:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.040260 on epoch=33
06/03/2022 18:28:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.027233 on epoch=34
06/03/2022 18:28:54 - INFO - __main__ - Global step 550 Train loss 0.049753 Classification-F1 0.6693360888659261 on epoch=34
06/03/2022 18:28:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.029848 on epoch=34
06/03/2022 18:29:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.044214 on epoch=35
06/03/2022 18:29:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.011229 on epoch=36
06/03/2022 18:29:15 - INFO - __main__ - Step 590 Global step 590 Train loss 0.029282 on epoch=36
06/03/2022 18:29:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.032465 on epoch=37
06/03/2022 18:29:23 - INFO - __main__ - Global step 600 Train loss 0.029408 Classification-F1 0.7262952101661779 on epoch=37
06/03/2022 18:29:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.004333 on epoch=38
06/03/2022 18:29:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.038175 on epoch=38
06/03/2022 18:29:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.023163 on epoch=39
06/03/2022 18:29:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.036212 on epoch=39
06/03/2022 18:29:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.002216 on epoch=40
06/03/2022 18:29:53 - INFO - __main__ - Global step 650 Train loss 0.020820 Classification-F1 0.681566972650407 on epoch=40
06/03/2022 18:29:58 - INFO - __main__ - Step 660 Global step 660 Train loss 0.029388 on epoch=41
06/03/2022 18:30:03 - INFO - __main__ - Step 670 Global step 670 Train loss 0.009486 on epoch=41
06/03/2022 18:30:08 - INFO - __main__ - Step 680 Global step 680 Train loss 0.006505 on epoch=42
06/03/2022 18:30:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.026307 on epoch=43
06/03/2022 18:30:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.005332 on epoch=43
06/03/2022 18:30:21 - INFO - __main__ - Global step 700 Train loss 0.015404 Classification-F1 0.6635897435897435 on epoch=43
06/03/2022 18:30:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.017454 on epoch=44
06/03/2022 18:30:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.003232 on epoch=44
06/03/2022 18:30:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.016514 on epoch=45
06/03/2022 18:30:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.002679 on epoch=46
06/03/2022 18:30:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.010481 on epoch=46
06/03/2022 18:30:51 - INFO - __main__ - Global step 750 Train loss 0.010072 Classification-F1 0.6562646606810645 on epoch=46
06/03/2022 18:30:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.029972 on epoch=47
06/03/2022 18:31:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.002942 on epoch=48
06/03/2022 18:31:06 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000948 on epoch=48
06/03/2022 18:31:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.020688 on epoch=49
06/03/2022 18:31:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.001095 on epoch=49
06/03/2022 18:31:20 - INFO - __main__ - Global step 800 Train loss 0.011129 Classification-F1 0.6896285682795107 on epoch=49
06/03/2022 18:31:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.004400 on epoch=50
06/03/2022 18:31:31 - INFO - __main__ - Step 820 Global step 820 Train loss 0.056600 on epoch=51
06/03/2022 18:31:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.010903 on epoch=51
06/03/2022 18:31:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.007776 on epoch=52
06/03/2022 18:31:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.006958 on epoch=53
06/03/2022 18:31:49 - INFO - __main__ - Global step 850 Train loss 0.017327 Classification-F1 0.7282754164936084 on epoch=53
06/03/2022 18:31:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.033553 on epoch=53
06/03/2022 18:32:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.004826 on epoch=54
06/03/2022 18:32:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.027587 on epoch=54
06/03/2022 18:32:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.022435 on epoch=55
06/03/2022 18:32:16 - INFO - __main__ - Step 900 Global step 900 Train loss 0.002033 on epoch=56
06/03/2022 18:32:18 - INFO - __main__ - Global step 900 Train loss 0.018087 Classification-F1 0.696811786441802 on epoch=56
06/03/2022 18:32:24 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000983 on epoch=56
06/03/2022 18:32:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.001303 on epoch=57
06/03/2022 18:32:34 - INFO - __main__ - Step 930 Global step 930 Train loss 0.019706 on epoch=58
06/03/2022 18:32:39 - INFO - __main__ - Step 940 Global step 940 Train loss 0.004394 on epoch=58
06/03/2022 18:32:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.005431 on epoch=59
06/03/2022 18:32:47 - INFO - __main__ - Global step 950 Train loss 0.006364 Classification-F1 0.5887550200803213 on epoch=59
06/03/2022 18:32:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.002789 on epoch=59
06/03/2022 18:32:58 - INFO - __main__ - Step 970 Global step 970 Train loss 0.021227 on epoch=60
06/03/2022 18:33:03 - INFO - __main__ - Step 980 Global step 980 Train loss 0.002595 on epoch=61
06/03/2022 18:33:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.002974 on epoch=61
06/03/2022 18:33:13 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.002423 on epoch=62
06/03/2022 18:33:15 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:33:15 - INFO - __main__ - Printing 3 examples
06/03/2022 18:33:15 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/03/2022 18:33:15 - INFO - __main__ - ['false']
06/03/2022 18:33:15 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/03/2022 18:33:15 - INFO - __main__ - ['false']
06/03/2022 18:33:15 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/03/2022 18:33:15 - INFO - __main__ - ['false']
06/03/2022 18:33:15 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:33:15 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:33:15 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 18:33:15 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:33:15 - INFO - __main__ - Printing 3 examples
06/03/2022 18:33:15 - INFO - __main__ -  [wiki_qa] question: what is a registered agent for an llc [SEP] answer: The registered agent's address may also be where the state will send the paperwork for the yearly renewal of the business entity's charter.
06/03/2022 18:33:15 - INFO - __main__ - ['false']
06/03/2022 18:33:15 - INFO - __main__ -  [wiki_qa] question: what does low self esteem mean [SEP] answer: Self-esteem encompasses beliefs (for example, "I am competent," "I am worthy") and emotions such as triumph, despair , pride and shame .
06/03/2022 18:33:15 - INFO - __main__ - ['false']
06/03/2022 18:33:15 - INFO - __main__ -  [wiki_qa] question: how many british soldiers were missing [SEP] answer: Becoming MIA has been an occupational risk for service personnel for as long as there has been warfare.
06/03/2022 18:33:15 - INFO - __main__ - ['false']
06/03/2022 18:33:15 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:33:15 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:33:15 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 18:33:16 - INFO - __main__ - Global step 1000 Train loss 0.006402 Classification-F1 0.6958897600380138 on epoch=62
06/03/2022 18:33:16 - INFO - __main__ - save last model!
06/03/2022 18:33:23 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 18:33:24 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 18:33:24 - INFO - __main__ - Printing 3 examples
06/03/2022 18:33:24 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 18:33:24 - INFO - __main__ - ['false']
06/03/2022 18:33:24 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 18:33:24 - INFO - __main__ - ['false']
06/03/2022 18:33:24 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 18:33:24 - INFO - __main__ - ['false']
06/03/2022 18:33:24 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:33:25 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:33:28 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 18:33:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 18:33:28 - INFO - __main__ - Starting training!
06/03/2022 18:33:56 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_13_0.0002_8_predictions.txt
06/03/2022 18:33:56 - INFO - __main__ - Classification-F1 on test data: 0.6121
06/03/2022 18:33:57 - INFO - __main__ - prefix=wiki_qa_128_13, lr=0.0002, bsz=8, dev_performance=0.7282754164936084, test_performance=0.6121161564595191
06/03/2022 18:33:57 - INFO - __main__ - Running ... prefix=wiki_qa_128_13, lr=0.0001, bsz=8 ...
06/03/2022 18:33:58 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:33:58 - INFO - __main__ - Printing 3 examples
06/03/2022 18:33:58 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
06/03/2022 18:33:58 - INFO - __main__ - ['false']
06/03/2022 18:33:58 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
06/03/2022 18:33:58 - INFO - __main__ - ['false']
06/03/2022 18:33:58 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
06/03/2022 18:33:58 - INFO - __main__ - ['false']
06/03/2022 18:33:58 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:33:58 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:33:58 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 18:33:58 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:33:58 - INFO - __main__ - Printing 3 examples
06/03/2022 18:33:58 - INFO - __main__ -  [wiki_qa] question: what is a registered agent for an llc [SEP] answer: The registered agent's address may also be where the state will send the paperwork for the yearly renewal of the business entity's charter.
06/03/2022 18:33:58 - INFO - __main__ - ['false']
06/03/2022 18:33:58 - INFO - __main__ -  [wiki_qa] question: what does low self esteem mean [SEP] answer: Self-esteem encompasses beliefs (for example, "I am competent," "I am worthy") and emotions such as triumph, despair , pride and shame .
06/03/2022 18:33:58 - INFO - __main__ - ['false']
06/03/2022 18:33:58 - INFO - __main__ -  [wiki_qa] question: how many british soldiers were missing [SEP] answer: Becoming MIA has been an occupational risk for service personnel for as long as there has been warfare.
06/03/2022 18:33:58 - INFO - __main__ - ['false']
06/03/2022 18:33:58 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:33:58 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:33:58 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 18:34:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 18:34:10 - INFO - __main__ - Starting training!
06/03/2022 18:34:14 - INFO - __main__ - Step 10 Global step 10 Train loss 24.905499 on epoch=0
06/03/2022 18:34:19 - INFO - __main__ - Step 20 Global step 20 Train loss 20.285843 on epoch=1
06/03/2022 18:34:25 - INFO - __main__ - Step 30 Global step 30 Train loss 19.328243 on epoch=1
06/03/2022 18:34:30 - INFO - __main__ - Step 40 Global step 40 Train loss 17.768864 on epoch=2
06/03/2022 18:34:35 - INFO - __main__ - Step 50 Global step 50 Train loss 17.242558 on epoch=3
06/03/2022 18:35:52 - INFO - __main__ - Global step 50 Train loss 19.906200 Classification-F1 0.0 on epoch=3
06/03/2022 18:35:58 - INFO - __main__ - Step 60 Global step 60 Train loss 16.481287 on epoch=3
06/03/2022 18:36:03 - INFO - __main__ - Step 70 Global step 70 Train loss 16.184303 on epoch=4
06/03/2022 18:36:08 - INFO - __main__ - Step 80 Global step 80 Train loss 15.839766 on epoch=4
06/03/2022 18:36:13 - INFO - __main__ - Step 90 Global step 90 Train loss 16.153706 on epoch=5
06/03/2022 18:36:18 - INFO - __main__ - Step 100 Global step 100 Train loss 15.735510 on epoch=6
06/03/2022 18:37:15 - INFO - __main__ - Global step 100 Train loss 16.078913 Classification-F1 0.0 on epoch=6
06/03/2022 18:37:20 - INFO - __main__ - Step 110 Global step 110 Train loss 15.881482 on epoch=6
06/03/2022 18:37:26 - INFO - __main__ - Step 120 Global step 120 Train loss 14.663847 on epoch=7
06/03/2022 18:37:31 - INFO - __main__ - Step 130 Global step 130 Train loss 14.258021 on epoch=8
06/03/2022 18:37:36 - INFO - __main__ - Step 140 Global step 140 Train loss 13.574022 on epoch=8
06/03/2022 18:37:41 - INFO - __main__ - Step 150 Global step 150 Train loss 12.763400 on epoch=9
06/03/2022 18:38:36 - INFO - __main__ - Global step 150 Train loss 14.228154 Classification-F1 0.0 on epoch=9
06/03/2022 18:38:41 - INFO - __main__ - Step 160 Global step 160 Train loss 12.415469 on epoch=9
06/03/2022 18:38:46 - INFO - __main__ - Step 170 Global step 170 Train loss 12.687854 on epoch=10
06/03/2022 18:38:51 - INFO - __main__ - Step 180 Global step 180 Train loss 11.822390 on epoch=11
06/03/2022 18:38:57 - INFO - __main__ - Step 190 Global step 190 Train loss 9.554798 on epoch=11
06/03/2022 18:39:02 - INFO - __main__ - Step 200 Global step 200 Train loss 5.522825 on epoch=12
06/03/2022 18:39:05 - INFO - __main__ - Global step 200 Train loss 10.400666 Classification-F1 0.22106179286335945 on epoch=12
06/03/2022 18:39:11 - INFO - __main__ - Step 210 Global step 210 Train loss 1.892646 on epoch=13
06/03/2022 18:39:16 - INFO - __main__ - Step 220 Global step 220 Train loss 1.830114 on epoch=13
06/03/2022 18:39:21 - INFO - __main__ - Step 230 Global step 230 Train loss 0.843884 on epoch=14
06/03/2022 18:39:26 - INFO - __main__ - Step 240 Global step 240 Train loss 0.761241 on epoch=14
06/03/2022 18:39:31 - INFO - __main__ - Step 250 Global step 250 Train loss 0.792470 on epoch=15
06/03/2022 18:39:34 - INFO - __main__ - Global step 250 Train loss 1.224071 Classification-F1 0.635467226041555 on epoch=15
06/03/2022 18:39:40 - INFO - __main__ - Step 260 Global step 260 Train loss 0.767156 on epoch=16
06/03/2022 18:39:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.418909 on epoch=16
06/03/2022 18:39:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.630167 on epoch=17
06/03/2022 18:39:55 - INFO - __main__ - Step 290 Global step 290 Train loss 0.654943 on epoch=18
06/03/2022 18:40:00 - INFO - __main__ - Step 300 Global step 300 Train loss 0.413044 on epoch=18
06/03/2022 18:40:03 - INFO - __main__ - Global step 300 Train loss 0.576844 Classification-F1 0.3486005089058525 on epoch=18
06/03/2022 18:40:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.408088 on epoch=19
06/03/2022 18:40:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.390678 on epoch=19
06/03/2022 18:40:18 - INFO - __main__ - Step 330 Global step 330 Train loss 0.383181 on epoch=20
06/03/2022 18:40:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.433690 on epoch=21
06/03/2022 18:40:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.414578 on epoch=21
06/03/2022 18:40:31 - INFO - __main__ - Global step 350 Train loss 0.406043 Classification-F1 0.3849492366116407 on epoch=21
06/03/2022 18:40:36 - INFO - __main__ - Step 360 Global step 360 Train loss 0.314706 on epoch=22
06/03/2022 18:40:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.616956 on epoch=23
06/03/2022 18:40:46 - INFO - __main__ - Step 380 Global step 380 Train loss 1.074618 on epoch=23
06/03/2022 18:40:52 - INFO - __main__ - Step 390 Global step 390 Train loss 1.261300 on epoch=24
06/03/2022 18:40:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.526198 on epoch=24
06/03/2022 18:41:00 - INFO - __main__ - Global step 400 Train loss 0.758756 Classification-F1 0.3591989987484355 on epoch=24
06/03/2022 18:41:05 - INFO - __main__ - Step 410 Global step 410 Train loss 1.207050 on epoch=25
06/03/2022 18:41:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.557722 on epoch=26
06/03/2022 18:41:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.572148 on epoch=26
06/03/2022 18:41:20 - INFO - __main__ - Step 440 Global step 440 Train loss 0.537672 on epoch=27
06/03/2022 18:41:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.482540 on epoch=28
06/03/2022 18:41:28 - INFO - __main__ - Global step 450 Train loss 0.671426 Classification-F1 0.3333333333333333 on epoch=28
06/03/2022 18:41:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.711692 on epoch=28
06/03/2022 18:41:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.416538 on epoch=29
06/03/2022 18:41:44 - INFO - __main__ - Step 480 Global step 480 Train loss 0.457361 on epoch=29
06/03/2022 18:41:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.423800 on epoch=30
06/03/2022 18:41:54 - INFO - __main__ - Step 500 Global step 500 Train loss 0.427165 on epoch=31
06/03/2022 18:41:57 - INFO - __main__ - Global step 500 Train loss 0.487311 Classification-F1 0.33726520681265204 on epoch=31
06/03/2022 18:42:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.417425 on epoch=31
06/03/2022 18:42:07 - INFO - __main__ - Step 520 Global step 520 Train loss 0.394338 on epoch=32
06/03/2022 18:42:13 - INFO - __main__ - Step 530 Global step 530 Train loss 0.437203 on epoch=33
06/03/2022 18:42:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.458630 on epoch=33
06/03/2022 18:42:23 - INFO - __main__ - Step 550 Global step 550 Train loss 0.530705 on epoch=34
06/03/2022 18:42:26 - INFO - __main__ - Global step 550 Train loss 0.447660 Classification-F1 0.3644512668902913 on epoch=34
06/03/2022 18:42:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.384780 on epoch=34
06/03/2022 18:42:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.389399 on epoch=35
06/03/2022 18:42:42 - INFO - __main__ - Step 580 Global step 580 Train loss 0.348959 on epoch=36
06/03/2022 18:42:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.363931 on epoch=36
06/03/2022 18:42:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.361103 on epoch=37
06/03/2022 18:42:55 - INFO - __main__ - Global step 600 Train loss 0.369635 Classification-F1 0.35055905289861883 on epoch=37
06/03/2022 18:43:00 - INFO - __main__ - Step 610 Global step 610 Train loss 0.406499 on epoch=38
06/03/2022 18:43:05 - INFO - __main__ - Step 620 Global step 620 Train loss 0.359263 on epoch=38
06/03/2022 18:43:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.333710 on epoch=39
06/03/2022 18:43:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.391176 on epoch=39
06/03/2022 18:43:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.363235 on epoch=40
06/03/2022 18:43:24 - INFO - __main__ - Global step 650 Train loss 0.370777 Classification-F1 0.40274392367156486 on epoch=40
06/03/2022 18:43:29 - INFO - __main__ - Step 660 Global step 660 Train loss 0.387562 on epoch=41
06/03/2022 18:43:34 - INFO - __main__ - Step 670 Global step 670 Train loss 0.319969 on epoch=41
06/03/2022 18:43:39 - INFO - __main__ - Step 680 Global step 680 Train loss 0.391420 on epoch=42
06/03/2022 18:43:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.365277 on epoch=43
06/03/2022 18:43:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.403015 on epoch=43
06/03/2022 18:43:52 - INFO - __main__ - Global step 700 Train loss 0.373449 Classification-F1 0.3692115143929912 on epoch=43
06/03/2022 18:43:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.368962 on epoch=44
06/03/2022 18:44:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.350194 on epoch=44
06/03/2022 18:44:08 - INFO - __main__ - Step 730 Global step 730 Train loss 0.371334 on epoch=45
06/03/2022 18:44:13 - INFO - __main__ - Step 740 Global step 740 Train loss 0.591706 on epoch=46
06/03/2022 18:44:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.326424 on epoch=46
06/03/2022 18:44:21 - INFO - __main__ - Global step 750 Train loss 0.401724 Classification-F1 0.48624913705909734 on epoch=46
06/03/2022 18:44:26 - INFO - __main__ - Step 760 Global step 760 Train loss 0.496294 on epoch=47
06/03/2022 18:44:31 - INFO - __main__ - Step 770 Global step 770 Train loss 0.389338 on epoch=48
06/03/2022 18:44:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.343987 on epoch=48
06/03/2022 18:44:42 - INFO - __main__ - Step 790 Global step 790 Train loss 0.354231 on epoch=49
06/03/2022 18:44:47 - INFO - __main__ - Step 800 Global step 800 Train loss 0.406079 on epoch=49
06/03/2022 18:44:50 - INFO - __main__ - Global step 800 Train loss 0.397986 Classification-F1 0.34673046251993617 on epoch=49
06/03/2022 18:44:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.369560 on epoch=50
06/03/2022 18:45:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.346336 on epoch=51
06/03/2022 18:45:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.351140 on epoch=51
06/03/2022 18:45:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.421821 on epoch=52
06/03/2022 18:45:16 - INFO - __main__ - Step 850 Global step 850 Train loss 0.393376 on epoch=53
06/03/2022 18:45:19 - INFO - __main__ - Global step 850 Train loss 0.376447 Classification-F1 0.38279939051439815 on epoch=53
06/03/2022 18:45:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.345580 on epoch=53
06/03/2022 18:45:29 - INFO - __main__ - Step 870 Global step 870 Train loss 0.357661 on epoch=54
06/03/2022 18:45:34 - INFO - __main__ - Step 880 Global step 880 Train loss 0.361552 on epoch=54
06/03/2022 18:45:39 - INFO - __main__ - Step 890 Global step 890 Train loss 0.345398 on epoch=55
06/03/2022 18:45:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.332380 on epoch=56
06/03/2022 18:45:47 - INFO - __main__ - Global step 900 Train loss 0.348514 Classification-F1 0.5241115363586659 on epoch=56
06/03/2022 18:45:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.340307 on epoch=56
06/03/2022 18:45:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.314412 on epoch=57
06/03/2022 18:46:02 - INFO - __main__ - Step 930 Global step 930 Train loss 0.322031 on epoch=58
06/03/2022 18:46:08 - INFO - __main__ - Step 940 Global step 940 Train loss 0.364546 on epoch=58
06/03/2022 18:46:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.310904 on epoch=59
06/03/2022 18:46:16 - INFO - __main__ - Global step 950 Train loss 0.330440 Classification-F1 0.3771988921326446 on epoch=59
06/03/2022 18:46:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.340972 on epoch=59
06/03/2022 18:46:26 - INFO - __main__ - Step 970 Global step 970 Train loss 0.294282 on epoch=60
06/03/2022 18:46:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.342766 on epoch=61
06/03/2022 18:46:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.361519 on epoch=61
06/03/2022 18:46:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.378322 on epoch=62
06/03/2022 18:46:42 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:46:42 - INFO - __main__ - Printing 3 examples
06/03/2022 18:46:42 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/03/2022 18:46:42 - INFO - __main__ - ['false']
06/03/2022 18:46:42 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/03/2022 18:46:42 - INFO - __main__ - ['false']
06/03/2022 18:46:42 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/03/2022 18:46:42 - INFO - __main__ - ['false']
06/03/2022 18:46:42 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:46:43 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:46:43 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 18:46:43 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:46:43 - INFO - __main__ - Printing 3 examples
06/03/2022 18:46:43 - INFO - __main__ -  [wiki_qa] question: who started world war i [SEP] answer: These alliances were both reorganised and expanded as more nations entered the war: Italy, Japan and the United States joined the Allies, and the Ottoman Empire and Bulgaria the Central Powers.
06/03/2022 18:46:43 - INFO - __main__ - ['false']
06/03/2022 18:46:43 - INFO - __main__ -  [wiki_qa] question: when did wwi begin [SEP] answer: One of the long-term causes of the war was the resurgence of imperialism in the foreign policies of the great powers of Europe.
06/03/2022 18:46:43 - INFO - __main__ - ['false']
06/03/2022 18:46:43 - INFO - __main__ -  [wiki_qa] question: how old were the twin towers when destroyed [SEP] answer: The new World Trade Center complex will include One World Trade Center , three other high-rise office towers, and the National September 11 Memorial & Museum .
06/03/2022 18:46:43 - INFO - __main__ - ['false']
06/03/2022 18:46:43 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:46:43 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:46:43 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 18:46:44 - INFO - __main__ - Global step 1000 Train loss 0.343572 Classification-F1 0.5053671103477888 on epoch=62
06/03/2022 18:46:44 - INFO - __main__ - save last model!
06/03/2022 18:46:51 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 18:46:52 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 18:46:52 - INFO - __main__ - Printing 3 examples
06/03/2022 18:46:52 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 18:46:52 - INFO - __main__ - ['false']
06/03/2022 18:46:52 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 18:46:52 - INFO - __main__ - ['false']
06/03/2022 18:46:52 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 18:46:52 - INFO - __main__ - ['false']
06/03/2022 18:46:52 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:46:53 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:46:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 18:46:56 - INFO - __main__ - Starting training!
06/03/2022 18:46:56 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 18:47:24 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_13_0.0001_8_predictions.txt
06/03/2022 18:47:24 - INFO - __main__ - Classification-F1 on test data: 0.4758
06/03/2022 18:47:24 - INFO - __main__ - prefix=wiki_qa_128_13, lr=0.0001, bsz=8, dev_performance=0.635467226041555, test_performance=0.47582883546614996
06/03/2022 18:47:24 - INFO - __main__ - Running ... prefix=wiki_qa_128_21, lr=0.0005, bsz=8 ...
06/03/2022 18:47:25 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:47:25 - INFO - __main__ - Printing 3 examples
06/03/2022 18:47:25 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/03/2022 18:47:25 - INFO - __main__ - ['false']
06/03/2022 18:47:25 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/03/2022 18:47:25 - INFO - __main__ - ['false']
06/03/2022 18:47:25 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/03/2022 18:47:25 - INFO - __main__ - ['false']
06/03/2022 18:47:25 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:47:25 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:47:26 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 18:47:26 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:47:26 - INFO - __main__ - Printing 3 examples
06/03/2022 18:47:26 - INFO - __main__ -  [wiki_qa] question: who started world war i [SEP] answer: These alliances were both reorganised and expanded as more nations entered the war: Italy, Japan and the United States joined the Allies, and the Ottoman Empire and Bulgaria the Central Powers.
06/03/2022 18:47:26 - INFO - __main__ - ['false']
06/03/2022 18:47:26 - INFO - __main__ -  [wiki_qa] question: when did wwi begin [SEP] answer: One of the long-term causes of the war was the resurgence of imperialism in the foreign policies of the great powers of Europe.
06/03/2022 18:47:26 - INFO - __main__ - ['false']
06/03/2022 18:47:26 - INFO - __main__ -  [wiki_qa] question: how old were the twin towers when destroyed [SEP] answer: The new World Trade Center complex will include One World Trade Center , three other high-rise office towers, and the National September 11 Memorial & Museum .
06/03/2022 18:47:26 - INFO - __main__ - ['false']
06/03/2022 18:47:26 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:47:26 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:47:26 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 18:47:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 18:47:39 - INFO - __main__ - Starting training!
06/03/2022 18:47:43 - INFO - __main__ - Step 10 Global step 10 Train loss 21.888309 on epoch=0
06/03/2022 18:47:48 - INFO - __main__ - Step 20 Global step 20 Train loss 18.416035 on epoch=1
06/03/2022 18:47:53 - INFO - __main__ - Step 30 Global step 30 Train loss 16.585964 on epoch=1
06/03/2022 18:47:58 - INFO - __main__ - Step 40 Global step 40 Train loss 14.897824 on epoch=2
06/03/2022 18:48:03 - INFO - __main__ - Step 50 Global step 50 Train loss 13.276337 on epoch=3
06/03/2022 18:48:22 - INFO - __main__ - Global step 50 Train loss 17.012894 Classification-F1 0.0015384615384615385 on epoch=3
06/03/2022 18:48:28 - INFO - __main__ - Step 60 Global step 60 Train loss 6.219120 on epoch=3
06/03/2022 18:48:33 - INFO - __main__ - Step 70 Global step 70 Train loss 1.182259 on epoch=4
06/03/2022 18:48:38 - INFO - __main__ - Step 80 Global step 80 Train loss 0.575288 on epoch=4
06/03/2022 18:48:43 - INFO - __main__ - Step 90 Global step 90 Train loss 0.495721 on epoch=5
06/03/2022 18:48:48 - INFO - __main__ - Step 100 Global step 100 Train loss 0.515253 on epoch=6
06/03/2022 18:48:51 - INFO - __main__ - Global step 100 Train loss 1.797528 Classification-F1 0.3333333333333333 on epoch=6
06/03/2022 18:48:57 - INFO - __main__ - Step 110 Global step 110 Train loss 0.976338 on epoch=6
06/03/2022 18:49:02 - INFO - __main__ - Step 120 Global step 120 Train loss 0.605452 on epoch=7
06/03/2022 18:49:07 - INFO - __main__ - Step 130 Global step 130 Train loss 0.554852 on epoch=8
06/03/2022 18:49:13 - INFO - __main__ - Step 140 Global step 140 Train loss 0.429915 on epoch=8
06/03/2022 18:49:18 - INFO - __main__ - Step 150 Global step 150 Train loss 0.440315 on epoch=9
06/03/2022 18:49:21 - INFO - __main__ - Global step 150 Train loss 0.601374 Classification-F1 0.3732922688146569 on epoch=9
06/03/2022 18:49:27 - INFO - __main__ - Step 160 Global step 160 Train loss 0.484664 on epoch=9
06/03/2022 18:49:32 - INFO - __main__ - Step 170 Global step 170 Train loss 0.454092 on epoch=10
06/03/2022 18:49:38 - INFO - __main__ - Step 180 Global step 180 Train loss 0.463628 on epoch=11
06/03/2022 18:49:43 - INFO - __main__ - Step 190 Global step 190 Train loss 0.418021 on epoch=11
06/03/2022 18:49:48 - INFO - __main__ - Step 200 Global step 200 Train loss 0.449707 on epoch=12
06/03/2022 18:49:51 - INFO - __main__ - Global step 200 Train loss 0.454022 Classification-F1 0.22915384930888807 on epoch=12
06/03/2022 18:49:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.466063 on epoch=13
06/03/2022 18:50:02 - INFO - __main__ - Step 220 Global step 220 Train loss 0.378274 on epoch=13
06/03/2022 18:50:07 - INFO - __main__ - Step 230 Global step 230 Train loss 0.406945 on epoch=14
06/03/2022 18:50:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.427004 on epoch=14
06/03/2022 18:50:18 - INFO - __main__ - Step 250 Global step 250 Train loss 0.433207 on epoch=15
06/03/2022 18:50:21 - INFO - __main__ - Global step 250 Train loss 0.422298 Classification-F1 0.3333333333333333 on epoch=15
06/03/2022 18:50:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.404364 on epoch=16
06/03/2022 18:50:32 - INFO - __main__ - Step 270 Global step 270 Train loss 0.352862 on epoch=16
06/03/2022 18:50:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.596776 on epoch=17
06/03/2022 18:50:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.801536 on epoch=18
06/03/2022 18:50:48 - INFO - __main__ - Step 300 Global step 300 Train loss 0.354493 on epoch=18
06/03/2022 18:50:51 - INFO - __main__ - Global step 300 Train loss 0.502006 Classification-F1 0.3333333333333333 on epoch=18
06/03/2022 18:50:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.419902 on epoch=19
06/03/2022 18:51:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.426554 on epoch=19
06/03/2022 18:51:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.383753 on epoch=20
06/03/2022 18:51:13 - INFO - __main__ - Step 340 Global step 340 Train loss 0.416389 on epoch=21
06/03/2022 18:51:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.377413 on epoch=21
06/03/2022 18:51:21 - INFO - __main__ - Global step 350 Train loss 0.404802 Classification-F1 0.43373856417334683 on epoch=21
06/03/2022 18:51:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.416740 on epoch=22
06/03/2022 18:51:33 - INFO - __main__ - Step 370 Global step 370 Train loss 0.382201 on epoch=23
06/03/2022 18:51:38 - INFO - __main__ - Step 380 Global step 380 Train loss 0.387902 on epoch=23
06/03/2022 18:51:44 - INFO - __main__ - Step 390 Global step 390 Train loss 0.358656 on epoch=24
06/03/2022 18:51:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.405825 on epoch=24
06/03/2022 18:51:52 - INFO - __main__ - Global step 400 Train loss 0.390265 Classification-F1 0.3333333333333333 on epoch=24
06/03/2022 18:51:57 - INFO - __main__ - Step 410 Global step 410 Train loss 0.375187 on epoch=25
06/03/2022 18:52:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.366532 on epoch=26
06/03/2022 18:52:08 - INFO - __main__ - Step 430 Global step 430 Train loss 0.389265 on epoch=26
06/03/2022 18:52:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.385752 on epoch=27
06/03/2022 18:52:19 - INFO - __main__ - Step 450 Global step 450 Train loss 0.354218 on epoch=28
06/03/2022 18:52:22 - INFO - __main__ - Global step 450 Train loss 0.374191 Classification-F1 0.3333333333333333 on epoch=28
06/03/2022 18:52:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.360140 on epoch=28
06/03/2022 18:52:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.387896 on epoch=29
06/03/2022 18:52:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.383004 on epoch=29
06/03/2022 18:52:43 - INFO - __main__ - Step 490 Global step 490 Train loss 0.364049 on epoch=30
06/03/2022 18:52:49 - INFO - __main__ - Step 500 Global step 500 Train loss 0.411087 on epoch=31
06/03/2022 18:52:51 - INFO - __main__ - Global step 500 Train loss 0.381235 Classification-F1 0.3333333333333333 on epoch=31
06/03/2022 18:52:57 - INFO - __main__ - Step 510 Global step 510 Train loss 0.400714 on epoch=31
06/03/2022 18:53:02 - INFO - __main__ - Step 520 Global step 520 Train loss 0.390088 on epoch=32
06/03/2022 18:53:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.421233 on epoch=33
06/03/2022 18:53:13 - INFO - __main__ - Step 540 Global step 540 Train loss 0.357976 on epoch=33
06/03/2022 18:53:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.377295 on epoch=34
06/03/2022 18:53:21 - INFO - __main__ - Global step 550 Train loss 0.389461 Classification-F1 0.46880856760374834 on epoch=34
06/03/2022 18:53:27 - INFO - __main__ - Step 560 Global step 560 Train loss 0.380224 on epoch=34
06/03/2022 18:53:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.359842 on epoch=35
06/03/2022 18:53:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.370313 on epoch=36
06/03/2022 18:53:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.381750 on epoch=36
06/03/2022 18:53:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.369048 on epoch=37
06/03/2022 18:53:52 - INFO - __main__ - Global step 600 Train loss 0.372236 Classification-F1 0.4899128268991283 on epoch=37
06/03/2022 18:53:58 - INFO - __main__ - Step 610 Global step 610 Train loss 0.399022 on epoch=38
06/03/2022 18:54:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.349815 on epoch=38
06/03/2022 18:54:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.372475 on epoch=39
06/03/2022 18:54:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.387055 on epoch=39
06/03/2022 18:54:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.365228 on epoch=40
06/03/2022 18:54:22 - INFO - __main__ - Global step 650 Train loss 0.374719 Classification-F1 0.3333333333333333 on epoch=40
06/03/2022 18:54:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.377829 on epoch=41
06/03/2022 18:54:34 - INFO - __main__ - Step 670 Global step 670 Train loss 0.378996 on epoch=41
06/03/2022 18:54:39 - INFO - __main__ - Step 680 Global step 680 Train loss 0.335413 on epoch=42
06/03/2022 18:54:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.392137 on epoch=43
06/03/2022 18:54:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.377291 on epoch=43
06/03/2022 18:54:53 - INFO - __main__ - Global step 700 Train loss 0.372333 Classification-F1 0.3333333333333333 on epoch=43
06/03/2022 18:54:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.331601 on epoch=44
06/03/2022 18:55:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.384065 on epoch=44
06/03/2022 18:55:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.374390 on epoch=45
06/03/2022 18:55:15 - INFO - __main__ - Step 740 Global step 740 Train loss 0.365939 on epoch=46
06/03/2022 18:55:20 - INFO - __main__ - Step 750 Global step 750 Train loss 0.356352 on epoch=46
06/03/2022 18:55:23 - INFO - __main__ - Global step 750 Train loss 0.362469 Classification-F1 0.36119461636703015 on epoch=46
06/03/2022 18:55:28 - INFO - __main__ - Step 760 Global step 760 Train loss 0.393416 on epoch=47
06/03/2022 18:55:34 - INFO - __main__ - Step 770 Global step 770 Train loss 0.349196 on epoch=48
06/03/2022 18:55:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.333614 on epoch=48
06/03/2022 18:55:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.353725 on epoch=49
06/03/2022 18:55:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.369119 on epoch=49
06/03/2022 18:55:52 - INFO - __main__ - Global step 800 Train loss 0.359814 Classification-F1 0.3333333333333333 on epoch=49
06/03/2022 18:55:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.339721 on epoch=50
06/03/2022 18:56:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.342293 on epoch=51
06/03/2022 18:56:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.326264 on epoch=51
06/03/2022 18:56:14 - INFO - __main__ - Step 840 Global step 840 Train loss 0.353829 on epoch=52
06/03/2022 18:56:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.405100 on epoch=53
06/03/2022 18:56:23 - INFO - __main__ - Global step 850 Train loss 0.353441 Classification-F1 0.3333333333333333 on epoch=53
06/03/2022 18:56:28 - INFO - __main__ - Step 860 Global step 860 Train loss 0.338492 on epoch=53
06/03/2022 18:56:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.351582 on epoch=54
06/03/2022 18:56:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.332050 on epoch=54
06/03/2022 18:56:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.319699 on epoch=55
06/03/2022 18:56:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.294395 on epoch=56
06/03/2022 18:56:53 - INFO - __main__ - Global step 900 Train loss 0.327243 Classification-F1 0.548791515318712 on epoch=56
06/03/2022 18:56:59 - INFO - __main__ - Step 910 Global step 910 Train loss 0.265559 on epoch=56
06/03/2022 18:57:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.264206 on epoch=57
06/03/2022 18:57:10 - INFO - __main__ - Step 930 Global step 930 Train loss 0.344060 on epoch=58
06/03/2022 18:57:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.252801 on epoch=58
06/03/2022 18:57:21 - INFO - __main__ - Step 950 Global step 950 Train loss 0.301072 on epoch=59
06/03/2022 18:57:24 - INFO - __main__ - Global step 950 Train loss 0.285540 Classification-F1 0.35307589038932324 on epoch=59
06/03/2022 18:57:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.288245 on epoch=59
06/03/2022 18:57:35 - INFO - __main__ - Step 970 Global step 970 Train loss 0.258111 on epoch=60
06/03/2022 18:57:40 - INFO - __main__ - Step 980 Global step 980 Train loss 0.307255 on epoch=61
06/03/2022 18:57:45 - INFO - __main__ - Step 990 Global step 990 Train loss 0.188207 on epoch=61
06/03/2022 18:57:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.190535 on epoch=62
06/03/2022 18:57:52 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:57:52 - INFO - __main__ - Printing 3 examples
06/03/2022 18:57:52 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/03/2022 18:57:52 - INFO - __main__ - ['false']
06/03/2022 18:57:52 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/03/2022 18:57:52 - INFO - __main__ - ['false']
06/03/2022 18:57:52 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/03/2022 18:57:52 - INFO - __main__ - ['false']
06/03/2022 18:57:52 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:57:52 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:57:52 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 18:57:52 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:57:52 - INFO - __main__ - Printing 3 examples
06/03/2022 18:57:52 - INFO - __main__ -  [wiki_qa] question: who started world war i [SEP] answer: These alliances were both reorganised and expanded as more nations entered the war: Italy, Japan and the United States joined the Allies, and the Ottoman Empire and Bulgaria the Central Powers.
06/03/2022 18:57:52 - INFO - __main__ - ['false']
06/03/2022 18:57:52 - INFO - __main__ -  [wiki_qa] question: when did wwi begin [SEP] answer: One of the long-term causes of the war was the resurgence of imperialism in the foreign policies of the great powers of Europe.
06/03/2022 18:57:52 - INFO - __main__ - ['false']
06/03/2022 18:57:52 - INFO - __main__ -  [wiki_qa] question: how old were the twin towers when destroyed [SEP] answer: The new World Trade Center complex will include One World Trade Center , three other high-rise office towers, and the National September 11 Memorial & Museum .
06/03/2022 18:57:52 - INFO - __main__ - ['false']
06/03/2022 18:57:52 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:57:53 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:57:53 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 18:57:54 - INFO - __main__ - Global step 1000 Train loss 0.246471 Classification-F1 0.5234084111579076 on epoch=62
06/03/2022 18:57:54 - INFO - __main__ - save last model!
06/03/2022 18:58:00 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 18:58:01 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 18:58:01 - INFO - __main__ - Printing 3 examples
06/03/2022 18:58:01 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 18:58:01 - INFO - __main__ - ['false']
06/03/2022 18:58:01 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 18:58:01 - INFO - __main__ - ['false']
06/03/2022 18:58:01 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 18:58:01 - INFO - __main__ - ['false']
06/03/2022 18:58:01 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:58:02 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:58:05 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 18:58:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 18:58:06 - INFO - __main__ - Starting training!
06/03/2022 18:58:34 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_21_0.0005_8_predictions.txt
06/03/2022 18:58:34 - INFO - __main__ - Classification-F1 on test data: 0.3770
06/03/2022 18:58:34 - INFO - __main__ - prefix=wiki_qa_128_21, lr=0.0005, bsz=8, dev_performance=0.548791515318712, test_performance=0.37695090060524616
06/03/2022 18:58:34 - INFO - __main__ - Running ... prefix=wiki_qa_128_21, lr=0.0003, bsz=8 ...
06/03/2022 18:58:35 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:58:35 - INFO - __main__ - Printing 3 examples
06/03/2022 18:58:35 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/03/2022 18:58:35 - INFO - __main__ - ['false']
06/03/2022 18:58:35 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/03/2022 18:58:35 - INFO - __main__ - ['false']
06/03/2022 18:58:35 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/03/2022 18:58:35 - INFO - __main__ - ['false']
06/03/2022 18:58:35 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:58:35 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:58:36 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 18:58:36 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 18:58:36 - INFO - __main__ - Printing 3 examples
06/03/2022 18:58:36 - INFO - __main__ -  [wiki_qa] question: who started world war i [SEP] answer: These alliances were both reorganised and expanded as more nations entered the war: Italy, Japan and the United States joined the Allies, and the Ottoman Empire and Bulgaria the Central Powers.
06/03/2022 18:58:36 - INFO - __main__ - ['false']
06/03/2022 18:58:36 - INFO - __main__ -  [wiki_qa] question: when did wwi begin [SEP] answer: One of the long-term causes of the war was the resurgence of imperialism in the foreign policies of the great powers of Europe.
06/03/2022 18:58:36 - INFO - __main__ - ['false']
06/03/2022 18:58:36 - INFO - __main__ -  [wiki_qa] question: how old were the twin towers when destroyed [SEP] answer: The new World Trade Center complex will include One World Trade Center , three other high-rise office towers, and the National September 11 Memorial & Museum .
06/03/2022 18:58:36 - INFO - __main__ - ['false']
06/03/2022 18:58:36 - INFO - __main__ - Tokenizing Input ...
06/03/2022 18:58:36 - INFO - __main__ - Tokenizing Output ...
06/03/2022 18:58:36 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 18:58:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 18:58:47 - INFO - __main__ - Starting training!
06/03/2022 18:58:51 - INFO - __main__ - Step 10 Global step 10 Train loss 23.164991 on epoch=0
06/03/2022 18:58:57 - INFO - __main__ - Step 20 Global step 20 Train loss 18.204649 on epoch=1
06/03/2022 18:59:02 - INFO - __main__ - Step 30 Global step 30 Train loss 16.573509 on epoch=1
06/03/2022 18:59:07 - INFO - __main__ - Step 40 Global step 40 Train loss 15.951961 on epoch=2
06/03/2022 18:59:13 - INFO - __main__ - Step 50 Global step 50 Train loss 14.338025 on epoch=3
06/03/2022 18:59:35 - INFO - __main__ - Global step 50 Train loss 17.646627 Classification-F1 0.0001550387596899225 on epoch=3
06/03/2022 18:59:42 - INFO - __main__ - Step 60 Global step 60 Train loss 13.471896 on epoch=3
06/03/2022 18:59:47 - INFO - __main__ - Step 70 Global step 70 Train loss 6.225234 on epoch=4
06/03/2022 18:59:52 - INFO - __main__ - Step 80 Global step 80 Train loss 5.633791 on epoch=4
06/03/2022 18:59:58 - INFO - __main__ - Step 90 Global step 90 Train loss 0.889244 on epoch=5
06/03/2022 19:00:03 - INFO - __main__ - Step 100 Global step 100 Train loss 0.638404 on epoch=6
06/03/2022 19:00:06 - INFO - __main__ - Global step 100 Train loss 5.371714 Classification-F1 0.23538650960034604 on epoch=6
06/03/2022 19:00:12 - INFO - __main__ - Step 110 Global step 110 Train loss 0.487641 on epoch=6
06/03/2022 19:00:18 - INFO - __main__ - Step 120 Global step 120 Train loss 0.649163 on epoch=7
06/03/2022 19:00:23 - INFO - __main__ - Step 130 Global step 130 Train loss 0.667713 on epoch=8
06/03/2022 19:00:28 - INFO - __main__ - Step 140 Global step 140 Train loss 0.434587 on epoch=8
06/03/2022 19:00:34 - INFO - __main__ - Step 150 Global step 150 Train loss 0.392138 on epoch=9
06/03/2022 19:00:36 - INFO - __main__ - Global step 150 Train loss 0.526248 Classification-F1 0.22398589065255733 on epoch=9
06/03/2022 19:00:42 - INFO - __main__ - Step 160 Global step 160 Train loss 0.641090 on epoch=9
06/03/2022 19:00:47 - INFO - __main__ - Step 170 Global step 170 Train loss 0.400651 on epoch=10
06/03/2022 19:00:53 - INFO - __main__ - Step 180 Global step 180 Train loss 0.556270 on epoch=11
06/03/2022 19:00:58 - INFO - __main__ - Step 190 Global step 190 Train loss 0.293332 on epoch=11
06/03/2022 19:01:03 - INFO - __main__ - Step 200 Global step 200 Train loss 1.690269 on epoch=12
06/03/2022 19:01:06 - INFO - __main__ - Global step 200 Train loss 0.716323 Classification-F1 0.23947448957285883 on epoch=12
06/03/2022 19:01:12 - INFO - __main__ - Step 210 Global step 210 Train loss 2.064048 on epoch=13
06/03/2022 19:01:17 - INFO - __main__ - Step 220 Global step 220 Train loss 1.365757 on epoch=13
06/03/2022 19:01:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.828244 on epoch=14
06/03/2022 19:01:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.453226 on epoch=14
06/03/2022 19:01:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.385583 on epoch=15
06/03/2022 19:01:35 - INFO - __main__ - Global step 250 Train loss 1.019372 Classification-F1 0.33159268929503916 on epoch=15
06/03/2022 19:01:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.431720 on epoch=16
06/03/2022 19:01:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.396542 on epoch=16
06/03/2022 19:01:51 - INFO - __main__ - Step 280 Global step 280 Train loss 0.451828 on epoch=17
06/03/2022 19:01:56 - INFO - __main__ - Step 290 Global step 290 Train loss 0.402134 on epoch=18
06/03/2022 19:02:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.364792 on epoch=18
06/03/2022 19:02:04 - INFO - __main__ - Global step 300 Train loss 0.409403 Classification-F1 0.3712545436683367 on epoch=18
06/03/2022 19:02:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.410849 on epoch=19
06/03/2022 19:02:15 - INFO - __main__ - Step 320 Global step 320 Train loss 0.406519 on epoch=19
06/03/2022 19:02:21 - INFO - __main__ - Step 330 Global step 330 Train loss 0.382658 on epoch=20
06/03/2022 19:02:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.404256 on epoch=21
06/03/2022 19:02:31 - INFO - __main__ - Step 350 Global step 350 Train loss 0.384789 on epoch=21
06/03/2022 19:02:34 - INFO - __main__ - Global step 350 Train loss 0.397814 Classification-F1 0.3383422492035824 on epoch=21
06/03/2022 19:02:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.403248 on epoch=22
06/03/2022 19:02:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.357047 on epoch=23
06/03/2022 19:02:50 - INFO - __main__ - Step 380 Global step 380 Train loss 0.363231 on epoch=23
06/03/2022 19:02:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.421957 on epoch=24
06/03/2022 19:03:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.350532 on epoch=24
06/03/2022 19:03:03 - INFO - __main__ - Global step 400 Train loss 0.379203 Classification-F1 0.3333333333333333 on epoch=24
06/03/2022 19:03:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.371654 on epoch=25
06/03/2022 19:03:14 - INFO - __main__ - Step 420 Global step 420 Train loss 0.319372 on epoch=26
06/03/2022 19:03:19 - INFO - __main__ - Step 430 Global step 430 Train loss 0.358548 on epoch=26
06/03/2022 19:03:24 - INFO - __main__ - Step 440 Global step 440 Train loss 0.393145 on epoch=27
06/03/2022 19:03:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.365119 on epoch=28
06/03/2022 19:03:32 - INFO - __main__ - Global step 450 Train loss 0.361567 Classification-F1 0.4342541436464089 on epoch=28
06/03/2022 19:03:38 - INFO - __main__ - Step 460 Global step 460 Train loss 0.351888 on epoch=28
06/03/2022 19:03:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.393864 on epoch=29
06/03/2022 19:03:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.393004 on epoch=29
06/03/2022 19:03:54 - INFO - __main__ - Step 490 Global step 490 Train loss 0.384545 on epoch=30
06/03/2022 19:03:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.350036 on epoch=31
06/03/2022 19:04:02 - INFO - __main__ - Global step 500 Train loss 0.374668 Classification-F1 0.34195559333697656 on epoch=31
06/03/2022 19:04:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.331259 on epoch=31
06/03/2022 19:04:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.413874 on epoch=32
06/03/2022 19:04:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.361002 on epoch=33
06/03/2022 19:04:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.342479 on epoch=33
06/03/2022 19:04:28 - INFO - __main__ - Step 550 Global step 550 Train loss 0.361136 on epoch=34
06/03/2022 19:04:31 - INFO - __main__ - Global step 550 Train loss 0.361950 Classification-F1 0.5140859140859141 on epoch=34
06/03/2022 19:04:37 - INFO - __main__ - Step 560 Global step 560 Train loss 0.371402 on epoch=34
06/03/2022 19:04:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.354737 on epoch=35
06/03/2022 19:04:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.389927 on epoch=36
06/03/2022 19:04:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.352747 on epoch=36
06/03/2022 19:04:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.361176 on epoch=37
06/03/2022 19:05:01 - INFO - __main__ - Global step 600 Train loss 0.365998 Classification-F1 0.48902195608782434 on epoch=37
06/03/2022 19:05:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.384010 on epoch=38
06/03/2022 19:05:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.344595 on epoch=38
06/03/2022 19:05:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.333617 on epoch=39
06/03/2022 19:05:22 - INFO - __main__ - Step 640 Global step 640 Train loss 0.421496 on epoch=39
06/03/2022 19:05:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.372402 on epoch=40
06/03/2022 19:05:30 - INFO - __main__ - Global step 650 Train loss 0.371224 Classification-F1 0.4155251141552511 on epoch=40
06/03/2022 19:05:36 - INFO - __main__ - Step 660 Global step 660 Train loss 0.319700 on epoch=41
06/03/2022 19:05:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.333510 on epoch=41
06/03/2022 19:05:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.300635 on epoch=42
06/03/2022 19:05:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.376330 on epoch=43
06/03/2022 19:05:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.350507 on epoch=43
06/03/2022 19:05:59 - INFO - __main__ - Global step 700 Train loss 0.336136 Classification-F1 0.4420755396365153 on epoch=43
06/03/2022 19:06:05 - INFO - __main__ - Step 710 Global step 710 Train loss 0.302798 on epoch=44
06/03/2022 19:06:10 - INFO - __main__ - Step 720 Global step 720 Train loss 0.376844 on epoch=44
06/03/2022 19:06:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.316261 on epoch=45
06/03/2022 19:06:20 - INFO - __main__ - Step 740 Global step 740 Train loss 0.373775 on epoch=46
06/03/2022 19:06:25 - INFO - __main__ - Step 750 Global step 750 Train loss 0.330853 on epoch=46
06/03/2022 19:06:28 - INFO - __main__ - Global step 750 Train loss 0.340106 Classification-F1 0.42025542025542023 on epoch=46
06/03/2022 19:06:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.323177 on epoch=47
06/03/2022 19:06:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.322444 on epoch=48
06/03/2022 19:06:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.254003 on epoch=48
06/03/2022 19:06:49 - INFO - __main__ - Step 790 Global step 790 Train loss 0.278045 on epoch=49
06/03/2022 19:06:54 - INFO - __main__ - Step 800 Global step 800 Train loss 0.362629 on epoch=49
06/03/2022 19:06:57 - INFO - __main__ - Global step 800 Train loss 0.308060 Classification-F1 0.3333333333333333 on epoch=49
06/03/2022 19:07:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.321118 on epoch=50
06/03/2022 19:07:08 - INFO - __main__ - Step 820 Global step 820 Train loss 0.302350 on epoch=51
06/03/2022 19:07:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.326851 on epoch=51
06/03/2022 19:07:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.412817 on epoch=52
06/03/2022 19:07:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.327079 on epoch=53
06/03/2022 19:07:26 - INFO - __main__ - Global step 850 Train loss 0.338043 Classification-F1 0.46906958449545877 on epoch=53
06/03/2022 19:07:32 - INFO - __main__ - Step 860 Global step 860 Train loss 0.292568 on epoch=53
06/03/2022 19:07:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.288824 on epoch=54
06/03/2022 19:07:43 - INFO - __main__ - Step 880 Global step 880 Train loss 0.320410 on epoch=54
06/03/2022 19:07:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.273767 on epoch=55
06/03/2022 19:07:53 - INFO - __main__ - Step 900 Global step 900 Train loss 0.338948 on epoch=56
06/03/2022 19:07:56 - INFO - __main__ - Global step 900 Train loss 0.302903 Classification-F1 0.521821755161044 on epoch=56
06/03/2022 19:08:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.314305 on epoch=56
06/03/2022 19:08:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.319132 on epoch=57
06/03/2022 19:08:13 - INFO - __main__ - Step 930 Global step 930 Train loss 0.316170 on epoch=58
06/03/2022 19:08:18 - INFO - __main__ - Step 940 Global step 940 Train loss 0.286431 on epoch=58
06/03/2022 19:08:23 - INFO - __main__ - Step 950 Global step 950 Train loss 0.261296 on epoch=59
06/03/2022 19:08:26 - INFO - __main__ - Global step 950 Train loss 0.299467 Classification-F1 0.574212252994583 on epoch=59
06/03/2022 19:08:32 - INFO - __main__ - Step 960 Global step 960 Train loss 0.296765 on epoch=59
06/03/2022 19:08:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.260416 on epoch=60
06/03/2022 19:08:42 - INFO - __main__ - Step 980 Global step 980 Train loss 0.274233 on epoch=61
06/03/2022 19:08:47 - INFO - __main__ - Step 990 Global step 990 Train loss 0.242469 on epoch=61
06/03/2022 19:08:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.236965 on epoch=62
06/03/2022 19:08:54 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:08:54 - INFO - __main__ - Printing 3 examples
06/03/2022 19:08:54 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/03/2022 19:08:54 - INFO - __main__ - ['false']
06/03/2022 19:08:54 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/03/2022 19:08:54 - INFO - __main__ - ['false']
06/03/2022 19:08:54 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/03/2022 19:08:54 - INFO - __main__ - ['false']
06/03/2022 19:08:54 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:08:54 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:08:54 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 19:08:54 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:08:54 - INFO - __main__ - Printing 3 examples
06/03/2022 19:08:54 - INFO - __main__ -  [wiki_qa] question: who started world war i [SEP] answer: These alliances were both reorganised and expanded as more nations entered the war: Italy, Japan and the United States joined the Allies, and the Ottoman Empire and Bulgaria the Central Powers.
06/03/2022 19:08:54 - INFO - __main__ - ['false']
06/03/2022 19:08:54 - INFO - __main__ -  [wiki_qa] question: when did wwi begin [SEP] answer: One of the long-term causes of the war was the resurgence of imperialism in the foreign policies of the great powers of Europe.
06/03/2022 19:08:54 - INFO - __main__ - ['false']
06/03/2022 19:08:54 - INFO - __main__ -  [wiki_qa] question: how old were the twin towers when destroyed [SEP] answer: The new World Trade Center complex will include One World Trade Center , three other high-rise office towers, and the National September 11 Memorial & Museum .
06/03/2022 19:08:54 - INFO - __main__ - ['false']
06/03/2022 19:08:54 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:08:54 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:08:55 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 19:08:56 - INFO - __main__ - Global step 1000 Train loss 0.262170 Classification-F1 0.5062438705459301 on epoch=62
06/03/2022 19:08:56 - INFO - __main__ - save last model!
06/03/2022 19:09:03 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 19:09:03 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 19:09:03 - INFO - __main__ - Printing 3 examples
06/03/2022 19:09:03 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 19:09:03 - INFO - __main__ - ['false']
06/03/2022 19:09:03 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 19:09:03 - INFO - __main__ - ['false']
06/03/2022 19:09:03 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 19:09:03 - INFO - __main__ - ['false']
06/03/2022 19:09:03 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:09:05 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:09:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 19:09:06 - INFO - __main__ - Starting training!
06/03/2022 19:09:08 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 19:09:39 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_21_0.0003_8_predictions.txt
06/03/2022 19:09:39 - INFO - __main__ - Classification-F1 on test data: 0.4064
06/03/2022 19:09:40 - INFO - __main__ - prefix=wiki_qa_128_21, lr=0.0003, bsz=8, dev_performance=0.574212252994583, test_performance=0.4064300245983263
06/03/2022 19:09:40 - INFO - __main__ - Running ... prefix=wiki_qa_128_21, lr=0.0002, bsz=8 ...
06/03/2022 19:09:41 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:09:41 - INFO - __main__ - Printing 3 examples
06/03/2022 19:09:41 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/03/2022 19:09:41 - INFO - __main__ - ['false']
06/03/2022 19:09:41 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/03/2022 19:09:41 - INFO - __main__ - ['false']
06/03/2022 19:09:41 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/03/2022 19:09:41 - INFO - __main__ - ['false']
06/03/2022 19:09:41 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:09:41 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:09:41 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 19:09:41 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:09:41 - INFO - __main__ - Printing 3 examples
06/03/2022 19:09:41 - INFO - __main__ -  [wiki_qa] question: who started world war i [SEP] answer: These alliances were both reorganised and expanded as more nations entered the war: Italy, Japan and the United States joined the Allies, and the Ottoman Empire and Bulgaria the Central Powers.
06/03/2022 19:09:41 - INFO - __main__ - ['false']
06/03/2022 19:09:41 - INFO - __main__ -  [wiki_qa] question: when did wwi begin [SEP] answer: One of the long-term causes of the war was the resurgence of imperialism in the foreign policies of the great powers of Europe.
06/03/2022 19:09:41 - INFO - __main__ - ['false']
06/03/2022 19:09:41 - INFO - __main__ -  [wiki_qa] question: how old were the twin towers when destroyed [SEP] answer: The new World Trade Center complex will include One World Trade Center , three other high-rise office towers, and the National September 11 Memorial & Museum .
06/03/2022 19:09:41 - INFO - __main__ - ['false']
06/03/2022 19:09:41 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:09:41 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:09:42 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 19:09:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 19:09:52 - INFO - __main__ - Starting training!
06/03/2022 19:09:57 - INFO - __main__ - Step 10 Global step 10 Train loss 24.561449 on epoch=0
06/03/2022 19:10:02 - INFO - __main__ - Step 20 Global step 20 Train loss 18.739824 on epoch=1
06/03/2022 19:10:07 - INFO - __main__ - Step 30 Global step 30 Train loss 16.802666 on epoch=1
06/03/2022 19:10:12 - INFO - __main__ - Step 40 Global step 40 Train loss 16.542538 on epoch=2
06/03/2022 19:10:17 - INFO - __main__ - Step 50 Global step 50 Train loss 15.561554 on epoch=3
06/03/2022 19:11:15 - INFO - __main__ - Global step 50 Train loss 18.441605 Classification-F1 0.0 on epoch=3
06/03/2022 19:11:21 - INFO - __main__ - Step 60 Global step 60 Train loss 14.952288 on epoch=3
06/03/2022 19:11:26 - INFO - __main__ - Step 70 Global step 70 Train loss 14.194366 on epoch=4
06/03/2022 19:11:31 - INFO - __main__ - Step 80 Global step 80 Train loss 14.024050 on epoch=4
06/03/2022 19:11:37 - INFO - __main__ - Step 90 Global step 90 Train loss 12.855896 on epoch=5
06/03/2022 19:11:41 - INFO - __main__ - Step 100 Global step 100 Train loss 4.398582 on epoch=6
06/03/2022 19:11:44 - INFO - __main__ - Global step 100 Train loss 12.085035 Classification-F1 0.3333333333333333 on epoch=6
06/03/2022 19:11:50 - INFO - __main__ - Step 110 Global step 110 Train loss 1.364665 on epoch=6
06/03/2022 19:11:55 - INFO - __main__ - Step 120 Global step 120 Train loss 0.535317 on epoch=7
06/03/2022 19:12:00 - INFO - __main__ - Step 130 Global step 130 Train loss 0.556807 on epoch=8
06/03/2022 19:12:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.426088 on epoch=8
06/03/2022 19:12:10 - INFO - __main__ - Step 150 Global step 150 Train loss 0.445676 on epoch=9
06/03/2022 19:12:13 - INFO - __main__ - Global step 150 Train loss 0.665711 Classification-F1 0.36516753625488524 on epoch=9
06/03/2022 19:12:19 - INFO - __main__ - Step 160 Global step 160 Train loss 0.535636 on epoch=9
06/03/2022 19:12:24 - INFO - __main__ - Step 170 Global step 170 Train loss 0.446534 on epoch=10
06/03/2022 19:12:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.477471 on epoch=11
06/03/2022 19:12:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.392995 on epoch=11
06/03/2022 19:12:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.408405 on epoch=12
06/03/2022 19:12:42 - INFO - __main__ - Global step 200 Train loss 0.452208 Classification-F1 0.3732922688146569 on epoch=12
06/03/2022 19:12:48 - INFO - __main__ - Step 210 Global step 210 Train loss 0.457039 on epoch=13
06/03/2022 19:12:53 - INFO - __main__ - Step 220 Global step 220 Train loss 0.373285 on epoch=13
06/03/2022 19:12:58 - INFO - __main__ - Step 230 Global step 230 Train loss 0.393604 on epoch=14
06/03/2022 19:13:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.413450 on epoch=14
06/03/2022 19:13:09 - INFO - __main__ - Step 250 Global step 250 Train loss 0.393185 on epoch=15
06/03/2022 19:13:11 - INFO - __main__ - Global step 250 Train loss 0.406112 Classification-F1 0.6636525233789319 on epoch=15
06/03/2022 19:13:17 - INFO - __main__ - Step 260 Global step 260 Train loss 0.392947 on epoch=16
06/03/2022 19:13:22 - INFO - __main__ - Step 270 Global step 270 Train loss 0.357841 on epoch=16
06/03/2022 19:13:27 - INFO - __main__ - Step 280 Global step 280 Train loss 0.418005 on epoch=17
06/03/2022 19:13:32 - INFO - __main__ - Step 290 Global step 290 Train loss 0.336666 on epoch=18
06/03/2022 19:13:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.340729 on epoch=18
06/03/2022 19:13:40 - INFO - __main__ - Global step 300 Train loss 0.369237 Classification-F1 0.3732922688146569 on epoch=18
06/03/2022 19:13:45 - INFO - __main__ - Step 310 Global step 310 Train loss 0.338277 on epoch=19
06/03/2022 19:13:50 - INFO - __main__ - Step 320 Global step 320 Train loss 0.282328 on epoch=19
06/03/2022 19:13:55 - INFO - __main__ - Step 330 Global step 330 Train loss 0.360661 on epoch=20
06/03/2022 19:14:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.239669 on epoch=21
06/03/2022 19:14:05 - INFO - __main__ - Step 350 Global step 350 Train loss 0.444068 on epoch=21
06/03/2022 19:14:08 - INFO - __main__ - Global step 350 Train loss 0.333001 Classification-F1 0.6009510163593708 on epoch=21
06/03/2022 19:14:13 - INFO - __main__ - Step 360 Global step 360 Train loss 0.297827 on epoch=22
06/03/2022 19:14:18 - INFO - __main__ - Step 370 Global step 370 Train loss 0.392465 on epoch=23
06/03/2022 19:14:23 - INFO - __main__ - Step 380 Global step 380 Train loss 0.255635 on epoch=23
06/03/2022 19:14:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.336694 on epoch=24
06/03/2022 19:14:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.282802 on epoch=24
06/03/2022 19:14:37 - INFO - __main__ - Global step 400 Train loss 0.313085 Classification-F1 0.5060982770479977 on epoch=24
06/03/2022 19:14:42 - INFO - __main__ - Step 410 Global step 410 Train loss 0.310029 on epoch=25
06/03/2022 19:14:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.402593 on epoch=26
06/03/2022 19:14:53 - INFO - __main__ - Step 430 Global step 430 Train loss 0.388146 on epoch=26
06/03/2022 19:14:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.286170 on epoch=27
06/03/2022 19:15:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.359948 on epoch=28
06/03/2022 19:15:06 - INFO - __main__ - Global step 450 Train loss 0.349377 Classification-F1 0.38709489051094886 on epoch=28
06/03/2022 19:15:11 - INFO - __main__ - Step 460 Global step 460 Train loss 0.235214 on epoch=28
06/03/2022 19:15:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.214590 on epoch=29
06/03/2022 19:15:22 - INFO - __main__ - Step 480 Global step 480 Train loss 0.264829 on epoch=29
06/03/2022 19:15:27 - INFO - __main__ - Step 490 Global step 490 Train loss 0.261714 on epoch=30
06/03/2022 19:15:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.254672 on epoch=31
06/03/2022 19:15:35 - INFO - __main__ - Global step 500 Train loss 0.246204 Classification-F1 0.5387387387387387 on epoch=31
06/03/2022 19:15:41 - INFO - __main__ - Step 510 Global step 510 Train loss 0.194568 on epoch=31
06/03/2022 19:15:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.197557 on epoch=32
06/03/2022 19:15:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.159499 on epoch=33
06/03/2022 19:15:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.203488 on epoch=33
06/03/2022 19:16:02 - INFO - __main__ - Step 550 Global step 550 Train loss 0.177261 on epoch=34
06/03/2022 19:16:05 - INFO - __main__ - Global step 550 Train loss 0.186475 Classification-F1 0.5398297067171239 on epoch=34
06/03/2022 19:16:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.153518 on epoch=34
06/03/2022 19:16:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.099530 on epoch=35
06/03/2022 19:16:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.177133 on epoch=36
06/03/2022 19:16:26 - INFO - __main__ - Step 590 Global step 590 Train loss 0.102834 on epoch=36
06/03/2022 19:16:31 - INFO - __main__ - Step 600 Global step 600 Train loss 0.111885 on epoch=37
06/03/2022 19:16:34 - INFO - __main__ - Global step 600 Train loss 0.128980 Classification-F1 0.5311355311355311 on epoch=37
06/03/2022 19:16:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.099319 on epoch=38
06/03/2022 19:16:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.135966 on epoch=38
06/03/2022 19:16:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.108761 on epoch=39
06/03/2022 19:16:55 - INFO - __main__ - Step 640 Global step 640 Train loss 0.098578 on epoch=39
06/03/2022 19:17:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.071792 on epoch=40
06/03/2022 19:17:03 - INFO - __main__ - Global step 650 Train loss 0.102884 Classification-F1 0.5287817938420348 on epoch=40
06/03/2022 19:17:08 - INFO - __main__ - Step 660 Global step 660 Train loss 0.150107 on epoch=41
06/03/2022 19:17:14 - INFO - __main__ - Step 670 Global step 670 Train loss 0.096973 on epoch=41
06/03/2022 19:17:19 - INFO - __main__ - Step 680 Global step 680 Train loss 0.132633 on epoch=42
06/03/2022 19:17:24 - INFO - __main__ - Step 690 Global step 690 Train loss 0.163695 on epoch=43
06/03/2022 19:17:30 - INFO - __main__ - Step 700 Global step 700 Train loss 0.142922 on epoch=43
06/03/2022 19:17:32 - INFO - __main__ - Global step 700 Train loss 0.137266 Classification-F1 0.5355894188270993 on epoch=43
06/03/2022 19:17:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.195833 on epoch=44
06/03/2022 19:17:43 - INFO - __main__ - Step 720 Global step 720 Train loss 0.181468 on epoch=44
06/03/2022 19:17:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.092054 on epoch=45
06/03/2022 19:17:53 - INFO - __main__ - Step 740 Global step 740 Train loss 0.144329 on epoch=46
06/03/2022 19:17:59 - INFO - __main__ - Step 750 Global step 750 Train loss 0.076405 on epoch=46
06/03/2022 19:18:02 - INFO - __main__ - Global step 750 Train loss 0.138018 Classification-F1 0.5263018768173408 on epoch=46
06/03/2022 19:18:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.055584 on epoch=47
06/03/2022 19:18:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.039199 on epoch=48
06/03/2022 19:18:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.054077 on epoch=48
06/03/2022 19:18:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.029167 on epoch=49
06/03/2022 19:18:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.080868 on epoch=49
06/03/2022 19:18:31 - INFO - __main__ - Global step 800 Train loss 0.051779 Classification-F1 0.5237401925099086 on epoch=49
06/03/2022 19:18:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.042984 on epoch=50
06/03/2022 19:18:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.040947 on epoch=51
06/03/2022 19:18:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.016785 on epoch=51
06/03/2022 19:18:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.069196 on epoch=52
06/03/2022 19:18:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.015375 on epoch=53
06/03/2022 19:19:00 - INFO - __main__ - Global step 850 Train loss 0.037058 Classification-F1 0.588430739079175 on epoch=53
06/03/2022 19:19:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.022598 on epoch=53
06/03/2022 19:19:11 - INFO - __main__ - Step 870 Global step 870 Train loss 0.018232 on epoch=54
06/03/2022 19:19:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.060173 on epoch=54
06/03/2022 19:19:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.051137 on epoch=55
06/03/2022 19:19:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.051039 on epoch=56
06/03/2022 19:19:29 - INFO - __main__ - Global step 900 Train loss 0.040636 Classification-F1 0.5793650793650793 on epoch=56
06/03/2022 19:19:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.016803 on epoch=56
06/03/2022 19:19:40 - INFO - __main__ - Step 920 Global step 920 Train loss 0.012502 on epoch=57
06/03/2022 19:19:45 - INFO - __main__ - Step 930 Global step 930 Train loss 0.032237 on epoch=58
06/03/2022 19:19:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.018974 on epoch=58
06/03/2022 19:19:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.088844 on epoch=59
06/03/2022 19:19:59 - INFO - __main__ - Global step 950 Train loss 0.033872 Classification-F1 0.5897874158743723 on epoch=59
06/03/2022 19:20:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.892019 on epoch=59
06/03/2022 19:20:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.002485 on epoch=60
06/03/2022 19:20:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.015777 on epoch=61
06/03/2022 19:20:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.014908 on epoch=61
06/03/2022 19:20:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.017282 on epoch=62
06/03/2022 19:20:26 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:20:26 - INFO - __main__ - Printing 3 examples
06/03/2022 19:20:26 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/03/2022 19:20:26 - INFO - __main__ - ['false']
06/03/2022 19:20:26 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/03/2022 19:20:26 - INFO - __main__ - ['false']
06/03/2022 19:20:26 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/03/2022 19:20:26 - INFO - __main__ - ['false']
06/03/2022 19:20:26 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:20:26 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:20:26 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 19:20:26 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:20:26 - INFO - __main__ - Printing 3 examples
06/03/2022 19:20:26 - INFO - __main__ -  [wiki_qa] question: who started world war i [SEP] answer: These alliances were both reorganised and expanded as more nations entered the war: Italy, Japan and the United States joined the Allies, and the Ottoman Empire and Bulgaria the Central Powers.
06/03/2022 19:20:26 - INFO - __main__ - ['false']
06/03/2022 19:20:26 - INFO - __main__ -  [wiki_qa] question: when did wwi begin [SEP] answer: One of the long-term causes of the war was the resurgence of imperialism in the foreign policies of the great powers of Europe.
06/03/2022 19:20:26 - INFO - __main__ - ['false']
06/03/2022 19:20:26 - INFO - __main__ -  [wiki_qa] question: how old were the twin towers when destroyed [SEP] answer: The new World Trade Center complex will include One World Trade Center , three other high-rise office towers, and the National September 11 Memorial & Museum .
06/03/2022 19:20:26 - INFO - __main__ - ['false']
06/03/2022 19:20:26 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:20:26 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:20:27 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 19:20:27 - INFO - __main__ - Global step 1000 Train loss 0.188494 Classification-F1 0.5740562653600159 on epoch=62
06/03/2022 19:20:27 - INFO - __main__ - save last model!
06/03/2022 19:20:34 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 19:20:35 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 19:20:35 - INFO - __main__ - Printing 3 examples
06/03/2022 19:20:35 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 19:20:35 - INFO - __main__ - ['false']
06/03/2022 19:20:35 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 19:20:35 - INFO - __main__ - ['false']
06/03/2022 19:20:35 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 19:20:35 - INFO - __main__ - ['false']
06/03/2022 19:20:35 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:20:36 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:20:39 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 19:20:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 19:20:40 - INFO - __main__ - Starting training!
06/03/2022 19:21:08 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_21_0.0002_8_predictions.txt
06/03/2022 19:21:08 - INFO - __main__ - Classification-F1 on test data: 0.4004
06/03/2022 19:21:09 - INFO - __main__ - prefix=wiki_qa_128_21, lr=0.0002, bsz=8, dev_performance=0.6636525233789319, test_performance=0.4004308391707089
06/03/2022 19:21:09 - INFO - __main__ - Running ... prefix=wiki_qa_128_21, lr=0.0001, bsz=8 ...
06/03/2022 19:21:10 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:21:10 - INFO - __main__ - Printing 3 examples
06/03/2022 19:21:10 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
06/03/2022 19:21:10 - INFO - __main__ - ['false']
06/03/2022 19:21:10 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
06/03/2022 19:21:10 - INFO - __main__ - ['false']
06/03/2022 19:21:10 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
06/03/2022 19:21:10 - INFO - __main__ - ['false']
06/03/2022 19:21:10 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:21:10 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:21:11 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 19:21:11 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:21:11 - INFO - __main__ - Printing 3 examples
06/03/2022 19:21:11 - INFO - __main__ -  [wiki_qa] question: who started world war i [SEP] answer: These alliances were both reorganised and expanded as more nations entered the war: Italy, Japan and the United States joined the Allies, and the Ottoman Empire and Bulgaria the Central Powers.
06/03/2022 19:21:11 - INFO - __main__ - ['false']
06/03/2022 19:21:11 - INFO - __main__ -  [wiki_qa] question: when did wwi begin [SEP] answer: One of the long-term causes of the war was the resurgence of imperialism in the foreign policies of the great powers of Europe.
06/03/2022 19:21:11 - INFO - __main__ - ['false']
06/03/2022 19:21:11 - INFO - __main__ -  [wiki_qa] question: how old were the twin towers when destroyed [SEP] answer: The new World Trade Center complex will include One World Trade Center , three other high-rise office towers, and the National September 11 Memorial & Museum .
06/03/2022 19:21:11 - INFO - __main__ - ['false']
06/03/2022 19:21:11 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:21:11 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:21:11 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 19:21:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 19:21:21 - INFO - __main__ - Starting training!
06/03/2022 19:21:26 - INFO - __main__ - Step 10 Global step 10 Train loss 24.159151 on epoch=0
06/03/2022 19:21:31 - INFO - __main__ - Step 20 Global step 20 Train loss 20.403477 on epoch=1
06/03/2022 19:21:37 - INFO - __main__ - Step 30 Global step 30 Train loss 19.033358 on epoch=1
06/03/2022 19:21:42 - INFO - __main__ - Step 40 Global step 40 Train loss 17.274748 on epoch=2
06/03/2022 19:21:47 - INFO - __main__ - Step 50 Global step 50 Train loss 17.468952 on epoch=3
06/03/2022 19:22:45 - INFO - __main__ - Global step 50 Train loss 19.667936 Classification-F1 0.0 on epoch=3
06/03/2022 19:22:51 - INFO - __main__ - Step 60 Global step 60 Train loss 17.649498 on epoch=3
06/03/2022 19:22:56 - INFO - __main__ - Step 70 Global step 70 Train loss 16.544666 on epoch=4
06/03/2022 19:23:02 - INFO - __main__ - Step 80 Global step 80 Train loss 16.424030 on epoch=4
06/03/2022 19:23:07 - INFO - __main__ - Step 90 Global step 90 Train loss 15.799441 on epoch=5
06/03/2022 19:23:13 - INFO - __main__ - Step 100 Global step 100 Train loss 15.512949 on epoch=6
06/03/2022 19:23:58 - INFO - __main__ - Global step 100 Train loss 16.386116 Classification-F1 0.0 on epoch=6
06/03/2022 19:24:03 - INFO - __main__ - Step 110 Global step 110 Train loss 15.154963 on epoch=6
06/03/2022 19:24:08 - INFO - __main__ - Step 120 Global step 120 Train loss 14.914413 on epoch=7
06/03/2022 19:24:14 - INFO - __main__ - Step 130 Global step 130 Train loss 14.819677 on epoch=8
06/03/2022 19:24:19 - INFO - __main__ - Step 140 Global step 140 Train loss 13.928250 on epoch=8
06/03/2022 19:24:24 - INFO - __main__ - Step 150 Global step 150 Train loss 14.392520 on epoch=9
06/03/2022 19:25:02 - INFO - __main__ - Global step 150 Train loss 14.641964 Classification-F1 0.0 on epoch=9
06/03/2022 19:25:07 - INFO - __main__ - Step 160 Global step 160 Train loss 13.033595 on epoch=9
06/03/2022 19:25:12 - INFO - __main__ - Step 170 Global step 170 Train loss 13.110586 on epoch=10
06/03/2022 19:25:18 - INFO - __main__ - Step 180 Global step 180 Train loss 12.770914 on epoch=11
06/03/2022 19:25:23 - INFO - __main__ - Step 190 Global step 190 Train loss 11.174187 on epoch=11
06/03/2022 19:25:28 - INFO - __main__ - Step 200 Global step 200 Train loss 11.247390 on epoch=12
06/03/2022 19:25:51 - INFO - __main__ - Global step 200 Train loss 12.267334 Classification-F1 0.0 on epoch=12
06/03/2022 19:25:56 - INFO - __main__ - Step 210 Global step 210 Train loss 8.205997 on epoch=13
06/03/2022 19:26:01 - INFO - __main__ - Step 220 Global step 220 Train loss 6.445934 on epoch=13
06/03/2022 19:26:07 - INFO - __main__ - Step 230 Global step 230 Train loss 6.013100 on epoch=14
06/03/2022 19:26:12 - INFO - __main__ - Step 240 Global step 240 Train loss 3.532489 on epoch=14
06/03/2022 19:26:18 - INFO - __main__ - Step 250 Global step 250 Train loss 3.296746 on epoch=15
06/03/2022 19:26:20 - INFO - __main__ - Global step 250 Train loss 5.498853 Classification-F1 0.2244264507422402 on epoch=15
06/03/2022 19:26:26 - INFO - __main__ - Step 260 Global step 260 Train loss 2.054932 on epoch=16
06/03/2022 19:26:32 - INFO - __main__ - Step 270 Global step 270 Train loss 1.276085 on epoch=16
06/03/2022 19:26:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.738345 on epoch=17
06/03/2022 19:26:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.569190 on epoch=18
06/03/2022 19:26:48 - INFO - __main__ - Step 300 Global step 300 Train loss 0.494371 on epoch=18
06/03/2022 19:26:50 - INFO - __main__ - Global step 300 Train loss 1.026585 Classification-F1 0.3732922688146569 on epoch=18
06/03/2022 19:26:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.427880 on epoch=19
06/03/2022 19:27:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.459541 on epoch=19
06/03/2022 19:27:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.442602 on epoch=20
06/03/2022 19:27:13 - INFO - __main__ - Step 340 Global step 340 Train loss 0.698574 on epoch=21
06/03/2022 19:27:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.467506 on epoch=21
06/03/2022 19:27:20 - INFO - __main__ - Global step 350 Train loss 0.499221 Classification-F1 0.42995169082125606 on epoch=21
06/03/2022 19:27:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.464581 on epoch=22
06/03/2022 19:27:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.441081 on epoch=23
06/03/2022 19:27:37 - INFO - __main__ - Step 380 Global step 380 Train loss 0.390990 on epoch=23
06/03/2022 19:27:43 - INFO - __main__ - Step 390 Global step 390 Train loss 0.480100 on epoch=24
06/03/2022 19:27:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.361842 on epoch=24
06/03/2022 19:27:51 - INFO - __main__ - Global step 400 Train loss 0.427719 Classification-F1 0.34195559333697656 on epoch=24
06/03/2022 19:27:56 - INFO - __main__ - Step 410 Global step 410 Train loss 0.456094 on epoch=25
06/03/2022 19:28:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.403654 on epoch=26
06/03/2022 19:28:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.498978 on epoch=26
06/03/2022 19:28:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.414190 on epoch=27
06/03/2022 19:28:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.411206 on epoch=28
06/03/2022 19:28:21 - INFO - __main__ - Global step 450 Train loss 0.436825 Classification-F1 0.4625414364640884 on epoch=28
06/03/2022 19:28:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.365018 on epoch=28
06/03/2022 19:28:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.327455 on epoch=29
06/03/2022 19:28:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.331909 on epoch=29
06/03/2022 19:28:43 - INFO - __main__ - Step 490 Global step 490 Train loss 0.304075 on epoch=30
06/03/2022 19:28:49 - INFO - __main__ - Step 500 Global step 500 Train loss 0.345910 on epoch=31
06/03/2022 19:28:51 - INFO - __main__ - Global step 500 Train loss 0.334873 Classification-F1 0.6906084109718972 on epoch=31
06/03/2022 19:28:58 - INFO - __main__ - Step 510 Global step 510 Train loss 0.283410 on epoch=31
06/03/2022 19:29:03 - INFO - __main__ - Step 520 Global step 520 Train loss 0.293958 on epoch=32
06/03/2022 19:29:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.266425 on epoch=33
06/03/2022 19:29:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.220422 on epoch=33
06/03/2022 19:29:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.314242 on epoch=34
06/03/2022 19:29:22 - INFO - __main__ - Global step 550 Train loss 0.275692 Classification-F1 0.6182325098878299 on epoch=34
06/03/2022 19:29:27 - INFO - __main__ - Step 560 Global step 560 Train loss 0.211090 on epoch=34
06/03/2022 19:29:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.252277 on epoch=35
06/03/2022 19:29:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.196212 on epoch=36
06/03/2022 19:29:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.246059 on epoch=36
06/03/2022 19:29:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.266076 on epoch=37
06/03/2022 19:29:51 - INFO - __main__ - Global step 600 Train loss 0.234343 Classification-F1 0.6610837438423646 on epoch=37
06/03/2022 19:29:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.194801 on epoch=38
06/03/2022 19:30:02 - INFO - __main__ - Step 620 Global step 620 Train loss 0.180986 on epoch=38
06/03/2022 19:30:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.249168 on epoch=39
06/03/2022 19:30:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.175838 on epoch=39
06/03/2022 19:30:18 - INFO - __main__ - Step 650 Global step 650 Train loss 0.165786 on epoch=40
06/03/2022 19:30:21 - INFO - __main__ - Global step 650 Train loss 0.193316 Classification-F1 0.6259893717790228 on epoch=40
06/03/2022 19:30:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.221568 on epoch=41
06/03/2022 19:30:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.130962 on epoch=41
06/03/2022 19:30:36 - INFO - __main__ - Step 680 Global step 680 Train loss 0.199997 on epoch=42
06/03/2022 19:30:42 - INFO - __main__ - Step 690 Global step 690 Train loss 0.170483 on epoch=43
06/03/2022 19:30:47 - INFO - __main__ - Step 700 Global step 700 Train loss 0.125244 on epoch=43
06/03/2022 19:30:50 - INFO - __main__ - Global step 700 Train loss 0.169651 Classification-F1 0.6542464447445777 on epoch=43
06/03/2022 19:30:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.125800 on epoch=44
06/03/2022 19:31:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.093538 on epoch=44
06/03/2022 19:31:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.133020 on epoch=45
06/03/2022 19:31:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.091719 on epoch=46
06/03/2022 19:31:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.100083 on epoch=46
06/03/2022 19:31:19 - INFO - __main__ - Global step 750 Train loss 0.108832 Classification-F1 0.5632007799986072 on epoch=46
06/03/2022 19:31:25 - INFO - __main__ - Step 760 Global step 760 Train loss 0.085271 on epoch=47
06/03/2022 19:31:30 - INFO - __main__ - Step 770 Global step 770 Train loss 0.087189 on epoch=48
06/03/2022 19:31:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.105469 on epoch=48
06/03/2022 19:31:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.062282 on epoch=49
06/03/2022 19:31:47 - INFO - __main__ - Step 800 Global step 800 Train loss 0.157808 on epoch=49
06/03/2022 19:31:50 - INFO - __main__ - Global step 800 Train loss 0.099604 Classification-F1 0.6893156156386819 on epoch=49
06/03/2022 19:31:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.054950 on epoch=50
06/03/2022 19:32:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.060256 on epoch=51
06/03/2022 19:32:06 - INFO - __main__ - Step 830 Global step 830 Train loss 0.040457 on epoch=51
06/03/2022 19:32:11 - INFO - __main__ - Step 840 Global step 840 Train loss 0.041275 on epoch=52
06/03/2022 19:32:17 - INFO - __main__ - Step 850 Global step 850 Train loss 0.041913 on epoch=53
06/03/2022 19:32:19 - INFO - __main__ - Global step 850 Train loss 0.047770 Classification-F1 0.6132993324345835 on epoch=53
06/03/2022 19:32:25 - INFO - __main__ - Step 860 Global step 860 Train loss 0.049961 on epoch=53
06/03/2022 19:32:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.068012 on epoch=54
06/03/2022 19:32:35 - INFO - __main__ - Step 880 Global step 880 Train loss 0.020206 on epoch=54
06/03/2022 19:32:41 - INFO - __main__ - Step 890 Global step 890 Train loss 0.050524 on epoch=55
06/03/2022 19:32:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.032950 on epoch=56
06/03/2022 19:32:49 - INFO - __main__ - Global step 900 Train loss 0.044331 Classification-F1 0.6519012653772935 on epoch=56
06/03/2022 19:32:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.035002 on epoch=56
06/03/2022 19:32:59 - INFO - __main__ - Step 920 Global step 920 Train loss 0.060349 on epoch=57
06/03/2022 19:33:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.061383 on epoch=58
06/03/2022 19:33:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.025159 on epoch=58
06/03/2022 19:33:15 - INFO - __main__ - Step 950 Global step 950 Train loss 0.039219 on epoch=59
06/03/2022 19:33:18 - INFO - __main__ - Global step 950 Train loss 0.044222 Classification-F1 0.6544137042841405 on epoch=59
06/03/2022 19:33:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.023548 on epoch=59
06/03/2022 19:33:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.008938 on epoch=60
06/03/2022 19:33:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.032069 on epoch=61
06/03/2022 19:33:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.025573 on epoch=61
06/03/2022 19:33:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.036301 on epoch=62
06/03/2022 19:33:45 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:33:45 - INFO - __main__ - Printing 3 examples
06/03/2022 19:33:45 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/03/2022 19:33:45 - INFO - __main__ - ['false']
06/03/2022 19:33:45 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/03/2022 19:33:45 - INFO - __main__ - ['false']
06/03/2022 19:33:45 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/03/2022 19:33:45 - INFO - __main__ - ['false']
06/03/2022 19:33:45 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:33:46 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:33:46 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 19:33:46 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:33:46 - INFO - __main__ - Printing 3 examples
06/03/2022 19:33:46 - INFO - __main__ -  [wiki_qa] question: what are the side effects for lyme disease [SEP] answer: Lyme disease is the most common tick-borne disease in the Northern Hemisphere .
06/03/2022 19:33:46 - INFO - __main__ - ['false']
06/03/2022 19:33:46 - INFO - __main__ -  [wiki_qa] question: how many gold medals usa won for basketball [SEP] answer: The USA won its first seven games at the 2006 FIBA World Championship in Japan before losing against Greece in the semi-finals, ending the competition with the bronze medal.
06/03/2022 19:33:46 - INFO - __main__ - ['false']
06/03/2022 19:33:46 - INFO - __main__ -  [wiki_qa] question: who played in the 2010 NBA Finals [SEP] answer: Repeated baskets from starters Kobe Bryant , Pau Gasol , and Ron Artest brought the Lakers close to victory in Game 1.
06/03/2022 19:33:46 - INFO - __main__ - ['false']
06/03/2022 19:33:46 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:33:46 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:33:46 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 19:33:47 - INFO - __main__ - Global step 1000 Train loss 0.025286 Classification-F1 0.6538364779874214 on epoch=62
06/03/2022 19:33:47 - INFO - __main__ - save last model!
06/03/2022 19:33:54 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 19:33:55 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 19:33:55 - INFO - __main__ - Printing 3 examples
06/03/2022 19:33:55 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 19:33:55 - INFO - __main__ - ['false']
06/03/2022 19:33:55 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 19:33:55 - INFO - __main__ - ['false']
06/03/2022 19:33:55 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 19:33:55 - INFO - __main__ - ['false']
06/03/2022 19:33:55 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:33:56 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:33:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 19:33:58 - INFO - __main__ - Starting training!
06/03/2022 19:33:59 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 19:34:28 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_21_0.0001_8_predictions.txt
06/03/2022 19:34:28 - INFO - __main__ - Classification-F1 on test data: 0.4754
06/03/2022 19:34:28 - INFO - __main__ - prefix=wiki_qa_128_21, lr=0.0001, bsz=8, dev_performance=0.6906084109718972, test_performance=0.47539684316224173
06/03/2022 19:34:29 - INFO - __main__ - Running ... prefix=wiki_qa_128_42, lr=0.0005, bsz=8 ...
06/03/2022 19:34:29 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:34:29 - INFO - __main__ - Printing 3 examples
06/03/2022 19:34:29 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/03/2022 19:34:29 - INFO - __main__ - ['false']
06/03/2022 19:34:29 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/03/2022 19:34:29 - INFO - __main__ - ['false']
06/03/2022 19:34:29 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/03/2022 19:34:29 - INFO - __main__ - ['false']
06/03/2022 19:34:29 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:34:30 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:34:30 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 19:34:30 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:34:30 - INFO - __main__ - Printing 3 examples
06/03/2022 19:34:30 - INFO - __main__ -  [wiki_qa] question: what are the side effects for lyme disease [SEP] answer: Lyme disease is the most common tick-borne disease in the Northern Hemisphere .
06/03/2022 19:34:30 - INFO - __main__ - ['false']
06/03/2022 19:34:30 - INFO - __main__ -  [wiki_qa] question: how many gold medals usa won for basketball [SEP] answer: The USA won its first seven games at the 2006 FIBA World Championship in Japan before losing against Greece in the semi-finals, ending the competition with the bronze medal.
06/03/2022 19:34:30 - INFO - __main__ - ['false']
06/03/2022 19:34:30 - INFO - __main__ -  [wiki_qa] question: who played in the 2010 NBA Finals [SEP] answer: Repeated baskets from starters Kobe Bryant , Pau Gasol , and Ron Artest brought the Lakers close to victory in Game 1.
06/03/2022 19:34:30 - INFO - __main__ - ['false']
06/03/2022 19:34:30 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:34:30 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:34:30 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 19:34:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 19:34:41 - INFO - __main__ - Starting training!
06/03/2022 19:34:46 - INFO - __main__ - Step 10 Global step 10 Train loss 21.601803 on epoch=0
06/03/2022 19:34:51 - INFO - __main__ - Step 20 Global step 20 Train loss 17.946720 on epoch=1
06/03/2022 19:34:57 - INFO - __main__ - Step 30 Global step 30 Train loss 14.893158 on epoch=1
06/03/2022 19:35:02 - INFO - __main__ - Step 40 Global step 40 Train loss 13.938298 on epoch=2
06/03/2022 19:35:07 - INFO - __main__ - Step 50 Global step 50 Train loss 10.097453 on epoch=3
06/03/2022 19:35:10 - INFO - __main__ - Global step 50 Train loss 15.695486 Classification-F1 0.03719977657791845 on epoch=3
06/03/2022 19:35:16 - INFO - __main__ - Step 60 Global step 60 Train loss 3.428601 on epoch=3
06/03/2022 19:35:21 - INFO - __main__ - Step 70 Global step 70 Train loss 1.622942 on epoch=4
06/03/2022 19:35:27 - INFO - __main__ - Step 80 Global step 80 Train loss 1.328211 on epoch=4
06/03/2022 19:35:32 - INFO - __main__ - Step 90 Global step 90 Train loss 0.475039 on epoch=5
06/03/2022 19:35:36 - INFO - __main__ - Step 100 Global step 100 Train loss 1.085907 on epoch=6
06/03/2022 19:35:39 - INFO - __main__ - Global step 100 Train loss 1.588140 Classification-F1 0.33159268929503916 on epoch=6
06/03/2022 19:35:45 - INFO - __main__ - Step 110 Global step 110 Train loss 0.456684 on epoch=6
06/03/2022 19:35:51 - INFO - __main__ - Step 120 Global step 120 Train loss 0.498576 on epoch=7
06/03/2022 19:35:56 - INFO - __main__ - Step 130 Global step 130 Train loss 0.535216 on epoch=8
06/03/2022 19:36:02 - INFO - __main__ - Step 140 Global step 140 Train loss 0.508985 on epoch=8
06/03/2022 19:36:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.511622 on epoch=9
06/03/2022 19:36:27 - INFO - __main__ - Global step 150 Train loss 0.502217 Classification-F1 0.105400967469933 on epoch=9
06/03/2022 19:36:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.849936 on epoch=9
06/03/2022 19:36:38 - INFO - __main__ - Step 170 Global step 170 Train loss 0.515545 on epoch=10
06/03/2022 19:36:43 - INFO - __main__ - Step 180 Global step 180 Train loss 0.426418 on epoch=11
06/03/2022 19:36:49 - INFO - __main__ - Step 190 Global step 190 Train loss 0.440496 on epoch=11
06/03/2022 19:36:54 - INFO - __main__ - Step 200 Global step 200 Train loss 0.466106 on epoch=12
06/03/2022 19:36:57 - INFO - __main__ - Global step 200 Train loss 0.539700 Classification-F1 0.3712545436683367 on epoch=12
06/03/2022 19:37:03 - INFO - __main__ - Step 210 Global step 210 Train loss 0.456906 on epoch=13
06/03/2022 19:37:09 - INFO - __main__ - Step 220 Global step 220 Train loss 0.394276 on epoch=13
06/03/2022 19:37:14 - INFO - __main__ - Step 230 Global step 230 Train loss 0.414770 on epoch=14
06/03/2022 19:37:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.476202 on epoch=14
06/03/2022 19:37:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.459881 on epoch=15
06/03/2022 19:37:28 - INFO - __main__ - Global step 250 Train loss 0.440407 Classification-F1 0.5376937220908852 on epoch=15
06/03/2022 19:37:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.382018 on epoch=16
06/03/2022 19:37:39 - INFO - __main__ - Step 270 Global step 270 Train loss 0.383737 on epoch=16
06/03/2022 19:37:45 - INFO - __main__ - Step 280 Global step 280 Train loss 0.452540 on epoch=17
06/03/2022 19:37:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.429454 on epoch=18
06/03/2022 19:37:56 - INFO - __main__ - Step 300 Global step 300 Train loss 0.368764 on epoch=18
06/03/2022 19:37:58 - INFO - __main__ - Global step 300 Train loss 0.403303 Classification-F1 0.3333333333333333 on epoch=18
06/03/2022 19:38:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.421964 on epoch=19
06/03/2022 19:38:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.400204 on epoch=19
06/03/2022 19:38:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.425459 on epoch=20
06/03/2022 19:38:20 - INFO - __main__ - Step 340 Global step 340 Train loss 0.423485 on epoch=21
06/03/2022 19:38:26 - INFO - __main__ - Step 350 Global step 350 Train loss 0.387302 on epoch=21
06/03/2022 19:38:28 - INFO - __main__ - Global step 350 Train loss 0.411683 Classification-F1 0.42752983181433807 on epoch=21
06/03/2022 19:38:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.421163 on epoch=22
06/03/2022 19:38:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.392596 on epoch=23
06/03/2022 19:38:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.364859 on epoch=23
06/03/2022 19:38:50 - INFO - __main__ - Step 390 Global step 390 Train loss 0.406417 on epoch=24
06/03/2022 19:38:55 - INFO - __main__ - Step 400 Global step 400 Train loss 0.383326 on epoch=24
06/03/2022 19:38:58 - INFO - __main__ - Global step 400 Train loss 0.393672 Classification-F1 0.3333333333333333 on epoch=24
06/03/2022 19:39:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.429533 on epoch=25
06/03/2022 19:39:09 - INFO - __main__ - Step 420 Global step 420 Train loss 0.379759 on epoch=26
06/03/2022 19:39:14 - INFO - __main__ - Step 430 Global step 430 Train loss 0.391130 on epoch=26
06/03/2022 19:39:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.437698 on epoch=27
06/03/2022 19:39:24 - INFO - __main__ - Step 450 Global step 450 Train loss 0.567689 on epoch=28
06/03/2022 19:39:27 - INFO - __main__ - Global step 450 Train loss 0.441162 Classification-F1 0.5551516890653149 on epoch=28
06/03/2022 19:39:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.362855 on epoch=28
06/03/2022 19:39:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.377038 on epoch=29
06/03/2022 19:39:44 - INFO - __main__ - Step 480 Global step 480 Train loss 0.392223 on epoch=29
06/03/2022 19:39:50 - INFO - __main__ - Step 490 Global step 490 Train loss 0.422802 on epoch=30
06/03/2022 19:39:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.384705 on epoch=31
06/03/2022 19:39:58 - INFO - __main__ - Global step 500 Train loss 0.387925 Classification-F1 0.34195559333697656 on epoch=31
06/03/2022 19:40:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.349315 on epoch=31
06/03/2022 19:40:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.405262 on epoch=32
06/03/2022 19:40:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.384891 on epoch=33
06/03/2022 19:40:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.325874 on epoch=33
06/03/2022 19:40:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.397510 on epoch=34
06/03/2022 19:40:27 - INFO - __main__ - Global step 550 Train loss 0.372570 Classification-F1 0.5503711558854718 on epoch=34
06/03/2022 19:40:32 - INFO - __main__ - Step 560 Global step 560 Train loss 0.334736 on epoch=34
06/03/2022 19:40:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.343626 on epoch=35
06/03/2022 19:40:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.344652 on epoch=36
06/03/2022 19:40:48 - INFO - __main__ - Step 590 Global step 590 Train loss 0.370514 on epoch=36
06/03/2022 19:40:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.348148 on epoch=37
06/03/2022 19:40:56 - INFO - __main__ - Global step 600 Train loss 0.348335 Classification-F1 0.3712545436683367 on epoch=37
06/03/2022 19:41:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.360177 on epoch=38
06/03/2022 19:41:07 - INFO - __main__ - Step 620 Global step 620 Train loss 0.327747 on epoch=38
06/03/2022 19:41:12 - INFO - __main__ - Step 630 Global step 630 Train loss 0.405768 on epoch=39
06/03/2022 19:41:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.371484 on epoch=39
06/03/2022 19:41:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.341770 on epoch=40
06/03/2022 19:41:26 - INFO - __main__ - Global step 650 Train loss 0.361389 Classification-F1 0.4801353814110908 on epoch=40
06/03/2022 19:41:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.309675 on epoch=41
06/03/2022 19:41:36 - INFO - __main__ - Step 670 Global step 670 Train loss 0.326496 on epoch=41
06/03/2022 19:41:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.362967 on epoch=42
06/03/2022 19:41:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.385810 on epoch=43
06/03/2022 19:41:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.321819 on epoch=43
06/03/2022 19:41:55 - INFO - __main__ - Global step 700 Train loss 0.341353 Classification-F1 0.3712545436683367 on epoch=43
06/03/2022 19:42:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.304635 on epoch=44
06/03/2022 19:42:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.312454 on epoch=44
06/03/2022 19:42:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.346505 on epoch=45
06/03/2022 19:42:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.317216 on epoch=46
06/03/2022 19:42:22 - INFO - __main__ - Step 750 Global step 750 Train loss 0.280894 on epoch=46
06/03/2022 19:42:25 - INFO - __main__ - Global step 750 Train loss 0.312341 Classification-F1 0.5039014937147365 on epoch=46
06/03/2022 19:42:30 - INFO - __main__ - Step 760 Global step 760 Train loss 0.340903 on epoch=47
06/03/2022 19:42:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.288766 on epoch=48
06/03/2022 19:42:41 - INFO - __main__ - Step 780 Global step 780 Train loss 0.315044 on epoch=48
06/03/2022 19:42:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.270821 on epoch=49
06/03/2022 19:42:51 - INFO - __main__ - Step 800 Global step 800 Train loss 0.314885 on epoch=49
06/03/2022 19:42:54 - INFO - __main__ - Global step 800 Train loss 0.306084 Classification-F1 0.44279184502648194 on epoch=49
06/03/2022 19:42:59 - INFO - __main__ - Step 810 Global step 810 Train loss 0.267301 on epoch=50
06/03/2022 19:43:05 - INFO - __main__ - Step 820 Global step 820 Train loss 0.281141 on epoch=51
06/03/2022 19:43:10 - INFO - __main__ - Step 830 Global step 830 Train loss 0.262595 on epoch=51
06/03/2022 19:43:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.213089 on epoch=52
06/03/2022 19:43:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.278629 on epoch=53
06/03/2022 19:43:23 - INFO - __main__ - Global step 850 Train loss 0.260551 Classification-F1 0.4775599801066694 on epoch=53
06/03/2022 19:43:29 - INFO - __main__ - Step 860 Global step 860 Train loss 0.264243 on epoch=53
06/03/2022 19:43:34 - INFO - __main__ - Step 870 Global step 870 Train loss 0.276284 on epoch=54
06/03/2022 19:43:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.142587 on epoch=54
06/03/2022 19:43:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.188887 on epoch=55
06/03/2022 19:43:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.102951 on epoch=56
06/03/2022 19:43:53 - INFO - __main__ - Global step 900 Train loss 0.194990 Classification-F1 0.4342541436464089 on epoch=56
06/03/2022 19:43:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.151586 on epoch=56
06/03/2022 19:44:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.119221 on epoch=57
06/03/2022 19:44:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.077289 on epoch=58
06/03/2022 19:44:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.121645 on epoch=58
06/03/2022 19:44:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.141601 on epoch=59
06/03/2022 19:44:22 - INFO - __main__ - Global step 950 Train loss 0.122268 Classification-F1 0.5417871403001515 on epoch=59
06/03/2022 19:44:27 - INFO - __main__ - Step 960 Global step 960 Train loss 0.046098 on epoch=59
06/03/2022 19:44:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.184468 on epoch=60
06/03/2022 19:44:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.129762 on epoch=61
06/03/2022 19:44:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.266448 on epoch=61
06/03/2022 19:44:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.168057 on epoch=62
06/03/2022 19:44:50 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:44:50 - INFO - __main__ - Printing 3 examples
06/03/2022 19:44:50 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/03/2022 19:44:50 - INFO - __main__ - ['false']
06/03/2022 19:44:50 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/03/2022 19:44:50 - INFO - __main__ - ['false']
06/03/2022 19:44:50 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/03/2022 19:44:50 - INFO - __main__ - ['false']
06/03/2022 19:44:50 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:44:50 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:44:50 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 19:44:50 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:44:50 - INFO - __main__ - Printing 3 examples
06/03/2022 19:44:50 - INFO - __main__ -  [wiki_qa] question: what are the side effects for lyme disease [SEP] answer: Lyme disease is the most common tick-borne disease in the Northern Hemisphere .
06/03/2022 19:44:50 - INFO - __main__ - ['false']
06/03/2022 19:44:50 - INFO - __main__ -  [wiki_qa] question: how many gold medals usa won for basketball [SEP] answer: The USA won its first seven games at the 2006 FIBA World Championship in Japan before losing against Greece in the semi-finals, ending the competition with the bronze medal.
06/03/2022 19:44:50 - INFO - __main__ - ['false']
06/03/2022 19:44:50 - INFO - __main__ -  [wiki_qa] question: who played in the 2010 NBA Finals [SEP] answer: Repeated baskets from starters Kobe Bryant , Pau Gasol , and Ron Artest brought the Lakers close to victory in Game 1.
06/03/2022 19:44:50 - INFO - __main__ - ['false']
06/03/2022 19:44:50 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:44:50 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:44:51 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 19:44:51 - INFO - __main__ - Global step 1000 Train loss 0.158967 Classification-F1 0.5625970798384592 on epoch=62
06/03/2022 19:44:52 - INFO - __main__ - save last model!
06/03/2022 19:45:00 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 19:45:01 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 19:45:01 - INFO - __main__ - Printing 3 examples
06/03/2022 19:45:01 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 19:45:01 - INFO - __main__ - ['false']
06/03/2022 19:45:01 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 19:45:01 - INFO - __main__ - ['false']
06/03/2022 19:45:01 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 19:45:01 - INFO - __main__ - ['false']
06/03/2022 19:45:01 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:45:02 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:45:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 19:45:03 - INFO - __main__ - Starting training!
06/03/2022 19:45:05 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 19:45:34 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_42_0.0005_8_predictions.txt
06/03/2022 19:45:34 - INFO - __main__ - Classification-F1 on test data: 0.4836
06/03/2022 19:45:35 - INFO - __main__ - prefix=wiki_qa_128_42, lr=0.0005, bsz=8, dev_performance=0.5625970798384592, test_performance=0.4836147723538647
06/03/2022 19:45:35 - INFO - __main__ - Running ... prefix=wiki_qa_128_42, lr=0.0003, bsz=8 ...
06/03/2022 19:45:36 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:45:36 - INFO - __main__ - Printing 3 examples
06/03/2022 19:45:36 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/03/2022 19:45:36 - INFO - __main__ - ['false']
06/03/2022 19:45:36 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/03/2022 19:45:36 - INFO - __main__ - ['false']
06/03/2022 19:45:36 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/03/2022 19:45:36 - INFO - __main__ - ['false']
06/03/2022 19:45:36 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:45:36 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:45:36 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 19:45:36 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:45:36 - INFO - __main__ - Printing 3 examples
06/03/2022 19:45:36 - INFO - __main__ -  [wiki_qa] question: what are the side effects for lyme disease [SEP] answer: Lyme disease is the most common tick-borne disease in the Northern Hemisphere .
06/03/2022 19:45:36 - INFO - __main__ - ['false']
06/03/2022 19:45:36 - INFO - __main__ -  [wiki_qa] question: how many gold medals usa won for basketball [SEP] answer: The USA won its first seven games at the 2006 FIBA World Championship in Japan before losing against Greece in the semi-finals, ending the competition with the bronze medal.
06/03/2022 19:45:36 - INFO - __main__ - ['false']
06/03/2022 19:45:36 - INFO - __main__ -  [wiki_qa] question: who played in the 2010 NBA Finals [SEP] answer: Repeated baskets from starters Kobe Bryant , Pau Gasol , and Ron Artest brought the Lakers close to victory in Game 1.
06/03/2022 19:45:36 - INFO - __main__ - ['false']
06/03/2022 19:45:36 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:45:36 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:45:36 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 19:45:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 19:45:47 - INFO - __main__ - Starting training!
06/03/2022 19:45:52 - INFO - __main__ - Step 10 Global step 10 Train loss 23.033619 on epoch=0
06/03/2022 19:45:57 - INFO - __main__ - Step 20 Global step 20 Train loss 18.401508 on epoch=1
06/03/2022 19:46:02 - INFO - __main__ - Step 30 Global step 30 Train loss 17.717388 on epoch=1
06/03/2022 19:46:07 - INFO - __main__ - Step 40 Global step 40 Train loss 15.925058 on epoch=2
06/03/2022 19:46:12 - INFO - __main__ - Step 50 Global step 50 Train loss 15.438904 on epoch=3
06/03/2022 19:46:50 - INFO - __main__ - Global step 50 Train loss 18.103296 Classification-F1 0.0 on epoch=3
06/03/2022 19:46:56 - INFO - __main__ - Step 60 Global step 60 Train loss 14.558973 on epoch=3
06/03/2022 19:47:01 - INFO - __main__ - Step 70 Global step 70 Train loss 12.314139 on epoch=4
06/03/2022 19:47:07 - INFO - __main__ - Step 80 Global step 80 Train loss 8.071741 on epoch=4
06/03/2022 19:47:12 - INFO - __main__ - Step 90 Global step 90 Train loss 1.040929 on epoch=5
06/03/2022 19:47:17 - INFO - __main__ - Step 100 Global step 100 Train loss 0.562676 on epoch=6
06/03/2022 19:47:20 - INFO - __main__ - Global step 100 Train loss 7.309692 Classification-F1 0.38709489051094886 on epoch=6
06/03/2022 19:47:26 - INFO - __main__ - Step 110 Global step 110 Train loss 0.447967 on epoch=6
06/03/2022 19:47:31 - INFO - __main__ - Step 120 Global step 120 Train loss 0.426720 on epoch=7
06/03/2022 19:47:37 - INFO - __main__ - Step 130 Global step 130 Train loss 0.426664 on epoch=8
06/03/2022 19:47:42 - INFO - __main__ - Step 140 Global step 140 Train loss 0.387824 on epoch=8
06/03/2022 19:47:47 - INFO - __main__ - Step 150 Global step 150 Train loss 0.337678 on epoch=9
06/03/2022 19:47:50 - INFO - __main__ - Global step 150 Train loss 0.405371 Classification-F1 0.3333333333333333 on epoch=9
06/03/2022 19:47:55 - INFO - __main__ - Step 160 Global step 160 Train loss 0.478812 on epoch=9
06/03/2022 19:48:01 - INFO - __main__ - Step 170 Global step 170 Train loss 0.491233 on epoch=10
06/03/2022 19:48:06 - INFO - __main__ - Step 180 Global step 180 Train loss 0.364494 on epoch=11
06/03/2022 19:48:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.365376 on epoch=11
06/03/2022 19:48:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.365058 on epoch=12
06/03/2022 19:48:19 - INFO - __main__ - Global step 200 Train loss 0.412995 Classification-F1 0.429800307219662 on epoch=12
06/03/2022 19:48:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.262679 on epoch=13
06/03/2022 19:48:31 - INFO - __main__ - Step 220 Global step 220 Train loss 0.245021 on epoch=13
06/03/2022 19:48:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.342198 on epoch=14
06/03/2022 19:48:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.177722 on epoch=14
06/03/2022 19:48:46 - INFO - __main__ - Step 250 Global step 250 Train loss 0.143380 on epoch=15
06/03/2022 19:48:49 - INFO - __main__ - Global step 250 Train loss 0.234200 Classification-F1 0.4396135265700484 on epoch=15
06/03/2022 19:48:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.149141 on epoch=16
06/03/2022 19:49:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.114855 on epoch=16
06/03/2022 19:49:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.090336 on epoch=17
06/03/2022 19:49:11 - INFO - __main__ - Step 290 Global step 290 Train loss 0.268700 on epoch=18
06/03/2022 19:49:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.078688 on epoch=18
06/03/2022 19:49:19 - INFO - __main__ - Global step 300 Train loss 0.140344 Classification-F1 0.5049787656998284 on epoch=18
06/03/2022 19:49:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.051907 on epoch=19
06/03/2022 19:49:31 - INFO - __main__ - Step 320 Global step 320 Train loss 0.012645 on epoch=19
06/03/2022 19:49:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.030024 on epoch=20
06/03/2022 19:49:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.112390 on epoch=21
06/03/2022 19:49:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.045547 on epoch=21
06/03/2022 19:49:50 - INFO - __main__ - Global step 350 Train loss 0.050503 Classification-F1 0.5148394479010227 on epoch=21
06/03/2022 19:49:56 - INFO - __main__ - Step 360 Global step 360 Train loss 0.045286 on epoch=22
06/03/2022 19:50:01 - INFO - __main__ - Step 370 Global step 370 Train loss 0.029513 on epoch=23
06/03/2022 19:50:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.020524 on epoch=23
06/03/2022 19:50:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.004614 on epoch=24
06/03/2022 19:50:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.031790 on epoch=24
06/03/2022 19:50:20 - INFO - __main__ - Global step 400 Train loss 0.026345 Classification-F1 0.7048968054700206 on epoch=24
06/03/2022 19:50:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.022242 on epoch=25
06/03/2022 19:50:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.002042 on epoch=26
06/03/2022 19:50:37 - INFO - __main__ - Step 430 Global step 430 Train loss 0.002753 on epoch=26
06/03/2022 19:50:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.022649 on epoch=27
06/03/2022 19:50:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.017214 on epoch=28
06/03/2022 19:50:51 - INFO - __main__ - Global step 450 Train loss 0.013380 Classification-F1 0.737379614460045 on epoch=28
06/03/2022 19:50:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.020587 on epoch=28
06/03/2022 19:51:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.014062 on epoch=29
06/03/2022 19:51:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.019762 on epoch=29
06/03/2022 19:51:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.002709 on epoch=30
06/03/2022 19:51:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.003082 on epoch=31
06/03/2022 19:51:22 - INFO - __main__ - Global step 500 Train loss 0.012040 Classification-F1 0.6243865418669365 on epoch=31
06/03/2022 19:51:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.014473 on epoch=31
06/03/2022 19:51:33 - INFO - __main__ - Step 520 Global step 520 Train loss 0.000816 on epoch=32
06/03/2022 19:51:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.000881 on epoch=33
06/03/2022 19:51:44 - INFO - __main__ - Step 540 Global step 540 Train loss 0.000586 on epoch=33
06/03/2022 19:51:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.000570 on epoch=34
06/03/2022 19:51:52 - INFO - __main__ - Global step 550 Train loss 0.003465 Classification-F1 0.6163836163836163 on epoch=34
06/03/2022 19:51:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.008442 on epoch=34
06/03/2022 19:52:03 - INFO - __main__ - Step 570 Global step 570 Train loss 0.000619 on epoch=35
06/03/2022 19:52:08 - INFO - __main__ - Step 580 Global step 580 Train loss 0.001992 on epoch=36
06/03/2022 19:52:13 - INFO - __main__ - Step 590 Global step 590 Train loss 0.000248 on epoch=36
06/03/2022 19:52:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000419 on epoch=37
06/03/2022 19:52:22 - INFO - __main__ - Global step 600 Train loss 0.002344 Classification-F1 0.6645474399417617 on epoch=37
06/03/2022 19:52:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.000228 on epoch=38
06/03/2022 19:52:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.019413 on epoch=38
06/03/2022 19:52:38 - INFO - __main__ - Step 630 Global step 630 Train loss 0.031112 on epoch=39
06/03/2022 19:52:43 - INFO - __main__ - Step 640 Global step 640 Train loss 0.005958 on epoch=39
06/03/2022 19:52:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000999 on epoch=40
06/03/2022 19:52:51 - INFO - __main__ - Global step 650 Train loss 0.011542 Classification-F1 0.6659027247262541 on epoch=40
06/03/2022 19:52:57 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000837 on epoch=41
06/03/2022 19:53:02 - INFO - __main__ - Step 670 Global step 670 Train loss 0.000138 on epoch=41
06/03/2022 19:53:08 - INFO - __main__ - Step 680 Global step 680 Train loss 0.078895 on epoch=42
06/03/2022 19:53:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.001406 on epoch=43
06/03/2022 19:53:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.004485 on epoch=43
06/03/2022 19:53:21 - INFO - __main__ - Global step 700 Train loss 0.017152 Classification-F1 0.5544852075166558 on epoch=43
06/03/2022 19:53:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000415 on epoch=44
06/03/2022 19:53:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.001177 on epoch=44
06/03/2022 19:53:38 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000320 on epoch=45
06/03/2022 19:53:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000226 on epoch=46
06/03/2022 19:53:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.012678 on epoch=46
06/03/2022 19:53:51 - INFO - __main__ - Global step 750 Train loss 0.002963 Classification-F1 0.6103896103896104 on epoch=46
06/03/2022 19:53:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000619 on epoch=47
06/03/2022 19:54:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000173 on epoch=48
06/03/2022 19:54:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000751 on epoch=48
06/03/2022 19:54:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000061 on epoch=49
06/03/2022 19:54:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000141 on epoch=49
06/03/2022 19:54:22 - INFO - __main__ - Global step 800 Train loss 0.000349 Classification-F1 0.6939117126596203 on epoch=49
06/03/2022 19:54:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000115 on epoch=50
06/03/2022 19:54:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000082 on epoch=51
06/03/2022 19:54:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000045 on epoch=51
06/03/2022 19:54:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000085 on epoch=52
06/03/2022 19:54:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000023 on epoch=53
06/03/2022 19:54:52 - INFO - __main__ - Global step 850 Train loss 0.000070 Classification-F1 0.6893005429575216 on epoch=53
06/03/2022 19:54:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000159 on epoch=53
06/03/2022 19:55:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000066 on epoch=54
06/03/2022 19:55:08 - INFO - __main__ - Step 880 Global step 880 Train loss 0.029452 on epoch=54
06/03/2022 19:55:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000620 on epoch=55
06/03/2022 19:55:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000018 on epoch=56
06/03/2022 19:55:22 - INFO - __main__ - Global step 900 Train loss 0.006063 Classification-F1 0.6728302192024589 on epoch=56
06/03/2022 19:55:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000040 on epoch=56
06/03/2022 19:55:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.001159 on epoch=57
06/03/2022 19:55:38 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000646 on epoch=58
06/03/2022 19:55:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000052 on epoch=58
06/03/2022 19:55:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000124 on epoch=59
06/03/2022 19:55:52 - INFO - __main__ - Global step 950 Train loss 0.000404 Classification-F1 0.6715123361541085 on epoch=59
06/03/2022 19:55:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000014 on epoch=59
06/03/2022 19:56:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.011659 on epoch=60
06/03/2022 19:56:08 - INFO - __main__ - Step 980 Global step 980 Train loss 0.004646 on epoch=61
06/03/2022 19:56:13 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000236 on epoch=61
06/03/2022 19:56:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000781 on epoch=62
06/03/2022 19:56:20 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:56:20 - INFO - __main__ - Printing 3 examples
06/03/2022 19:56:20 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/03/2022 19:56:20 - INFO - __main__ - ['false']
06/03/2022 19:56:20 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/03/2022 19:56:20 - INFO - __main__ - ['false']
06/03/2022 19:56:20 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/03/2022 19:56:20 - INFO - __main__ - ['false']
06/03/2022 19:56:20 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:56:20 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:56:20 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 19:56:20 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:56:20 - INFO - __main__ - Printing 3 examples
06/03/2022 19:56:20 - INFO - __main__ -  [wiki_qa] question: what are the side effects for lyme disease [SEP] answer: Lyme disease is the most common tick-borne disease in the Northern Hemisphere .
06/03/2022 19:56:20 - INFO - __main__ - ['false']
06/03/2022 19:56:20 - INFO - __main__ -  [wiki_qa] question: how many gold medals usa won for basketball [SEP] answer: The USA won its first seven games at the 2006 FIBA World Championship in Japan before losing against Greece in the semi-finals, ending the competition with the bronze medal.
06/03/2022 19:56:20 - INFO - __main__ - ['false']
06/03/2022 19:56:20 - INFO - __main__ -  [wiki_qa] question: who played in the 2010 NBA Finals [SEP] answer: Repeated baskets from starters Kobe Bryant , Pau Gasol , and Ron Artest brought the Lakers close to victory in Game 1.
06/03/2022 19:56:20 - INFO - __main__ - ['false']
06/03/2022 19:56:20 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:56:20 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:56:21 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 19:56:22 - INFO - __main__ - Global step 1000 Train loss 0.003467 Classification-F1 0.6352067868504772 on epoch=62
06/03/2022 19:56:22 - INFO - __main__ - save last model!
06/03/2022 19:56:29 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 19:56:30 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 19:56:30 - INFO - __main__ - Printing 3 examples
06/03/2022 19:56:30 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 19:56:30 - INFO - __main__ - ['false']
06/03/2022 19:56:30 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 19:56:30 - INFO - __main__ - ['false']
06/03/2022 19:56:30 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 19:56:30 - INFO - __main__ - ['false']
06/03/2022 19:56:30 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:56:31 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:56:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 19:56:32 - INFO - __main__ - Starting training!
06/03/2022 19:56:35 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 19:57:05 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_42_0.0003_8_predictions.txt
06/03/2022 19:57:05 - INFO - __main__ - Classification-F1 on test data: 0.5316
06/03/2022 19:57:06 - INFO - __main__ - prefix=wiki_qa_128_42, lr=0.0003, bsz=8, dev_performance=0.737379614460045, test_performance=0.5316385652887745
06/03/2022 19:57:06 - INFO - __main__ - Running ... prefix=wiki_qa_128_42, lr=0.0002, bsz=8 ...
06/03/2022 19:57:07 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:57:07 - INFO - __main__ - Printing 3 examples
06/03/2022 19:57:07 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/03/2022 19:57:07 - INFO - __main__ - ['false']
06/03/2022 19:57:07 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/03/2022 19:57:07 - INFO - __main__ - ['false']
06/03/2022 19:57:07 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/03/2022 19:57:07 - INFO - __main__ - ['false']
06/03/2022 19:57:07 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:57:07 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:57:07 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 19:57:07 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 19:57:07 - INFO - __main__ - Printing 3 examples
06/03/2022 19:57:07 - INFO - __main__ -  [wiki_qa] question: what are the side effects for lyme disease [SEP] answer: Lyme disease is the most common tick-borne disease in the Northern Hemisphere .
06/03/2022 19:57:07 - INFO - __main__ - ['false']
06/03/2022 19:57:07 - INFO - __main__ -  [wiki_qa] question: how many gold medals usa won for basketball [SEP] answer: The USA won its first seven games at the 2006 FIBA World Championship in Japan before losing against Greece in the semi-finals, ending the competition with the bronze medal.
06/03/2022 19:57:07 - INFO - __main__ - ['false']
06/03/2022 19:57:07 - INFO - __main__ -  [wiki_qa] question: who played in the 2010 NBA Finals [SEP] answer: Repeated baskets from starters Kobe Bryant , Pau Gasol , and Ron Artest brought the Lakers close to victory in Game 1.
06/03/2022 19:57:07 - INFO - __main__ - ['false']
06/03/2022 19:57:07 - INFO - __main__ - Tokenizing Input ...
06/03/2022 19:57:08 - INFO - __main__ - Tokenizing Output ...
06/03/2022 19:57:08 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 19:57:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 19:57:22 - INFO - __main__ - Starting training!
06/03/2022 19:57:26 - INFO - __main__ - Step 10 Global step 10 Train loss 23.219931 on epoch=0
06/03/2022 19:57:31 - INFO - __main__ - Step 20 Global step 20 Train loss 19.598932 on epoch=1
06/03/2022 19:57:37 - INFO - __main__ - Step 30 Global step 30 Train loss 17.911915 on epoch=1
06/03/2022 19:57:42 - INFO - __main__ - Step 40 Global step 40 Train loss 16.324457 on epoch=2
06/03/2022 19:57:47 - INFO - __main__ - Step 50 Global step 50 Train loss 15.265974 on epoch=3
06/03/2022 19:58:36 - INFO - __main__ - Global step 50 Train loss 18.464241 Classification-F1 0.0 on epoch=3
06/03/2022 19:58:41 - INFO - __main__ - Step 60 Global step 60 Train loss 15.691317 on epoch=3
06/03/2022 19:58:47 - INFO - __main__ - Step 70 Global step 70 Train loss 14.685339 on epoch=4
06/03/2022 19:58:53 - INFO - __main__ - Step 80 Global step 80 Train loss 13.020676 on epoch=4
06/03/2022 19:58:58 - INFO - __main__ - Step 90 Global step 90 Train loss 12.467200 on epoch=5
06/03/2022 19:59:03 - INFO - __main__ - Step 100 Global step 100 Train loss 9.501482 on epoch=6
06/03/2022 19:59:16 - INFO - __main__ - Global step 100 Train loss 13.073202 Classification-F1 0.03079015367877057 on epoch=6
06/03/2022 19:59:22 - INFO - __main__ - Step 110 Global step 110 Train loss 2.254734 on epoch=6
06/03/2022 19:59:27 - INFO - __main__ - Step 120 Global step 120 Train loss 0.850082 on epoch=7
06/03/2022 19:59:32 - INFO - __main__ - Step 130 Global step 130 Train loss 0.548378 on epoch=8
06/03/2022 19:59:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.497684 on epoch=8
06/03/2022 19:59:43 - INFO - __main__ - Step 150 Global step 150 Train loss 0.643598 on epoch=9
06/03/2022 19:59:46 - INFO - __main__ - Global step 150 Train loss 0.958895 Classification-F1 0.3977126900530763 on epoch=9
06/03/2022 19:59:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.985140 on epoch=9
06/03/2022 19:59:56 - INFO - __main__ - Step 170 Global step 170 Train loss 0.532530 on epoch=10
06/03/2022 20:00:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.554330 on epoch=11
06/03/2022 20:00:07 - INFO - __main__ - Step 190 Global step 190 Train loss 0.530002 on epoch=11
06/03/2022 20:00:13 - INFO - __main__ - Step 200 Global step 200 Train loss 0.494615 on epoch=12
06/03/2022 20:00:16 - INFO - __main__ - Global step 200 Train loss 0.619323 Classification-F1 0.36318407960199 on epoch=12
06/03/2022 20:00:21 - INFO - __main__ - Step 210 Global step 210 Train loss 0.420012 on epoch=13
06/03/2022 20:00:26 - INFO - __main__ - Step 220 Global step 220 Train loss 0.376220 on epoch=13
06/03/2022 20:00:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.424975 on epoch=14
06/03/2022 20:00:38 - INFO - __main__ - Step 240 Global step 240 Train loss 0.347742 on epoch=14
06/03/2022 20:00:43 - INFO - __main__ - Step 250 Global step 250 Train loss 0.479577 on epoch=15
06/03/2022 20:00:46 - INFO - __main__ - Global step 250 Train loss 0.409705 Classification-F1 0.3333333333333333 on epoch=15
06/03/2022 20:00:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.423876 on epoch=16
06/03/2022 20:00:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.409396 on epoch=16
06/03/2022 20:01:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.420700 on epoch=17
06/03/2022 20:01:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.395405 on epoch=18
06/03/2022 20:01:13 - INFO - __main__ - Step 300 Global step 300 Train loss 0.422384 on epoch=18
06/03/2022 20:01:16 - INFO - __main__ - Global step 300 Train loss 0.414352 Classification-F1 0.34195559333697656 on epoch=18
06/03/2022 20:01:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.322595 on epoch=19
06/03/2022 20:01:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.356402 on epoch=19
06/03/2022 20:01:32 - INFO - __main__ - Step 330 Global step 330 Train loss 0.329280 on epoch=20
06/03/2022 20:01:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.403476 on epoch=21
06/03/2022 20:01:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.346232 on epoch=21
06/03/2022 20:01:46 - INFO - __main__ - Global step 350 Train loss 0.351597 Classification-F1 0.5820310677800066 on epoch=21
06/03/2022 20:01:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.309632 on epoch=22
06/03/2022 20:01:57 - INFO - __main__ - Step 370 Global step 370 Train loss 0.282223 on epoch=23
06/03/2022 20:02:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.243868 on epoch=23
06/03/2022 20:02:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.270147 on epoch=24
06/03/2022 20:02:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.355542 on epoch=24
06/03/2022 20:02:16 - INFO - __main__ - Global step 400 Train loss 0.292282 Classification-F1 0.45639387390773273 on epoch=24
06/03/2022 20:02:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.265688 on epoch=25
06/03/2022 20:02:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.208686 on epoch=26
06/03/2022 20:02:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.212186 on epoch=26
06/03/2022 20:02:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.189575 on epoch=27
06/03/2022 20:02:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.212321 on epoch=28
06/03/2022 20:02:46 - INFO - __main__ - Global step 450 Train loss 0.217691 Classification-F1 0.713861370978855 on epoch=28
06/03/2022 20:02:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.185981 on epoch=28
06/03/2022 20:02:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.181081 on epoch=29
06/03/2022 20:03:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.191681 on epoch=29
06/03/2022 20:03:09 - INFO - __main__ - Step 490 Global step 490 Train loss 0.213302 on epoch=30
06/03/2022 20:03:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.124914 on epoch=31
06/03/2022 20:03:17 - INFO - __main__ - Global step 500 Train loss 0.179392 Classification-F1 0.7306828709155714 on epoch=31
06/03/2022 20:03:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.147590 on epoch=31
06/03/2022 20:03:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.255035 on epoch=32
06/03/2022 20:03:34 - INFO - __main__ - Step 530 Global step 530 Train loss 0.338106 on epoch=33
06/03/2022 20:03:39 - INFO - __main__ - Step 540 Global step 540 Train loss 0.287218 on epoch=33
06/03/2022 20:03:45 - INFO - __main__ - Step 550 Global step 550 Train loss 0.289842 on epoch=34
06/03/2022 20:03:48 - INFO - __main__ - Global step 550 Train loss 0.263558 Classification-F1 0.6403008513100257 on epoch=34
06/03/2022 20:03:53 - INFO - __main__ - Step 560 Global step 560 Train loss 0.284298 on epoch=34
06/03/2022 20:03:59 - INFO - __main__ - Step 570 Global step 570 Train loss 0.208931 on epoch=35
06/03/2022 20:04:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.153222 on epoch=36
06/03/2022 20:04:10 - INFO - __main__ - Step 590 Global step 590 Train loss 0.143608 on epoch=36
06/03/2022 20:04:15 - INFO - __main__ - Step 600 Global step 600 Train loss 0.158178 on epoch=37
06/03/2022 20:04:18 - INFO - __main__ - Global step 600 Train loss 0.189647 Classification-F1 0.7432376132207941 on epoch=37
06/03/2022 20:04:24 - INFO - __main__ - Step 610 Global step 610 Train loss 0.139935 on epoch=38
06/03/2022 20:04:30 - INFO - __main__ - Step 620 Global step 620 Train loss 0.131156 on epoch=38
06/03/2022 20:04:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.225356 on epoch=39
06/03/2022 20:04:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.140497 on epoch=39
06/03/2022 20:04:46 - INFO - __main__ - Step 650 Global step 650 Train loss 0.189350 on epoch=40
06/03/2022 20:04:49 - INFO - __main__ - Global step 650 Train loss 0.165259 Classification-F1 0.6755386565272496 on epoch=40
06/03/2022 20:04:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.306737 on epoch=41
06/03/2022 20:05:00 - INFO - __main__ - Step 670 Global step 670 Train loss 0.317104 on epoch=41
06/03/2022 20:05:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.292021 on epoch=42
06/03/2022 20:05:11 - INFO - __main__ - Step 690 Global step 690 Train loss 0.206337 on epoch=43
06/03/2022 20:05:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.241696 on epoch=43
06/03/2022 20:05:19 - INFO - __main__ - Global step 700 Train loss 0.272779 Classification-F1 0.6565953369530502 on epoch=43
06/03/2022 20:05:25 - INFO - __main__ - Step 710 Global step 710 Train loss 0.235413 on epoch=44
06/03/2022 20:05:30 - INFO - __main__ - Step 720 Global step 720 Train loss 0.131635 on epoch=44
06/03/2022 20:05:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.126553 on epoch=45
06/03/2022 20:05:41 - INFO - __main__ - Step 740 Global step 740 Train loss 0.131686 on epoch=46
06/03/2022 20:05:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.167449 on epoch=46
06/03/2022 20:05:49 - INFO - __main__ - Global step 750 Train loss 0.158547 Classification-F1 0.5334548294714918 on epoch=46
06/03/2022 20:05:55 - INFO - __main__ - Step 760 Global step 760 Train loss 0.170163 on epoch=47
06/03/2022 20:06:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.140262 on epoch=48
06/03/2022 20:06:06 - INFO - __main__ - Step 780 Global step 780 Train loss 0.085292 on epoch=48
06/03/2022 20:06:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.127978 on epoch=49
06/03/2022 20:06:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.060750 on epoch=49
06/03/2022 20:06:20 - INFO - __main__ - Global step 800 Train loss 0.116889 Classification-F1 0.7849954952891414 on epoch=49
06/03/2022 20:06:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.099007 on epoch=50
06/03/2022 20:06:31 - INFO - __main__ - Step 820 Global step 820 Train loss 0.105232 on epoch=51
06/03/2022 20:06:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.073359 on epoch=51
06/03/2022 20:06:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.102006 on epoch=52
06/03/2022 20:06:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.142303 on epoch=53
06/03/2022 20:06:50 - INFO - __main__ - Global step 850 Train loss 0.104381 Classification-F1 0.6877801536390276 on epoch=53
06/03/2022 20:06:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.107766 on epoch=53
06/03/2022 20:07:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.077395 on epoch=54
06/03/2022 20:07:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.074806 on epoch=54
06/03/2022 20:07:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.114978 on epoch=55
06/03/2022 20:07:17 - INFO - __main__ - Step 900 Global step 900 Train loss 0.048220 on epoch=56
06/03/2022 20:07:20 - INFO - __main__ - Global step 900 Train loss 0.084633 Classification-F1 0.6775668237160051 on epoch=56
06/03/2022 20:07:26 - INFO - __main__ - Step 910 Global step 910 Train loss 0.067182 on epoch=56
06/03/2022 20:07:31 - INFO - __main__ - Step 920 Global step 920 Train loss 0.064754 on epoch=57
06/03/2022 20:07:37 - INFO - __main__ - Step 930 Global step 930 Train loss 0.108473 on epoch=58
06/03/2022 20:07:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.085636 on epoch=58
06/03/2022 20:07:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.145088 on epoch=59
06/03/2022 20:07:50 - INFO - __main__ - Global step 950 Train loss 0.094227 Classification-F1 0.6333748443337484 on epoch=59
06/03/2022 20:07:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.240666 on epoch=59
06/03/2022 20:08:01 - INFO - __main__ - Step 970 Global step 970 Train loss 0.216971 on epoch=60
06/03/2022 20:08:07 - INFO - __main__ - Step 980 Global step 980 Train loss 0.180776 on epoch=61
06/03/2022 20:08:13 - INFO - __main__ - Step 990 Global step 990 Train loss 0.281889 on epoch=61
06/03/2022 20:08:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.413587 on epoch=62
06/03/2022 20:08:19 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:08:19 - INFO - __main__ - Printing 3 examples
06/03/2022 20:08:19 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/03/2022 20:08:19 - INFO - __main__ - ['false']
06/03/2022 20:08:19 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/03/2022 20:08:19 - INFO - __main__ - ['false']
06/03/2022 20:08:19 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/03/2022 20:08:19 - INFO - __main__ - ['false']
06/03/2022 20:08:19 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:08:19 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:08:19 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 20:08:19 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:08:19 - INFO - __main__ - Printing 3 examples
06/03/2022 20:08:19 - INFO - __main__ -  [wiki_qa] question: what are the side effects for lyme disease [SEP] answer: Lyme disease is the most common tick-borne disease in the Northern Hemisphere .
06/03/2022 20:08:19 - INFO - __main__ - ['false']
06/03/2022 20:08:19 - INFO - __main__ -  [wiki_qa] question: how many gold medals usa won for basketball [SEP] answer: The USA won its first seven games at the 2006 FIBA World Championship in Japan before losing against Greece in the semi-finals, ending the competition with the bronze medal.
06/03/2022 20:08:19 - INFO - __main__ - ['false']
06/03/2022 20:08:19 - INFO - __main__ -  [wiki_qa] question: who played in the 2010 NBA Finals [SEP] answer: Repeated baskets from starters Kobe Bryant , Pau Gasol , and Ron Artest brought the Lakers close to victory in Game 1.
06/03/2022 20:08:19 - INFO - __main__ - ['false']
06/03/2022 20:08:19 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:08:20 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:08:20 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 20:08:21 - INFO - __main__ - Global step 1000 Train loss 0.266778 Classification-F1 0.4829723518350859 on epoch=62
06/03/2022 20:08:21 - INFO - __main__ - save last model!
06/03/2022 20:08:27 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 20:08:28 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 20:08:28 - INFO - __main__ - Printing 3 examples
06/03/2022 20:08:28 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 20:08:28 - INFO - __main__ - ['false']
06/03/2022 20:08:28 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 20:08:28 - INFO - __main__ - ['false']
06/03/2022 20:08:28 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 20:08:28 - INFO - __main__ - ['false']
06/03/2022 20:08:28 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:08:30 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:08:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 20:08:32 - INFO - __main__ - Starting training!
06/03/2022 20:08:32 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 20:09:02 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_42_0.0002_8_predictions.txt
06/03/2022 20:09:02 - INFO - __main__ - Classification-F1 on test data: 0.5428
06/03/2022 20:09:02 - INFO - __main__ - prefix=wiki_qa_128_42, lr=0.0002, bsz=8, dev_performance=0.7849954952891414, test_performance=0.5428061053789327
06/03/2022 20:09:02 - INFO - __main__ - Running ... prefix=wiki_qa_128_42, lr=0.0001, bsz=8 ...
06/03/2022 20:09:03 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:09:03 - INFO - __main__ - Printing 3 examples
06/03/2022 20:09:03 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
06/03/2022 20:09:03 - INFO - __main__ - ['false']
06/03/2022 20:09:03 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
06/03/2022 20:09:03 - INFO - __main__ - ['false']
06/03/2022 20:09:03 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
06/03/2022 20:09:03 - INFO - __main__ - ['false']
06/03/2022 20:09:03 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:09:03 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:09:03 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 20:09:03 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:09:03 - INFO - __main__ - Printing 3 examples
06/03/2022 20:09:03 - INFO - __main__ -  [wiki_qa] question: what are the side effects for lyme disease [SEP] answer: Lyme disease is the most common tick-borne disease in the Northern Hemisphere .
06/03/2022 20:09:03 - INFO - __main__ - ['false']
06/03/2022 20:09:03 - INFO - __main__ -  [wiki_qa] question: how many gold medals usa won for basketball [SEP] answer: The USA won its first seven games at the 2006 FIBA World Championship in Japan before losing against Greece in the semi-finals, ending the competition with the bronze medal.
06/03/2022 20:09:03 - INFO - __main__ - ['false']
06/03/2022 20:09:03 - INFO - __main__ -  [wiki_qa] question: who played in the 2010 NBA Finals [SEP] answer: Repeated baskets from starters Kobe Bryant , Pau Gasol , and Ron Artest brought the Lakers close to victory in Game 1.
06/03/2022 20:09:03 - INFO - __main__ - ['false']
06/03/2022 20:09:03 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:09:03 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:09:04 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 20:09:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 20:09:14 - INFO - __main__ - Starting training!
06/03/2022 20:09:19 - INFO - __main__ - Step 10 Global step 10 Train loss 24.349720 on epoch=0
06/03/2022 20:09:24 - INFO - __main__ - Step 20 Global step 20 Train loss 21.000286 on epoch=1
06/03/2022 20:09:29 - INFO - __main__ - Step 30 Global step 30 Train loss 18.887012 on epoch=1
06/03/2022 20:09:35 - INFO - __main__ - Step 40 Global step 40 Train loss 18.070232 on epoch=2
06/03/2022 20:09:40 - INFO - __main__ - Step 50 Global step 50 Train loss 17.619839 on epoch=3
06/03/2022 20:10:46 - INFO - __main__ - Global step 50 Train loss 19.985418 Classification-F1 0.0 on epoch=3
06/03/2022 20:10:52 - INFO - __main__ - Step 60 Global step 60 Train loss 16.831289 on epoch=3
06/03/2022 20:10:57 - INFO - __main__ - Step 70 Global step 70 Train loss 17.302082 on epoch=4
06/03/2022 20:11:03 - INFO - __main__ - Step 80 Global step 80 Train loss 16.050268 on epoch=4
06/03/2022 20:11:08 - INFO - __main__ - Step 90 Global step 90 Train loss 15.917763 on epoch=5
06/03/2022 20:11:14 - INFO - __main__ - Step 100 Global step 100 Train loss 15.919569 on epoch=6
06/03/2022 20:11:57 - INFO - __main__ - Global step 100 Train loss 16.404196 Classification-F1 0.0 on epoch=6
06/03/2022 20:12:03 - INFO - __main__ - Step 110 Global step 110 Train loss 15.283099 on epoch=6
06/03/2022 20:12:08 - INFO - __main__ - Step 120 Global step 120 Train loss 14.844480 on epoch=7
06/03/2022 20:12:13 - INFO - __main__ - Step 130 Global step 130 Train loss 14.648771 on epoch=8
06/03/2022 20:12:19 - INFO - __main__ - Step 140 Global step 140 Train loss 14.016167 on epoch=8
06/03/2022 20:12:24 - INFO - __main__ - Step 150 Global step 150 Train loss 13.206705 on epoch=9
06/03/2022 20:12:59 - INFO - __main__ - Global step 150 Train loss 14.399844 Classification-F1 0.0 on epoch=9
06/03/2022 20:13:05 - INFO - __main__ - Step 160 Global step 160 Train loss 13.050924 on epoch=9
06/03/2022 20:13:10 - INFO - __main__ - Step 170 Global step 170 Train loss 12.729757 on epoch=10
06/03/2022 20:13:16 - INFO - __main__ - Step 180 Global step 180 Train loss 10.885494 on epoch=11
06/03/2022 20:13:21 - INFO - __main__ - Step 190 Global step 190 Train loss 6.199118 on epoch=11
06/03/2022 20:13:27 - INFO - __main__ - Step 200 Global step 200 Train loss 2.078449 on epoch=12
06/03/2022 20:13:29 - INFO - __main__ - Global step 200 Train loss 8.988749 Classification-F1 0.45003929787791463 on epoch=12
06/03/2022 20:13:35 - INFO - __main__ - Step 210 Global step 210 Train loss 1.420813 on epoch=13
06/03/2022 20:13:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.830996 on epoch=13
06/03/2022 20:13:46 - INFO - __main__ - Step 230 Global step 230 Train loss 0.620624 on epoch=14
06/03/2022 20:13:51 - INFO - __main__ - Step 240 Global step 240 Train loss 0.662934 on epoch=14
06/03/2022 20:13:57 - INFO - __main__ - Step 250 Global step 250 Train loss 0.525244 on epoch=15
06/03/2022 20:14:00 - INFO - __main__ - Global step 250 Train loss 0.812122 Classification-F1 0.43468822516655437 on epoch=15
06/03/2022 20:14:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.519669 on epoch=16
06/03/2022 20:14:10 - INFO - __main__ - Step 270 Global step 270 Train loss 0.511967 on epoch=16
06/03/2022 20:14:16 - INFO - __main__ - Step 280 Global step 280 Train loss 0.605023 on epoch=17
06/03/2022 20:14:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.603685 on epoch=18
06/03/2022 20:14:26 - INFO - __main__ - Step 300 Global step 300 Train loss 0.447473 on epoch=18
06/03/2022 20:14:29 - INFO - __main__ - Global step 300 Train loss 0.537563 Classification-F1 0.36516753625488524 on epoch=18
06/03/2022 20:14:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.434333 on epoch=19
06/03/2022 20:14:40 - INFO - __main__ - Step 320 Global step 320 Train loss 0.451932 on epoch=19
06/03/2022 20:14:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.417786 on epoch=20
06/03/2022 20:14:50 - INFO - __main__ - Step 340 Global step 340 Train loss 0.327153 on epoch=21
06/03/2022 20:14:56 - INFO - __main__ - Step 350 Global step 350 Train loss 0.448751 on epoch=21
06/03/2022 20:14:59 - INFO - __main__ - Global step 350 Train loss 0.415991 Classification-F1 0.6182325098878299 on epoch=21
06/03/2022 20:15:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.316317 on epoch=22
06/03/2022 20:15:10 - INFO - __main__ - Step 370 Global step 370 Train loss 0.558955 on epoch=23
06/03/2022 20:15:15 - INFO - __main__ - Step 380 Global step 380 Train loss 0.276012 on epoch=23
06/03/2022 20:15:21 - INFO - __main__ - Step 390 Global step 390 Train loss 0.258318 on epoch=24
06/03/2022 20:15:26 - INFO - __main__ - Step 400 Global step 400 Train loss 0.324657 on epoch=24
06/03/2022 20:15:29 - INFO - __main__ - Global step 400 Train loss 0.346852 Classification-F1 0.7225504113812947 on epoch=24
06/03/2022 20:15:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.265381 on epoch=25
06/03/2022 20:15:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.295259 on epoch=26
06/03/2022 20:15:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.477074 on epoch=26
06/03/2022 20:15:51 - INFO - __main__ - Step 440 Global step 440 Train loss 0.229079 on epoch=27
06/03/2022 20:15:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.213712 on epoch=28
06/03/2022 20:15:59 - INFO - __main__ - Global step 450 Train loss 0.296101 Classification-F1 0.5885088919288647 on epoch=28
06/03/2022 20:16:04 - INFO - __main__ - Step 460 Global step 460 Train loss 0.221363 on epoch=28
06/03/2022 20:16:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.198365 on epoch=29
06/03/2022 20:16:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.163016 on epoch=29
06/03/2022 20:16:21 - INFO - __main__ - Step 490 Global step 490 Train loss 0.242230 on epoch=30
06/03/2022 20:16:26 - INFO - __main__ - Step 500 Global step 500 Train loss 0.204091 on epoch=31
06/03/2022 20:16:29 - INFO - __main__ - Global step 500 Train loss 0.205813 Classification-F1 0.5693860386879731 on epoch=31
06/03/2022 20:16:34 - INFO - __main__ - Step 510 Global step 510 Train loss 0.220106 on epoch=31
06/03/2022 20:16:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.158192 on epoch=32
06/03/2022 20:16:45 - INFO - __main__ - Step 530 Global step 530 Train loss 0.212759 on epoch=33
06/03/2022 20:16:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.176789 on epoch=33
06/03/2022 20:16:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.113907 on epoch=34
06/03/2022 20:16:59 - INFO - __main__ - Global step 550 Train loss 0.176351 Classification-F1 0.5632007799986072 on epoch=34
06/03/2022 20:17:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.120359 on epoch=34
06/03/2022 20:17:10 - INFO - __main__ - Step 570 Global step 570 Train loss 0.186095 on epoch=35
06/03/2022 20:17:15 - INFO - __main__ - Step 580 Global step 580 Train loss 0.148701 on epoch=36
06/03/2022 20:17:21 - INFO - __main__ - Step 590 Global step 590 Train loss 0.083504 on epoch=36
06/03/2022 20:17:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.085230 on epoch=37
06/03/2022 20:17:29 - INFO - __main__ - Global step 600 Train loss 0.124778 Classification-F1 0.5077994631067257 on epoch=37
06/03/2022 20:17:34 - INFO - __main__ - Step 610 Global step 610 Train loss 0.117976 on epoch=38
06/03/2022 20:17:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.118089 on epoch=38
06/03/2022 20:17:45 - INFO - __main__ - Step 630 Global step 630 Train loss 0.079419 on epoch=39
06/03/2022 20:17:51 - INFO - __main__ - Step 640 Global step 640 Train loss 0.097618 on epoch=39
06/03/2022 20:17:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.063338 on epoch=40
06/03/2022 20:17:59 - INFO - __main__ - Global step 650 Train loss 0.095288 Classification-F1 0.5544852075166558 on epoch=40
06/03/2022 20:18:04 - INFO - __main__ - Step 660 Global step 660 Train loss 0.042936 on epoch=41
06/03/2022 20:18:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.140951 on epoch=41
06/03/2022 20:18:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.432263 on epoch=42
06/03/2022 20:18:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.667236 on epoch=43
06/03/2022 20:18:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.516283 on epoch=43
06/03/2022 20:18:29 - INFO - __main__ - Global step 700 Train loss 0.359934 Classification-F1 0.47462421654001885 on epoch=43
06/03/2022 20:18:34 - INFO - __main__ - Step 710 Global step 710 Train loss 1.112279 on epoch=44
06/03/2022 20:18:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.643944 on epoch=44
06/03/2022 20:18:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.411041 on epoch=45
06/03/2022 20:18:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.311805 on epoch=46
06/03/2022 20:18:56 - INFO - __main__ - Step 750 Global step 750 Train loss 0.328389 on epoch=46
06/03/2022 20:18:58 - INFO - __main__ - Global step 750 Train loss 0.561492 Classification-F1 0.5876218736752862 on epoch=46
06/03/2022 20:19:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.310003 on epoch=47
06/03/2022 20:19:09 - INFO - __main__ - Step 770 Global step 770 Train loss 0.312132 on epoch=48
06/03/2022 20:19:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.329483 on epoch=48
06/03/2022 20:19:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.351324 on epoch=49
06/03/2022 20:19:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.257201 on epoch=49
06/03/2022 20:19:28 - INFO - __main__ - Global step 800 Train loss 0.312029 Classification-F1 0.40963382782578167 on epoch=49
06/03/2022 20:19:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.291196 on epoch=50
06/03/2022 20:19:39 - INFO - __main__ - Step 820 Global step 820 Train loss 0.290485 on epoch=51
06/03/2022 20:19:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.237713 on epoch=51
06/03/2022 20:19:50 - INFO - __main__ - Step 840 Global step 840 Train loss 0.233358 on epoch=52
06/03/2022 20:19:55 - INFO - __main__ - Step 850 Global step 850 Train loss 0.327967 on epoch=53
06/03/2022 20:19:58 - INFO - __main__ - Global step 850 Train loss 0.276144 Classification-F1 0.5780125142972482 on epoch=53
06/03/2022 20:20:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.301274 on epoch=53
06/03/2022 20:20:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.448858 on epoch=54
06/03/2022 20:20:14 - INFO - __main__ - Step 880 Global step 880 Train loss 0.333591 on epoch=54
06/03/2022 20:20:19 - INFO - __main__ - Step 890 Global step 890 Train loss 0.303676 on epoch=55
06/03/2022 20:20:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.330959 on epoch=56
06/03/2022 20:20:28 - INFO - __main__ - Global step 900 Train loss 0.343672 Classification-F1 0.5630099444052933 on epoch=56
06/03/2022 20:20:33 - INFO - __main__ - Step 910 Global step 910 Train loss 0.346270 on epoch=56
06/03/2022 20:20:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.323912 on epoch=57
06/03/2022 20:20:44 - INFO - __main__ - Step 930 Global step 930 Train loss 0.358337 on epoch=58
06/03/2022 20:20:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.382069 on epoch=58
06/03/2022 20:20:55 - INFO - __main__ - Step 950 Global step 950 Train loss 0.326721 on epoch=59
06/03/2022 20:20:58 - INFO - __main__ - Global step 950 Train loss 0.347462 Classification-F1 0.6445258258945602 on epoch=59
06/03/2022 20:21:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.289138 on epoch=59
06/03/2022 20:21:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.313825 on epoch=60
06/03/2022 20:21:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.378278 on epoch=61
06/03/2022 20:21:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.283976 on epoch=61
06/03/2022 20:21:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.279442 on epoch=62
06/03/2022 20:21:26 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:21:26 - INFO - __main__ - Printing 3 examples
06/03/2022 20:21:26 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/03/2022 20:21:26 - INFO - __main__ - ['false']
06/03/2022 20:21:26 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/03/2022 20:21:26 - INFO - __main__ - ['false']
06/03/2022 20:21:26 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/03/2022 20:21:26 - INFO - __main__ - ['false']
06/03/2022 20:21:26 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:21:27 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:21:27 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 20:21:27 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:21:27 - INFO - __main__ - Printing 3 examples
06/03/2022 20:21:27 - INFO - __main__ -  [wiki_qa] question: what year did aerosmith i dont want to miss a thing [SEP] answer: In the UK, the song peaked at number four, becoming Aerosmith's highest charting song in the UK, where it was the 17th best-selling single of 1998 , and has sold over a million copies.
06/03/2022 20:21:27 - INFO - __main__ - ['false']
06/03/2022 20:21:27 - INFO - __main__ -  [wiki_qa] question: How did the pendulum improve upon earlier clocks? [SEP] answer: When released, the restoring force combined with the pendulum's mass causes it to oscillate about the equilibrium position, swinging back and forth.
06/03/2022 20:21:27 - INFO - __main__ - ['false']
06/03/2022 20:21:27 - INFO - __main__ -  [wiki_qa] question: what is puerto rico currency [SEP] answer: However, printing of these banknotes ceased after 1815.
06/03/2022 20:21:27 - INFO - __main__ - ['false']
06/03/2022 20:21:27 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:21:27 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:21:27 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 20:21:28 - INFO - __main__ - Global step 1000 Train loss 0.308932 Classification-F1 0.5396603396603397 on epoch=62
06/03/2022 20:21:28 - INFO - __main__ - save last model!
06/03/2022 20:21:35 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 20:21:36 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 20:21:36 - INFO - __main__ - Printing 3 examples
06/03/2022 20:21:36 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 20:21:36 - INFO - __main__ - ['false']
06/03/2022 20:21:36 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 20:21:36 - INFO - __main__ - ['false']
06/03/2022 20:21:36 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 20:21:36 - INFO - __main__ - ['false']
06/03/2022 20:21:36 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:21:37 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:21:40 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 20:21:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 20:21:40 - INFO - __main__ - Starting training!
06/03/2022 20:22:09 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_42_0.0001_8_predictions.txt
06/03/2022 20:22:09 - INFO - __main__ - Classification-F1 on test data: 0.5574
06/03/2022 20:22:10 - INFO - __main__ - prefix=wiki_qa_128_42, lr=0.0001, bsz=8, dev_performance=0.7225504113812947, test_performance=0.5574053350263093
06/03/2022 20:22:10 - INFO - __main__ - Running ... prefix=wiki_qa_128_87, lr=0.0005, bsz=8 ...
06/03/2022 20:22:11 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:22:11 - INFO - __main__ - Printing 3 examples
06/03/2022 20:22:11 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/03/2022 20:22:11 - INFO - __main__ - ['false']
06/03/2022 20:22:11 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/03/2022 20:22:11 - INFO - __main__ - ['false']
06/03/2022 20:22:11 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/03/2022 20:22:11 - INFO - __main__ - ['false']
06/03/2022 20:22:11 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:22:11 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:22:12 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 20:22:12 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:22:12 - INFO - __main__ - Printing 3 examples
06/03/2022 20:22:12 - INFO - __main__ -  [wiki_qa] question: what year did aerosmith i dont want to miss a thing [SEP] answer: In the UK, the song peaked at number four, becoming Aerosmith's highest charting song in the UK, where it was the 17th best-selling single of 1998 , and has sold over a million copies.
06/03/2022 20:22:12 - INFO - __main__ - ['false']
06/03/2022 20:22:12 - INFO - __main__ -  [wiki_qa] question: How did the pendulum improve upon earlier clocks? [SEP] answer: When released, the restoring force combined with the pendulum's mass causes it to oscillate about the equilibrium position, swinging back and forth.
06/03/2022 20:22:12 - INFO - __main__ - ['false']
06/03/2022 20:22:12 - INFO - __main__ -  [wiki_qa] question: what is puerto rico currency [SEP] answer: However, printing of these banknotes ceased after 1815.
06/03/2022 20:22:12 - INFO - __main__ - ['false']
06/03/2022 20:22:12 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:22:12 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:22:12 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 20:22:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 20:22:23 - INFO - __main__ - Starting training!
06/03/2022 20:22:28 - INFO - __main__ - Step 10 Global step 10 Train loss 21.731060 on epoch=0
06/03/2022 20:22:33 - INFO - __main__ - Step 20 Global step 20 Train loss 18.773455 on epoch=1
06/03/2022 20:22:39 - INFO - __main__ - Step 30 Global step 30 Train loss 15.666598 on epoch=1
06/03/2022 20:22:44 - INFO - __main__ - Step 40 Global step 40 Train loss 13.316984 on epoch=2
06/03/2022 20:22:50 - INFO - __main__ - Step 50 Global step 50 Train loss 7.135025 on epoch=3
06/03/2022 20:22:52 - INFO - __main__ - Global step 50 Train loss 15.324624 Classification-F1 0.3333333333333333 on epoch=3
06/03/2022 20:22:58 - INFO - __main__ - Step 60 Global step 60 Train loss 1.844701 on epoch=3
06/03/2022 20:23:03 - INFO - __main__ - Step 70 Global step 70 Train loss 1.420770 on epoch=4
06/03/2022 20:23:09 - INFO - __main__ - Step 80 Global step 80 Train loss 0.607900 on epoch=4
06/03/2022 20:23:14 - INFO - __main__ - Step 90 Global step 90 Train loss 0.476243 on epoch=5
06/03/2022 20:23:20 - INFO - __main__ - Step 100 Global step 100 Train loss 0.505749 on epoch=6
06/03/2022 20:23:22 - INFO - __main__ - Global step 100 Train loss 0.971073 Classification-F1 0.3784863604213263 on epoch=6
06/03/2022 20:23:29 - INFO - __main__ - Step 110 Global step 110 Train loss 0.470909 on epoch=6
06/03/2022 20:23:34 - INFO - __main__ - Step 120 Global step 120 Train loss 0.375687 on epoch=7
06/03/2022 20:23:40 - INFO - __main__ - Step 130 Global step 130 Train loss 0.464117 on epoch=8
06/03/2022 20:23:45 - INFO - __main__ - Step 140 Global step 140 Train loss 0.360415 on epoch=8
06/03/2022 20:23:51 - INFO - __main__ - Step 150 Global step 150 Train loss 0.396680 on epoch=9
06/03/2022 20:23:53 - INFO - __main__ - Global step 150 Train loss 0.413562 Classification-F1 0.3750290630086026 on epoch=9
06/03/2022 20:23:58 - INFO - __main__ - Step 160 Global step 160 Train loss 0.361652 on epoch=9
06/03/2022 20:24:04 - INFO - __main__ - Step 170 Global step 170 Train loss 0.447330 on epoch=10
06/03/2022 20:24:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.458405 on epoch=11
06/03/2022 20:24:15 - INFO - __main__ - Step 190 Global step 190 Train loss 0.358774 on epoch=11
06/03/2022 20:24:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.469857 on epoch=12
06/03/2022 20:24:22 - INFO - __main__ - Global step 200 Train loss 0.419204 Classification-F1 0.38910917735713646 on epoch=12
06/03/2022 20:24:28 - INFO - __main__ - Step 210 Global step 210 Train loss 0.429161 on epoch=13
06/03/2022 20:24:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.976696 on epoch=13
06/03/2022 20:24:39 - INFO - __main__ - Step 230 Global step 230 Train loss 0.348546 on epoch=14
06/03/2022 20:24:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.397002 on epoch=14
06/03/2022 20:24:50 - INFO - __main__ - Step 250 Global step 250 Train loss 0.440602 on epoch=15
06/03/2022 20:24:52 - INFO - __main__ - Global step 250 Train loss 0.518401 Classification-F1 0.3333333333333333 on epoch=15
06/03/2022 20:24:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.424183 on epoch=16
06/03/2022 20:25:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.404002 on epoch=16
06/03/2022 20:25:09 - INFO - __main__ - Step 280 Global step 280 Train loss 0.418145 on epoch=17
06/03/2022 20:25:14 - INFO - __main__ - Step 290 Global step 290 Train loss 0.364719 on epoch=18
06/03/2022 20:25:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.381493 on epoch=18
06/03/2022 20:25:22 - INFO - __main__ - Global step 300 Train loss 0.398508 Classification-F1 0.3486005089058525 on epoch=18
06/03/2022 20:25:27 - INFO - __main__ - Step 310 Global step 310 Train loss 0.538953 on epoch=19
06/03/2022 20:25:33 - INFO - __main__ - Step 320 Global step 320 Train loss 0.413668 on epoch=19
06/03/2022 20:25:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.395541 on epoch=20
06/03/2022 20:25:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.356488 on epoch=21
06/03/2022 20:25:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.379081 on epoch=21
06/03/2022 20:25:52 - INFO - __main__ - Global step 350 Train loss 0.416746 Classification-F1 0.36516753625488524 on epoch=21
06/03/2022 20:25:58 - INFO - __main__ - Step 360 Global step 360 Train loss 0.369124 on epoch=22
06/03/2022 20:26:03 - INFO - __main__ - Step 370 Global step 370 Train loss 0.402658 on epoch=23
06/03/2022 20:26:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.390979 on epoch=23
06/03/2022 20:26:14 - INFO - __main__ - Step 390 Global step 390 Train loss 0.381260 on epoch=24
06/03/2022 20:26:20 - INFO - __main__ - Step 400 Global step 400 Train loss 0.409135 on epoch=24
06/03/2022 20:26:23 - INFO - __main__ - Global step 400 Train loss 0.390631 Classification-F1 0.3333333333333333 on epoch=24
06/03/2022 20:26:28 - INFO - __main__ - Step 410 Global step 410 Train loss 0.384284 on epoch=25
06/03/2022 20:26:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.377761 on epoch=26
06/03/2022 20:26:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.369478 on epoch=26
06/03/2022 20:26:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.367294 on epoch=27
06/03/2022 20:26:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.391246 on epoch=28
06/03/2022 20:26:53 - INFO - __main__ - Global step 450 Train loss 0.378013 Classification-F1 0.3486005089058525 on epoch=28
06/03/2022 20:26:58 - INFO - __main__ - Step 460 Global step 460 Train loss 0.363524 on epoch=28
06/03/2022 20:27:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.343350 on epoch=29
06/03/2022 20:27:09 - INFO - __main__ - Step 480 Global step 480 Train loss 0.365761 on epoch=29
06/03/2022 20:27:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.416968 on epoch=30
06/03/2022 20:27:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.378713 on epoch=31
06/03/2022 20:27:23 - INFO - __main__ - Global step 500 Train loss 0.373663 Classification-F1 0.39581271412257324 on epoch=31
06/03/2022 20:27:30 - INFO - __main__ - Step 510 Global step 510 Train loss 0.378672 on epoch=31
06/03/2022 20:27:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.421790 on epoch=32
06/03/2022 20:27:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.361009 on epoch=33
06/03/2022 20:27:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.373425 on epoch=33
06/03/2022 20:27:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.342086 on epoch=34
06/03/2022 20:27:54 - INFO - __main__ - Global step 550 Train loss 0.375396 Classification-F1 0.5064935064935064 on epoch=34
06/03/2022 20:28:00 - INFO - __main__ - Step 560 Global step 560 Train loss 0.350682 on epoch=34
06/03/2022 20:28:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.395185 on epoch=35
06/03/2022 20:28:11 - INFO - __main__ - Step 580 Global step 580 Train loss 0.343038 on epoch=36
06/03/2022 20:28:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.363148 on epoch=36
06/03/2022 20:28:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.369684 on epoch=37
06/03/2022 20:28:24 - INFO - __main__ - Global step 600 Train loss 0.364347 Classification-F1 0.36516753625488524 on epoch=37
06/03/2022 20:28:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.337195 on epoch=38
06/03/2022 20:28:35 - INFO - __main__ - Step 620 Global step 620 Train loss 0.328931 on epoch=38
06/03/2022 20:28:40 - INFO - __main__ - Step 630 Global step 630 Train loss 0.383838 on epoch=39
06/03/2022 20:28:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.375047 on epoch=39
06/03/2022 20:28:51 - INFO - __main__ - Step 650 Global step 650 Train loss 0.371514 on epoch=40
06/03/2022 20:28:53 - INFO - __main__ - Global step 650 Train loss 0.359305 Classification-F1 0.350463149416029 on epoch=40
06/03/2022 20:28:59 - INFO - __main__ - Step 660 Global step 660 Train loss 0.355064 on epoch=41
06/03/2022 20:29:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.375215 on epoch=41
06/03/2022 20:29:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.378320 on epoch=42
06/03/2022 20:29:16 - INFO - __main__ - Step 690 Global step 690 Train loss 0.409909 on epoch=43
06/03/2022 20:29:21 - INFO - __main__ - Step 700 Global step 700 Train loss 0.356051 on epoch=43
06/03/2022 20:29:24 - INFO - __main__ - Global step 700 Train loss 0.374911 Classification-F1 0.3486005089058525 on epoch=43
06/03/2022 20:29:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.353899 on epoch=44
06/03/2022 20:29:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.360329 on epoch=44
06/03/2022 20:29:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.360869 on epoch=45
06/03/2022 20:29:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.369986 on epoch=46
06/03/2022 20:29:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.341583 on epoch=46
06/03/2022 20:29:53 - INFO - __main__ - Global step 750 Train loss 0.357333 Classification-F1 0.3712545436683367 on epoch=46
06/03/2022 20:29:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.373503 on epoch=47
06/03/2022 20:30:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.374925 on epoch=48
06/03/2022 20:30:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.347008 on epoch=48
06/03/2022 20:30:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.354819 on epoch=49
06/03/2022 20:30:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.346598 on epoch=49
06/03/2022 20:30:23 - INFO - __main__ - Global step 800 Train loss 0.359370 Classification-F1 0.3333333333333333 on epoch=49
06/03/2022 20:30:29 - INFO - __main__ - Step 810 Global step 810 Train loss 0.354014 on epoch=50
06/03/2022 20:30:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.341361 on epoch=51
06/03/2022 20:30:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.349051 on epoch=51
06/03/2022 20:30:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.340782 on epoch=52
06/03/2022 20:30:51 - INFO - __main__ - Step 850 Global step 850 Train loss 0.360574 on epoch=53
06/03/2022 20:30:53 - INFO - __main__ - Global step 850 Train loss 0.349156 Classification-F1 0.41296643735668126 on epoch=53
06/03/2022 20:30:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.371702 on epoch=53
06/03/2022 20:31:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.323730 on epoch=54
06/03/2022 20:31:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.351431 on epoch=54
06/03/2022 20:31:15 - INFO - __main__ - Step 890 Global step 890 Train loss 0.389009 on epoch=55
06/03/2022 20:31:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.356760 on epoch=56
06/03/2022 20:31:23 - INFO - __main__ - Global step 900 Train loss 0.358526 Classification-F1 0.4106280193236715 on epoch=56
06/03/2022 20:31:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.342221 on epoch=56
06/03/2022 20:31:34 - INFO - __main__ - Step 920 Global step 920 Train loss 0.384963 on epoch=57
06/03/2022 20:31:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.370654 on epoch=58
06/03/2022 20:31:45 - INFO - __main__ - Step 940 Global step 940 Train loss 0.370669 on epoch=58
06/03/2022 20:31:51 - INFO - __main__ - Step 950 Global step 950 Train loss 0.351064 on epoch=59
06/03/2022 20:31:53 - INFO - __main__ - Global step 950 Train loss 0.363914 Classification-F1 0.5280283023568688 on epoch=59
06/03/2022 20:31:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.348382 on epoch=59
06/03/2022 20:32:05 - INFO - __main__ - Step 970 Global step 970 Train loss 0.331903 on epoch=60
06/03/2022 20:32:10 - INFO - __main__ - Step 980 Global step 980 Train loss 0.339758 on epoch=61
06/03/2022 20:32:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.335209 on epoch=61
06/03/2022 20:32:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.340867 on epoch=62
06/03/2022 20:32:22 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:32:22 - INFO - __main__ - Printing 3 examples
06/03/2022 20:32:22 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/03/2022 20:32:22 - INFO - __main__ - ['false']
06/03/2022 20:32:22 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/03/2022 20:32:22 - INFO - __main__ - ['false']
06/03/2022 20:32:22 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/03/2022 20:32:22 - INFO - __main__ - ['false']
06/03/2022 20:32:22 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:32:23 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:32:23 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 20:32:23 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:32:23 - INFO - __main__ - Printing 3 examples
06/03/2022 20:32:23 - INFO - __main__ -  [wiki_qa] question: what year did aerosmith i dont want to miss a thing [SEP] answer: In the UK, the song peaked at number four, becoming Aerosmith's highest charting song in the UK, where it was the 17th best-selling single of 1998 , and has sold over a million copies.
06/03/2022 20:32:23 - INFO - __main__ - ['false']
06/03/2022 20:32:23 - INFO - __main__ -  [wiki_qa] question: How did the pendulum improve upon earlier clocks? [SEP] answer: When released, the restoring force combined with the pendulum's mass causes it to oscillate about the equilibrium position, swinging back and forth.
06/03/2022 20:32:23 - INFO - __main__ - ['false']
06/03/2022 20:32:23 - INFO - __main__ -  [wiki_qa] question: what is puerto rico currency [SEP] answer: However, printing of these banknotes ceased after 1815.
06/03/2022 20:32:23 - INFO - __main__ - ['false']
06/03/2022 20:32:23 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:32:23 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:32:23 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 20:32:23 - INFO - __main__ - Global step 1000 Train loss 0.339224 Classification-F1 0.5684492751296418 on epoch=62
06/03/2022 20:32:24 - INFO - __main__ - save last model!
06/03/2022 20:32:32 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 20:32:33 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 20:32:33 - INFO - __main__ - Printing 3 examples
06/03/2022 20:32:33 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 20:32:33 - INFO - __main__ - ['false']
06/03/2022 20:32:33 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 20:32:33 - INFO - __main__ - ['false']
06/03/2022 20:32:33 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 20:32:33 - INFO - __main__ - ['false']
06/03/2022 20:32:33 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:32:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 20:32:34 - INFO - __main__ - Starting training!
06/03/2022 20:32:34 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:32:37 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 20:33:01 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_87_0.0005_8_predictions.txt
06/03/2022 20:33:01 - INFO - __main__ - Classification-F1 on test data: 0.4911
06/03/2022 20:33:01 - INFO - __main__ - prefix=wiki_qa_128_87, lr=0.0005, bsz=8, dev_performance=0.5684492751296418, test_performance=0.4910742595435215
06/03/2022 20:33:01 - INFO - __main__ - Running ... prefix=wiki_qa_128_87, lr=0.0003, bsz=8 ...
06/03/2022 20:33:02 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:33:02 - INFO - __main__ - Printing 3 examples
06/03/2022 20:33:02 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/03/2022 20:33:02 - INFO - __main__ - ['false']
06/03/2022 20:33:02 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/03/2022 20:33:02 - INFO - __main__ - ['false']
06/03/2022 20:33:02 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/03/2022 20:33:02 - INFO - __main__ - ['false']
06/03/2022 20:33:02 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:33:02 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:33:02 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 20:33:02 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:33:02 - INFO - __main__ - Printing 3 examples
06/03/2022 20:33:02 - INFO - __main__ -  [wiki_qa] question: what year did aerosmith i dont want to miss a thing [SEP] answer: In the UK, the song peaked at number four, becoming Aerosmith's highest charting song in the UK, where it was the 17th best-selling single of 1998 , and has sold over a million copies.
06/03/2022 20:33:02 - INFO - __main__ - ['false']
06/03/2022 20:33:02 - INFO - __main__ -  [wiki_qa] question: How did the pendulum improve upon earlier clocks? [SEP] answer: When released, the restoring force combined with the pendulum's mass causes it to oscillate about the equilibrium position, swinging back and forth.
06/03/2022 20:33:02 - INFO - __main__ - ['false']
06/03/2022 20:33:02 - INFO - __main__ -  [wiki_qa] question: what is puerto rico currency [SEP] answer: However, printing of these banknotes ceased after 1815.
06/03/2022 20:33:02 - INFO - __main__ - ['false']
06/03/2022 20:33:02 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:33:03 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:33:03 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 20:33:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 20:33:14 - INFO - __main__ - Starting training!
06/03/2022 20:33:18 - INFO - __main__ - Step 10 Global step 10 Train loss 22.675007 on epoch=0
06/03/2022 20:33:24 - INFO - __main__ - Step 20 Global step 20 Train loss 18.983967 on epoch=1
06/03/2022 20:33:29 - INFO - __main__ - Step 30 Global step 30 Train loss 17.653128 on epoch=1
06/03/2022 20:33:35 - INFO - __main__ - Step 40 Global step 40 Train loss 16.217348 on epoch=2
06/03/2022 20:33:40 - INFO - __main__ - Step 50 Global step 50 Train loss 14.350914 on epoch=3
06/03/2022 20:33:57 - INFO - __main__ - Global step 50 Train loss 17.976070 Classification-F1 0.0 on epoch=3
06/03/2022 20:34:03 - INFO - __main__ - Step 60 Global step 60 Train loss 14.414907 on epoch=3
06/03/2022 20:34:09 - INFO - __main__ - Step 70 Global step 70 Train loss 12.538446 on epoch=4
06/03/2022 20:34:14 - INFO - __main__ - Step 80 Global step 80 Train loss 9.729447 on epoch=4
06/03/2022 20:34:19 - INFO - __main__ - Step 90 Global step 90 Train loss 4.625937 on epoch=5
06/03/2022 20:34:25 - INFO - __main__ - Step 100 Global step 100 Train loss 0.835341 on epoch=6
06/03/2022 20:34:28 - INFO - __main__ - Global step 100 Train loss 8.428816 Classification-F1 0.5870650587602735 on epoch=6
06/03/2022 20:34:34 - INFO - __main__ - Step 110 Global step 110 Train loss 0.648785 on epoch=6
06/03/2022 20:34:39 - INFO - __main__ - Step 120 Global step 120 Train loss 0.546848 on epoch=7
06/03/2022 20:34:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.508730 on epoch=8
06/03/2022 20:34:50 - INFO - __main__ - Step 140 Global step 140 Train loss 0.671217 on epoch=8
06/03/2022 20:34:55 - INFO - __main__ - Step 150 Global step 150 Train loss 0.408664 on epoch=9
06/03/2022 20:34:58 - INFO - __main__ - Global step 150 Train loss 0.556849 Classification-F1 0.35501021683496337 on epoch=9
06/03/2022 20:35:03 - INFO - __main__ - Step 160 Global step 160 Train loss 0.402130 on epoch=9
06/03/2022 20:35:09 - INFO - __main__ - Step 170 Global step 170 Train loss 0.512292 on epoch=10
06/03/2022 20:35:14 - INFO - __main__ - Step 180 Global step 180 Train loss 0.398724 on epoch=11
06/03/2022 20:35:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.499680 on epoch=11
06/03/2022 20:35:25 - INFO - __main__ - Step 200 Global step 200 Train loss 0.392970 on epoch=12
06/03/2022 20:35:28 - INFO - __main__ - Global step 200 Train loss 0.441159 Classification-F1 0.3486005089058525 on epoch=12
06/03/2022 20:35:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.455863 on epoch=13
06/03/2022 20:35:38 - INFO - __main__ - Step 220 Global step 220 Train loss 0.352149 on epoch=13
06/03/2022 20:35:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.323758 on epoch=14
06/03/2022 20:35:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.361492 on epoch=14
06/03/2022 20:35:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.346432 on epoch=15
06/03/2022 20:35:58 - INFO - __main__ - Global step 250 Train loss 0.367939 Classification-F1 0.520769036175057 on epoch=15
06/03/2022 20:36:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.286358 on epoch=16
06/03/2022 20:36:08 - INFO - __main__ - Step 270 Global step 270 Train loss 0.250188 on epoch=16
06/03/2022 20:36:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.264012 on epoch=17
06/03/2022 20:36:19 - INFO - __main__ - Step 290 Global step 290 Train loss 0.348956 on epoch=18
06/03/2022 20:36:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.148483 on epoch=18
06/03/2022 20:36:27 - INFO - __main__ - Global step 300 Train loss 0.259599 Classification-F1 0.36516753625488524 on epoch=18
06/03/2022 20:36:32 - INFO - __main__ - Step 310 Global step 310 Train loss 0.197450 on epoch=19
06/03/2022 20:36:38 - INFO - __main__ - Step 320 Global step 320 Train loss 0.173212 on epoch=19
06/03/2022 20:36:43 - INFO - __main__ - Step 330 Global step 330 Train loss 0.141297 on epoch=20
06/03/2022 20:36:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.149221 on epoch=21
06/03/2022 20:36:54 - INFO - __main__ - Step 350 Global step 350 Train loss 0.146313 on epoch=21
06/03/2022 20:36:57 - INFO - __main__ - Global step 350 Train loss 0.161499 Classification-F1 0.512735326688815 on epoch=21
06/03/2022 20:37:03 - INFO - __main__ - Step 360 Global step 360 Train loss 0.097822 on epoch=22
06/03/2022 20:37:08 - INFO - __main__ - Step 370 Global step 370 Train loss 0.049351 on epoch=23
06/03/2022 20:37:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.059186 on epoch=23
06/03/2022 20:37:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.035637 on epoch=24
06/03/2022 20:37:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.034557 on epoch=24
06/03/2022 20:37:27 - INFO - __main__ - Global step 400 Train loss 0.055311 Classification-F1 0.5670995670995671 on epoch=24
06/03/2022 20:37:32 - INFO - __main__ - Step 410 Global step 410 Train loss 0.063989 on epoch=25
06/03/2022 20:37:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.023776 on epoch=26
06/03/2022 20:37:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.024977 on epoch=26
06/03/2022 20:37:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.010850 on epoch=27
06/03/2022 20:37:54 - INFO - __main__ - Step 450 Global step 450 Train loss 0.033783 on epoch=28
06/03/2022 20:37:57 - INFO - __main__ - Global step 450 Train loss 0.031475 Classification-F1 0.6268507863444572 on epoch=28
06/03/2022 20:38:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.090810 on epoch=28
06/03/2022 20:38:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.029723 on epoch=29
06/03/2022 20:38:14 - INFO - __main__ - Step 480 Global step 480 Train loss 0.006895 on epoch=29
06/03/2022 20:38:19 - INFO - __main__ - Step 490 Global step 490 Train loss 0.004137 on epoch=30
06/03/2022 20:38:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.009551 on epoch=31
06/03/2022 20:38:28 - INFO - __main__ - Global step 500 Train loss 0.028223 Classification-F1 0.5503947345985303 on epoch=31
06/03/2022 20:38:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.003898 on epoch=31
06/03/2022 20:38:39 - INFO - __main__ - Step 520 Global step 520 Train loss 0.003051 on epoch=32
06/03/2022 20:38:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.002109 on epoch=33
06/03/2022 20:38:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.037283 on epoch=33
06/03/2022 20:38:55 - INFO - __main__ - Step 550 Global step 550 Train loss 0.004598 on epoch=34
06/03/2022 20:38:58 - INFO - __main__ - Global step 550 Train loss 0.010188 Classification-F1 0.6157138294474608 on epoch=34
06/03/2022 20:39:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.012239 on epoch=34
06/03/2022 20:39:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.016392 on epoch=35
06/03/2022 20:39:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.008258 on epoch=36
06/03/2022 20:39:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.001165 on epoch=36
06/03/2022 20:39:25 - INFO - __main__ - Step 600 Global step 600 Train loss 0.002781 on epoch=37
06/03/2022 20:39:28 - INFO - __main__ - Global step 600 Train loss 0.008167 Classification-F1 0.6211799523901436 on epoch=37
06/03/2022 20:39:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.007278 on epoch=38
06/03/2022 20:39:39 - INFO - __main__ - Step 620 Global step 620 Train loss 0.001842 on epoch=38
06/03/2022 20:39:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.001214 on epoch=39
06/03/2022 20:39:49 - INFO - __main__ - Step 640 Global step 640 Train loss 0.001137 on epoch=39
06/03/2022 20:39:55 - INFO - __main__ - Step 650 Global step 650 Train loss 0.012145 on epoch=40
06/03/2022 20:39:58 - INFO - __main__ - Global step 650 Train loss 0.004723 Classification-F1 0.6307692307692307 on epoch=40
06/03/2022 20:40:04 - INFO - __main__ - Step 660 Global step 660 Train loss 0.004869 on epoch=41
06/03/2022 20:40:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.001952 on epoch=41
06/03/2022 20:40:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000589 on epoch=42
06/03/2022 20:40:20 - INFO - __main__ - Step 690 Global step 690 Train loss 0.001506 on epoch=43
06/03/2022 20:40:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000228 on epoch=43
06/03/2022 20:40:29 - INFO - __main__ - Global step 700 Train loss 0.001829 Classification-F1 0.6752274274398169 on epoch=43
06/03/2022 20:40:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000687 on epoch=44
06/03/2022 20:40:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000800 on epoch=44
06/03/2022 20:40:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000315 on epoch=45
06/03/2022 20:40:51 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000071 on epoch=46
06/03/2022 20:40:56 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000362 on epoch=46
06/03/2022 20:40:59 - INFO - __main__ - Global step 750 Train loss 0.000447 Classification-F1 0.6855809383443872 on epoch=46
06/03/2022 20:41:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.001291 on epoch=47
06/03/2022 20:41:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000420 on epoch=48
06/03/2022 20:41:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.001464 on epoch=48
06/03/2022 20:41:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000760 on epoch=49
06/03/2022 20:41:27 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000278 on epoch=49
06/03/2022 20:41:29 - INFO - __main__ - Global step 800 Train loss 0.000843 Classification-F1 0.6351734398246026 on epoch=49
06/03/2022 20:41:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000981 on epoch=50
06/03/2022 20:41:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.005931 on epoch=51
06/03/2022 20:41:46 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000164 on epoch=51
06/03/2022 20:41:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.001086 on epoch=52
06/03/2022 20:41:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.001134 on epoch=53
06/03/2022 20:41:59 - INFO - __main__ - Global step 850 Train loss 0.001859 Classification-F1 0.6374384236453202 on epoch=53
06/03/2022 20:42:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000194 on epoch=53
06/03/2022 20:42:10 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000092 on epoch=54
06/03/2022 20:42:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000061 on epoch=54
06/03/2022 20:42:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000277 on epoch=55
06/03/2022 20:42:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000333 on epoch=56
06/03/2022 20:42:29 - INFO - __main__ - Global step 900 Train loss 0.000191 Classification-F1 0.649514667651176 on epoch=56
06/03/2022 20:42:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000041 on epoch=56
06/03/2022 20:42:40 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000097 on epoch=57
06/03/2022 20:42:46 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000030 on epoch=58
06/03/2022 20:42:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000629 on epoch=58
06/03/2022 20:42:57 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000040 on epoch=59
06/03/2022 20:42:59 - INFO - __main__ - Global step 950 Train loss 0.000167 Classification-F1 0.6177693579719685 on epoch=59
06/03/2022 20:43:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000075 on epoch=59
06/03/2022 20:43:11 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000017 on epoch=60
06/03/2022 20:43:16 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000066 on epoch=61
06/03/2022 20:43:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000234 on epoch=61
06/03/2022 20:43:27 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000211 on epoch=62
06/03/2022 20:43:28 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:43:28 - INFO - __main__ - Printing 3 examples
06/03/2022 20:43:28 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/03/2022 20:43:28 - INFO - __main__ - ['false']
06/03/2022 20:43:28 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/03/2022 20:43:28 - INFO - __main__ - ['false']
06/03/2022 20:43:28 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/03/2022 20:43:28 - INFO - __main__ - ['false']
06/03/2022 20:43:28 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:43:28 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:43:28 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 20:43:28 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:43:28 - INFO - __main__ - Printing 3 examples
06/03/2022 20:43:28 - INFO - __main__ -  [wiki_qa] question: what year did aerosmith i dont want to miss a thing [SEP] answer: In the UK, the song peaked at number four, becoming Aerosmith's highest charting song in the UK, where it was the 17th best-selling single of 1998 , and has sold over a million copies.
06/03/2022 20:43:28 - INFO - __main__ - ['false']
06/03/2022 20:43:28 - INFO - __main__ -  [wiki_qa] question: How did the pendulum improve upon earlier clocks? [SEP] answer: When released, the restoring force combined with the pendulum's mass causes it to oscillate about the equilibrium position, swinging back and forth.
06/03/2022 20:43:28 - INFO - __main__ - ['false']
06/03/2022 20:43:28 - INFO - __main__ -  [wiki_qa] question: what is puerto rico currency [SEP] answer: However, printing of these banknotes ceased after 1815.
06/03/2022 20:43:28 - INFO - __main__ - ['false']
06/03/2022 20:43:28 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:43:29 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:43:29 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 20:43:30 - INFO - __main__ - Global step 1000 Train loss 0.000120 Classification-F1 0.6514635806671205 on epoch=62
06/03/2022 20:43:30 - INFO - __main__ - save last model!
06/03/2022 20:43:37 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 20:43:38 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 20:43:38 - INFO - __main__ - Printing 3 examples
06/03/2022 20:43:38 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 20:43:38 - INFO - __main__ - ['false']
06/03/2022 20:43:38 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 20:43:38 - INFO - __main__ - ['false']
06/03/2022 20:43:38 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 20:43:38 - INFO - __main__ - ['false']
06/03/2022 20:43:38 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:43:39 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:43:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 20:43:40 - INFO - __main__ - Starting training!
06/03/2022 20:43:42 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 20:44:11 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_87_0.0003_8_predictions.txt
06/03/2022 20:44:11 - INFO - __main__ - Classification-F1 on test data: 0.5196
06/03/2022 20:44:11 - INFO - __main__ - prefix=wiki_qa_128_87, lr=0.0003, bsz=8, dev_performance=0.6855809383443872, test_performance=0.5196152866741102
06/03/2022 20:44:11 - INFO - __main__ - Running ... prefix=wiki_qa_128_87, lr=0.0002, bsz=8 ...
06/03/2022 20:44:12 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:44:12 - INFO - __main__ - Printing 3 examples
06/03/2022 20:44:12 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/03/2022 20:44:12 - INFO - __main__ - ['false']
06/03/2022 20:44:12 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/03/2022 20:44:12 - INFO - __main__ - ['false']
06/03/2022 20:44:12 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/03/2022 20:44:12 - INFO - __main__ - ['false']
06/03/2022 20:44:12 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:44:12 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:44:12 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 20:44:12 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:44:12 - INFO - __main__ - Printing 3 examples
06/03/2022 20:44:12 - INFO - __main__ -  [wiki_qa] question: what year did aerosmith i dont want to miss a thing [SEP] answer: In the UK, the song peaked at number four, becoming Aerosmith's highest charting song in the UK, where it was the 17th best-selling single of 1998 , and has sold over a million copies.
06/03/2022 20:44:12 - INFO - __main__ - ['false']
06/03/2022 20:44:12 - INFO - __main__ -  [wiki_qa] question: How did the pendulum improve upon earlier clocks? [SEP] answer: When released, the restoring force combined with the pendulum's mass causes it to oscillate about the equilibrium position, swinging back and forth.
06/03/2022 20:44:12 - INFO - __main__ - ['false']
06/03/2022 20:44:12 - INFO - __main__ -  [wiki_qa] question: what is puerto rico currency [SEP] answer: However, printing of these banknotes ceased after 1815.
06/03/2022 20:44:12 - INFO - __main__ - ['false']
06/03/2022 20:44:12 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:44:13 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:44:13 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 20:44:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 20:44:24 - INFO - __main__ - Starting training!
06/03/2022 20:44:29 - INFO - __main__ - Step 10 Global step 10 Train loss 23.016647 on epoch=0
06/03/2022 20:44:34 - INFO - __main__ - Step 20 Global step 20 Train loss 18.869299 on epoch=1
06/03/2022 20:44:40 - INFO - __main__ - Step 30 Global step 30 Train loss 18.435673 on epoch=1
06/03/2022 20:44:45 - INFO - __main__ - Step 40 Global step 40 Train loss 16.546314 on epoch=2
06/03/2022 20:44:51 - INFO - __main__ - Step 50 Global step 50 Train loss 15.919306 on epoch=3
06/03/2022 20:45:24 - INFO - __main__ - Global step 50 Train loss 18.557446 Classification-F1 0.0 on epoch=3
06/03/2022 20:45:30 - INFO - __main__ - Step 60 Global step 60 Train loss 15.429703 on epoch=3
06/03/2022 20:45:35 - INFO - __main__ - Step 70 Global step 70 Train loss 13.808192 on epoch=4
06/03/2022 20:45:41 - INFO - __main__ - Step 80 Global step 80 Train loss 13.813489 on epoch=4
06/03/2022 20:45:46 - INFO - __main__ - Step 90 Global step 90 Train loss 14.006558 on epoch=5
06/03/2022 20:45:51 - INFO - __main__ - Step 100 Global step 100 Train loss 13.250015 on epoch=6
06/03/2022 20:46:17 - INFO - __main__ - Global step 100 Train loss 14.061590 Classification-F1 0.0 on epoch=6
06/03/2022 20:46:23 - INFO - __main__ - Step 110 Global step 110 Train loss 12.108328 on epoch=6
06/03/2022 20:46:28 - INFO - __main__ - Step 120 Global step 120 Train loss 11.525185 on epoch=7
06/03/2022 20:46:34 - INFO - __main__ - Step 130 Global step 130 Train loss 10.129131 on epoch=8
06/03/2022 20:46:40 - INFO - __main__ - Step 140 Global step 140 Train loss 8.251777 on epoch=8
06/03/2022 20:46:45 - INFO - __main__ - Step 150 Global step 150 Train loss 4.248571 on epoch=9
06/03/2022 20:46:48 - INFO - __main__ - Global step 150 Train loss 9.252599 Classification-F1 0.3333333333333333 on epoch=9
06/03/2022 20:46:55 - INFO - __main__ - Step 160 Global step 160 Train loss 3.323666 on epoch=9
06/03/2022 20:47:00 - INFO - __main__ - Step 170 Global step 170 Train loss 1.899214 on epoch=10
06/03/2022 20:47:05 - INFO - __main__ - Step 180 Global step 180 Train loss 0.634793 on epoch=11
06/03/2022 20:47:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.749910 on epoch=11
06/03/2022 20:47:17 - INFO - __main__ - Step 200 Global step 200 Train loss 0.553887 on epoch=12
06/03/2022 20:47:20 - INFO - __main__ - Global step 200 Train loss 1.432294 Classification-F1 0.3486005089058525 on epoch=12
06/03/2022 20:47:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.596020 on epoch=13
06/03/2022 20:47:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.496958 on epoch=13
06/03/2022 20:47:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.538113 on epoch=14
06/03/2022 20:47:43 - INFO - __main__ - Step 240 Global step 240 Train loss 0.541587 on epoch=14
06/03/2022 20:47:49 - INFO - __main__ - Step 250 Global step 250 Train loss 0.603629 on epoch=15
06/03/2022 20:47:52 - INFO - __main__ - Global step 250 Train loss 0.555261 Classification-F1 0.39581271412257324 on epoch=15
06/03/2022 20:47:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.440655 on epoch=16
06/03/2022 20:48:04 - INFO - __main__ - Step 270 Global step 270 Train loss 0.424566 on epoch=16
06/03/2022 20:48:09 - INFO - __main__ - Step 280 Global step 280 Train loss 0.420713 on epoch=17
06/03/2022 20:48:15 - INFO - __main__ - Step 290 Global step 290 Train loss 0.449717 on epoch=18
06/03/2022 20:48:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.362127 on epoch=18
06/03/2022 20:48:23 - INFO - __main__ - Global step 300 Train loss 0.419556 Classification-F1 0.3486005089058525 on epoch=18
06/03/2022 20:48:29 - INFO - __main__ - Step 310 Global step 310 Train loss 0.392564 on epoch=19
06/03/2022 20:48:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.432419 on epoch=19
06/03/2022 20:48:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.386791 on epoch=20
06/03/2022 20:48:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.431012 on epoch=21
06/03/2022 20:48:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.440522 on epoch=21
06/03/2022 20:48:53 - INFO - __main__ - Global step 350 Train loss 0.416662 Classification-F1 0.3333333333333333 on epoch=21
06/03/2022 20:48:58 - INFO - __main__ - Step 360 Global step 360 Train loss 0.487623 on epoch=22
06/03/2022 20:49:04 - INFO - __main__ - Step 370 Global step 370 Train loss 0.447405 on epoch=23
06/03/2022 20:49:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.407596 on epoch=23
06/03/2022 20:49:14 - INFO - __main__ - Step 390 Global step 390 Train loss 0.378888 on epoch=24
06/03/2022 20:49:20 - INFO - __main__ - Step 400 Global step 400 Train loss 0.339183 on epoch=24
06/03/2022 20:49:22 - INFO - __main__ - Global step 400 Train loss 0.412139 Classification-F1 0.3333333333333333 on epoch=24
06/03/2022 20:49:28 - INFO - __main__ - Step 410 Global step 410 Train loss 0.399927 on epoch=25
06/03/2022 20:49:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.475215 on epoch=26
06/03/2022 20:49:38 - INFO - __main__ - Step 430 Global step 430 Train loss 0.403984 on epoch=26
06/03/2022 20:49:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.376556 on epoch=27
06/03/2022 20:49:49 - INFO - __main__ - Step 450 Global step 450 Train loss 0.430257 on epoch=28
06/03/2022 20:49:52 - INFO - __main__ - Global step 450 Train loss 0.417188 Classification-F1 0.3486005089058525 on epoch=28
06/03/2022 20:49:58 - INFO - __main__ - Step 460 Global step 460 Train loss 0.345258 on epoch=28
06/03/2022 20:50:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.369128 on epoch=29
06/03/2022 20:50:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.361913 on epoch=29
06/03/2022 20:50:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.423350 on epoch=30
06/03/2022 20:50:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.384140 on epoch=31
06/03/2022 20:50:22 - INFO - __main__ - Global step 500 Train loss 0.376758 Classification-F1 0.34195559333697656 on epoch=31
06/03/2022 20:50:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.377267 on epoch=31
06/03/2022 20:50:33 - INFO - __main__ - Step 520 Global step 520 Train loss 0.364468 on epoch=32
06/03/2022 20:50:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.351555 on epoch=33
06/03/2022 20:50:44 - INFO - __main__ - Step 540 Global step 540 Train loss 0.345282 on epoch=33
06/03/2022 20:50:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.398484 on epoch=34
06/03/2022 20:50:52 - INFO - __main__ - Global step 550 Train loss 0.367411 Classification-F1 0.41013824884792627 on epoch=34
06/03/2022 20:50:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.393287 on epoch=34
06/03/2022 20:51:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.405259 on epoch=35
06/03/2022 20:51:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.438920 on epoch=36
06/03/2022 20:51:14 - INFO - __main__ - Step 590 Global step 590 Train loss 1.281384 on epoch=36
06/03/2022 20:51:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.402491 on epoch=37
06/03/2022 20:51:23 - INFO - __main__ - Global step 600 Train loss 0.584268 Classification-F1 0.3486005089058525 on epoch=37
06/03/2022 20:51:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.411553 on epoch=38
06/03/2022 20:51:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.350601 on epoch=38
06/03/2022 20:51:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.343533 on epoch=39
06/03/2022 20:51:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.353179 on epoch=39
06/03/2022 20:51:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.368416 on epoch=40
06/03/2022 20:51:53 - INFO - __main__ - Global step 650 Train loss 0.365456 Classification-F1 0.5294117647058825 on epoch=40
06/03/2022 20:51:59 - INFO - __main__ - Step 660 Global step 660 Train loss 0.399041 on epoch=41
06/03/2022 20:52:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.374755 on epoch=41
06/03/2022 20:52:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.405491 on epoch=42
06/03/2022 20:52:16 - INFO - __main__ - Step 690 Global step 690 Train loss 0.379411 on epoch=43
06/03/2022 20:52:21 - INFO - __main__ - Step 700 Global step 700 Train loss 0.354062 on epoch=43
06/03/2022 20:52:24 - INFO - __main__ - Global step 700 Train loss 0.382552 Classification-F1 0.3486005089058525 on epoch=43
06/03/2022 20:52:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.365103 on epoch=44
06/03/2022 20:52:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.354168 on epoch=44
06/03/2022 20:52:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.364549 on epoch=45
06/03/2022 20:52:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.390125 on epoch=46
06/03/2022 20:52:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.340662 on epoch=46
06/03/2022 20:52:54 - INFO - __main__ - Global step 750 Train loss 0.362922 Classification-F1 0.566081817765358 on epoch=46
06/03/2022 20:53:00 - INFO - __main__ - Step 760 Global step 760 Train loss 0.385049 on epoch=47
06/03/2022 20:53:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.383963 on epoch=48
06/03/2022 20:53:11 - INFO - __main__ - Step 780 Global step 780 Train loss 1.318224 on epoch=48
06/03/2022 20:53:17 - INFO - __main__ - Step 790 Global step 790 Train loss 1.600865 on epoch=49
06/03/2022 20:53:23 - INFO - __main__ - Step 800 Global step 800 Train loss 1.750274 on epoch=49
06/03/2022 20:53:25 - INFO - __main__ - Global step 800 Train loss 1.087675 Classification-F1 0.3333333333333333 on epoch=49
06/03/2022 20:53:31 - INFO - __main__ - Step 810 Global step 810 Train loss 1.557842 on epoch=50
06/03/2022 20:53:37 - INFO - __main__ - Step 820 Global step 820 Train loss 1.392467 on epoch=51
06/03/2022 20:53:42 - INFO - __main__ - Step 830 Global step 830 Train loss 1.595720 on epoch=51
06/03/2022 20:53:48 - INFO - __main__ - Step 840 Global step 840 Train loss 1.394523 on epoch=52
06/03/2022 20:53:53 - INFO - __main__ - Step 850 Global step 850 Train loss 1.253237 on epoch=53
06/03/2022 20:53:56 - INFO - __main__ - Global step 850 Train loss 1.438758 Classification-F1 0.5345225809622094 on epoch=53
06/03/2022 20:54:02 - INFO - __main__ - Step 860 Global step 860 Train loss 1.302750 on epoch=53
06/03/2022 20:54:07 - INFO - __main__ - Step 870 Global step 870 Train loss 1.048953 on epoch=54
06/03/2022 20:54:13 - INFO - __main__ - Step 880 Global step 880 Train loss 0.854059 on epoch=54
06/03/2022 20:54:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.985799 on epoch=55
06/03/2022 20:54:24 - INFO - __main__ - Step 900 Global step 900 Train loss 0.823252 on epoch=56
06/03/2022 20:54:27 - INFO - __main__ - Global step 900 Train loss 1.002962 Classification-F1 0.3333333333333333 on epoch=56
06/03/2022 20:54:32 - INFO - __main__ - Step 910 Global step 910 Train loss 0.720379 on epoch=56
06/03/2022 20:54:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.604328 on epoch=57
06/03/2022 20:54:43 - INFO - __main__ - Step 930 Global step 930 Train loss 0.588590 on epoch=58
06/03/2022 20:54:49 - INFO - __main__ - Step 940 Global step 940 Train loss 0.490668 on epoch=58
06/03/2022 20:54:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.491496 on epoch=59
06/03/2022 20:54:58 - INFO - __main__ - Global step 950 Train loss 0.579092 Classification-F1 0.3333333333333333 on epoch=59
06/03/2022 20:55:03 - INFO - __main__ - Step 960 Global step 960 Train loss 0.558047 on epoch=59
06/03/2022 20:55:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.524230 on epoch=60
06/03/2022 20:55:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.541320 on epoch=61
06/03/2022 20:55:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.753212 on epoch=61
06/03/2022 20:55:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.471783 on epoch=62
06/03/2022 20:55:26 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:55:26 - INFO - __main__ - Printing 3 examples
06/03/2022 20:55:26 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/03/2022 20:55:26 - INFO - __main__ - ['false']
06/03/2022 20:55:26 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/03/2022 20:55:26 - INFO - __main__ - ['false']
06/03/2022 20:55:26 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/03/2022 20:55:26 - INFO - __main__ - ['false']
06/03/2022 20:55:26 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:55:26 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:55:26 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 20:55:26 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:55:26 - INFO - __main__ - Printing 3 examples
06/03/2022 20:55:26 - INFO - __main__ -  [wiki_qa] question: what year did aerosmith i dont want to miss a thing [SEP] answer: In the UK, the song peaked at number four, becoming Aerosmith's highest charting song in the UK, where it was the 17th best-selling single of 1998 , and has sold over a million copies.
06/03/2022 20:55:26 - INFO - __main__ - ['false']
06/03/2022 20:55:26 - INFO - __main__ -  [wiki_qa] question: How did the pendulum improve upon earlier clocks? [SEP] answer: When released, the restoring force combined with the pendulum's mass causes it to oscillate about the equilibrium position, swinging back and forth.
06/03/2022 20:55:26 - INFO - __main__ - ['false']
06/03/2022 20:55:26 - INFO - __main__ -  [wiki_qa] question: what is puerto rico currency [SEP] answer: However, printing of these banknotes ceased after 1815.
06/03/2022 20:55:26 - INFO - __main__ - ['false']
06/03/2022 20:55:26 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:55:26 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:55:27 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 20:55:28 - INFO - __main__ - Global step 1000 Train loss 0.569718 Classification-F1 0.4531123388581953 on epoch=62
06/03/2022 20:55:28 - INFO - __main__ - save last model!
06/03/2022 20:55:35 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 20:55:36 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 20:55:36 - INFO - __main__ - Printing 3 examples
06/03/2022 20:55:36 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 20:55:36 - INFO - __main__ - ['false']
06/03/2022 20:55:36 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 20:55:36 - INFO - __main__ - ['false']
06/03/2022 20:55:36 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 20:55:36 - INFO - __main__ - ['false']
06/03/2022 20:55:36 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:55:38 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:55:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 20:55:38 - INFO - __main__ - Starting training!
06/03/2022 20:55:41 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 20:56:12 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_87_0.0002_8_predictions.txt
06/03/2022 20:56:12 - INFO - __main__ - Classification-F1 on test data: 0.4347
06/03/2022 20:56:12 - INFO - __main__ - prefix=wiki_qa_128_87, lr=0.0002, bsz=8, dev_performance=0.566081817765358, test_performance=0.4346613620174257
06/03/2022 20:56:12 - INFO - __main__ - Running ... prefix=wiki_qa_128_87, lr=0.0001, bsz=8 ...
06/03/2022 20:56:13 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:56:13 - INFO - __main__ - Printing 3 examples
06/03/2022 20:56:13 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
06/03/2022 20:56:13 - INFO - __main__ - ['false']
06/03/2022 20:56:13 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
06/03/2022 20:56:13 - INFO - __main__ - ['false']
06/03/2022 20:56:13 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
06/03/2022 20:56:13 - INFO - __main__ - ['false']
06/03/2022 20:56:13 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:56:13 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:56:13 - INFO - __main__ - Loaded 256 examples from train data
06/03/2022 20:56:13 - INFO - __main__ - Start tokenizing ... 256 instances
06/03/2022 20:56:13 - INFO - __main__ - Printing 3 examples
06/03/2022 20:56:13 - INFO - __main__ -  [wiki_qa] question: what year did aerosmith i dont want to miss a thing [SEP] answer: In the UK, the song peaked at number four, becoming Aerosmith's highest charting song in the UK, where it was the 17th best-selling single of 1998 , and has sold over a million copies.
06/03/2022 20:56:13 - INFO - __main__ - ['false']
06/03/2022 20:56:13 - INFO - __main__ -  [wiki_qa] question: How did the pendulum improve upon earlier clocks? [SEP] answer: When released, the restoring force combined with the pendulum's mass causes it to oscillate about the equilibrium position, swinging back and forth.
06/03/2022 20:56:13 - INFO - __main__ - ['false']
06/03/2022 20:56:13 - INFO - __main__ -  [wiki_qa] question: what is puerto rico currency [SEP] answer: However, printing of these banknotes ceased after 1815.
06/03/2022 20:56:13 - INFO - __main__ - ['false']
06/03/2022 20:56:13 - INFO - __main__ - Tokenizing Input ...
06/03/2022 20:56:13 - INFO - __main__ - Tokenizing Output ...
06/03/2022 20:56:14 - INFO - __main__ - Loaded 256 examples from dev data
06/03/2022 20:56:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
06/03/2022 20:56:25 - INFO - __main__ - Starting training!
06/03/2022 20:56:30 - INFO - __main__ - Step 10 Global step 10 Train loss 24.289349 on epoch=0
06/03/2022 20:56:35 - INFO - __main__ - Step 20 Global step 20 Train loss 20.577280 on epoch=1
06/03/2022 20:56:40 - INFO - __main__ - Step 30 Global step 30 Train loss 19.027012 on epoch=1
06/03/2022 20:56:46 - INFO - __main__ - Step 40 Global step 40 Train loss 18.832447 on epoch=2
06/03/2022 20:56:51 - INFO - __main__ - Step 50 Global step 50 Train loss 17.032070 on epoch=3
06/03/2022 20:57:44 - INFO - __main__ - Global step 50 Train loss 19.951632 Classification-F1 0.0 on epoch=3
06/03/2022 20:57:50 - INFO - __main__ - Step 60 Global step 60 Train loss 16.881742 on epoch=3
06/03/2022 20:57:56 - INFO - __main__ - Step 70 Global step 70 Train loss 16.767008 on epoch=4
06/03/2022 20:58:01 - INFO - __main__ - Step 80 Global step 80 Train loss 15.710437 on epoch=4
06/03/2022 20:58:07 - INFO - __main__ - Step 90 Global step 90 Train loss 16.212912 on epoch=5
06/03/2022 20:58:12 - INFO - __main__ - Step 100 Global step 100 Train loss 15.627645 on epoch=6
06/03/2022 20:58:45 - INFO - __main__ - Global step 100 Train loss 16.239948 Classification-F1 0.0 on epoch=6
06/03/2022 20:58:51 - INFO - __main__ - Step 110 Global step 110 Train loss 15.258594 on epoch=6
06/03/2022 20:58:56 - INFO - __main__ - Step 120 Global step 120 Train loss 14.733458 on epoch=7
06/03/2022 20:59:01 - INFO - __main__ - Step 130 Global step 130 Train loss 14.716896 on epoch=8
06/03/2022 20:59:07 - INFO - __main__ - Step 140 Global step 140 Train loss 13.459002 on epoch=8
06/03/2022 20:59:12 - INFO - __main__ - Step 150 Global step 150 Train loss 13.801468 on epoch=9
06/03/2022 20:59:38 - INFO - __main__ - Global step 150 Train loss 14.393885 Classification-F1 0.0 on epoch=9
06/03/2022 20:59:43 - INFO - __main__ - Step 160 Global step 160 Train loss 13.038922 on epoch=9
06/03/2022 20:59:49 - INFO - __main__ - Step 170 Global step 170 Train loss 13.290515 on epoch=10
06/03/2022 20:59:54 - INFO - __main__ - Step 180 Global step 180 Train loss 12.729886 on epoch=11
06/03/2022 21:00:00 - INFO - __main__ - Step 190 Global step 190 Train loss 11.252901 on epoch=11
06/03/2022 21:00:05 - INFO - __main__ - Step 200 Global step 200 Train loss 10.555521 on epoch=12
06/03/2022 21:00:28 - INFO - __main__ - Global step 200 Train loss 12.173549 Classification-F1 0.0 on epoch=12
06/03/2022 21:00:34 - INFO - __main__ - Step 210 Global step 210 Train loss 8.739859 on epoch=13
06/03/2022 21:00:39 - INFO - __main__ - Step 220 Global step 220 Train loss 7.183746 on epoch=13
06/03/2022 21:00:45 - INFO - __main__ - Step 230 Global step 230 Train loss 5.254153 on epoch=14
06/03/2022 21:00:50 - INFO - __main__ - Step 240 Global step 240 Train loss 2.007404 on epoch=14
06/03/2022 21:00:56 - INFO - __main__ - Step 250 Global step 250 Train loss 1.365793 on epoch=15
06/03/2022 21:00:58 - INFO - __main__ - Global step 250 Train loss 4.910191 Classification-F1 0.32342974574233185 on epoch=15
06/03/2022 21:01:05 - INFO - __main__ - Step 260 Global step 260 Train loss 1.654295 on epoch=16
06/03/2022 21:01:10 - INFO - __main__ - Step 270 Global step 270 Train loss 0.849802 on epoch=16
06/03/2022 21:01:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.556843 on epoch=17
06/03/2022 21:01:21 - INFO - __main__ - Step 290 Global step 290 Train loss 1.303762 on epoch=18
06/03/2022 21:01:26 - INFO - __main__ - Step 300 Global step 300 Train loss 0.685839 on epoch=18
06/03/2022 21:01:29 - INFO - __main__ - Global step 300 Train loss 1.010108 Classification-F1 0.34195559333697656 on epoch=18
06/03/2022 21:01:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.578595 on epoch=19
06/03/2022 21:01:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.442221 on epoch=19
06/03/2022 21:01:47 - INFO - __main__ - Step 330 Global step 330 Train loss 0.497284 on epoch=20
06/03/2022 21:01:53 - INFO - __main__ - Step 340 Global step 340 Train loss 0.439379 on epoch=21
06/03/2022 21:01:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.449344 on epoch=21
06/03/2022 21:02:01 - INFO - __main__ - Global step 350 Train loss 0.481365 Classification-F1 0.5426267808878098 on epoch=21
06/03/2022 21:02:08 - INFO - __main__ - Step 360 Global step 360 Train loss 0.392656 on epoch=22
06/03/2022 21:02:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.447294 on epoch=23
06/03/2022 21:02:19 - INFO - __main__ - Step 380 Global step 380 Train loss 0.356810 on epoch=23
06/03/2022 21:02:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.480278 on epoch=24
06/03/2022 21:02:30 - INFO - __main__ - Step 400 Global step 400 Train loss 0.408430 on epoch=24
06/03/2022 21:02:33 - INFO - __main__ - Global step 400 Train loss 0.417094 Classification-F1 0.3333333333333333 on epoch=24
06/03/2022 21:02:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.404849 on epoch=25
06/03/2022 21:02:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.426551 on epoch=26
06/03/2022 21:02:49 - INFO - __main__ - Step 430 Global step 430 Train loss 0.575024 on epoch=26
06/03/2022 21:02:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.425258 on epoch=27
06/03/2022 21:03:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.451397 on epoch=28
06/03/2022 21:03:03 - INFO - __main__ - Global step 450 Train loss 0.456616 Classification-F1 0.3486005089058525 on epoch=28
06/03/2022 21:03:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.744142 on epoch=28
06/03/2022 21:03:14 - INFO - __main__ - Step 470 Global step 470 Train loss 0.423942 on epoch=29
06/03/2022 21:03:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.378654 on epoch=29
06/03/2022 21:03:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.353186 on epoch=30
06/03/2022 21:03:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.413208 on epoch=31
06/03/2022 21:03:34 - INFO - __main__ - Global step 500 Train loss 0.462626 Classification-F1 0.5933346300979058 on epoch=31
06/03/2022 21:03:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.368230 on epoch=31
06/03/2022 21:03:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.406657 on epoch=32
06/03/2022 21:03:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.467561 on epoch=33
06/03/2022 21:03:57 - INFO - __main__ - Step 540 Global step 540 Train loss 0.560371 on epoch=33
06/03/2022 21:04:02 - INFO - __main__ - Step 550 Global step 550 Train loss 0.367628 on epoch=34
06/03/2022 21:04:05 - INFO - __main__ - Global step 550 Train loss 0.434089 Classification-F1 0.49473684210526314 on epoch=34
06/03/2022 21:04:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.381620 on epoch=34
06/03/2022 21:04:16 - INFO - __main__ - Step 570 Global step 570 Train loss 0.366074 on epoch=35
06/03/2022 21:04:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.445215 on epoch=36
06/03/2022 21:04:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.730895 on epoch=36
06/03/2022 21:04:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.827217 on epoch=37
06/03/2022 21:04:35 - INFO - __main__ - Global step 600 Train loss 0.550204 Classification-F1 0.35693779904306216 on epoch=37
06/03/2022 21:04:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.524995 on epoch=38
06/03/2022 21:04:46 - INFO - __main__ - Step 620 Global step 620 Train loss 0.493407 on epoch=38
06/03/2022 21:04:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.361797 on epoch=39
06/03/2022 21:04:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.414229 on epoch=39
06/03/2022 21:05:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.340532 on epoch=40
06/03/2022 21:05:05 - INFO - __main__ - Global step 650 Train loss 0.426992 Classification-F1 0.4538513361778576 on epoch=40
06/03/2022 21:05:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.350546 on epoch=41
06/03/2022 21:05:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.414591 on epoch=41
06/03/2022 21:05:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.391023 on epoch=42
06/03/2022 21:05:28 - INFO - __main__ - Step 690 Global step 690 Train loss 0.388087 on epoch=43
06/03/2022 21:05:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.327714 on epoch=43
06/03/2022 21:05:36 - INFO - __main__ - Global step 700 Train loss 0.374392 Classification-F1 0.3486005089058525 on epoch=43
06/03/2022 21:05:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.350585 on epoch=44
06/03/2022 21:05:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.386922 on epoch=44
06/03/2022 21:05:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.323062 on epoch=45
06/03/2022 21:05:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.313185 on epoch=46
06/03/2022 21:06:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.301770 on epoch=46
06/03/2022 21:06:07 - INFO - __main__ - Global step 750 Train loss 0.335105 Classification-F1 0.6476476476476476 on epoch=46
06/03/2022 21:06:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.388390 on epoch=47
06/03/2022 21:06:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.353451 on epoch=48
06/03/2022 21:06:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.360456 on epoch=48
06/03/2022 21:06:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.307398 on epoch=49
06/03/2022 21:06:35 - INFO - __main__ - Step 800 Global step 800 Train loss 0.308727 on epoch=49
06/03/2022 21:06:37 - INFO - __main__ - Global step 800 Train loss 0.343685 Classification-F1 0.6209889818754188 on epoch=49
06/03/2022 21:06:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.317482 on epoch=50
06/03/2022 21:06:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.389764 on epoch=51
06/03/2022 21:06:54 - INFO - __main__ - Step 830 Global step 830 Train loss 0.292060 on epoch=51
06/03/2022 21:06:59 - INFO - __main__ - Step 840 Global step 840 Train loss 0.258194 on epoch=52
06/03/2022 21:07:04 - INFO - __main__ - Step 850 Global step 850 Train loss 0.281739 on epoch=53
06/03/2022 21:07:07 - INFO - __main__ - Global step 850 Train loss 0.307848 Classification-F1 0.3486005089058525 on epoch=53
06/03/2022 21:07:13 - INFO - __main__ - Step 860 Global step 860 Train loss 0.273551 on epoch=53
06/03/2022 21:07:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.283290 on epoch=54
06/03/2022 21:07:23 - INFO - __main__ - Step 880 Global step 880 Train loss 0.278106 on epoch=54
06/03/2022 21:07:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.253979 on epoch=55
06/03/2022 21:07:34 - INFO - __main__ - Step 900 Global step 900 Train loss 0.306776 on epoch=56
06/03/2022 21:07:37 - INFO - __main__ - Global step 900 Train loss 0.279141 Classification-F1 0.6476633227306092 on epoch=56
06/03/2022 21:07:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.291498 on epoch=56
06/03/2022 21:07:49 - INFO - __main__ - Step 920 Global step 920 Train loss 0.292666 on epoch=57
06/03/2022 21:07:54 - INFO - __main__ - Step 930 Global step 930 Train loss 0.227682 on epoch=58
06/03/2022 21:07:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.225855 on epoch=58
06/03/2022 21:08:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.261597 on epoch=59
06/03/2022 21:08:08 - INFO - __main__ - Global step 950 Train loss 0.259860 Classification-F1 0.6493205901339925 on epoch=59
06/03/2022 21:08:14 - INFO - __main__ - Step 960 Global step 960 Train loss 0.229776 on epoch=59
06/03/2022 21:08:19 - INFO - __main__ - Step 970 Global step 970 Train loss 0.228517 on epoch=60
06/03/2022 21:08:24 - INFO - __main__ - Step 980 Global step 980 Train loss 0.218001 on epoch=61
06/03/2022 21:08:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.222216 on epoch=61
06/03/2022 21:08:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.210992 on epoch=62
06/03/2022 21:08:38 - INFO - __main__ - Global step 1000 Train loss 0.221900 Classification-F1 0.47871071893746214 on epoch=62
06/03/2022 21:08:38 - INFO - __main__ - save last model!
06/03/2022 21:08:45 - INFO - __main__ - Loading checkpoint on the fly
06/03/2022 21:08:46 - INFO - __main__ - Start tokenizing ... 2733 instances
06/03/2022 21:08:46 - INFO - __main__ - Printing 3 examples
06/03/2022 21:08:46 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
06/03/2022 21:08:46 - INFO - __main__ - ['false']
06/03/2022 21:08:46 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
06/03/2022 21:08:46 - INFO - __main__ - ['false']
06/03/2022 21:08:46 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
06/03/2022 21:08:46 - INFO - __main__ - ['false']
06/03/2022 21:08:46 - INFO - __main__ - Tokenizing Input ...
06/03/2022 21:08:48 - INFO - __main__ - Tokenizing Output ...
06/03/2022 21:08:51 - INFO - __main__ - Loaded 2733 examples from test data
06/03/2022 21:09:20 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-wiki_qa/wiki_qa_128_87_0.0001_8_predictions.txt
06/03/2022 21:09:20 - INFO - __main__ - Classification-F1 on test data: 0.4155
06/03/2022 21:09:20 - INFO - __main__ - prefix=wiki_qa_128_87, lr=0.0001, bsz=8, dev_performance=0.6493205901339925, test_performance=0.4155124848583505
