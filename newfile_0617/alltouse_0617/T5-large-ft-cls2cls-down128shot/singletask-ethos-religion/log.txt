05/22/2022 07:51:09 - INFO - __main__ - Namespace(task_dir='data_128/ethos-religion/', task_name='ethos-religion', identifier='T5-large-ft-cls2cls-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/22/2022 07:51:09 - INFO - __main__ - models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion
05/22/2022 07:51:09 - INFO - __main__ - Namespace(task_dir='data_128/ethos-religion/', task_name='ethos-religion', identifier='T5-large-ft-cls2cls-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/22/2022 07:51:09 - INFO - __main__ - models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion
05/22/2022 07:51:11 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/22/2022 07:51:11 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/22/2022 07:51:11 - INFO - __main__ - args.device: cuda:0
05/22/2022 07:51:11 - INFO - __main__ - Using 2 gpus
05/22/2022 07:51:11 - INFO - __main__ - Fine-tuning the following samples: ['ethos-religion_128_100', 'ethos-religion_128_13', 'ethos-religion_128_21', 'ethos-religion_128_42', 'ethos-religion_128_87']
05/22/2022 07:51:11 - INFO - __main__ - args.device: cuda:1
05/22/2022 07:51:11 - INFO - __main__ - Using 2 gpus
05/22/2022 07:51:11 - INFO - __main__ - Fine-tuning the following samples: ['ethos-religion_128_100', 'ethos-religion_128_13', 'ethos-religion_128_21', 'ethos-religion_128_42', 'ethos-religion_128_87']
05/22/2022 07:51:16 - INFO - __main__ - Running ... prefix=ethos-religion_128_100, lr=0.0005, bsz=8 ...
05/22/2022 07:51:16 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 07:51:16 - INFO - __main__ - Printing 3 examples
05/22/2022 07:51:16 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/22/2022 07:51:16 - INFO - __main__ - ['false']
05/22/2022 07:51:16 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/22/2022 07:51:16 - INFO - __main__ - ['false']
05/22/2022 07:51:16 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/22/2022 07:51:16 - INFO - __main__ - ['false']
05/22/2022 07:51:16 - INFO - __main__ - Tokenizing Input ...
05/22/2022 07:51:16 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 07:51:16 - INFO - __main__ - Printing 3 examples
05/22/2022 07:51:16 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/22/2022 07:51:16 - INFO - __main__ - ['false']
05/22/2022 07:51:16 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/22/2022 07:51:16 - INFO - __main__ - ['false']
05/22/2022 07:51:16 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/22/2022 07:51:16 - INFO - __main__ - ['false']
05/22/2022 07:51:16 - INFO - __main__ - Tokenizing Input ...
05/22/2022 07:51:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 07:51:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 07:51:17 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 07:51:17 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 07:51:17 - INFO - __main__ - Printing 3 examples
05/22/2022 07:51:17 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/22/2022 07:51:17 - INFO - __main__ - ['false']
05/22/2022 07:51:17 - INFO - __main__ -  [ethos-religion] Crazy auntie get rid of your autistic son and make good to planet
05/22/2022 07:51:17 - INFO - __main__ - ['false']
05/22/2022 07:51:17 - INFO - __main__ -  [ethos-religion] I don’t like this gender at all. I definitely wouldn’t hire any male bitch at ma shop
05/22/2022 07:51:17 - INFO - __main__ - ['false']
05/22/2022 07:51:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 07:51:17 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 07:51:17 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 07:51:17 - INFO - __main__ - Printing 3 examples
05/22/2022 07:51:17 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/22/2022 07:51:17 - INFO - __main__ - ['false']
05/22/2022 07:51:17 - INFO - __main__ -  [ethos-religion] Crazy auntie get rid of your autistic son and make good to planet
05/22/2022 07:51:17 - INFO - __main__ - ['false']
05/22/2022 07:51:17 - INFO - __main__ -  [ethos-religion] I don’t like this gender at all. I definitely wouldn’t hire any male bitch at ma shop
05/22/2022 07:51:17 - INFO - __main__ - ['false']
05/22/2022 07:51:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 07:51:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 07:51:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 07:51:17 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 07:51:17 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 07:51:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 07:51:30 - INFO - __main__ - Starting training!
05/22/2022 07:51:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 07:51:30 - INFO - __main__ - Starting training!
05/22/2022 07:51:35 - INFO - __main__ - Step 10 Global step 10 Train loss 23.969357 on epoch=0
05/22/2022 07:51:39 - INFO - __main__ - Step 20 Global step 20 Train loss 17.454412 on epoch=1
05/22/2022 07:51:44 - INFO - __main__ - Step 30 Global step 30 Train loss 14.498968 on epoch=2
05/22/2022 07:51:49 - INFO - __main__ - Step 40 Global step 40 Train loss 12.799173 on epoch=3
05/22/2022 07:51:54 - INFO - __main__ - Step 50 Global step 50 Train loss 8.914678 on epoch=4
05/22/2022 07:52:35 - INFO - __main__ - Global step 50 Train loss 15.527317 Classification-F1 0.05405405405405406 on epoch=4
05/22/2022 07:52:41 - INFO - __main__ - Step 60 Global step 60 Train loss 5.097410 on epoch=4
05/22/2022 07:52:46 - INFO - __main__ - Step 70 Global step 70 Train loss 0.994381 on epoch=5
05/22/2022 07:52:51 - INFO - __main__ - Step 80 Global step 80 Train loss 0.640757 on epoch=6
05/22/2022 07:52:56 - INFO - __main__ - Step 90 Global step 90 Train loss 0.548624 on epoch=7
05/22/2022 07:53:01 - INFO - __main__ - Step 100 Global step 100 Train loss 0.340668 on epoch=8
05/22/2022 07:53:02 - INFO - __main__ - Global step 100 Train loss 1.524368 Classification-F1 0.43859649122807015 on epoch=8
05/22/2022 07:53:08 - INFO - __main__ - Step 110 Global step 110 Train loss 0.386153 on epoch=9
05/22/2022 07:53:13 - INFO - __main__ - Step 120 Global step 120 Train loss 0.239781 on epoch=9
05/22/2022 07:53:18 - INFO - __main__ - Step 130 Global step 130 Train loss 0.291131 on epoch=10
05/22/2022 07:53:23 - INFO - __main__ - Step 140 Global step 140 Train loss 0.171248 on epoch=11
05/22/2022 07:53:28 - INFO - __main__ - Step 150 Global step 150 Train loss 0.190013 on epoch=12
05/22/2022 07:53:29 - INFO - __main__ - Global step 150 Train loss 0.255665 Classification-F1 0.4838709677419355 on epoch=12
05/22/2022 07:53:35 - INFO - __main__ - Step 160 Global step 160 Train loss 0.152528 on epoch=13
05/22/2022 07:53:40 - INFO - __main__ - Step 170 Global step 170 Train loss 0.219999 on epoch=14
05/22/2022 07:53:45 - INFO - __main__ - Step 180 Global step 180 Train loss 0.168125 on epoch=14
05/22/2022 07:53:50 - INFO - __main__ - Step 190 Global step 190 Train loss 0.134263 on epoch=15
05/22/2022 07:53:55 - INFO - __main__ - Step 200 Global step 200 Train loss 0.196334 on epoch=16
05/22/2022 07:53:56 - INFO - __main__ - Global step 200 Train loss 0.174250 Classification-F1 0.4796747967479675 on epoch=16
05/22/2022 07:54:01 - INFO - __main__ - Step 210 Global step 210 Train loss 0.107447 on epoch=17
05/22/2022 07:54:06 - INFO - __main__ - Step 220 Global step 220 Train loss 0.116974 on epoch=18
05/22/2022 07:54:11 - INFO - __main__ - Step 230 Global step 230 Train loss 0.048786 on epoch=19
05/22/2022 07:54:16 - INFO - __main__ - Step 240 Global step 240 Train loss 0.036806 on epoch=19
05/22/2022 07:54:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.035710 on epoch=20
05/22/2022 07:54:22 - INFO - __main__ - Global step 250 Train loss 0.069145 Classification-F1 0.47107438016528924 on epoch=20
05/22/2022 07:54:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.096587 on epoch=21
05/22/2022 07:54:32 - INFO - __main__ - Step 270 Global step 270 Train loss 0.076318 on epoch=22
05/22/2022 07:54:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.019373 on epoch=23
05/22/2022 07:54:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.001605 on epoch=24
05/22/2022 07:54:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.011081 on epoch=24
05/22/2022 07:54:48 - INFO - __main__ - Global step 300 Train loss 0.040993 Classification-F1 0.47540983606557374 on epoch=24
05/22/2022 07:54:53 - INFO - __main__ - Step 310 Global step 310 Train loss 0.008070 on epoch=25
05/22/2022 07:54:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.007050 on epoch=26
05/22/2022 07:55:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.000505 on epoch=27
05/22/2022 07:55:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.001752 on epoch=28
05/22/2022 07:55:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.026375 on epoch=29
05/22/2022 07:55:14 - INFO - __main__ - Global step 350 Train loss 0.008751 Classification-F1 0.4817813765182186 on epoch=29
05/22/2022 07:55:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.021513 on epoch=29
05/22/2022 07:55:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.006589 on epoch=30
05/22/2022 07:55:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.001858 on epoch=31
05/22/2022 07:55:34 - INFO - __main__ - Step 390 Global step 390 Train loss 0.000454 on epoch=32
05/22/2022 07:55:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.001609 on epoch=33
05/22/2022 07:55:40 - INFO - __main__ - Global step 400 Train loss 0.006405 Classification-F1 0.46887966804979253 on epoch=33
05/22/2022 07:55:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.000555 on epoch=34
05/22/2022 07:55:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.000092 on epoch=34
05/22/2022 07:55:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.000980 on epoch=35
05/22/2022 07:56:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.001839 on epoch=36
05/22/2022 07:56:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.001136 on epoch=37
05/22/2022 07:56:06 - INFO - __main__ - Global step 450 Train loss 0.000921 Classification-F1 0.47107438016528924 on epoch=37
05/22/2022 07:56:11 - INFO - __main__ - Step 460 Global step 460 Train loss 0.000402 on epoch=38
05/22/2022 07:56:16 - INFO - __main__ - Step 470 Global step 470 Train loss 0.009700 on epoch=39
05/22/2022 07:56:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.018456 on epoch=39
05/22/2022 07:56:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.000361 on epoch=40
05/22/2022 07:56:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.005417 on epoch=41
05/22/2022 07:56:32 - INFO - __main__ - Global step 500 Train loss 0.006867 Classification-F1 0.4775510204081633 on epoch=41
05/22/2022 07:56:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.000820 on epoch=42
05/22/2022 07:56:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.000582 on epoch=43
05/22/2022 07:56:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.001604 on epoch=44
05/22/2022 07:56:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.001210 on epoch=44
05/22/2022 07:56:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.000328 on epoch=45
05/22/2022 07:56:58 - INFO - __main__ - Global step 550 Train loss 0.000909 Classification-F1 0.4796747967479675 on epoch=45
05/22/2022 07:57:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.000165 on epoch=46
05/22/2022 07:57:07 - INFO - __main__ - Step 570 Global step 570 Train loss 0.000205 on epoch=47
05/22/2022 07:57:12 - INFO - __main__ - Step 580 Global step 580 Train loss 0.026056 on epoch=48
05/22/2022 07:57:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.031954 on epoch=49
05/22/2022 07:57:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.067695 on epoch=49
05/22/2022 07:57:24 - INFO - __main__ - Global step 600 Train loss 0.025215 Classification-F1 0.47107438016528924 on epoch=49
05/22/2022 07:57:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.067250 on epoch=50
05/22/2022 07:57:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.006340 on epoch=51
05/22/2022 07:57:38 - INFO - __main__ - Step 630 Global step 630 Train loss 0.000713 on epoch=52
05/22/2022 07:57:43 - INFO - __main__ - Step 640 Global step 640 Train loss 0.000741 on epoch=53
05/22/2022 07:57:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000158 on epoch=54
05/22/2022 07:57:50 - INFO - __main__ - Global step 650 Train loss 0.015041 Classification-F1 0.4775510204081633 on epoch=54
05/22/2022 07:57:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000429 on epoch=54
05/22/2022 07:57:59 - INFO - __main__ - Step 670 Global step 670 Train loss 0.000185 on epoch=55
05/22/2022 07:58:04 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000067 on epoch=56
05/22/2022 07:58:09 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000221 on epoch=57
05/22/2022 07:58:14 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000071 on epoch=58
05/22/2022 07:58:16 - INFO - __main__ - Global step 700 Train loss 0.000195 Classification-F1 0.4775510204081633 on epoch=58
05/22/2022 07:58:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000273 on epoch=59
05/22/2022 07:58:25 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000172 on epoch=59
05/22/2022 07:58:30 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000820 on epoch=60
05/22/2022 07:58:35 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000234 on epoch=61
05/22/2022 07:58:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000142 on epoch=62
05/22/2022 07:58:42 - INFO - __main__ - Global step 750 Train loss 0.000328 Classification-F1 0.4775510204081633 on epoch=62
05/22/2022 07:58:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000410 on epoch=63
05/22/2022 07:58:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000051 on epoch=64
05/22/2022 07:58:56 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000064 on epoch=64
05/22/2022 07:59:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000043 on epoch=65
05/22/2022 07:59:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000200 on epoch=66
05/22/2022 07:59:08 - INFO - __main__ - Global step 800 Train loss 0.000154 Classification-F1 0.47540983606557374 on epoch=66
05/22/2022 07:59:12 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000036 on epoch=67
05/22/2022 07:59:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000036 on epoch=68
05/22/2022 07:59:22 - INFO - __main__ - Step 830 Global step 830 Train loss 0.003007 on epoch=69
05/22/2022 07:59:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000128 on epoch=69
05/22/2022 07:59:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000361 on epoch=70
05/22/2022 07:59:34 - INFO - __main__ - Global step 850 Train loss 0.000714 Classification-F1 0.47540983606557374 on epoch=70
05/22/2022 07:59:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000058 on epoch=71
05/22/2022 07:59:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000020 on epoch=72
05/22/2022 07:59:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.068788 on epoch=73
05/22/2022 07:59:53 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000050 on epoch=74
05/22/2022 07:59:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000068 on epoch=74
05/22/2022 08:00:00 - INFO - __main__ - Global step 900 Train loss 0.013797 Classification-F1 0.47107438016528924 on epoch=74
05/22/2022 08:00:05 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000103 on epoch=75
05/22/2022 08:00:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000028 on epoch=76
05/22/2022 08:00:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000057 on epoch=77
05/22/2022 08:00:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000054 on epoch=78
05/22/2022 08:00:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000037 on epoch=79
05/22/2022 08:00:26 - INFO - __main__ - Global step 950 Train loss 0.000056 Classification-F1 0.4732510288065844 on epoch=79
05/22/2022 08:00:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000067 on epoch=79
05/22/2022 08:00:35 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000414 on epoch=80
05/22/2022 08:00:40 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000061 on epoch=81
05/22/2022 08:00:45 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000054 on epoch=82
05/22/2022 08:00:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000032 on epoch=83
05/22/2022 08:00:51 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 08:00:51 - INFO - __main__ - Printing 3 examples
05/22/2022 08:00:51 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/22/2022 08:00:51 - INFO - __main__ - ['false']
05/22/2022 08:00:51 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/22/2022 08:00:51 - INFO - __main__ - ['false']
05/22/2022 08:00:51 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/22/2022 08:00:51 - INFO - __main__ - ['false']
05/22/2022 08:00:51 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:00:52 - INFO - __main__ - Global step 1000 Train loss 0.000126 Classification-F1 0.4732510288065844 on epoch=83
05/22/2022 08:00:52 - INFO - __main__ - save last model!
05/22/2022 08:00:52 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:00:52 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 08:00:52 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 08:00:52 - INFO - __main__ - Printing 3 examples
05/22/2022 08:00:52 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/22/2022 08:00:52 - INFO - __main__ - ['false']
05/22/2022 08:00:52 - INFO - __main__ -  [ethos-religion] Crazy auntie get rid of your autistic son and make good to planet
05/22/2022 08:00:52 - INFO - __main__ - ['false']
05/22/2022 08:00:52 - INFO - __main__ -  [ethos-religion] I don’t like this gender at all. I definitely wouldn’t hire any male bitch at ma shop
05/22/2022 08:00:52 - INFO - __main__ - ['false']
05/22/2022 08:00:52 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:00:52 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:00:52 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 08:01:00 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 08:01:00 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 08:01:00 - INFO - __main__ - Printing 3 examples
05/22/2022 08:01:00 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 08:01:00 - INFO - __main__ - ['false']
05/22/2022 08:01:00 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 08:01:00 - INFO - __main__ - ['false']
05/22/2022 08:01:00 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 08:01:00 - INFO - __main__ - ['true']
05/22/2022 08:01:00 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:01:00 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:01:00 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 08:01:02 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_100_0.0005_8_predictions.txt
05/22/2022 08:01:02 - INFO - __main__ - Classification-F1 on test data: 0.9504
05/22/2022 08:01:02 - INFO - __main__ - prefix=ethos-religion_128_100, lr=0.0005, bsz=8, dev_performance=0.4838709677419355, test_performance=0.9504273504273504
05/22/2022 08:01:02 - INFO - __main__ - Running ... prefix=ethos-religion_128_100, lr=0.0003, bsz=8 ...
05/22/2022 08:01:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 08:01:02 - INFO - __main__ - Starting training!
05/22/2022 08:01:03 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 08:01:03 - INFO - __main__ - Printing 3 examples
05/22/2022 08:01:03 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/22/2022 08:01:03 - INFO - __main__ - ['false']
05/22/2022 08:01:03 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/22/2022 08:01:03 - INFO - __main__ - ['false']
05/22/2022 08:01:03 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/22/2022 08:01:03 - INFO - __main__ - ['false']
05/22/2022 08:01:03 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:01:03 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:01:03 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 08:01:03 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 08:01:03 - INFO - __main__ - Printing 3 examples
05/22/2022 08:01:03 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/22/2022 08:01:03 - INFO - __main__ - ['false']
05/22/2022 08:01:03 - INFO - __main__ -  [ethos-religion] Crazy auntie get rid of your autistic son and make good to planet
05/22/2022 08:01:03 - INFO - __main__ - ['false']
05/22/2022 08:01:03 - INFO - __main__ -  [ethos-religion] I don’t like this gender at all. I definitely wouldn’t hire any male bitch at ma shop
05/22/2022 08:01:03 - INFO - __main__ - ['false']
05/22/2022 08:01:03 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:01:03 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:01:03 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 08:01:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 08:01:16 - INFO - __main__ - Starting training!
05/22/2022 08:01:20 - INFO - __main__ - Step 10 Global step 10 Train loss 23.653524 on epoch=0
05/22/2022 08:01:25 - INFO - __main__ - Step 20 Global step 20 Train loss 19.245970 on epoch=1
05/22/2022 08:01:30 - INFO - __main__ - Step 30 Global step 30 Train loss 16.237375 on epoch=2
05/22/2022 08:01:35 - INFO - __main__ - Step 40 Global step 40 Train loss 15.216916 on epoch=3
05/22/2022 08:01:41 - INFO - __main__ - Step 50 Global step 50 Train loss 14.432653 on epoch=4
05/22/2022 08:01:43 - INFO - __main__ - Global step 50 Train loss 17.757288 Classification-F1 0.0 on epoch=4
05/22/2022 08:01:48 - INFO - __main__ - Step 60 Global step 60 Train loss 14.351407 on epoch=4
05/22/2022 08:01:53 - INFO - __main__ - Step 70 Global step 70 Train loss 12.781641 on epoch=5
05/22/2022 08:01:58 - INFO - __main__ - Step 80 Global step 80 Train loss 11.636096 on epoch=6
05/22/2022 08:02:04 - INFO - __main__ - Step 90 Global step 90 Train loss 9.914845 on epoch=7
05/22/2022 08:02:09 - INFO - __main__ - Step 100 Global step 100 Train loss 7.510423 on epoch=8
05/22/2022 08:02:10 - INFO - __main__ - Global step 100 Train loss 11.238882 Classification-F1 0.0 on epoch=8
05/22/2022 08:02:16 - INFO - __main__ - Step 110 Global step 110 Train loss 5.700439 on epoch=9
05/22/2022 08:02:21 - INFO - __main__ - Step 120 Global step 120 Train loss 3.159007 on epoch=9
05/22/2022 08:02:26 - INFO - __main__ - Step 130 Global step 130 Train loss 2.513549 on epoch=10
05/22/2022 08:02:31 - INFO - __main__ - Step 140 Global step 140 Train loss 2.532763 on epoch=11
05/22/2022 08:02:36 - INFO - __main__ - Step 150 Global step 150 Train loss 3.271709 on epoch=12
05/22/2022 08:02:37 - INFO - __main__ - Global step 150 Train loss 3.435494 Classification-F1 1.0 on epoch=12
05/22/2022 08:02:43 - INFO - __main__ - Step 160 Global step 160 Train loss 1.934803 on epoch=13
05/22/2022 08:02:49 - INFO - __main__ - Step 170 Global step 170 Train loss 2.015511 on epoch=14
05/22/2022 08:02:54 - INFO - __main__ - Step 180 Global step 180 Train loss 1.559644 on epoch=14
05/22/2022 08:02:59 - INFO - __main__ - Step 190 Global step 190 Train loss 1.742770 on epoch=15
05/22/2022 08:03:04 - INFO - __main__ - Step 200 Global step 200 Train loss 1.970057 on epoch=16
05/22/2022 08:03:05 - INFO - __main__ - Global step 200 Train loss 1.844557 Classification-F1 1.0 on epoch=16
05/22/2022 08:03:10 - INFO - __main__ - Step 210 Global step 210 Train loss 1.812393 on epoch=17
05/22/2022 08:03:15 - INFO - __main__ - Step 220 Global step 220 Train loss 1.875615 on epoch=18
05/22/2022 08:03:20 - INFO - __main__ - Step 230 Global step 230 Train loss 1.655122 on epoch=19
05/22/2022 08:03:25 - INFO - __main__ - Step 240 Global step 240 Train loss 1.766116 on epoch=19
05/22/2022 08:03:30 - INFO - __main__ - Step 250 Global step 250 Train loss 2.073535 on epoch=20
05/22/2022 08:03:32 - INFO - __main__ - Global step 250 Train loss 1.836556 Classification-F1 1.0 on epoch=20
05/22/2022 08:03:36 - INFO - __main__ - Step 260 Global step 260 Train loss 1.782249 on epoch=21
05/22/2022 08:03:41 - INFO - __main__ - Step 270 Global step 270 Train loss 1.871270 on epoch=22
05/22/2022 08:03:46 - INFO - __main__ - Step 280 Global step 280 Train loss 1.774463 on epoch=23
05/22/2022 08:03:51 - INFO - __main__ - Step 290 Global step 290 Train loss 1.273345 on epoch=24
05/22/2022 08:03:56 - INFO - __main__ - Step 300 Global step 300 Train loss 1.465206 on epoch=24
05/22/2022 08:03:58 - INFO - __main__ - Global step 300 Train loss 1.633307 Classification-F1 1.0 on epoch=24
05/22/2022 08:04:03 - INFO - __main__ - Step 310 Global step 310 Train loss 2.050725 on epoch=25
05/22/2022 08:04:08 - INFO - __main__ - Step 320 Global step 320 Train loss 1.234238 on epoch=26
05/22/2022 08:04:12 - INFO - __main__ - Step 330 Global step 330 Train loss 1.387156 on epoch=27
05/22/2022 08:04:17 - INFO - __main__ - Step 340 Global step 340 Train loss 1.269048 on epoch=28
05/22/2022 08:04:22 - INFO - __main__ - Step 350 Global step 350 Train loss 1.604813 on epoch=29
05/22/2022 08:04:24 - INFO - __main__ - Global step 350 Train loss 1.509196 Classification-F1 1.0 on epoch=29
05/22/2022 08:04:29 - INFO - __main__ - Step 360 Global step 360 Train loss 1.397388 on epoch=29
05/22/2022 08:04:34 - INFO - __main__ - Step 370 Global step 370 Train loss 1.264520 on epoch=30
05/22/2022 08:04:39 - INFO - __main__ - Step 380 Global step 380 Train loss 1.081196 on epoch=31
05/22/2022 08:04:44 - INFO - __main__ - Step 390 Global step 390 Train loss 1.425190 on epoch=32
05/22/2022 08:04:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.850781 on epoch=33
05/22/2022 08:04:50 - INFO - __main__ - Global step 400 Train loss 1.203815 Classification-F1 1.0 on epoch=33
05/22/2022 08:04:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.641889 on epoch=34
05/22/2022 08:05:00 - INFO - __main__ - Step 420 Global step 420 Train loss 1.256627 on epoch=34
05/22/2022 08:05:05 - INFO - __main__ - Step 430 Global step 430 Train loss 1.255930 on epoch=35
05/22/2022 08:05:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.926771 on epoch=36
05/22/2022 08:05:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.777293 on epoch=37
05/22/2022 08:05:16 - INFO - __main__ - Global step 450 Train loss 0.971702 Classification-F1 1.0 on epoch=37
05/22/2022 08:05:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.604250 on epoch=38
05/22/2022 08:05:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.699381 on epoch=39
05/22/2022 08:05:31 - INFO - __main__ - Step 480 Global step 480 Train loss 0.896835 on epoch=39
05/22/2022 08:05:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.797572 on epoch=40
05/22/2022 08:05:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.600244 on epoch=41
05/22/2022 08:05:42 - INFO - __main__ - Global step 500 Train loss 0.719656 Classification-F1 1.0 on epoch=41
05/22/2022 08:05:47 - INFO - __main__ - Step 510 Global step 510 Train loss 0.629470 on epoch=42
05/22/2022 08:05:52 - INFO - __main__ - Step 520 Global step 520 Train loss 0.660288 on epoch=43
05/22/2022 08:05:57 - INFO - __main__ - Step 530 Global step 530 Train loss 0.734564 on epoch=44
05/22/2022 08:06:02 - INFO - __main__ - Step 540 Global step 540 Train loss 0.544933 on epoch=44
05/22/2022 08:06:07 - INFO - __main__ - Step 550 Global step 550 Train loss 0.533485 on epoch=45
05/22/2022 08:06:09 - INFO - __main__ - Global step 550 Train loss 0.620548 Classification-F1 1.0 on epoch=45
05/22/2022 08:06:13 - INFO - __main__ - Step 560 Global step 560 Train loss 0.493106 on epoch=46
05/22/2022 08:06:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.690136 on epoch=47
05/22/2022 08:06:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.561923 on epoch=48
05/22/2022 08:06:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.441498 on epoch=49
05/22/2022 08:06:33 - INFO - __main__ - Step 600 Global step 600 Train loss 0.495731 on epoch=49
05/22/2022 08:06:35 - INFO - __main__ - Global step 600 Train loss 0.536479 Classification-F1 1.0 on epoch=49
05/22/2022 08:06:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.564636 on epoch=50
05/22/2022 08:06:45 - INFO - __main__ - Step 620 Global step 620 Train loss 0.604172 on epoch=51
05/22/2022 08:06:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.577711 on epoch=52
05/22/2022 08:06:55 - INFO - __main__ - Step 640 Global step 640 Train loss 0.346408 on epoch=53
05/22/2022 08:07:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.492571 on epoch=54
05/22/2022 08:07:01 - INFO - __main__ - Global step 650 Train loss 0.517099 Classification-F1 1.0 on epoch=54
05/22/2022 08:07:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.475724 on epoch=54
05/22/2022 08:07:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.414223 on epoch=55
05/22/2022 08:07:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.502802 on epoch=56
05/22/2022 08:07:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.424382 on epoch=57
05/22/2022 08:07:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.380646 on epoch=58
05/22/2022 08:07:28 - INFO - __main__ - Global step 700 Train loss 0.439555 Classification-F1 1.0 on epoch=58
05/22/2022 08:07:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.365328 on epoch=59
05/22/2022 08:07:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.414669 on epoch=59
05/22/2022 08:07:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.496179 on epoch=60
05/22/2022 08:07:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.460352 on epoch=61
05/22/2022 08:07:53 - INFO - __main__ - Step 750 Global step 750 Train loss 0.505587 on epoch=62
05/22/2022 08:07:54 - INFO - __main__ - Global step 750 Train loss 0.448423 Classification-F1 1.0 on epoch=62
05/22/2022 08:07:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.385511 on epoch=63
05/22/2022 08:08:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.436315 on epoch=64
05/22/2022 08:08:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.517286 on epoch=64
05/22/2022 08:08:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.402439 on epoch=65
05/22/2022 08:08:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.430385 on epoch=66
05/22/2022 08:08:20 - INFO - __main__ - Global step 800 Train loss 0.434387 Classification-F1 1.0 on epoch=66
05/22/2022 08:08:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.382048 on epoch=67
05/22/2022 08:08:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.347929 on epoch=68
05/22/2022 08:08:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.377465 on epoch=69
05/22/2022 08:08:40 - INFO - __main__ - Step 840 Global step 840 Train loss 0.383680 on epoch=69
05/22/2022 08:08:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.488029 on epoch=70
05/22/2022 08:08:46 - INFO - __main__ - Global step 850 Train loss 0.395830 Classification-F1 1.0 on epoch=70
05/22/2022 08:08:51 - INFO - __main__ - Step 860 Global step 860 Train loss 2.456718 on epoch=71
05/22/2022 08:08:56 - INFO - __main__ - Step 870 Global step 870 Train loss 4.024814 on epoch=72
05/22/2022 08:09:01 - INFO - __main__ - Step 880 Global step 880 Train loss 2.258719 on epoch=73
05/22/2022 08:09:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.413513 on epoch=74
05/22/2022 08:09:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.390935 on epoch=74
05/22/2022 08:09:12 - INFO - __main__ - Global step 900 Train loss 1.908940 Classification-F1 1.0 on epoch=74
05/22/2022 08:09:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.368029 on epoch=75
05/22/2022 08:09:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.409008 on epoch=76
05/22/2022 08:09:27 - INFO - __main__ - Step 930 Global step 930 Train loss 0.329430 on epoch=77
05/22/2022 08:09:32 - INFO - __main__ - Step 940 Global step 940 Train loss 0.356583 on epoch=78
05/22/2022 08:09:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.385003 on epoch=79
05/22/2022 08:09:38 - INFO - __main__ - Global step 950 Train loss 0.369610 Classification-F1 1.0 on epoch=79
05/22/2022 08:09:43 - INFO - __main__ - Step 960 Global step 960 Train loss 0.317031 on epoch=79
05/22/2022 08:09:48 - INFO - __main__ - Step 970 Global step 970 Train loss 0.361835 on epoch=80
05/22/2022 08:09:53 - INFO - __main__ - Step 980 Global step 980 Train loss 0.378224 on epoch=81
05/22/2022 08:09:58 - INFO - __main__ - Step 990 Global step 990 Train loss 0.389782 on epoch=82
05/22/2022 08:10:03 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.352119 on epoch=83
05/22/2022 08:10:04 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 08:10:04 - INFO - __main__ - Printing 3 examples
05/22/2022 08:10:04 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/22/2022 08:10:04 - INFO - __main__ - ['false']
05/22/2022 08:10:04 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/22/2022 08:10:04 - INFO - __main__ - ['false']
05/22/2022 08:10:04 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/22/2022 08:10:04 - INFO - __main__ - ['false']
05/22/2022 08:10:04 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:10:04 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:10:04 - INFO - __main__ - Global step 1000 Train loss 0.359798 Classification-F1 1.0 on epoch=83
05/22/2022 08:10:04 - INFO - __main__ - save last model!
05/22/2022 08:10:04 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 08:10:04 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 08:10:04 - INFO - __main__ - Printing 3 examples
05/22/2022 08:10:04 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/22/2022 08:10:04 - INFO - __main__ - ['false']
05/22/2022 08:10:04 - INFO - __main__ -  [ethos-religion] Crazy auntie get rid of your autistic son and make good to planet
05/22/2022 08:10:04 - INFO - __main__ - ['false']
05/22/2022 08:10:04 - INFO - __main__ -  [ethos-religion] I don’t like this gender at all. I definitely wouldn’t hire any male bitch at ma shop
05/22/2022 08:10:04 - INFO - __main__ - ['false']
05/22/2022 08:10:04 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:10:04 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:10:04 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 08:10:11 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 08:10:12 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 08:10:12 - INFO - __main__ - Printing 3 examples
05/22/2022 08:10:12 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 08:10:12 - INFO - __main__ - ['false']
05/22/2022 08:10:12 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 08:10:12 - INFO - __main__ - ['false']
05/22/2022 08:10:12 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 08:10:12 - INFO - __main__ - ['true']
05/22/2022 08:10:12 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:10:12 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:10:12 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 08:10:14 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_100_0.0003_8_predictions.txt
05/22/2022 08:10:14 - INFO - __main__ - Classification-F1 on test data: 0.4387
05/22/2022 08:10:14 - INFO - __main__ - prefix=ethos-religion_128_100, lr=0.0003, bsz=8, dev_performance=1.0, test_performance=0.4387096774193549
05/22/2022 08:10:14 - INFO - __main__ - Running ... prefix=ethos-religion_128_100, lr=0.0002, bsz=8 ...
05/22/2022 08:10:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 08:10:15 - INFO - __main__ - Starting training!
05/22/2022 08:10:15 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 08:10:15 - INFO - __main__ - Printing 3 examples
05/22/2022 08:10:15 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/22/2022 08:10:15 - INFO - __main__ - ['false']
05/22/2022 08:10:15 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/22/2022 08:10:15 - INFO - __main__ - ['false']
05/22/2022 08:10:15 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/22/2022 08:10:15 - INFO - __main__ - ['false']
05/22/2022 08:10:15 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:10:15 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:10:15 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 08:10:15 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 08:10:15 - INFO - __main__ - Printing 3 examples
05/22/2022 08:10:15 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/22/2022 08:10:15 - INFO - __main__ - ['false']
05/22/2022 08:10:15 - INFO - __main__ -  [ethos-religion] Crazy auntie get rid of your autistic son and make good to planet
05/22/2022 08:10:15 - INFO - __main__ - ['false']
05/22/2022 08:10:15 - INFO - __main__ -  [ethos-religion] I don’t like this gender at all. I definitely wouldn’t hire any male bitch at ma shop
05/22/2022 08:10:15 - INFO - __main__ - ['false']
05/22/2022 08:10:15 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:10:15 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:10:15 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 08:10:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 08:10:28 - INFO - __main__ - Starting training!
05/22/2022 08:10:32 - INFO - __main__ - Step 10 Global step 10 Train loss 23.331738 on epoch=0
05/22/2022 08:10:37 - INFO - __main__ - Step 20 Global step 20 Train loss 18.637976 on epoch=1
05/22/2022 08:10:42 - INFO - __main__ - Step 30 Global step 30 Train loss 17.403894 on epoch=2
05/22/2022 08:10:47 - INFO - __main__ - Step 40 Global step 40 Train loss 16.426178 on epoch=3
05/22/2022 08:10:52 - INFO - __main__ - Step 50 Global step 50 Train loss 14.675787 on epoch=4
05/22/2022 08:11:31 - INFO - __main__ - Global step 50 Train loss 18.095114 Classification-F1 0.0 on epoch=4
05/22/2022 08:11:36 - INFO - __main__ - Step 60 Global step 60 Train loss 14.665222 on epoch=4
05/22/2022 08:11:41 - INFO - __main__ - Step 70 Global step 70 Train loss 13.908775 on epoch=5
05/22/2022 08:11:46 - INFO - __main__ - Step 80 Global step 80 Train loss 12.900856 on epoch=6
05/22/2022 08:11:51 - INFO - __main__ - Step 90 Global step 90 Train loss 11.603907 on epoch=7
05/22/2022 08:11:56 - INFO - __main__ - Step 100 Global step 100 Train loss 9.751712 on epoch=8
05/22/2022 08:12:00 - INFO - __main__ - Global step 100 Train loss 12.566095 Classification-F1 0.006153846153846154 on epoch=8
05/22/2022 08:12:06 - INFO - __main__ - Step 110 Global step 110 Train loss 6.665387 on epoch=9
05/22/2022 08:12:11 - INFO - __main__ - Step 120 Global step 120 Train loss 1.912259 on epoch=9
05/22/2022 08:12:17 - INFO - __main__ - Step 130 Global step 130 Train loss 0.701193 on epoch=10
05/22/2022 08:12:22 - INFO - __main__ - Step 140 Global step 140 Train loss 0.506445 on epoch=11
05/22/2022 08:12:27 - INFO - __main__ - Step 150 Global step 150 Train loss 0.384596 on epoch=12
05/22/2022 08:12:29 - INFO - __main__ - Global step 150 Train loss 2.033976 Classification-F1 0.49606299212598426 on epoch=12
05/22/2022 08:12:34 - INFO - __main__ - Step 160 Global step 160 Train loss 0.422009 on epoch=13
05/22/2022 08:12:39 - INFO - __main__ - Step 170 Global step 170 Train loss 0.382254 on epoch=14
05/22/2022 08:12:45 - INFO - __main__ - Step 180 Global step 180 Train loss 0.316279 on epoch=14
05/22/2022 08:12:50 - INFO - __main__ - Step 190 Global step 190 Train loss 0.413883 on epoch=15
05/22/2022 08:12:55 - INFO - __main__ - Step 200 Global step 200 Train loss 0.268471 on epoch=16
05/22/2022 08:12:56 - INFO - __main__ - Global step 200 Train loss 0.360579 Classification-F1 0.4859437751004016 on epoch=16
05/22/2022 08:13:02 - INFO - __main__ - Step 210 Global step 210 Train loss 0.388225 on epoch=17
05/22/2022 08:13:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.357400 on epoch=18
05/22/2022 08:13:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.238350 on epoch=19
05/22/2022 08:13:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.254631 on epoch=19
05/22/2022 08:13:22 - INFO - __main__ - Step 250 Global step 250 Train loss 0.203215 on epoch=20
05/22/2022 08:13:24 - INFO - __main__ - Global step 250 Train loss 0.288364 Classification-F1 0.4666666666666667 on epoch=20
05/22/2022 08:13:29 - INFO - __main__ - Step 260 Global step 260 Train loss 0.180089 on epoch=21
05/22/2022 08:13:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.152479 on epoch=22
05/22/2022 08:13:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.165106 on epoch=23
05/22/2022 08:13:44 - INFO - __main__ - Step 290 Global step 290 Train loss 0.092770 on epoch=24
05/22/2022 08:13:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.125756 on epoch=24
05/22/2022 08:13:51 - INFO - __main__ - Global step 300 Train loss 0.143240 Classification-F1 0.4796747967479675 on epoch=24
05/22/2022 08:13:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.119024 on epoch=25
05/22/2022 08:14:01 - INFO - __main__ - Step 320 Global step 320 Train loss 0.099452 on epoch=26
05/22/2022 08:14:06 - INFO - __main__ - Step 330 Global step 330 Train loss 0.092417 on epoch=27
05/22/2022 08:14:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.082203 on epoch=28
05/22/2022 08:14:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.057677 on epoch=29
05/22/2022 08:14:18 - INFO - __main__ - Global step 350 Train loss 0.090155 Classification-F1 0.4796747967479675 on epoch=29
05/22/2022 08:14:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.093285 on epoch=29
05/22/2022 08:14:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.057542 on epoch=30
05/22/2022 08:14:34 - INFO - __main__ - Step 380 Global step 380 Train loss 0.105532 on epoch=31
05/22/2022 08:14:39 - INFO - __main__ - Step 390 Global step 390 Train loss 0.053651 on epoch=32
05/22/2022 08:14:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.078714 on epoch=33
05/22/2022 08:14:45 - INFO - __main__ - Global step 400 Train loss 0.077745 Classification-F1 0.46887966804979253 on epoch=33
05/22/2022 08:14:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.044222 on epoch=34
05/22/2022 08:14:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.060255 on epoch=34
05/22/2022 08:15:01 - INFO - __main__ - Step 430 Global step 430 Train loss 0.029270 on epoch=35
05/22/2022 08:15:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.116949 on epoch=36
05/22/2022 08:15:11 - INFO - __main__ - Step 450 Global step 450 Train loss 0.019322 on epoch=37
05/22/2022 08:15:13 - INFO - __main__ - Global step 450 Train loss 0.054004 Classification-F1 0.47107438016528924 on epoch=37
05/22/2022 08:15:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.039093 on epoch=38
05/22/2022 08:15:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.036196 on epoch=39
05/22/2022 08:15:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.035713 on epoch=39
05/22/2022 08:15:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.076360 on epoch=40
05/22/2022 08:15:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.028772 on epoch=41
05/22/2022 08:15:40 - INFO - __main__ - Global step 500 Train loss 0.043227 Classification-F1 0.47540983606557374 on epoch=41
05/22/2022 08:15:45 - INFO - __main__ - Step 510 Global step 510 Train loss 0.014657 on epoch=42
05/22/2022 08:15:50 - INFO - __main__ - Step 520 Global step 520 Train loss 0.013858 on epoch=43
05/22/2022 08:15:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.015952 on epoch=44
05/22/2022 08:16:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.020095 on epoch=44
05/22/2022 08:16:06 - INFO - __main__ - Step 550 Global step 550 Train loss 0.051915 on epoch=45
05/22/2022 08:16:07 - INFO - __main__ - Global step 550 Train loss 0.023295 Classification-F1 0.47107438016528924 on epoch=45
05/22/2022 08:16:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.005242 on epoch=46
05/22/2022 08:16:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.009769 on epoch=47
05/22/2022 08:16:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.037030 on epoch=48
05/22/2022 08:16:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.031948 on epoch=49
05/22/2022 08:16:33 - INFO - __main__ - Step 600 Global step 600 Train loss 0.043266 on epoch=49
05/22/2022 08:16:35 - INFO - __main__ - Global step 600 Train loss 0.025451 Classification-F1 0.4796747967479675 on epoch=49
05/22/2022 08:16:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.003632 on epoch=50
05/22/2022 08:16:45 - INFO - __main__ - Step 620 Global step 620 Train loss 0.002393 on epoch=51
05/22/2022 08:16:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.009388 on epoch=52
05/22/2022 08:16:55 - INFO - __main__ - Step 640 Global step 640 Train loss 0.017754 on epoch=53
05/22/2022 08:17:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.001059 on epoch=54
05/22/2022 08:17:02 - INFO - __main__ - Global step 650 Train loss 0.006845 Classification-F1 0.47540983606557374 on epoch=54
05/22/2022 08:17:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.020372 on epoch=54
05/22/2022 08:17:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.017681 on epoch=55
05/22/2022 08:17:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.019653 on epoch=56
05/22/2022 08:17:22 - INFO - __main__ - Step 690 Global step 690 Train loss 0.006540 on epoch=57
05/22/2022 08:17:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.001601 on epoch=58
05/22/2022 08:17:29 - INFO - __main__ - Global step 700 Train loss 0.013169 Classification-F1 0.4796747967479675 on epoch=58
05/22/2022 08:17:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.003948 on epoch=59
05/22/2022 08:17:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.001353 on epoch=59
05/22/2022 08:17:44 - INFO - __main__ - Step 730 Global step 730 Train loss 0.012529 on epoch=60
05/22/2022 08:17:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.002131 on epoch=61
05/22/2022 08:17:55 - INFO - __main__ - Step 750 Global step 750 Train loss 0.003178 on epoch=62
05/22/2022 08:17:56 - INFO - __main__ - Global step 750 Train loss 0.004628 Classification-F1 0.47540983606557374 on epoch=62
05/22/2022 08:18:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.001472 on epoch=63
05/22/2022 08:18:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.003096 on epoch=64
05/22/2022 08:18:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.076168 on epoch=64
05/22/2022 08:18:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.008436 on epoch=65
05/22/2022 08:18:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000939 on epoch=66
05/22/2022 08:18:24 - INFO - __main__ - Global step 800 Train loss 0.018022 Classification-F1 0.47540983606557374 on epoch=66
05/22/2022 08:18:29 - INFO - __main__ - Step 810 Global step 810 Train loss 0.001444 on epoch=67
05/22/2022 08:18:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.094111 on epoch=68
05/22/2022 08:18:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000688 on epoch=69
05/22/2022 08:18:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000613 on epoch=69
05/22/2022 08:18:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.001700 on epoch=70
05/22/2022 08:18:51 - INFO - __main__ - Global step 850 Train loss 0.019711 Classification-F1 0.47540983606557374 on epoch=70
05/22/2022 08:18:56 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000319 on epoch=71
05/22/2022 08:19:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000160 on epoch=72
05/22/2022 08:19:07 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000151 on epoch=73
05/22/2022 08:19:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.034173 on epoch=74
05/22/2022 08:19:17 - INFO - __main__ - Step 900 Global step 900 Train loss 0.021637 on epoch=74
05/22/2022 08:19:19 - INFO - __main__ - Global step 900 Train loss 0.011288 Classification-F1 0.47540983606557374 on epoch=74
05/22/2022 08:19:24 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000179 on epoch=75
05/22/2022 08:19:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000241 on epoch=76
05/22/2022 08:19:34 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000361 on epoch=77
05/22/2022 08:19:39 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000543 on epoch=78
05/22/2022 08:19:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000437 on epoch=79
05/22/2022 08:19:46 - INFO - __main__ - Global step 950 Train loss 0.000352 Classification-F1 0.47540983606557374 on epoch=79
05/22/2022 08:19:51 - INFO - __main__ - Step 960 Global step 960 Train loss 0.012875 on epoch=79
05/22/2022 08:19:56 - INFO - __main__ - Step 970 Global step 970 Train loss 0.002145 on epoch=80
05/22/2022 08:20:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000115 on epoch=81
05/22/2022 08:20:07 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000260 on epoch=82
05/22/2022 08:20:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000604 on epoch=83
05/22/2022 08:20:13 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 08:20:13 - INFO - __main__ - Printing 3 examples
05/22/2022 08:20:13 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/22/2022 08:20:13 - INFO - __main__ - ['false']
05/22/2022 08:20:13 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/22/2022 08:20:13 - INFO - __main__ - ['false']
05/22/2022 08:20:13 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/22/2022 08:20:13 - INFO - __main__ - ['false']
05/22/2022 08:20:13 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:20:13 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:20:13 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 08:20:13 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 08:20:13 - INFO - __main__ - Printing 3 examples
05/22/2022 08:20:13 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/22/2022 08:20:13 - INFO - __main__ - ['false']
05/22/2022 08:20:13 - INFO - __main__ -  [ethos-religion] Crazy auntie get rid of your autistic son and make good to planet
05/22/2022 08:20:13 - INFO - __main__ - ['false']
05/22/2022 08:20:13 - INFO - __main__ -  [ethos-religion] I don’t like this gender at all. I definitely wouldn’t hire any male bitch at ma shop
05/22/2022 08:20:13 - INFO - __main__ - ['false']
05/22/2022 08:20:13 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:20:13 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:20:14 - INFO - __main__ - Global step 1000 Train loss 0.003200 Classification-F1 0.4775510204081633 on epoch=83
05/22/2022 08:20:14 - INFO - __main__ - save last model!
05/22/2022 08:20:14 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 08:20:21 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 08:20:22 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 08:20:22 - INFO - __main__ - Printing 3 examples
05/22/2022 08:20:22 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 08:20:22 - INFO - __main__ - ['false']
05/22/2022 08:20:22 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 08:20:22 - INFO - __main__ - ['false']
05/22/2022 08:20:22 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 08:20:22 - INFO - __main__ - ['true']
05/22/2022 08:20:22 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:20:22 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:20:22 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 08:20:24 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_100_0.0002_8_predictions.txt
05/22/2022 08:20:24 - INFO - __main__ - Classification-F1 on test data: 0.7589
05/22/2022 08:20:24 - INFO - __main__ - prefix=ethos-religion_128_100, lr=0.0002, bsz=8, dev_performance=0.49606299212598426, test_performance=0.7588813303099017
05/22/2022 08:20:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 08:20:24 - INFO - __main__ - Running ... prefix=ethos-religion_128_100, lr=0.0001, bsz=8 ...
05/22/2022 08:20:24 - INFO - __main__ - Starting training!
05/22/2022 08:20:25 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 08:20:25 - INFO - __main__ - Printing 3 examples
05/22/2022 08:20:25 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/22/2022 08:20:25 - INFO - __main__ - ['false']
05/22/2022 08:20:25 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/22/2022 08:20:25 - INFO - __main__ - ['false']
05/22/2022 08:20:25 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/22/2022 08:20:25 - INFO - __main__ - ['false']
05/22/2022 08:20:25 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:20:25 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:20:25 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 08:20:25 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 08:20:25 - INFO - __main__ - Printing 3 examples
05/22/2022 08:20:25 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/22/2022 08:20:25 - INFO - __main__ - ['false']
05/22/2022 08:20:25 - INFO - __main__ -  [ethos-religion] Crazy auntie get rid of your autistic son and make good to planet
05/22/2022 08:20:25 - INFO - __main__ - ['false']
05/22/2022 08:20:25 - INFO - __main__ -  [ethos-religion] I don’t like this gender at all. I definitely wouldn’t hire any male bitch at ma shop
05/22/2022 08:20:25 - INFO - __main__ - ['false']
05/22/2022 08:20:25 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:20:25 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:20:25 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 08:20:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 08:20:38 - INFO - __main__ - Starting training!
05/22/2022 08:20:42 - INFO - __main__ - Step 10 Global step 10 Train loss 24.481113 on epoch=0
05/22/2022 08:20:47 - INFO - __main__ - Step 20 Global step 20 Train loss 20.652191 on epoch=1
05/22/2022 08:20:52 - INFO - __main__ - Step 30 Global step 30 Train loss 18.467922 on epoch=2
05/22/2022 08:20:57 - INFO - __main__ - Step 40 Global step 40 Train loss 17.103800 on epoch=3
05/22/2022 08:21:02 - INFO - __main__ - Step 50 Global step 50 Train loss 16.525465 on epoch=4
05/22/2022 08:21:43 - INFO - __main__ - Global step 50 Train loss 19.446098 Classification-F1 0.0 on epoch=4
05/22/2022 08:21:48 - INFO - __main__ - Step 60 Global step 60 Train loss 16.475117 on epoch=4
05/22/2022 08:21:53 - INFO - __main__ - Step 70 Global step 70 Train loss 16.003941 on epoch=5
05/22/2022 08:21:59 - INFO - __main__ - Step 80 Global step 80 Train loss 16.235884 on epoch=6
05/22/2022 08:22:04 - INFO - __main__ - Step 90 Global step 90 Train loss 15.680997 on epoch=7
05/22/2022 08:22:09 - INFO - __main__ - Step 100 Global step 100 Train loss 13.935617 on epoch=8
05/22/2022 08:22:49 - INFO - __main__ - Global step 100 Train loss 15.666311 Classification-F1 0.0 on epoch=8
05/22/2022 08:22:54 - INFO - __main__ - Step 110 Global step 110 Train loss 14.896353 on epoch=9
05/22/2022 08:22:59 - INFO - __main__ - Step 120 Global step 120 Train loss 13.594518 on epoch=9
05/22/2022 08:23:04 - INFO - __main__ - Step 130 Global step 130 Train loss 13.336743 on epoch=10
05/22/2022 08:23:09 - INFO - __main__ - Step 140 Global step 140 Train loss 13.810292 on epoch=11
05/22/2022 08:23:14 - INFO - __main__ - Step 150 Global step 150 Train loss 12.993022 on epoch=12
05/22/2022 08:23:54 - INFO - __main__ - Global step 150 Train loss 13.726185 Classification-F1 0.0 on epoch=12
05/22/2022 08:23:59 - INFO - __main__ - Step 160 Global step 160 Train loss 11.319597 on epoch=13
05/22/2022 08:24:04 - INFO - __main__ - Step 170 Global step 170 Train loss 11.693875 on epoch=14
05/22/2022 08:24:09 - INFO - __main__ - Step 180 Global step 180 Train loss 10.269033 on epoch=14
05/22/2022 08:24:14 - INFO - __main__ - Step 190 Global step 190 Train loss 7.948483 on epoch=15
05/22/2022 08:24:19 - INFO - __main__ - Step 200 Global step 200 Train loss 5.783647 on epoch=16
05/22/2022 08:24:21 - INFO - __main__ - Global step 200 Train loss 9.402926 Classification-F1 0.4410480349344978 on epoch=16
05/22/2022 08:24:26 - INFO - __main__ - Step 210 Global step 210 Train loss 1.553638 on epoch=17
05/22/2022 08:24:31 - INFO - __main__ - Step 220 Global step 220 Train loss 0.804348 on epoch=18
05/22/2022 08:24:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.523321 on epoch=19
05/22/2022 08:24:42 - INFO - __main__ - Step 240 Global step 240 Train loss 0.547549 on epoch=19
05/22/2022 08:24:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.568415 on epoch=20
05/22/2022 08:24:48 - INFO - __main__ - Global step 250 Train loss 0.799454 Classification-F1 1.0 on epoch=20
05/22/2022 08:24:54 - INFO - __main__ - Step 260 Global step 260 Train loss 0.464063 on epoch=21
05/22/2022 08:24:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.346858 on epoch=22
05/22/2022 08:25:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.379758 on epoch=23
05/22/2022 08:25:09 - INFO - __main__ - Step 290 Global step 290 Train loss 0.365073 on epoch=24
05/22/2022 08:25:14 - INFO - __main__ - Step 300 Global step 300 Train loss 0.251240 on epoch=24
05/22/2022 08:25:16 - INFO - __main__ - Global step 300 Train loss 0.361398 Classification-F1 0.42342342342342343 on epoch=24
05/22/2022 08:25:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.310314 on epoch=25
05/22/2022 08:25:26 - INFO - __main__ - Step 320 Global step 320 Train loss 0.386945 on epoch=26
05/22/2022 08:25:31 - INFO - __main__ - Step 330 Global step 330 Train loss 0.230548 on epoch=27
05/22/2022 08:25:36 - INFO - __main__ - Step 340 Global step 340 Train loss 0.222549 on epoch=28
05/22/2022 08:25:41 - INFO - __main__ - Step 350 Global step 350 Train loss 0.262473 on epoch=29
05/22/2022 08:25:43 - INFO - __main__ - Global step 350 Train loss 0.282566 Classification-F1 0.4775510204081633 on epoch=29
05/22/2022 08:25:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.222202 on epoch=29
05/22/2022 08:25:53 - INFO - __main__ - Step 370 Global step 370 Train loss 0.341796 on epoch=30
05/22/2022 08:25:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.367612 on epoch=31
05/22/2022 08:26:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.270409 on epoch=32
05/22/2022 08:26:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.188716 on epoch=33
05/22/2022 08:26:09 - INFO - __main__ - Global step 400 Train loss 0.278147 Classification-F1 0.46887966804979253 on epoch=33
05/22/2022 08:26:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.206927 on epoch=34
05/22/2022 08:26:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.230941 on epoch=34
05/22/2022 08:26:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.599525 on epoch=35
05/22/2022 08:26:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.243927 on epoch=36
05/22/2022 08:26:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.168694 on epoch=37
05/22/2022 08:26:36 - INFO - __main__ - Global step 450 Train loss 0.290003 Classification-F1 0.4666666666666667 on epoch=37
05/22/2022 08:26:42 - INFO - __main__ - Step 460 Global step 460 Train loss 0.129881 on epoch=38
05/22/2022 08:26:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.321949 on epoch=39
05/22/2022 08:26:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.238599 on epoch=39
05/22/2022 08:26:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.500188 on epoch=40
05/22/2022 08:27:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.174414 on epoch=41
05/22/2022 08:27:03 - INFO - __main__ - Global step 500 Train loss 0.273006 Classification-F1 0.4796747967479675 on epoch=41
05/22/2022 08:27:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.134451 on epoch=42
05/22/2022 08:27:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.180101 on epoch=43
05/22/2022 08:27:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.120066 on epoch=44
05/22/2022 08:27:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.117350 on epoch=44
05/22/2022 08:27:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.134889 on epoch=45
05/22/2022 08:27:31 - INFO - __main__ - Global step 550 Train loss 0.137371 Classification-F1 0.47540983606557374 on epoch=45
05/22/2022 08:27:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.193966 on epoch=46
05/22/2022 08:27:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.135368 on epoch=47
05/22/2022 08:27:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.142583 on epoch=48
05/22/2022 08:27:51 - INFO - __main__ - Step 590 Global step 590 Train loss 0.127096 on epoch=49
05/22/2022 08:27:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.273010 on epoch=49
05/22/2022 08:27:58 - INFO - __main__ - Global step 600 Train loss 0.174405 Classification-F1 0.4817813765182186 on epoch=49
05/22/2022 08:28:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.104124 on epoch=50
05/22/2022 08:28:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.093263 on epoch=51
05/22/2022 08:28:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.111140 on epoch=52
05/22/2022 08:28:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.076455 on epoch=53
05/22/2022 08:28:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.111192 on epoch=54
05/22/2022 08:28:25 - INFO - __main__ - Global step 650 Train loss 0.099235 Classification-F1 0.47540983606557374 on epoch=54
05/22/2022 08:28:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.117823 on epoch=54
05/22/2022 08:28:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.084666 on epoch=55
05/22/2022 08:28:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.084740 on epoch=56
05/22/2022 08:28:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.072831 on epoch=57
05/22/2022 08:28:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.071542 on epoch=58
05/22/2022 08:28:52 - INFO - __main__ - Global step 700 Train loss 0.086320 Classification-F1 0.4732510288065844 on epoch=58
05/22/2022 08:28:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.077409 on epoch=59
05/22/2022 08:29:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.084975 on epoch=59
05/22/2022 08:29:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.115138 on epoch=60
05/22/2022 08:29:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.073139 on epoch=61
05/22/2022 08:29:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.110927 on epoch=62
05/22/2022 08:29:19 - INFO - __main__ - Global step 750 Train loss 0.092318 Classification-F1 0.4775510204081633 on epoch=62
05/22/2022 08:29:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.059970 on epoch=63
05/22/2022 08:29:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.080714 on epoch=64
05/22/2022 08:29:34 - INFO - __main__ - Step 780 Global step 780 Train loss 0.116308 on epoch=64
05/22/2022 08:29:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.094968 on epoch=65
05/22/2022 08:29:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.059754 on epoch=66
05/22/2022 08:29:46 - INFO - __main__ - Global step 800 Train loss 0.082343 Classification-F1 0.4775510204081633 on epoch=66
05/22/2022 08:29:51 - INFO - __main__ - Step 810 Global step 810 Train loss 0.105750 on epoch=67
05/22/2022 08:29:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.078033 on epoch=68
05/22/2022 08:30:01 - INFO - __main__ - Step 830 Global step 830 Train loss 0.065081 on epoch=69
05/22/2022 08:30:06 - INFO - __main__ - Step 840 Global step 840 Train loss 0.094818 on epoch=69
05/22/2022 08:30:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.048411 on epoch=70
05/22/2022 08:30:13 - INFO - __main__ - Global step 850 Train loss 0.078419 Classification-F1 0.4775510204081633 on epoch=70
05/22/2022 08:30:18 - INFO - __main__ - Step 860 Global step 860 Train loss 0.116626 on epoch=71
05/22/2022 08:30:23 - INFO - __main__ - Step 870 Global step 870 Train loss 0.053682 on epoch=72
05/22/2022 08:30:28 - INFO - __main__ - Step 880 Global step 880 Train loss 0.047199 on epoch=73
05/22/2022 08:30:33 - INFO - __main__ - Step 890 Global step 890 Train loss 0.044032 on epoch=74
05/22/2022 08:30:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.019034 on epoch=74
05/22/2022 08:30:40 - INFO - __main__ - Global step 900 Train loss 0.056114 Classification-F1 0.4775510204081633 on epoch=74
05/22/2022 08:30:45 - INFO - __main__ - Step 910 Global step 910 Train loss 0.124694 on epoch=75
05/22/2022 08:30:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.015555 on epoch=76
05/22/2022 08:30:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.073150 on epoch=77
05/22/2022 08:31:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.063043 on epoch=78
05/22/2022 08:31:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.035851 on epoch=79
05/22/2022 08:31:06 - INFO - __main__ - Global step 950 Train loss 0.062459 Classification-F1 0.47107438016528924 on epoch=79
05/22/2022 08:31:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.043712 on epoch=79
05/22/2022 08:31:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.063666 on epoch=80
05/22/2022 08:31:22 - INFO - __main__ - Step 980 Global step 980 Train loss 0.046266 on epoch=81
05/22/2022 08:31:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.100337 on epoch=82
05/22/2022 08:31:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.074420 on epoch=83
05/22/2022 08:31:33 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 08:31:33 - INFO - __main__ - Printing 3 examples
05/22/2022 08:31:33 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 08:31:33 - INFO - __main__ - ['false']
05/22/2022 08:31:33 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 08:31:33 - INFO - __main__ - ['false']
05/22/2022 08:31:33 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/22/2022 08:31:33 - INFO - __main__ - ['false']
05/22/2022 08:31:33 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:31:33 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:31:33 - INFO - __main__ - Global step 1000 Train loss 0.065680 Classification-F1 0.4817813765182186 on epoch=83
05/22/2022 08:31:33 - INFO - __main__ - save last model!
05/22/2022 08:31:34 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 08:31:34 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 08:31:34 - INFO - __main__ - Printing 3 examples
05/22/2022 08:31:34 - INFO - __main__ -  [ethos-religion] This homo faggot Spike Lee wore this at the Flopscers. Notice the blatant subliminal messages.
05/22/2022 08:31:34 - INFO - __main__ - ['false']
05/22/2022 08:31:34 - INFO - __main__ -  [ethos-religion] I wish HIV to your butthole male whore
05/22/2022 08:31:34 - INFO - __main__ - ['false']
05/22/2022 08:31:34 - INFO - __main__ -  [ethos-religion] This is S-I-C-K If I ever seen a Girlyman like him go into the same lavatory as my wife, or daughter somebody better call the EMTs because the ONLY way SheHe is coming out will be on a Stretcher, or in a body bag! Just sayin..........
05/22/2022 08:31:34 - INFO - __main__ - ['false']
05/22/2022 08:31:34 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:31:34 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:31:34 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 08:31:40 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 08:31:41 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 08:31:41 - INFO - __main__ - Printing 3 examples
05/22/2022 08:31:41 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 08:31:41 - INFO - __main__ - ['false']
05/22/2022 08:31:41 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 08:31:41 - INFO - __main__ - ['false']
05/22/2022 08:31:41 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 08:31:41 - INFO - __main__ - ['true']
05/22/2022 08:31:41 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:31:41 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:31:41 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 08:31:42 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_100_0.0001_8_predictions.txt
05/22/2022 08:31:42 - INFO - __main__ - Classification-F1 on test data: 0.4387
05/22/2022 08:31:43 - INFO - __main__ - prefix=ethos-religion_128_100, lr=0.0001, bsz=8, dev_performance=1.0, test_performance=0.4387096774193549
05/22/2022 08:31:43 - INFO - __main__ - Running ... prefix=ethos-religion_128_13, lr=0.0005, bsz=8 ...
05/22/2022 08:31:44 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 08:31:44 - INFO - __main__ - Printing 3 examples
05/22/2022 08:31:44 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 08:31:44 - INFO - __main__ - ['false']
05/22/2022 08:31:44 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 08:31:44 - INFO - __main__ - ['false']
05/22/2022 08:31:44 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/22/2022 08:31:44 - INFO - __main__ - ['false']
05/22/2022 08:31:44 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:31:44 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:31:44 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 08:31:44 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 08:31:44 - INFO - __main__ - Printing 3 examples
05/22/2022 08:31:44 - INFO - __main__ -  [ethos-religion] This homo faggot Spike Lee wore this at the Flopscers. Notice the blatant subliminal messages.
05/22/2022 08:31:44 - INFO - __main__ - ['false']
05/22/2022 08:31:44 - INFO - __main__ -  [ethos-religion] I wish HIV to your butthole male whore
05/22/2022 08:31:44 - INFO - __main__ - ['false']
05/22/2022 08:31:44 - INFO - __main__ -  [ethos-religion] This is S-I-C-K If I ever seen a Girlyman like him go into the same lavatory as my wife, or daughter somebody better call the EMTs because the ONLY way SheHe is coming out will be on a Stretcher, or in a body bag! Just sayin..........
05/22/2022 08:31:44 - INFO - __main__ - ['false']
05/22/2022 08:31:44 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:31:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 08:31:44 - INFO - __main__ - Starting training!
05/22/2022 08:31:44 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:31:44 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 08:31:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 08:31:55 - INFO - __main__ - Starting training!
05/22/2022 08:31:59 - INFO - __main__ - Step 10 Global step 10 Train loss 23.842110 on epoch=0
05/22/2022 08:32:04 - INFO - __main__ - Step 20 Global step 20 Train loss 18.730947 on epoch=1
05/22/2022 08:32:09 - INFO - __main__ - Step 30 Global step 30 Train loss 16.051989 on epoch=2
05/22/2022 08:32:14 - INFO - __main__ - Step 40 Global step 40 Train loss 13.254987 on epoch=3
05/22/2022 08:32:19 - INFO - __main__ - Step 50 Global step 50 Train loss 11.160808 on epoch=4
05/22/2022 08:32:43 - INFO - __main__ - Global step 50 Train loss 16.608170 Classification-F1 0.0 on epoch=4
05/22/2022 08:32:48 - INFO - __main__ - Step 60 Global step 60 Train loss 7.814363 on epoch=4
05/22/2022 08:32:53 - INFO - __main__ - Step 70 Global step 70 Train loss 3.184978 on epoch=5
05/22/2022 08:32:58 - INFO - __main__ - Step 80 Global step 80 Train loss 0.589312 on epoch=6
05/22/2022 08:33:03 - INFO - __main__ - Step 90 Global step 90 Train loss 0.536413 on epoch=7
05/22/2022 08:33:08 - INFO - __main__ - Step 100 Global step 100 Train loss 0.369592 on epoch=8
05/22/2022 08:33:10 - INFO - __main__ - Global step 100 Train loss 2.498932 Classification-F1 0.4859437751004016 on epoch=8
05/22/2022 08:33:15 - INFO - __main__ - Step 110 Global step 110 Train loss 0.260222 on epoch=9
05/22/2022 08:33:20 - INFO - __main__ - Step 120 Global step 120 Train loss 0.540220 on epoch=9
05/22/2022 08:33:25 - INFO - __main__ - Step 130 Global step 130 Train loss 0.693224 on epoch=10
05/22/2022 08:33:30 - INFO - __main__ - Step 140 Global step 140 Train loss 0.528654 on epoch=11
05/22/2022 08:33:35 - INFO - __main__ - Step 150 Global step 150 Train loss 0.451999 on epoch=12
05/22/2022 08:33:37 - INFO - __main__ - Global step 150 Train loss 0.494864 Classification-F1 1.0 on epoch=12
05/22/2022 08:33:43 - INFO - __main__ - Step 160 Global step 160 Train loss 0.444337 on epoch=13
05/22/2022 08:33:48 - INFO - __main__ - Step 170 Global step 170 Train loss 0.397471 on epoch=14
05/22/2022 08:33:53 - INFO - __main__ - Step 180 Global step 180 Train loss 0.376972 on epoch=14
05/22/2022 08:33:58 - INFO - __main__ - Step 190 Global step 190 Train loss 0.454355 on epoch=15
05/22/2022 08:34:03 - INFO - __main__ - Step 200 Global step 200 Train loss 0.820785 on epoch=16
05/22/2022 08:34:04 - INFO - __main__ - Global step 200 Train loss 0.498784 Classification-F1 1.0 on epoch=16
05/22/2022 08:34:09 - INFO - __main__ - Step 210 Global step 210 Train loss 0.386222 on epoch=17
05/22/2022 08:34:14 - INFO - __main__ - Step 220 Global step 220 Train loss 0.409503 on epoch=18
05/22/2022 08:34:19 - INFO - __main__ - Step 230 Global step 230 Train loss 0.360997 on epoch=19
05/22/2022 08:34:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.363350 on epoch=19
05/22/2022 08:34:29 - INFO - __main__ - Step 250 Global step 250 Train loss 0.425398 on epoch=20
05/22/2022 08:34:31 - INFO - __main__ - Global step 250 Train loss 0.389094 Classification-F1 1.0 on epoch=20
05/22/2022 08:34:36 - INFO - __main__ - Step 260 Global step 260 Train loss 0.369860 on epoch=21
05/22/2022 08:34:41 - INFO - __main__ - Step 270 Global step 270 Train loss 0.367798 on epoch=22
05/22/2022 08:34:46 - INFO - __main__ - Step 280 Global step 280 Train loss 0.409753 on epoch=23
05/22/2022 08:34:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.385965 on epoch=24
05/22/2022 08:34:56 - INFO - __main__ - Step 300 Global step 300 Train loss 0.336835 on epoch=24
05/22/2022 08:34:57 - INFO - __main__ - Global step 300 Train loss 0.374042 Classification-F1 1.0 on epoch=24
05/22/2022 08:35:02 - INFO - __main__ - Step 310 Global step 310 Train loss 0.377859 on epoch=25
05/22/2022 08:35:07 - INFO - __main__ - Step 320 Global step 320 Train loss 0.402013 on epoch=26
05/22/2022 08:35:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.366579 on epoch=27
05/22/2022 08:35:17 - INFO - __main__ - Step 340 Global step 340 Train loss 0.340736 on epoch=28
05/22/2022 08:35:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.346039 on epoch=29
05/22/2022 08:35:23 - INFO - __main__ - Global step 350 Train loss 0.366645 Classification-F1 0.49206349206349204 on epoch=29
05/22/2022 08:35:28 - INFO - __main__ - Step 360 Global step 360 Train loss 0.246176 on epoch=29
05/22/2022 08:35:33 - INFO - __main__ - Step 370 Global step 370 Train loss 0.337308 on epoch=30
05/22/2022 08:35:38 - INFO - __main__ - Step 380 Global step 380 Train loss 0.218670 on epoch=31
05/22/2022 08:35:43 - INFO - __main__ - Step 390 Global step 390 Train loss 0.453938 on epoch=32
05/22/2022 08:35:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.310221 on epoch=33
05/22/2022 08:35:50 - INFO - __main__ - Global step 400 Train loss 0.313263 Classification-F1 0.4859437751004016 on epoch=33
05/22/2022 08:35:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.241383 on epoch=34
05/22/2022 08:36:00 - INFO - __main__ - Step 420 Global step 420 Train loss 0.294929 on epoch=34
05/22/2022 08:36:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.429234 on epoch=35
05/22/2022 08:36:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.376621 on epoch=36
05/22/2022 08:36:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.198582 on epoch=37
05/22/2022 08:36:16 - INFO - __main__ - Global step 450 Train loss 0.308150 Classification-F1 0.46887966804979253 on epoch=37
05/22/2022 08:36:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.152304 on epoch=38
05/22/2022 08:36:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.145074 on epoch=39
05/22/2022 08:36:31 - INFO - __main__ - Step 480 Global step 480 Train loss 0.222346 on epoch=39
05/22/2022 08:36:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.180262 on epoch=40
05/22/2022 08:36:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.100685 on epoch=41
05/22/2022 08:36:43 - INFO - __main__ - Global step 500 Train loss 0.160134 Classification-F1 0.47107438016528924 on epoch=41
05/22/2022 08:36:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.126448 on epoch=42
05/22/2022 08:36:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.134549 on epoch=43
05/22/2022 08:36:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.107020 on epoch=44
05/22/2022 08:37:03 - INFO - __main__ - Step 540 Global step 540 Train loss 0.116815 on epoch=44
05/22/2022 08:37:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.251252 on epoch=45
05/22/2022 08:37:09 - INFO - __main__ - Global step 550 Train loss 0.147217 Classification-F1 0.4859437751004016 on epoch=45
05/22/2022 08:37:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.111769 on epoch=46
05/22/2022 08:37:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.064864 on epoch=47
05/22/2022 08:37:24 - INFO - __main__ - Step 580 Global step 580 Train loss 0.044606 on epoch=48
05/22/2022 08:37:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.090976 on epoch=49
05/22/2022 08:37:34 - INFO - __main__ - Step 600 Global step 600 Train loss 0.064874 on epoch=49
05/22/2022 08:37:36 - INFO - __main__ - Global step 600 Train loss 0.075418 Classification-F1 0.488 on epoch=49
05/22/2022 08:37:41 - INFO - __main__ - Step 610 Global step 610 Train loss 0.099768 on epoch=50
05/22/2022 08:37:46 - INFO - __main__ - Step 620 Global step 620 Train loss 0.048634 on epoch=51
05/22/2022 08:37:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.074278 on epoch=52
05/22/2022 08:37:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.014456 on epoch=53
05/22/2022 08:38:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.024297 on epoch=54
05/22/2022 08:38:02 - INFO - __main__ - Global step 650 Train loss 0.052286 Classification-F1 0.4838709677419355 on epoch=54
05/22/2022 08:38:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.039397 on epoch=54
05/22/2022 08:38:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.004632 on epoch=55
05/22/2022 08:38:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.008335 on epoch=56
05/22/2022 08:38:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.002317 on epoch=57
05/22/2022 08:38:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.011104 on epoch=58
05/22/2022 08:38:29 - INFO - __main__ - Global step 700 Train loss 0.013157 Classification-F1 0.4796747967479675 on epoch=58
05/22/2022 08:38:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.021854 on epoch=59
05/22/2022 08:38:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.012727 on epoch=59
05/22/2022 08:38:44 - INFO - __main__ - Step 730 Global step 730 Train loss 0.027874 on epoch=60
05/22/2022 08:38:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.001665 on epoch=61
05/22/2022 08:38:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.003452 on epoch=62
05/22/2022 08:38:56 - INFO - __main__ - Global step 750 Train loss 0.013514 Classification-F1 0.4838709677419355 on epoch=62
05/22/2022 08:39:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.001163 on epoch=63
05/22/2022 08:39:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000242 on epoch=64
05/22/2022 08:39:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.010832 on epoch=64
05/22/2022 08:39:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.012199 on epoch=65
05/22/2022 08:39:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.021700 on epoch=66
05/22/2022 08:39:22 - INFO - __main__ - Global step 800 Train loss 0.009227 Classification-F1 0.4817813765182186 on epoch=66
05/22/2022 08:39:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.002995 on epoch=67
05/22/2022 08:39:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.010012 on epoch=68
05/22/2022 08:39:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.004897 on epoch=69
05/22/2022 08:39:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000533 on epoch=69
05/22/2022 08:39:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000709 on epoch=70
05/22/2022 08:39:49 - INFO - __main__ - Global step 850 Train loss 0.003829 Classification-F1 0.4838709677419355 on epoch=70
05/22/2022 08:39:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.007138 on epoch=71
05/22/2022 08:39:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.001008 on epoch=72
05/22/2022 08:40:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000503 on epoch=73
05/22/2022 08:40:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000273 on epoch=74
05/22/2022 08:40:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000205 on epoch=74
05/22/2022 08:40:16 - INFO - __main__ - Global step 900 Train loss 0.001825 Classification-F1 0.4817813765182186 on epoch=74
05/22/2022 08:40:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000541 on epoch=75
05/22/2022 08:40:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000097 on epoch=76
05/22/2022 08:40:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000206 on epoch=77
05/22/2022 08:40:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000166 on epoch=78
05/22/2022 08:40:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000553 on epoch=79
05/22/2022 08:40:43 - INFO - __main__ - Global step 950 Train loss 0.000312 Classification-F1 0.4817813765182186 on epoch=79
05/22/2022 08:40:48 - INFO - __main__ - Step 960 Global step 960 Train loss 0.001398 on epoch=79
05/22/2022 08:40:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.005356 on epoch=80
05/22/2022 08:40:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.012769 on epoch=81
05/22/2022 08:41:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000393 on epoch=82
05/22/2022 08:41:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000256 on epoch=83
05/22/2022 08:41:10 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 08:41:10 - INFO - __main__ - Printing 3 examples
05/22/2022 08:41:10 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 08:41:10 - INFO - __main__ - ['false']
05/22/2022 08:41:10 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 08:41:10 - INFO - __main__ - ['false']
05/22/2022 08:41:10 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/22/2022 08:41:10 - INFO - __main__ - ['false']
05/22/2022 08:41:10 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:41:10 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:41:10 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 08:41:10 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 08:41:10 - INFO - __main__ - Printing 3 examples
05/22/2022 08:41:10 - INFO - __main__ -  [ethos-religion] This homo faggot Spike Lee wore this at the Flopscers. Notice the blatant subliminal messages.
05/22/2022 08:41:10 - INFO - __main__ - ['false']
05/22/2022 08:41:10 - INFO - __main__ -  [ethos-religion] I wish HIV to your butthole male whore
05/22/2022 08:41:10 - INFO - __main__ - ['false']
05/22/2022 08:41:10 - INFO - __main__ -  [ethos-religion] This is S-I-C-K If I ever seen a Girlyman like him go into the same lavatory as my wife, or daughter somebody better call the EMTs because the ONLY way SheHe is coming out will be on a Stretcher, or in a body bag! Just sayin..........
05/22/2022 08:41:10 - INFO - __main__ - ['false']
05/22/2022 08:41:10 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:41:10 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:41:10 - INFO - __main__ - Global step 1000 Train loss 0.004034 Classification-F1 0.4838709677419355 on epoch=83
05/22/2022 08:41:10 - INFO - __main__ - save last model!
05/22/2022 08:41:10 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 08:41:17 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 08:41:18 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 08:41:18 - INFO - __main__ - Printing 3 examples
05/22/2022 08:41:18 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 08:41:18 - INFO - __main__ - ['false']
05/22/2022 08:41:18 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 08:41:18 - INFO - __main__ - ['false']
05/22/2022 08:41:18 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 08:41:18 - INFO - __main__ - ['true']
05/22/2022 08:41:18 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:41:18 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:41:18 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 08:41:20 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_13_0.0005_8_predictions.txt
05/22/2022 08:41:20 - INFO - __main__ - Classification-F1 on test data: 0.4387
05/22/2022 08:41:20 - INFO - __main__ - prefix=ethos-religion_128_13, lr=0.0005, bsz=8, dev_performance=1.0, test_performance=0.4387096774193549
05/22/2022 08:41:20 - INFO - __main__ - Running ... prefix=ethos-religion_128_13, lr=0.0003, bsz=8 ...
05/22/2022 08:41:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 08:41:21 - INFO - __main__ - Starting training!
05/22/2022 08:41:21 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 08:41:21 - INFO - __main__ - Printing 3 examples
05/22/2022 08:41:21 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 08:41:21 - INFO - __main__ - ['false']
05/22/2022 08:41:21 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 08:41:21 - INFO - __main__ - ['false']
05/22/2022 08:41:21 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/22/2022 08:41:21 - INFO - __main__ - ['false']
05/22/2022 08:41:21 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:41:21 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:41:21 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 08:41:21 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 08:41:21 - INFO - __main__ - Printing 3 examples
05/22/2022 08:41:21 - INFO - __main__ -  [ethos-religion] This homo faggot Spike Lee wore this at the Flopscers. Notice the blatant subliminal messages.
05/22/2022 08:41:21 - INFO - __main__ - ['false']
05/22/2022 08:41:21 - INFO - __main__ -  [ethos-religion] I wish HIV to your butthole male whore
05/22/2022 08:41:21 - INFO - __main__ - ['false']
05/22/2022 08:41:21 - INFO - __main__ -  [ethos-religion] This is S-I-C-K If I ever seen a Girlyman like him go into the same lavatory as my wife, or daughter somebody better call the EMTs because the ONLY way SheHe is coming out will be on a Stretcher, or in a body bag! Just sayin..........
05/22/2022 08:41:21 - INFO - __main__ - ['false']
05/22/2022 08:41:21 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:41:21 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:41:21 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 08:41:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 08:41:34 - INFO - __main__ - Starting training!
05/22/2022 08:41:38 - INFO - __main__ - Step 10 Global step 10 Train loss 22.898754 on epoch=0
05/22/2022 08:41:44 - INFO - __main__ - Step 20 Global step 20 Train loss 20.067123 on epoch=1
05/22/2022 08:41:49 - INFO - __main__ - Step 30 Global step 30 Train loss 16.207935 on epoch=2
05/22/2022 08:41:54 - INFO - __main__ - Step 40 Global step 40 Train loss 14.919428 on epoch=3
05/22/2022 08:41:59 - INFO - __main__ - Step 50 Global step 50 Train loss 14.253171 on epoch=4
05/22/2022 08:42:31 - INFO - __main__ - Global step 50 Train loss 17.669283 Classification-F1 0.0013545037248852436 on epoch=4
05/22/2022 08:42:37 - INFO - __main__ - Step 60 Global step 60 Train loss 12.934880 on epoch=4
05/22/2022 08:42:42 - INFO - __main__ - Step 70 Global step 70 Train loss 11.623835 on epoch=5
05/22/2022 08:42:47 - INFO - __main__ - Step 80 Global step 80 Train loss 8.408274 on epoch=6
05/22/2022 08:42:52 - INFO - __main__ - Step 90 Global step 90 Train loss 2.095401 on epoch=7
05/22/2022 08:42:57 - INFO - __main__ - Step 100 Global step 100 Train loss 1.668143 on epoch=8
05/22/2022 08:42:58 - INFO - __main__ - Global step 100 Train loss 7.346106 Classification-F1 0.07913669064748201 on epoch=8
05/22/2022 08:43:04 - INFO - __main__ - Step 110 Global step 110 Train loss 0.667279 on epoch=9
05/22/2022 08:43:09 - INFO - __main__ - Step 120 Global step 120 Train loss 0.506354 on epoch=9
05/22/2022 08:43:14 - INFO - __main__ - Step 130 Global step 130 Train loss 0.556419 on epoch=10
05/22/2022 08:43:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.514597 on epoch=11
05/22/2022 08:43:25 - INFO - __main__ - Step 150 Global step 150 Train loss 0.409963 on epoch=12
05/22/2022 08:43:26 - INFO - __main__ - Global step 150 Train loss 0.530922 Classification-F1 1.0 on epoch=12
05/22/2022 08:43:32 - INFO - __main__ - Step 160 Global step 160 Train loss 0.502879 on epoch=13
05/22/2022 08:43:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.384388 on epoch=14
05/22/2022 08:43:42 - INFO - __main__ - Step 180 Global step 180 Train loss 0.374124 on epoch=14
05/22/2022 08:43:47 - INFO - __main__ - Step 190 Global step 190 Train loss 0.376892 on epoch=15
05/22/2022 08:43:52 - INFO - __main__ - Step 200 Global step 200 Train loss 0.415956 on epoch=16
05/22/2022 08:43:54 - INFO - __main__ - Global step 200 Train loss 0.410848 Classification-F1 0.4796747967479675 on epoch=16
05/22/2022 08:43:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.314063 on epoch=17
05/22/2022 08:44:04 - INFO - __main__ - Step 220 Global step 220 Train loss 0.294886 on epoch=18
05/22/2022 08:44:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.267037 on epoch=19
05/22/2022 08:44:14 - INFO - __main__ - Step 240 Global step 240 Train loss 0.301187 on epoch=19
05/22/2022 08:44:19 - INFO - __main__ - Step 250 Global step 250 Train loss 0.184019 on epoch=20
05/22/2022 08:44:20 - INFO - __main__ - Global step 250 Train loss 0.272238 Classification-F1 0.488 on epoch=20
05/22/2022 08:44:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.242249 on epoch=21
05/22/2022 08:44:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.132218 on epoch=22
05/22/2022 08:44:36 - INFO - __main__ - Step 280 Global step 280 Train loss 0.190853 on epoch=23
05/22/2022 08:44:41 - INFO - __main__ - Step 290 Global step 290 Train loss 0.205901 on epoch=24
05/22/2022 08:44:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.163123 on epoch=24
05/22/2022 08:44:47 - INFO - __main__ - Global step 300 Train loss 0.186869 Classification-F1 0.4838709677419355 on epoch=24
05/22/2022 08:44:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.169139 on epoch=25
05/22/2022 08:44:57 - INFO - __main__ - Step 320 Global step 320 Train loss 0.110398 on epoch=26
05/22/2022 08:45:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.150263 on epoch=27
05/22/2022 08:45:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.128853 on epoch=28
05/22/2022 08:45:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.082021 on epoch=29
05/22/2022 08:45:14 - INFO - __main__ - Global step 350 Train loss 0.128135 Classification-F1 0.49206349206349204 on epoch=29
05/22/2022 08:45:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.146363 on epoch=29
05/22/2022 08:45:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.136683 on epoch=30
05/22/2022 08:45:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.098417 on epoch=31
05/22/2022 08:45:34 - INFO - __main__ - Step 390 Global step 390 Train loss 0.127891 on epoch=32
05/22/2022 08:45:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.086312 on epoch=33
05/22/2022 08:45:41 - INFO - __main__ - Global step 400 Train loss 0.119133 Classification-F1 0.4775510204081633 on epoch=33
05/22/2022 08:45:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.081151 on epoch=34
05/22/2022 08:45:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.109366 on epoch=34
05/22/2022 08:45:56 - INFO - __main__ - Step 430 Global step 430 Train loss 0.040427 on epoch=35
05/22/2022 08:46:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.046211 on epoch=36
05/22/2022 08:46:06 - INFO - __main__ - Step 450 Global step 450 Train loss 0.074413 on epoch=37
05/22/2022 08:46:08 - INFO - __main__ - Global step 450 Train loss 0.070314 Classification-F1 0.4775510204081633 on epoch=37
05/22/2022 08:46:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.017975 on epoch=38
05/22/2022 08:46:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.044540 on epoch=39
05/22/2022 08:46:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.062171 on epoch=39
05/22/2022 08:46:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.029636 on epoch=40
05/22/2022 08:46:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.007029 on epoch=41
05/22/2022 08:46:34 - INFO - __main__ - Global step 500 Train loss 0.032270 Classification-F1 0.4817813765182186 on epoch=41
05/22/2022 08:46:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.017211 on epoch=42
05/22/2022 08:46:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.213762 on epoch=43
05/22/2022 08:46:50 - INFO - __main__ - Step 530 Global step 530 Train loss 0.094461 on epoch=44
05/22/2022 08:46:55 - INFO - __main__ - Step 540 Global step 540 Train loss 0.019868 on epoch=44
05/22/2022 08:47:00 - INFO - __main__ - Step 550 Global step 550 Train loss 0.020878 on epoch=45
05/22/2022 08:47:01 - INFO - __main__ - Global step 550 Train loss 0.073236 Classification-F1 0.4859437751004016 on epoch=45
05/22/2022 08:47:06 - INFO - __main__ - Step 560 Global step 560 Train loss 0.062009 on epoch=46
05/22/2022 08:47:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.050146 on epoch=47
05/22/2022 08:47:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.049835 on epoch=48
05/22/2022 08:47:22 - INFO - __main__ - Step 590 Global step 590 Train loss 0.004488 on epoch=49
05/22/2022 08:47:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.033244 on epoch=49
05/22/2022 08:47:28 - INFO - __main__ - Global step 600 Train loss 0.039944 Classification-F1 0.4859437751004016 on epoch=49
05/22/2022 08:47:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.090950 on epoch=50
05/22/2022 08:47:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.044915 on epoch=51
05/22/2022 08:47:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.013223 on epoch=52
05/22/2022 08:47:48 - INFO - __main__ - Step 640 Global step 640 Train loss 0.015346 on epoch=53
05/22/2022 08:47:53 - INFO - __main__ - Step 650 Global step 650 Train loss 0.009071 on epoch=54
05/22/2022 08:47:55 - INFO - __main__ - Global step 650 Train loss 0.034701 Classification-F1 0.4838709677419355 on epoch=54
05/22/2022 08:48:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.002689 on epoch=54
05/22/2022 08:48:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.001941 on epoch=55
05/22/2022 08:48:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.024410 on epoch=56
05/22/2022 08:48:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.007980 on epoch=57
05/22/2022 08:48:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.018858 on epoch=58
05/22/2022 08:48:22 - INFO - __main__ - Global step 700 Train loss 0.011176 Classification-F1 0.4817813765182186 on epoch=58
05/22/2022 08:48:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.012748 on epoch=59
05/22/2022 08:48:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.016942 on epoch=59
05/22/2022 08:48:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.008931 on epoch=60
05/22/2022 08:48:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.001639 on epoch=61
05/22/2022 08:48:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.024093 on epoch=62
05/22/2022 08:48:49 - INFO - __main__ - Global step 750 Train loss 0.012871 Classification-F1 0.4796747967479675 on epoch=62
05/22/2022 08:48:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.012609 on epoch=63
05/22/2022 08:48:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.009653 on epoch=64
05/22/2022 08:49:04 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000544 on epoch=64
05/22/2022 08:49:09 - INFO - __main__ - Step 790 Global step 790 Train loss 0.008724 on epoch=65
05/22/2022 08:49:14 - INFO - __main__ - Step 800 Global step 800 Train loss 0.003927 on epoch=66
05/22/2022 08:49:15 - INFO - __main__ - Global step 800 Train loss 0.007091 Classification-F1 0.4859437751004016 on epoch=66
05/22/2022 08:49:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.001790 on epoch=67
05/22/2022 08:49:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000376 on epoch=68
05/22/2022 08:49:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000706 on epoch=69
05/22/2022 08:49:36 - INFO - __main__ - Step 840 Global step 840 Train loss 0.007510 on epoch=69
05/22/2022 08:49:41 - INFO - __main__ - Step 850 Global step 850 Train loss 0.013343 on epoch=70
05/22/2022 08:49:42 - INFO - __main__ - Global step 850 Train loss 0.004745 Classification-F1 0.31978319783197834 on epoch=70
05/22/2022 08:49:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000804 on epoch=71
05/22/2022 08:49:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.005284 on epoch=72
05/22/2022 08:49:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.003326 on epoch=73
05/22/2022 08:50:02 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000164 on epoch=74
05/22/2022 08:50:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.010213 on epoch=74
05/22/2022 08:50:09 - INFO - __main__ - Global step 900 Train loss 0.003958 Classification-F1 0.32118758434547906 on epoch=74
05/22/2022 08:50:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000562 on epoch=75
05/22/2022 08:50:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.008838 on epoch=76
05/22/2022 08:50:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000063 on epoch=77
05/22/2022 08:50:29 - INFO - __main__ - Step 940 Global step 940 Train loss 0.007710 on epoch=78
05/22/2022 08:50:34 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000351 on epoch=79
05/22/2022 08:50:36 - INFO - __main__ - Global step 950 Train loss 0.003505 Classification-F1 0.4838709677419355 on epoch=79
05/22/2022 08:50:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.017200 on epoch=79
05/22/2022 08:50:46 - INFO - __main__ - Step 970 Global step 970 Train loss 0.002199 on epoch=80
05/22/2022 08:50:51 - INFO - __main__ - Step 980 Global step 980 Train loss 0.001135 on epoch=81
05/22/2022 08:50:56 - INFO - __main__ - Step 990 Global step 990 Train loss 0.005662 on epoch=82
05/22/2022 08:51:01 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.012008 on epoch=83
05/22/2022 08:51:02 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 08:51:02 - INFO - __main__ - Printing 3 examples
05/22/2022 08:51:02 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 08:51:02 - INFO - __main__ - ['false']
05/22/2022 08:51:02 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 08:51:02 - INFO - __main__ - ['false']
05/22/2022 08:51:02 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/22/2022 08:51:02 - INFO - __main__ - ['false']
05/22/2022 08:51:02 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:51:02 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:51:03 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 08:51:03 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 08:51:03 - INFO - __main__ - Printing 3 examples
05/22/2022 08:51:03 - INFO - __main__ -  [ethos-religion] This homo faggot Spike Lee wore this at the Flopscers. Notice the blatant subliminal messages.
05/22/2022 08:51:03 - INFO - __main__ - ['false']
05/22/2022 08:51:03 - INFO - __main__ -  [ethos-religion] I wish HIV to your butthole male whore
05/22/2022 08:51:03 - INFO - __main__ - ['false']
05/22/2022 08:51:03 - INFO - __main__ -  [ethos-religion] This is S-I-C-K If I ever seen a Girlyman like him go into the same lavatory as my wife, or daughter somebody better call the EMTs because the ONLY way SheHe is coming out will be on a Stretcher, or in a body bag! Just sayin..........
05/22/2022 08:51:03 - INFO - __main__ - ['false']
05/22/2022 08:51:03 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:51:03 - INFO - __main__ - Global step 1000 Train loss 0.007641 Classification-F1 0.4859437751004016 on epoch=83
05/22/2022 08:51:03 - INFO - __main__ - save last model!
05/22/2022 08:51:03 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:51:03 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 08:51:10 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 08:51:11 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 08:51:11 - INFO - __main__ - Printing 3 examples
05/22/2022 08:51:11 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 08:51:11 - INFO - __main__ - ['false']
05/22/2022 08:51:11 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 08:51:11 - INFO - __main__ - ['false']
05/22/2022 08:51:11 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 08:51:11 - INFO - __main__ - ['true']
05/22/2022 08:51:11 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:51:11 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:51:11 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 08:51:12 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_13_0.0003_8_predictions.txt
05/22/2022 08:51:12 - INFO - __main__ - Classification-F1 on test data: 0.4387
05/22/2022 08:51:13 - INFO - __main__ - prefix=ethos-religion_128_13, lr=0.0003, bsz=8, dev_performance=1.0, test_performance=0.4387096774193549
05/22/2022 08:51:13 - INFO - __main__ - Running ... prefix=ethos-religion_128_13, lr=0.0002, bsz=8 ...
05/22/2022 08:51:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 08:51:13 - INFO - __main__ - Starting training!
05/22/2022 08:51:14 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 08:51:14 - INFO - __main__ - Printing 3 examples
05/22/2022 08:51:14 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 08:51:14 - INFO - __main__ - ['false']
05/22/2022 08:51:14 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 08:51:14 - INFO - __main__ - ['false']
05/22/2022 08:51:14 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/22/2022 08:51:14 - INFO - __main__ - ['false']
05/22/2022 08:51:14 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:51:14 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:51:14 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 08:51:14 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 08:51:14 - INFO - __main__ - Printing 3 examples
05/22/2022 08:51:14 - INFO - __main__ -  [ethos-religion] This homo faggot Spike Lee wore this at the Flopscers. Notice the blatant subliminal messages.
05/22/2022 08:51:14 - INFO - __main__ - ['false']
05/22/2022 08:51:14 - INFO - __main__ -  [ethos-religion] I wish HIV to your butthole male whore
05/22/2022 08:51:14 - INFO - __main__ - ['false']
05/22/2022 08:51:14 - INFO - __main__ -  [ethos-religion] This is S-I-C-K If I ever seen a Girlyman like him go into the same lavatory as my wife, or daughter somebody better call the EMTs because the ONLY way SheHe is coming out will be on a Stretcher, or in a body bag! Just sayin..........
05/22/2022 08:51:14 - INFO - __main__ - ['false']
05/22/2022 08:51:14 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:51:14 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:51:14 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 08:51:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 08:51:26 - INFO - __main__ - Starting training!
05/22/2022 08:51:31 - INFO - __main__ - Step 10 Global step 10 Train loss 23.298357 on epoch=0
05/22/2022 08:51:36 - INFO - __main__ - Step 20 Global step 20 Train loss 20.373363 on epoch=1
05/22/2022 08:51:41 - INFO - __main__ - Step 30 Global step 30 Train loss 18.256540 on epoch=2
05/22/2022 08:51:46 - INFO - __main__ - Step 40 Global step 40 Train loss 17.251228 on epoch=3
05/22/2022 08:51:51 - INFO - __main__ - Step 50 Global step 50 Train loss 16.061989 on epoch=4
05/22/2022 08:52:22 - INFO - __main__ - Global step 50 Train loss 19.048296 Classification-F1 0.0 on epoch=4
05/22/2022 08:52:28 - INFO - __main__ - Step 60 Global step 60 Train loss 15.712723 on epoch=4
05/22/2022 08:52:33 - INFO - __main__ - Step 70 Global step 70 Train loss 14.868584 on epoch=5
05/22/2022 08:52:38 - INFO - __main__ - Step 80 Global step 80 Train loss 13.894493 on epoch=6
05/22/2022 08:52:43 - INFO - __main__ - Step 90 Global step 90 Train loss 13.454489 on epoch=7
05/22/2022 08:52:48 - INFO - __main__ - Step 100 Global step 100 Train loss 12.212173 on epoch=8
05/22/2022 08:53:01 - INFO - __main__ - Global step 100 Train loss 14.028494 Classification-F1 0.0 on epoch=8
05/22/2022 08:53:06 - INFO - __main__ - Step 110 Global step 110 Train loss 11.536078 on epoch=9
05/22/2022 08:53:12 - INFO - __main__ - Step 120 Global step 120 Train loss 9.267500 on epoch=9
05/22/2022 08:53:17 - INFO - __main__ - Step 130 Global step 130 Train loss 5.993010 on epoch=10
05/22/2022 08:53:22 - INFO - __main__ - Step 140 Global step 140 Train loss 1.868453 on epoch=11
05/22/2022 08:53:27 - INFO - __main__ - Step 150 Global step 150 Train loss 0.693617 on epoch=12
05/22/2022 08:53:28 - INFO - __main__ - Global step 150 Train loss 5.871732 Classification-F1 1.0 on epoch=12
05/22/2022 08:53:34 - INFO - __main__ - Step 160 Global step 160 Train loss 0.524606 on epoch=13
05/22/2022 08:53:39 - INFO - __main__ - Step 170 Global step 170 Train loss 0.528420 on epoch=14
05/22/2022 08:53:44 - INFO - __main__ - Step 180 Global step 180 Train loss 0.495890 on epoch=14
05/22/2022 08:53:49 - INFO - __main__ - Step 190 Global step 190 Train loss 0.428886 on epoch=15
05/22/2022 08:53:54 - INFO - __main__ - Step 200 Global step 200 Train loss 0.480744 on epoch=16
05/22/2022 08:53:56 - INFO - __main__ - Global step 200 Train loss 0.491709 Classification-F1 1.0 on epoch=16
05/22/2022 08:54:01 - INFO - __main__ - Step 210 Global step 210 Train loss 0.436648 on epoch=17
05/22/2022 08:54:06 - INFO - __main__ - Step 220 Global step 220 Train loss 0.452470 on epoch=18
05/22/2022 08:54:11 - INFO - __main__ - Step 230 Global step 230 Train loss 0.423083 on epoch=19
05/22/2022 08:54:16 - INFO - __main__ - Step 240 Global step 240 Train loss 0.364830 on epoch=19
05/22/2022 08:54:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.373660 on epoch=20
05/22/2022 08:54:22 - INFO - __main__ - Global step 250 Train loss 0.410138 Classification-F1 1.0 on epoch=20
05/22/2022 08:54:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.448509 on epoch=21
05/22/2022 08:54:33 - INFO - __main__ - Step 270 Global step 270 Train loss 0.364343 on epoch=22
05/22/2022 08:54:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.380505 on epoch=23
05/22/2022 08:54:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.400591 on epoch=24
05/22/2022 08:54:48 - INFO - __main__ - Step 300 Global step 300 Train loss 0.360670 on epoch=24
05/22/2022 08:54:49 - INFO - __main__ - Global step 300 Train loss 0.390924 Classification-F1 1.0 on epoch=24
05/22/2022 08:54:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.420442 on epoch=25
05/22/2022 08:55:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.487145 on epoch=26
05/22/2022 08:55:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.371002 on epoch=27
05/22/2022 08:55:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.314829 on epoch=28
05/22/2022 08:55:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.338457 on epoch=29
05/22/2022 08:55:16 - INFO - __main__ - Global step 350 Train loss 0.386375 Classification-F1 1.0 on epoch=29
05/22/2022 08:55:22 - INFO - __main__ - Step 360 Global step 360 Train loss 0.300273 on epoch=29
05/22/2022 08:55:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.403567 on epoch=30
05/22/2022 08:55:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.442361 on epoch=31
05/22/2022 08:55:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.340932 on epoch=32
05/22/2022 08:55:42 - INFO - __main__ - Step 400 Global step 400 Train loss 0.368299 on epoch=33
05/22/2022 08:55:43 - INFO - __main__ - Global step 400 Train loss 0.371087 Classification-F1 0.058823529411764705 on epoch=33
05/22/2022 08:55:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.380596 on epoch=34
05/22/2022 08:55:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.394453 on epoch=34
05/22/2022 08:55:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.382953 on epoch=35
05/22/2022 08:56:04 - INFO - __main__ - Step 440 Global step 440 Train loss 0.384433 on epoch=36
05/22/2022 08:56:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.333060 on epoch=37
05/22/2022 08:56:10 - INFO - __main__ - Global step 450 Train loss 0.375099 Classification-F1 1.0 on epoch=37
05/22/2022 08:56:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.376325 on epoch=38
05/22/2022 08:56:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.327833 on epoch=39
05/22/2022 08:56:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.333148 on epoch=39
05/22/2022 08:56:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.376277 on epoch=40
05/22/2022 08:56:36 - INFO - __main__ - Step 500 Global step 500 Train loss 0.369721 on epoch=41
05/22/2022 08:56:37 - INFO - __main__ - Global step 500 Train loss 0.356661 Classification-F1 1.0 on epoch=41
05/22/2022 08:56:43 - INFO - __main__ - Step 510 Global step 510 Train loss 0.339835 on epoch=42
05/22/2022 08:56:48 - INFO - __main__ - Step 520 Global step 520 Train loss 0.360164 on epoch=43
05/22/2022 08:56:53 - INFO - __main__ - Step 530 Global step 530 Train loss 0.392662 on epoch=44
05/22/2022 08:56:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.314802 on epoch=44
05/22/2022 08:57:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.359687 on epoch=45
05/22/2022 08:57:04 - INFO - __main__ - Global step 550 Train loss 0.353430 Classification-F1 1.0 on epoch=45
05/22/2022 08:57:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.332191 on epoch=46
05/22/2022 08:57:14 - INFO - __main__ - Step 570 Global step 570 Train loss 0.350609 on epoch=47
05/22/2022 08:57:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.349841 on epoch=48
05/22/2022 08:57:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.355915 on epoch=49
05/22/2022 08:57:30 - INFO - __main__ - Step 600 Global step 600 Train loss 0.335572 on epoch=49
05/22/2022 08:57:31 - INFO - __main__ - Global step 600 Train loss 0.344825 Classification-F1 0.4980392156862745 on epoch=49
05/22/2022 08:57:36 - INFO - __main__ - Step 610 Global step 610 Train loss 0.343882 on epoch=50
05/22/2022 08:57:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.375639 on epoch=51
05/22/2022 08:57:46 - INFO - __main__ - Step 630 Global step 630 Train loss 0.383291 on epoch=52
05/22/2022 08:57:51 - INFO - __main__ - Step 640 Global step 640 Train loss 0.313187 on epoch=53
05/22/2022 08:57:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.326915 on epoch=54
05/22/2022 08:57:58 - INFO - __main__ - Global step 650 Train loss 0.348583 Classification-F1 1.0 on epoch=54
05/22/2022 08:58:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.269411 on epoch=54
05/22/2022 08:58:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.323041 on epoch=55
05/22/2022 08:58:13 - INFO - __main__ - Step 680 Global step 680 Train loss 0.372401 on epoch=56
05/22/2022 08:58:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.399391 on epoch=57
05/22/2022 08:58:23 - INFO - __main__ - Step 700 Global step 700 Train loss 0.333626 on epoch=58
05/22/2022 08:58:25 - INFO - __main__ - Global step 700 Train loss 0.339574 Classification-F1 0.3155080213903743 on epoch=58
05/22/2022 08:58:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.335371 on epoch=59
05/22/2022 08:58:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.290443 on epoch=59
05/22/2022 08:58:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.358166 on epoch=60
05/22/2022 08:58:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.362328 on epoch=61
05/22/2022 08:58:50 - INFO - __main__ - Step 750 Global step 750 Train loss 0.332244 on epoch=62
05/22/2022 08:58:52 - INFO - __main__ - Global step 750 Train loss 0.335711 Classification-F1 0.46443514644351463 on epoch=62
05/22/2022 08:58:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.299027 on epoch=63
05/22/2022 08:59:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.336284 on epoch=64
05/22/2022 08:59:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.319623 on epoch=64
05/22/2022 08:59:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.287735 on epoch=65
05/22/2022 08:59:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.355094 on epoch=66
05/22/2022 08:59:19 - INFO - __main__ - Global step 800 Train loss 0.319552 Classification-F1 0.452991452991453 on epoch=66
05/22/2022 08:59:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.270632 on epoch=67
05/22/2022 08:59:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.217662 on epoch=68
05/22/2022 08:59:34 - INFO - __main__ - Step 830 Global step 830 Train loss 0.252766 on epoch=69
05/22/2022 08:59:39 - INFO - __main__ - Step 840 Global step 840 Train loss 0.258703 on epoch=69
05/22/2022 08:59:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.249915 on epoch=70
05/22/2022 08:59:46 - INFO - __main__ - Global step 850 Train loss 0.249936 Classification-F1 0.49206349206349204 on epoch=70
05/22/2022 08:59:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.284957 on epoch=71
05/22/2022 08:59:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.300734 on epoch=72
05/22/2022 09:00:01 - INFO - __main__ - Step 880 Global step 880 Train loss 0.220969 on epoch=73
05/22/2022 09:00:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.323573 on epoch=74
05/22/2022 09:00:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.255879 on epoch=74
05/22/2022 09:00:12 - INFO - __main__ - Global step 900 Train loss 0.277222 Classification-F1 0.45064377682403434 on epoch=74
05/22/2022 09:00:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.244463 on epoch=75
05/22/2022 09:00:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.334144 on epoch=76
05/22/2022 09:00:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.312958 on epoch=77
05/22/2022 09:00:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.269770 on epoch=78
05/22/2022 09:00:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.250331 on epoch=79
05/22/2022 09:00:40 - INFO - __main__ - Global step 950 Train loss 0.282333 Classification-F1 0.488 on epoch=79
05/22/2022 09:00:45 - INFO - __main__ - Step 960 Global step 960 Train loss 0.257384 on epoch=79
05/22/2022 09:00:50 - INFO - __main__ - Step 970 Global step 970 Train loss 0.240756 on epoch=80
05/22/2022 09:00:55 - INFO - __main__ - Step 980 Global step 980 Train loss 0.245214 on epoch=81
05/22/2022 09:01:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.253680 on epoch=82
05/22/2022 09:01:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.184846 on epoch=83
05/22/2022 09:01:06 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 09:01:06 - INFO - __main__ - Printing 3 examples
05/22/2022 09:01:06 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 09:01:06 - INFO - __main__ - ['false']
05/22/2022 09:01:06 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 09:01:06 - INFO - __main__ - ['false']
05/22/2022 09:01:06 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/22/2022 09:01:06 - INFO - __main__ - ['false']
05/22/2022 09:01:06 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:01:06 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:01:07 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 09:01:07 - INFO - __main__ - Global step 1000 Train loss 0.236376 Classification-F1 0.42081447963800905 on epoch=83
05/22/2022 09:01:07 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 09:01:07 - INFO - __main__ - Printing 3 examples
05/22/2022 09:01:07 - INFO - __main__ -  [ethos-religion] This homo faggot Spike Lee wore this at the Flopscers. Notice the blatant subliminal messages.
05/22/2022 09:01:07 - INFO - __main__ - ['false']
05/22/2022 09:01:07 - INFO - __main__ -  [ethos-religion] I wish HIV to your butthole male whore
05/22/2022 09:01:07 - INFO - __main__ - ['false']
05/22/2022 09:01:07 - INFO - __main__ -  [ethos-religion] This is S-I-C-K If I ever seen a Girlyman like him go into the same lavatory as my wife, or daughter somebody better call the EMTs because the ONLY way SheHe is coming out will be on a Stretcher, or in a body bag! Just sayin..........
05/22/2022 09:01:07 - INFO - __main__ - ['false']
05/22/2022 09:01:07 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:01:07 - INFO - __main__ - save last model!
05/22/2022 09:01:07 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:01:07 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 09:01:14 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 09:01:14 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 09:01:14 - INFO - __main__ - Printing 3 examples
05/22/2022 09:01:14 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 09:01:14 - INFO - __main__ - ['false']
05/22/2022 09:01:14 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 09:01:14 - INFO - __main__ - ['false']
05/22/2022 09:01:14 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 09:01:14 - INFO - __main__ - ['true']
05/22/2022 09:01:14 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:01:14 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:01:14 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 09:01:16 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_13_0.0002_8_predictions.txt
05/22/2022 09:01:16 - INFO - __main__ - Classification-F1 on test data: 0.4387
05/22/2022 09:01:16 - INFO - __main__ - prefix=ethos-religion_128_13, lr=0.0002, bsz=8, dev_performance=1.0, test_performance=0.4387096774193549
05/22/2022 09:01:16 - INFO - __main__ - Running ... prefix=ethos-religion_128_13, lr=0.0001, bsz=8 ...
05/22/2022 09:01:17 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 09:01:17 - INFO - __main__ - Printing 3 examples
05/22/2022 09:01:17 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 09:01:17 - INFO - __main__ - ['false']
05/22/2022 09:01:17 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 09:01:17 - INFO - __main__ - ['false']
05/22/2022 09:01:17 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/22/2022 09:01:17 - INFO - __main__ - ['false']
05/22/2022 09:01:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:01:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 09:01:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:01:17 - INFO - __main__ - Starting training!
05/22/2022 09:01:17 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 09:01:17 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 09:01:17 - INFO - __main__ - Printing 3 examples
05/22/2022 09:01:17 - INFO - __main__ -  [ethos-religion] This homo faggot Spike Lee wore this at the Flopscers. Notice the blatant subliminal messages.
05/22/2022 09:01:17 - INFO - __main__ - ['false']
05/22/2022 09:01:17 - INFO - __main__ -  [ethos-religion] I wish HIV to your butthole male whore
05/22/2022 09:01:17 - INFO - __main__ - ['false']
05/22/2022 09:01:17 - INFO - __main__ -  [ethos-religion] This is S-I-C-K If I ever seen a Girlyman like him go into the same lavatory as my wife, or daughter somebody better call the EMTs because the ONLY way SheHe is coming out will be on a Stretcher, or in a body bag! Just sayin..........
05/22/2022 09:01:17 - INFO - __main__ - ['false']
05/22/2022 09:01:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:01:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:01:17 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 09:01:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 09:01:30 - INFO - __main__ - Starting training!
05/22/2022 09:01:34 - INFO - __main__ - Step 10 Global step 10 Train loss 23.980518 on epoch=0
05/22/2022 09:01:39 - INFO - __main__ - Step 20 Global step 20 Train loss 21.231487 on epoch=1
05/22/2022 09:01:45 - INFO - __main__ - Step 30 Global step 30 Train loss 18.749544 on epoch=2
05/22/2022 09:01:50 - INFO - __main__ - Step 40 Global step 40 Train loss 17.666183 on epoch=3
05/22/2022 09:01:55 - INFO - __main__ - Step 50 Global step 50 Train loss 17.542112 on epoch=4
05/22/2022 09:02:37 - INFO - __main__ - Global step 50 Train loss 19.833969 Classification-F1 0.0 on epoch=4
05/22/2022 09:02:42 - INFO - __main__ - Step 60 Global step 60 Train loss 17.471363 on epoch=4
05/22/2022 09:02:48 - INFO - __main__ - Step 70 Global step 70 Train loss 16.471163 on epoch=5
05/22/2022 09:02:53 - INFO - __main__ - Step 80 Global step 80 Train loss 16.491497 on epoch=6
05/22/2022 09:02:58 - INFO - __main__ - Step 90 Global step 90 Train loss 16.173475 on epoch=7
05/22/2022 09:03:03 - INFO - __main__ - Step 100 Global step 100 Train loss 15.079363 on epoch=8
05/22/2022 09:03:43 - INFO - __main__ - Global step 100 Train loss 16.337372 Classification-F1 0.0 on epoch=8
05/22/2022 09:03:48 - INFO - __main__ - Step 110 Global step 110 Train loss 15.045160 on epoch=9
05/22/2022 09:03:53 - INFO - __main__ - Step 120 Global step 120 Train loss 14.180168 on epoch=9
05/22/2022 09:03:58 - INFO - __main__ - Step 130 Global step 130 Train loss 14.010365 on epoch=10
05/22/2022 09:04:03 - INFO - __main__ - Step 140 Global step 140 Train loss 13.508865 on epoch=11
05/22/2022 09:04:08 - INFO - __main__ - Step 150 Global step 150 Train loss 13.879397 on epoch=12
05/22/2022 09:04:13 - INFO - __main__ - Global step 150 Train loss 14.124790 Classification-F1 0.0 on epoch=12
05/22/2022 09:04:18 - INFO - __main__ - Step 160 Global step 160 Train loss 13.222191 on epoch=13
05/22/2022 09:04:23 - INFO - __main__ - Step 170 Global step 170 Train loss 13.001694 on epoch=14
05/22/2022 09:04:29 - INFO - __main__ - Step 180 Global step 180 Train loss 12.419570 on epoch=14
05/22/2022 09:04:34 - INFO - __main__ - Step 190 Global step 190 Train loss 11.756561 on epoch=15
05/22/2022 09:04:39 - INFO - __main__ - Step 200 Global step 200 Train loss 11.396245 on epoch=16
05/22/2022 09:04:42 - INFO - __main__ - Global step 200 Train loss 12.359252 Classification-F1 0.0 on epoch=16
05/22/2022 09:04:47 - INFO - __main__ - Step 210 Global step 210 Train loss 10.272084 on epoch=17
05/22/2022 09:04:52 - INFO - __main__ - Step 220 Global step 220 Train loss 10.540611 on epoch=18
05/22/2022 09:04:58 - INFO - __main__ - Step 230 Global step 230 Train loss 8.385866 on epoch=19
05/22/2022 09:05:03 - INFO - __main__ - Step 240 Global step 240 Train loss 7.558181 on epoch=19
05/22/2022 09:05:08 - INFO - __main__ - Step 250 Global step 250 Train loss 5.808447 on epoch=20
05/22/2022 09:05:28 - INFO - __main__ - Global step 250 Train loss 8.513038 Classification-F1 0.019555555555555555 on epoch=20
05/22/2022 09:05:35 - INFO - __main__ - Step 260 Global step 260 Train loss 3.194106 on epoch=21
05/22/2022 09:05:40 - INFO - __main__ - Step 270 Global step 270 Train loss 1.041807 on epoch=22
05/22/2022 09:05:45 - INFO - __main__ - Step 280 Global step 280 Train loss 0.737990 on epoch=23
05/22/2022 09:05:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.805451 on epoch=24
05/22/2022 09:05:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.490809 on epoch=24
05/22/2022 09:05:56 - INFO - __main__ - Global step 300 Train loss 1.254033 Classification-F1 0.4980392156862745 on epoch=24
05/22/2022 09:06:02 - INFO - __main__ - Step 310 Global step 310 Train loss 0.595030 on epoch=25
05/22/2022 09:06:07 - INFO - __main__ - Step 320 Global step 320 Train loss 0.448772 on epoch=26
05/22/2022 09:06:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.415016 on epoch=27
05/22/2022 09:06:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.890965 on epoch=28
05/22/2022 09:06:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.741990 on epoch=29
05/22/2022 09:06:24 - INFO - __main__ - Global step 350 Train loss 0.618355 Classification-F1 0.4980392156862745 on epoch=29
05/22/2022 09:06:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.693115 on epoch=29
05/22/2022 09:06:34 - INFO - __main__ - Step 370 Global step 370 Train loss 0.452393 on epoch=30
05/22/2022 09:06:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.391043 on epoch=31
05/22/2022 09:06:44 - INFO - __main__ - Step 390 Global step 390 Train loss 0.575888 on epoch=32
05/22/2022 09:06:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.196059 on epoch=33
05/22/2022 09:06:51 - INFO - __main__ - Global step 400 Train loss 0.461700 Classification-F1 0.4732510288065844 on epoch=33
05/22/2022 09:06:56 - INFO - __main__ - Step 410 Global step 410 Train loss 0.363214 on epoch=34
05/22/2022 09:07:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.239065 on epoch=34
05/22/2022 09:07:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.268715 on epoch=35
05/22/2022 09:07:11 - INFO - __main__ - Step 440 Global step 440 Train loss 0.284190 on epoch=36
05/22/2022 09:07:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.185853 on epoch=37
05/22/2022 09:07:18 - INFO - __main__ - Global step 450 Train loss 0.268207 Classification-F1 0.452991452991453 on epoch=37
05/22/2022 09:07:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.149766 on epoch=38
05/22/2022 09:07:28 - INFO - __main__ - Step 470 Global step 470 Train loss 0.191211 on epoch=39
05/22/2022 09:07:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.242316 on epoch=39
05/22/2022 09:07:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.391712 on epoch=40
05/22/2022 09:07:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.389549 on epoch=41
05/22/2022 09:07:45 - INFO - __main__ - Global step 500 Train loss 0.272910 Classification-F1 0.4817813765182186 on epoch=41
05/22/2022 09:07:50 - INFO - __main__ - Step 510 Global step 510 Train loss 0.194695 on epoch=42
05/22/2022 09:07:55 - INFO - __main__ - Step 520 Global step 520 Train loss 0.158891 on epoch=43
05/22/2022 09:08:00 - INFO - __main__ - Step 530 Global step 530 Train loss 0.207934 on epoch=44
05/22/2022 09:08:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.134472 on epoch=44
05/22/2022 09:08:11 - INFO - __main__ - Step 550 Global step 550 Train loss 0.210465 on epoch=45
05/22/2022 09:08:12 - INFO - __main__ - Global step 550 Train loss 0.181292 Classification-F1 0.4859437751004016 on epoch=45
05/22/2022 09:08:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.168158 on epoch=46
05/22/2022 09:08:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.130817 on epoch=47
05/22/2022 09:08:27 - INFO - __main__ - Step 580 Global step 580 Train loss 0.101093 on epoch=48
05/22/2022 09:08:33 - INFO - __main__ - Step 590 Global step 590 Train loss 0.155927 on epoch=49
05/22/2022 09:08:38 - INFO - __main__ - Step 600 Global step 600 Train loss 0.226330 on epoch=49
05/22/2022 09:08:39 - INFO - __main__ - Global step 600 Train loss 0.156465 Classification-F1 0.49407114624505927 on epoch=49
05/22/2022 09:08:44 - INFO - __main__ - Step 610 Global step 610 Train loss 0.083573 on epoch=50
05/22/2022 09:08:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.099193 on epoch=51
05/22/2022 09:08:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.114658 on epoch=52
05/22/2022 09:09:00 - INFO - __main__ - Step 640 Global step 640 Train loss 0.152507 on epoch=53
05/22/2022 09:09:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.140423 on epoch=54
05/22/2022 09:09:06 - INFO - __main__ - Global step 650 Train loss 0.118071 Classification-F1 0.4838709677419355 on epoch=54
05/22/2022 09:09:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.109313 on epoch=54
05/22/2022 09:09:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.137084 on epoch=55
05/22/2022 09:09:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.113822 on epoch=56
05/22/2022 09:09:27 - INFO - __main__ - Step 690 Global step 690 Train loss 0.164853 on epoch=57
05/22/2022 09:09:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.101510 on epoch=58
05/22/2022 09:09:33 - INFO - __main__ - Global step 700 Train loss 0.125316 Classification-F1 0.4838709677419355 on epoch=58
05/22/2022 09:09:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.318352 on epoch=59
05/22/2022 09:09:43 - INFO - __main__ - Step 720 Global step 720 Train loss 0.112384 on epoch=59
05/22/2022 09:09:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.128277 on epoch=60
05/22/2022 09:09:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.149435 on epoch=61
05/22/2022 09:09:59 - INFO - __main__ - Step 750 Global step 750 Train loss 0.074838 on epoch=62
05/22/2022 09:10:00 - INFO - __main__ - Global step 750 Train loss 0.156657 Classification-F1 0.4732510288065844 on epoch=62
05/22/2022 09:10:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.099224 on epoch=63
05/22/2022 09:10:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.081047 on epoch=64
05/22/2022 09:10:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.084407 on epoch=64
05/22/2022 09:10:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.080278 on epoch=65
05/22/2022 09:10:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.070633 on epoch=66
05/22/2022 09:10:27 - INFO - __main__ - Global step 800 Train loss 0.083118 Classification-F1 0.4796747967479675 on epoch=66
05/22/2022 09:10:32 - INFO - __main__ - Step 810 Global step 810 Train loss 0.109247 on epoch=67
05/22/2022 09:10:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.086909 on epoch=68
05/22/2022 09:10:42 - INFO - __main__ - Step 830 Global step 830 Train loss 0.064779 on epoch=69
05/22/2022 09:10:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.096745 on epoch=69
05/22/2022 09:10:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.077704 on epoch=70
05/22/2022 09:10:54 - INFO - __main__ - Global step 850 Train loss 0.087077 Classification-F1 0.4817813765182186 on epoch=70
05/22/2022 09:10:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.067338 on epoch=71
05/22/2022 09:11:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.085598 on epoch=72
05/22/2022 09:11:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.070226 on epoch=73
05/22/2022 09:11:15 - INFO - __main__ - Step 890 Global step 890 Train loss 0.088692 on epoch=74
05/22/2022 09:11:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.114687 on epoch=74
05/22/2022 09:11:21 - INFO - __main__ - Global step 900 Train loss 0.085308 Classification-F1 0.488 on epoch=74
05/22/2022 09:11:26 - INFO - __main__ - Step 910 Global step 910 Train loss 0.080594 on epoch=75
05/22/2022 09:11:31 - INFO - __main__ - Step 920 Global step 920 Train loss 0.073816 on epoch=76
05/22/2022 09:11:36 - INFO - __main__ - Step 930 Global step 930 Train loss 0.045133 on epoch=77
05/22/2022 09:11:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.040940 on epoch=78
05/22/2022 09:11:47 - INFO - __main__ - Step 950 Global step 950 Train loss 0.064714 on epoch=79
05/22/2022 09:11:48 - INFO - __main__ - Global step 950 Train loss 0.061040 Classification-F1 0.4838709677419355 on epoch=79
05/22/2022 09:11:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.092844 on epoch=79
05/22/2022 09:11:58 - INFO - __main__ - Step 970 Global step 970 Train loss 0.011285 on epoch=80
05/22/2022 09:12:03 - INFO - __main__ - Step 980 Global step 980 Train loss 0.031791 on epoch=81
05/22/2022 09:12:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.066070 on epoch=82
05/22/2022 09:12:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.046426 on epoch=83
05/22/2022 09:12:15 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 09:12:15 - INFO - __main__ - Printing 3 examples
05/22/2022 09:12:15 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 09:12:15 - INFO - __main__ - ['false']
05/22/2022 09:12:15 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/22/2022 09:12:15 - INFO - __main__ - ['false']
05/22/2022 09:12:15 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/22/2022 09:12:15 - INFO - __main__ - ['false']
05/22/2022 09:12:15 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:12:15 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:12:15 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 09:12:15 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 09:12:15 - INFO - __main__ - Printing 3 examples
05/22/2022 09:12:15 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 09:12:15 - INFO - __main__ - ['false']
05/22/2022 09:12:15 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 09:12:15 - INFO - __main__ - ['false']
05/22/2022 09:12:15 - INFO - __main__ -  [ethos-religion] With no legs you are just a bag of meat in your household. Do them the favour and get dead already
05/22/2022 09:12:15 - INFO - __main__ - ['false']
05/22/2022 09:12:15 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:12:15 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:12:15 - INFO - __main__ - Global step 1000 Train loss 0.049683 Classification-F1 0.4838709677419355 on epoch=83
05/22/2022 09:12:15 - INFO - __main__ - save last model!
05/22/2022 09:12:15 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 09:12:23 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 09:12:23 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 09:12:23 - INFO - __main__ - Printing 3 examples
05/22/2022 09:12:23 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 09:12:23 - INFO - __main__ - ['false']
05/22/2022 09:12:23 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 09:12:23 - INFO - __main__ - ['false']
05/22/2022 09:12:23 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 09:12:23 - INFO - __main__ - ['true']
05/22/2022 09:12:23 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:12:23 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:12:24 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 09:12:25 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_13_0.0001_8_predictions.txt
05/22/2022 09:12:25 - INFO - __main__ - Classification-F1 on test data: 0.5397
05/22/2022 09:12:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 09:12:26 - INFO - __main__ - Starting training!
05/22/2022 09:12:26 - INFO - __main__ - prefix=ethos-religion_128_13, lr=0.0001, bsz=8, dev_performance=0.4980392156862745, test_performance=0.5396825396825398
05/22/2022 09:12:26 - INFO - __main__ - Running ... prefix=ethos-religion_128_21, lr=0.0005, bsz=8 ...
05/22/2022 09:12:27 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 09:12:27 - INFO - __main__ - Printing 3 examples
05/22/2022 09:12:27 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 09:12:27 - INFO - __main__ - ['false']
05/22/2022 09:12:27 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/22/2022 09:12:27 - INFO - __main__ - ['false']
05/22/2022 09:12:27 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/22/2022 09:12:27 - INFO - __main__ - ['false']
05/22/2022 09:12:27 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:12:27 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:12:27 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 09:12:27 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 09:12:27 - INFO - __main__ - Printing 3 examples
05/22/2022 09:12:27 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 09:12:27 - INFO - __main__ - ['false']
05/22/2022 09:12:27 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 09:12:27 - INFO - __main__ - ['false']
05/22/2022 09:12:27 - INFO - __main__ -  [ethos-religion] With no legs you are just a bag of meat in your household. Do them the favour and get dead already
05/22/2022 09:12:27 - INFO - __main__ - ['false']
05/22/2022 09:12:27 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:12:27 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:12:27 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 09:12:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 09:12:39 - INFO - __main__ - Starting training!
05/22/2022 09:12:44 - INFO - __main__ - Step 10 Global step 10 Train loss 23.329996 on epoch=0
05/22/2022 09:12:49 - INFO - __main__ - Step 20 Global step 20 Train loss 17.507977 on epoch=1
05/22/2022 09:12:54 - INFO - __main__ - Step 30 Global step 30 Train loss 16.145908 on epoch=2
05/22/2022 09:12:59 - INFO - __main__ - Step 40 Global step 40 Train loss 13.712636 on epoch=3
05/22/2022 09:13:04 - INFO - __main__ - Step 50 Global step 50 Train loss 11.580969 on epoch=4
05/22/2022 09:13:38 - INFO - __main__ - Global step 50 Train loss 16.455498 Classification-F1 0.0 on epoch=4
05/22/2022 09:13:44 - INFO - __main__ - Step 60 Global step 60 Train loss 3.968457 on epoch=4
05/22/2022 09:13:49 - INFO - __main__ - Step 70 Global step 70 Train loss 4.000705 on epoch=5
05/22/2022 09:13:54 - INFO - __main__ - Step 80 Global step 80 Train loss 2.723318 on epoch=6
05/22/2022 09:13:59 - INFO - __main__ - Step 90 Global step 90 Train loss 1.997598 on epoch=7
05/22/2022 09:14:04 - INFO - __main__ - Step 100 Global step 100 Train loss 0.957013 on epoch=8
05/22/2022 09:14:06 - INFO - __main__ - Global step 100 Train loss 2.729418 Classification-F1 0.0 on epoch=8
05/22/2022 09:14:11 - INFO - __main__ - Step 110 Global step 110 Train loss 0.626290 on epoch=9
05/22/2022 09:14:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.450258 on epoch=9
05/22/2022 09:14:21 - INFO - __main__ - Step 130 Global step 130 Train loss 0.458003 on epoch=10
05/22/2022 09:14:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.409152 on epoch=11
05/22/2022 09:14:31 - INFO - __main__ - Step 150 Global step 150 Train loss 0.507235 on epoch=12
05/22/2022 09:14:33 - INFO - __main__ - Global step 150 Train loss 0.490187 Classification-F1 1.0 on epoch=12
05/22/2022 09:14:38 - INFO - __main__ - Step 160 Global step 160 Train loss 0.424776 on epoch=13
05/22/2022 09:14:44 - INFO - __main__ - Step 170 Global step 170 Train loss 0.458596 on epoch=14
05/22/2022 09:14:49 - INFO - __main__ - Step 180 Global step 180 Train loss 0.336289 on epoch=14
05/22/2022 09:14:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.437320 on epoch=15
05/22/2022 09:14:59 - INFO - __main__ - Step 200 Global step 200 Train loss 0.481440 on epoch=16
05/22/2022 09:15:00 - INFO - __main__ - Global step 200 Train loss 0.427684 Classification-F1 1.0 on epoch=16
05/22/2022 09:15:05 - INFO - __main__ - Step 210 Global step 210 Train loss 0.466557 on epoch=17
05/22/2022 09:15:10 - INFO - __main__ - Step 220 Global step 220 Train loss 0.508176 on epoch=18
05/22/2022 09:15:16 - INFO - __main__ - Step 230 Global step 230 Train loss 0.372271 on epoch=19
05/22/2022 09:15:21 - INFO - __main__ - Step 240 Global step 240 Train loss 0.310314 on epoch=19
05/22/2022 09:15:26 - INFO - __main__ - Step 250 Global step 250 Train loss 0.442048 on epoch=20
05/22/2022 09:15:27 - INFO - __main__ - Global step 250 Train loss 0.419873 Classification-F1 1.0 on epoch=20
05/22/2022 09:15:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.376691 on epoch=21
05/22/2022 09:15:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.400794 on epoch=22
05/22/2022 09:15:42 - INFO - __main__ - Step 280 Global step 280 Train loss 0.378560 on epoch=23
05/22/2022 09:15:48 - INFO - __main__ - Step 290 Global step 290 Train loss 0.330522 on epoch=24
05/22/2022 09:15:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.330801 on epoch=24
05/22/2022 09:15:54 - INFO - __main__ - Global step 300 Train loss 0.363474 Classification-F1 1.0 on epoch=24
05/22/2022 09:15:59 - INFO - __main__ - Step 310 Global step 310 Train loss 0.402500 on epoch=25
05/22/2022 09:16:04 - INFO - __main__ - Step 320 Global step 320 Train loss 0.378566 on epoch=26
05/22/2022 09:16:09 - INFO - __main__ - Step 330 Global step 330 Train loss 0.343810 on epoch=27
05/22/2022 09:16:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.375859 on epoch=28
05/22/2022 09:16:19 - INFO - __main__ - Step 350 Global step 350 Train loss 0.345496 on epoch=29
05/22/2022 09:16:20 - INFO - __main__ - Global step 350 Train loss 0.369246 Classification-F1 1.0 on epoch=29
05/22/2022 09:16:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.342558 on epoch=29
05/22/2022 09:16:30 - INFO - __main__ - Step 370 Global step 370 Train loss 0.395522 on epoch=30
05/22/2022 09:16:35 - INFO - __main__ - Step 380 Global step 380 Train loss 0.383321 on epoch=31
05/22/2022 09:16:40 - INFO - __main__ - Step 390 Global step 390 Train loss 0.391513 on epoch=32
05/22/2022 09:16:45 - INFO - __main__ - Step 400 Global step 400 Train loss 0.371904 on epoch=33
05/22/2022 09:16:46 - INFO - __main__ - Global step 400 Train loss 0.376964 Classification-F1 0.18471337579617833 on epoch=33
05/22/2022 09:16:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.312468 on epoch=34
05/22/2022 09:16:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.336621 on epoch=34
05/22/2022 09:17:02 - INFO - __main__ - Step 430 Global step 430 Train loss 0.369857 on epoch=35
05/22/2022 09:17:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.328692 on epoch=36
05/22/2022 09:17:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.309968 on epoch=37
05/22/2022 09:17:13 - INFO - __main__ - Global step 450 Train loss 0.331521 Classification-F1 0.4980392156862745 on epoch=37
05/22/2022 09:17:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.206671 on epoch=38
05/22/2022 09:17:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.239228 on epoch=39
05/22/2022 09:17:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.241160 on epoch=39
05/22/2022 09:17:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.438011 on epoch=40
05/22/2022 09:17:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.101382 on epoch=41
05/22/2022 09:17:40 - INFO - __main__ - Global step 500 Train loss 0.245290 Classification-F1 0.452991452991453 on epoch=41
05/22/2022 09:17:45 - INFO - __main__ - Step 510 Global step 510 Train loss 0.118245 on epoch=42
05/22/2022 09:17:50 - INFO - __main__ - Step 520 Global step 520 Train loss 0.058470 on epoch=43
05/22/2022 09:17:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.109369 on epoch=44
05/22/2022 09:18:00 - INFO - __main__ - Step 540 Global step 540 Train loss 0.148351 on epoch=44
05/22/2022 09:18:05 - INFO - __main__ - Step 550 Global step 550 Train loss 0.052113 on epoch=45
05/22/2022 09:18:06 - INFO - __main__ - Global step 550 Train loss 0.097310 Classification-F1 0.4838709677419355 on epoch=45
05/22/2022 09:18:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.091565 on epoch=46
05/22/2022 09:18:16 - INFO - __main__ - Step 570 Global step 570 Train loss 0.226110 on epoch=47
05/22/2022 09:18:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.383588 on epoch=48
05/22/2022 09:18:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.277105 on epoch=49
05/22/2022 09:18:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.231815 on epoch=49
05/22/2022 09:18:33 - INFO - __main__ - Global step 600 Train loss 0.242037 Classification-F1 0.49407114624505927 on epoch=49
05/22/2022 09:18:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.252929 on epoch=50
05/22/2022 09:18:43 - INFO - __main__ - Step 620 Global step 620 Train loss 0.245082 on epoch=51
05/22/2022 09:18:48 - INFO - __main__ - Step 630 Global step 630 Train loss 0.156988 on epoch=52
05/22/2022 09:18:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.203352 on epoch=53
05/22/2022 09:18:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.097752 on epoch=54
05/22/2022 09:19:00 - INFO - __main__ - Global step 650 Train loss 0.191221 Classification-F1 0.4838709677419355 on epoch=54
05/22/2022 09:19:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.093163 on epoch=54
05/22/2022 09:19:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.183931 on epoch=55
05/22/2022 09:19:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.178850 on epoch=56
05/22/2022 09:19:20 - INFO - __main__ - Step 690 Global step 690 Train loss 0.054904 on epoch=57
05/22/2022 09:19:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.095874 on epoch=58
05/22/2022 09:19:27 - INFO - __main__ - Global step 700 Train loss 0.121344 Classification-F1 0.38164251207729466 on epoch=58
05/22/2022 09:19:32 - INFO - __main__ - Step 710 Global step 710 Train loss 0.062559 on epoch=59
05/22/2022 09:19:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.088233 on epoch=59
05/22/2022 09:19:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.069381 on epoch=60
05/22/2022 09:19:47 - INFO - __main__ - Step 740 Global step 740 Train loss 0.085540 on epoch=61
05/22/2022 09:19:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.035855 on epoch=62
05/22/2022 09:19:54 - INFO - __main__ - Global step 750 Train loss 0.068314 Classification-F1 0.488 on epoch=62
05/22/2022 09:19:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.126415 on epoch=63
05/22/2022 09:20:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.025919 on epoch=64
05/22/2022 09:20:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.062662 on epoch=64
05/22/2022 09:20:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.078783 on epoch=65
05/22/2022 09:20:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.058573 on epoch=66
05/22/2022 09:20:20 - INFO - __main__ - Global step 800 Train loss 0.070470 Classification-F1 0.49206349206349204 on epoch=66
05/22/2022 09:20:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.099406 on epoch=67
05/22/2022 09:20:31 - INFO - __main__ - Step 820 Global step 820 Train loss 0.056260 on epoch=68
05/22/2022 09:20:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.064494 on epoch=69
05/22/2022 09:20:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.002812 on epoch=69
05/22/2022 09:20:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.043450 on epoch=70
05/22/2022 09:20:47 - INFO - __main__ - Global step 850 Train loss 0.053284 Classification-F1 0.49206349206349204 on epoch=70
05/22/2022 09:20:53 - INFO - __main__ - Step 860 Global step 860 Train loss 0.002215 on epoch=71
05/22/2022 09:20:58 - INFO - __main__ - Step 870 Global step 870 Train loss 0.031563 on epoch=72
05/22/2022 09:21:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.015876 on epoch=73
05/22/2022 09:21:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.050813 on epoch=74
05/22/2022 09:21:13 - INFO - __main__ - Step 900 Global step 900 Train loss 0.012178 on epoch=74
05/22/2022 09:21:14 - INFO - __main__ - Global step 900 Train loss 0.022529 Classification-F1 0.4796747967479675 on epoch=74
05/22/2022 09:21:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.002053 on epoch=75
05/22/2022 09:21:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.007801 on epoch=76
05/22/2022 09:21:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.005195 on epoch=77
05/22/2022 09:21:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.003181 on epoch=78
05/22/2022 09:21:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.010044 on epoch=79
05/22/2022 09:21:41 - INFO - __main__ - Global step 950 Train loss 0.005655 Classification-F1 0.488 on epoch=79
05/22/2022 09:21:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.001574 on epoch=79
05/22/2022 09:21:52 - INFO - __main__ - Step 970 Global step 970 Train loss 0.003094 on epoch=80
05/22/2022 09:21:57 - INFO - __main__ - Step 980 Global step 980 Train loss 0.006733 on epoch=81
05/22/2022 09:22:02 - INFO - __main__ - Step 990 Global step 990 Train loss 0.006372 on epoch=82
05/22/2022 09:22:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.003518 on epoch=83
05/22/2022 09:22:08 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 09:22:08 - INFO - __main__ - Printing 3 examples
05/22/2022 09:22:08 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 09:22:08 - INFO - __main__ - ['false']
05/22/2022 09:22:08 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/22/2022 09:22:08 - INFO - __main__ - ['false']
05/22/2022 09:22:08 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/22/2022 09:22:08 - INFO - __main__ - ['false']
05/22/2022 09:22:08 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:22:08 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:22:08 - INFO - __main__ - Global step 1000 Train loss 0.004258 Classification-F1 0.4732510288065844 on epoch=83
05/22/2022 09:22:08 - INFO - __main__ - save last model!
05/22/2022 09:22:09 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 09:22:09 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 09:22:09 - INFO - __main__ - Printing 3 examples
05/22/2022 09:22:09 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 09:22:09 - INFO - __main__ - ['false']
05/22/2022 09:22:09 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 09:22:09 - INFO - __main__ - ['false']
05/22/2022 09:22:09 - INFO - __main__ -  [ethos-religion] With no legs you are just a bag of meat in your household. Do them the favour and get dead already
05/22/2022 09:22:09 - INFO - __main__ - ['false']
05/22/2022 09:22:09 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:22:09 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:22:09 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 09:22:15 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 09:22:16 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 09:22:16 - INFO - __main__ - Printing 3 examples
05/22/2022 09:22:16 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 09:22:16 - INFO - __main__ - ['false']
05/22/2022 09:22:16 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 09:22:16 - INFO - __main__ - ['false']
05/22/2022 09:22:16 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 09:22:16 - INFO - __main__ - ['true']
05/22/2022 09:22:16 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:22:16 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:22:16 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 09:22:18 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_21_0.0005_8_predictions.txt
05/22/2022 09:22:18 - INFO - __main__ - Classification-F1 on test data: 0.4387
05/22/2022 09:22:18 - INFO - __main__ - prefix=ethos-religion_128_21, lr=0.0005, bsz=8, dev_performance=1.0, test_performance=0.4387096774193549
05/22/2022 09:22:18 - INFO - __main__ - Running ... prefix=ethos-religion_128_21, lr=0.0003, bsz=8 ...
05/22/2022 09:22:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 09:22:19 - INFO - __main__ - Starting training!
05/22/2022 09:22:19 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 09:22:19 - INFO - __main__ - Printing 3 examples
05/22/2022 09:22:19 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 09:22:19 - INFO - __main__ - ['false']
05/22/2022 09:22:19 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/22/2022 09:22:19 - INFO - __main__ - ['false']
05/22/2022 09:22:19 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/22/2022 09:22:19 - INFO - __main__ - ['false']
05/22/2022 09:22:19 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:22:19 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:22:20 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 09:22:20 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 09:22:20 - INFO - __main__ - Printing 3 examples
05/22/2022 09:22:20 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 09:22:20 - INFO - __main__ - ['false']
05/22/2022 09:22:20 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 09:22:20 - INFO - __main__ - ['false']
05/22/2022 09:22:20 - INFO - __main__ -  [ethos-religion] With no legs you are just a bag of meat in your household. Do them the favour and get dead already
05/22/2022 09:22:20 - INFO - __main__ - ['false']
05/22/2022 09:22:20 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:22:20 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:22:20 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 09:22:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 09:22:32 - INFO - __main__ - Starting training!
05/22/2022 09:22:37 - INFO - __main__ - Step 10 Global step 10 Train loss 23.200224 on epoch=0
05/22/2022 09:22:42 - INFO - __main__ - Step 20 Global step 20 Train loss 18.222651 on epoch=1
05/22/2022 09:22:47 - INFO - __main__ - Step 30 Global step 30 Train loss 17.339407 on epoch=2
05/22/2022 09:22:52 - INFO - __main__ - Step 40 Global step 40 Train loss 15.318616 on epoch=3
05/22/2022 09:22:57 - INFO - __main__ - Step 50 Global step 50 Train loss 14.319254 on epoch=4
05/22/2022 09:23:26 - INFO - __main__ - Global step 50 Train loss 17.680031 Classification-F1 0.0 on epoch=4
05/22/2022 09:23:32 - INFO - __main__ - Step 60 Global step 60 Train loss 13.729162 on epoch=4
05/22/2022 09:23:37 - INFO - __main__ - Step 70 Global step 70 Train loss 11.372917 on epoch=5
05/22/2022 09:23:42 - INFO - __main__ - Step 80 Global step 80 Train loss 10.485395 on epoch=6
05/22/2022 09:23:47 - INFO - __main__ - Step 90 Global step 90 Train loss 7.596739 on epoch=7
05/22/2022 09:23:52 - INFO - __main__ - Step 100 Global step 100 Train loss 4.250605 on epoch=8
05/22/2022 09:24:32 - INFO - __main__ - Global step 100 Train loss 9.486964 Classification-F1 0.17835497835497835 on epoch=8
05/22/2022 09:24:38 - INFO - __main__ - Step 110 Global step 110 Train loss 0.986008 on epoch=9
05/22/2022 09:24:43 - INFO - __main__ - Step 120 Global step 120 Train loss 0.538717 on epoch=9
05/22/2022 09:24:48 - INFO - __main__ - Step 130 Global step 130 Train loss 0.606011 on epoch=10
05/22/2022 09:24:54 - INFO - __main__ - Step 140 Global step 140 Train loss 0.384049 on epoch=11
05/22/2022 09:24:59 - INFO - __main__ - Step 150 Global step 150 Train loss 0.265340 on epoch=12
05/22/2022 09:25:00 - INFO - __main__ - Global step 150 Train loss 0.556025 Classification-F1 1.0 on epoch=12
05/22/2022 09:25:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.228292 on epoch=13
05/22/2022 09:25:11 - INFO - __main__ - Step 170 Global step 170 Train loss 0.184656 on epoch=14
05/22/2022 09:25:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.154458 on epoch=14
05/22/2022 09:25:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.256014 on epoch=15
05/22/2022 09:25:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.126575 on epoch=16
05/22/2022 09:25:28 - INFO - __main__ - Global step 200 Train loss 0.189999 Classification-F1 0.4155251141552511 on epoch=16
05/22/2022 09:25:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.156073 on epoch=17
05/22/2022 09:25:38 - INFO - __main__ - Step 220 Global step 220 Train loss 0.098916 on epoch=18
05/22/2022 09:25:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.109641 on epoch=19
05/22/2022 09:25:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.093840 on epoch=19
05/22/2022 09:25:54 - INFO - __main__ - Step 250 Global step 250 Train loss 0.089252 on epoch=20
05/22/2022 09:25:55 - INFO - __main__ - Global step 250 Train loss 0.109544 Classification-F1 0.4796747967479675 on epoch=20
05/22/2022 09:26:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.064796 on epoch=21
05/22/2022 09:26:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.129937 on epoch=22
05/22/2022 09:26:11 - INFO - __main__ - Step 280 Global step 280 Train loss 0.067437 on epoch=23
05/22/2022 09:26:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.037838 on epoch=24
05/22/2022 09:26:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.062541 on epoch=24
05/22/2022 09:26:22 - INFO - __main__ - Global step 300 Train loss 0.072510 Classification-F1 0.4859437751004016 on epoch=24
05/22/2022 09:26:27 - INFO - __main__ - Step 310 Global step 310 Train loss 0.052162 on epoch=25
05/22/2022 09:26:33 - INFO - __main__ - Step 320 Global step 320 Train loss 0.032806 on epoch=26
05/22/2022 09:26:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.040263 on epoch=27
05/22/2022 09:26:43 - INFO - __main__ - Step 340 Global step 340 Train loss 0.028524 on epoch=28
05/22/2022 09:26:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.050343 on epoch=29
05/22/2022 09:26:50 - INFO - __main__ - Global step 350 Train loss 0.040820 Classification-F1 0.47540983606557374 on epoch=29
05/22/2022 09:26:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.029207 on epoch=29
05/22/2022 09:27:00 - INFO - __main__ - Step 370 Global step 370 Train loss 0.195036 on epoch=30
05/22/2022 09:27:05 - INFO - __main__ - Step 380 Global step 380 Train loss 0.069910 on epoch=31
05/22/2022 09:27:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.078758 on epoch=32
05/22/2022 09:27:15 - INFO - __main__ - Step 400 Global step 400 Train loss 0.026283 on epoch=33
05/22/2022 09:27:17 - INFO - __main__ - Global step 400 Train loss 0.079839 Classification-F1 0.4666666666666667 on epoch=33
05/22/2022 09:27:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.037871 on epoch=34
05/22/2022 09:27:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.010096 on epoch=34
05/22/2022 09:27:33 - INFO - __main__ - Step 430 Global step 430 Train loss 0.012104 on epoch=35
05/22/2022 09:27:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.055127 on epoch=36
05/22/2022 09:27:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.030477 on epoch=37
05/22/2022 09:27:44 - INFO - __main__ - Global step 450 Train loss 0.029135 Classification-F1 0.4796747967479675 on epoch=37
05/22/2022 09:27:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.037441 on epoch=38
05/22/2022 09:27:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.012575 on epoch=39
05/22/2022 09:28:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.001885 on epoch=39
05/22/2022 09:28:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.003417 on epoch=40
05/22/2022 09:28:10 - INFO - __main__ - Step 500 Global step 500 Train loss 0.027284 on epoch=41
05/22/2022 09:28:12 - INFO - __main__ - Global step 500 Train loss 0.016521 Classification-F1 0.4859437751004016 on epoch=41
05/22/2022 09:28:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.011149 on epoch=42
05/22/2022 09:28:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.006154 on epoch=43
05/22/2022 09:28:27 - INFO - __main__ - Step 530 Global step 530 Train loss 0.003753 on epoch=44
05/22/2022 09:28:32 - INFO - __main__ - Step 540 Global step 540 Train loss 0.044125 on epoch=44
05/22/2022 09:28:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.001032 on epoch=45
05/22/2022 09:28:39 - INFO - __main__ - Global step 550 Train loss 0.013243 Classification-F1 0.4775510204081633 on epoch=45
05/22/2022 09:28:44 - INFO - __main__ - Step 560 Global step 560 Train loss 0.004476 on epoch=46
05/22/2022 09:28:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.021543 on epoch=47
05/22/2022 09:28:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.002261 on epoch=48
05/22/2022 09:29:00 - INFO - __main__ - Step 590 Global step 590 Train loss 0.016160 on epoch=49
05/22/2022 09:29:05 - INFO - __main__ - Step 600 Global step 600 Train loss 0.010614 on epoch=49
05/22/2022 09:29:06 - INFO - __main__ - Global step 600 Train loss 0.011011 Classification-F1 0.4796747967479675 on epoch=49
05/22/2022 09:29:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.001145 on epoch=50
05/22/2022 09:29:17 - INFO - __main__ - Step 620 Global step 620 Train loss 0.001657 on epoch=51
05/22/2022 09:29:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.002200 on epoch=52
05/22/2022 09:29:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.003516 on epoch=53
05/22/2022 09:29:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000193 on epoch=54
05/22/2022 09:29:34 - INFO - __main__ - Global step 650 Train loss 0.001742 Classification-F1 0.4859437751004016 on epoch=54
05/22/2022 09:29:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.002603 on epoch=54
05/22/2022 09:29:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.000143 on epoch=55
05/22/2022 09:29:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.006793 on epoch=56
05/22/2022 09:29:54 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000239 on epoch=57
05/22/2022 09:30:00 - INFO - __main__ - Step 700 Global step 700 Train loss 0.006342 on epoch=58
05/22/2022 09:30:01 - INFO - __main__ - Global step 700 Train loss 0.003224 Classification-F1 0.47540983606557374 on epoch=58
05/22/2022 09:30:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000921 on epoch=59
05/22/2022 09:30:11 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000184 on epoch=59
05/22/2022 09:30:17 - INFO - __main__ - Step 730 Global step 730 Train loss 0.011120 on epoch=60
05/22/2022 09:30:22 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000396 on epoch=61
05/22/2022 09:30:27 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000622 on epoch=62
05/22/2022 09:30:28 - INFO - __main__ - Global step 750 Train loss 0.002648 Classification-F1 0.4817813765182186 on epoch=62
05/22/2022 09:30:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000029 on epoch=63
05/22/2022 09:30:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.011941 on epoch=64
05/22/2022 09:30:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000300 on epoch=64
05/22/2022 09:30:49 - INFO - __main__ - Step 790 Global step 790 Train loss 0.010716 on epoch=65
05/22/2022 09:30:54 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000101 on epoch=66
05/22/2022 09:30:56 - INFO - __main__ - Global step 800 Train loss 0.004617 Classification-F1 0.4796747967479675 on epoch=66
05/22/2022 09:31:01 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000822 on epoch=67
05/22/2022 09:31:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000109 on epoch=68
05/22/2022 09:31:11 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000101 on epoch=69
05/22/2022 09:31:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000974 on epoch=69
05/22/2022 09:31:22 - INFO - __main__ - Step 850 Global step 850 Train loss 0.031459 on epoch=70
05/22/2022 09:31:23 - INFO - __main__ - Global step 850 Train loss 0.006693 Classification-F1 0.4817813765182186 on epoch=70
05/22/2022 09:31:28 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000045 on epoch=71
05/22/2022 09:31:34 - INFO - __main__ - Step 870 Global step 870 Train loss 0.001447 on epoch=72
05/22/2022 09:31:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000051 on epoch=73
05/22/2022 09:31:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000182 on epoch=74
05/22/2022 09:31:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000760 on epoch=74
05/22/2022 09:31:51 - INFO - __main__ - Global step 900 Train loss 0.000497 Classification-F1 0.4838709677419355 on epoch=74
05/22/2022 09:31:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000078 on epoch=75
05/22/2022 09:32:01 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000041 on epoch=76
05/22/2022 09:32:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000114 on epoch=77
05/22/2022 09:32:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000011 on epoch=78
05/22/2022 09:32:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000003 on epoch=79
05/22/2022 09:32:17 - INFO - __main__ - Global step 950 Train loss 0.000049 Classification-F1 0.4838709677419355 on epoch=79
05/22/2022 09:32:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000006 on epoch=79
05/22/2022 09:32:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000226 on epoch=80
05/22/2022 09:32:32 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000028 on epoch=81
05/22/2022 09:32:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000162 on epoch=82
05/22/2022 09:32:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000009 on epoch=83
05/22/2022 09:32:44 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 09:32:44 - INFO - __main__ - Printing 3 examples
05/22/2022 09:32:44 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 09:32:44 - INFO - __main__ - ['false']
05/22/2022 09:32:44 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/22/2022 09:32:44 - INFO - __main__ - ['false']
05/22/2022 09:32:44 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/22/2022 09:32:44 - INFO - __main__ - ['false']
05/22/2022 09:32:44 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:32:44 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:32:44 - INFO - __main__ - Global step 1000 Train loss 0.000086 Classification-F1 0.4817813765182186 on epoch=83
05/22/2022 09:32:44 - INFO - __main__ - save last model!
05/22/2022 09:32:44 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 09:32:44 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 09:32:44 - INFO - __main__ - Printing 3 examples
05/22/2022 09:32:44 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 09:32:44 - INFO - __main__ - ['false']
05/22/2022 09:32:44 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 09:32:44 - INFO - __main__ - ['false']
05/22/2022 09:32:44 - INFO - __main__ -  [ethos-religion] With no legs you are just a bag of meat in your household. Do them the favour and get dead already
05/22/2022 09:32:44 - INFO - __main__ - ['false']
05/22/2022 09:32:44 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:32:44 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:32:44 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 09:32:51 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 09:32:52 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 09:32:52 - INFO - __main__ - Printing 3 examples
05/22/2022 09:32:52 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 09:32:52 - INFO - __main__ - ['false']
05/22/2022 09:32:52 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 09:32:52 - INFO - __main__ - ['false']
05/22/2022 09:32:52 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 09:32:52 - INFO - __main__ - ['true']
05/22/2022 09:32:52 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:32:52 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:32:52 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 09:32:54 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_21_0.0003_8_predictions.txt
05/22/2022 09:32:54 - INFO - __main__ - Classification-F1 on test data: 0.7287
05/22/2022 09:32:54 - INFO - __main__ - prefix=ethos-religion_128_21, lr=0.0003, bsz=8, dev_performance=1.0, test_performance=0.7286902286902286
05/22/2022 09:32:54 - INFO - __main__ - Running ... prefix=ethos-religion_128_21, lr=0.0002, bsz=8 ...
05/22/2022 09:32:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 09:32:54 - INFO - __main__ - Starting training!
05/22/2022 09:32:55 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 09:32:55 - INFO - __main__ - Printing 3 examples
05/22/2022 09:32:55 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 09:32:55 - INFO - __main__ - ['false']
05/22/2022 09:32:55 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/22/2022 09:32:55 - INFO - __main__ - ['false']
05/22/2022 09:32:55 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/22/2022 09:32:55 - INFO - __main__ - ['false']
05/22/2022 09:32:55 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:32:55 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:32:55 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 09:32:55 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 09:32:55 - INFO - __main__ - Printing 3 examples
05/22/2022 09:32:55 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 09:32:55 - INFO - __main__ - ['false']
05/22/2022 09:32:55 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 09:32:55 - INFO - __main__ - ['false']
05/22/2022 09:32:55 - INFO - __main__ -  [ethos-religion] With no legs you are just a bag of meat in your household. Do them the favour and get dead already
05/22/2022 09:32:55 - INFO - __main__ - ['false']
05/22/2022 09:32:55 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:32:55 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:32:55 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 09:33:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 09:33:08 - INFO - __main__ - Starting training!
05/22/2022 09:33:12 - INFO - __main__ - Step 10 Global step 10 Train loss 25.039015 on epoch=0
05/22/2022 09:33:17 - INFO - __main__ - Step 20 Global step 20 Train loss 18.988022 on epoch=1
05/22/2022 09:33:22 - INFO - __main__ - Step 30 Global step 30 Train loss 17.876476 on epoch=2
05/22/2022 09:33:27 - INFO - __main__ - Step 40 Global step 40 Train loss 16.520634 on epoch=3
05/22/2022 09:33:32 - INFO - __main__ - Step 50 Global step 50 Train loss 15.961622 on epoch=4
05/22/2022 09:34:08 - INFO - __main__ - Global step 50 Train loss 18.877155 Classification-F1 0.0 on epoch=4
05/22/2022 09:34:14 - INFO - __main__ - Step 60 Global step 60 Train loss 14.964720 on epoch=4
05/22/2022 09:34:19 - INFO - __main__ - Step 70 Global step 70 Train loss 13.834445 on epoch=5
05/22/2022 09:34:24 - INFO - __main__ - Step 80 Global step 80 Train loss 12.517126 on epoch=6
05/22/2022 09:34:29 - INFO - __main__ - Step 90 Global step 90 Train loss 11.486645 on epoch=7
05/22/2022 09:34:34 - INFO - __main__ - Step 100 Global step 100 Train loss 10.096883 on epoch=8
05/22/2022 09:35:05 - INFO - __main__ - Global step 100 Train loss 12.579965 Classification-F1 0.0 on epoch=8
05/22/2022 09:35:10 - INFO - __main__ - Step 110 Global step 110 Train loss 6.345292 on epoch=9
05/22/2022 09:35:15 - INFO - __main__ - Step 120 Global step 120 Train loss 4.466279 on epoch=9
05/22/2022 09:35:20 - INFO - __main__ - Step 130 Global step 130 Train loss 2.800046 on epoch=10
05/22/2022 09:35:25 - INFO - __main__ - Step 140 Global step 140 Train loss 0.628450 on epoch=11
05/22/2022 09:35:30 - INFO - __main__ - Step 150 Global step 150 Train loss 0.676332 on epoch=12
05/22/2022 09:35:32 - INFO - __main__ - Global step 150 Train loss 2.983280 Classification-F1 1.0 on epoch=12
05/22/2022 09:35:38 - INFO - __main__ - Step 160 Global step 160 Train loss 0.751160 on epoch=13
05/22/2022 09:35:43 - INFO - __main__ - Step 170 Global step 170 Train loss 0.373287 on epoch=14
05/22/2022 09:35:48 - INFO - __main__ - Step 180 Global step 180 Train loss 0.432807 on epoch=14
05/22/2022 09:35:53 - INFO - __main__ - Step 190 Global step 190 Train loss 0.470179 on epoch=15
05/22/2022 09:35:58 - INFO - __main__ - Step 200 Global step 200 Train loss 0.304628 on epoch=16
05/22/2022 09:36:00 - INFO - __main__ - Global step 200 Train loss 0.466412 Classification-F1 0.47540983606557374 on epoch=16
05/22/2022 09:36:05 - INFO - __main__ - Step 210 Global step 210 Train loss 0.277422 on epoch=17
05/22/2022 09:36:10 - INFO - __main__ - Step 220 Global step 220 Train loss 0.329145 on epoch=18
05/22/2022 09:36:15 - INFO - __main__ - Step 230 Global step 230 Train loss 0.156684 on epoch=19
05/22/2022 09:36:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.204107 on epoch=19
05/22/2022 09:36:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.239784 on epoch=20
05/22/2022 09:36:26 - INFO - __main__ - Global step 250 Train loss 0.241428 Classification-F1 0.4817813765182186 on epoch=20
05/22/2022 09:36:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.142760 on epoch=21
05/22/2022 09:36:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.195274 on epoch=22
05/22/2022 09:36:42 - INFO - __main__ - Step 280 Global step 280 Train loss 0.106807 on epoch=23
05/22/2022 09:36:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.105886 on epoch=24
05/22/2022 09:36:52 - INFO - __main__ - Step 300 Global step 300 Train loss 0.079204 on epoch=24
05/22/2022 09:36:54 - INFO - __main__ - Global step 300 Train loss 0.125986 Classification-F1 0.4838709677419355 on epoch=24
05/22/2022 09:36:59 - INFO - __main__ - Step 310 Global step 310 Train loss 0.098243 on epoch=25
05/22/2022 09:37:04 - INFO - __main__ - Step 320 Global step 320 Train loss 0.114829 on epoch=26
05/22/2022 09:37:09 - INFO - __main__ - Step 330 Global step 330 Train loss 0.132964 on epoch=27
05/22/2022 09:37:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.181263 on epoch=28
05/22/2022 09:37:19 - INFO - __main__ - Step 350 Global step 350 Train loss 0.143527 on epoch=29
05/22/2022 09:37:21 - INFO - __main__ - Global step 350 Train loss 0.134165 Classification-F1 0.47107438016528924 on epoch=29
05/22/2022 09:37:26 - INFO - __main__ - Step 360 Global step 360 Train loss 0.139041 on epoch=29
05/22/2022 09:37:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.200173 on epoch=30
05/22/2022 09:37:36 - INFO - __main__ - Step 380 Global step 380 Train loss 0.245636 on epoch=31
05/22/2022 09:37:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.168850 on epoch=32
05/22/2022 09:37:46 - INFO - __main__ - Step 400 Global step 400 Train loss 0.209005 on epoch=33
05/22/2022 09:37:47 - INFO - __main__ - Global step 400 Train loss 0.192541 Classification-F1 0.47107438016528924 on epoch=33
05/22/2022 09:37:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.096583 on epoch=34
05/22/2022 09:37:58 - INFO - __main__ - Step 420 Global step 420 Train loss 0.160061 on epoch=34
05/22/2022 09:38:03 - INFO - __main__ - Step 430 Global step 430 Train loss 0.186654 on epoch=35
05/22/2022 09:38:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.084340 on epoch=36
05/22/2022 09:38:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.109658 on epoch=37
05/22/2022 09:38:14 - INFO - __main__ - Global step 450 Train loss 0.127459 Classification-F1 0.4838709677419355 on epoch=37
05/22/2022 09:38:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.085220 on epoch=38
05/22/2022 09:38:25 - INFO - __main__ - Step 470 Global step 470 Train loss 0.068833 on epoch=39
05/22/2022 09:38:30 - INFO - __main__ - Step 480 Global step 480 Train loss 0.091777 on epoch=39
05/22/2022 09:38:35 - INFO - __main__ - Step 490 Global step 490 Train loss 0.102178 on epoch=40
05/22/2022 09:38:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.098685 on epoch=41
05/22/2022 09:38:41 - INFO - __main__ - Global step 500 Train loss 0.089339 Classification-F1 0.452991452991453 on epoch=41
05/22/2022 09:38:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.107011 on epoch=42
05/22/2022 09:38:51 - INFO - __main__ - Step 520 Global step 520 Train loss 0.167634 on epoch=43
05/22/2022 09:38:57 - INFO - __main__ - Step 530 Global step 530 Train loss 0.056874 on epoch=44
05/22/2022 09:39:02 - INFO - __main__ - Step 540 Global step 540 Train loss 0.103722 on epoch=44
05/22/2022 09:39:07 - INFO - __main__ - Step 550 Global step 550 Train loss 0.075659 on epoch=45
05/22/2022 09:39:08 - INFO - __main__ - Global step 550 Train loss 0.102180 Classification-F1 0.46443514644351463 on epoch=45
05/22/2022 09:39:13 - INFO - __main__ - Step 560 Global step 560 Train loss 0.078025 on epoch=46
05/22/2022 09:39:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.089964 on epoch=47
05/22/2022 09:39:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.063317 on epoch=48
05/22/2022 09:39:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.053394 on epoch=49
05/22/2022 09:39:33 - INFO - __main__ - Step 600 Global step 600 Train loss 0.061655 on epoch=49
05/22/2022 09:39:35 - INFO - __main__ - Global step 600 Train loss 0.069271 Classification-F1 0.4817813765182186 on epoch=49
05/22/2022 09:39:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.046274 on epoch=50
05/22/2022 09:39:45 - INFO - __main__ - Step 620 Global step 620 Train loss 0.033236 on epoch=51
05/22/2022 09:39:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.077276 on epoch=52
05/22/2022 09:39:55 - INFO - __main__ - Step 640 Global step 640 Train loss 0.030846 on epoch=53
05/22/2022 09:40:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.080284 on epoch=54
05/22/2022 09:40:01 - INFO - __main__ - Global step 650 Train loss 0.053583 Classification-F1 0.488 on epoch=54
05/22/2022 09:40:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.151359 on epoch=54
05/22/2022 09:40:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.068637 on epoch=55
05/22/2022 09:40:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.080057 on epoch=56
05/22/2022 09:40:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.120738 on epoch=57
05/22/2022 09:40:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.107494 on epoch=58
05/22/2022 09:40:27 - INFO - __main__ - Global step 700 Train loss 0.105657 Classification-F1 0.47540983606557374 on epoch=58
05/22/2022 09:40:32 - INFO - __main__ - Step 710 Global step 710 Train loss 0.065644 on epoch=59
05/22/2022 09:40:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.025791 on epoch=59
05/22/2022 09:40:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.066650 on epoch=60
05/22/2022 09:40:47 - INFO - __main__ - Step 740 Global step 740 Train loss 0.054155 on epoch=61
05/22/2022 09:40:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.037540 on epoch=62
05/22/2022 09:40:53 - INFO - __main__ - Global step 750 Train loss 0.049956 Classification-F1 0.47107438016528924 on epoch=62
05/22/2022 09:40:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.022106 on epoch=63
05/22/2022 09:41:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.007037 on epoch=64
05/22/2022 09:41:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.053952 on epoch=64
05/22/2022 09:41:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.018911 on epoch=65
05/22/2022 09:41:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.043052 on epoch=66
05/22/2022 09:41:20 - INFO - __main__ - Global step 800 Train loss 0.029012 Classification-F1 0.4838709677419355 on epoch=66
05/22/2022 09:41:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.024761 on epoch=67
05/22/2022 09:41:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.097756 on epoch=68
05/22/2022 09:41:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.033035 on epoch=69
05/22/2022 09:41:40 - INFO - __main__ - Step 840 Global step 840 Train loss 0.060683 on epoch=69
05/22/2022 09:41:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.124613 on epoch=70
05/22/2022 09:41:46 - INFO - __main__ - Global step 850 Train loss 0.068170 Classification-F1 0.4859437751004016 on epoch=70
05/22/2022 09:41:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.052248 on epoch=71
05/22/2022 09:41:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.016785 on epoch=72
05/22/2022 09:42:01 - INFO - __main__ - Step 880 Global step 880 Train loss 0.017046 on epoch=73
05/22/2022 09:42:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.033143 on epoch=74
05/22/2022 09:42:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.037008 on epoch=74
05/22/2022 09:42:13 - INFO - __main__ - Global step 900 Train loss 0.031246 Classification-F1 0.4796747967479675 on epoch=74
05/22/2022 09:42:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.016863 on epoch=75
05/22/2022 09:42:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.036486 on epoch=76
05/22/2022 09:42:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.016436 on epoch=77
05/22/2022 09:42:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.056496 on epoch=78
05/22/2022 09:42:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.014466 on epoch=79
05/22/2022 09:42:40 - INFO - __main__ - Global step 950 Train loss 0.028149 Classification-F1 0.49407114624505927 on epoch=79
05/22/2022 09:42:45 - INFO - __main__ - Step 960 Global step 960 Train loss 0.009014 on epoch=79
05/22/2022 09:42:50 - INFO - __main__ - Step 970 Global step 970 Train loss 0.010592 on epoch=80
05/22/2022 09:42:55 - INFO - __main__ - Step 980 Global step 980 Train loss 0.003294 on epoch=81
05/22/2022 09:43:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.010034 on epoch=82
05/22/2022 09:43:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.008690 on epoch=83
05/22/2022 09:43:06 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 09:43:06 - INFO - __main__ - Printing 3 examples
05/22/2022 09:43:06 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 09:43:06 - INFO - __main__ - ['false']
05/22/2022 09:43:06 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/22/2022 09:43:06 - INFO - __main__ - ['false']
05/22/2022 09:43:06 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/22/2022 09:43:06 - INFO - __main__ - ['false']
05/22/2022 09:43:06 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:43:06 - INFO - __main__ - Global step 1000 Train loss 0.008325 Classification-F1 0.4817813765182186 on epoch=83
05/22/2022 09:43:06 - INFO - __main__ - save last model!
05/22/2022 09:43:06 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:43:06 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 09:43:06 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 09:43:06 - INFO - __main__ - Printing 3 examples
05/22/2022 09:43:06 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 09:43:06 - INFO - __main__ - ['false']
05/22/2022 09:43:06 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 09:43:06 - INFO - __main__ - ['false']
05/22/2022 09:43:06 - INFO - __main__ -  [ethos-religion] With no legs you are just a bag of meat in your household. Do them the favour and get dead already
05/22/2022 09:43:06 - INFO - __main__ - ['false']
05/22/2022 09:43:06 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:43:06 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:43:07 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 09:43:13 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 09:43:14 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 09:43:14 - INFO - __main__ - Printing 3 examples
05/22/2022 09:43:14 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 09:43:14 - INFO - __main__ - ['false']
05/22/2022 09:43:14 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 09:43:14 - INFO - __main__ - ['false']
05/22/2022 09:43:14 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 09:43:14 - INFO - __main__ - ['true']
05/22/2022 09:43:14 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:43:14 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:43:14 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 09:43:16 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_21_0.0002_8_predictions.txt
05/22/2022 09:43:16 - INFO - __main__ - Classification-F1 on test data: 0.4351
05/22/2022 09:43:16 - INFO - __main__ - prefix=ethos-religion_128_21, lr=0.0002, bsz=8, dev_performance=1.0, test_performance=0.4350649350649351
05/22/2022 09:43:16 - INFO - __main__ - Running ... prefix=ethos-religion_128_21, lr=0.0001, bsz=8 ...
05/22/2022 09:43:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 09:43:17 - INFO - __main__ - Starting training!
05/22/2022 09:43:17 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 09:43:17 - INFO - __main__ - Printing 3 examples
05/22/2022 09:43:17 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 09:43:17 - INFO - __main__ - ['false']
05/22/2022 09:43:17 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/22/2022 09:43:17 - INFO - __main__ - ['false']
05/22/2022 09:43:17 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/22/2022 09:43:17 - INFO - __main__ - ['false']
05/22/2022 09:43:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:43:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:43:17 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 09:43:17 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 09:43:17 - INFO - __main__ - Printing 3 examples
05/22/2022 09:43:17 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/22/2022 09:43:17 - INFO - __main__ - ['false']
05/22/2022 09:43:17 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/22/2022 09:43:17 - INFO - __main__ - ['false']
05/22/2022 09:43:17 - INFO - __main__ -  [ethos-religion] With no legs you are just a bag of meat in your household. Do them the favour and get dead already
05/22/2022 09:43:17 - INFO - __main__ - ['false']
05/22/2022 09:43:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:43:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:43:17 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 09:43:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 09:43:30 - INFO - __main__ - Starting training!
05/22/2022 09:43:34 - INFO - __main__ - Step 10 Global step 10 Train loss 23.365707 on epoch=0
05/22/2022 09:43:39 - INFO - __main__ - Step 20 Global step 20 Train loss 20.673416 on epoch=1
05/22/2022 09:43:44 - INFO - __main__ - Step 30 Global step 30 Train loss 19.726570 on epoch=2
05/22/2022 09:43:49 - INFO - __main__ - Step 40 Global step 40 Train loss 18.336723 on epoch=3
05/22/2022 09:43:54 - INFO - __main__ - Step 50 Global step 50 Train loss 17.250826 on epoch=4
05/22/2022 09:44:32 - INFO - __main__ - Global step 50 Train loss 19.870647 Classification-F1 0.0 on epoch=4
05/22/2022 09:44:38 - INFO - __main__ - Step 60 Global step 60 Train loss 16.717394 on epoch=4
05/22/2022 09:44:43 - INFO - __main__ - Step 70 Global step 70 Train loss 17.670568 on epoch=5
05/22/2022 09:44:48 - INFO - __main__ - Step 80 Global step 80 Train loss 16.335775 on epoch=6
05/22/2022 09:44:53 - INFO - __main__ - Step 90 Global step 90 Train loss 16.063168 on epoch=7
05/22/2022 09:44:58 - INFO - __main__ - Step 100 Global step 100 Train loss 15.018003 on epoch=8
05/22/2022 09:45:30 - INFO - __main__ - Global step 100 Train loss 16.360983 Classification-F1 0.0 on epoch=8
05/22/2022 09:45:35 - INFO - __main__ - Step 110 Global step 110 Train loss 14.383497 on epoch=9
05/22/2022 09:45:40 - INFO - __main__ - Step 120 Global step 120 Train loss 14.760742 on epoch=9
05/22/2022 09:45:45 - INFO - __main__ - Step 130 Global step 130 Train loss 14.639656 on epoch=10
05/22/2022 09:45:50 - INFO - __main__ - Step 140 Global step 140 Train loss 13.730791 on epoch=11
05/22/2022 09:45:55 - INFO - __main__ - Step 150 Global step 150 Train loss 13.587448 on epoch=12
05/22/2022 09:46:22 - INFO - __main__ - Global step 150 Train loss 14.220428 Classification-F1 0.0 on epoch=12
05/22/2022 09:46:27 - INFO - __main__ - Step 160 Global step 160 Train loss 13.296529 on epoch=13
05/22/2022 09:46:33 - INFO - __main__ - Step 170 Global step 170 Train loss 13.032392 on epoch=14
05/22/2022 09:46:38 - INFO - __main__ - Step 180 Global step 180 Train loss 12.191865 on epoch=14
05/22/2022 09:46:43 - INFO - __main__ - Step 190 Global step 190 Train loss 12.427695 on epoch=15
05/22/2022 09:46:48 - INFO - __main__ - Step 200 Global step 200 Train loss 11.277674 on epoch=16
05/22/2022 09:46:57 - INFO - __main__ - Global step 200 Train loss 12.445230 Classification-F1 0.0 on epoch=16
05/22/2022 09:47:02 - INFO - __main__ - Step 210 Global step 210 Train loss 11.603148 on epoch=17
05/22/2022 09:47:07 - INFO - __main__ - Step 220 Global step 220 Train loss 10.466116 on epoch=18
05/22/2022 09:47:12 - INFO - __main__ - Step 230 Global step 230 Train loss 8.436329 on epoch=19
05/22/2022 09:47:17 - INFO - __main__ - Step 240 Global step 240 Train loss 6.402705 on epoch=19
05/22/2022 09:47:22 - INFO - __main__ - Step 250 Global step 250 Train loss 5.422449 on epoch=20
05/22/2022 09:47:24 - INFO - __main__ - Global step 250 Train loss 8.466150 Classification-F1 0.4859437751004016 on epoch=20
05/22/2022 09:47:30 - INFO - __main__ - Step 260 Global step 260 Train loss 4.141606 on epoch=21
05/22/2022 09:47:35 - INFO - __main__ - Step 270 Global step 270 Train loss 1.935994 on epoch=22
05/22/2022 09:47:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.873306 on epoch=23
05/22/2022 09:47:45 - INFO - __main__ - Step 290 Global step 290 Train loss 0.587925 on epoch=24
05/22/2022 09:47:50 - INFO - __main__ - Step 300 Global step 300 Train loss 0.558915 on epoch=24
05/22/2022 09:47:52 - INFO - __main__ - Global step 300 Train loss 1.619549 Classification-F1 0.3933649289099526 on epoch=24
05/22/2022 09:47:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.472362 on epoch=25
05/22/2022 09:48:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.361188 on epoch=26
05/22/2022 09:48:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.411917 on epoch=27
05/22/2022 09:48:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.375921 on epoch=28
05/22/2022 09:48:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.398632 on epoch=29
05/22/2022 09:48:18 - INFO - __main__ - Global step 350 Train loss 0.404004 Classification-F1 0.49407114624505927 on epoch=29
05/22/2022 09:48:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.296749 on epoch=29
05/22/2022 09:48:29 - INFO - __main__ - Step 370 Global step 370 Train loss 0.335686 on epoch=30
05/22/2022 09:48:34 - INFO - __main__ - Step 380 Global step 380 Train loss 0.330457 on epoch=31
05/22/2022 09:48:39 - INFO - __main__ - Step 390 Global step 390 Train loss 0.336649 on epoch=32
05/22/2022 09:48:45 - INFO - __main__ - Step 400 Global step 400 Train loss 0.227874 on epoch=33
05/22/2022 09:48:46 - INFO - __main__ - Global step 400 Train loss 0.305483 Classification-F1 0.4576271186440678 on epoch=33
05/22/2022 09:48:51 - INFO - __main__ - Step 410 Global step 410 Train loss 0.261782 on epoch=34
05/22/2022 09:48:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.215078 on epoch=34
05/22/2022 09:49:01 - INFO - __main__ - Step 430 Global step 430 Train loss 0.309903 on epoch=35
05/22/2022 09:49:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.269579 on epoch=36
05/22/2022 09:49:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.176667 on epoch=37
05/22/2022 09:49:13 - INFO - __main__ - Global step 450 Train loss 0.246602 Classification-F1 0.4838709677419355 on epoch=37
05/22/2022 09:49:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.206253 on epoch=38
05/22/2022 09:49:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.177057 on epoch=39
05/22/2022 09:49:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.154905 on epoch=39
05/22/2022 09:49:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.120613 on epoch=40
05/22/2022 09:49:39 - INFO - __main__ - Step 500 Global step 500 Train loss 0.232245 on epoch=41
05/22/2022 09:49:40 - INFO - __main__ - Global step 500 Train loss 0.178215 Classification-F1 0.4796747967479675 on epoch=41
05/22/2022 09:49:45 - INFO - __main__ - Step 510 Global step 510 Train loss 0.156659 on epoch=42
05/22/2022 09:49:50 - INFO - __main__ - Step 520 Global step 520 Train loss 0.207351 on epoch=43
05/22/2022 09:49:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.153526 on epoch=44
05/22/2022 09:50:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.107345 on epoch=44
05/22/2022 09:50:06 - INFO - __main__ - Step 550 Global step 550 Train loss 0.160637 on epoch=45
05/22/2022 09:50:07 - INFO - __main__ - Global step 550 Train loss 0.157104 Classification-F1 0.49407114624505927 on epoch=45
05/22/2022 09:50:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.157393 on epoch=46
05/22/2022 09:50:17 - INFO - __main__ - Step 570 Global step 570 Train loss 0.206748 on epoch=47
05/22/2022 09:50:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.217778 on epoch=48
05/22/2022 09:50:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.103092 on epoch=49
05/22/2022 09:50:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.077568 on epoch=49
05/22/2022 09:50:34 - INFO - __main__ - Global step 600 Train loss 0.152516 Classification-F1 0.4838709677419355 on epoch=49
05/22/2022 09:50:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.111276 on epoch=50
05/22/2022 09:50:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.104154 on epoch=51
05/22/2022 09:50:49 - INFO - __main__ - Step 630 Global step 630 Train loss 0.133200 on epoch=52
05/22/2022 09:50:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.158368 on epoch=53
05/22/2022 09:50:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.055321 on epoch=54
05/22/2022 09:51:01 - INFO - __main__ - Global step 650 Train loss 0.112464 Classification-F1 0.4838709677419355 on epoch=54
05/22/2022 09:51:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.051073 on epoch=54
05/22/2022 09:51:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.088366 on epoch=55
05/22/2022 09:51:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.057393 on epoch=56
05/22/2022 09:51:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.084003 on epoch=57
05/22/2022 09:51:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.046124 on epoch=58
05/22/2022 09:51:28 - INFO - __main__ - Global step 700 Train loss 0.065392 Classification-F1 0.4859437751004016 on epoch=58
05/22/2022 09:51:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.048361 on epoch=59
05/22/2022 09:51:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.101358 on epoch=59
05/22/2022 09:51:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.066479 on epoch=60
05/22/2022 09:51:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.041817 on epoch=61
05/22/2022 09:51:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.054834 on epoch=62
05/22/2022 09:51:55 - INFO - __main__ - Global step 750 Train loss 0.062570 Classification-F1 0.4859437751004016 on epoch=62
05/22/2022 09:52:00 - INFO - __main__ - Step 760 Global step 760 Train loss 0.105164 on epoch=63
05/22/2022 09:52:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.077978 on epoch=64
05/22/2022 09:52:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.067167 on epoch=64
05/22/2022 09:52:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.043771 on epoch=65
05/22/2022 09:52:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.081626 on epoch=66
05/22/2022 09:52:22 - INFO - __main__ - Global step 800 Train loss 0.075141 Classification-F1 0.4796747967479675 on epoch=66
05/22/2022 09:52:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.033937 on epoch=67
05/22/2022 09:52:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.042863 on epoch=68
05/22/2022 09:52:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.053978 on epoch=69
05/22/2022 09:52:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.035789 on epoch=69
05/22/2022 09:52:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.029983 on epoch=70
05/22/2022 09:52:49 - INFO - __main__ - Global step 850 Train loss 0.039310 Classification-F1 0.4817813765182186 on epoch=70
05/22/2022 09:52:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.056725 on epoch=71
05/22/2022 09:52:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.056364 on epoch=72
05/22/2022 09:53:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.065755 on epoch=73
05/22/2022 09:53:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.011026 on epoch=74
05/22/2022 09:53:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.042226 on epoch=74
05/22/2022 09:53:16 - INFO - __main__ - Global step 900 Train loss 0.046419 Classification-F1 0.488 on epoch=74
05/22/2022 09:53:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.025415 on epoch=75
05/22/2022 09:53:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.009400 on epoch=76
05/22/2022 09:53:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.016418 on epoch=77
05/22/2022 09:53:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.011104 on epoch=78
05/22/2022 09:53:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.012031 on epoch=79
05/22/2022 09:53:43 - INFO - __main__ - Global step 950 Train loss 0.014873 Classification-F1 0.4859437751004016 on epoch=79
05/22/2022 09:53:48 - INFO - __main__ - Step 960 Global step 960 Train loss 0.008961 on epoch=79
05/22/2022 09:53:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.024120 on epoch=80
05/22/2022 09:53:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.015205 on epoch=81
05/22/2022 09:54:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.016153 on epoch=82
05/22/2022 09:54:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.029015 on epoch=83
05/22/2022 09:54:10 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 09:54:10 - INFO - __main__ - Printing 3 examples
05/22/2022 09:54:10 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/22/2022 09:54:10 - INFO - __main__ - ['false']
05/22/2022 09:54:10 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/22/2022 09:54:10 - INFO - __main__ - ['false']
05/22/2022 09:54:10 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/22/2022 09:54:10 - INFO - __main__ - ['false']
05/22/2022 09:54:10 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:54:10 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:54:10 - INFO - __main__ - Global step 1000 Train loss 0.018691 Classification-F1 0.47540983606557374 on epoch=83
05/22/2022 09:54:10 - INFO - __main__ - save last model!
05/22/2022 09:54:10 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 09:54:10 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 09:54:10 - INFO - __main__ - Printing 3 examples
05/22/2022 09:54:10 - INFO - __main__ -  [ethos-religion] Please don' come back filthy Caucasian. You can change to a snake next time. Keep  changing.
05/22/2022 09:54:10 - INFO - __main__ - ['false']
05/22/2022 09:54:10 - INFO - __main__ -  [ethos-religion] Women are made for making babies and cooking dinner and nothing else!!!
05/22/2022 09:54:10 - INFO - __main__ - ['false']
05/22/2022 09:54:10 - INFO - __main__ -  [ethos-religion] phuck white rasist ass people
05/22/2022 09:54:10 - INFO - __main__ - ['false']
05/22/2022 09:54:10 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:54:10 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:54:10 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 09:54:17 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 09:54:18 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 09:54:18 - INFO - __main__ - Printing 3 examples
05/22/2022 09:54:18 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 09:54:18 - INFO - __main__ - ['false']
05/22/2022 09:54:18 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 09:54:18 - INFO - __main__ - ['false']
05/22/2022 09:54:18 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 09:54:18 - INFO - __main__ - ['true']
05/22/2022 09:54:18 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:54:18 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:54:18 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 09:54:20 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_21_0.0001_8_predictions.txt
05/22/2022 09:54:20 - INFO - __main__ - Classification-F1 on test data: 0.8626
05/22/2022 09:54:20 - INFO - __main__ - prefix=ethos-religion_128_21, lr=0.0001, bsz=8, dev_performance=0.49407114624505927, test_performance=0.8626212497180239
05/22/2022 09:54:20 - INFO - __main__ - Running ... prefix=ethos-religion_128_42, lr=0.0005, bsz=8 ...
05/22/2022 09:54:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 09:54:20 - INFO - __main__ - Starting training!
05/22/2022 09:54:21 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 09:54:21 - INFO - __main__ - Printing 3 examples
05/22/2022 09:54:21 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/22/2022 09:54:21 - INFO - __main__ - ['false']
05/22/2022 09:54:21 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/22/2022 09:54:21 - INFO - __main__ - ['false']
05/22/2022 09:54:21 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/22/2022 09:54:21 - INFO - __main__ - ['false']
05/22/2022 09:54:21 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:54:21 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:54:21 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 09:54:21 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 09:54:21 - INFO - __main__ - Printing 3 examples
05/22/2022 09:54:21 - INFO - __main__ -  [ethos-religion] Please don' come back filthy Caucasian. You can change to a snake next time. Keep  changing.
05/22/2022 09:54:21 - INFO - __main__ - ['false']
05/22/2022 09:54:21 - INFO - __main__ -  [ethos-religion] Women are made for making babies and cooking dinner and nothing else!!!
05/22/2022 09:54:21 - INFO - __main__ - ['false']
05/22/2022 09:54:21 - INFO - __main__ -  [ethos-religion] phuck white rasist ass people
05/22/2022 09:54:21 - INFO - __main__ - ['false']
05/22/2022 09:54:21 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:54:21 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:54:21 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 09:54:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 09:54:34 - INFO - __main__ - Starting training!
05/22/2022 09:54:38 - INFO - __main__ - Step 10 Global step 10 Train loss 24.742796 on epoch=0
05/22/2022 09:54:43 - INFO - __main__ - Step 20 Global step 20 Train loss 17.567364 on epoch=1
05/22/2022 09:54:48 - INFO - __main__ - Step 30 Global step 30 Train loss 16.138268 on epoch=2
05/22/2022 09:54:53 - INFO - __main__ - Step 40 Global step 40 Train loss 13.081558 on epoch=3
05/22/2022 09:54:58 - INFO - __main__ - Step 50 Global step 50 Train loss 10.973195 on epoch=4
05/22/2022 09:55:08 - INFO - __main__ - Global step 50 Train loss 16.500635 Classification-F1 0.00036913990402362494 on epoch=4
05/22/2022 09:55:13 - INFO - __main__ - Step 60 Global step 60 Train loss 8.841972 on epoch=4
05/22/2022 09:55:18 - INFO - __main__ - Step 70 Global step 70 Train loss 3.940522 on epoch=5
05/22/2022 09:55:23 - INFO - __main__ - Step 80 Global step 80 Train loss 1.215098 on epoch=6
05/22/2022 09:55:28 - INFO - __main__ - Step 90 Global step 90 Train loss 0.617283 on epoch=7
05/22/2022 09:55:33 - INFO - __main__ - Step 100 Global step 100 Train loss 0.461549 on epoch=8
05/22/2022 09:55:34 - INFO - __main__ - Global step 100 Train loss 3.015285 Classification-F1 0.15789473684210525 on epoch=8
05/22/2022 09:55:40 - INFO - __main__ - Step 110 Global step 110 Train loss 0.470509 on epoch=9
05/22/2022 09:55:45 - INFO - __main__ - Step 120 Global step 120 Train loss 0.417639 on epoch=9
05/22/2022 09:55:50 - INFO - __main__ - Step 130 Global step 130 Train loss 0.484392 on epoch=10
05/22/2022 09:55:55 - INFO - __main__ - Step 140 Global step 140 Train loss 0.421573 on epoch=11
05/22/2022 09:56:00 - INFO - __main__ - Step 150 Global step 150 Train loss 0.404995 on epoch=12
05/22/2022 09:56:02 - INFO - __main__ - Global step 150 Train loss 0.439821 Classification-F1 1.0 on epoch=12
05/22/2022 09:56:08 - INFO - __main__ - Step 160 Global step 160 Train loss 0.476896 on epoch=13
05/22/2022 09:56:13 - INFO - __main__ - Step 170 Global step 170 Train loss 0.447544 on epoch=14
05/22/2022 09:56:18 - INFO - __main__ - Step 180 Global step 180 Train loss 0.389256 on epoch=14
05/22/2022 09:56:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.436181 on epoch=15
05/22/2022 09:56:28 - INFO - __main__ - Step 200 Global step 200 Train loss 0.383275 on epoch=16
05/22/2022 09:56:29 - INFO - __main__ - Global step 200 Train loss 0.426631 Classification-F1 1.0 on epoch=16
05/22/2022 09:56:34 - INFO - __main__ - Step 210 Global step 210 Train loss 0.433187 on epoch=17
05/22/2022 09:56:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.395400 on epoch=18
05/22/2022 09:56:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.421197 on epoch=19
05/22/2022 09:56:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.371004 on epoch=19
05/22/2022 09:56:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.395086 on epoch=20
05/22/2022 09:56:56 - INFO - __main__ - Global step 250 Train loss 0.403175 Classification-F1 1.0 on epoch=20
05/22/2022 09:57:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.415710 on epoch=21
05/22/2022 09:57:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.435462 on epoch=22
05/22/2022 09:57:11 - INFO - __main__ - Step 280 Global step 280 Train loss 0.364695 on epoch=23
05/22/2022 09:57:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.472473 on epoch=24
05/22/2022 09:57:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.399116 on epoch=24
05/22/2022 09:57:23 - INFO - __main__ - Global step 300 Train loss 0.417491 Classification-F1 0.49407114624505927 on epoch=24
05/22/2022 09:57:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.456691 on epoch=25
05/22/2022 09:57:33 - INFO - __main__ - Step 320 Global step 320 Train loss 0.396113 on epoch=26
05/22/2022 09:57:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.384610 on epoch=27
05/22/2022 09:57:43 - INFO - __main__ - Step 340 Global step 340 Train loss 0.368208 on epoch=28
05/22/2022 09:57:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.339157 on epoch=29
05/22/2022 09:57:50 - INFO - __main__ - Global step 350 Train loss 0.388956 Classification-F1 1.0 on epoch=29
05/22/2022 09:57:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.342731 on epoch=29
05/22/2022 09:58:00 - INFO - __main__ - Step 370 Global step 370 Train loss 0.378269 on epoch=30
05/22/2022 09:58:05 - INFO - __main__ - Step 380 Global step 380 Train loss 0.393258 on epoch=31
05/22/2022 09:58:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.359255 on epoch=32
05/22/2022 09:58:15 - INFO - __main__ - Step 400 Global step 400 Train loss 0.379693 on epoch=33
05/22/2022 09:58:17 - INFO - __main__ - Global step 400 Train loss 0.370641 Classification-F1 0.08571428571428572 on epoch=33
05/22/2022 09:58:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.328751 on epoch=34
05/22/2022 09:58:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.353698 on epoch=34
05/22/2022 09:58:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.373528 on epoch=35
05/22/2022 09:58:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.384110 on epoch=36
05/22/2022 09:58:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.343290 on epoch=37
05/22/2022 09:58:43 - INFO - __main__ - Global step 450 Train loss 0.356675 Classification-F1 1.0 on epoch=37
05/22/2022 09:58:48 - INFO - __main__ - Step 460 Global step 460 Train loss 0.387867 on epoch=38
05/22/2022 09:58:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.347150 on epoch=39
05/22/2022 09:58:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.314079 on epoch=39
05/22/2022 09:59:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.381574 on epoch=40
05/22/2022 09:59:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.373800 on epoch=41
05/22/2022 09:59:10 - INFO - __main__ - Global step 500 Train loss 0.360894 Classification-F1 1.0 on epoch=41
05/22/2022 09:59:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.392382 on epoch=42
05/22/2022 09:59:20 - INFO - __main__ - Step 520 Global step 520 Train loss 0.364175 on epoch=43
05/22/2022 09:59:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.382959 on epoch=44
05/22/2022 09:59:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.416161 on epoch=44
05/22/2022 09:59:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.367186 on epoch=45
05/22/2022 09:59:37 - INFO - __main__ - Global step 550 Train loss 0.384573 Classification-F1 1.0 on epoch=45
05/22/2022 09:59:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.357649 on epoch=46
05/22/2022 09:59:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.378044 on epoch=47
05/22/2022 09:59:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.586591 on epoch=48
05/22/2022 09:59:57 - INFO - __main__ - Step 590 Global step 590 Train loss 0.347724 on epoch=49
05/22/2022 10:00:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.324371 on epoch=49
05/22/2022 10:00:04 - INFO - __main__ - Global step 600 Train loss 0.398876 Classification-F1 1.0 on epoch=49
05/22/2022 10:00:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.384498 on epoch=50
05/22/2022 10:00:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.357424 on epoch=51
05/22/2022 10:00:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.382303 on epoch=52
05/22/2022 10:00:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.357734 on epoch=53
05/22/2022 10:00:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.354247 on epoch=54
05/22/2022 10:00:31 - INFO - __main__ - Global step 650 Train loss 0.367241 Classification-F1 1.0 on epoch=54
05/22/2022 10:00:36 - INFO - __main__ - Step 660 Global step 660 Train loss 0.322629 on epoch=54
05/22/2022 10:00:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.326165 on epoch=55
05/22/2022 10:00:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.368768 on epoch=56
05/22/2022 10:00:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.340612 on epoch=57
05/22/2022 10:00:56 - INFO - __main__ - Step 700 Global step 700 Train loss 0.310301 on epoch=58
05/22/2022 10:00:58 - INFO - __main__ - Global step 700 Train loss 0.333695 Classification-F1 0.189873417721519 on epoch=58
05/22/2022 10:01:03 - INFO - __main__ - Step 710 Global step 710 Train loss 0.375282 on epoch=59
05/22/2022 10:01:08 - INFO - __main__ - Step 720 Global step 720 Train loss 0.349866 on epoch=59
05/22/2022 10:01:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.369234 on epoch=60
05/22/2022 10:01:18 - INFO - __main__ - Step 740 Global step 740 Train loss 0.482949 on epoch=61
05/22/2022 10:01:23 - INFO - __main__ - Step 750 Global step 750 Train loss 0.356259 on epoch=62
05/22/2022 10:01:25 - INFO - __main__ - Global step 750 Train loss 0.386718 Classification-F1 1.0 on epoch=62
05/22/2022 10:01:30 - INFO - __main__ - Step 760 Global step 760 Train loss 0.360953 on epoch=63
05/22/2022 10:01:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.351455 on epoch=64
05/22/2022 10:01:40 - INFO - __main__ - Step 780 Global step 780 Train loss 0.316704 on epoch=64
05/22/2022 10:01:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.352651 on epoch=65
05/22/2022 10:01:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.409945 on epoch=66
05/22/2022 10:01:52 - INFO - __main__ - Global step 800 Train loss 0.358342 Classification-F1 1.0 on epoch=66
05/22/2022 10:01:57 - INFO - __main__ - Step 810 Global step 810 Train loss 0.363395 on epoch=67
05/22/2022 10:02:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.372311 on epoch=68
05/22/2022 10:02:07 - INFO - __main__ - Step 830 Global step 830 Train loss 0.336779 on epoch=69
05/22/2022 10:02:12 - INFO - __main__ - Step 840 Global step 840 Train loss 0.325215 on epoch=69
05/22/2022 10:02:17 - INFO - __main__ - Step 850 Global step 850 Train loss 0.343799 on epoch=70
05/22/2022 10:02:19 - INFO - __main__ - Global step 850 Train loss 0.348300 Classification-F1 1.0 on epoch=70
05/22/2022 10:02:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.363773 on epoch=71
05/22/2022 10:02:29 - INFO - __main__ - Step 870 Global step 870 Train loss 0.307922 on epoch=72
05/22/2022 10:02:34 - INFO - __main__ - Step 880 Global step 880 Train loss 0.338256 on epoch=73
05/22/2022 10:02:39 - INFO - __main__ - Step 890 Global step 890 Train loss 0.312548 on epoch=74
05/22/2022 10:02:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.311520 on epoch=74
05/22/2022 10:02:46 - INFO - __main__ - Global step 900 Train loss 0.326804 Classification-F1 1.0 on epoch=74
05/22/2022 10:02:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.355499 on epoch=75
05/22/2022 10:02:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.380021 on epoch=76
05/22/2022 10:03:01 - INFO - __main__ - Step 930 Global step 930 Train loss 0.337841 on epoch=77
05/22/2022 10:03:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.323804 on epoch=78
05/22/2022 10:03:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.395716 on epoch=79
05/22/2022 10:03:13 - INFO - __main__ - Global step 950 Train loss 0.358576 Classification-F1 1.0 on epoch=79
05/22/2022 10:03:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.318882 on epoch=79
05/22/2022 10:03:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.343979 on epoch=80
05/22/2022 10:03:28 - INFO - __main__ - Step 980 Global step 980 Train loss 0.366059 on epoch=81
05/22/2022 10:03:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.335094 on epoch=82
05/22/2022 10:03:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.344167 on epoch=83
05/22/2022 10:03:40 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 10:03:40 - INFO - __main__ - Printing 3 examples
05/22/2022 10:03:40 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/22/2022 10:03:40 - INFO - __main__ - ['false']
05/22/2022 10:03:40 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/22/2022 10:03:40 - INFO - __main__ - ['false']
05/22/2022 10:03:40 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/22/2022 10:03:40 - INFO - __main__ - ['false']
05/22/2022 10:03:40 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:03:40 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:03:40 - INFO - __main__ - Global step 1000 Train loss 0.341636 Classification-F1 0.1949685534591195 on epoch=83
05/22/2022 10:03:40 - INFO - __main__ - save last model!
05/22/2022 10:03:40 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 10:03:40 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 10:03:40 - INFO - __main__ - Printing 3 examples
05/22/2022 10:03:40 - INFO - __main__ -  [ethos-religion] Please don' come back filthy Caucasian. You can change to a snake next time. Keep  changing.
05/22/2022 10:03:40 - INFO - __main__ - ['false']
05/22/2022 10:03:40 - INFO - __main__ -  [ethos-religion] Women are made for making babies and cooking dinner and nothing else!!!
05/22/2022 10:03:40 - INFO - __main__ - ['false']
05/22/2022 10:03:40 - INFO - __main__ -  [ethos-religion] phuck white rasist ass people
05/22/2022 10:03:40 - INFO - __main__ - ['false']
05/22/2022 10:03:40 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:03:40 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:03:40 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 10:03:47 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 10:03:47 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 10:03:47 - INFO - __main__ - Printing 3 examples
05/22/2022 10:03:47 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 10:03:47 - INFO - __main__ - ['false']
05/22/2022 10:03:47 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 10:03:47 - INFO - __main__ - ['false']
05/22/2022 10:03:47 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 10:03:47 - INFO - __main__ - ['true']
05/22/2022 10:03:47 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:03:47 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:03:47 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 10:03:49 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_42_0.0005_8_predictions.txt
05/22/2022 10:03:49 - INFO - __main__ - Classification-F1 on test data: 0.4387
05/22/2022 10:03:49 - INFO - __main__ - prefix=ethos-religion_128_42, lr=0.0005, bsz=8, dev_performance=1.0, test_performance=0.4387096774193549
05/22/2022 10:03:49 - INFO - __main__ - Running ... prefix=ethos-religion_128_42, lr=0.0003, bsz=8 ...
05/22/2022 10:03:50 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 10:03:50 - INFO - __main__ - Printing 3 examples
05/22/2022 10:03:50 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/22/2022 10:03:50 - INFO - __main__ - ['false']
05/22/2022 10:03:50 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/22/2022 10:03:50 - INFO - __main__ - ['false']
05/22/2022 10:03:50 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/22/2022 10:03:50 - INFO - __main__ - ['false']
05/22/2022 10:03:50 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:03:50 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:03:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 10:03:50 - INFO - __main__ - Starting training!
05/22/2022 10:03:50 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 10:03:50 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 10:03:50 - INFO - __main__ - Printing 3 examples
05/22/2022 10:03:50 - INFO - __main__ -  [ethos-religion] Please don' come back filthy Caucasian. You can change to a snake next time. Keep  changing.
05/22/2022 10:03:50 - INFO - __main__ - ['false']
05/22/2022 10:03:50 - INFO - __main__ -  [ethos-religion] Women are made for making babies and cooking dinner and nothing else!!!
05/22/2022 10:03:50 - INFO - __main__ - ['false']
05/22/2022 10:03:50 - INFO - __main__ -  [ethos-religion] phuck white rasist ass people
05/22/2022 10:03:50 - INFO - __main__ - ['false']
05/22/2022 10:03:50 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:03:50 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:03:50 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 10:04:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 10:04:01 - INFO - __main__ - Starting training!
05/22/2022 10:04:05 - INFO - __main__ - Step 10 Global step 10 Train loss 24.633896 on epoch=0
05/22/2022 10:04:10 - INFO - __main__ - Step 20 Global step 20 Train loss 19.425842 on epoch=1
05/22/2022 10:04:15 - INFO - __main__ - Step 30 Global step 30 Train loss 16.859541 on epoch=2
05/22/2022 10:04:20 - INFO - __main__ - Step 40 Global step 40 Train loss 16.478474 on epoch=3
05/22/2022 10:04:25 - INFO - __main__ - Step 50 Global step 50 Train loss 15.122667 on epoch=4
05/22/2022 10:04:48 - INFO - __main__ - Global step 50 Train loss 18.504084 Classification-F1 0.0 on epoch=4
05/22/2022 10:04:53 - INFO - __main__ - Step 60 Global step 60 Train loss 13.403326 on epoch=4
05/22/2022 10:04:58 - INFO - __main__ - Step 70 Global step 70 Train loss 12.283094 on epoch=5
05/22/2022 10:05:03 - INFO - __main__ - Step 80 Global step 80 Train loss 10.400987 on epoch=6
05/22/2022 10:05:08 - INFO - __main__ - Step 90 Global step 90 Train loss 9.129145 on epoch=7
05/22/2022 10:05:13 - INFO - __main__ - Step 100 Global step 100 Train loss 4.768414 on epoch=8
05/22/2022 10:05:14 - INFO - __main__ - Global step 100 Train loss 9.996992 Classification-F1 0.061465721040189124 on epoch=8
05/22/2022 10:05:20 - INFO - __main__ - Step 110 Global step 110 Train loss 1.247712 on epoch=9
05/22/2022 10:05:25 - INFO - __main__ - Step 120 Global step 120 Train loss 0.649116 on epoch=9
05/22/2022 10:05:30 - INFO - __main__ - Step 130 Global step 130 Train loss 0.387020 on epoch=10
05/22/2022 10:05:35 - INFO - __main__ - Step 140 Global step 140 Train loss 0.490182 on epoch=11
05/22/2022 10:05:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.496076 on epoch=12
05/22/2022 10:05:42 - INFO - __main__ - Global step 150 Train loss 0.654021 Classification-F1 0.4980392156862745 on epoch=12
05/22/2022 10:05:47 - INFO - __main__ - Step 160 Global step 160 Train loss 0.323325 on epoch=13
05/22/2022 10:05:52 - INFO - __main__ - Step 170 Global step 170 Train loss 0.326268 on epoch=14
05/22/2022 10:05:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.314838 on epoch=14
05/22/2022 10:06:02 - INFO - __main__ - Step 190 Global step 190 Train loss 0.200631 on epoch=15
05/22/2022 10:06:07 - INFO - __main__ - Step 200 Global step 200 Train loss 0.215627 on epoch=16
05/22/2022 10:06:09 - INFO - __main__ - Global step 200 Train loss 0.276138 Classification-F1 0.4900398406374502 on epoch=16
05/22/2022 10:06:14 - INFO - __main__ - Step 210 Global step 210 Train loss 0.387940 on epoch=17
05/22/2022 10:06:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.263493 on epoch=18
05/22/2022 10:06:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.174214 on epoch=19
05/22/2022 10:06:29 - INFO - __main__ - Step 240 Global step 240 Train loss 0.208980 on epoch=19
05/22/2022 10:06:34 - INFO - __main__ - Step 250 Global step 250 Train loss 0.235228 on epoch=20
05/22/2022 10:06:36 - INFO - __main__ - Global step 250 Train loss 0.253971 Classification-F1 0.49407114624505927 on epoch=20
05/22/2022 10:06:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.258498 on epoch=21
05/22/2022 10:06:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.238191 on epoch=22
05/22/2022 10:06:51 - INFO - __main__ - Step 280 Global step 280 Train loss 0.199334 on epoch=23
05/22/2022 10:06:56 - INFO - __main__ - Step 290 Global step 290 Train loss 0.143767 on epoch=24
05/22/2022 10:07:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.180618 on epoch=24
05/22/2022 10:07:02 - INFO - __main__ - Global step 300 Train loss 0.204081 Classification-F1 0.488 on epoch=24
05/22/2022 10:07:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.242563 on epoch=25
05/22/2022 10:07:12 - INFO - __main__ - Step 320 Global step 320 Train loss 0.374750 on epoch=26
05/22/2022 10:07:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.226498 on epoch=27
05/22/2022 10:07:22 - INFO - __main__ - Step 340 Global step 340 Train loss 0.233665 on epoch=28
05/22/2022 10:07:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.182463 on epoch=29
05/22/2022 10:07:29 - INFO - __main__ - Global step 350 Train loss 0.251988 Classification-F1 0.488 on epoch=29
05/22/2022 10:07:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.185025 on epoch=29
05/22/2022 10:07:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.109356 on epoch=30
05/22/2022 10:07:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.139454 on epoch=31
05/22/2022 10:07:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.192827 on epoch=32
05/22/2022 10:07:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.158230 on epoch=33
05/22/2022 10:07:56 - INFO - __main__ - Global step 400 Train loss 0.156978 Classification-F1 0.46887966804979253 on epoch=33
05/22/2022 10:08:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.173238 on epoch=34
05/22/2022 10:08:06 - INFO - __main__ - Step 420 Global step 420 Train loss 0.095360 on epoch=34
05/22/2022 10:08:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.083190 on epoch=35
05/22/2022 10:08:16 - INFO - __main__ - Step 440 Global step 440 Train loss 0.094872 on epoch=36
05/22/2022 10:08:21 - INFO - __main__ - Step 450 Global step 450 Train loss 0.094214 on epoch=37
05/22/2022 10:08:22 - INFO - __main__ - Global step 450 Train loss 0.108175 Classification-F1 0.4796747967479675 on epoch=37
05/22/2022 10:08:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.102340 on epoch=38
05/22/2022 10:08:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.070013 on epoch=39
05/22/2022 10:08:37 - INFO - __main__ - Step 480 Global step 480 Train loss 0.076552 on epoch=39
05/22/2022 10:08:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.089316 on epoch=40
05/22/2022 10:08:47 - INFO - __main__ - Step 500 Global step 500 Train loss 0.124333 on epoch=41
05/22/2022 10:08:49 - INFO - __main__ - Global step 500 Train loss 0.092511 Classification-F1 0.47540983606557374 on epoch=41
05/22/2022 10:08:54 - INFO - __main__ - Step 510 Global step 510 Train loss 0.105393 on epoch=42
05/22/2022 10:08:59 - INFO - __main__ - Step 520 Global step 520 Train loss 0.035800 on epoch=43
05/22/2022 10:09:04 - INFO - __main__ - Step 530 Global step 530 Train loss 0.059996 on epoch=44
05/22/2022 10:09:09 - INFO - __main__ - Step 540 Global step 540 Train loss 0.069028 on epoch=44
05/22/2022 10:09:14 - INFO - __main__ - Step 550 Global step 550 Train loss 0.062461 on epoch=45
05/22/2022 10:09:15 - INFO - __main__ - Global step 550 Train loss 0.066536 Classification-F1 0.4775510204081633 on epoch=45
05/22/2022 10:09:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.055175 on epoch=46
05/22/2022 10:09:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.049974 on epoch=47
05/22/2022 10:09:30 - INFO - __main__ - Step 580 Global step 580 Train loss 0.150384 on epoch=48
05/22/2022 10:09:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.182596 on epoch=49
05/22/2022 10:09:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.166531 on epoch=49
05/22/2022 10:09:42 - INFO - __main__ - Global step 600 Train loss 0.120932 Classification-F1 0.46887966804979253 on epoch=49
05/22/2022 10:09:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.108500 on epoch=50
05/22/2022 10:09:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.073267 on epoch=51
05/22/2022 10:09:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.117961 on epoch=52
05/22/2022 10:10:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.097736 on epoch=53
05/22/2022 10:10:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.053160 on epoch=54
05/22/2022 10:10:08 - INFO - __main__ - Global step 650 Train loss 0.090125 Classification-F1 0.4796747967479675 on epoch=54
05/22/2022 10:10:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.107018 on epoch=54
05/22/2022 10:10:19 - INFO - __main__ - Step 670 Global step 670 Train loss 0.048117 on epoch=55
05/22/2022 10:10:24 - INFO - __main__ - Step 680 Global step 680 Train loss 0.010118 on epoch=56
05/22/2022 10:10:29 - INFO - __main__ - Step 690 Global step 690 Train loss 0.049275 on epoch=57
05/22/2022 10:10:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.071777 on epoch=58
05/22/2022 10:10:35 - INFO - __main__ - Global step 700 Train loss 0.057261 Classification-F1 0.4410480349344978 on epoch=58
05/22/2022 10:10:40 - INFO - __main__ - Step 710 Global step 710 Train loss 0.190891 on epoch=59
05/22/2022 10:10:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.065683 on epoch=59
05/22/2022 10:10:50 - INFO - __main__ - Step 730 Global step 730 Train loss 0.164708 on epoch=60
05/22/2022 10:10:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.151867 on epoch=61
05/22/2022 10:11:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.135487 on epoch=62
05/22/2022 10:11:02 - INFO - __main__ - Global step 750 Train loss 0.141727 Classification-F1 0.4775510204081633 on epoch=62
05/22/2022 10:11:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.110520 on epoch=63
05/22/2022 10:11:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.129883 on epoch=64
05/22/2022 10:11:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.166571 on epoch=64
05/22/2022 10:11:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.088194 on epoch=65
05/22/2022 10:11:27 - INFO - __main__ - Step 800 Global step 800 Train loss 0.106268 on epoch=66
05/22/2022 10:11:28 - INFO - __main__ - Global step 800 Train loss 0.120287 Classification-F1 0.4817813765182186 on epoch=66
05/22/2022 10:11:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.211963 on epoch=67
05/22/2022 10:11:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.158620 on epoch=68
05/22/2022 10:11:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.245361 on epoch=69
05/22/2022 10:11:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.188808 on epoch=69
05/22/2022 10:11:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.147646 on epoch=70
05/22/2022 10:11:55 - INFO - __main__ - Global step 850 Train loss 0.190480 Classification-F1 0.4838709677419355 on epoch=70
05/22/2022 10:12:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.140561 on epoch=71
05/22/2022 10:12:05 - INFO - __main__ - Step 870 Global step 870 Train loss 0.245762 on epoch=72
05/22/2022 10:12:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.162804 on epoch=73
05/22/2022 10:12:15 - INFO - __main__ - Step 890 Global step 890 Train loss 0.189381 on epoch=74
05/22/2022 10:12:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.084700 on epoch=74
05/22/2022 10:12:22 - INFO - __main__ - Global step 900 Train loss 0.164642 Classification-F1 0.4817813765182186 on epoch=74
05/22/2022 10:12:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.040829 on epoch=75
05/22/2022 10:12:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.097553 on epoch=76
05/22/2022 10:12:37 - INFO - __main__ - Step 930 Global step 930 Train loss 0.030559 on epoch=77
05/22/2022 10:12:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.005483 on epoch=78
05/22/2022 10:12:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.011964 on epoch=79
05/22/2022 10:12:49 - INFO - __main__ - Global step 950 Train loss 0.037278 Classification-F1 0.4817813765182186 on epoch=79
05/22/2022 10:12:54 - INFO - __main__ - Step 960 Global step 960 Train loss 0.050612 on epoch=79
05/22/2022 10:12:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.037596 on epoch=80
05/22/2022 10:13:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.066423 on epoch=81
05/22/2022 10:13:09 - INFO - __main__ - Step 990 Global step 990 Train loss 0.092029 on epoch=82
05/22/2022 10:13:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.031191 on epoch=83
05/22/2022 10:13:16 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 10:13:16 - INFO - __main__ - Printing 3 examples
05/22/2022 10:13:16 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/22/2022 10:13:16 - INFO - __main__ - ['false']
05/22/2022 10:13:16 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/22/2022 10:13:16 - INFO - __main__ - ['false']
05/22/2022 10:13:16 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/22/2022 10:13:16 - INFO - __main__ - ['false']
05/22/2022 10:13:16 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:13:16 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:13:16 - INFO - __main__ - Global step 1000 Train loss 0.055570 Classification-F1 0.4838709677419355 on epoch=83
05/22/2022 10:13:16 - INFO - __main__ - save last model!
05/22/2022 10:13:16 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 10:13:16 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 10:13:16 - INFO - __main__ - Printing 3 examples
05/22/2022 10:13:16 - INFO - __main__ -  [ethos-religion] Please don' come back filthy Caucasian. You can change to a snake next time. Keep  changing.
05/22/2022 10:13:16 - INFO - __main__ - ['false']
05/22/2022 10:13:16 - INFO - __main__ -  [ethos-religion] Women are made for making babies and cooking dinner and nothing else!!!
05/22/2022 10:13:16 - INFO - __main__ - ['false']
05/22/2022 10:13:16 - INFO - __main__ -  [ethos-religion] phuck white rasist ass people
05/22/2022 10:13:16 - INFO - __main__ - ['false']
05/22/2022 10:13:16 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:13:16 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:13:16 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 10:13:23 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 10:13:24 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 10:13:24 - INFO - __main__ - Printing 3 examples
05/22/2022 10:13:24 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 10:13:24 - INFO - __main__ - ['false']
05/22/2022 10:13:24 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 10:13:24 - INFO - __main__ - ['false']
05/22/2022 10:13:24 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 10:13:24 - INFO - __main__ - ['true']
05/22/2022 10:13:24 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:13:24 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:13:24 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 10:13:26 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_42_0.0003_8_predictions.txt
05/22/2022 10:13:26 - INFO - __main__ - Classification-F1 on test data: 0.8748
05/22/2022 10:13:26 - INFO - __main__ - prefix=ethos-religion_128_42, lr=0.0003, bsz=8, dev_performance=0.4980392156862745, test_performance=0.874820143884892
05/22/2022 10:13:26 - INFO - __main__ - Running ... prefix=ethos-religion_128_42, lr=0.0002, bsz=8 ...
05/22/2022 10:13:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 10:13:26 - INFO - __main__ - Starting training!
05/22/2022 10:13:27 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 10:13:27 - INFO - __main__ - Printing 3 examples
05/22/2022 10:13:27 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/22/2022 10:13:27 - INFO - __main__ - ['false']
05/22/2022 10:13:27 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/22/2022 10:13:27 - INFO - __main__ - ['false']
05/22/2022 10:13:27 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/22/2022 10:13:27 - INFO - __main__ - ['false']
05/22/2022 10:13:27 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:13:27 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:13:27 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 10:13:27 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 10:13:27 - INFO - __main__ - Printing 3 examples
05/22/2022 10:13:27 - INFO - __main__ -  [ethos-religion] Please don' come back filthy Caucasian. You can change to a snake next time. Keep  changing.
05/22/2022 10:13:27 - INFO - __main__ - ['false']
05/22/2022 10:13:27 - INFO - __main__ -  [ethos-religion] Women are made for making babies and cooking dinner and nothing else!!!
05/22/2022 10:13:27 - INFO - __main__ - ['false']
05/22/2022 10:13:27 - INFO - __main__ -  [ethos-religion] phuck white rasist ass people
05/22/2022 10:13:27 - INFO - __main__ - ['false']
05/22/2022 10:13:27 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:13:27 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:13:28 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 10:13:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 10:13:39 - INFO - __main__ - Starting training!
05/22/2022 10:13:43 - INFO - __main__ - Step 10 Global step 10 Train loss 23.849360 on epoch=0
05/22/2022 10:13:49 - INFO - __main__ - Step 20 Global step 20 Train loss 18.857653 on epoch=1
05/22/2022 10:13:54 - INFO - __main__ - Step 30 Global step 30 Train loss 17.672649 on epoch=2
05/22/2022 10:13:59 - INFO - __main__ - Step 40 Global step 40 Train loss 15.460230 on epoch=3
05/22/2022 10:14:04 - INFO - __main__ - Step 50 Global step 50 Train loss 15.915609 on epoch=4
05/22/2022 10:14:41 - INFO - __main__ - Global step 50 Train loss 18.351099 Classification-F1 0.0 on epoch=4
05/22/2022 10:14:47 - INFO - __main__ - Step 60 Global step 60 Train loss 14.687444 on epoch=4
05/22/2022 10:14:52 - INFO - __main__ - Step 70 Global step 70 Train loss 13.808115 on epoch=5
05/22/2022 10:14:57 - INFO - __main__ - Step 80 Global step 80 Train loss 13.258575 on epoch=6
05/22/2022 10:15:02 - INFO - __main__ - Step 90 Global step 90 Train loss 12.421329 on epoch=7
05/22/2022 10:15:07 - INFO - __main__ - Step 100 Global step 100 Train loss 11.200877 on epoch=8
05/22/2022 10:15:44 - INFO - __main__ - Global step 100 Train loss 13.075269 Classification-F1 0.0 on epoch=8
05/22/2022 10:15:49 - INFO - __main__ - Step 110 Global step 110 Train loss 9.131016 on epoch=9
05/22/2022 10:15:54 - INFO - __main__ - Step 120 Global step 120 Train loss 6.470958 on epoch=9
05/22/2022 10:16:00 - INFO - __main__ - Step 130 Global step 130 Train loss 1.924878 on epoch=10
05/22/2022 10:16:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.823023 on epoch=11
05/22/2022 10:16:10 - INFO - __main__ - Step 150 Global step 150 Train loss 0.622662 on epoch=12
05/22/2022 10:16:11 - INFO - __main__ - Global step 150 Train loss 3.794508 Classification-F1 1.0 on epoch=12
05/22/2022 10:16:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.477928 on epoch=13
05/22/2022 10:16:22 - INFO - __main__ - Step 170 Global step 170 Train loss 0.396967 on epoch=14
05/22/2022 10:16:27 - INFO - __main__ - Step 180 Global step 180 Train loss 0.537491 on epoch=14
05/22/2022 10:16:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.358181 on epoch=15
05/22/2022 10:16:37 - INFO - __main__ - Step 200 Global step 200 Train loss 0.281928 on epoch=16
05/22/2022 10:16:39 - INFO - __main__ - Global step 200 Train loss 0.410499 Classification-F1 0.4775510204081633 on epoch=16
05/22/2022 10:16:44 - INFO - __main__ - Step 210 Global step 210 Train loss 0.295167 on epoch=17
05/22/2022 10:16:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.228762 on epoch=18
05/22/2022 10:16:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.169777 on epoch=19
05/22/2022 10:16:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.211722 on epoch=19
05/22/2022 10:17:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.170968 on epoch=20
05/22/2022 10:17:05 - INFO - __main__ - Global step 250 Train loss 0.215279 Classification-F1 0.4859437751004016 on epoch=20
05/22/2022 10:17:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.127330 on epoch=21
05/22/2022 10:17:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.086244 on epoch=22
05/22/2022 10:17:21 - INFO - __main__ - Step 280 Global step 280 Train loss 0.163406 on epoch=23
05/22/2022 10:17:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.092775 on epoch=24
05/22/2022 10:17:31 - INFO - __main__ - Step 300 Global step 300 Train loss 0.052484 on epoch=24
05/22/2022 10:17:32 - INFO - __main__ - Global step 300 Train loss 0.104448 Classification-F1 0.4900398406374502 on epoch=24
05/22/2022 10:17:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.073467 on epoch=25
05/22/2022 10:17:42 - INFO - __main__ - Step 320 Global step 320 Train loss 0.135172 on epoch=26
05/22/2022 10:17:48 - INFO - __main__ - Step 330 Global step 330 Train loss 0.055126 on epoch=27
05/22/2022 10:17:53 - INFO - __main__ - Step 340 Global step 340 Train loss 0.048841 on epoch=28
05/22/2022 10:17:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.029709 on epoch=29
05/22/2022 10:17:59 - INFO - __main__ - Global step 350 Train loss 0.068463 Classification-F1 0.4838709677419355 on epoch=29
05/22/2022 10:18:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.042124 on epoch=29
05/22/2022 10:18:10 - INFO - __main__ - Step 370 Global step 370 Train loss 0.064158 on epoch=30
05/22/2022 10:18:15 - INFO - __main__ - Step 380 Global step 380 Train loss 0.045405 on epoch=31
05/22/2022 10:18:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.045009 on epoch=32
05/22/2022 10:18:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.049375 on epoch=33
05/22/2022 10:18:26 - INFO - __main__ - Global step 400 Train loss 0.049214 Classification-F1 0.4817813765182186 on epoch=33
05/22/2022 10:18:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.027328 on epoch=34
05/22/2022 10:18:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.046689 on epoch=34
05/22/2022 10:18:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.055971 on epoch=35
05/22/2022 10:18:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.027310 on epoch=36
05/22/2022 10:18:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.018482 on epoch=37
05/22/2022 10:18:53 - INFO - __main__ - Global step 450 Train loss 0.035156 Classification-F1 0.4796747967479675 on epoch=37
05/22/2022 10:18:58 - INFO - __main__ - Step 460 Global step 460 Train loss 0.064646 on epoch=38
05/22/2022 10:19:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.011303 on epoch=39
05/22/2022 10:19:09 - INFO - __main__ - Step 480 Global step 480 Train loss 0.009430 on epoch=39
05/22/2022 10:19:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.016632 on epoch=40
05/22/2022 10:19:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.036538 on epoch=41
05/22/2022 10:19:20 - INFO - __main__ - Global step 500 Train loss 0.027710 Classification-F1 0.4796747967479675 on epoch=41
05/22/2022 10:19:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.007097 on epoch=42
05/22/2022 10:19:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.023741 on epoch=43
05/22/2022 10:19:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.005035 on epoch=44
05/22/2022 10:19:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.005327 on epoch=44
05/22/2022 10:19:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.016937 on epoch=45
05/22/2022 10:19:47 - INFO - __main__ - Global step 550 Train loss 0.011628 Classification-F1 0.4817813765182186 on epoch=45
05/22/2022 10:19:52 - INFO - __main__ - Step 560 Global step 560 Train loss 0.057315 on epoch=46
05/22/2022 10:19:57 - INFO - __main__ - Step 570 Global step 570 Train loss 0.008246 on epoch=47
05/22/2022 10:20:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.001983 on epoch=48
05/22/2022 10:20:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.073391 on epoch=49
05/22/2022 10:20:13 - INFO - __main__ - Step 600 Global step 600 Train loss 0.045281 on epoch=49
05/22/2022 10:20:14 - INFO - __main__ - Global step 600 Train loss 0.037243 Classification-F1 0.4838709677419355 on epoch=49
05/22/2022 10:20:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.007615 on epoch=50
05/22/2022 10:20:24 - INFO - __main__ - Step 620 Global step 620 Train loss 0.021985 on epoch=51
05/22/2022 10:20:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.002420 on epoch=52
05/22/2022 10:20:34 - INFO - __main__ - Step 640 Global step 640 Train loss 0.021261 on epoch=53
05/22/2022 10:20:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.009394 on epoch=54
05/22/2022 10:20:41 - INFO - __main__ - Global step 650 Train loss 0.012535 Classification-F1 0.4859437751004016 on epoch=54
05/22/2022 10:20:46 - INFO - __main__ - Step 660 Global step 660 Train loss 0.004141 on epoch=54
05/22/2022 10:20:51 - INFO - __main__ - Step 670 Global step 670 Train loss 0.002347 on epoch=55
05/22/2022 10:20:56 - INFO - __main__ - Step 680 Global step 680 Train loss 0.002282 on epoch=56
05/22/2022 10:21:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000752 on epoch=57
05/22/2022 10:21:06 - INFO - __main__ - Step 700 Global step 700 Train loss 0.001126 on epoch=58
05/22/2022 10:21:08 - INFO - __main__ - Global step 700 Train loss 0.002129 Classification-F1 0.4796747967479675 on epoch=58
05/22/2022 10:21:13 - INFO - __main__ - Step 710 Global step 710 Train loss 0.001779 on epoch=59
05/22/2022 10:21:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000283 on epoch=59
05/22/2022 10:21:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000480 on epoch=60
05/22/2022 10:21:28 - INFO - __main__ - Step 740 Global step 740 Train loss 0.003948 on epoch=61
05/22/2022 10:21:33 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000193 on epoch=62
05/22/2022 10:21:35 - INFO - __main__ - Global step 750 Train loss 0.001337 Classification-F1 0.4796747967479675 on epoch=62
05/22/2022 10:21:40 - INFO - __main__ - Step 760 Global step 760 Train loss 0.001004 on epoch=63
05/22/2022 10:21:45 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000122 on epoch=64
05/22/2022 10:21:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.003836 on epoch=64
05/22/2022 10:21:55 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000322 on epoch=65
05/22/2022 10:22:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000040 on epoch=66
05/22/2022 10:22:01 - INFO - __main__ - Global step 800 Train loss 0.001065 Classification-F1 0.4796747967479675 on epoch=66
05/22/2022 10:22:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000036 on epoch=67
05/22/2022 10:22:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000107 on epoch=68
05/22/2022 10:22:17 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000301 on epoch=69
05/22/2022 10:22:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000057 on epoch=69
05/22/2022 10:22:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000913 on epoch=70
05/22/2022 10:22:28 - INFO - __main__ - Global step 850 Train loss 0.000283 Classification-F1 0.4796747967479675 on epoch=70
05/22/2022 10:22:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.021039 on epoch=71
05/22/2022 10:22:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000055 on epoch=72
05/22/2022 10:22:44 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000130 on epoch=73
05/22/2022 10:22:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000078 on epoch=74
05/22/2022 10:22:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000071 on epoch=74
05/22/2022 10:22:55 - INFO - __main__ - Global step 900 Train loss 0.004275 Classification-F1 0.4817813765182186 on epoch=74
05/22/2022 10:23:00 - INFO - __main__ - Step 910 Global step 910 Train loss 0.001623 on epoch=75
05/22/2022 10:23:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000629 on epoch=76
05/22/2022 10:23:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000087 on epoch=77
05/22/2022 10:23:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000444 on epoch=78
05/22/2022 10:23:21 - INFO - __main__ - Step 950 Global step 950 Train loss 0.001839 on epoch=79
05/22/2022 10:23:22 - INFO - __main__ - Global step 950 Train loss 0.000924 Classification-F1 0.4732510288065844 on epoch=79
05/22/2022 10:23:27 - INFO - __main__ - Step 960 Global step 960 Train loss 0.020199 on epoch=79
05/22/2022 10:23:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.017492 on epoch=80
05/22/2022 10:23:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.003045 on epoch=81
05/22/2022 10:23:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.001903 on epoch=82
05/22/2022 10:23:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000410 on epoch=83
05/22/2022 10:23:49 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 10:23:49 - INFO - __main__ - Printing 3 examples
05/22/2022 10:23:49 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/22/2022 10:23:49 - INFO - __main__ - ['false']
05/22/2022 10:23:49 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/22/2022 10:23:49 - INFO - __main__ - ['false']
05/22/2022 10:23:49 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/22/2022 10:23:49 - INFO - __main__ - ['false']
05/22/2022 10:23:49 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:23:49 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:23:49 - INFO - __main__ - Global step 1000 Train loss 0.008610 Classification-F1 0.4817813765182186 on epoch=83
05/22/2022 10:23:49 - INFO - __main__ - save last model!
05/22/2022 10:23:49 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 10:23:49 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 10:23:49 - INFO - __main__ - Printing 3 examples
05/22/2022 10:23:49 - INFO - __main__ -  [ethos-religion] Please don' come back filthy Caucasian. You can change to a snake next time. Keep  changing.
05/22/2022 10:23:49 - INFO - __main__ - ['false']
05/22/2022 10:23:49 - INFO - __main__ -  [ethos-religion] Women are made for making babies and cooking dinner and nothing else!!!
05/22/2022 10:23:49 - INFO - __main__ - ['false']
05/22/2022 10:23:49 - INFO - __main__ -  [ethos-religion] phuck white rasist ass people
05/22/2022 10:23:49 - INFO - __main__ - ['false']
05/22/2022 10:23:49 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:23:50 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:23:50 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 10:23:56 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 10:23:57 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 10:23:57 - INFO - __main__ - Printing 3 examples
05/22/2022 10:23:57 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 10:23:57 - INFO - __main__ - ['false']
05/22/2022 10:23:57 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 10:23:57 - INFO - __main__ - ['false']
05/22/2022 10:23:57 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 10:23:57 - INFO - __main__ - ['true']
05/22/2022 10:23:57 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:23:57 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:23:57 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 10:23:59 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_42_0.0002_8_predictions.txt
05/22/2022 10:23:59 - INFO - __main__ - Classification-F1 on test data: 0.4387
05/22/2022 10:23:59 - INFO - __main__ - prefix=ethos-religion_128_42, lr=0.0002, bsz=8, dev_performance=1.0, test_performance=0.4387096774193549
05/22/2022 10:23:59 - INFO - __main__ - Running ... prefix=ethos-religion_128_42, lr=0.0001, bsz=8 ...
05/22/2022 10:24:00 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 10:24:00 - INFO - __main__ - Printing 3 examples
05/22/2022 10:24:00 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/22/2022 10:24:00 - INFO - __main__ - ['false']
05/22/2022 10:24:00 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/22/2022 10:24:00 - INFO - __main__ - ['false']
05/22/2022 10:24:00 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/22/2022 10:24:00 - INFO - __main__ - ['false']
05/22/2022 10:24:00 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:24:00 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:24:00 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 10:24:00 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 10:24:00 - INFO - __main__ - Printing 3 examples
05/22/2022 10:24:00 - INFO - __main__ -  [ethos-religion] Please don' come back filthy Caucasian. You can change to a snake next time. Keep  changing.
05/22/2022 10:24:00 - INFO - __main__ - ['false']
05/22/2022 10:24:00 - INFO - __main__ -  [ethos-religion] Women are made for making babies and cooking dinner and nothing else!!!
05/22/2022 10:24:00 - INFO - __main__ - ['false']
05/22/2022 10:24:00 - INFO - __main__ -  [ethos-religion] phuck white rasist ass people
05/22/2022 10:24:00 - INFO - __main__ - ['false']
05/22/2022 10:24:00 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:24:00 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:24:01 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 10:24:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 10:24:03 - INFO - __main__ - Starting training!
05/22/2022 10:24:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 10:24:13 - INFO - __main__ - Starting training!
05/22/2022 10:24:17 - INFO - __main__ - Step 10 Global step 10 Train loss 24.927296 on epoch=0
05/22/2022 10:24:22 - INFO - __main__ - Step 20 Global step 20 Train loss 21.453751 on epoch=1
05/22/2022 10:24:28 - INFO - __main__ - Step 30 Global step 30 Train loss 19.292967 on epoch=2
05/22/2022 10:24:33 - INFO - __main__ - Step 40 Global step 40 Train loss 18.243717 on epoch=3
05/22/2022 10:24:38 - INFO - __main__ - Step 50 Global step 50 Train loss 17.288818 on epoch=4
05/22/2022 10:25:15 - INFO - __main__ - Global step 50 Train loss 20.241310 Classification-F1 0.0 on epoch=4
05/22/2022 10:25:21 - INFO - __main__ - Step 60 Global step 60 Train loss 16.666134 on epoch=4
05/22/2022 10:25:26 - INFO - __main__ - Step 70 Global step 70 Train loss 17.348179 on epoch=5
05/22/2022 10:25:31 - INFO - __main__ - Step 80 Global step 80 Train loss 15.440094 on epoch=6
05/22/2022 10:25:36 - INFO - __main__ - Step 90 Global step 90 Train loss 15.926498 on epoch=7
05/22/2022 10:25:41 - INFO - __main__ - Step 100 Global step 100 Train loss 15.669891 on epoch=8
05/22/2022 10:26:18 - INFO - __main__ - Global step 100 Train loss 16.210159 Classification-F1 0.0 on epoch=8
05/22/2022 10:26:23 - INFO - __main__ - Step 110 Global step 110 Train loss 14.322888 on epoch=9
05/22/2022 10:26:28 - INFO - __main__ - Step 120 Global step 120 Train loss 14.823469 on epoch=9
05/22/2022 10:26:33 - INFO - __main__ - Step 130 Global step 130 Train loss 14.114286 on epoch=10
05/22/2022 10:26:38 - INFO - __main__ - Step 140 Global step 140 Train loss 13.797559 on epoch=11
05/22/2022 10:26:43 - INFO - __main__ - Step 150 Global step 150 Train loss 13.225519 on epoch=12
05/22/2022 10:27:17 - INFO - __main__ - Global step 150 Train loss 14.056745 Classification-F1 0.0 on epoch=12
05/22/2022 10:27:22 - INFO - __main__ - Step 160 Global step 160 Train loss 12.991125 on epoch=13
05/22/2022 10:27:27 - INFO - __main__ - Step 170 Global step 170 Train loss 12.478803 on epoch=14
05/22/2022 10:27:32 - INFO - __main__ - Step 180 Global step 180 Train loss 11.511411 on epoch=14
05/22/2022 10:27:37 - INFO - __main__ - Step 190 Global step 190 Train loss 11.048566 on epoch=15
05/22/2022 10:27:43 - INFO - __main__ - Step 200 Global step 200 Train loss 9.878963 on epoch=16
05/22/2022 10:28:14 - INFO - __main__ - Global step 200 Train loss 11.581774 Classification-F1 0.000591715976331361 on epoch=16
05/22/2022 10:28:20 - INFO - __main__ - Step 210 Global step 210 Train loss 9.030087 on epoch=17
05/22/2022 10:28:25 - INFO - __main__ - Step 220 Global step 220 Train loss 7.798811 on epoch=18
05/22/2022 10:28:31 - INFO - __main__ - Step 230 Global step 230 Train loss 5.634499 on epoch=19
05/22/2022 10:28:36 - INFO - __main__ - Step 240 Global step 240 Train loss 3.948825 on epoch=19
05/22/2022 10:28:41 - INFO - __main__ - Step 250 Global step 250 Train loss 4.438859 on epoch=20
05/22/2022 10:29:21 - INFO - __main__ - Global step 250 Train loss 6.170217 Classification-F1 0.016891891891891893 on epoch=20
05/22/2022 10:29:27 - INFO - __main__ - Step 260 Global step 260 Train loss 3.633562 on epoch=21
05/22/2022 10:29:33 - INFO - __main__ - Step 270 Global step 270 Train loss 3.562735 on epoch=22
05/22/2022 10:29:38 - INFO - __main__ - Step 280 Global step 280 Train loss 2.368652 on epoch=23
05/22/2022 10:29:43 - INFO - __main__ - Step 290 Global step 290 Train loss 1.346159 on epoch=24
05/22/2022 10:29:48 - INFO - __main__ - Step 300 Global step 300 Train loss 1.356118 on epoch=24
05/22/2022 10:29:49 - INFO - __main__ - Global step 300 Train loss 2.453445 Classification-F1 0.32669322709163345 on epoch=24
05/22/2022 10:29:55 - INFO - __main__ - Step 310 Global step 310 Train loss 0.814284 on epoch=25
05/22/2022 10:30:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.762241 on epoch=26
05/22/2022 10:30:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.630542 on epoch=27
05/22/2022 10:30:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.508348 on epoch=28
05/22/2022 10:30:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.538702 on epoch=29
05/22/2022 10:30:17 - INFO - __main__ - Global step 350 Train loss 0.650823 Classification-F1 1.0 on epoch=29
05/22/2022 10:30:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.892267 on epoch=29
05/22/2022 10:30:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.422701 on epoch=30
05/22/2022 10:30:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.422876 on epoch=31
05/22/2022 10:30:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.365644 on epoch=32
05/22/2022 10:30:43 - INFO - __main__ - Step 400 Global step 400 Train loss 0.361224 on epoch=33
05/22/2022 10:30:45 - INFO - __main__ - Global step 400 Train loss 0.492942 Classification-F1 0.4260089686098655 on epoch=33
05/22/2022 10:30:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.299897 on epoch=34
05/22/2022 10:30:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.444039 on epoch=34
05/22/2022 10:31:00 - INFO - __main__ - Step 430 Global step 430 Train loss 0.281546 on epoch=35
05/22/2022 10:31:05 - INFO - __main__ - Step 440 Global step 440 Train loss 0.291014 on epoch=36
05/22/2022 10:31:10 - INFO - __main__ - Step 450 Global step 450 Train loss 0.274090 on epoch=37
05/22/2022 10:31:12 - INFO - __main__ - Global step 450 Train loss 0.318117 Classification-F1 0.47107438016528924 on epoch=37
05/22/2022 10:31:17 - INFO - __main__ - Step 460 Global step 460 Train loss 0.254222 on epoch=38
05/22/2022 10:31:22 - INFO - __main__ - Step 470 Global step 470 Train loss 0.228356 on epoch=39
05/22/2022 10:31:27 - INFO - __main__ - Step 480 Global step 480 Train loss 0.124552 on epoch=39
05/22/2022 10:31:32 - INFO - __main__ - Step 490 Global step 490 Train loss 0.279560 on epoch=40
05/22/2022 10:31:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.355562 on epoch=41
05/22/2022 10:31:39 - INFO - __main__ - Global step 500 Train loss 0.248450 Classification-F1 0.4817813765182186 on epoch=41
05/22/2022 10:31:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.194186 on epoch=42
05/22/2022 10:31:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.235523 on epoch=43
05/22/2022 10:31:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.222174 on epoch=44
05/22/2022 10:32:00 - INFO - __main__ - Step 540 Global step 540 Train loss 0.299477 on epoch=44
05/22/2022 10:32:05 - INFO - __main__ - Step 550 Global step 550 Train loss 0.138817 on epoch=45
05/22/2022 10:32:06 - INFO - __main__ - Global step 550 Train loss 0.218035 Classification-F1 0.49206349206349204 on epoch=45
05/22/2022 10:32:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.202282 on epoch=46
05/22/2022 10:32:16 - INFO - __main__ - Step 570 Global step 570 Train loss 0.111533 on epoch=47
05/22/2022 10:32:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.130420 on epoch=48
05/22/2022 10:32:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.142204 on epoch=49
05/22/2022 10:32:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.157728 on epoch=49
05/22/2022 10:32:33 - INFO - __main__ - Global step 600 Train loss 0.148833 Classification-F1 0.49407114624505927 on epoch=49
05/22/2022 10:32:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.211071 on epoch=50
05/22/2022 10:32:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.194480 on epoch=51
05/22/2022 10:32:49 - INFO - __main__ - Step 630 Global step 630 Train loss 0.203248 on epoch=52
05/22/2022 10:32:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.190110 on epoch=53
05/22/2022 10:32:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.118110 on epoch=54
05/22/2022 10:33:01 - INFO - __main__ - Global step 650 Train loss 0.183404 Classification-F1 0.4838709677419355 on epoch=54
05/22/2022 10:33:06 - INFO - __main__ - Step 660 Global step 660 Train loss 0.158405 on epoch=54
05/22/2022 10:33:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.126943 on epoch=55
05/22/2022 10:33:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.208369 on epoch=56
05/22/2022 10:33:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.258414 on epoch=57
05/22/2022 10:33:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.114300 on epoch=58
05/22/2022 10:33:28 - INFO - __main__ - Global step 700 Train loss 0.173286 Classification-F1 0.49206349206349204 on epoch=58
05/22/2022 10:33:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.174880 on epoch=59
05/22/2022 10:33:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.058351 on epoch=59
05/22/2022 10:33:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.113684 on epoch=60
05/22/2022 10:33:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.161021 on epoch=61
05/22/2022 10:33:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.100889 on epoch=62
05/22/2022 10:33:55 - INFO - __main__ - Global step 750 Train loss 0.121765 Classification-F1 0.4859437751004016 on epoch=62
05/22/2022 10:34:00 - INFO - __main__ - Step 760 Global step 760 Train loss 0.114947 on epoch=63
05/22/2022 10:34:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.048702 on epoch=64
05/22/2022 10:34:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.133569 on epoch=64
05/22/2022 10:34:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.073989 on epoch=65
05/22/2022 10:34:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.176013 on epoch=66
05/22/2022 10:34:22 - INFO - __main__ - Global step 800 Train loss 0.109444 Classification-F1 0.4666666666666667 on epoch=66
05/22/2022 10:34:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.224787 on epoch=67
05/22/2022 10:34:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.047743 on epoch=68
05/22/2022 10:34:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.098041 on epoch=69
05/22/2022 10:34:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.105462 on epoch=69
05/22/2022 10:34:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.102471 on epoch=70
05/22/2022 10:34:49 - INFO - __main__ - Global step 850 Train loss 0.115701 Classification-F1 0.488 on epoch=70
05/22/2022 10:34:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.161636 on epoch=71
05/22/2022 10:34:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.122197 on epoch=72
05/22/2022 10:35:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.142841 on epoch=73
05/22/2022 10:35:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.119419 on epoch=74
05/22/2022 10:35:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.152699 on epoch=74
05/22/2022 10:35:15 - INFO - __main__ - Global step 900 Train loss 0.139758 Classification-F1 0.488 on epoch=74
05/22/2022 10:35:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.171872 on epoch=75
05/22/2022 10:35:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.276495 on epoch=76
05/22/2022 10:35:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.585288 on epoch=77
05/22/2022 10:35:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.258803 on epoch=78
05/22/2022 10:35:41 - INFO - __main__ - Step 950 Global step 950 Train loss 0.309880 on epoch=79
05/22/2022 10:35:42 - INFO - __main__ - Global step 950 Train loss 0.320468 Classification-F1 0.4838709677419355 on epoch=79
05/22/2022 10:35:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.283338 on epoch=79
05/22/2022 10:35:52 - INFO - __main__ - Step 970 Global step 970 Train loss 0.128636 on epoch=80
05/22/2022 10:35:57 - INFO - __main__ - Step 980 Global step 980 Train loss 0.163350 on epoch=81
05/22/2022 10:36:02 - INFO - __main__ - Step 990 Global step 990 Train loss 0.222496 on epoch=82
05/22/2022 10:36:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.187963 on epoch=83
05/22/2022 10:36:09 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 10:36:09 - INFO - __main__ - Printing 3 examples
05/22/2022 10:36:09 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/22/2022 10:36:09 - INFO - __main__ - ['false']
05/22/2022 10:36:09 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/22/2022 10:36:09 - INFO - __main__ - ['false']
05/22/2022 10:36:09 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/22/2022 10:36:09 - INFO - __main__ - ['false']
05/22/2022 10:36:09 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:36:09 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:36:09 - INFO - __main__ - Global step 1000 Train loss 0.197157 Classification-F1 0.46218487394957986 on epoch=83
05/22/2022 10:36:09 - INFO - __main__ - save last model!
05/22/2022 10:36:09 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 10:36:09 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 10:36:09 - INFO - __main__ - Printing 3 examples
05/22/2022 10:36:09 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/22/2022 10:36:09 - INFO - __main__ - ['false']
05/22/2022 10:36:09 - INFO - __main__ -  [ethos-religion] Trans are using the same logic feminists have been using for decades to destroy men so i don&#39t feel sorry for wamen not one bit!
05/22/2022 10:36:09 - INFO - __main__ - ['false']
05/22/2022 10:36:09 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 10:36:09 - INFO - __main__ - ['false']
05/22/2022 10:36:09 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:36:09 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:36:09 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 10:36:16 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 10:36:16 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 10:36:16 - INFO - __main__ - Printing 3 examples
05/22/2022 10:36:16 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 10:36:16 - INFO - __main__ - ['false']
05/22/2022 10:36:16 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 10:36:16 - INFO - __main__ - ['false']
05/22/2022 10:36:16 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 10:36:16 - INFO - __main__ - ['true']
05/22/2022 10:36:16 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:36:16 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:36:16 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 10:36:18 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_42_0.0001_8_predictions.txt
05/22/2022 10:36:18 - INFO - __main__ - Classification-F1 on test data: 0.6964
05/22/2022 10:36:18 - INFO - __main__ - prefix=ethos-religion_128_42, lr=0.0001, bsz=8, dev_performance=1.0, test_performance=0.6963758389261745
05/22/2022 10:36:18 - INFO - __main__ - Running ... prefix=ethos-religion_128_87, lr=0.0005, bsz=8 ...
05/22/2022 10:36:19 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 10:36:19 - INFO - __main__ - Printing 3 examples
05/22/2022 10:36:19 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/22/2022 10:36:19 - INFO - __main__ - ['false']
05/22/2022 10:36:19 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/22/2022 10:36:19 - INFO - __main__ - ['false']
05/22/2022 10:36:19 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/22/2022 10:36:19 - INFO - __main__ - ['false']
05/22/2022 10:36:19 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:36:19 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:36:20 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 10:36:20 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 10:36:20 - INFO - __main__ - Printing 3 examples
05/22/2022 10:36:20 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/22/2022 10:36:20 - INFO - __main__ - ['false']
05/22/2022 10:36:20 - INFO - __main__ -  [ethos-religion] Trans are using the same logic feminists have been using for decades to destroy men so i don&#39t feel sorry for wamen not one bit!
05/22/2022 10:36:20 - INFO - __main__ - ['false']
05/22/2022 10:36:20 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 10:36:20 - INFO - __main__ - ['false']
05/22/2022 10:36:20 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:36:20 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:36:20 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 10:36:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 10:36:22 - INFO - __main__ - Starting training!
05/22/2022 10:36:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 10:36:32 - INFO - __main__ - Starting training!
05/22/2022 10:36:37 - INFO - __main__ - Step 10 Global step 10 Train loss 23.590349 on epoch=0
05/22/2022 10:36:42 - INFO - __main__ - Step 20 Global step 20 Train loss 18.456017 on epoch=1
05/22/2022 10:36:47 - INFO - __main__ - Step 30 Global step 30 Train loss 15.925329 on epoch=2
05/22/2022 10:36:52 - INFO - __main__ - Step 40 Global step 40 Train loss 13.439316 on epoch=3
05/22/2022 10:36:57 - INFO - __main__ - Step 50 Global step 50 Train loss 11.453773 on epoch=4
05/22/2022 10:36:58 - INFO - __main__ - Global step 50 Train loss 16.572956 Classification-F1 0.0 on epoch=4
05/22/2022 10:37:04 - INFO - __main__ - Step 60 Global step 60 Train loss 8.296907 on epoch=4
05/22/2022 10:37:09 - INFO - __main__ - Step 70 Global step 70 Train loss 4.254108 on epoch=5
05/22/2022 10:37:14 - INFO - __main__ - Step 80 Global step 80 Train loss 2.715034 on epoch=6
05/22/2022 10:37:19 - INFO - __main__ - Step 90 Global step 90 Train loss 1.180773 on epoch=7
05/22/2022 10:37:24 - INFO - __main__ - Step 100 Global step 100 Train loss 0.771325 on epoch=8
05/22/2022 10:37:25 - INFO - __main__ - Global step 100 Train loss 3.443630 Classification-F1 0.1794871794871795 on epoch=8
05/22/2022 10:37:31 - INFO - __main__ - Step 110 Global step 110 Train loss 0.421378 on epoch=9
05/22/2022 10:37:36 - INFO - __main__ - Step 120 Global step 120 Train loss 0.446719 on epoch=9
05/22/2022 10:37:41 - INFO - __main__ - Step 130 Global step 130 Train loss 0.445241 on epoch=10
05/22/2022 10:37:46 - INFO - __main__ - Step 140 Global step 140 Train loss 0.491856 on epoch=11
05/22/2022 10:37:52 - INFO - __main__ - Step 150 Global step 150 Train loss 0.592433 on epoch=12
05/22/2022 10:37:53 - INFO - __main__ - Global step 150 Train loss 0.479525 Classification-F1 1.0 on epoch=12
05/22/2022 10:37:59 - INFO - __main__ - Step 160 Global step 160 Train loss 0.442442 on epoch=13
05/22/2022 10:38:04 - INFO - __main__ - Step 170 Global step 170 Train loss 0.405953 on epoch=14
05/22/2022 10:38:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.321962 on epoch=14
05/22/2022 10:38:14 - INFO - __main__ - Step 190 Global step 190 Train loss 0.368329 on epoch=15
05/22/2022 10:38:19 - INFO - __main__ - Step 200 Global step 200 Train loss 0.331475 on epoch=16
05/22/2022 10:38:21 - INFO - __main__ - Global step 200 Train loss 0.374032 Classification-F1 0.49606299212598426 on epoch=16
05/22/2022 10:38:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.296772 on epoch=17
05/22/2022 10:38:31 - INFO - __main__ - Step 220 Global step 220 Train loss 0.261123 on epoch=18
05/22/2022 10:38:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.331711 on epoch=19
05/22/2022 10:38:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.266762 on epoch=19
05/22/2022 10:38:46 - INFO - __main__ - Step 250 Global step 250 Train loss 0.261886 on epoch=20
05/22/2022 10:38:47 - INFO - __main__ - Global step 250 Train loss 0.283651 Classification-F1 0.49407114624505927 on epoch=20
05/22/2022 10:38:52 - INFO - __main__ - Step 260 Global step 260 Train loss 0.231520 on epoch=21
05/22/2022 10:38:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.264547 on epoch=22
05/22/2022 10:39:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.201248 on epoch=23
05/22/2022 10:39:07 - INFO - __main__ - Step 290 Global step 290 Train loss 0.302483 on epoch=24
05/22/2022 10:39:13 - INFO - __main__ - Step 300 Global step 300 Train loss 0.267851 on epoch=24
05/22/2022 10:39:14 - INFO - __main__ - Global step 300 Train loss 0.253530 Classification-F1 0.4576271186440678 on epoch=24
05/22/2022 10:39:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.185699 on epoch=25
05/22/2022 10:39:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.211005 on epoch=26
05/22/2022 10:39:29 - INFO - __main__ - Step 330 Global step 330 Train loss 0.212919 on epoch=27
05/22/2022 10:39:34 - INFO - __main__ - Step 340 Global step 340 Train loss 0.169924 on epoch=28
05/22/2022 10:39:39 - INFO - __main__ - Step 350 Global step 350 Train loss 0.152613 on epoch=29
05/22/2022 10:39:41 - INFO - __main__ - Global step 350 Train loss 0.186432 Classification-F1 0.4980392156862745 on epoch=29
05/22/2022 10:39:46 - INFO - __main__ - Step 360 Global step 360 Train loss 0.173173 on epoch=29
05/22/2022 10:39:51 - INFO - __main__ - Step 370 Global step 370 Train loss 0.116475 on epoch=30
05/22/2022 10:39:56 - INFO - __main__ - Step 380 Global step 380 Train loss 0.121515 on epoch=31
05/22/2022 10:40:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.096047 on epoch=32
05/22/2022 10:40:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.028962 on epoch=33
05/22/2022 10:40:08 - INFO - __main__ - Global step 400 Train loss 0.107235 Classification-F1 0.4838709677419355 on epoch=33
05/22/2022 10:40:13 - INFO - __main__ - Step 410 Global step 410 Train loss 0.035040 on epoch=34
05/22/2022 10:40:18 - INFO - __main__ - Step 420 Global step 420 Train loss 0.085794 on epoch=34
05/22/2022 10:40:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.092743 on epoch=35
05/22/2022 10:40:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.063057 on epoch=36
05/22/2022 10:40:33 - INFO - __main__ - Step 450 Global step 450 Train loss 0.086305 on epoch=37
05/22/2022 10:40:35 - INFO - __main__ - Global step 450 Train loss 0.072588 Classification-F1 0.4900398406374502 on epoch=37
05/22/2022 10:40:40 - INFO - __main__ - Step 460 Global step 460 Train loss 0.196204 on epoch=38
05/22/2022 10:40:45 - INFO - __main__ - Step 470 Global step 470 Train loss 0.191699 on epoch=39
05/22/2022 10:40:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.194837 on epoch=39
05/22/2022 10:40:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.096414 on epoch=40
05/22/2022 10:41:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.114070 on epoch=41
05/22/2022 10:41:02 - INFO - __main__ - Global step 500 Train loss 0.158645 Classification-F1 0.4817813765182186 on epoch=41
05/22/2022 10:41:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.079124 on epoch=42
05/22/2022 10:41:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.048828 on epoch=43
05/22/2022 10:41:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.086529 on epoch=44
05/22/2022 10:41:22 - INFO - __main__ - Step 540 Global step 540 Train loss 0.036262 on epoch=44
05/22/2022 10:41:27 - INFO - __main__ - Step 550 Global step 550 Train loss 0.084100 on epoch=45
05/22/2022 10:41:29 - INFO - __main__ - Global step 550 Train loss 0.066969 Classification-F1 0.488 on epoch=45
05/22/2022 10:41:34 - INFO - __main__ - Step 560 Global step 560 Train loss 0.070089 on epoch=46
05/22/2022 10:41:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.051803 on epoch=47
05/22/2022 10:41:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.013739 on epoch=48
05/22/2022 10:41:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.061589 on epoch=49
05/22/2022 10:41:54 - INFO - __main__ - Step 600 Global step 600 Train loss 0.050729 on epoch=49
05/22/2022 10:41:56 - INFO - __main__ - Global step 600 Train loss 0.049590 Classification-F1 0.4817813765182186 on epoch=49
05/22/2022 10:42:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.041421 on epoch=50
05/22/2022 10:42:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.050832 on epoch=51
05/22/2022 10:42:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.027881 on epoch=52
05/22/2022 10:42:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.005121 on epoch=53
05/22/2022 10:42:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.009136 on epoch=54
05/22/2022 10:42:23 - INFO - __main__ - Global step 650 Train loss 0.026878 Classification-F1 0.488 on epoch=54
05/22/2022 10:42:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.002084 on epoch=54
05/22/2022 10:42:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.050042 on epoch=55
05/22/2022 10:42:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.012952 on epoch=56
05/22/2022 10:42:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.016972 on epoch=57
05/22/2022 10:42:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.005876 on epoch=58
05/22/2022 10:42:50 - INFO - __main__ - Global step 700 Train loss 0.017585 Classification-F1 0.488 on epoch=58
05/22/2022 10:42:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.002808 on epoch=59
05/22/2022 10:43:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.021983 on epoch=59
05/22/2022 10:43:05 - INFO - __main__ - Step 730 Global step 730 Train loss 0.049878 on epoch=60
05/22/2022 10:43:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.037575 on epoch=61
05/22/2022 10:43:16 - INFO - __main__ - Step 750 Global step 750 Train loss 0.028520 on epoch=62
05/22/2022 10:43:17 - INFO - __main__ - Global step 750 Train loss 0.028153 Classification-F1 0.488 on epoch=62
05/22/2022 10:43:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.013190 on epoch=63
05/22/2022 10:43:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.020622 on epoch=64
05/22/2022 10:43:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.025619 on epoch=64
05/22/2022 10:43:37 - INFO - __main__ - Step 790 Global step 790 Train loss 0.079019 on epoch=65
05/22/2022 10:43:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.023768 on epoch=66
05/22/2022 10:43:44 - INFO - __main__ - Global step 800 Train loss 0.032444 Classification-F1 0.49206349206349204 on epoch=66
05/22/2022 10:43:49 - INFO - __main__ - Step 810 Global step 810 Train loss 0.001964 on epoch=67
05/22/2022 10:43:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.004019 on epoch=68
05/22/2022 10:43:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.007810 on epoch=69
05/22/2022 10:44:04 - INFO - __main__ - Step 840 Global step 840 Train loss 0.006646 on epoch=69
05/22/2022 10:44:09 - INFO - __main__ - Step 850 Global step 850 Train loss 0.004409 on epoch=70
05/22/2022 10:44:11 - INFO - __main__ - Global step 850 Train loss 0.004970 Classification-F1 0.49407114624505927 on epoch=70
05/22/2022 10:44:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.040206 on epoch=71
05/22/2022 10:44:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.002013 on epoch=72
05/22/2022 10:44:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000110 on epoch=73
05/22/2022 10:44:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000179 on epoch=74
05/22/2022 10:44:36 - INFO - __main__ - Step 900 Global step 900 Train loss 0.005170 on epoch=74
05/22/2022 10:44:37 - INFO - __main__ - Global step 900 Train loss 0.009536 Classification-F1 0.49206349206349204 on epoch=74
05/22/2022 10:44:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.003880 on epoch=75
05/22/2022 10:44:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.005835 on epoch=76
05/22/2022 10:44:52 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000148 on epoch=77
05/22/2022 10:44:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000182 on epoch=78
05/22/2022 10:45:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.002005 on epoch=79
05/22/2022 10:45:04 - INFO - __main__ - Global step 950 Train loss 0.002410 Classification-F1 0.4900398406374502 on epoch=79
05/22/2022 10:45:09 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000564 on epoch=79
05/22/2022 10:45:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000120 on epoch=80
05/22/2022 10:45:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000360 on epoch=81
05/22/2022 10:45:24 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000217 on epoch=82
05/22/2022 10:45:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.002431 on epoch=83
05/22/2022 10:45:31 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 10:45:31 - INFO - __main__ - Printing 3 examples
05/22/2022 10:45:31 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/22/2022 10:45:31 - INFO - __main__ - ['false']
05/22/2022 10:45:31 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/22/2022 10:45:31 - INFO - __main__ - ['false']
05/22/2022 10:45:31 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/22/2022 10:45:31 - INFO - __main__ - ['false']
05/22/2022 10:45:31 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:45:31 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:45:31 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 10:45:31 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 10:45:31 - INFO - __main__ - Printing 3 examples
05/22/2022 10:45:31 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/22/2022 10:45:31 - INFO - __main__ - ['false']
05/22/2022 10:45:31 - INFO - __main__ -  [ethos-religion] Trans are using the same logic feminists have been using for decades to destroy men so i don&#39t feel sorry for wamen not one bit!
05/22/2022 10:45:31 - INFO - __main__ - ['false']
05/22/2022 10:45:31 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 10:45:31 - INFO - __main__ - ['false']
05/22/2022 10:45:31 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:45:31 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:45:31 - INFO - __main__ - Global step 1000 Train loss 0.000738 Classification-F1 0.49206349206349204 on epoch=83
05/22/2022 10:45:31 - INFO - __main__ - save last model!
05/22/2022 10:45:31 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 10:45:38 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 10:45:39 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 10:45:39 - INFO - __main__ - Printing 3 examples
05/22/2022 10:45:39 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 10:45:39 - INFO - __main__ - ['false']
05/22/2022 10:45:39 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 10:45:39 - INFO - __main__ - ['false']
05/22/2022 10:45:39 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 10:45:39 - INFO - __main__ - ['true']
05/22/2022 10:45:39 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:45:39 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:45:39 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 10:45:41 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_87_0.0005_8_predictions.txt
05/22/2022 10:45:41 - INFO - __main__ - Classification-F1 on test data: 0.4916
05/22/2022 10:45:41 - INFO - __main__ - prefix=ethos-religion_128_87, lr=0.0005, bsz=8, dev_performance=1.0, test_performance=0.49155844155844153
05/22/2022 10:45:41 - INFO - __main__ - Running ... prefix=ethos-religion_128_87, lr=0.0003, bsz=8 ...
05/22/2022 10:45:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 10:45:42 - INFO - __main__ - Starting training!
05/22/2022 10:45:42 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 10:45:42 - INFO - __main__ - Printing 3 examples
05/22/2022 10:45:42 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/22/2022 10:45:42 - INFO - __main__ - ['false']
05/22/2022 10:45:42 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/22/2022 10:45:42 - INFO - __main__ - ['false']
05/22/2022 10:45:42 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/22/2022 10:45:42 - INFO - __main__ - ['false']
05/22/2022 10:45:42 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:45:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:45:42 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 10:45:42 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 10:45:42 - INFO - __main__ - Printing 3 examples
05/22/2022 10:45:42 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/22/2022 10:45:42 - INFO - __main__ - ['false']
05/22/2022 10:45:42 - INFO - __main__ -  [ethos-religion] Trans are using the same logic feminists have been using for decades to destroy men so i don&#39t feel sorry for wamen not one bit!
05/22/2022 10:45:42 - INFO - __main__ - ['false']
05/22/2022 10:45:42 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 10:45:42 - INFO - __main__ - ['false']
05/22/2022 10:45:42 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:45:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:45:43 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 10:45:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 10:45:55 - INFO - __main__ - Starting training!
05/22/2022 10:45:59 - INFO - __main__ - Step 10 Global step 10 Train loss 23.638340 on epoch=0
05/22/2022 10:46:05 - INFO - __main__ - Step 20 Global step 20 Train loss 19.186733 on epoch=1
05/22/2022 10:46:10 - INFO - __main__ - Step 30 Global step 30 Train loss 16.832821 on epoch=2
05/22/2022 10:46:15 - INFO - __main__ - Step 40 Global step 40 Train loss 15.313138 on epoch=3
05/22/2022 10:46:20 - INFO - __main__ - Step 50 Global step 50 Train loss 14.062347 on epoch=4
05/22/2022 10:46:58 - INFO - __main__ - Global step 50 Train loss 17.806675 Classification-F1 0.0 on epoch=4
05/22/2022 10:47:04 - INFO - __main__ - Step 60 Global step 60 Train loss 13.188910 on epoch=4
05/22/2022 10:47:09 - INFO - __main__ - Step 70 Global step 70 Train loss 12.215894 on epoch=5
05/22/2022 10:47:14 - INFO - __main__ - Step 80 Global step 80 Train loss 9.787323 on epoch=6
05/22/2022 10:47:19 - INFO - __main__ - Step 90 Global step 90 Train loss 3.807916 on epoch=7
05/22/2022 10:47:24 - INFO - __main__ - Step 100 Global step 100 Train loss 4.663209 on epoch=8
05/22/2022 10:47:26 - INFO - __main__ - Global step 100 Train loss 8.732650 Classification-F1 1.0 on epoch=8
05/22/2022 10:47:32 - INFO - __main__ - Step 110 Global step 110 Train loss 3.018634 on epoch=9
05/22/2022 10:47:37 - INFO - __main__ - Step 120 Global step 120 Train loss 2.996610 on epoch=9
05/22/2022 10:47:42 - INFO - __main__ - Step 130 Global step 130 Train loss 1.246234 on epoch=10
05/22/2022 10:47:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.585687 on epoch=11
05/22/2022 10:47:52 - INFO - __main__ - Step 150 Global step 150 Train loss 0.593279 on epoch=12
05/22/2022 10:47:54 - INFO - __main__ - Global step 150 Train loss 1.688089 Classification-F1 1.0 on epoch=12
05/22/2022 10:47:59 - INFO - __main__ - Step 160 Global step 160 Train loss 0.513566 on epoch=13
05/22/2022 10:48:04 - INFO - __main__ - Step 170 Global step 170 Train loss 0.374593 on epoch=14
05/22/2022 10:48:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.419946 on epoch=14
05/22/2022 10:48:14 - INFO - __main__ - Step 190 Global step 190 Train loss 0.391781 on epoch=15
05/22/2022 10:48:19 - INFO - __main__ - Step 200 Global step 200 Train loss 0.410295 on epoch=16
05/22/2022 10:48:21 - INFO - __main__ - Global step 200 Train loss 0.422036 Classification-F1 1.0 on epoch=16
05/22/2022 10:48:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.371423 on epoch=17
05/22/2022 10:48:31 - INFO - __main__ - Step 220 Global step 220 Train loss 0.316896 on epoch=18
05/22/2022 10:48:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.402780 on epoch=19
05/22/2022 10:48:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.256968 on epoch=19
05/22/2022 10:48:46 - INFO - __main__ - Step 250 Global step 250 Train loss 0.513471 on epoch=20
05/22/2022 10:48:48 - INFO - __main__ - Global step 250 Train loss 0.372308 Classification-F1 0.4900398406374502 on epoch=20
05/22/2022 10:48:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.382455 on epoch=21
05/22/2022 10:48:58 - INFO - __main__ - Step 270 Global step 270 Train loss 0.348264 on epoch=22
05/22/2022 10:49:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.241604 on epoch=23
05/22/2022 10:49:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.218217 on epoch=24
05/22/2022 10:49:14 - INFO - __main__ - Step 300 Global step 300 Train loss 0.262649 on epoch=24
05/22/2022 10:49:15 - INFO - __main__ - Global step 300 Train loss 0.290638 Classification-F1 0.488 on epoch=24
05/22/2022 10:49:20 - INFO - __main__ - Step 310 Global step 310 Train loss 0.374073 on epoch=25
05/22/2022 10:49:25 - INFO - __main__ - Step 320 Global step 320 Train loss 0.306732 on epoch=26
05/22/2022 10:49:31 - INFO - __main__ - Step 330 Global step 330 Train loss 0.269136 on epoch=27
05/22/2022 10:49:36 - INFO - __main__ - Step 340 Global step 340 Train loss 0.276270 on epoch=28
05/22/2022 10:49:41 - INFO - __main__ - Step 350 Global step 350 Train loss 0.242897 on epoch=29
05/22/2022 10:49:42 - INFO - __main__ - Global step 350 Train loss 0.293822 Classification-F1 0.49407114624505927 on epoch=29
05/22/2022 10:49:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.199970 on epoch=29
05/22/2022 10:49:53 - INFO - __main__ - Step 370 Global step 370 Train loss 0.255795 on epoch=30
05/22/2022 10:49:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.188447 on epoch=31
05/22/2022 10:50:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.128567 on epoch=32
05/22/2022 10:50:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.180004 on epoch=33
05/22/2022 10:50:09 - INFO - __main__ - Global step 400 Train loss 0.190557 Classification-F1 0.488 on epoch=33
05/22/2022 10:50:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.208591 on epoch=34
05/22/2022 10:50:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.216154 on epoch=34
05/22/2022 10:50:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.194158 on epoch=35
05/22/2022 10:50:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.231178 on epoch=36
05/22/2022 10:50:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.199221 on epoch=37
05/22/2022 10:50:37 - INFO - __main__ - Global step 450 Train loss 0.209861 Classification-F1 0.488 on epoch=37
05/22/2022 10:50:42 - INFO - __main__ - Step 460 Global step 460 Train loss 0.155844 on epoch=38
05/22/2022 10:50:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.208580 on epoch=39
05/22/2022 10:50:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.188802 on epoch=39
05/22/2022 10:50:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.179680 on epoch=40
05/22/2022 10:51:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.107784 on epoch=41
05/22/2022 10:51:04 - INFO - __main__ - Global step 500 Train loss 0.168138 Classification-F1 0.49206349206349204 on epoch=41
05/22/2022 10:51:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.228065 on epoch=42
05/22/2022 10:51:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.131905 on epoch=43
05/22/2022 10:51:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.184108 on epoch=44
05/22/2022 10:51:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.116351 on epoch=44
05/22/2022 10:51:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.190659 on epoch=45
05/22/2022 10:51:31 - INFO - __main__ - Global step 550 Train loss 0.170218 Classification-F1 0.49407114624505927 on epoch=45
05/22/2022 10:51:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.082121 on epoch=46
05/22/2022 10:51:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.101801 on epoch=47
05/22/2022 10:51:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.226767 on epoch=48
05/22/2022 10:51:51 - INFO - __main__ - Step 590 Global step 590 Train loss 0.197289 on epoch=49
05/22/2022 10:51:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.176713 on epoch=49
05/22/2022 10:51:58 - INFO - __main__ - Global step 600 Train loss 0.156938 Classification-F1 0.4900398406374502 on epoch=49
05/22/2022 10:52:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.183163 on epoch=50
05/22/2022 10:52:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.106710 on epoch=51
05/22/2022 10:52:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.079464 on epoch=52
05/22/2022 10:52:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.042662 on epoch=53
05/22/2022 10:52:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.102671 on epoch=54
05/22/2022 10:52:25 - INFO - __main__ - Global step 650 Train loss 0.102934 Classification-F1 0.4859437751004016 on epoch=54
05/22/2022 10:52:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.047672 on epoch=54
05/22/2022 10:52:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.051003 on epoch=55
05/22/2022 10:52:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.045015 on epoch=56
05/22/2022 10:52:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.135213 on epoch=57
05/22/2022 10:52:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.202962 on epoch=58
05/22/2022 10:52:52 - INFO - __main__ - Global step 700 Train loss 0.096373 Classification-F1 0.4859437751004016 on epoch=58
05/22/2022 10:52:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.172608 on epoch=59
05/22/2022 10:53:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.128916 on epoch=59
05/22/2022 10:53:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.204871 on epoch=60
05/22/2022 10:53:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.124117 on epoch=61
05/22/2022 10:53:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.161304 on epoch=62
05/22/2022 10:53:19 - INFO - __main__ - Global step 750 Train loss 0.158363 Classification-F1 0.49407114624505927 on epoch=62
05/22/2022 10:53:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.104635 on epoch=63
05/22/2022 10:53:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.097273 on epoch=64
05/22/2022 10:53:34 - INFO - __main__ - Step 780 Global step 780 Train loss 0.066903 on epoch=64
05/22/2022 10:53:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.100739 on epoch=65
05/22/2022 10:53:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.095529 on epoch=66
05/22/2022 10:53:46 - INFO - __main__ - Global step 800 Train loss 0.093016 Classification-F1 0.47107438016528924 on epoch=66
05/22/2022 10:53:51 - INFO - __main__ - Step 810 Global step 810 Train loss 0.063189 on epoch=67
05/22/2022 10:53:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.041762 on epoch=68
05/22/2022 10:54:01 - INFO - __main__ - Step 830 Global step 830 Train loss 0.046400 on epoch=69
05/22/2022 10:54:06 - INFO - __main__ - Step 840 Global step 840 Train loss 0.008697 on epoch=69
05/22/2022 10:54:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.025268 on epoch=70
05/22/2022 10:54:13 - INFO - __main__ - Global step 850 Train loss 0.037063 Classification-F1 0.4900398406374502 on epoch=70
05/22/2022 10:54:18 - INFO - __main__ - Step 860 Global step 860 Train loss 0.061155 on epoch=71
05/22/2022 10:54:23 - INFO - __main__ - Step 870 Global step 870 Train loss 0.115724 on epoch=72
05/22/2022 10:54:28 - INFO - __main__ - Step 880 Global step 880 Train loss 0.036343 on epoch=73
05/22/2022 10:54:33 - INFO - __main__ - Step 890 Global step 890 Train loss 0.064212 on epoch=74
05/22/2022 10:54:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.026014 on epoch=74
05/22/2022 10:54:40 - INFO - __main__ - Global step 900 Train loss 0.060690 Classification-F1 0.4900398406374502 on epoch=74
05/22/2022 10:54:45 - INFO - __main__ - Step 910 Global step 910 Train loss 0.059100 on epoch=75
05/22/2022 10:54:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.043724 on epoch=76
05/22/2022 10:54:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.052804 on epoch=77
05/22/2022 10:55:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.012600 on epoch=78
05/22/2022 10:55:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.046224 on epoch=79
05/22/2022 10:55:07 - INFO - __main__ - Global step 950 Train loss 0.042891 Classification-F1 0.4900398406374502 on epoch=79
05/22/2022 10:55:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.053531 on epoch=79
05/22/2022 10:55:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.019712 on epoch=80
05/22/2022 10:55:22 - INFO - __main__ - Step 980 Global step 980 Train loss 0.065105 on epoch=81
05/22/2022 10:55:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.027632 on epoch=82
05/22/2022 10:55:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.010038 on epoch=83
05/22/2022 10:55:34 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 10:55:34 - INFO - __main__ - Printing 3 examples
05/22/2022 10:55:34 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/22/2022 10:55:34 - INFO - __main__ - ['false']
05/22/2022 10:55:34 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/22/2022 10:55:34 - INFO - __main__ - ['false']
05/22/2022 10:55:34 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/22/2022 10:55:34 - INFO - __main__ - ['false']
05/22/2022 10:55:34 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:55:34 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:55:34 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 10:55:34 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 10:55:34 - INFO - __main__ - Printing 3 examples
05/22/2022 10:55:34 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/22/2022 10:55:34 - INFO - __main__ - ['false']
05/22/2022 10:55:34 - INFO - __main__ -  [ethos-religion] Trans are using the same logic feminists have been using for decades to destroy men so i don&#39t feel sorry for wamen not one bit!
05/22/2022 10:55:34 - INFO - __main__ - ['false']
05/22/2022 10:55:34 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 10:55:34 - INFO - __main__ - ['false']
05/22/2022 10:55:34 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:55:34 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:55:34 - INFO - __main__ - Global step 1000 Train loss 0.035204 Classification-F1 0.49206349206349204 on epoch=83
05/22/2022 10:55:34 - INFO - __main__ - save last model!
05/22/2022 10:55:34 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 10:55:41 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 10:55:42 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 10:55:42 - INFO - __main__ - Printing 3 examples
05/22/2022 10:55:42 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 10:55:42 - INFO - __main__ - ['false']
05/22/2022 10:55:42 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 10:55:42 - INFO - __main__ - ['false']
05/22/2022 10:55:42 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 10:55:42 - INFO - __main__ - ['true']
05/22/2022 10:55:42 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:55:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:55:42 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 10:55:43 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_87_0.0003_8_predictions.txt
05/22/2022 10:55:43 - INFO - __main__ - Classification-F1 on test data: 0.4387
05/22/2022 10:55:44 - INFO - __main__ - prefix=ethos-religion_128_87, lr=0.0003, bsz=8, dev_performance=1.0, test_performance=0.4387096774193549
05/22/2022 10:55:44 - INFO - __main__ - Running ... prefix=ethos-religion_128_87, lr=0.0002, bsz=8 ...
05/22/2022 10:55:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 10:55:44 - INFO - __main__ - Starting training!
05/22/2022 10:55:44 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 10:55:44 - INFO - __main__ - Printing 3 examples
05/22/2022 10:55:44 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/22/2022 10:55:44 - INFO - __main__ - ['false']
05/22/2022 10:55:44 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/22/2022 10:55:44 - INFO - __main__ - ['false']
05/22/2022 10:55:44 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/22/2022 10:55:44 - INFO - __main__ - ['false']
05/22/2022 10:55:44 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:55:45 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:55:45 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 10:55:45 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 10:55:45 - INFO - __main__ - Printing 3 examples
05/22/2022 10:55:45 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/22/2022 10:55:45 - INFO - __main__ - ['false']
05/22/2022 10:55:45 - INFO - __main__ -  [ethos-religion] Trans are using the same logic feminists have been using for decades to destroy men so i don&#39t feel sorry for wamen not one bit!
05/22/2022 10:55:45 - INFO - __main__ - ['false']
05/22/2022 10:55:45 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 10:55:45 - INFO - __main__ - ['false']
05/22/2022 10:55:45 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:55:45 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:55:45 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 10:55:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 10:55:58 - INFO - __main__ - Starting training!
05/22/2022 10:56:02 - INFO - __main__ - Step 10 Global step 10 Train loss 23.697191 on epoch=0
05/22/2022 10:56:07 - INFO - __main__ - Step 20 Global step 20 Train loss 19.586203 on epoch=1
05/22/2022 10:56:12 - INFO - __main__ - Step 30 Global step 30 Train loss 17.465767 on epoch=2
05/22/2022 10:56:17 - INFO - __main__ - Step 40 Global step 40 Train loss 16.311939 on epoch=3
05/22/2022 10:56:22 - INFO - __main__ - Step 50 Global step 50 Train loss 15.549408 on epoch=4
05/22/2022 10:56:42 - INFO - __main__ - Global step 50 Train loss 18.522100 Classification-F1 0.0 on epoch=4
05/22/2022 10:56:48 - INFO - __main__ - Step 60 Global step 60 Train loss 14.436424 on epoch=4
05/22/2022 10:56:53 - INFO - __main__ - Step 70 Global step 70 Train loss 13.940741 on epoch=5
05/22/2022 10:56:58 - INFO - __main__ - Step 80 Global step 80 Train loss 13.305202 on epoch=6
05/22/2022 10:57:03 - INFO - __main__ - Step 90 Global step 90 Train loss 12.363908 on epoch=7
05/22/2022 10:57:08 - INFO - __main__ - Step 100 Global step 100 Train loss 11.335638 on epoch=8
05/22/2022 10:57:10 - INFO - __main__ - Global step 100 Train loss 13.076382 Classification-F1 0.0 on epoch=8
05/22/2022 10:57:15 - INFO - __main__ - Step 110 Global step 110 Train loss 5.994960 on epoch=9
05/22/2022 10:57:20 - INFO - __main__ - Step 120 Global step 120 Train loss 3.232100 on epoch=9
05/22/2022 10:57:25 - INFO - __main__ - Step 130 Global step 130 Train loss 0.679534 on epoch=10
05/22/2022 10:57:30 - INFO - __main__ - Step 140 Global step 140 Train loss 0.610616 on epoch=11
05/22/2022 10:57:36 - INFO - __main__ - Step 150 Global step 150 Train loss 0.477556 on epoch=12
05/22/2022 10:57:37 - INFO - __main__ - Global step 150 Train loss 2.198953 Classification-F1 1.0 on epoch=12
05/22/2022 10:57:43 - INFO - __main__ - Step 160 Global step 160 Train loss 0.449513 on epoch=13
05/22/2022 10:57:49 - INFO - __main__ - Step 170 Global step 170 Train loss 0.414856 on epoch=14
05/22/2022 10:57:54 - INFO - __main__ - Step 180 Global step 180 Train loss 0.309798 on epoch=14
05/22/2022 10:57:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.257062 on epoch=15
05/22/2022 10:58:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.251807 on epoch=16
05/22/2022 10:58:05 - INFO - __main__ - Global step 200 Train loss 0.336607 Classification-F1 0.46887966804979253 on epoch=16
05/22/2022 10:58:11 - INFO - __main__ - Step 210 Global step 210 Train loss 0.212792 on epoch=17
05/22/2022 10:58:16 - INFO - __main__ - Step 220 Global step 220 Train loss 0.235528 on epoch=18
05/22/2022 10:58:21 - INFO - __main__ - Step 230 Global step 230 Train loss 0.200752 on epoch=19
05/22/2022 10:58:26 - INFO - __main__ - Step 240 Global step 240 Train loss 0.191265 on epoch=19
05/22/2022 10:58:31 - INFO - __main__ - Step 250 Global step 250 Train loss 0.257120 on epoch=20
05/22/2022 10:58:32 - INFO - __main__ - Global step 250 Train loss 0.219492 Classification-F1 0.49606299212598426 on epoch=20
05/22/2022 10:58:37 - INFO - __main__ - Step 260 Global step 260 Train loss 0.244982 on epoch=21
05/22/2022 10:58:43 - INFO - __main__ - Step 270 Global step 270 Train loss 0.484051 on epoch=22
05/22/2022 10:58:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.111343 on epoch=23
05/22/2022 10:58:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.121574 on epoch=24
05/22/2022 10:58:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.073307 on epoch=24
05/22/2022 10:58:59 - INFO - __main__ - Global step 300 Train loss 0.207051 Classification-F1 0.49206349206349204 on epoch=24
05/22/2022 10:59:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.120628 on epoch=25
05/22/2022 10:59:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.206754 on epoch=26
05/22/2022 10:59:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.079665 on epoch=27
05/22/2022 10:59:20 - INFO - __main__ - Step 340 Global step 340 Train loss 0.085687 on epoch=28
05/22/2022 10:59:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.075018 on epoch=29
05/22/2022 10:59:27 - INFO - __main__ - Global step 350 Train loss 0.113550 Classification-F1 0.49606299212598426 on epoch=29
05/22/2022 10:59:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.143962 on epoch=29
05/22/2022 10:59:37 - INFO - __main__ - Step 370 Global step 370 Train loss 0.067645 on epoch=30
05/22/2022 10:59:42 - INFO - __main__ - Step 380 Global step 380 Train loss 0.084713 on epoch=31
05/22/2022 10:59:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.391463 on epoch=32
05/22/2022 10:59:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.098317 on epoch=33
05/22/2022 10:59:53 - INFO - __main__ - Global step 400 Train loss 0.157220 Classification-F1 0.488 on epoch=33
05/22/2022 10:59:58 - INFO - __main__ - Step 410 Global step 410 Train loss 0.084803 on epoch=34
05/22/2022 11:00:04 - INFO - __main__ - Step 420 Global step 420 Train loss 0.051196 on epoch=34
05/22/2022 11:00:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.062937 on epoch=35
05/22/2022 11:00:14 - INFO - __main__ - Step 440 Global step 440 Train loss 0.083668 on epoch=36
05/22/2022 11:00:19 - INFO - __main__ - Step 450 Global step 450 Train loss 0.042483 on epoch=37
05/22/2022 11:00:20 - INFO - __main__ - Global step 450 Train loss 0.065017 Classification-F1 0.4838709677419355 on epoch=37
05/22/2022 11:00:26 - INFO - __main__ - Step 460 Global step 460 Train loss 0.044440 on epoch=38
05/22/2022 11:00:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.056668 on epoch=39
05/22/2022 11:00:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.038101 on epoch=39
05/22/2022 11:00:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.020851 on epoch=40
05/22/2022 11:00:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.023445 on epoch=41
05/22/2022 11:00:48 - INFO - __main__ - Global step 500 Train loss 0.036701 Classification-F1 0.49206349206349204 on epoch=41
05/22/2022 11:00:53 - INFO - __main__ - Step 510 Global step 510 Train loss 0.063006 on epoch=42
05/22/2022 11:00:58 - INFO - __main__ - Step 520 Global step 520 Train loss 0.004361 on epoch=43
05/22/2022 11:01:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.053464 on epoch=44
05/22/2022 11:01:08 - INFO - __main__ - Step 540 Global step 540 Train loss 0.044960 on epoch=44
05/22/2022 11:01:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.032325 on epoch=45
05/22/2022 11:01:15 - INFO - __main__ - Global step 550 Train loss 0.039623 Classification-F1 0.49206349206349204 on epoch=45
05/22/2022 11:01:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.031214 on epoch=46
05/22/2022 11:01:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.030475 on epoch=47
05/22/2022 11:01:30 - INFO - __main__ - Step 580 Global step 580 Train loss 0.029177 on epoch=48
05/22/2022 11:01:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.018752 on epoch=49
05/22/2022 11:01:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.042496 on epoch=49
05/22/2022 11:01:42 - INFO - __main__ - Global step 600 Train loss 0.030423 Classification-F1 0.49407114624505927 on epoch=49
05/22/2022 11:01:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.010749 on epoch=50
05/22/2022 11:01:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.032732 on epoch=51
05/22/2022 11:01:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.012886 on epoch=52
05/22/2022 11:02:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.025769 on epoch=53
05/22/2022 11:02:08 - INFO - __main__ - Step 650 Global step 650 Train loss 0.025759 on epoch=54
05/22/2022 11:02:09 - INFO - __main__ - Global step 650 Train loss 0.021579 Classification-F1 0.49606299212598426 on epoch=54
05/22/2022 11:02:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.036732 on epoch=54
05/22/2022 11:02:19 - INFO - __main__ - Step 670 Global step 670 Train loss 0.026514 on epoch=55
05/22/2022 11:02:25 - INFO - __main__ - Step 680 Global step 680 Train loss 0.016380 on epoch=56
05/22/2022 11:02:30 - INFO - __main__ - Step 690 Global step 690 Train loss 0.013537 on epoch=57
05/22/2022 11:02:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.014833 on epoch=58
05/22/2022 11:02:36 - INFO - __main__ - Global step 700 Train loss 0.021599 Classification-F1 0.49606299212598426 on epoch=58
05/22/2022 11:02:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.037700 on epoch=59
05/22/2022 11:02:46 - INFO - __main__ - Step 720 Global step 720 Train loss 0.014888 on epoch=59
05/22/2022 11:02:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.004592 on epoch=60
05/22/2022 11:02:57 - INFO - __main__ - Step 740 Global step 740 Train loss 0.042840 on epoch=61
05/22/2022 11:03:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.032651 on epoch=62
05/22/2022 11:03:03 - INFO - __main__ - Global step 750 Train loss 0.026534 Classification-F1 0.49407114624505927 on epoch=62
05/22/2022 11:03:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.016883 on epoch=63
05/22/2022 11:03:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.008851 on epoch=64
05/22/2022 11:03:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.025422 on epoch=64
05/22/2022 11:03:24 - INFO - __main__ - Step 790 Global step 790 Train loss 0.009455 on epoch=65
05/22/2022 11:03:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.015310 on epoch=66
05/22/2022 11:03:30 - INFO - __main__ - Global step 800 Train loss 0.015184 Classification-F1 0.49606299212598426 on epoch=66
05/22/2022 11:03:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.028688 on epoch=67
05/22/2022 11:03:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.004194 on epoch=68
05/22/2022 11:03:46 - INFO - __main__ - Step 830 Global step 830 Train loss 0.007262 on epoch=69
05/22/2022 11:03:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.047005 on epoch=69
05/22/2022 11:03:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.043299 on epoch=70
05/22/2022 11:03:57 - INFO - __main__ - Global step 850 Train loss 0.026090 Classification-F1 0.488 on epoch=70
05/22/2022 11:04:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.040018 on epoch=71
05/22/2022 11:04:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.001235 on epoch=72
05/22/2022 11:04:12 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000299 on epoch=73
05/22/2022 11:04:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.011829 on epoch=74
05/22/2022 11:04:23 - INFO - __main__ - Step 900 Global step 900 Train loss 0.020045 on epoch=74
05/22/2022 11:04:24 - INFO - __main__ - Global step 900 Train loss 0.014685 Classification-F1 0.4900398406374502 on epoch=74
05/22/2022 11:04:29 - INFO - __main__ - Step 910 Global step 910 Train loss 0.019193 on epoch=75
05/22/2022 11:04:34 - INFO - __main__ - Step 920 Global step 920 Train loss 0.056201 on epoch=76
05/22/2022 11:04:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.020064 on epoch=77
05/22/2022 11:04:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.017771 on epoch=78
05/22/2022 11:04:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.011952 on epoch=79
05/22/2022 11:04:51 - INFO - __main__ - Global step 950 Train loss 0.025036 Classification-F1 0.49606299212598426 on epoch=79
05/22/2022 11:04:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.107048 on epoch=79
05/22/2022 11:05:01 - INFO - __main__ - Step 970 Global step 970 Train loss 0.077419 on epoch=80
05/22/2022 11:05:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.041882 on epoch=81
05/22/2022 11:05:11 - INFO - __main__ - Step 990 Global step 990 Train loss 0.003788 on epoch=82
05/22/2022 11:05:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.007758 on epoch=83
05/22/2022 11:05:18 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 11:05:18 - INFO - __main__ - Printing 3 examples
05/22/2022 11:05:18 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/22/2022 11:05:18 - INFO - __main__ - ['false']
05/22/2022 11:05:18 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/22/2022 11:05:18 - INFO - __main__ - ['false']
05/22/2022 11:05:18 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/22/2022 11:05:18 - INFO - __main__ - ['false']
05/22/2022 11:05:18 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:05:18 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:05:18 - INFO - __main__ - Global step 1000 Train loss 0.047579 Classification-F1 0.4980392156862745 on epoch=83
05/22/2022 11:05:18 - INFO - __main__ - save last model!
05/22/2022 11:05:18 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 11:05:18 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 11:05:18 - INFO - __main__ - Printing 3 examples
05/22/2022 11:05:18 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/22/2022 11:05:18 - INFO - __main__ - ['false']
05/22/2022 11:05:18 - INFO - __main__ -  [ethos-religion] Trans are using the same logic feminists have been using for decades to destroy men so i don&#39t feel sorry for wamen not one bit!
05/22/2022 11:05:18 - INFO - __main__ - ['false']
05/22/2022 11:05:18 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 11:05:18 - INFO - __main__ - ['false']
05/22/2022 11:05:18 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:05:18 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:05:18 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 11:05:25 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 11:05:26 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 11:05:26 - INFO - __main__ - Printing 3 examples
05/22/2022 11:05:26 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 11:05:26 - INFO - __main__ - ['false']
05/22/2022 11:05:26 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 11:05:26 - INFO - __main__ - ['false']
05/22/2022 11:05:26 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 11:05:26 - INFO - __main__ - ['true']
05/22/2022 11:05:26 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:05:26 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:05:26 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 11:05:27 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_87_0.0002_8_predictions.txt
05/22/2022 11:05:27 - INFO - __main__ - Classification-F1 on test data: 0.4916
05/22/2022 11:05:28 - INFO - __main__ - prefix=ethos-religion_128_87, lr=0.0002, bsz=8, dev_performance=1.0, test_performance=0.49155844155844153
05/22/2022 11:05:28 - INFO - __main__ - Running ... prefix=ethos-religion_128_87, lr=0.0001, bsz=8 ...
05/22/2022 11:05:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 11:05:28 - INFO - __main__ - Start tokenizing ... 190 instances
05/22/2022 11:05:28 - INFO - __main__ - Printing 3 examples
05/22/2022 11:05:28 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/22/2022 11:05:28 - INFO - __main__ - ['false']
05/22/2022 11:05:28 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/22/2022 11:05:28 - INFO - __main__ - ['false']
05/22/2022 11:05:28 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/22/2022 11:05:28 - INFO - __main__ - ['false']
05/22/2022 11:05:28 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:05:28 - INFO - __main__ - Starting training!
05/22/2022 11:05:29 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:05:29 - INFO - __main__ - Loaded 190 examples from train data
05/22/2022 11:05:29 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 11:05:29 - INFO - __main__ - Printing 3 examples
05/22/2022 11:05:29 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/22/2022 11:05:29 - INFO - __main__ - ['false']
05/22/2022 11:05:29 - INFO - __main__ -  [ethos-religion] Trans are using the same logic feminists have been using for decades to destroy men so i don&#39t feel sorry for wamen not one bit!
05/22/2022 11:05:29 - INFO - __main__ - ['false']
05/22/2022 11:05:29 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/22/2022 11:05:29 - INFO - __main__ - ['false']
05/22/2022 11:05:29 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:05:29 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:05:29 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 11:05:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/22/2022 11:05:42 - INFO - __main__ - Starting training!
05/22/2022 11:05:46 - INFO - __main__ - Step 10 Global step 10 Train loss 23.276442 on epoch=0
05/22/2022 11:05:51 - INFO - __main__ - Step 20 Global step 20 Train loss 20.784786 on epoch=1
05/22/2022 11:05:56 - INFO - __main__ - Step 30 Global step 30 Train loss 18.763102 on epoch=2
05/22/2022 11:06:01 - INFO - __main__ - Step 40 Global step 40 Train loss 17.002228 on epoch=3
05/22/2022 11:06:06 - INFO - __main__ - Step 50 Global step 50 Train loss 17.614309 on epoch=4
05/22/2022 11:06:46 - INFO - __main__ - Global step 50 Train loss 19.488174 Classification-F1 0.0 on epoch=4
05/22/2022 11:06:51 - INFO - __main__ - Step 60 Global step 60 Train loss 16.786316 on epoch=4
05/22/2022 11:06:57 - INFO - __main__ - Step 70 Global step 70 Train loss 15.988764 on epoch=5
05/22/2022 11:07:02 - INFO - __main__ - Step 80 Global step 80 Train loss 16.791765 on epoch=6
05/22/2022 11:07:07 - INFO - __main__ - Step 90 Global step 90 Train loss 16.165934 on epoch=7
05/22/2022 11:07:12 - INFO - __main__ - Step 100 Global step 100 Train loss 14.478671 on epoch=8
05/22/2022 11:07:52 - INFO - __main__ - Global step 100 Train loss 16.042290 Classification-F1 0.0 on epoch=8
05/22/2022 11:07:57 - INFO - __main__ - Step 110 Global step 110 Train loss 14.093788 on epoch=9
05/22/2022 11:08:02 - INFO - __main__ - Step 120 Global step 120 Train loss 14.274211 on epoch=9
05/22/2022 11:08:07 - INFO - __main__ - Step 130 Global step 130 Train loss 13.854620 on epoch=10
05/22/2022 11:08:13 - INFO - __main__ - Step 140 Global step 140 Train loss 13.542313 on epoch=11
05/22/2022 11:08:18 - INFO - __main__ - Step 150 Global step 150 Train loss 13.124741 on epoch=12
05/22/2022 11:08:57 - INFO - __main__ - Global step 150 Train loss 13.777935 Classification-F1 0.0 on epoch=12
05/22/2022 11:09:02 - INFO - __main__ - Step 160 Global step 160 Train loss 13.190092 on epoch=13
05/22/2022 11:09:07 - INFO - __main__ - Step 170 Global step 170 Train loss 11.907898 on epoch=14
05/22/2022 11:09:13 - INFO - __main__ - Step 180 Global step 180 Train loss 10.187854 on epoch=14
05/22/2022 11:09:18 - INFO - __main__ - Step 190 Global step 190 Train loss 10.425969 on epoch=15
05/22/2022 11:09:23 - INFO - __main__ - Step 200 Global step 200 Train loss 9.562504 on epoch=16
05/22/2022 11:09:59 - INFO - __main__ - Global step 200 Train loss 11.054863 Classification-F1 0.0008327550312283137 on epoch=16
05/22/2022 11:10:05 - INFO - __main__ - Step 210 Global step 210 Train loss 5.504142 on epoch=17
05/22/2022 11:10:10 - INFO - __main__ - Step 220 Global step 220 Train loss 4.126673 on epoch=18
05/22/2022 11:10:16 - INFO - __main__ - Step 230 Global step 230 Train loss 4.046988 on epoch=19
05/22/2022 11:10:21 - INFO - __main__ - Step 240 Global step 240 Train loss 3.355735 on epoch=19
05/22/2022 11:10:26 - INFO - __main__ - Step 250 Global step 250 Train loss 3.449292 on epoch=20
05/22/2022 11:10:27 - INFO - __main__ - Global step 250 Train loss 4.096566 Classification-F1 0.4900398406374502 on epoch=20
05/22/2022 11:10:33 - INFO - __main__ - Step 260 Global step 260 Train loss 3.204492 on epoch=21
05/22/2022 11:10:38 - INFO - __main__ - Step 270 Global step 270 Train loss 2.513668 on epoch=22
05/22/2022 11:10:43 - INFO - __main__ - Step 280 Global step 280 Train loss 1.728000 on epoch=23
05/22/2022 11:10:48 - INFO - __main__ - Step 290 Global step 290 Train loss 0.907557 on epoch=24
05/22/2022 11:10:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.709792 on epoch=24
05/22/2022 11:10:55 - INFO - __main__ - Global step 300 Train loss 1.812702 Classification-F1 0.46218487394957986 on epoch=24
05/22/2022 11:11:00 - INFO - __main__ - Step 310 Global step 310 Train loss 0.698122 on epoch=25
05/22/2022 11:11:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.542812 on epoch=26
05/22/2022 11:11:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.414008 on epoch=27
05/22/2022 11:11:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.367196 on epoch=28
05/22/2022 11:11:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.444339 on epoch=29
05/22/2022 11:11:22 - INFO - __main__ - Global step 350 Train loss 0.493295 Classification-F1 1.0 on epoch=29
05/22/2022 11:11:28 - INFO - __main__ - Step 360 Global step 360 Train loss 0.477914 on epoch=29
05/22/2022 11:11:33 - INFO - __main__ - Step 370 Global step 370 Train loss 0.343409 on epoch=30
05/22/2022 11:11:38 - INFO - __main__ - Step 380 Global step 380 Train loss 0.337769 on epoch=31
05/22/2022 11:11:43 - INFO - __main__ - Step 390 Global step 390 Train loss 0.370724 on epoch=32
05/22/2022 11:11:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.320222 on epoch=33
05/22/2022 11:11:50 - INFO - __main__ - Global step 400 Train loss 0.370008 Classification-F1 0.4410480349344978 on epoch=33
05/22/2022 11:11:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.331242 on epoch=34
05/22/2022 11:12:00 - INFO - __main__ - Step 420 Global step 420 Train loss 0.269466 on epoch=34
05/22/2022 11:12:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.349429 on epoch=35
05/22/2022 11:12:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.277182 on epoch=36
05/22/2022 11:12:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.285763 on epoch=37
05/22/2022 11:12:16 - INFO - __main__ - Global step 450 Train loss 0.302617 Classification-F1 0.4838709677419355 on epoch=37
05/22/2022 11:12:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.262309 on epoch=38
05/22/2022 11:12:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.203216 on epoch=39
05/22/2022 11:12:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.260246 on epoch=39
05/22/2022 11:12:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.292830 on epoch=40
05/22/2022 11:12:42 - INFO - __main__ - Step 500 Global step 500 Train loss 0.238123 on epoch=41
05/22/2022 11:12:43 - INFO - __main__ - Global step 500 Train loss 0.251345 Classification-F1 0.488 on epoch=41
05/22/2022 11:12:49 - INFO - __main__ - Step 510 Global step 510 Train loss 0.307692 on epoch=42
05/22/2022 11:12:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.169220 on epoch=43
05/22/2022 11:12:59 - INFO - __main__ - Step 530 Global step 530 Train loss 0.209481 on epoch=44
05/22/2022 11:13:04 - INFO - __main__ - Step 540 Global step 540 Train loss 0.275101 on epoch=44
05/22/2022 11:13:09 - INFO - __main__ - Step 550 Global step 550 Train loss 0.238515 on epoch=45
05/22/2022 11:13:11 - INFO - __main__ - Global step 550 Train loss 0.240002 Classification-F1 0.49606299212598426 on epoch=45
05/22/2022 11:13:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.210593 on epoch=46
05/22/2022 11:13:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.207431 on epoch=47
05/22/2022 11:13:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.174522 on epoch=48
05/22/2022 11:13:31 - INFO - __main__ - Step 590 Global step 590 Train loss 0.245072 on epoch=49
05/22/2022 11:13:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.180844 on epoch=49
05/22/2022 11:13:38 - INFO - __main__ - Global step 600 Train loss 0.203692 Classification-F1 0.49407114624505927 on epoch=49
05/22/2022 11:13:43 - INFO - __main__ - Step 610 Global step 610 Train loss 0.208442 on epoch=50
05/22/2022 11:13:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.161902 on epoch=51
05/22/2022 11:13:53 - INFO - __main__ - Step 630 Global step 630 Train loss 0.172543 on epoch=52
05/22/2022 11:13:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.157770 on epoch=53
05/22/2022 11:14:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.178487 on epoch=54
05/22/2022 11:14:05 - INFO - __main__ - Global step 650 Train loss 0.175829 Classification-F1 0.49407114624505927 on epoch=54
05/22/2022 11:14:10 - INFO - __main__ - Step 660 Global step 660 Train loss 0.125663 on epoch=54
05/22/2022 11:14:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.172336 on epoch=55
05/22/2022 11:14:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.182664 on epoch=56
05/22/2022 11:14:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.104475 on epoch=57
05/22/2022 11:14:31 - INFO - __main__ - Step 700 Global step 700 Train loss 0.139564 on epoch=58
05/22/2022 11:14:33 - INFO - __main__ - Global step 700 Train loss 0.144940 Classification-F1 0.4796747967479675 on epoch=58
05/22/2022 11:14:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.116880 on epoch=59
05/22/2022 11:14:43 - INFO - __main__ - Step 720 Global step 720 Train loss 0.173301 on epoch=59
05/22/2022 11:14:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.125307 on epoch=60
05/22/2022 11:14:53 - INFO - __main__ - Step 740 Global step 740 Train loss 0.188077 on epoch=61
05/22/2022 11:14:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.131648 on epoch=62
05/22/2022 11:15:00 - INFO - __main__ - Global step 750 Train loss 0.147043 Classification-F1 0.488 on epoch=62
05/22/2022 11:15:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.074200 on epoch=63
05/22/2022 11:15:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.125898 on epoch=64
05/22/2022 11:15:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.108598 on epoch=64
05/22/2022 11:15:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.107504 on epoch=65
05/22/2022 11:15:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.163615 on epoch=66
05/22/2022 11:15:27 - INFO - __main__ - Global step 800 Train loss 0.115963 Classification-F1 0.4900398406374502 on epoch=66
05/22/2022 11:15:32 - INFO - __main__ - Step 810 Global step 810 Train loss 0.085778 on epoch=67
05/22/2022 11:15:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.055801 on epoch=68
05/22/2022 11:15:42 - INFO - __main__ - Step 830 Global step 830 Train loss 0.061207 on epoch=69
05/22/2022 11:15:47 - INFO - __main__ - Step 840 Global step 840 Train loss 0.069545 on epoch=69
05/22/2022 11:15:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.073990 on epoch=70
05/22/2022 11:15:53 - INFO - __main__ - Global step 850 Train loss 0.069264 Classification-F1 0.49407114624505927 on epoch=70
05/22/2022 11:15:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.053749 on epoch=71
05/22/2022 11:16:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.064059 on epoch=72
05/22/2022 11:16:08 - INFO - __main__ - Step 880 Global step 880 Train loss 0.087532 on epoch=73
05/22/2022 11:16:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.045436 on epoch=74
05/22/2022 11:16:18 - INFO - __main__ - Step 900 Global step 900 Train loss 0.062878 on epoch=74
05/22/2022 11:16:20 - INFO - __main__ - Global step 900 Train loss 0.062731 Classification-F1 0.49407114624505927 on epoch=74
05/22/2022 11:16:25 - INFO - __main__ - Step 910 Global step 910 Train loss 0.092236 on epoch=75
05/22/2022 11:16:30 - INFO - __main__ - Step 920 Global step 920 Train loss 0.120393 on epoch=76
05/22/2022 11:16:35 - INFO - __main__ - Step 930 Global step 930 Train loss 0.092907 on epoch=77
05/22/2022 11:16:40 - INFO - __main__ - Step 940 Global step 940 Train loss 0.040695 on epoch=78
05/22/2022 11:16:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.056276 on epoch=79
05/22/2022 11:16:47 - INFO - __main__ - Global step 950 Train loss 0.080501 Classification-F1 0.49606299212598426 on epoch=79
05/22/2022 11:16:52 - INFO - __main__ - Step 960 Global step 960 Train loss 0.042761 on epoch=79
05/22/2022 11:16:57 - INFO - __main__ - Step 970 Global step 970 Train loss 0.092360 on epoch=80
05/22/2022 11:17:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.045072 on epoch=81
05/22/2022 11:17:07 - INFO - __main__ - Step 990 Global step 990 Train loss 0.050720 on epoch=82
05/22/2022 11:17:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.024566 on epoch=83
05/22/2022 11:17:13 - INFO - __main__ - Global step 1000 Train loss 0.051096 Classification-F1 0.49206349206349204 on epoch=83
05/22/2022 11:17:13 - INFO - __main__ - save last model!
05/22/2022 11:17:20 - INFO - __main__ - Loading checkpoint on the fly
05/22/2022 11:17:21 - INFO - __main__ - Start tokenizing ... 87 instances
05/22/2022 11:17:21 - INFO - __main__ - Printing 3 examples
05/22/2022 11:17:21 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/22/2022 11:17:21 - INFO - __main__ - ['false']
05/22/2022 11:17:21 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/22/2022 11:17:21 - INFO - __main__ - ['false']
05/22/2022 11:17:21 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/22/2022 11:17:21 - INFO - __main__ - ['true']
05/22/2022 11:17:21 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:17:21 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:17:21 - INFO - __main__ - Loaded 87 examples from test data
05/22/2022 11:17:22 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down128shot/singletask-ethos-religion/ethos-religion_128_87_0.0001_8_predictions.txt
05/22/2022 11:17:22 - INFO - __main__ - Classification-F1 on test data: 0.5397
05/22/2022 11:17:23 - INFO - __main__ - prefix=ethos-religion_128_87, lr=0.0001, bsz=8, dev_performance=1.0, test_performance=0.5396825396825398
